---

title: Multiplet-based matrix mixing for high-channel count multichannel audio
abstract: A multiplet-based spatial matrixing codec and method for reducing channel counts (and thus bitrates) of high-channel count (seven or more channels) multichannel audio, optimizing audio quality by enabling tradeoffs between spatial accuracy and basic audio quality, and converting audio signal formats to playback environment configurations. An initial N channel count is reduced to M channels by spatial matrix mixing to a lower number of channels using multiplet pan laws. The multiplet pan laws include doublet, triplet, and quadruplet pan laws. For example, using a quadruplet pan law one of the N channels can be downmixed to four of the M channels to create a quadruplet channel. Spatial information as well and audio content is contained in the multiplet channels. During upmixing the downmixed channel is extracted from the multiplet channels using the corresponding multiplet pan law. The extracted channel then is rendered at any location within a playback environment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09552819&OS=09552819&RS=09552819
owner: DTS, Inc.
number: 09552819
owner_city: Calabassas
owner_country: US
publication_date: 20141126
---
This application claims the benefit of U.S. Provisional Patent Application Ser. No. 61 909 841 filed on Nov. 27 2013 entitled MULTIPLET BASED MATRIX MIXING FOR HIGH CHANNEL COUNT MULTICHANNEL AUDIO and U.S. patent application Ser. No. 14 447 516 filed on Jul. 30 2014 entitled MATRIX DECODER WITH CONSTANT POWER PAIRWISE PANNING the entire contents of both of which are hereby incorporated herein by reference.

Many audio reproduction systems are capable of recording transmitting and playing back synchronous multi channel audio sometimes referred to as surround sound. Though entertainment audio began with simplistic monophonic systems it soon developed two channel stereo and higher channel count formats surround sound in an effort to capture a convincing spatial image and sense of listener immersion. Surround sound is a technique for enhancing reproduction of an audio signal by using more than two audio channels. Content is delivered over multiple discrete audio channels and reproduced using an array of loudspeakers or speakers . The additional audio channels or surround channels provide a listener with an immersive listening experience.

Surround sound systems typically have speakers positioned around the listener to give the listener a sense of sound localization and envelopment. Many surround sound systems having only a few channels such as a 5.1 format have speakers positioned in specific locations in a 360 degree arc about the listener. These speakers also are arranged such that all of the speakers are in the same plane as each other and the listener s ears. Many higher channel count surround sound systems such as 7.1 11.1 and so forth also include height or elevation speakers that are positioned above the plane of the listener s ears to give the audio content a sense of height. Often these surround sound configurations include a discrete low frequency effects LFE channel that provides additional low frequency bass audio to supplement the bass audio in the other main audio channels. Because this LFE channel requires only a portion of the bandwidth of the other audio channels it is designated as the .X channel where X is any positive integer including zero such as in 5.1 or 7.1 surround sound .

Ideally surround sound audio is mixed into discrete channels and those channels are kept discrete through playback to the listener. In reality however storage and transmission limitations dictate that the file size of the surround sound audio be reduced to minimize storage space and transmission bandwidth. Moreover two channel audio content is typically compatible with a larger variety of broadcasting and reproduction systems as compared to audio content having more than two channels.

Matrixing was developed to address these needs. Matrixing involves downmixing an original signal having more than two discrete audio channels into a two channel audio signal. The additional channels over two channels are downmixed according to a pre determined process to generate a two channel downmix that includes information from all of the audio channels. The additional audio channels may later be extracted and synthesized from the two channel downmix using an upmix process such that the original channel mix can be recovered to some level of approximation. Upmixing receives the two channel audio signal as input and generates a larger number of channels for playback. This playback is an acceptable approximation of the discrete audio channels of the original signal.

Several upmixing techniques use constant power panning. The concept of panning is derived from motion pictures and specifically the word panorama. Panorama means to have a complete visual view of a given area in every direction. In the audio realm audio can be panned in the stereo field so that the audio is perceived as being positioned in physical space such that all the sounds in a performance are heard by a listener in their proper location and dimension. For musical recordings a common practice is to place the musical instruments where they would be physically located on a real stage. For example stage left instruments are panned left and stage right instruments are panned right. This idea seeks to replicate a real life performance for the listener during playback.

Constant power panning maintains constant signal power across audio channels as the input audio signal is distributed among them. Although constant power panning is widespread current downmixing and upmixing techniques struggle to preserve and recover the precise panning behavior and localization present in an original mix. In addition some techniques are prone to artifacts and all have limited ability to separate independent signals that overlap in time and frequency but originate from different spatial directions.

For example some popular upmixing techniques use voltage controlled amplifiers to normalize both input channels to approximately the same level. These two signals then are combined in an ad hoc manner to produce the output channels. Due to this ad hoc approach however the final output has difficulty achieving desired panning behaviors and includes problems with crosstalk and at best approximates discrete surround sound audio.

Other types of upmixing techniques are precise only in a few panning locations but are imprecise away from those locations. By way of example some upmixing techniques define a limited number of panning locations where upmixing results in precise and predictable behavior. Dominance vector analysis is used to interpolate between a limited number of pre defined sets of dematrixing coefficients at the precise panning location points. Any panning location falling between the points use interpolation to find the dematrixing coefficient values. Due to this interpolation panning locations falling between the precise points can be imprecise and adversely affect audio quality.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Embodiments of the multiplet based spatial matrixing codec and method reduce channel counts and thus bitrates of high channel count seven or more channels multichannel audio. In addition embodiments of the codec and method optimize audio quality by enabling tradeoffs between spatial accuracy and basic audio quality and convert audio signal formats to playback environment configurations. This is achieved in part by determining a target bitrate and the number of channels that the bitrate will support or surviving channels . The remainder of the channels the non surviving channels are downmixed onto multiplets of the surviving channels. This could be a pair or doublet of channels a triplet of channels a quadruplet of channels or any higher order multiplet of channels.

For example a fifth non surviving channel may be downmixed onto four other surviving channels. During upmix the fifth channel is extracted from the four other channels and rendering in a playback environment. Those encoded four channels are further configured and combined in various ways for backwards compatibility with existing decoders and then compressed using either lossy or lossless bitrate compression. The decoder is provided with the encoded four encoded audio channels as well as the relevant metadata enabling proper decoding back to the original source speaker layout such as an 11.x layout .

For the decoder to properly decode a channel reduced signal the decoder must be informed of the layouts parameters and coefficients that were used in the encoding process. For example if the encoder encoded an 11.2 channel base mix to a 7.1 channel reduced signal then information describing the original layout the channel reduced layout the contributing downmix channels and the downmix coefficients will be transmitted to the decoder to enable proper decoding back to the original 11.2 channel count layout. This type of information is provided in the data structure of the bitstream. When information of this nature is provided and used to reconstruct the original signal the codec is operating in metadata mode.

The codec and method can also be used as a blind up mixer for legacy content in order to create an output channel layout that matches the listening layout of the playback environment. The difference in the blind upmix use case is that the codec configures the signal processing modules based on layout and signal assumptions instead of a known encoding process. Thus the codec is operating in blind mode when it does not have or use explicit metadata information.

The multiplet based spatial matrixing codec and method described herein is an attempt to address a number of interrelated problems arising when mixing delivering and reproducing multi channel audio having many channels in a way that gives due regard to backward compatibility and flexibility of mixing or rendering techniques. It will be appreciated by those with skill in the field that a myriad of spatial arrangements are possible for sound sources microphones or speakers and that the speaker arrangement owned by the end consumer may not be perfectly predictable to the artist engineer or distributor of entertainment audio. Embodiments of the codec and method also addresses the need to achieve a functional and practical compromise between data bandwidth channel count and quality that is more workable for large channel counts.

The multiplet based spatial matrixing codec and method are designed to reduce channel counts and thus bit rates optimize audio quality by enabling tradeoffs between spatial accuracy and basic audio quality and convert audio signal formats to playback environment configurations. Accordingly embodiments of the codec and method use a combination of matrixing and discrete channel compression to create and playback a multichannel mix having N channels from a base mix having M channels and LFE channels where N is larger than M and where both N and M are larger than two. This technique is especially advantageous when N is large for example in the range 10 to 50 and includes height channels as well as surround channels and when it is desired to provide a backward compatible base mix such as a 5.1 or 7.1 surround mix.

Given a sound mix comprising base channels such as 5.1 or 7.1 and additional channels the invention uses a combination of pairwise triplet and quadruplet based matrix rules in order to mix additional channels into the base channels in a manner that will allow a complementary upmix said upmix capable of recovering the additional channels with clarity and definition together with a convincing illusion of a spatially defined sound source for each additional channel. Legacy decoders are enabled to decode the base mix while newer decoders are enabled by embodiments of the codec and method to perform an upmix that separates additional channels such as height channels .

It should be noted that alternative embodiments are possible and steps and elements discussed herein may be changed added or eliminated depending on the particular embodiment. These alternative embodiments include alternative steps and alternative elements that may be used and structural changes that may be made without departing from the scope of the invention.

In the following description of embodiments of a multiplet based spatial matrixing codec and method reference is made to the accompanying drawings. These drawings shown by way of illustration specific examples of how embodiments of the multiplet based spatial matrixing codec and method may be practiced. It is understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the claimed subject matter.

Following are some basic terms and concepts used in this document. Note that some of these terms and concepts may have slightly different meanings than they do when used with other audio technologies.

This document discusses both channel based audio and object based audio. Music or soundtracks traditionally are created by mixing a number of different sounds together in a recording studio deciding where those sounds should be heard and creating output channels to be played on each individual speaker in a speaker system. In this channel based audio the channels are meant for a defined standard speaker configuration. If a different speaker configuration is used the sounds may not end up where they are intended to go or at the correct playback level.

In object based audio all of the different sounds are combined with information or metadata describing how the sound should be reproduced including its position in a three dimensional 3D space. It is then up to the playback system to render the object for the given speaker system so that the object is reproduced as intended and placed at the correct position. With object based audio the music or soundtrack should sound essentially the same on systems with different numbers of speakers or with speakers in different positions relative to the listener. This methodology helps preserve the true intent of the artist.

The phrase gain coefficient is an amount by which the level of an audio signal is adjusted to increase or decrease its volume. The term rendering indicates a process to transform a given audio distribution format to the particular playback speaker configuration being used. Rendering attempts to recreate the playback spatial acoustical space as closely to the original spatial acoustical space as possible given the parameters and limitations of the playback system and environment.

When either surround or elevated speakers are missing from the speaker layout in the playback environment then audio objects that were meant for these missing speakers may be remapped to other speakers that are physically present in the playback environment. In order to enable this functionality virtual speakers can be defined that are used in the playback environment but are not directly associated with an output channel. Instead their signal is rerouted to physical speaker channels by using a downmix map.

As used in this document the term multiplet means a grouping of a plurality of channels that has a signal panned onto it. For example one type of multiplet is a doublet whereby a signal is panned onto two channels. Similarly another type of multiplet is a triplet whereby a signal is panned onto three channels. When a signal is panned onto four channels the resulting multiplet is called a quadruplet. The multiplet can include a grouping of two or more channels including five channels six channels seven channels and so forth onto which a signal is panned. For pedagogical purposes this document only discusses the doublet triplet and quadruplet cases. However it should be noted that the principles taught herein can be expanded to multiplets containing five or more channels.

Embodiments of the multiplet based spatial matrixing codec and method or aspects thereof are used in a system for delivery and recording of multichannel audio especially when large numbers of channels are to be transmitted or recorded. As used in this document high channel count multichannel audio means that there are seven or more audio channels. For example in one such system a multitude of channels are recorded and are assumed to be configured in a known playback geometry having L channels disposed at ear level around the listener P channels disposed around a height ring disposed at higher than ear level and optionally a center channel at or near the Zenith above the listener where L and P are positive integers larger than 1 .

The P or height plane contains a left front height speaker and a right front height speaker . The P plane also includes a left surround height speaker and a right surround height speaker . The optional overhead speaker is shown located in the P plane . Alternatively the optional overhead speaker may be located above the P plane at a zenith of the content creation environment. The L plane and the P plane are separated by a distance d.

Although an 11.1 content creation environment speaker layout along with an optional overhead speaker is shown in embodiments of the multiplet based spatial matrixing codec and method can be generalized such that content could be mixed in high channel count environments containing seven or more audio channels. Moreover it should be noted that in the speakers in the content creation environment speaker layout and the listener s head and ears are not to scale with each other. In particular the listener s head and ears are shown larger than scale to illustrate the concept that each of the speakers and the listener s ears are in the same horizontal plane as the L plane .

The speakers in the P plane may be arranged according to various conventional geometries and the presumed geometry is known to a mixing engineer or recording artist engineer. According to embodiments of the multiplet based spatial matrixing codec and method the L P channel count is reduced by a novel method of matrix mixing to a lower number of channels for example L P channels mapped onto L channels only . The reduced count channels are then encoded and compressed by known methods that preserve the discrete nature of the reduced count channels.

On decoding the operation of embodiments of the codec and method depends upon the decoder capabilities. In legacy decoders the reduced count L channels are reproduced having the P channels mixed therein. In a more advanced decoder the full consort of L P channels are recoverable by upmixing and routed each to a corresponding one of the L P speakers.

In accordance with the invention both upmixing and downmixing operations matrixing dematrixing include a combination of multiplet pan laws such as pairwise triplet and quadruplet pan laws to place the perceived sound sources upon reproduction closely corresponding to the presumed locations intended by the recording artist or engineer. The matrixing operation channel layout reduction can be applied to the bed mix channels in a a bed mix plus object composition of the enhanced bitstream b a channel based only composition of the enhanced bitstream. In addition the matrixing operation can be applied to stationary objects objects that are not moving around and after dematrixing still achieve sufficient object separation that will allow independent level modifications and rendering for individual objects or c applying the matrixing operation to channel based objects.

Embodiments of the multiplet based spatial matrixing codec and method reduce high channel count multichannel audio and bitrates by panning certain channels onto multiplets of remaining channels. This serves to optimize audio quality by enabling tradeoffs between spatial accuracy and basic audio quality. Embodiments of the codec and method also convert audio signal formats to playback environment configurations.

The content creator selects an N.x base mix that best represents the creator s spatial intent where N represents the number of regular channels and x represents the number of low frequency channels. Moreover N is a positive integer greater than 1 and x is a non negative integer. For example in an 11.1 surround system N 11 and x 1. This of course is subject to a maximum number of channels such that N x MAX where MAX is a positive integer representing the maximum number of allowable channels.

In the final mix is an N.x mix such that each of the audio sources is mixed into N x number of channels. The final N.x mix then is encoded and downmixed using the multiplet based spatial matrixing encoder . The encoder is typically located on a computing device having one or more processing devices. The encoder encodes and downmixes the final N.x mix into an M.x mix having M regular channels and x low frequency channels where M is a positive integer greater than 1 and M is less than N.

The M.x downmix is delivered for consumption by a listener through a delivery environment . Several delivery options are available including streaming delivery over a network . Alternatively the M.x downmix may be recorded on a media such as optical disk for consumption by the listener. In addition there are many other delivery options not enumerated here that may be used to deliver the M.x downmix.

The output of the delivery environment is an M.x stream that is input to the multiplet based spatial matrixing decoder . The decoder decodes and upmixes the M.x stream to obtain a reconstructed N.x content . Embodiments of the decoder are typically located on a computing device having one or more processing devices.

Embodiments of the decoder extract the PCM audio from the compressed audio stored in the M.x stream . The decoder used is based upon which audio compression scheme was used to compress the data. Several types of audio compression schemes may be used in the M.x stream including lossy compression low bitrate coding and lossless compression.

The decoder decodes each channel of the M.x stream and expands them into discrete output channels represented by the N.x output . This reconstructed N.x output is reproduced in a playback environment that includes a playback speaker or channel layout. The playback speaker layout may or may not be the same as the content creation speaker layout. The playback speaker layout shown in is an 11.2 layout. In other embodiments the playback speaker layout may be headphones such that the speakers are merely virtual speakers from which sound appears to originate in the playback environment . For example the listener may be listening to the reconstructed N.x mix through headphones. In this situation the speakers are not actual physical speakers but sounds appear to originate from different spatial locations in the playback environment corresponding for example to an 11.2 surround sound speaker configuration.

The N.x PCM bed mix is input to the multiplet based matrix mixing system . The system processes the N.x PCM bed mix as explained in detail below and reduces the channel count of the N.x PCM bed mix to an M.x PCM bed mix . In addition the system output assorted information including an M.x layout metadata which is data about the spatial layout of the M.x PCM bed mix . The system also outputs information about the original channel layout and matrixing metadata . The original channel layout is spatial information about the layout of the original channels in the content creation environment . The matrixing metadata contains information about the different coefficients used during the downmixing. In particular it contains information about how the channels were encoded into the downmix so that the decoder knows the correct way to upmix.

As shown in the object PCM the object metadata the M.x PCM bed mix the M.x layout metadata and the original channel layout and matrixing metadata all are input to the compression and bitstream packing module . The module takes this information compresses it and packs it into an M.x enhanced bitstream . The bitstream is referred to as enhanced because in addition to audio data it also contains spatial and other types of metadata.

Embodiments of the multiplet based matrix mixing system reduce the channel count by examining such variables as a total available bitrate minimum bitrate per channel a discrete audio channel and so forth. Based on these variables the system takes the original N channels and downmixes them to M channels. The number M is dependent on the data rate. By way of example if N equals 22 original channels and the available bitrate is 500 Kbits second then the system may determine that M has to be 8 in order to achieve the bitrate and encode the content. This means that there is only enough bandwidth to encode 8 audio channels. These 8 channels then will be encoded and transmitted.

The decoder will know that these 8 channels came from an original 22 channels and we upmix those 8 channels back up to 22 channels. Of course there will be some level of spatial fidelity lost in order to achieve the bitrate. For example assume that the given minimum bitrate per channel is 32 Kbits channel. If the total bitrate is 128 bits second then 4 channels could be encoded at 32 Kbits channel. In another example suppose that the input to the encoder is an 11.1 base mix the given bitrate is 128 kbits second and the minimum bitrate per channel is 32 Kbits second. This means that the codec and method would take those 11 original channels and downmix them to 4 channels transmit the 4 channels and at the decode side upmix those 4 channels back to 11 channels.

The M.x enhanced bitstream is delivered to a receiving device containing the decoder for rendering. is a block diagram illustrating the details of non legacy embodiments of the multiplet based spatial matrixing decoder shown in . In these non legacy embodiments the decoder does not retain backward compatibility with previous types of bitstreams and cannot decode them. As shown in the decoder includes a multiplet based matrix upmixing system a decompression and bitstream unpacking module a delay module an object inclusion rendering engine and a downmixer and speaker remapping module .

As shown in the input to the decoder is the M.x enhanced bitstream . The decompression and bitstream unpacking module then unpack and decompress the bitstream back into PCM signals including the bed mix and audio objects and associated metadata. The output from the module is an M.x PCM bed mix . In addition the original N.x channel layout and the matrixing metadata including the matrixing coefficients the object PCM and the object metadata are output from the module .

The M.x PCM bed mix is processed by the multiplet based matrix upmixing system and upmixed. The multiplet based matrix upmixing system is discussed further below. The output of the system is an N.x PCM bed mix which is in the same channel or speaker layout configuration as the original layout. The N.x PCM bed mix is processed by the downmixer and speaker remapping module to map the N.x bed mix into the listener s playback speaker layout. For example if N 22 and M 11 then the 22 channels would be downmixed to 11 channels by the encoder . The decoder then would take the 11 channels and upmix them back to 22 channels. But if the listener has only a 5.1 playback speaker layout then the module would downmix those 22 channels and remap them to the playback speaker layout for playback by the listener.

The downmixer and speaker remapping module is responsible for adapting the content stored in the bitstream to a given output speaker configuration. Theoretically the audio can be formatted for any arbitrary playback speaker layout. The playback speaker layout is selected by the listener or the system. Based on this selection the decoder selects the channel sets that need to be decoded and determines whether speaker remapping and downmixing must be performed. The selection of output speaker layout is performed using an application programming interface API call.

When the intended playback loudspeaker layout does not match the actual playback loudspeaker layout of the playback environment or listening space the overall impression of an audio presentation may be compromised. In order to optimize the audio presentation quality in a number of popular speaker configurations the M.x enhanced bitstream can contain loudspeaker remapping coefficients.

There are two modes of operation for embodiments of the downmixer and speaker remapping module . First a direct mode whereby the decoder configures the spatial remapper to produce the originally encoded channel layout over the given output speaker configuration as closely as possible. Second a non direct mode whereby embodiments of the decoder will convert the content to the selected output channel configuration regardless of the source configuration.

The object PCM gets delayed by the delay module so that there is some level of latency while the M.x PCM bed mix is processed by the multiplet based matrix upmixing system . The output of the delay module is delayed object PCM . This delayed object PCM and the object metadata are summed and rendered by the object inclusion rendering engine .

The object inclusion rendering engine and an object removal rendering engine discussed below are the main engines for performing 3D object based audio rendering. The primary job of these rendering engines is to add or subtract registered audio objects to or from a base mix. Each object comes with information dictating its position in a 3D space including its azimuth elevation distance gain and a flag dictating if the object should be allowed to snap to the nearest speaker location. Object rendering performs the necessary processing to place the object at the position indicated. The rendering engines support both point and extended sources. A point source sounds as though it is coming from one specific spot in space whereas extended sources are sounds with width a height or both.

The rendering engines use a spherical coordinate system representation. If an authoring tool in the content creation environment represents the room as a shoe box then transformation from concentric boxes to concentric spheres and back can be performed under the hood within an authoring tool. In this manner placement of sources on the walls maps to the placement of the sources on the unit sphere.

The bed mix from the downmixer and speaker remapping module and the output from the object inclusion rendering engine are combined to provide an N.x audio presentation . The N.x audio presentation is output from the decoder and played back on the playback speaker layout not shown .

It should be noted that some of the modules of the decoder may be optional. For example the multiplet based matrix upmixing system is not needed if N.M. Similarly the downmix and speaker remapping module are not needed if N.M. And the object inclusion rendering engine is not needed if there are no objects in the M.x enhanced bitstream and the signal is only a channel based signal.

As shown in the encoder includes an object inclusion rendering engine and a downmix embedder . For the purposes of backward compatibility any audio information stored in audio objects is also mixed into the M.x bed mix to create a base mix that legacy decoders can use. If the decoder system can render objects then the objects must be removed from the base mix so that they are not doubly reproduced. The decoded objects are rendered to an appropriate bed mix specifically for this purpose and then subtracted from the base mix.

The object PCM and the object metadata are input to the engine and are mixed with the M.x PCM bed mix . The result goes to the downmix embedder that creates an embedded downmix. This embedded downmix downmix metadata M.x layout metadata original channel layout and matrixing metadata the object PCM and the object metadata are compressed and packed into a bitstream by the compression and bitstream packing module . The output is a backward compatible M.x enhanced bitstream .

The backward compatible M.x enhanced bitstream is delivered to a receiving device containing the decoder for rendering. is a block diagram illustrating the details of backward compatible embodiments of the multiplet based spatial matrixing decoder shown in . In these backward compatible embodiments the decoder retains backward compatibility with previous types of bitstreams to enable the decoder to decode them.

The backward compatible embodiments of the decoder are similar to the non backward compatible embodiments shown in except that there is an object removal portion. These backward compatible embodiments deal with legacy issues of the codec where it is desirable to provide a bitstream that legacy decoders can still decode. In these cases the decoder removes the objects from the embedded downmix and then upmixes to obtain the original upmix.

As shown in the decompression and bitstream unpacking module outputs the original channel layout and matrixing coefficients the object PCM and the object metadata . The output of the module also undoes the embedded downmixing of the embedded downmix to obtain the M.x PCM bed mix . This basically separates the channels and the objects from each other.

After encoding the new smaller channel layout may still have too many channels to store in the portion of the bitstream used by legacy decoders. In these cases as noted above with reference to an additional embedded downmix is performed to ensure that the audio from the channels not supported in older decoders is included in the backwards compatible mix. The extra channels present are downmixed into the backwards compatible mix and transmitted separately. When the bitstream is decoded for a speaker output format that will support more channels than the backwards compatible mix the audio from the extra channels is removed from the mix and the discrete channels are used instead. This operation of undoing the embedded downmix occurs before upmixing.

The output of the module also includes M.x layout metadata . The M.x layout metadata and the object PCM are used by an object removal rendering engine to render the removed objects into the M.x PCM bed mix . The object PCM is also run through the delay module and into the object inclusion rendering engine . The engine takes the object metadata the delayed object PCM and renders the objects and N.x bed mix into an N.x audio presentation for playback on the playback speaker layout not shown .

The system details of components of embodiments of the multiplet based spatial matrixing codec and method will now be discussed. It should be noted that only a few of the several ways in which the modules systems and codecs may be implemented are detailed below. Many variations are possible from that which is shown in .

The system also includes a mixing coefficient matrix downmixer . The hollow arrows in indicate that the signal is a time domain signal. The downmixer takes surviving channels and passes them through without processing. Non surviving channels are downmixed onto multiplets based on proximity. In particular some non surviving channels may be downmixed onto surviving pairs or doublets . Some non surviving channels may be downmixed onto surviving triplets of surviving channels. Some non surviving channels may be downmixed onto surviving quadruplets of surviving channels. This can continue for multiplets of any Y where Y is a positive integer greater than 2. For example if Y 8 then a non surviving channel may be downmixed onto a surviving octuplet of surviving channels. This is shown in by the ellipsis . It should noted that some all or any combination of multiplets may be used to downmix the N.x PCM bed mix .

The resultant M.x downmix from the downmixer goes into a loudness normalization module . The normalization process is discussed more in detail below. The N.x PCM bed mix is used to normalize the M.x downmix and the output is a normalized M.x PCM bed mix .

These passes continue through each of the Y number of multiplets as indicated by the ellipses . The passes then continue sequentially until each of the Y multiplets has been processed. shows that the spatial analysis is performed on the quadruplets to obtain spatial information such as the radius and angle in space of the non surviving channel downmixed to the quadruplets. Next the non surviving channel is extracted from the quadruplets of surviving channels . The extracted channel C Y is then input to the subband power normalization module . The channels involved in this pass then are repanned .

In the next pass the spatial analysis is performed on the triplets to obtain spatial information such as the radius and angle in space of the non surviving channel downmixed to the triplets. Next the non surviving channel is extracted from the triplets of surviving channels . The extracted channel C Y is then input to the module . The channels involved in this pass then are repanned . Similarly in the last pass the spatial analysis is performed on the doublets to obtain spatial information such as the radius and angle in space of the non surviving channel downmixed to the doublets. Next the non surviving channel is extracted from the doublets of surviving channels . The extracted channel C Y 1 is then input to the module . The channels involved in this pass then are repanned .

Each of the channels then are processed by the module to obtained a N.x upmix. This N.x upmix is processed by the oversampled synthesis filter bank to combine them into the N.x PCM bed mix . As shown in the N.x PCM bed mix then is input to the downmixer and speaker remapping module .

Embodiments of the multiplet based spatial matrixing codec and method are spatial encoding and decoding technologies that reduce channel counts and thus bitrates optimize audio quality by enabling tradeoffs between spatial accuracy and basic audio quality and convert audio signal formats to playback environment configurations.

Embodiments of the encoder and decoder have two primary use cases. A first use case is the metadata use case where embodiments of the multiplet based spatial matrixing codec and method are used to encode high channel count audio signals onto a lower number of channels. In addition this use case includes decoding of the lower number of channels in order to recover an accurate approximation of the original high channel count audio. A second use case is the blind upmix use case that performs blind upmixing of legacy content in standard mono stereo or multi channel layouts such as 5.1 or 7.1 to 3D layouts consisting of both horizontal and elevated channel locations.

The first use case for embodiments of the codec and method is as a bitrate reduction tool. One example scenario where the codec and method may be used for bitrate reduction is when the available bitrate per channel is below the minimum bitrate per channel supported by the codec . In this scenario embodiments of the codec and method may be used reduce the number of encoded channels thus enabling a higher bitrate allocation for the surviving channels. These channels need to be encoded with sufficiently high bitrate to prevent unmasking of artifacts after dematrixing.

In this scenario the encoder may use matrixing for bit rate reduction dependent on one or more of the following factors. One factor is the minimum bitrate per channel required for discrete channel encoding designated as MinBR Discr . Another factor is the minimum bit rate per channel required for matrixed channel encoding designated as MinBR Mtrx . Still another factor is the total available bit rate designated as BR Tot .

In addition the original channel layout and metadata describing the matrixing procedure is carried in the bitstream. Moreover the value of the MinBR Mtrx is chosen to be sufficiently high for each respective codec technology to prevent unmasking of artifacts after dematrixing.

On the decoder side upmixing is performed just to bring the format to the original N.x layout or some proper sub set of the N.x layout. There is upmixing is needed for further format conversion. It is assumed that the spatial resolution carried in the original N.x layout is the intended spatial resolution hence any further format conversion will consist of just downmixing and possible speaker remapping. In the case of a channel based only stream the surviving M.x layout may be used directly without applying dematrixing as a starting point for the derivation of a desired downmix K.x K

Another example scenario where the codec and method may be used for bitrate reduction is when the original high channel count layout has high spatial accuracy such as 22.2 and the available bitrate is sufficient to encode all channels discretely but not sufficient enough to provide a near transparent basic audio quality level. In this scenario embodiments of the codec and method may be used to optimize overall performance by slightly sacrificing spatial accuracy but in return allowing an improvement in basic audio quality. This is achieved by converting the original layout to a layout with less channels sufficient spatial accuracy such as 11.2 and allocating all of the bitpool to surviving channels to provide bring basic audio quality to a higher level while not having a great impact on the spatial accuracy.

In this example the encoder uses matrixing as a tool to optimize overall quality by slightly sacrificing spatial accuracy but in return allowing an improvement in basic audio quality. The surviving channels are chosen to best preserve the original spatial accuracy with a minimum number of encoded channels. In addition the original channel layout and metadata describing the matrixing procedure is carried in the stream.

The encoder selects a bitrate per channel that may be sufficiently high to allow object inclusion into the surviving layout as well as further downmix embedding. Moreover either M.x or an associated embedded downmix may be directly playable on a 5.1 7.1 systems.

The decoder in this example uses upmixing is performed just to bring the format to the original N.x layout or some proper sub set of the N.x layout. No further format conversion is needed. It is assumed that the spatial resolution carried in the original N.x layout is the intended spatial resolution hence any further format conversion will consist of just downmixing and possibly speaker remapping.

For the above scenarios the encoding and method described herein may be applied to a channel based format or to the base mix channels in an object plus base mix format. The corresponding decoding operation will bring the channel reduced layout back to the original high channel count layout.

For channel reduced signal to be property decoded the decoder described herein must be informed of the layouts parameters and coefficients that were used in the encoding process. The codec and method defines a bitstream syntax for communicating such information from the encoder to the decoder . For example if the encoder encoded a 22.2 channel base mix to an 11.2 channel reduced signal then information describing the original layout the channel reduced layout the contributing downmix channels and the downmix coefficients will be transmitted to the decoder to enable proper decoding back to the original 22.2 channel count layout.

The second use case for embodiments of the codec and method is to perform blind upmixing of legacy content. This capability allows the codec and method to convert legacy content to 3D layouts including horizontal and elevated channels matching the loudspeaker locations of the playback environment . Blind upmixing can be performed on standard layouts such as mono stereo 5.1 7.1 and others.

Next the N channels are downmixed and encoded to M channels using a combination of multiplet pan laws to obtain PCM bed mix containing M multiplet encoded channels box . The method then transmits PCM bed mix at or below the desired bitrate over a network box . The PCM bed mix is received and separated into the plurality of M number of multiplet encoded channels box .

The method then upmixes and decodes each of the M multiplet encoded channels using a combination of multiplet pan laws to extract the N channels from the M multiplet encoded channels and obtain a resultant output audio signal having N channels box . This resultant output audio signal is rendered in a playback environment having a playback channel layout box .

Embodiments of the codec and method or aspects thereof is used in a system for delivery and recording of multichannel audio especially when large numbers of channels are to be transmitted or recorded more than 7 . For example in one such system a multitude of channels are recorded and are assumed to be configured in a known playback geometry having L channels disposed at ear level around the listener P channels disposed around a height ring disposed at higher than ear level and optionally a center channel at or near the Zenith above the listener where L and P are arbitrary integers larger than 1 . The P channels may be arranged according to various conventional geometries and the presumed geometry is known to a mixing engineer or recording artist engineer. According to the invention the L plus P channel count is reduced by a novel method of matrix mixing to a lower number of channels for example L P mapped onto L only . The reduced count channels are then encoded and compressed by known methods that preserve the discrete nature of the reduced count channels.

On decoding the operation of the system depends upon the decoder capabilities. In legacy decoders the reduced count L channels are reproduced having the P channels mixed therein. In a more advanced decoder according to the invention the full consort of L P channels are recoverable by upmixing and routed each to a corresponding one of the L P speakers.

In accordance with the invention both upmixing and downmixing operations matrixing dematrixing include a combination of pairwise triplet and preferably quadruplet pan laws to place the perceived sound sources upon reproduction closely corresponding to the presumed locations intended by the recording artist or engineer.

The matrixing operation channel layout reduction can be applied to the base mix channels in a a base mix object composition of the stream or b a channel based only composition of the stream.

In addition the matrixing operation can be applied to the stationary objects objects that are not moving around and after dematrixing still achieve sufficient object separation that will allow level modifications for individual

The operational details of embodiments of the multiplet based spatial matrixing codec and method now will be discussed.

In an exemplary embodiment of the multiplet based matrix downmixing system the system accepts an N channel audio signal and outputs an M channel audio signal where N and M are integers and N is greater than M. The system may be configured using knowledge of the content creation environment original channel layout the downmixed channel layout and mixing coefficients that describe the mixing weights that each original channel will contribute to each downmixed channel. For example the mixing coefficients may be defined by a matrix C of size M N where the rows correspond to the output channels and the columns correspond to the input channels such as 

Some embodiments of the system also include a loudness normalization module shown in . The loudness normalization process is designed to normalize the perceived loudness of the downmixed signal to that of the original signal. While the mixing coefficients of matrix C are commonly chosen to preserve power for a single original signal component for example a standard sin cos panning law will preserve power for a single component for more complex signal material the power preservation properties will not hold. Because the downmix process combines audio signals in the amplitude domain and not the power domain the resulting signal power of the downmixed signal is unpredictable and signal dependent. Furthermore it may be desirable to preserve perceived loudness of the downmixed audio signal instead of signal power since loudness is a more relevant perceptual property.

The loudness normalization process is performed by comparing the ratio of the input loudness to the downmixed loudness. The input loudness is estimated via the following equation 

As can be observed the input loudness is essentially a root mean squared RMS measure of the frequency weighted input channels where the frequency weighting is designed to improve correlation with the human perception of loudness. Likewise the output loudness is estimated via the following equation 

Now that estimates of both the input and output perceived loudness have been computed we can normalize the downmixed audio signal such that the loudness of the downmixed signal will be approximately equal to the loudness of the original signal via the following normalization equation 

In the above equation it can be observed that the loudness normalization process results in scaling all of the downmixed channels by the ratio of the input loudness to the output loudness.

The static downmix for a given output channel y n where x n are the input channels and care the downmix coefficients for output channel i and input channel j. Per Channel Loudness Normalization

Dynamic downmix using per channel loudness normalization where d n is a channel dependent gain given as

Intuitively the time varying per channel gains can be viewed as the ratio of the summed loudness of each input channel weighted by the appropriate downmix coefficient by the loudness of each statically downmixed channel.

Intuitively the time varying channel independent gain can be viewed as the ratio of the summed loudness of the input channels by the summed loudness of the downmixed channels.

In exemplary embodiments of the multiplet based matrix upmixing system shown in the system accepts an M channel audio signal and outputs an N channel audio signal where M and N are integers and N is greater than M. In some embodiments the system will target an output channel layout that is the same as the original channel layout as processed by a downmixer. In some embodiments the upmix processing is performed in the frequency domain with the inclusion of analysis and synthesis filter banks. Performing the upmix processing in the frequency domain allows for separate processing on a plurality of frequency bands. Processing multiple frequency bands separately allows the upmixer to handle situations where different frequency bands are simultaneously emanating from different locations in a sound field. Note however that it is also possible to perform the upmix processing on the broadband time domain signals.

After the input audio signal has been converted to a frequency domain representation spatial analysis is performed on any quadruplet channel sets upon which surplus channels have been matrixed following the quadruplet mathematical framework previously described herein. Based on the quadruplet spatial analysis output channels are extracted from the quadruplet sets again following the previously described quadruplet framework. The extracted channels correspond to the surplus channels that were originally matrixed onto the quadruplet sets in the downmixing system . The quadruplet sets are then re panned appropriately based on the extracted channels again following the previously described quadruplet framework.

After quadruplet processing has been performed the downmixed channels are passed to triplet processing modules where spatial analysis is performed on any triplet channel sets upon which surplus channels have been matrixed following the triplet mathematical framework previously described herein. Based on the triplet spatial analysis output channels are extracted from the triplet sets again following the previously described triplet framework. The extracted channels correspond to the surplus channels that were originally matrixed onto the triplet sets in the downmixing system . The triplet sets are then re panned appropriately based on the extracted channels again following the previously described triplet framework.

After triplet processing has been performed the downmixed channels are passed to pairwise processing modules where spatial analysis is performed on any pairwise channel sets upon which surplus channels have been matrixed following the pairwise mathematical framework previously described herein. Based on the pairwise spatial analysis output channels are extracted from the pairwise sets again following the previously described pairwise framework. The extracted channels correspond to the surplus channels that were originally matrixed onto the pairwise sets in the downmixing system . The pairwise sets are then re panned appropriately based on the extracted channels again following the previously described pairwise framework.

At this point the N channel output signal has been generated in the frequency domain and consists of all of the extracted channels from the quadruplet triplet and pairwise sets as well as the re panned downmixed channels. Before converting the channels back to the time domain some embodiments of the upmixing system may perform a subband power normalization which is designed to normalize the total power within each output subband to that of each input downmixed subband. The total power of each input downmixed subband can be estimated as 

Now that estimates of both the input and output subband powers have been computed we can normalize the output audio signal such that the power of the output signal per subband will be approximately equal to the power of the input downmixed signal per subband via the following normalization equation 

In the above equation it can be observed that the subband power normalization process results in scaling all of the output channels by the ratio of the input power to the output power per subband. If the upmixer is not performed in the frequency domain then a loudness normalization process may be performed instead of the subband power normalization process similar to that as described in the downmix architecture.

Once all output channels have been generated and subband powers have been normalized the frequency domain output channels are sent to a synthesis filter bank module which converts the frequency domain channels back to time domain channels.

The actual matrix downmixing and complementary upmixing in accordance with embodiments of the codec and method are performed using a combination of pairwise triplet and preferably also quadruplet mixing laws depending on speaker configuration. In other words if in recording mixing a particular speaker is to be eliminated or virtualized by downmixing a decision is applied whether the position is a case of a on or near a line segment between a pair of surviving speakers b within a triangle defined by 3 surviving channel speakers or c within a quadrilateral defined by four channel speakers each disposed at a vertex.

This last case is advantageous for matrixing a height channel disposed at the zenith for example. Also note that in other embodiments of the codec and method the matrixing could be extended beyond quadruplet channel sets if the geometry of the original and downmixed channel layouts required it such as to quintuplet or sextuplet channel sets.

In some embodiments of the codec and method the signal in each audio channel is filtered into a plurality of subbands for example perceptually relevant frequency bands such as Bark bands. This may advantageously be done by a band of quadrature mirror filters or by polyphase filters followed optionally by decimation to reduce the required number of samples in each subband known in the art . Following filtering the matrix downmix analysis should be performed independently in each perceptually significant subband in each coupled set of audio channels pair triplet or quad . Each coupled set of subbands is then analyzed and processed preferably by the equations and methods set forth below to provide an appropriate downmix from which the original discrete subband channel set can be recovered by performing a complementary upmix in each subband channel set at a decoder.

The following discussion sets forth the preferred method in accordance with embodiments of the codec and method for downmixing and complementary upmixing N to M channels and vice versa where each of the surplus channels is mixed either to a channel pair doublet triplet or quadruplet. The same equations and principles are applicable whether mixing in each subband or in wideband signal channels.

In the decoder upmix case the order of operations is significant in that it is very strongly preferred according to embodiments of the codec and method to first process quadruplet sets then triplet sets then channel pairs. This can be extended to cases where there are Y multiplets such that the largest multiplet is processed first followed by the next largest multiplet and so forth. Processing the channel sets with the largest number of channels first allows the upmixer to analyze the broadest and most general channel relationships. By processing the quadruplet sets prior to the triplet or pairwise sets the upmixer can accurately analyze the relevant signal components that are common across all channels included in the quadruplet set. After the broadest channel relationships are analyzed and processed via the quadruplet processing the next broadest channel relationships can be analyzed and processed via the triplet processing. The most limited channel relationships the pairwise relationships are processed last. If the triplet or pairwise sets happened to be processed before the quadruplet sets then although some meaningful channel relationships may be observed across the triplet or pairwise channels those observed channel relationships would only be a subset of the true channel relationships.

As an example consider a scenario where a given channel call this channel A of an original audio signal is downmixed onto a quadruplet set. At the upmixer the quadruplet processing will be able to analyze the common signal components of channel A across that quadruplet set and extract an approximation of the original audio channel A. Any subsequent triplet or pairwise processing will be performed as expected and no further analysis or extraction will be carried out on the channel A signal components since they have already been extracted. If instead triplet processing is performed prior to the quadruplet processing and the triplet set is a subset of the quadruplet set then the triplet processing will analyze the common signal components of channel A across that triplet set and extract an audio signal to a different output channel i.e. not output channel A . If the quadruplet processing is then performed after the triplet processing then the original audio channel A will not be able to be extracted since only a portion of the channel A signal components will still exist across the quadruplet channel set i.e. a portion of the channel A signal components have already been extracted during the triplet processing .

As explained above processing quadruplet sets first followed by triplet sets followed by pairwise sets last is the preferred sequence of processing. It should be noted that although the above discussion addresses pairwise doublet triplet and quadruplet sets any number of sets are possible. For pairwise sets a line is formed for triplet sets a triangle is formed and for quadruplet sets a square is formed. However additional types of polygons are possible.

In accordance with embodiments of the codec and method when the location of a non surviving or surplus channel lies between a doublet defined by the positions of two surviving channels or corresponding subbands in surviving channels the channel to be downmixed should be matrixed in accordance with a set of doublet or pairwise channel relationships as set forth below.

Embodiments of the multiplet based spatial matrixing codec and method calculate an inter channel level difference between the left and right channels. This calculation is shown in detail below. Moreover the codec and method use the inter channel level difference to compute an estimated panning angle. In addition an inter channel phase difference is computed by the method using the left and right input channels. This inter channel phase difference determines a relative phase difference between the left and right input channels that indicates whether the left and right signals of the two channel input audio signal are in phase or out of phase.

Some embodiments of the codec and method utilize a panning angle to determine the downmix process and subsequent upmix process from the two channel downmix. Moreover some embodiments assume a Sin Cos panning law. In these situations the two channel downmix is calculated as a function of the panning angle as 

To synthesize the additional audio channels from a two channel downmix an estimate of the panning angle or estimated panning angle denoted as circumflex over can be calculated from the inter channel level difference denoted as ICLD . Let the ICLD be defined as 

Assuming that a signal component is generated via intensity panning using the Sin Cos panning law the ICLD can be expressed as a function of the panning angle estimate 

The following angle sum and difference identities will be used throughout the remaining derivations sin sin cos cos sin cos cos cos sin sin Moreover the following derivations assume a 5.1 surround sound output configuration. However this analysis can easily be applied to additional channels.

A Center channel is generated from a two channel downmix using the following equation where the a and b coefficients are determined based on the panning angle estimate circumflex over to achieve certain pre defined goals. In Phase Components

For the in phase components of the Center channel a desired panning behavior is illustrated in . illustrates panning behavior corresponding to an in phase plot given by the equation sin circumflex over Substituting the desired Center channel panning behavior for in phase components and the assumed Sin Cos downmix functions yields 

For the out of phase components of the Center channel a desired panning behavior is illustrated in . illustrates panning behavior corresponding to an out of phase plot given by the equation 0 Substituting the desired Center channel panning behavior for out of phase components and the assumed Sin Cos downmix functions leads to 

The surround channels are generated from a two channel downmix using the following equations where Lis the left surround channel and Ris the right surround channel. Moreover the a and b coefficients are determined based on the estimated panning angle circumflex over to achieve certain pre defined goals. In Phase Components

The ideal panning behavior for in phase components of the Left Surround channel is illustrated in . illustrates panning behavior corresponding to an in phase plot given by the equation 0

Substituting the desired Left Surround channel panning behavior for in phase components and the assumed Sin Cos downmix functions leads to 

The goal for the Left Surround channel for out of phase components is to achieve panning behavior as illustrated by the out of phase plot in . illustrates two specific angles corresponding to downmix equations where the Left Surround and Right Surround channels are discretely encoded and decoded these angles are approximately 0.25 and 0.75 corresponding to 45 and 135 on the out of phase plot in . These angles are referred to as Left Surround encoding angle 0.25 Right Surround encoding angle 0.75 

The a and b coefficients for the Left Surround channel are generated via a piecewise function due to the piecewise behavior of the desired output. For circumflex over the desired panning behavior for the Left Surround channel corresponds to 

Substituting the desired Left Surround channel panning behavior for out of phase components and the assumed Sin Cos downmix functions leads to 

Substituting the desired Left Surround channel panning behavior for out of phase components and the assumed Sin Cos downmix functions leads to 

Substituting the desired Left Surround channel panning behavior for out of phase components and the assumed Sin Cos downmix functions leads to 

The a and b coefficients for the Right Surround channel generation are calculated similarly to those for the Left Surround channel generation as described above.

The Left and Right channels are modified using the following equations to remove either fully or partially those components generated in the Center and Surround channels where the a and b coefficients are determined based on the panning angle estimate circumflex over to achieve certain pre defined goals and L is the modified Left channel and R is the modified Right channel. In Phase Components

The goal for the modified Left channel for in phase components is to achieve panning behavior as illustrated by the in phase plot in . In a panning angle of 0.5 corresponds to a discrete Center channel. The a and b coefficients for the modified Left channel are generated via a piecewise function due to the piecewise behavior of the desired output.

Substituting the desired modified Left channel panning behavior for in phase components and the assumed Sin Cos downmix functions leads to 

For circumflex over 0.5 the desired panning behavior for the modified Left channel corresponds to 0 Substituting the desired modified Left channel panning behavior for in phase components and the assumed Sin Cos downmix functions leads to 

The goal for the modified Left channel for out of phase components is to achieve panning behavior as illustrated by the out of phase plot in . In a panning angle corresponds to the encoding angle for the Left Surround channel. The a and b coefficients for the modified Left channel are generated via a piecewise function due to the piecewise behavior of the desired output.

For circumflex over the desired panning behavior for the modified Left channel corresponds to 0. Substituting the desired modified Left channel panning behavior for out of phase components and the assumed Sin Cos downmix functions leads to 

The channel synthesis derivations presented above are based on achieving desired panning behavior for source content that is either in phase or out of phase. The relative phase difference of the source content can be determined through the Inter Channel Phase Difference ICPD property defined as 

The ICPD value is bounded in the range 1 1 where values of 1 indicate that the components are out of phase and values of 1 indicate that the components are in phase. The ICPD property can then be used to determine the final a and b coefficients to use in the channel synthesis equations using linear interpolation. However instead of interpolating the a and b coefficients directly it can be noted that all of the a and b coefficients are generated using trigonometric functions of the panning angle estimate circumflex over .

The linear interpolation is thus carried out on the angle arguments of the trigonometric functions. Performing the linear interpolation in this manner has two main advantages. First it preserves the property that a b 1 for any panning angle and ICPD value. Second it reduces the number of trigonometric function calls required thereby reducing processing requirements.

The Center output channel is generated using the modified ICPD value which is defined as where sin ICPD 1 ICPD cos ICPD 1 ICPD . The first term in the argument of the sine function above represents the in phase component of the first dematrixing coefficient while the second term represents the out of phase component. Thus represents an in phase coefficient and represents an out of phase coefficient. Together the in phase coefficient and the out of phase coefficient are known as the phase coefficients.

For each output channel embodiments of the codec and method calculate the phase coefficients based on the estimated panning angle. For the Center output channel the in phase coefficient and the out of phase coefficient are given as 

Note that some trigonometric identities and phase wrapping properties were applied to simplify the and coefficients to the equations given above.

The subject matter discussed above is a system for generating Center Left Surround Right Surround Left and Right channels from a two channel downmix. However the system may be easily modified to generate other additional audio channels by defining additional panning behaviors.

In accordance with embodiments of the codec and method when the location of a non surviving or surplus channel lies within a triangle defined by the positions of three surviving channels or corresponding subbands in surviving channels the channel to be downmixed should be matrixed in accordance with a set of triplet channel relationships as set forth below.

A non surviving channel is downmixed onto three surviving channels forming a triangle. Mathematically a signal S is amplitude panned onto channel triplet C C C. is a diagram illustrating the panning of a signal source S onto a channel triplet. Referring to for a signal source S located between channels Cand C it is assumed that channels C C Care generated according to the following signal model 

The objective when upmixing the triplet is to obtain the non surviving channel that was downmixed onto the triplet by creating four output channels C C C Cfrom the input triplet C C C. is a diagram illustrating the extraction of a non surviving fourth channel that has been panned onto a triplet. Referring to the location of the fourth output channel Cis assumed to be at the origin while the location of the other three output channels C C C is assumed identical to the input channels C C C. Embodiments of the multiplet based spatial matrixing decoder generate the four output channels such that the spatial location and signal energy of the original signal component S is preserved.

The original location of the sound source S is not transmitted to embodiments of the multiplet based spatial matrixing decoder and it can only be estimated from the input channels C C Cthemselves. Embodiments of the decoder are able to appropriately generate the four output channels for any arbitrary location of S. For the remainder of this section it can be assumed that the original signal component S has unit energy i.e. S 1 to simplify derivations without loss of generality.

The output channel Cwill be generated via the following equation where the a b and c coefficients will be determined based on the estimated angle circumflex over and radius circumflex over r .

Furthermore the final a b and c coefficients can be simplified to expressions consisting only of the channel energy ratios square root over 3 square root over 3 square root over 3 

Output channels C C C will be generated from input channels C C Csuch that the signal components already generated in output channel Cwill be appropriately removed from input channels C C C.

The final a b and c coefficients can be simplified to expressions consisting only of the channel energy ratios 

The final a b and c coefficients can be simplified to expressions consisting only of the channel energy ratios 

The final a b and c coefficients can be simplified to expressions consisting only of the channel energy ratios 

An inter channel phase difference ICPD spatial property can be calculated for a triplet from the underlying pairwise ICPD values 

Note that the triplet signal model assumes that a sound source has been amplitude panned onto the triplet channels implying that the three channels are fully correlated. The triplet ICPD measure can be used to estimate the total correlation of the three channels. When the triplet channels are fully correlated or nearly fully correlated the triplet framework can be employed to generate the four output channels with highly predictable results. When the triplet channels are uncorrelated it may be desirable to use a different framework or method since the uncorrelated triplet channels violate the assumed signal model that may result in unpredictable results.

In accordance with embodiments of the codec and method when certain conditions of symmetry prevail the surplus channel or channel subband may be advantageously considered to lie within a quadrilateral. In such a case embodiments of the codec and method include downmixing and complementary upmixing in accordance with a quadruplet case set of relationships set forth below.

A non surviving channel is downmixed onto four surviving channels forming a quadrilateral. Mathematically a signal source S is amplitude panned onto channel quadruplet C C C C. is a diagram illustrating the panning of a signal source S onto a channel quadruplet. Referring to for a signal source S located between channels Cand C it is assumed that channels C C C Care generated according to the following signal model 

The objective when upmixing the quadruplet is to obtain the non surviving channel that was downmixed onto the quadruplet by creating five output channels C C C C Cfrom the input quadruplet C C C C. is a diagram illustrating the extraction of a non surviving fifth channel that has been panned onto a quadruplet. Referring to the location of the fifth output channel Cis assumed to be at the origin while the location of the other four output channels C C C C is assumed identical to the input channels C C C C. Embodiments of the multiplet based spatial matrixing decoder generate the five output channels such that the spatial location and signal energy of the original signal component S is preserved.

The original location of the sound source S is not transmitted to the embodiments of the decoder and can only be estimated from the input channels C C C Cthemselves. Embodiments of the decoder must be able to appropriately generate the five output channels for any arbitrary location of S.

For the remainder of the section it can be assumed that the original signal component S has unit energy in other words S 1 to simplify derivations without loss of generality. The decoder first derives circumflex over r and circumflex over estimates from channel energies C C C C 

Output channel Cwill be generated via the following equation where the a b c and d coefficients will be determined based on the estimated angle circumflex over and radius circumflex over r .

Furthermore the final a b c and d coefficients can be simplified to expressions consisting only of the channel energy ratios 2 min 2 min 2min min 2min min 

Output channels C C C C will be generated from input channels C C C Csuch that the signal components already generated in output channel Cwill be appropriately removed from input channels C C C C.

The final a b c and d coefficients can be simplified to expressions consisting only of the channel energy ratios 

The final a b c and d coefficients can be simplified to expressions consisting only of the channel energy ratios 

The final a b c and d coefficients can be simplified to expressions consisting only of the channel energy ratios 

The final a b c and d coefficients can be simplified to expressions consisting only of the channel energy ratios 

An inter channel phase difference ICPD spatial property can be calculated for a quadruplet from the underlying pairwise ICPD values 

Note that the quadruplet signal model assumes that a sound source has been amplitude panned onto the quadruplet channels implying that the four channels are fully correlated. The quadruplet ICPD measure can be used to estimate the total correlation of the four channels. When the quadruplet channels are fully correlated or nearly fully correlated the quadruplet framework can be employed to generate the five output channels with highly predictable results. When the quadruplet channels are uncorrelated it may be desirable to use a different framework or method since the uncorrelated quadruplet channels violate the assumed signal model which may result in unpredictable results.

Embodiments of the codec and method render audio object waveforms over a speaker array using a novel extension of vector based amplitude panning VBAP techniques. Traditional VBAP techniques create three dimensional sound fields using any number of arbitrarily placed loudspeakers on a unit sphere. The hemisphere on the unit sphere creates a dome over the listener. With VBAP the most localizable sound that can be created comes from a maximum of 3 channels making up some triangular arrangement. If it so happens that the sound is coming from a point that lies on a line between two speakers then VBAP will just use those two speakers. If the sound is supposed to be coming from the location where a speaker is located then VBAP will just use that one speaker. So VBAP uses a maximum of 3 speakers and a minimum of 1 speaker to reproduce the sound. The playback environment may have more than 3 speakers but the VBAP technique reproduces the sound using only 3 of those speakers.

The extended rendering technique used by embodiments of the codec and method renders audio objects off the unit sphere to any point within the unit sphere. For example assume a triangle is created using three speakers. By extending traditional VBAP methods that locate a source at a point along a line and extending those methods to use three speakers a source can be located anywhere within the triangle formed by those three speakers. The goal of the rendering engine is to find a gain array to create the sound at the correct position along the 3D vectors created by this geometry with the least amount of leakage to neighboring speakers.

The multiplets and the sphere should cover the locations of all waveforms in the bitstream. This idea can be extended to four or more speakers if needed thus creating rectangles or other polygons to work within to accurately achieve the correct position in space on the hemisphere of the unit sphere .

The DTS UHD rendering engine performs 3D panning of point and extended sources to arbitrary loudspeaker layouts. A point source sounds as though it is coming from one specific spot in space whereas extended sources are sounds with width and or height . Support for spatial extension of a source is done by means of modeling contributions of virtual sources covering the area of the extended sound.

The extended rendering technique renders a point or extended sources that are on the unit sphere surrounding the listener . However for point sources that are inside the unit sphere the sources must be moved off the unit sphere . The extended rendering technique uses three methods to move objects off the unit sphere .

First once the waveform is positioned on the unit sphere using the VBAP or similar technique it is cross faded with a source positioned at the center of the unit sphere in order to pull the sound in along the radius r. All of the speakers in the system are used to perform the cross fade.

Second for elevated sources the sound is extended in the vertical plane in order to give the listener the impression that it is moving closer. Only the speakers needed to extend the sound vertically are used. Third for sources in the horizontal plane that may or may not have zero elevation the sound is extended horizontally again to give the impression that it is moving closer to the listener . The only active speakers are those needed to do the extension.

Given the category of the input layout the selected number of surviving channels M and the following rules specify the matrixing of each non surviving channel in a unique way regardless of the actual input layout. are lookup tables that dictate the mapping of matrix multiplets for any speakers in the input layout that is not present in the surviving layout.

In addition each non surviving channel is pairwise matrixed between a pair of surviving channels. In some scenarios a triplet quadruplet or larger group of surviving channels may be used for matrixing a single non surviving channel. Also whenever possible a pair of surviving channels is used for matrixing one and only one non surviving channel.

If height channels are present in the input channel layout than at least one height channel shall exist among the surviving channels. Whenever appropriate at least 3 encircling surviving channels in each loudspeaker ring should be used applies to the listener plane ring and the elevated plane ring .

When no object inclusion or embedded downmix are required there are other possibilities for optimization of the proposed approach. First non surviving channels N M of them shall in this scenario be called quasi surviving channels can be encoded with very limited bandwidth say F 3 kHz . Second content in the quasi surviving channels above Fshould be matrixed onto selected surviving channels. Third the low bands of the quasi surviving channels and all bands of the surviving channels get encoded and packed into a stream.

The above optimization allows for minimal impact on spatial accuracy with still significant reduction in bit rate. To manage decoder MIPS a careful selection of the time frequency representation for dematrixing is needed such that decoder subband samples can be inserted into the dematrixing synthesis filter bank. On the other hand relaxation on required frequency resolution for dematrixing is possible since dematrixing is not applied below F.

In the above discussion it should be appreciated that re panning refers to the upmixing operation by which discrete channels numbering in excess of the downmixed channels N M are recovered from the downmix in each channel set. Preferably this is performed in each of a plurality of perceptually critical subbands for each set.

It should be appreciated that the optimum or near optimum results from this method will be best approximated when channel geometry is assumed by the recording artist or engineer either explicitly or implicitly via software or hardware and when in addition the geometry and assumed channel configurations and downmix parameters are communicated by some means to the decoder receiver. In other words if the original recording used a 22 channel discrete mix based on a certain microphone speaker geometry which was mixed down to a 7.1 channel downmix according to the matrixing methods set forth above then these presumptions should be communicated to the receiver decoder by some means to allow complementary upmix.

One method would be to communicate in file headers the presumed original geometry and the downmix configuration 22 with height channels in configuration X downmix to 7.1 in conventional arrangement . This requires only minimal amounts of data bandwidth and infrequent updating in real time. The parameters could be multiplexed into reserved fields in existing audio formats for example. Other methods are available including cloud storage website access user input and the like.

In some embodiments of the codec and method the upmixing system or decoder is aware of the channel layouts and mixing coefficients of both the original audio signal and the channel reduced audio signal. Knowledge of the channel layouts and mixing coefficients allows the upmixing system to accurately decode the channel reduced audio signal back to an adequate approximation of the original audio signal. Without knowledge of the channel layouts and mixing coefficients the upmixer would be unable to determine the target output channel layout or the correct decoder functions needed to generate adequate approximations of the original audio channels.

As an example an original audio signal may consist of 15 channels corresponding to the following channel locations 1 Center 2 Front Left 3 Front Right 4 Left Side Surround 5 Right Side Surround 6 Left Surround Rear 7 Right Surround Rear 8 Left or Center 9 Right of Center 10 Center Height 11 Left Height 12 Right Height 13 Center Height Rear 14 Left Height Rear and 15 Right Height Rear. Due to bandwidth constraints or some other motivation it may desirable to reduce this high channel count audio signal to a channel reduced audio signal consisting of 8 channels.

The downmixing system may be configured to encode the original 15 channels to an 8 channel audio signal consisting of the following channel locations 1 Center 2 Front Left 3 Front Right 4 Left Surround 5 Right Surround 6 Left Height 7 Right Height and 8 Center Height Rear. The downmixing system may further be configured to use the following mixing coefficients when downmixing the original 15 channel audio signal 

For the above example scenario in order for the upmixing system to optimally or near optimally decode an approximation of the original audio signal from the channel reduced signal the upmixing system may have knowledge of the original and downmixed channel layouts i.e. C FL FR LSS RSS LSR RSR LoC RoC CH LH RH CHR LHR RHR and C FL FR LS RS LH RH CHR respectively and the mixing coefficients used during the downmix process i.e. the above mixing coefficient matrix . With knowledge of this information the upmixing system can accurately determine the decoding functions needed for each output channel using the matrixing dematrixing mathematical frameworks set forth above since it will be fully aware of the actual downmix configuration used. For example the upmixing system will know to decode the output LSR channel from the downmixed LS and RS channels and it will also know the relative channel levels between the LS and RS channels that will imply a discrete LSR channel output i.e. 0.924 and 0.383 respectively .

If the upmixing system is unable to obtain the relevant channel layout and mixing coefficient information about the original and channel reduced audio signals for example if a data channel is not available for transmitting this information from the downmixing system to the upmixer or if the received audio signal is a legacy or non downmixed signal where such information is undetermined or unknown then it still may be possible to perform a satisfactory upmix by using heuristics to select suitable decoding functions for the upmixing system . In these blind upmix cases it may be possible to use the geometry of the channel reduced layout and the target upmixed layout to determine suitable decoding functions.

By way of example the decoding function for a given output channel may be determined by comparing that output channel s location relative to the nearest line segment between a pair of input channels. For instance if a given output channel lies directly between a pair of input channels it may be determined to extract equal intensity common signal components from that pair into the output channel. Likewise if the given output channel lies nearer to one of the input channels the decoding function may incorporate this geometry and favor a larger intensity for the nearer channel. Alternatively it may be possible to use assumptions about the recording mixing or production techniques of the audio signal to determine suitable decoding functions. For example it may be suitable to make assumptions about relationships between certain channels such as assuming that height channel components may have been panned across the front and rear channel pairs i.e. L Lsr and R Rsr pairs of a 7.1 audio signal such as during a flyover effect from a movie.

It should also be appreciated that the audio channels used in the downmixing system and the upmixing system might not necessarily conform to actual speaker feed signals intended for a specific speaker location. Embodiments of the codec and method are also applicable to so called object audio formats wherein an audio object corresponds to a distinct sound signal that is independently stored and transmitted with accompanying metadata information such as spatial location gain equalization reverberation diffusion and so forth. Commonly an object audio format will consist of many synchronized audio objects that need to be transmitted simultaneously from an encoder to a decoder.

In scenarios where data bandwidth is limited the existence of numerous simultaneous audio objects can cause problems due to the necessity to individually encode each distinct audio object waveform. In this case embodiments of the codec and method are applicable to reduce the number of audio object waveforms needing to be encoded. For example if there are N audio objects in an object based signal the downmix process of embodiments of the codec and method can be used to reduce the number of objects to M where N is greater than M. A compression scheme can then encode those M objects requiring less data bandwidth than the original N objects would have required.

At the decoder side the upmix process can be used to recover an approximation of the original N audio objects. A rendering system may then render those audio objects using the accompanying metadata information into a channel based audio signal where each channel corresponds to a speaker location in an actual playback environment. For example a common rendering method is vector based amplitude panning or VBAP.

Many other variations than those described herein will be apparent from this document. For example depending on the embodiment certain acts events or functions of any of the methods and algorithms described herein can be performed in a different sequence can be added merged or left out altogether such that not all described acts or events are necessary for the practice of the methods and algorithms . Moreover in certain embodiments acts or events can be performed concurrently such as through multi threaded processing interrupt processing or multiple processors or processor cores or on other parallel architectures rather than sequentially. In addition different tasks or processes can be performed by different machines and computing systems that can function together.

The various illustrative logical blocks modules methods and algorithm processes and sequences described in connection with the embodiments disclosed herein can be implemented as electronic hardware computer software or combinations of both. To clearly illustrate this interchangeability of hardware and software various illustrative components blocks modules and process actions have been described above generally in terms of their functionality. Whether such functionality is implemented as hardware or software depends upon the particular application and design constraints imposed on the overall system. The described functionality can be implemented in varying ways for each particular application but such implementation decisions should not be interpreted as causing a departure from the scope of this document.

The various illustrative logical blocks and modules described in connection with the embodiments disclosed herein can be implemented or performed by a machine such as a general purpose processor a processing device a computing device having one or more processing devices a digital signal processor DSP an application specific integrated circuit ASIC a field programmable gate array FPGA or other programmable logic device discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. A general purpose processor and processing device can be a microprocessor but in the alternative the processor can be a controller microcontroller or state machine combinations of the same or the like. A processor can also be implemented as a combination of computing devices such as a combination of a DSP and a microprocessor a plurality of microprocessors one or more microprocessors in conjunction with a DSP core or any other such configuration.

Embodiments of the multiplet based spatial matrixing codec and method described herein are operational within numerous types of general purpose or special purpose computing system environments or configurations. In general a computing environment can include any type of computer system including but not limited to a computer system based on one or more microprocessors a mainframe computer a digital signal processor a portable computing device a personal organizer a device controller a computational engine within an appliance a mobile phone a desktop computer a mobile computer a tablet computer a smartphone and appliances with an embedded computer to name a few.

Such computing devices can be typically be found in devices having at least some minimum computational capability including but not limited to personal computers server computers hand held computing devices laptop or mobile computers communications devices such as cell phones and PDA s multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputers mainframe computers audio or video media players and so forth. In some embodiments the computing devices will include one or more processors. Each processor may be a specialized microprocessor such as a digital signal processor DSP a very long instruction word VLIW or other microcontroller or can be conventional central processing units CPUs having one or more processing cores including specialized graphics processing unit GPU based cores in a multi core CPU.

The process actions of a method process or algorithm described in connection with the embodiments disclosed herein can be embodied directly in hardware in a software module executed by a processor or in any combination of the two. The software module can be contained in computer readable media that can be accessed by a computing device. The computer readable media includes both volatile and nonvolatile media that is either removable non removable or some combination thereof. The computer readable media is used to store information such as computer readable or computer executable instructions data structures program modules or other data. By way of example and not limitation computer readable media may comprise computer storage media and communication media.

Computer storage media includes but is not limited to computer or machine readable media or storage devices such as Bluray discs BD digital versatile discs DVDs compact discs CDs floppy disks tape drives hard drives optical drives solid state memory devices RAM memory ROM memory EPROM memory EEPROM memory flash memory or other memory technology magnetic cassettes magnetic tapes magnetic disk storage or other magnetic storage devices or any other device which can be used to store the desired information and which can be accessed by one or more computing devices.

A software module can reside in the RAM memory flash memory ROM memory EPROM memory EEPROM memory registers hard disk a removable disk a CD ROM or any other form of non transitory computer readable storage medium media or physical computer storage known in the art. An exemplary storage medium can be coupled to the processor such that the processor can read information from and write information to the storage medium. In the alternative the storage medium can be integral to the processor. The processor and the storage medium can reside in an application specific integrated circuit ASIC . The ASIC can reside in a user terminal. Alternatively the processor and the storage medium can reside as discrete components in a user terminal.

The phrase non transitory as used in this document means enduring or long lived . The phrase non transitory computer readable media includes any and all computer readable media with the sole exception of a transitory propagating signal. This includes by way of example and not limitation non transitory computer readable media such as register memory processor cache and random access memory RAM .

Retention of information such as computer readable or computer executable instructions data structures program modules and so forth can also be accomplished by using a variety of the communication media to encode one or more modulated data signals electromagnetic waves such as carrier waves or other transport mechanisms or communications protocols and includes any wired or wireless information delivery mechanism. In general these communication media refer to a signal that has one or more of its characteristics set or changed in such a manner as to encode information or instructions in the signal. For example communication media includes wired media such as a wired network or direct wired connection carrying one or more modulated data signals and wireless media such as acoustic radio frequency RF infrared laser and other wireless media for transmitting receiving or both one or more modulated data signals or electromagnetic waves. Combinations of the any of the above should also be included within the scope of communication media.

Further one or any combination of software programs computer program products that embody some or all of the various embodiments of the multiplet based spatial matrixing codec and method described herein or portions thereof may be stored received transmitted or read from any desired combination of computer or machine readable media or storage devices and communication media in the form of computer executable instructions or other data structures.

Embodiments of the multiplet based spatial matrixing codec and method described herein may be further described in the general context of computer executable instructions such as program modules being executed by a computing device. Generally program modules include routines programs objects components data structures and so forth which perform particular tasks or implement particular abstract data types. The embodiments described herein may also be practiced in distributed computing environments where tasks are performed by one or more remote processing devices or within a cloud of one or more devices that are linked through one or more communications networks. In a distributed computing environment program modules may be located in both local and remote computer storage media including media storage devices. Still further the aforementioned instructions may be implemented in part or in whole as hardware logic circuits which may or may not include a processor.

Conditional language used herein such as among others can might may e.g. and the like unless specifically stated otherwise or otherwise understood within the context as used is generally intended to convey that certain embodiments include while other embodiments do not include certain features elements and or states. Thus such conditional language is not generally intended to imply that features elements and or states are in any way required for one or more embodiments or that one or more embodiments necessarily include logic for deciding with or without author input or prompting whether these features elements and or states are included or are to be performed in any particular embodiment. The terms comprising including having and the like are synonymous and are used inclusively in an open ended fashion and do not exclude additional elements features acts operations and so forth. Also the term or is used in its inclusive sense and not in its exclusive sense so that when used for example to connect a list of elements the term or means one some or all of the elements in the list.

While the above detailed description has shown described and pointed out novel features as applied to various embodiments it will be understood that various omissions substitutions and changes in the form and details of the devices or algorithms illustrated can be made without departing from the spirit of the disclosure. As will be recognized certain embodiments of the inventions described herein can be embodied within a form that does not provide all of the features and benefits set forth herein as some features can be used or practiced separately from others.

Moreover although the subject matter has been described in language specific to structural features and methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

