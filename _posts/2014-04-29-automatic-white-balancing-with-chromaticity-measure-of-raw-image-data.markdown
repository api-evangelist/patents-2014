---

title: Automatic white balancing with chromaticity measure of raw image data
abstract: An apparatus and methods for estimating a chromaticity of illumination from raw image data. In an embodiment, one or more image chromaticity weight is determined based on a distance between the raw image data in a sensor chromaticity space and a nearest point within a locus of sensor illumination chromaticities. In a further embodiment, one or more image chromaticity weight is determined based on a disparity among normalized color channel values. In certain embodiments, image chromaticity estimates are utilized to determine a white point estimate for the raw image data. In embodiments, an electronic device including a camera estimates the chromaticity value of raw image data captured by the camera as part of an AWB pipeline. The electronic device may further determine, for example as part of the AWB pipeline, a white point estimate based, at least in part, on the raw image data chromaticity value estimate(s).
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09386289&OS=09386289&RS=09386289
owner: Intel Corporation
number: 09386289
owner_city: Santa Clara
owner_country: US
publication_date: 20140429
---
A digital camera is a component often included in commercial electronic media device platforms. Digital cameras are now available in wearable form factors e.g. video capture earpieces video capture headsets video capture eyeglasses etc. as well as embedded within smartphones tablet computers and notebook computers etc. The transformation of image data collected by a camera module e.g. camera sensor and optics into values suitable for reproduction and or display poses a challenging problem for camera control algorithms CCA implemented by device platforms. A computational color constancy algorithm also known as an automatic white balancing AWB algorithm is one important part of a CCA for achieving desired color reproduction from digital cameras. The role of AWB is to estimate the chromaticity of illumination or chromaticities in case of multiple different light sources in terms of the response of the camera sensor color components. AWB typically entails adjustment of the intensities of the different color components to enable color reproduction that a user expects in which the needed adjustment is highly dependent on image sensor characteristics and ambient illumination conditions at the time of capture.

Knowledge of raw image data chromaticity is advantageous for estimating the white point reliably and accurately. One technique known as the gray edge algorithm is premised on reflections originating from the edges in a raw image data most likely being achromatic. Achromatic regions are therefore obtained from around edges within a scene. In practice the gray edge algorithm may require high resolution information to be available for accurate edge information extraction and so the accuracy of the gray edge algorithm may be degraded significantly by a down sampled representation i.e. low resolution of the raw image. Therefore the gray edge algorithm may not be well suited to some device platforms having limited processing capability or operating under tight power constraints such as most mobile device platforms. Also the gray edge technique does not address scenes lacking edges or matte edges and surfaces. Other conventional methods for example employing gamut mapping or color by correlation techniques often rely heavily on camera module characterization CMC information leading them to be susceptible to CMC information errors associated with mass production of the camera modules. CMC intensive methods may also be computationally expensive.

Techniques for accurately estimating illumination chromaticity in terms of raw image data without strong assumptions of image content with minimal reliance on CMC data and without high level image processing would therefore be advantageous for example to improve an AWB algorithm and thereby enhance performance of digital camera platforms.

One or more embodiments are described with reference to the enclosed figures. While specific configurations and arrangements are depicted and discussed in detail it should be understood that this is done for illustrative purposes only. Persons skilled in the relevant art will recognize that other configurations and arrangements are possible without departing from the spirit and scope of the description. It will be apparent to those skilled in the relevant art that techniques and or arrangements described herein may be employed in a variety of other systems and applications beyond what is described in detail herein.

Reference is made in the following detailed description to the accompanying drawings which form a part hereof and illustrate exemplary embodiments. Further it is to be understood that other embodiments may be utilized and structural and or logical changes may be made without departing from the scope of claimed subject matter. Therefore the following detailed description is not to be taken in a limiting sense and the scope of claimed subject matter is defined solely by the appended claims and their equivalents.

In the following description numerous details are set forth however it will be apparent to one skilled in the art that embodiments may be practiced without these specific details. Well known methods and devices are shown in block diagram form rather than in detail to avoid obscuring more significant aspects. References throughout this specification to an embodiment or one embodiment mean that a particular feature structure function or characteristic described in connection with the embodiment is included in at least one embodiment. Thus the appearances of the phrase in an embodiment or in one embodiment in various places throughout this specification are not necessarily referring to the same embodiment. Furthermore the particular features structures functions or characteristics described in the context of an embodiment may be combined in any suitable manner in one or more embodiments. For example a first embodiment may be combined with a second embodiment anywhere the particular features structures functions or characteristics associated with the two embodiments are not mutually exclusive.

As used in the description of the exemplary embodiments and the appended claims the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will also be understood that the term and or as used herein refers to and encompasses any and all possible combinations of one or more of the associated listed items.

As used throughout the description and in the claims a list of items joined by the term at least one of or one or more of can mean any combination of the listed terms. For example the phrase at least one of A B or C can mean A B C A and B A and C B and C or A B and C.

The terms coupled and connected along with their derivatives may be used herein to describe functional or structural relationships between components. It should be understood that these terms are not intended as synonyms for each other. Rather in particular embodiments connected may be used to indicate that two or more elements are in direct physical optical or electrical contact with each other. Coupled may be used to indicated that two or more elements are in either direct or indirect with other intervening elements between them physical optical or electrical contact with each other and or that the two or more elements co operate or interact with each other e.g. as in a cause an effect relationship .

Some portions of the detailed descriptions provide herein are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. Unless specifically stated otherwise as apparent from the following discussion it is appreciated that throughout the description discussions utilizing terms such as calculating computing determining estimating storing collecting displaying receiving consolidating generating updating or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s circuitry including registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

While the following description sets forth embodiments that may be manifested in architectures such system on a chip SoC architectures for example. Implementation of the techniques and or arrangements described herein are not restricted to particular architectures and or computing systems and may be implemented by any architecture and or computing system for similar purposes. Various architectures employing for example multiple integrated circuit IC chips and or packages and or various computing devices and or consumer electronic CE devices such as set top boxes smartphones etc. may implement the techniques and or arrangements described herein. Further while the following description may set forth numerous specific details such as logic implementations types and interrelationships of system components logic partitioning integration choices etc. claimed subject matter may be practiced without such specific details. Furthermore some material such as for example control structures and full software instruction sequences may not be shown in detail in order not to obscure the material disclosed herein.

Certain portions of the material disclosed herein are implemented in hardware for example as logic circuitry in a graphics processor. Certain other portions may be implemented in hardware firmware software or any combination thereof. At least some of the material disclosed herein may also be implemented as instructions stored on a machine readable medium which may be read and executed by one or more processors graphics processors and or central processors . A machine readable medium may include any medium and or mechanism for storing or transmitting information in a form readable by a machine e.g. a computing device . For example a machine readable medium may include read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices electrical optical acoustical or other similarly non transitory tangible media.

One or more system apparatus method and computer readable media is described below for estimating the chromaticity value of raw image data. In certain embodiments the image chromaticity estimate is utilized to determine a white point estimate for the raw image data. In further embodiments the white point estimate may be combined with one or more additional white point estimate determined for the raw image data through other algorithms such as a CMC dependent techniques. In embodiments an electronic device including a camera estimates the chromaticity of raw image data captured by the camera as part of an AWB pipeline. The electronic device may further determine for example as part of the AWB pipeline a white point estimate based at least in part on the raw image data chromaticity value estimate.

As described in further detail below raw image data chromaticity measurements may entail determining a distance of raw image data to a reference position of an illumination chromaticity probability map. A chromaticity of the raw image data may then be determined based on this distance for example with image data being deemed more achromatic with decreasing distance to a center of the white map. For such embodiments it may be assumed that within the chromaticity space relatively more achromatic image data is located in the high probability region s of a map of illumination chromaticities while the relatively more chromatic image data falls into regions farther from the high probability region.

As also described in more detail below raw image data chromaticity measurement embodiments may entail comparing R G and B color channel energy levels. Image data with convergent channel energies may be assessed as more achromatic than image data having more divergent color channel energies. In certain such embodiments chromaticity is determined based upon on the disparity between R G and B channel values normalized by a white point correction factor that is dependent on camera module characterization CMC information and or a previously determined preliminary white point estimate.

Also as described below image data determined to be achromatic by one or more of the above techniques may be utilized by an AWB method in preference over chromatic image data to determine a chromaticity of illumination. Chromaticity of illumination is a chromaticity value that is determined from a block of pixels of different color components e.g. R G and B color components registering light reflected from an achromatic surface reflecting all wavelengths equally without altering the illumination spectrum and hence directly indicating the illumination chromaticity . Based on this chromaticity of illumination the R G and B gains to be applied in the ISP image reconstruction are calculated by the AWB algorithm pipeline. Chromaticity of illumination is distinguished from the true chromaticity of objects i.e. color of objects . More specifically the correct reproduction of object color follows from i an AWB algorithm being able to correctly estimate the chromaticity of illumination followed by ii accurate color conversion from sensor RGB to sRGB. Embodiments may achieve more accurate and robust white point estimates without burdensome image resolution and or image content requirements and also without computationally intensive image processing e.g. edge detection .

Chromaticity measurement embodiments described herein are independent of how an input image is represented. For example the chromaticity measurements described herein may be applied at full image resolution or raw image area may be divided into a grid of blocks having either fixed equal size or variable size. Each block covers the area of multiple pixels of different color components e.g. R G and B color components . The average level of each color component in the area of the block can be calculated e.g. denoting averages as R G and Bfor block i . The chromaticity value at block i is then equal to R G B G .

As used herein raw image data is image data that may be pre processed by an upstream image signal processing ISP pipeline. For example in one embodiment raw image data has been linearized and color shade corrected. More specifically raw Bayer data or the like output by camera sensor may undergo linearization including also black level correction and color shading correction before the raw image data chromaticity is calculated following one or more of the embodiments described herein.

A chromaticity weight is a measure of raw image data chromaticity for example scaling between 0 and 1 with a larger weight value being associated with a more achromatic raw image than a lower weight value. Raw image data that is more achromatic more accurately reflects the illumination chromaticity and so AWB white balancing gains may be advantageously calculated based on raw image data deemed sufficiently achromatic by the algorithms described herein. As illustrated in a plurality of image chromaticity weights e.g. a a a may be determined for a raw data block i having multiple pixels of different color components. The chromaticity weights may be determined independently e.g. in parallel using distinct measurement algorithms to arrive at independent measures of chromaticity for raw image data . Image chromaticity weights are advantageously determined following algorithms that render the weights complementary so that together the weights represent a robust illumination chromaticity measurement of the raw image data. Alternatively one or more of the chromaticity weights may be utilized in absence of other weights for example as a function of some control signal etc.

Following the data dependency arrows in chromaticity weight amay be determined by processing raw image data through a first algorithm. As further illustrated in chromaticity weight amay then be employed in a white point estimate . Chromaticity weight amay be so employed exclusive of any other chromaticity weight or in a manner inclusive of chromaticity weight aand or a. For example following the solid arrows three chromaticity measurement algorithms may be independently performed on raw image data generating chromaticity weights aaand a which are subsequently combined linearly or non linearly to form derivative chromaticity weights a aas inputs to white point estimate . Exemplary combinations of chromaticity weights include but are not limited to products of two or more weights an average of two or more weights a weighted averages of two or more weights a maximum of two or more weights a minimum of two or more weights a median or two or more weights or a non linear combination such as a . . . a .

As illustrated in one or more of the plurality of image chromaticity weights e.g. a a a may be further based in part on CMC characterization data . For embodiments where the chromaticity measures generating weights a a aare at a front end of an AWB pipeline it is advantageous to enlist CMC data in a limited manner so that the chromaticity weights are insensitive to inaccuracies in the CMC data. In further embodiments a preliminary white point estimate is utilized as an input to determine one or more of image chromaticity weights a a a. As described further below the preliminary white point estimate may be determined with still another algorithm distinct from those described elsewhere herein for determining the chromaticity weights a a a. Thus the chromaticity measurement embodiments described herein are not limited to being a first stage in an AWB algorithm. Serially staging multiple chromaticity measurements may be an advantageous manner of combining the measurements for increase robustness to image scene content variation. Although not depicted in one or more of the chromaticity weights a a amay themselves be serially staged with one measurement algorithm outputting a chromaticity weight e.g. a that is utilized in some manner to determine another chromaticity weight e.g. aand or a through a second measurement algorithm. For example the preliminary white point estimate may be based on chromaticity weight aand that preliminary white point estimate may then be employed to further determine the chromaticity weights a a. Thus the chromaticity measurement embodiments described herein may be utilized across multiple stages of an AWB algorithm.

In an embodiment one or more image chromaticity weight is determined based on a distance between the location of the raw image data in the sensor chromaticity space and a nearest point within and or around a locus or region of sensor illumination chromaticities. is a flow diagram illustrating a method for determining one or more chromaticity weight afor a raw image data block D in accordance with one such embodiment. Method begins with receiving or accessing CMC data associated with an image sensor employed to collect image pixel data represented by the raw image data block Dto be analyzed. The CMC data may advantageously include for example spectral responses of the RGB color components of the camera module and knowledge of illumination chromaticities and typical illumination spectra for the chromaticity points at different correlated color temperature CCT regions. At operation a locus of white points of high likelihood within the sensor chromaticity space are determined from the CMC data. Alternatively a region of chromaticity space associated with a predetermined confidence level is determined at operation . In one exemplary embodiment the locus of white points is an average illumination chromaticity along with the related CCT values determined by mapping illumination chromaticities in R G B G sensor space. Such a two dimensional white map is illustrated in with the locus of average illumination chromaticity demarked within a high likelihood white point map e.g. determined as a function of the illumination chromaticity response deviation from the locus of average illumination chromaticity .

Method continues at operation where raw data block Dmay be optionally filtered based on a predetermined saturation value threshold. In one exemplary embodiment where the average level of non saturated red green and blue pixels is stored for each raw image data block D the amount of saturated pixels within that block in relation to the total amount of pixels in the block is also stored. A raw image data block Dhaving too many saturated pixels is omitted from method because true chromaticity information is lost for the saturated pixels. In addition pixels close to saturated pixels could be affected by pixel blooming depending on the characteristics of the sensor. Hence method may proceed to subsequent operations only for raw image data blocks associated with a saturation value below a predetermined maximum saturation threshold.

The probability that measured raw image data is more achromatic increases with decreasing distance between raw image data and the locus of white point of high likelihood in the sensor chromaticity space. This distance is therefore quantified for each raw data block Dat operation and may be calculated in various ways. further illustrates two raw image data values mapped to the sensor chromaticity space. Following embodiments herein raw image data value is deemed more achromatic than raw image data value because raw image data value is closer to the locus of average illumination chromaticity distance d than is raw image data value distance d . Any distance information may serves as the basis for the measure of chromaticity for a raw image data D. In certain embodiments image chromaticity weight am may be made directly proportional to the distance. For example an absolute Euclidean distance within sensor chromaticity space may be determined between R G B G values of a raw image data block i and a nearest point within a locus of sensor illumination chromaticities. In one implementation the locus is the average illumination chromaticity e.g. locus . In alternative embodiments distance between the raw data and some larger region defined by high likelihood threshold may be determined. For example distance can be assumed to be fixed at a predetermined value e.g. 1 within the white map space and a distance to the borders of the white map space determined if the raw image data falls outside of white map space .

In an embodiment one or more image chromaticity weight is determined based on a disparity among normalized color channel values. is a flow diagram illustrating a method for determining one or more chromaticity weights a a for a raw image data block D in accordance with one or more embodiment. Method begins with receiving color channel values associated with a raw image data block D. In an exemplary embodiment the color channel values include three e.g. R G B channel values. At operation raw data block Dis again filtered based on a color saturation value threshold. In one exemplary embodiment where the average level of non saturated red green and blue pixels is stored for each raw image data block D the amount of saturated pixels within that block in relation to the total amount of pixels in the block is also stored. A raw image data block Dhaving too many saturated pixels is omitted from method . Hence method may proceed to subsequent operations only for raw image data blocks associated with a saturation value below a predetermined maximum saturation threshold.

At operation the color channel values are normalized with a white point correction factor. As illustrated in normalization operation may be based on CMC data and or a preliminary white point estimate . In one embodiment the white point correction factor is a fixed value determined based image sensor characterization data associated with an image sensor employed to collect the image pixel data represented by the raw image data block i.e. CMC data . As one example the white point correction factor may be based on CMC data associated with daylight illumination. is a graph of CMC data plotted in R G B G sensor chromaticity space in accordance with an embodiment. R G and B G values associated with a particular illumination white point such as 5500K may be determined from the CMC data. Gains to the RBG color channel values of the raw image data block Dmay then be normalized by a correction factor such as 1 R G 1 1 B G . is a graph of relative spectral response of RGB color channels for raw image data associated with an exemplary camera sensor after normalization operation .

In another embodiment instead of fixing the normalization point at a predetermined CCT the normalization point is determined according to a distinct AWB algorithm employed at operation to generate a preliminary white point estimate e.g. preliminary estimate in . While operation may employ any algorithm to determine the normalization point the operative principle of the algorithm employed is advantageously different than the principle of method . Strong and weak points of each algorithm are advantageously complementary for different types of scenes. The algorithm utilized at operation is then advantageously linked to the output of the chromaticity measurement method through the dependency of the normalization operation . As one example the initial white point estimation or initial CCT range estimation operation may be performed using information based on illumination gamuts in the sensor chromaticity space. An estimate for the CCT range and or white point may be based on which illumination gamut the measured raw image data fall. Gain correction factors employed at operation may then be determined based on color channel values associated with the preliminary white point estimate determined at operation .

Following normalization method continues with operation where the chromaticity of the raw image data block Dis estimated based on how close the R G and B channel values are to each other. The closer or more convergent the channel counts the more achromatic the image data block. Notably illumination spectrums that are far from the illumination spectrum that corresponds to the white point correction factor utilized for normalizing the color channels prior to assessing the channel energy divergence will induce larger differences between the color components for achromatic objects. However the same effect can be expected to occur for more chromatic objects. One or more chromaticity weights a amay be determined as a function of the disparity between normalized color channel values. Any variation metric may be determined at operation . In one exemplary embodiment a minimum color channel value min R G B and a maximum color channel value max R G B from the normalized raw image data block Dare determined at operation . Chromaticity weight amay then be based on a ratio of the minimum and maximum color channel values 

In an embodiment a first white point estimate is determined as a function of one or more of the image chromaticity weights. With the individual image chromaticity weights a adetermined as described above the weights may be combined to arrive at one weight for a raw image data block D. For example as illustrated in chromaticity weights aand amay be combined to derive chromaticity weight a. As noted above in reference to chromaticity weights may be combined in any linear or non linear manner. In certain embodiments statistics such as means medians weighted means etc. may be utilized. In one exemplary embodiment ais a product of aand a. In further embodiments chromaticity weight ais combined with chromaticity weight a for example by taking the product of a a and a to derive chromaticity weight a

The white point estimation operation is in part further based on one or more of the image chromaticity weights a a adetermined at operation . For example in the GW algorithm where values of the R G and B components of the image are averaged to arrive at a common gray value representing the achromatic point in the sensor chromaticity space the R G and Bcolor channel values associated with a raw image data block Dare multiplied with an image chromaticity weight and the chromaticity weighted values are then accumulated over the plurality of data blocks 

In one embodiment the AWB pipeline terminates with operation . In the exemplary embodiment illustrated by method however the candidate white points obtained at operation provide an estimate of the CCT range in which the final white point resides. This range estimate is input into one or more additional stage in the AWB pipeline. Depending on the reliability of the white points obtained at operation one or more CMC data dependent algorithm may be utilized to search a reduced CCT range for the final white point estimate. At operation for example CCT is further restricted based on camera module characterization data a lux level estimate and or manual CCT range limits. A search for achromatic areas is then performed at operation employing one or more search criteria algorithm. At operation the white point identified by the search is refined based on higher level features such as face skin scene information user data and geographical or other device information to arrive at the final white point estimate output by method . The final white point estimate is then stored to a memory and may be utilized for gain balancing in any conventional manner.

System may implement all or a subset of the various methods described above in the context of . In various exemplary embodiments processor invokes or otherwise implements video image enhancement operations including AWB. Processor includes functionality to perform image chromaticity measurement methods upon which AWB processes may be predicated for example as described elsewhere herein. For example in one embodiment a processor implements or includes an AWB module to determine one or more raw image chromaticity weight a a a a or a. In further embodiments AWB module is further to determine a white point based at least in part on image chromaticity weights a a a a a. In one exemplary embodiment processor includes fixed function and or programmable logic circuitry to determine a white point based at least in part on image chromaticity weights a a a a aof from raw image data collected by camera module and transmitted to processor and or image signal processor over a bus. In some embodiments one or more computer readable media may store instructions which when executed by processor cause the processor to perform one or more of the raw image chromaticity measurements described elsewhere herein. In alternative embodiments ISP includes firmware configured as an AWB module that determines one or more raw image chromaticity weight a a a a or a. In further embodiments AWB module is further to determine a white point based at least in part on image chromaticity weight a a a a a. One or more white point or image chromaticity weights a a a a amay then be stored in memory .

In embodiments system includes a platform coupled to a human interface device HID . Platform may receive raw image data from camera module which is then processed by ISP and or processor and or output to HID and or communicated via radio to network . A navigation controller including one or more navigation features may be used to interact with for example platform and or HID . In embodiments HID may include any television type monitor or display. HID may include for example a computer display screen touch screen display video monitor television like device and or a television.

Under the control of one or more software applications platform may display user interface on HID . Movements of the navigation features of controller may be replicated on a display e.g. HID by movements of a pointer cursor focus ring or other visual indicators displayed on the display. For example under the control of software applications the navigation features located on navigation controller may be mapped to virtual navigation features displayed on user interface for example.

In embodiments platform may include any combination of a camera module ISP chipset processor memory storage applications and or radio . Chipset may provide intercommunication among processor memory storage graphics processor applications or radio .

Processor may be implemented as one or more Complex Instruction Set Computer CISC or Reduced Instruction Set Computer RISC processors x86 instruction set compatible processors multi core or any other microprocessor or central processing unit CPU . In embodiments processor may be a multi core processor s multi core mobile processor s and so forth.

Memory may be implemented as a volatile memory device such as but not limited to a Random Access Memory RAM Dynamic Random Access Memory DRAM or Static RAM SRAM .

Storage may be implemented as a non volatile storage device such as but not limited to a magnetic disk drive optical disk drive tape drive an internal storage device an attached storage device flash memory battery backed up SDRAM synchronous DRAM and or a network accessible storage device.

Processor may perform processing of images such as still or video media data for display or perform general computing functions. Processor may include one or more CPU GPU or SoC for example. An analog or digital interface may be used to communicatively couple processor and display . For example the interface may be any of a High Definition Multimedia Interface Display Port wireless HDMI and or wireless HD compliant techniques. Processor may be integrated with a graphics processor onto a single chip i.e. SoC as a graphics core or a graphics processor may be further provided as part of chipset .

Radio may include one or more radios capable of transmitting and receiving signals using various suitable wireless communications techniques. Such techniques may involve communications across one or more wireless networks. Example wireless networks include but are not limited to wireless local area networks WLANs wireless personal area networks WPANs wireless metropolitan area network WMANs cellular networks and satellite networks. In communicating across such networks radio may operate in accordance with one or more applicable standards in any version.

In embodiments system may be implemented as a wireless system a wired system or a combination of both. When implemented as a wireless system system may include components and interfaces suitable for communicating over a wireless shared media such as one or more antennas transmitters receivers transceivers amplifiers filters control logic and so forth. An example of wireless shared media may include portions of a wireless spectrum such as the RF spectrum and so forth. When implemented as a wired system system may include components and interfaces suitable for communicating over wired communications media such as input output I O adapters physical connectors to connect the I O adapter with a corresponding wired communications medium a network interface card NIC disc controller video controller audio controller and the like. Examples of wired communications media may include a wire cable metal leads printed circuit board PCB backplane switch fabric semiconductor material twisted pair wire co axial cable fiber optics and so forth.

The image data chromaticity measurements and AWB processes predicated on such measurements as described herein may be implemented in various hardware architectures cell designs or IP cores. 

As described above system may be embodied in varying physical styles or form factors. illustrates embodiments of a small form factor device in which system may be embodied. In embodiments for example device may be implemented as a mobile computing device having wireless capabilities. A mobile computing device may refer to any device having a processing system and a mobile power source or supply such as one or more batteries for example.

Examples of a mobile computing device may include a personal computer PC laptop computer ultra laptop computer tablet touch pad portable computer handheld computer palmtop computer personal digital assistant PDA cellular telephone combination cellular telephone PDA television smart device e.g. smartphone tablet or smart television mobile internet device MID messaging device data communication device and so forth.

Examples of a mobile computing device also may include computers and or media capture transmission devices configured to be worn by a person such as a wrist computer finger computer ring computer eyeglass computer belt clip computer arm band computer shoe computers clothing computers and other wearable computers. In various embodiments for example a mobile computing device may be implemented as a smart phone capable of executing computer applications as well as voice communications and or data communications. Although some embodiments may be described with a mobile computing device implemented as a smart phone by way of example it may be appreciated that other embodiments may be implemented using other wireless mobile computing devices as well. The embodiments are not limited in this context.

As shown in device may include a housing a display an input output I O device and an antenna . Device also may include navigation features . Display may include any suitable display unit for displaying information appropriate for a mobile computing device. I O device may include any suitable I O device for entering information into a mobile computing device. Examples for I O device may include an alphanumeric keyboard a numeric keypad a touch pad input keys buttons switches rocker switches microphones speakers voice recognition device and software and so forth. Information also may be entered into device by way of microphone not shown or may be digitized by a voice recognition device. Embodiments are not limited in this context.

Embodiments described herein may be implemented using hardware elements software elements or a combination of both. Examples of hardware elements or modules include processors microprocessors circuitry circuit elements e.g. transistors resistors capacitors inductors and so forth integrated circuits application specific integrated circuits ASIC programmable logic devices PLD digital signal processors DSP field programmable gate array FPGA logic gates registers semiconductor device chips microchips chip sets and so forth. Examples of software elements or modules include applications computer programs application programs system programs machine programs operating system software middleware firmware routines subroutines functions methods procedures software interfaces application programming interfaces API instruction sets computing code computer code code segments computer code segments data words values symbols or any combination thereof. Determining whether an embodiment is implemented using hardware elements and or software elements may vary in accordance with any number of factors considered for the choice of design such as but not limited to desired computational rate power levels heat tolerances processing cycle budget input data rates output data rates memory resources data bus speeds and other design or performance constraints.

One or more aspects of at least one embodiment may be implemented by representative instructions stored on a machine readable storage medium. Such instructions may reside completely or at least partially within a main memory and or within a processor during execution thereof by the machine the main memory and the processor portions storing the instructions then also constituting a machine readable storage media. Programmable logic circuitry may have registers state machines etc. configured by the processor implementing the computer readable media. Such logic circuitry as programmed may then be understood to have been physically transformed into a system falling within the scope of the embodiments described herein. Instructions representing various logic within the processor which when read by a machine may also cause the machine to fabricate logic adhering to the architectures described herein and or to perform the techniques described herein. Such representations known as cell designs or IP cores may be stored on a tangible machine readable medium and supplied to various customers or manufacturing facilities to load into the fabrication machines that actually make the logic or processor.

While certain features set forth herein have been described with reference to embodiments this description is not intended to be construed in a limiting sense. Hence various modifications of the implementations described herein as well as other implementations which are apparent to persons skilled in the art to which the present disclosure pertains are deemed to be within the spirit and scope of the present disclosure.

In one or more first embodiment a computer implemented method for estimating a chromaticity value of raw image data includes receiving color channel values of a raw image data block and normalizing the color channel values with a white point correction factor. The method further includes determining one or more first image chromaticity weight by quantifying a disparity among the normalized color channel values. The method further includes storing to a memory the one or more first image chromaticity weight in association with the raw image data block.

In furtherance of the one or more first embodiment the method further includes determining a first white point estimate as a function of the one or more first image chromaticity weight and storing the first white point estimate to a memory.

In furtherance of the one or more first embodiment quantifying the disparity between color channel values further comprises determining a minimum color channel value and a maximum color channel value from the normalized raw image data block and determining a ratio of the minimum and maximum color channel values.

In furtherance of the one or more first embodiment quantifying the disparity between color channel values further comprises determining a mean color channel value from the normalized raw image data block and determining from the mean color channel value a variation metric of the color channel values.

In furtherance of the one or more first embodiment determining the one or more first image chromaticity weight further comprises determining first and second chromaticity weights as functions of the disparity between the color channel values.

In furtherance of the one or more first embodiment determining the first and the second chromaticity weights further comprises determining a minimum color channel value and a maximum color channel value from the normalized raw image data block. The method further includes determining the first chromaticity weight based on a ratio of the minimum and maximum color channel values. The method further includes determining a mean color channel value from the normalized raw image data block. The method further includes determining from the mean color channel value a root mean square deviation of the color channel values. The method further includes determining the second chromaticity weight based on the root mean square deviation.

In furtherance of the one or more first embodiment the method further includes determining the white point correction factor from sensor characterization data associated with an image sensor employed to collect image pixel data represented by the raw image data block.

In furtherance of the one or more first embodiment the method further includes determining a preliminary estimate of the white point independently from the one or more image chromaticity weight and determining the white point correction factor based on the preliminary estimate.

In furtherance of the one or more first embodiment the method further includes determining one or more second image chromaticity weight based on a distance between a location of the raw image data in a sensor chromaticity space and a nearest point within a locus of sensor illumination chromaticities. The method further includes determining the first white point estimate as a function of the one or more first chromaticity weight and of the one or more second chromaticity weight.

In furtherance of the embodiment immediately above the method further includes determining the one or more second image chromaticity weight further comprises receiving sensor characterization data associated with an image sensor employed to collect image pixel data represented by the raw image data block. The method further includes determining the locus of sensor illumination chromaticities within the sensor chromaticity space based on the characterization data. The method further includes determining the distance within the chromaticity space between the raw image data and the nearest point in the locus of sensor illumination chromaticities. The method further includes determining the image chromaticity weight as a function of the determined distance.

In furtherance of the embodiment immediately above receiving the raw image data further comprises receiving a plurality of image data blocks each image data block including R G and B color channel values representative of a plurality of pixel color channel values. The one or more first image chromaticity weight and the one or more second image chromaticity weight are determined for each of the plurality of image data blocks. Determining the first white point estimate further comprises at least one of determining the white point correction factor based on a preliminary estimate of the white point determined over the image data blocks or combining the one or more first image chromaticity weight determined for each of the plurality of image data blocks with the one or more second image chromaticity weight determined for the corresponding raw data block. Determining the first white point estimate further comprises weighting the R G and B color channel values associated with each of the plurality of image data blocks with the one or more first image chromaticity weight or with the combination thereof and accumulating the weighted R G B color channel values over the plurality of data blocks.

In furtherance of the embodiment immediately above the combination of the one or more first image chromaticity weight comprises a product of a first and a second chromaticity weight that is each a function of a disparity between the R G and B color channel values for each data block and a third chromaticity weight that is based on a distance within the chromaticity space between the raw image data and the nearest point in the locus of sensor illumination chromaticities. The method further comprises determining a saturation value for each of the raw image data blocks and determining the first white point estimate based only on the raw image data blocks associated with a saturation value below a predetermined maximum saturation threshold.

In furtherance of the embodiment immediately above the method further includes determining a correlated color temperature CCT range based at least in part on sensor characterization data associated with an image sensor employed to collect image pixel data represented by the raw image data blocks. The method further includes identifying achromatic areas through a search of the plurality of raw data blocks having data values within the CCT range. The method further includes determining a second white point estimate based on the identified achromatic areas. The method further includes determining white balancing gains based on both the first white point estimate and the second white point estimate.

In one or more second embodiment a processor includes an AWB module. The AWB module comprising logic circuitry to receive color channel values of a raw image data block. The module comprises logic circuitry to normalize the color channel values with a white point correction factor. The module comprises logic circuitry to determine one or more first image chromaticity weight by quantifying a disparity among the normalized color channel values. The module comprises logic circuitry to store to a memory the one or more first image chromaticity weight in association with the raw image data block.

In furtherance of the one or more second embodiment the AWB module further comprises logic circuitry to quantify the disparity among the normalized color channel values by determining a minimum color channel value and a maximum color channel value from the normalized raw image data block and determining a ratio of the minimum and maximum color channel values.

In furtherance of the one or more second embodiment the AWB module further comprises logic circuitry to determine one or more second image chromaticity weight based on a distance between the raw image data in a sensor chromaticity space and a nearest point within a locus of sensor illumination chromaticities. The AWB module further comprises logic circuitry to determine the first white point estimate as a function of the one or more first chromaticity weight and of the one or more second chromaticity weight.

In one or more fourth embodiment a mobile device includes a camera module to generate raw image data. The device further includes a processor including an AWB module. The AWB module is coupled to the camera module to receive the raw image data. The AWB module is to generate raw image data blocks from the collected raw image data. The AWB module is to receive color channel values of a raw image data block. The AWB module is to normalize the color channel values with a white point correction factor. The AWB module is to determine one or more first image chromaticity weight by quantifying a disparity among the normalized color channel values. The mobile device further includes a memory to store the one or more first image chromaticity weight in association with the raw image data block.

In furtherance of the one or more fourth embodiment the AWB module is further to determine one or more second image chromaticity weight based on a distance between the raw image data within a sensor chromaticity space and a nearest point within a locus of sensor illumination chromaticities. The AWB module is further to determine the first white point estimate as a function of the one or more first chromaticity weight and of the one or more second chromaticity weight.

In one or more fifth embodiment one or more computer readable storage media has instructions stored thereon which when executed by a processor cause the processor to perform a method comprising receiving color channel values of a raw image data block normalizing the color channel values with a white point correction factor determining one or more first image chromaticity weight by quantifying a disparity among the normalized color channel values and storing to a memory the one or more first image chromaticity weight in association with the raw image data block.

In furtherance of the one or more fifth embodiment the media further includes instructions stored thereon which when executed by the processor further cause the processor to perform the method further comprising determining one or more second image chromaticity weight based on a distance between the raw image data in a sensor chromaticity space and a nearest point within a locus of sensor illumination chromaticities and determining the first white point estimate as a function of the one or more first chromaticity weight and of the one or more second chromaticity weight.

In one or more sixth embodiment the AWB module comprising logic circuitry to perform any one of the method.

In one or more seventh embodiment one or more computer readable storage media has instructions stored thereon which when executed by a processor cause the processor to perform the method recited in any one of the one or more fifth embodiments.

In one or more eighth embodiment a processor includes an AWB module. The AWB module includes a receiving means to receive color channel values of a raw image data block. The AWB module includes a normalization means coupled to the receiving means to normalize the color channel values with a white point correction factor. The AWB module include a color channel comparison means coupled to the normalization means to determine one or more first image chromaticity weight by quantifying a disparity among the normalized color channel values. The AWB module includes a storage means coupled to the comparison means to store the one or more first image chromaticity weight in association with the raw image data block.

In furtherance of the one or more eighth embodiment the color channel comparison means further comprises a min max identification means to determine a minimum color channel value and a maximum color channel value from the normalized raw image data block. The color channel comparison means further comprises a rationing means coupled to the min max identification means to determine a ratio of the minimum and maximum color channel values.

In furtherance of the one or more eighth embodiment the AWB module further comprises a chromaticity distance determining means to determine one or more second image chromaticity weight based on a distance between the raw image data in a sensor chromaticity space and a nearest point within a locus of sensor illumination chromaticities and a white point estimation means coupled to the chromaticity distance determining means and to the color channel comparison means to determine the first white point estimate as a function of the one or more first chromaticity weight and of the one or more second chromaticity weight.

It will be recognized that the embodiments are not limited to the exemplary embodiments so described but can be practiced with modification and alteration without departing from the scope of the appended claims. For example the above embodiments may include specific combination of features. However the above embodiments are not limited in this regard and in embodiments the above embodiments may include the undertaking only a subset of such features undertaking a different order of such features undertaking a different combination of such features and or undertaking additional features than those features explicitly listed. Scope should therefore be determined with reference to the appended claims along with the full scope of equivalents to which such claims are entitled.

