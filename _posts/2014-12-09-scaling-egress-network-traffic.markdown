---

title: Scaling egress network traffic
abstract: In an embodiment, a method is provided. The method of this embodiment provides generating one or more packets of data, the one or more packets of data being associated with a connection; and associating the one or more packets with one of a plurality of transmit queues based, at least in part, on the connection associated with the one or more packets.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09276854&OS=09276854&RS=09276854
owner: Intel Corporation
number: 09276854
owner_city: Santa Clara
owner_country: US
publication_date: 20141209
---
This application is a continuation of U.S. patent application Ser. No. 13 336 497 filed Dec. 23 2011 which is continuation of U.S. patent application Ser. No. 12 877 072 filed Sep. 7 2010 now U.S. Pat. No. 8 085 769 which is a continuation of U.S. patent application Ser. No. 11 395 959 filed on Mar. 31 2006 now U.S. Pat. No. 7 792 102 and are incorporated herein in their entirety.

As network speeds increase it becomes necessary to scale packet processing across multiple processors in a system. For receive processing a feature called RSS Receive Side Scaling can distribute incoming packets across multiple processors in a system. RSS is a Microsoft Windows operating system technology that enables receive processing to scale with the number of available computer processors by allowing the network load from a network controller to be balanced across multiple processors. RSS is described in Scalable Networking Eliminating the Receive Processing Bottleneck Introducing RSS WinHEC Windows Hardware Engineering Conference 2004 Apr. 14 2004 hereinafter the WinHEC Apr. 14 2004 white paper . It is also scheduled to be part of the yet to be released future version of the Network Driver Interface Specification NDIS . NDIS describes a Microsoft Windows device driver that enables a single network controller such as a NIC network interface card to support multiple network protocols or that enables multiple network controllers to support multiple network protocols. The current version of NDIS is NDIS 5.1 and is available from Microsoft Corporation of Redmond Wash. The subsequent version of NDIS known as NDIS 5.2 available from Microsoft Corporation is currently known as the Scalable Networking Pack for Windows Server 2003.

While there are defined mechanisms that enable receive processing to scale with increasing network speeds there currently are no such known mechanisms defined for transmit processing. For example when an application executes simultaneously on different processors a transmit request having one or more packets that originates with an application may typically be propagated through the protocol stack and call into a network device driver on the same processor assuming a multithreaded network device driver . If the network device driver only supports one transmit queue the network device driver may have to acquire a spin lock on the single transmit queue and wait until other processors have released their locks on the transmit queue. The spin lock may result in lock contention which may degrade performance by requiring threads on one processor to busy wait and unnecessarily increasing processor utilization for example.

One possibility would be to have multiple transmit queues and to associate each transmit queue with one or more processors. This would require that packets be posted to one of the transmit queues based on which processor generated the packets. However since applications are not guaranteed to always transmit from the same processor for a given connection it is possible that earlier packets on a highly loaded processor may be transmitted after later packets on a lightly loaded processor resulting in out of order transmits.

Examples described below are for illustrative purposes only and are in no way intended to limit embodiments of the invention. Thus where examples may be described in detail or where a list of examples may be provided it should be understood that the examples are not to be construed as exhaustive and do not limit embodiments of the invention to the examples described and or illustrated.

Methods described herein may be implemented in a system such as system illustrated in . System may comprise one or more processors A B . . . N. A processor as discussed herein relates to a combination of hardware and software resources for accomplishing computational tasks. For example a processor may comprise a system memory and processing circuitry e.g. a central processing unit CPU or microcontroller to execute machine readable instructions for processing data according to a predefined instruction set. Alternatively a processor may comprise just the processing circuitry e.g. CPU . Another example of a processor is a computational engine that may be comprised in a multi core processor for example where the operating system may perceive the computational engine as a discrete processor with a full set of execution resources. However these are merely examples of processor and embodiments of the present invention are not limited in this respect.

Each processor A B . . . N may be a coprocessor. In an embodiment one or more processors A B . . . N may perform substantially the same functions. Any one or more processors A B . . . N may comprise for example an Intel Pentium microprocessor that is commercially available from the Assignee of the subject application. Of course alternatively any of processors A B . . . N may comprise another type of processor such as for example a microprocessor that is manufactured and or commercially available from Assignee or a source other than the Assignee of the subject application without departing from embodiments of the invention.

System may additionally comprise memory . Memory may store machine executable instructions that are capable of being executed and or data capable of being accessed operated upon and or manipulated. Machine executable instructions as referred to herein relate to expressions which may be understood by one or more machines for performing one or more logical operations. For example machine executable instructions may comprise instructions which are interpretable by a processor compiler for executing one or more operations on one or more data objects. However this is merely an example of machine executable instructions and embodiments of the present invention are not limited in this respect. Memory may for example comprise read only mass storage random access computer accessible memory and or one or more other types of machine accessible memories.

Chipset may comprise one or more integrated circuit chips such as those selected from integrated circuit chipsets commercially available from Intel Corporation e.g. graphics memory and I O controller hub chipsets although other one or more integrated circuit chips may also or alternatively be used. According to an embodiment chipset may comprise an input output control hub ICH and a memory control hub MCH although embodiments of the invention are not limited by this. Chipset may comprise a host bridge hub system that may couple processor A B . . . N and host memory to each other and to local bus . Chipset may communicate with memory via memory bus and with host processor via system bus . In alternative embodiments host processor and host memory may be coupled directly to bus rather than via chipset .

Local bus may be coupled to a circuit card slot having a bus connector not shown . Local bus may comprise a bus that complies with the Peripheral Component Interconnect PCI Local Bus Specification Revision 3.0 Feb. 3 2004 available from the PCI Special Interest Group Portland Oreg. U.S.A. hereinafter referred to as a PCI bus . Alternatively for example bus may comprise a bus that complies with the PCI Express Base Specification Revision 1.1 Mar. 28 2005 also available from the PCI Special Interest Group hereinafter referred to as a PCI Express bus . Bus may comprise other types and configurations of bus systems.

System may additionally comprise one or more network controllers only one shown . A network controller as referred to herein relates to a device which may be coupled to a communication medium to transmit data to and or receive data from other devices coupled to the communication medium i.e. to send and receive network traffic. For example a network controller may transmit packets to and or receive packets from devices coupled to a network such as a local area network. As used herein a packet means a sequence of one or more symbols and or values that may be encoded by one or more signals transmitted from at least one sender to at least one receiver. Such a network controller may communicate with other devices according to any one of several data communication formats such as for example communication formats according to versions of IEEE Institute of Electrical and Electronics Engineers Std. 802.3 CSMA CD Access Method 2002 Edition IEEE Std. 802.11 LAN MAN Wireless LANS 1999 Edition IEEE Std. 802.16 2003 and 2004 Editions LAN MAN Broadband Wireless LANS Universal Serial Bus Firewire asynchronous transfer mode ATM synchronous optical network SONET or synchronous digital hierarchy SDH standards.

In an embodiment network controller may be comprised on system motherboard . Rather than reside on motherboard network controller may be integrated onto chipset . Network controller may instead be comprised in a circuit card e.g. NIC or network interface card that may be inserted into circuit card slot . Circuit card slot may comprise for example a PCI expansion slot that comprises a PCI bus connector not shown . PCI bus connector not shown may be electrically and mechanically mated with a PCI bus connector not shown that is comprised in circuit card . Circuit card slot and circuit card may be constructed to permit circuit card to be inserted into circuit card slot . When circuit card is inserted into circuit card slot PCI bus connectors not shown may become electrically and mechanically coupled to each other. When PCI bus connectors not shown are so coupled to each other logic in circuit card may become electrically coupled to system bus .

System may comprise logic . Logic may comprise hardware software or a combination of hardware and software e.g. firmware . For example logic may comprise circuitry i.e. one or more circuits to perform operations described herein. For example logic may comprise one or more digital circuits one or more analog circuits one or more state machines programmable logic and or one or more ASIC s Application Specific Integrated Circuits . Logic may be hardwired to perform the one or more operations. Alternatively or additionally logic may be embodied in machine executable instructions stored in a memory such as memory to perform these operations. Alternatively or additionally logic may be embodied in firmware. Logic may be comprised in various components of system including network controller chipset one or more processors A B . . . N and or on motherboard . Logic may be used to perform various functions by various components as described herein.

System may comprise more than one and other types of memories buses processors and network controllers. For example system may comprise a server having multiple processors A B . . . N and multiple network controllers . Processors A B . . . N memory and busses may be comprised in a single circuit board such as for example a system motherboard but embodiments of the invention are not limited in this respect.

In network one or more of the nodes A . . . N may comprise one or more intermediate stations such as for example one or more hubs switches and or routers additionally or alternatively one or more of the nodes A . . . N may comprise one or more end stations. Also additionally or alternatively network may comprise one or more not shown intermediate stations and medium may communicatively couple together at least some of the nodes A . . . N and one or more of these intermediate stations. Of course many alternatives are possible.

In an embodiment for example application may create a socket API application programming interface to request a connection that enables application to communicate with another application over a network. Protocol stack may establish the connection . Application may generate data and call into protocol stack of operating system to create one or more packets that include the data to be sent to the other application. Each packet may include a header and payload. The header may include information about the connection for example a source port and destination port. The payload may include at least a portion of the data to be sent to the other application. In an embodiment protocol stack may call into network device driver to create a transmit request that includes the one or more packets of data .

At block the method may comprise associating the one or more packets with one of a plurality of transmit queues based at least in part on the connection associated with the one or more packets.

In an embodiment associating the one or more packets with one of a plurality of transmit queues A B . . . N based at least in part on the connection associated with the one or more packets may comprise directing the one or more packets based at least in part on a known number of transmit queues A B . . . N provided by a particular network interface. In this embodiment for example protocol stack may be aware of the number of transmit queues A B . . . N provided by a particular network interface and the specific characteristics of the network interface. For example network interface may refer to the network device driver that is exposed to system where the network device driver may indicate whether transmit scaling is supported. If it is protocol stack may direct network device driver to post packets associated with a given TCP connection to the same transmit queue.

In another embodiment associating the one or more packets with one of a plurality of transmit queues A B . . . N based at least in part on the connection associated with the one or more packets may comprise generating a unique identifier to associate with the connection and associating the unique identifier used to identify a given connection with one of the transmit queues A B . . . N. For example protocol stack may generate the unique identifier. The unique identifier may comprise a four tuple comprising the local and remote IP addresses and local and remote TCP ports that identify the connection. Protocol stack may propagate the unique identifier to network device driver and network device driver may use this to associate the one or more packets with one of the plurality of transmit queues A B . . . N.

The unique identifier may be associated with one of the transmit queues A B . . . N by for example using an algorithm to map the unique identifier to a given transmit queue A B . . . N. Alternatively the unique identifier may be indexed into a lookup table having entries of unique identifiers and corresponding transmit queues A B . . . N where a corresponding one of the plurality of transmit queues A B . . . N may be selected. If the unique identifier is not found in the lookup table then an entry may be added to the lookup table . There are a number of ways in which the transmit queue A B . . . N corresponding to a given unique identifier may be selected for new entries. For example round robin selection or using low bits from the unique identifier to map to a transmit queue A B . . . N.

In an embodiment for example unique identifier may comprise an RSS hash value. An RSS hash value may be calculated by performing a hash function over one or more header fields in a header of a packet to be transmitted. In an embodiment the selected header fields in a header over which a hash function is performed would ensure that all packets going out on the same connection will be associated with the same hash value. Furthermore in this embodiment lookup table may comprise an indirection table as described in the NDIS specification.

At block the method may comprise submitting the one or more packets to the transmit queue. In an embodiment network device driver may post the one or more packets to the transmit queue A B . . . N. The one or more packets on the transmit queue A B . . . N may subsequently be consumed by network controller for transmission over network to the other system.

In an embodiment prior to said submitting the one or more packets to the transmit queue A B . . . N protocol stack may determine if the lookup table has changed and if the lookup table has changed the protocol stack may wait for one or more previously submitted packets to complete transmission over the wire before submitting new packets to network device driver . For example protocol stack may change the lookup table periodically to balance the load across the processors A B . . . N in the system.

At block the method may comprise submitting the one or more packets to one of a plurality of transmit queues based at least in part on the connection. In an embodiment submitting the one or more packets to one of a plurality of transmit queues A B . . . N based at least in part on the connection may comprise directing the one or more packets based at least in part on a known number of transmit queues A B . . . N provided by a network interface.

In another embodiment submitting the one or more packets to one of a plurality of transmit queues A B . . . N based at least in part on the connection may comprise submitting the one or more packets to a transmit queue A . . . N with which a unique identifier is associated. For example this may be done by submitting the one or more packets based at least in part on an algorithm used to map the unique identifier to a transmit queue A B . . . N. Alternatively this may comprise submitting the one or more packets to a transmit queue based at least in part on using the unique identifier to index into a lookup table and selecting a corresponding one of the plurality of transmit queues A B . . . N from the lookup table . For example in addition to generating one or more packets protocol stack may additionally generate a unique identifier and propagate this to network device driver . Network device driver may use the unique identifier to associate with one of the plurality of transmit queues A B . . . N.

In an embodiment prior to submitting the one or more packets to one of a plurality of transmit queues A B . . . N protocol stack may determine if the lookup table has changed and if the lookup table has changed the protocol stack may wait for one or more previously submitted packets to complete transmission.

Therefore in an embodiment a method may comprise generating one or more packets of data the one or more packets of data being associated with a connection and associating the one or more packets with one of a plurality of transmit queues based at least in part on the connection associated with the one or more packets.

Embodiments of the invention may enable transmit packet processing to scale with network speeds increase. By posting packets to transmit queues based on the connection with which the packets are associated the problem of scaling transmit processing with increased network speeds is addressed and traffic may be scaled efficiently across multiple transmit queues.

In the foregoing specification the invention has been described with reference to specific embodiments thereof. It will however be evident that various modifications and changes may be made to these embodiments without departing therefrom. The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

