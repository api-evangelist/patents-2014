---

title: Automatic batching of GUI-based tasks
abstract: Described herein are techniques for automatically batching GUI-based (Graphical User Interface) tasks. The described techniques include automatically determining whether a user is performing batchable tasks in a GUI-based environment. Once detected, the described techniques include predicting the next tasks of a batch based upon those detected batchable tasks. With the described techniques, the user may be asked to verify and/or correct the predicted next tasks. Furthermore, the described techniques may include performing a batch and doing so without user interaction.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09424068&OS=09424068&RS=09424068
owner: Microsoft Technology Licensing, LLC
number: 09424068
owner_city: Redmond
owner_country: US
publication_date: 20141222
---
This application is a continuation of and claims priority to U.S. patent application Ser. No. 13 756 237 filed on Jan. 31 2013 entitled Automatic Batching of GUI Based Tasks which is a continuation of and claims priority to U.S. patent application Ser. No. 12 948 353 filed on Nov. 17 2010 entitled Automatic Batching of GUI Based Tasks the disclosure of both is incorporated herein by reference in their entirety.

During their daily usage of a computer users often perform many repetitive tasks that are batchable. An example of batchable tasks includes repeating essentially the same re size operation on all of the photos in a particular folder on a storage device. A batchable task is an operation e.g. re size that is repeated but where a few aspects e.g. specific photo file in a folder vary with each operation. Batchable tasks may include essentially the same action repeated or may involve a repeated pattern of differing actions.

Some surveys have suggested that employees may spend as much as an hour in a typical workday performing repetitive operation such as batchable tasks. Of course a computer can be and often is programmed to perform batchable tasks. Unfortunately many users do not possess sufficient technical savvy to program such tasks. Even if a user has the technical savvy to script a series of batchable tasks many of those savvy users do not bother to take the time to write an appropriate script to perform a batch of the batchable tasks.

Moreover few if any options exists for scripting a series of batchable tasks across multiple applications available on one of the many available GUI based Graphical User Interface Operating System OS environments. Present solutions offer application specific macro scripting capabilities within particular applications. For example an application specific macro can be run within a word processing application such as Microsoft Word. However as the label suggests application specific macros do not operate across multiple applications in a GUI based OS environment.

Furthermore no present solution offers a way of automatically determining that a user is performing batchable tasks in a GUI based OS environment and then automatically completing a batch started by the user.

Described herein are techniques for automatically batching GUI based Graphical User Interface tasks. The described techniques include automatically determining whether a user is performing batchable tasks in a GUI based environment. Once detected the described techniques include predicting the next tasks of a batch based upon those detected batchable tasks. With the described techniques the user may be asked to verify and or correct the predicted next tasks. Furthermore the described techniques may include performing a batch and doing so without user interaction.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter. The term techniques for instance may refer to device s system s method s and or computer readable instructions as permitted by the context above and throughout this document.

Described herein are techniques for automatically batching GUI based Graphical User Interface tasks. The described techniques include automatically determining whether a user is performing batchable tasks in a GUI based environment. Once detected the described techniques include predicting the next tasks of a batch based upon those detected batchable tasks. In other words after a pattern of batchable tasks is identified a system using the described techniques may project what one or more of the next few tasks might be.

The user may be asked to verify and or correct the predicted next tasks. After verification or correction the described techniques may include automatically i.e. without user interaction performing a batch based at least in part upon the corrected or verified next tasks.

The following is an example image re sizing scenario that might illustrate how one or more described techniques may be implemented. In this example scenario a user s computer system has a particular subfolder containing one hundred digital photos. Using the GUI based OS the user navigates to view the contents of the particular subfolder. Using a GUI based image manipulation application the user selects the first digital photo in the subfolder and re sizes the image to meet the user s specific criteria e.g. perhaps to be better viewed on a smaller display device . With the conventional approach the user must repeat the re sizing task one hundred times i.e. once for each digital photo . Each of the iterations of the re sizing task is essentially the same as each of the other iterations. The only differences between iterations are a few details such as the name of the particular digital photo being re sized in that iteration.

If the user is sufficiently trained the user could write a short script or generate an application specific macro to perform the re sizing task one hundred times to process the one hundred digital photos in the subfolder. Most users do not have the skills to write such a script and those that do have the skills may not want to take the time to write such a script because it might take nearly as long to write as it would to manually perform the repetitive tasks.

With at least one described implementation a configured system tracks the GUI based re sizing tasks as the user manually performs each task. Once it identifies a pattern of tracked tasks the system determines that the tasks of the pattern are capable of being batched. Such tasks are called batchable tasks herein. Since the user appears to be selecting digital photos in a particular subfolder it is likely that the user intends to re size each of the remaining digital photos in that subfolder. The system may predict the next few tasks based upon the repeated pattern and anticipating which of the digital photos are next in the subfolder.

By visually walking the user through the next one or more predicted tasks the user is given a chance to verify whether the predicted next few tasks are correct. Once verified the system generates the full batch based upon the verified prediction and the batch runs automatically without manual user input thereafter. In this example scenario the remaining digital photos in the subfolder are re sized without any additional manual input from the user.

The computing device of this example computer environment includes one or more processors one or more storage subsystems at least one monitor and one or more memories . Running at least in part on the computing device is an Operating System OS and in particular this OS interacts with the user via a Graphical User Interface GUI . Herein this OS is called the GUI based OS . An example of a typical GUI based user interface UI of a GUI based OS is shown on the monitor . This example GUI based UI includes two example GUI based applications and that might be displayed on such a UI.

As depicted the auto batcher includes four modules a GUI based task tracker a batchable task determiner a batchable task confirmer and a batch performer . Each of these modules is described generally below but each are discussed in more details in the following section about the auto batcher .

In an on going basis the GUI based task tracker monitors pre processes and records the tasks or actions that the user performs within the GUI based environment of the GUI based OS . This includes tasks performed with one or more GUI based applications such as applications and . More particularly the GUI based task tracker tracks the user s actions across multiple GUI based applications. Tracked actions may include for example clicking on a button double clicking on an icon selecting an item in a list entering values in an input box right clicking and the like.

The GUI based task tracker pre processes the tracked tasks to organize and identify them. In addition the GUI based task tracker stores the tracked and or pre processed tasks in the memory and or the storage system .

In an on going basis as the tasks are tracked the batchable task determiner detects whether batchable tasks have been performed by the user . The batchable task determiner detects a pattern of repeated tasks in the incoming stream of tracked tasks. Once it indicates that a set of repeated tasks may be batchable the batchable task determiner predicts a forthcoming sequence of variant portions of future iterations of the batchable tasks.

The batchable task confirmer has the user verify the determined batchable tasks and the predictions about the forthcoming sequence of variable portions of such tasks. Also the batchable task confirmer may allow the user to correct the predictions.

With a confirmation or correction from the user the batch performer then generates the remainder of the batch and performs the generated batch automatically i.e. without user interaction . Indeed the batch when performed may act over multiple GUI based applications such as GUI based applications and . That is the batch may include actions performed on by in or with multiple GUI based applications.

The GUI based task tracker monitors pre processes and records the user s GUI based tasks. The GUI based task tracker includes at least two sub modules a user operation capturer and a GUI based task parser .

Generally the GUI based task tracker operates in the background of the GUI based OS . Because of this the user is typically unaware that the user operation capturer is silently observing and recording the actions performed by the user as she goes about performing various tasks via inputs such as those from a keyboard and a mouse. Regardless of which application is being used e.g. GUI based applications and or the user operation capturer may capture all GUI based tasks of the user. Indeed the GUI based task tracker may track the user s actions across multiple GUI based applications such as GUI based applications and . Tracked tasks may include inputs from the keyboard mouse touchscreen or other such inputs used for selections of options of GUI based applications.

Rather than an application specific function an OS wide hook may be used to capture the input e.g. keyboard and or mouse events to implement the described techniques for automatically batching GUI based tasks. Generally OS wide hooks using application programming interfaces APIs identify and store the detail information of a GUI element such as the element type element name and its parent components information. Examples of such APIs are part of the UI automation accessibility framework such as Microsoft Active Accessibility MSAA and its successor the Microsoft UI Automation UIA each of which is supported by various GUI based operating systems. Such frameworks are general interfaces for most GUI based applications and can get the information of basic GUI based elements such as the button link menu input box file window etc.

Using GUI element identification hooks the user operation capturer gets information about the GUI based element e.g. the button link menu input box file window etc. that is the subject of the user s GUI based actions. This GUI based element is called the operation target.

The user operation capturer detects tracks and records the operation types e.g. the mouse keyboard events and operation element e.g. which button menu in which window is clicked . With this information the user operation capturer stores a unique identification of each user operation in a defined format. Each operation record as user operation is called is stored as a combination of the operation type and the operation element. The structure of the operation record enables a unique representation of the operation target and an operation type so as to indicate the user interaction. Implementations may use new or existing formats of the operation records. Suitable existing formats include those offered by MSAA or UTA.

The operation record format contains the process name main window information and frame window information together with a hierarchy tree structure of the element. For example the element of an OK button in the Save as . . . dialog of a specific application called X may have the process name WinX the main window of X frame window to be the Save as . . . dialog and a hierarchy tree structure from the frame window to the OK button. With this data structure the target element may be accessed later when tasks are automatically performed as part of a batch.

The GUI based task parser receives a series of operation records as such records are being captured by the user operation capturer . The GUI based task parser analyzes this operation record sequence to parse the invariant portions of each task from the variant portions. Herein the invariant portion is called a logkey and the variant portion is called a parameter. The invariant portion of a task includes that portion that remains essentially the same each time the task is repeatedly performed. The variant portion of a task includes that portion that changes each time the task is repeatedly performed. For example if the repeated task includes re sizing an image the actions involving re sizing are invariant while the specific image being re sized varies for each repetition of the task.

Below is an expanded view of the re sizing example. An example operation record sequence of the repetitive task of editing a collection of digital photos with the same re size operation is as follows 

In the Example Operation Sequence 1 shown above the invariant part i.e. logkey of each repeated task is shown without the underline. This invariant part indicates the general operation of the task. The variant part i.e. parameters is shown with underline. The variant part indicates the specific information among similar repeated operations.

In different types of batchable tasks the location and arrangement of the logkey and parameters may be different. The logkey and parameters are typically distinguished by comparing and contrasting the operation sub sequences side by side. A sub sequence is a chronologically adjacent grouping of one or more tasks. For example in the above Example Operation Sequence 1 through comparing the operation sub sequences side by side the GUI based task parser is able to determine the invariant and variant parts among the sub sequences and label them appropriately as logkey or parameter. The parameters are 1 sea.jpg 2 mountain.jpg 3 and flower.jpg. The remainder of each task represents the logkey.

From observed patterns in collected records the GUI based task parser may be pre programmed to look at some fixed locations for potential parameters which can assist in separating the logkey and parameters. Some of the known fixed locations for potential parameters include by way of example only and not limitation 

By separating the logkey and parameters the GUI based task parser generates a logkey sequence. From this the GUI based task parser may map the essentially same logkeys to the same identification e.g. ID label. In this way the above Example Operation Sequence 1 is mapped into this ID sequence 

Similarly the GUI based task parser may map the parameters. In this way the above Example Operation Sequence 1 is mapped into this parameter sequence 

Using the captured and pre processed operation sequence from the GUI based task tracker the batchable task determiner detects batchable tasks and attempts to anticipate the operations that the user might perform next in the batch. The batchable task determiner includes at least two sub modules a task pattern detector and a parameter projector .

The task pattern detector uses the logkey sequence generated here by the GUI based task parser to detect the repetition pattern of sub sequences inside the operation sequence. When such a pattern is detected the tasks in that sub sequence pattern are batchable. That is the tasks of a detected pattern are capable of being batched.

The task pattern detector determines that there is a pattern in the sequence when it detects at least two chronologically adjacent sub sequences having the same set of logkey IDs. In other words the task pattern detector declares a pattern when the operation sequence shows at least two sets of sub sequent tasks in succession having the same repeated pattern of logkey IDs.

Some implementations may employ a classical repetition detection approach called the Karp Miller Rosenberg KMR algorithm to detect the repetition pattern inside a long sequence. To illustrate further consider this Example Operation Sequence 2 ID1 ID2 ID3 ID4 ID5 ID2 ID3 ID4 . Using the classical repetition detection approach the task pattern detector detects the repetition pattern of sub sequence ID2 ID3 ID4 of the Example Operation Sequence 2 and that pattern has a repetition length of three. If the next operation in the Example Operation Sequence 2 is ID5 then the task pattern detector detects the following as the repetition pattern ID2 ID3 ID4 ID5 .

In some implementations the task pattern detector may use the classical repetition detection approach with some constraints for filtering results. Those constraints may include 

To illustrate the affect of the timeliness constraint consider this Example Operation Sequence 3 ID1 ID2 ID3 ID1 ID2 ID3 ID1 ID2 ID3 ID6 ID5 ID2 ID4 IDT ID6 ID2 . Based upon the timeliness constraint the task pattern detector does not detect a pattern in the Example Operation Sequence 3 because the end of the sequence does not include any pattern. The pattern of ID1 ID2 ID3 exists in the sequence but since it is not at the end of the sequence being analyzed it is not designated a pattern. The imposition of this timeliness constraint prevents the task pattern detector from detecting a pattern of tasks that the user is no longer performing and thus is probably not interested in.

To illustrate the affect of the batchability constraint consider this Example Operation Sequence 4 ID1 ID2 ID3 ID8 ID1 ID2 ID3 IDT ID1 ID2 ID3 ID6 ID1 ID2 ID3 . Based upon the batchability constraint the task pattern detector does not detect a pattern in the Example Operation Sequence 4 because an operation e.g. ID8 IDT or ID6 intercedes the repeated pattern of ID1 ID2 ID3 . The imposition of this batchability constraint helps ensure that the task pattern detector detects patterns that are worthwhile to batch. The intercession of non repeating tasks e.g. ID8 IDT or ID6 between repeating patterns means that any resulting batch would be short and thus the user would save little time using such a batch.

Once a pattern is detected the parameter projector then predicts the parameters of the future operations in the anticipated batch. That is the parameter projector projects what the next parameters will be for one or more of the next operations that the user has not yet performed. That includes predicting the specific values expected for the parameters of forthcoming iterations of the batchable tasks. In some implementations the parameter projector may make these predictions based upon the category or classification of the parameters and or tasks.

Based upon a defined set of assumptions or rules for a class of parameters the parameter projector may project the expected values of the parameters. For example when the parameter is a file name and two or three files of a specified folder have been the subject of the tasks thus far a reasonable rule or assumption might predict that the remaining files in that folder may be the subject of the batch. These rules or assumptions may also be called parameter sequences herein.

The following are examples of some parameter sequences that the parameter projector may use by way of example only and not limitation 

The parameter projector may be pre loaded with a set of useful known parameter sequences. In addition the user may be offered an opportunity to customize the existing parameter sequences and or generate new parameter sequences to match her needs. The predefined user customized and or user generated parameter sequences are stored in the memory and or storage system of the computer device .

Once a pattern is detected and the parameters are projected the batchable task confirmer confirms the predicted batchable tasks with the user or allows the user to correct the predictions. The batchable task confirmer includes at least two sub modules a projection verifier and a projection corrector .

The projection verifier notifies the user that an auto batch is available for verification. This notification may be accomplished via any one of several suitable mechanisms. For example an icon may appear in a status tray a specific audible notification may sound and or a dialog box may appear on screen.

In response to the notification the user may choose to engage in the verification process. As part of that process the projection verifier visually steps the user through the projected next tasks in the batch. That is the projection verifier shows the user on screen what the next action is that the user would have performed as part of the detected repeated pattern of tasks.

To illustrate how the projection verifier may perform its verification presume that the repetition pattern is ID1 ID2 IDn and the predicted parameters are P1 P2 Pn . From this the predicated combination is represented by this operation sequence ID1 P1 ID2 P2 . . . IDn Pn . With that predicted operation sequence the projection verifier locates the next operation target e.g. a drop down list in a particular application and highlights the operation elements i.e. a particular element of the predicted future operations. For example if the next operation target is an input box the projection verifier locates that input box and shows the predicted value in the box.

The projection verifier may get verification from the user via a conventional user input dialog box. Alternatively the projection verifier may get verification from the user by how the user interacts during the visual presentation of the projected next target operation. It may be presumed that the user agrees or disagrees with the anticipated batch task by how the user follows or fails to follow a visual simulation of the anticipated batch task. Here following may include the user providing coordinating user input such as the user controlled cursor moving near or along with the simulated cursor controlled by the projection verifier .

With one or more implementations the batch verifier may draw a colored shape e.g. red rectangle around the located GUI element that is the target of the projected target operation. This colored shape highlights the target operation and acts as a guide to the user. If the user does not follow the highlighted target to do the operations for a defined number of steps e.g. three steps then the projection verifier may assume that the prediction is wrong and guidance ends.

If the prediction is wrong the projection corrector may ask the user to correct the projection. The user may do this for example by modeling the missing or incorrect GUI based tasks or by correcting the parameter sequence used by the parameter projector . Once corrected the parameter projector may generate a new projection based upon the correction.

If the user follows the highlight target and the predicted values to do the operations for one task or a major part of one task then the projection verifier concludes that the prediction is correct. In this case the projection verifier may ask the user to confirm whether to automatically complete the succeeding tasks e.g. the batch on her behalf.

Instead of verifying or correcting if the user ignores the notification or does not confirm the projections then the present projections are discarded. However the user may be notified again once a new projection is ready based upon the existing or a newly detected pattern of GUI based tasks.

With the user s confirmation or correction the batch performer performs the batch based upon the verified or corrected projections or more simply the confirmed projections . The batch performer includes at least four sub modules a parameter range determiner an operation target locator a batch generator and a user input emulator .

The parameter range determiner detects and confirms the range of the parameters. Based upon context the parameter range determiner may detect the range or upper lower limits of the parameters. For example by noticing that there are fifty digital photos in a target subfolder the parameter range determiner may determine that these fifty digital photos form the range or limit for the parameter. Then the parameter range determiner may ask the user to confirm this detected range. The user also has a chance here to correct the range if the detected range is not what the user desires. Alternatively the user may just be asked for the range without any detection being performed.

To mimic the user actually performing the remaining part of the batch tasks the operation target locator locates the target elements of the operations of the generated batch. That is the location of the target element e.g. buttons input boxes etc. is determined within a relative context. As opposed to an absolute context e.g. coordinates of pixels on a screen or in a window the relative context is where a particular element is located regardless of its absolute location. For example a particular button may be located regardless of where it is on a screen at the time.

To illustrate consider this repetition pattern ID1 ID2 IDn and this predicted parameter set P1 P2 Pn . When the two are combined this predicted set of operations is generated ID1 P1 ID2 P2 . . . IDn Pn . The operation target locator maps each of these IDs back to a logkey i.e. the invariable part of a GUI based task . The operation target locator generates an operation record by adding the parameters Pn to the IDs. Herein this is called the predicted operation record. The predicted operation records may be formatted in accordance with the operation record format discussed above. Each predicted record uniquely represents its operation target together with an operation type to indicate the user interaction.

Within the operation record format each predicted operation record includes the process name main window information frame window information and a hierarchy tree structure of the element. With this data structure the target element on the system can be found. The operation type is used to indicate the user interaction such as a right click left click double click drag mouse move keyboard input etc.

With the predicted operation record the batch generator generates a predicted operation sequence which may be called the predicted batch. The predicted batch may be stored in the memory and or storage system of the computer device .

When each GUI based task of a predicted operation record is preformed the user input emulator mimics the appearance of a user controlling the input. This user input emulation is more pleasing to the user and provides the user with feedback regarding what actions are taking place automatically. Exactly what occurs depends upon the operation type of the operation target of the predicted operation record being automatically performed for the user.

The user input emulator may implement the click double click move operations by generating system level mouse events. For example a click consists of one mouse down and one mouse up with a proper time interval and a double click consists of a first mouse down a first mouse up a second mouse down and a second mouse up.

As shown here the process begins with operation where the computing device tracks the GUI based tasks or actions performed by the user as part of a GUI based OS environment. This operation is the default or baseline operation performed by the process. The tracking includes monitoring pre processing and recording the user s GUI based tasks.

As part of operation the computing device tracks the GUI based tasks of the user within the context of the GUI based environment. The computing device detects and captures user input as discrete tasks or actions performed by the user via a graphical user interface. This may be accomplished for example by having a hook that is running in cooperation with the OS for identifying the GUI elements of the OS or GUI based application.

In addition the computing device converts the captured tasks into a pre defined format such as the operation record format already discussed. Then the components of the formatted captured tasks are parsed and portions are labeled as being invariant or variant relative to other tasks performed by the user. That is the computing device parses and labels each of the tracked GUI based tasks into an invariant portion and one or more variant portions wherein the invariant portion of like tasks do not differ between like tasks and the variant portions of like tasks differ between like tasks. Herein the invariant portions of a task are called logkeys and the variant portions are called parameters.

At operation the computing device detects batchable tasks. The computing device examines the invariant portion of each task of a sequence of GUI based tasks and detects in the sequence a repeated sub sequence of tasks having a common pattern of invariant portions.

By comparing the invariant portions of tasks the computing device determines whether the user is manually performing a repeated pattern of like tasks. As indicated by the dashed arrow operation returns back to the baseline tracking operation until a repeated pattern is detected. Conversely once a repeated pattern is detected this process proceeds to the next operation which is .

At operation the computing device anticipates one or more GUI based tasks not yet performed by the user. To do this the computing device sets the values of the parameters and thereby effectively predicts the parameters of the future operations in the anticipated batch. Based at least in part upon known pre defined user customized and or user defined sequences of parameters the computing device projects what the next parameters will be for the next operations that the user has yet to perform. As indicated by the dashed arrow this operation returns back to the baseline tracking operation if no appropriate parameter sequence is found in order to project the parameters of the detected pattern. Conversely once the appropriate parameters are projected this process proceeds to the next operation which is .

At operation the computing device verifies with the user that the one or more anticipated GUI based tasks match forthcoming GUI based tasks that the user intends to perform. To do this the computing device verifies that the projected parameters accurately predict the actions the user was intending to perform next. This may be accomplished by demonstrating the next actions for the user and asking the user to confirm. Alternatively this may be accomplished by asking the user to follow the demonstrated actions with user input.

At operation the computing device receives an indication from the user during the verification process as to whether the parameters of the demonstrated actions are accurate. If verified the process proceeds to operation . If not verified the process may return to operation to track the user s tasks again. A failure of the user to respond within a defined period e.g. 5 seconds may be presumed to be non verification. Alternatively the user may be offered an opportunity to correct a non verified projection. In this instance the process may proceed to operation for the user to correct the batch.

At operation the user corrects or adjusts the parameter sequence used by operation to match the pattern that the user intends to use. By utilizing the user provided or user corrected parameter sequence this operation may perform the projections of operation . From here the process may proceed to operation .

At operation the computing device performs a batch of the verified GUI based tasks visually simulating a user providing input in performing the GUI based tasks of the batch. In other words the computing device performs the batch based upon the verified or corrected projections. provides more details about how that is done. Once the batch is performed the process returns back to baseline operation to continue to track the user s GUI based tasks.

As shown here the process begins with operation where the computing device detects and confirms a range of parameters. Based upon context the computing device may detect a range or upper lower limits of the parameters. After detecting the upper and or lower limit of the parameters the computing device may ask the user to confirm this detected limit.

At operation the computing device locates the target elements of the operations of the generated batch in order to be able to later mimic the user performing the batch tasks. The computing device maps the IDs of the detected repetition pattern to their logkeys. The computing device then combines the predicted parameters with the mapped logkeys to produce predicted operation records. The predicted operation records may be formatted in accordance with the operation record format already discussed.

Using the predicted operation records at operation the computing device generates a predicted operation sequence which may be called the predicted batch. The generated batch may be stored in the memory or storage system of the computer device .

At operation for each GUI based task of a predicted operation record the user input emulator determines how to emulate a user controlling the input. In this way while the batch is being automatically performed it appears that a user is controlling the input. For example it appears that the user is moving the cursor on screen and clicking buttons.

At operation the computing device performs the predicted batch and does so without user interaction or intervention. That is it does so automatically.

As used in this application the terms component module system interface or the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of example both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media.

Computer readable media includes at least two types of computer readable media namely computer storage media and communications media.

Computer storage media includes volatile and non volatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other non transmission medium that can be used to store information for access by a computing device.

In contrast communication media may embody computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transmission mechanism. As defined herein computer storage media does not include communication media.

As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . For example unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims should generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as example forms of implementing the claims.

