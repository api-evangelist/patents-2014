---

title: Multi-user sensor-based interactions
abstract: Disclosed in some examples are methods systems and machine readable mediums in which actions or states of a first user (e.g., natural interactions) having a first corresponding computing device are observed by a sensor on a second computing device corresponding to a second user. A notification describing the observed actions or states of a first user may be shared across a network with the first corresponding computing device. In this way, the first computing device may be provided with information concerning the state of the user without having to directly sense the user.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09633622&OS=09633622&RS=09633622
owner: Intel Corporation
number: 09633622
owner_city: Santa Clara
owner_country: US
publication_date: 20141218
---
A portion of the disclosure of this patent document contains material that is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent files or records but otherwise reserves all copyright rights whatsoever. The following notice applies to the software and data as described below and in the drawings that form a part of this document Copyright 2014 Intel Inc. All Rights Reserved.

Embodiments pertain to augmented reality systems. Some embodiments relate to gesture recognition multi device interaction and natural user interaction.

Computing devices have decreased in size over the last several years. These computing devices may even take the form of devices worn on a user s body. Even as computing devices have decreased in size functionality has increased. For example many computing devices have on board sensors such as cameras motion sensors and the like.

As disclosed herein computing applications may utilize sensor data which describes information about the real world and in particular about users in the real world to provide various sensor based applications. In one example sensor based application natural interactions such as gestures and emotions of a first party may be detected and displayed to the first party to provide real time analysis of how that party is being received by a second party. For example an application may detect a speaker s gestures and emotions and display them to the speaker as they are speaking. Knowing how one s gestures are likely to be received by another party may improve relations between the parties to the conversation. A sensor based application may be any application executable by a computing device which makes use of a sensor in the computing device to provide functionality to a user.

As another example of a sensor based application augmented reality applications blend the physical real world environment with inserted computer generated objects and data making the computer generated objects appear to be part of the physical real world environment. The computer generated objects may be manipulated by the participant users using natural gestures and interactions. The augmented reality may be provided by one or more computing devices which utilize one or more sensors in order to sense measure and detect items in the real world including users and their gestures and movements and to add one or more computer generated objects which are visible on one or more output e.g. display devices. Example augmented reality applications include games which superimpose game objects in a real world environment. Players may interact with the game objects using natural physical gestures. For example a user may pick up move delete change or otherwise interact with the objects similar as if they were real life objects. Other example applications may include navigation applications where a route indicator e.g. a line is superimposed upon a picture of the correct road to take.

Sensing devices for these applications may include global positioning sensors GPS accelerometers image sensors e.g. cameras such as an Intel RealSense 3D camera object scanners and the like. Sensing devices may output data called sensor data such as GPS coordinates image pixel data acceleration quantities and directions and the like. This data may be analyzed by the computing device to determine model data. The model data describes information e.g. size position and other attributes of at least a portion of the real world including one or more objects in the real world. The model may be derived from the raw sensor data. Objects in the real world may include people in the real world. In some examples the model may include detected actions of those objects. Actions may include any movements of objects such as gestures hand and finger tracking speech recognition facial movements and other aspects regarding people and other objects detected in the real world. Detecting of action information may include detecting natural interactions such as gestures facial movements and the like. Action information may describe one or more detected actions. In some examples the model may include one or more inferred states for the real world objects that are inferred from object actions. States that apply to persons may include happy sad bored disinterested and the like. For example facial recognition and gesture recognition may infer states of individuals from facial actions such as facial expressions. States may be described by object state information. Software such as Intel RealSense software may be employed to do this analysis.

In order to make these applications more usable and enjoyable in everyday environments the sensory devices e.g. cameras may be on wearable devices and other portable computing devices. However wearable and other portable computing devices may only have a camera facing outward thus the sensors may not detect gestures facial expressions and other input regarding the user themselves. Positioning a camera facing inward to capture the facial expressions and gestures of the wearing user would increase the device s size and cost. Adding the camera facing inward would also be difficult to implement in many wearables as this would require placing the camera at a distance from the subject to achieve a satisfactory focal length and to capture enough of the user. Thus wearables have difficulty in sensing the gestures hand and finger tracking speech recognition facial analysis and other aspects of the user that is wearing it. While the forward facing camera can detect these aspects for other people the ability of the wearable to facilitate the interaction of the user with the augmented reality environment is limited.

Disclosed in some examples are methods systems and machine readable mediums in which actions or states of a first user e.g. natural interactions having a first corresponding computing device are observed by a sensor on a second computing device corresponding to a second user. A notification describing the observed actions or states of a first user may be shared across a network with the first corresponding computing device. In this way the first computing device may be provided with information concerning the state of the user without having to directly sense the user. In the same way the first computing device may send information about the second user to the second computing device. This collaborative sharing of detected natural interactions may allow for expanded applications of sensor based applications. For example this collaborative sharing may allow the first and second user to see themselves through the other user s eyes. For example the second computing device may relay detected gestures emotions and other observations about the first user to the first user s computing device for use on the first user s display device.

The information exchanged between the computing devices may be an exchange of notification data which may include one or more of raw sensor data which may then be used by the recipient to calculate model data including objects actions and object states model data action information e.g. information on gestures or object state information. This notification data may be sent directly to other computing devices participating in the application or may be sent to a central computing device. The central computing device may then forward the notification data to other computing devices participating in the application. The notifications may be sent over a computer network.

In some examples one or more of processing raw sensor data to form model data detecting objects detecting actions or inferring states of the objects from those actions may be done on the computing devices of the participating users. In other examples one or more of processing raw sensor data to form model data detecting objects detecting actions or inferring states of the objects from those actions may be done on the central computing device based upon notification data sent from the computing devices of the users participating in the application.

Notification data sent from the devices of the users to the central computing device may be different from the notification data disseminated from the central computing device to the devices of the users in response. For example a computing device associated with a user of the application may send raw sensor data which may be processed into object state information by the central computing device and the like. The object state information may then be sent to the individual computing devices instead of the raw sensor data.

As noted actions or states of a first user e.g. natural interactions having a first corresponding computing device are observed by a sensor on a second computing device corresponding to a second user. The second computing device or the central computing device may associate the observed actions or states of the first user with the first user s computing device and indeed the first user . In some examples this may be done based upon facial or other object recognition techniques performed by either the second computing device or the central computing device. For example each user may submit one or more registration images of themselves to the system for example to the central computing device. In some examples this may happen during registration. One or more facial recognition algorithms may utilize the registration images to determine the user that corresponds to the action or state. These algorithms may be run on the computing devices or the central computing devices. In other examples other ways of associating the first user with the particular action or state may include using locations e.g. a location registry where user s locations are compared with locations of observed actions or states wirelessly broadcast identifiers e.g. the computing devices broadcast a unique identifier on a short range less than 100 m wireless link or the like.

Computing devices may include wearable computing devices such as smart glasses smart watches and the like. Computing devices may also include tablet computers laptop computers desktop computers and the like.

These systems methods and machine readable mediums may have a variety of uses. For example feedback on how other users in the system see or perceive you can be displayed to you and used to improve social relations understand conflicts and improve your ability to persuade and influence stakeholders in a face to face meeting. Other uses include edutainment gaming dating and the like.

In User A is equipped with wearable computing device and is facing User B . User B is also equipped with a wearable computing device and is facing User A . User C is facing User A and is equipped with a computing device. In an example User B s computing device may record video of User A. User A s actions e.g. a gesture may be detected by User B s computing device and vice versa through analysis of the raw sensor data. Notification information about User A e.g. action information may be sent to central computing device using notifications . Central computing device may send the notification information on to one or more of computing devices of User A User B and User C . The selection of which computing devices to share the notification information with may be determined by one or more of device subscriptions e.g. devices subscribe to receive this information privacy settings in the computing device proximity and the like. For example notification information relating to users within a particular proximity to a particular computing device may be sent to the particular computing device. User C s computing device may also record sensor data of User A. User A s actions e.g. a gesture may be detected by User C s computing device and vice versa through analysis of the raw sensor data. Notification information about User A e.g. action information may be sent to central computing device using notifications . Central computing device may send the notification information to one or more of computing devices of User A User B and User C . User A s computing device may also record sensor data of User B. User B s actions e.g. a gesture may be detected by User A s computing device and vice versa through analysis of the raw sensor data. Notification information about User B e.g. action information may be sent to central computing device using notifications . Central computing device may send the notification information to one or more of computing devices of User A User B and User C . As already noted notification information may be the same information as sent in notification information and or may be different notification information which is based upon the notification information in and . Thus despite each computing device having only a limited field of view of users in the application through collaborative sharing of information each computing device may obtain information regarding all users in the application.

At operation the computing device of User A may detect an event corresponding to another user e.g. User B . Events may be any change in the model for example a detected action a change in state of one or more objects or users and the like. An event may also include expiration of a timer e.g. the computing device may regularly send updates including notification information to the central computing device e.g. the central computing device . In some examples notification information may describe the event or may describe the current model of the computing device. Notification may be sent to the web server which may forward it to the central computing device . Central computing device may forward the notification back to web server in message for distribution to one or more selected computing devices based upon the subscription information. In some examples central computing device may process the received notifications . For example if the notification is raw sensor data the central computing device may use that data and in some examples raw sensor data from other devices that were received previously to build a model detect objects detect actions infer states and the like. In these examples the information in notifications and may be different than the information in the notification sent from the central computing device in that it may be processed. Web server may forward the notification to User B s computing device using message and in some examples to User A s computing device using message . While showed an example implementation with point to point messaging and in other examples multi cast or broadcast messaging may be employed.

Continuing on User B may smile . User A s computing device may detect the smile and send a notification message to the central computing device . Central computing device may send a notification indicating that User B has smiled to User C s device and in some examples a notification to User B s computing device and in even further examples an indication to User A s computing device . As already noted this may be an indication that the User B smiled or some other user state indication or may be an update to one or more virtual objects. Similarly when User C walks it may be detected by User B s computing device . User B s computing device may send a notification to the central computing device which may then send notifications and to User A s computing device and User C s computing device.

Turning now to a flowchart of a method of a central computing device facilitating sharing of information in a sensor based application according to some examples of the present disclosure. At operation the central computing device may receive a message. If the message is a registration message the central computing device may process the registration message at operation . Processing the registration message may include storing registration details in local storage. Registration messages may register a computing device with a particular application. In some examples registration messages may register the computing device at a particular location in examples in which notifications are sent based upon proximity to the particular user for which the notification was sent. In these examples the registration messages may be sent periodically by the computing devices to update the location of the computing devices with the central computing device.

If the message received at operation is a notification message the notification message may be processed at operation . In some examples processing the notification may include calculating model information including actions states and the like based upon the information included in the notification. At operation the computing devices target devices which will receive the second notification from the central computing device may be determined. This may be based upon the registration information. At operation the second notification may be sent to the target computing devices. The first and second notifications may comprise the same information e.g. raw sensor data action information state information model information and the like . In other examples the second notification may comprise information calculated based upon the first notification e.g. model data calculated from raw sensor data in the first notification e.g. calculated at operation .

Turning now to a method of a computing device providing information about the user to a sensor based application according to some examples of the present disclosure is shown. At operation the computing device registers with the central computing device. At operation the computing device receives an event. Events may include notifications or sensor data. If the event is a notification e.g. received from another computing device or the central computing device the computing device may read the notification and if necessary compute or update the computing device s model at . E.g. if the notification is raw sensor data the computing device may detect one or more one or more objects one or more actions and or one or more states of the detected objects. In other examples if the notifications include model information the model information in the notification may be used to update the model information in the computing device. At operation in some examples the notification information and or updated model may be utilized to notify the application. For example the computing device may send a notification to the sensor based application. In some examples the operations of may be performed by the sensor based application itself. In these examples the notification may be a function call a procedure call a flag intra process communications inter process communications or the like. The application may utilize the information to update the application state. Updates may include for example updating a display of the application. As an example if the notification information is information about the perceived state of the user of the sensor based application e.g. a perceived emotion as perceived by another computing device the sensor based application may display that state to the user.

If the received event at operation is sensor data or in some examples a scheduled sensor reading the computing device may compute or update the model . For example the computing device may calculate an action states e.g. emotions or other model information from the sensor data. At operation the computing device may send the sensor data or model information including action emotions and the like to the central computing device. At operation the computing device may notify the sensor based application based upon the sensor data.

Registration module may register with central computing device . As already noted it may register to receive notifications associated with a particular application. In some examples the registration module may send registration messages to central computing device to update central computing device on the location of the computing device . Registration module may send registration messages to central computing device through input and output module . Input and output module may implement one or more communication protocols to communicate across network with one or more other computing devices and central computing device . Input and output module may also output a display and other interfaces to the user of the computing device .

Sensor module may be one or more sensors such as a 3D camera which may be forward facing and which may capture data about the real world. Sensor module may provide this data to model module . Model module may analyze the sensor data to identify objects in the real world determine actions that those objects take and based on those actions to determine states of those objects e.g. emotions . In some examples computing device may not have the processing power or battery life to calculate model information from the sensor data or it may be desirable to limit the amount of processing power used to calculate model information. In these examples computing device may send raw sensor data or partial calculations to the central computing device . Model module of the central computing device may then use the raw sensor data or partial calculations to calculate the model information. The completed calculations may then be sent back to computing device . Control module may utilize the data determined about the user of the computing device in a sensor based application coupled to the computing device. For example control module may communicate this data to the sensor based application or may provide a way for the sensor based application to obtain this information e.g. providing an application programming interface API . In other examples control module may provide the sensor based application such as augmented reality applications and may coordinate the actions of the other modules. Control module may send a notification to central computing device based upon the sensor data. For example the control module may send a notification when the model changes or when the model changes in a predetermined fashion e.g. a state of an object changes an action is detected or the like. 

Central computing device may include a variety of logical modules which may implement one or more of the methods of and message sequence charts from . The methods of may be performed by one or more of the modules shown for central computing device of . For example central computing device may include registration module which may process registrations and or updates to a location of computing device . Model module may utilize notifications received from other computing devices through notification module to update or create a model stored by central computing device . For example model module may analyze the information in the notifications to identify objects in the real world determine actions that those objects take and based on those actions to determine states of those objects e.g. emotions . Notification module may determine which computing devices to send notifications to as a result of receiving a notification. As already noted the notifications sent from the notification module may comprise the same or different information as what is received from the computing devices. Notification module may also receive and process notifications from computing devices. Input and output module may implement one or more communication protocols to communicate across network with one or more other computing devices. Control module may coordinate the activities of the registration module model module notification module and input and output module . Control module may also provide or facilitate one or more centrally managed sensor applications. For example an augmented reality game. In these examples the notifications sent from computing devices may update one or more states of these applications. Updates to applications may then be sent in notification messages to computing devices .

Examples as described herein may include or may operate on logic or a number of components modules or mechanisms. Modules are tangible entities e.g. hardware capable of performing specified operations and may be configured or arranged in a certain manner. In an example circuits may be arranged e.g. internally or with respect to external entities such as other circuits in a specified manner as a module. In an example the whole or part of one or more computer systems e.g. a standalone client or server computer system or one or more hardware processors may be configured by firmware or software e.g. instructions an application portion or an application as a module that operates to perform specified operations. In an example the software may reside on a machine readable medium. In an example the software when executed by the underlying hardware of the module causes the hardware to perform the specified operations.

Accordingly the term module is understood to encompass a tangible entity be that an entity that is physically constructed specifically configured e.g. hardwired or temporarily e.g. transitorily configured e.g. programmed to operate in a specified manner or to perform part or all of any operation described herein. Considering examples in which modules are temporarily configured each of the modules need not be instantiated at any one moment in time. For example where the modules comprise a general purpose hardware processor configured using software the general purpose hardware processor may be configured as respective different modules at different times. Software may accordingly configure a hardware processor for example to constitute a particular module at one instance of time and to constitute a different module at a different instance of time.

Machine e.g. computer system may include a hardware processor e.g. a central processing unit CPU a graphics processing unit GPU a hardware processor core or any combination thereof a main memory and a static memory some or all of which may communicate with each other via an interlink e.g. bus . The machine may further include a display unit an alphanumeric input device e.g. a keyboard and a user interface UI navigation device e.g. a mouse . In an example the display unit input device and UI navigation device may be a touch screen display. The machine may additionally include a storage device e.g. drive unit a signal generation device e.g. a speaker a network interface device and one or more sensors such as a global positioning system GPS sensor compass accelerometer or other sensor. The machine may include an output controller such as a serial e.g. universal serial bus USB parallel or other wired or wireless e.g. infrared IR near field communication NFC etc. connection to communicate or control one or more peripheral devices e.g. a printer card reader etc. .

The storage device may include a machine readable medium on which is stored one or more sets of data structures or instructions e.g. software embodying or utilized by any one or more of the techniques or functions described herein. The instructions may also reside completely or at least partially within the main memory within static memory or within the hardware processor during execution thereof by the machine . In an example one or any combination of the hardware processor the main memory the static memory or the storage device may constitute machine readable media.

While the machine readable medium is illustrated as a single medium the term machine readable medium may include a single medium or multiple media e.g. a centralized or distributed database and or associated caches and servers configured to store the one or more instructions .

The term machine readable medium may include any medium that is capable of storing encoding or carrying instructions for execution by the machine and that cause the machine to perform any one or more of the techniques of the present disclosure or that is capable of storing encoding or carrying data structures used by or associated with such instructions. Non limiting machine readable medium examples may include solid state memories and optical and magnetic media. Specific examples of machine readable media may include non volatile memory such as semiconductor memory devices e.g. Electrically Programmable Read Only Memory EPROM Electrically Erasable Programmable Read Only Memory EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks Random Access Memory RAM Solid State Drives SSD and CD ROM and DVD ROM disks. In some examples machine readable media may include non transitory machine readable media. In some examples machine readable media may include machine readable media that is not a transitory propagating signal.

The instructions may further be transmitted or received over a communications network using a transmission medium via the network interface device . The Machine may communicate with one or more other machines utilizing any one of a number of transfer protocols e.g. frame relay internet protocol IP transmission control protocol TCP user datagram protocol UDP hypertext transfer protocol HTTP etc. . Example communication networks may include a local area network LAN a wide area network WAN a packet data network e.g. the Internet mobile telephone networks e.g. cellular networks Plain Old Telephone POTS networks and wireless data networks e.g. Institute of Electrical and Electronics Engineers IEEE 802.11 family of standards known as Wi Fi IEEE 802.16 family of standards known as WiMax IEEE 802.15.4 family of standards a Long Term Evolution LTE family of standards a Universal Mobile Telecommunications System UMTS family of standards peer to peer P2P networks among others. In an example the network interface device may include one or more physical jacks e.g. Ethernet coaxial or phone jacks or one or more antennas to connect to the communications network . In an example the network interface device may include a plurality of antennas to wirelessly communicate using at least one of single input multiple output SIMO multiple input multiple output MIMO or multiple input single output MISO techniques. In some examples the network interface device may wirelessly communicate using Multiple User MIMO techniques.

Example 1 includes subject matter such as a device apparatus or machine comprising one or more computer processors configured to include a notification module to receive over a computer network a first notification from a first computing device the first notification including data determined from a sensor on the first computing device the data determined from the sensor indicating information determined about a user associated with a second computing device a control module to confirm that the second computing device is registered with an augmented reality application and send a second notification to the second computing device in response to confirming that the second computing device is registered wherein the second notification is based upon the first notification.

In Example 2 the subject matter of Example 1 may include wherein the first notification comprises raw sensor data and wherein the second notification comprises the raw sensor data.

In Example 3 the subject matter of any one of Examples 1 to 2 may include wherein the first notification comprises raw sensor data and wherein the control module is further configured to determine model data about the user from the raw sensor data and wherein the second notification includes the model data.

In Example 4 the subject matter of any one of Examples 1 to 3 may include wherein the model data is action information describing an action of the user.

In Example 5 the subject matter of any one of Examples 1 to 4 may include wherein the model data is state information describing a state of the user.

In Example 6 the subject matter of any one of Examples 1 to 5 may include wherein the first notification comprises model data corresponding to the user and wherein the second notification comprises the model data.

In Example 7 the subject matter of any one of Examples 1 to 6 may include wherein the first notification comprises object state information describing a state of the first user and wherein the second notification comprises object state information.

In Example 8 the subject matter of any one of Examples 1 to 7 may include wherein the first notification comprises action information describing an action of the user and wherein the second notification comprises action information.

In Example 9 the subject matter of any one of Examples 1 to 8 may include wherein the augmented reality application is a game.

In Example 10 the subject matter of any one of Examples 1 to 9 may include wherein the augmented reality application is an application which displays a state of the user to the user the state detected by the second computing device.

Example 11 includes subject matter such as a method means for performing acts machine readable medium including instructions that when performed by a machine cause the machine to performs acts or an apparatus to perform comprising at a central computing device using one or more processors receiving over a computer network a first notification from a first computing device the first notification including data determined from a sensor on the first computing device the data determined from the sensor indicating information about a user associated with a second computing device confirming that the second computing device is registered with an augmented reality application and responsive to confirming that the second computing device is registered to the augmented reality application sending a second notification to the second computing device wherein the second notification is based upon the first notification.

In Example 12 the subject matter of Example 11 may include wherein the first notification comprises raw sensor data and wherein the second notification comprises the raw sensor data.

In Example 13 the subject matter of any one of Examples 11 to 12 may include wherein the first notification comprises raw sensor data and wherein the method comprises determining model data about the user from the raw sensor data and wherein the second notification includes the model data.

In Example 14 the subject matter of any one of Examples 11 to 13 may include wherein the model data is action information describing an action of the user.

In Example 15 the subject matter of any one of Examples 11 to 14 may include wherein the model data is state information describing a state of the user.

In Example 16 the subject matter of any one of Examples 11 to 15 may include wherein the first notification comprises model data corresponding to the user and wherein the second notification comprises the model data.

In Example 17 the subject matter of any one of Examples 11 to 16 may include wherein the first notification comprises object state information describing a state of the first user and wherein the second notification comprises object state information.

In Example 18 the subject matter of any one of Examples 11 to 17 may include wherein the first notification comprises action information describing an action of the user and wherein the second notification comprises action information.

In Example 19 the subject matter of any one of Examples 11 to 18 may include wherein the augmented reality application is a game.

In Example 20 the subject matter of any one of Examples 11 to 19 may include wherein the augmented reality application is an application which displays a state of the user to the user the state detected by the second computing device.

Example 21 includes at least one machine readable medium including instructions which when executed by a machine cause the machine to perform operations of any of the Examples 11 20.

Example 23 includes subject matter such as a device apparatus or machine comprising means for receiving over a computer network a first notification from a first computing device the first notification including data determined from a sensor on the first computing device the data determined from the sensor indicating information about a user associated with a second computing device means for confirming that the second computing device is registered with an augmented reality application and means for sending a second notification to the second computing device responsive to confirming that the second computing device is registered to the augmented reality application wherein the second notification is based upon the first notification.

In Example 24 the subject matter of Example 23 may include wherein the first notification comprises raw sensor data and wherein the second notification comprises the raw sensor data.

In Example 25 the subject matter of any one of Examples 23 to 24 may include wherein the first notification comprises raw sensor data and wherein the central computing device comprises means for determining model data about the user from the raw sensor data and wherein the second notification includes the model data.

In Example 26 the subject matter of any one of Examples 23 to 25 may include wherein the model data is action information describing an action of the user.

In Example 27 the subject matter of any one of Examples 23 to 26 may include wherein the model data is state information describing a state of the user.

In Example 28 the subject matter of any one of Examples 23 to 27 may include wherein the first notification comprises model data corresponding to the user and wherein the second notification comprises the model data.

In Example 29 the subject matter of any one of Examples 23 to 28 may include wherein the first notification comprises object state information describing a state of the first user and wherein the second notification comprises object state information.

In Example 30 the subject matter of any one of Examples 23 to 29 may include wherein the first notification comprises action information describing an action of the user and wherein the second notification comprises action information.

In Example 31 the subject matter of any one of Examples 23 to 30 may include wherein the augmented reality application is a game.

In Example 32 the subject matter of any one of Examples 23 to 31 may include wherein the augmented reality application is an application which comprises means for displays a state of the user to the user the state detected by the second computing device.

Example 33 includes subject matter such as a device apparatus or machine comprising one or more computer processors configured to include a registration module to send a registration message to a central computing device the registration message registering the first computing device with the central computing device a notification module to receive a notification from the central computing device wherein the notification comprises data determined about a user of the computing device from a forward facing sensor on a second computing device and a control module to utilize the data determined about the user of the computing device in a sensor based application coupled to the computing device.

In Example 34 the subject matter of Example 33 may include wherein the notification comprises raw sensor data.

In Example 35 the subject matter of any one of Examples 33 to 34 may include wherein the notification comprises model data.

In Example 36 the subject matter of any one of Examples 33 to 35 may include wherein the model data is state information describing a state of the first user.

In Example 37 the subject matter of any one of Examples 33 to 36 may include wherein the model data is action information describing an action of the user.

In Example 38 the subject matter of any one of Examples 33 to 37 may include wherein the sensor based application is a game and wherein the first and second notifications are inputs that act on an object from the game.

Example 39 includes subject matter such as a method means for performing acts machine readable medium including instructions that when performed by a machine cause the machine to performs acts or an apparatus to perform comprising at a first computing device associated with a user using one or more processors sending a registration message to a central computing device the registration message registering the first computing device with the central computing device receiving a notification from the central computing device wherein the notification comprises data determined about the user from a forward facing sensor on a second computing device and utilizing the data determined about the user of the computing device in a sensor based application coupled to the computing device.

In Example 40 the subject matter of Example 39 may include wherein the notification comprises raw sensor data.

In Example 41 the subject matter of any one of Examples 39 to 40 may include wherein the notification comprises model data.

In Example 42 the subject matter of any one of Examples 39 to 41 may include wherein the model data is state information describing a state of the first user.

In Example 43 the subject matter of any one of Examples 39 to 42 may include wherein the model data is action information describing an action of the user.

In Example 44 the subject matter of any one of Examples 39 to 43 may include wherein the sensor based application is a game and wherein the first and second notifications are inputs that act on an object from the game.

Example 45 includes at least one machine readable medium including instructions which when executed by a machine cause the machine to perform operations of any of the Examples 39 44.

Example 47 includes subject matter such as a device apparatus or machine comprising means for sending a registration message to a central computing device the registration message registering the first computing device with the central computing device means for receiving a notification from the central computing device wherein the notification comprises data determined about a user associated with the computing device from a forward facing sensor on a second computing device and means for utilizing the data determined about the user of the computing device in a sensor based application coupled to the computing device.

In Example 48 the subject matter of Example 47 may include wherein the notification comprises raw sensor data.

In Example 49 the subject matter of any one of Examples 47 to 48 may include wherein the notification comprises model data.

In Example 50 the subject matter of any one of Examples 47 to 49 may include wherein the model data is state information describing a state of the first user.

In Example 51 the subject matter of any one of Examples 47 to 50 may include wherein the model data is action information describing an action of the user.

In Example 52 the subject matter of any one of Examples 47 to 51 may include wherein the sensor based application is a game and wherein the first and second notifications are inputs that act on an object from the game.

Example 53 includes subject matter such as a device apparatus or machine comprising one or more computer processors configured to include a registration module to send a registration message to a central computing device the registration message registering the first computing device with the central computing device a notification module to send a notification to the central computing device wherein the notification comprises data determined about a user of a second computing device from a forward facing sensor on the computing device and a control module to utilize the data determined about the user of the second computing device in a sensor based application coupled to the computing device.

In Example 54 the subject matter of Example 53 may include wherein the notification comprises raw sensor data.

In Example 55 the subject matter of any one of Examples 53 to 54 may include wherein the notification comprises model data.

In Example 56 the subject matter of any one of Examples 53 to 55 may include wherein the model data is state information describing a state of the first user.

In Example 57 the subject matter of any one of Examples 53 to 56 may include wherein the model data is action information describing an action of the user.

In Example 58 the subject matter of any one of Examples 53 to 57 may include wherein the sensor based application is a game and wherein the first and second notifications are inputs that act on an object from the game.

Example 59 includes subject matter such as a method means for performing acts machine readable medium including instructions that when performed by a machine cause the machine to performs acts or an apparatus to perform comprising at a first computing device associated with a user using one or more processors sending a registration message to a central computing device the registration message registering the first computing device with the central computing device sending a notification to the central computing device wherein the notification comprises data determined about a user of a second computing device from a forward facing sensor on the computing device and utilizing the data determined about the user of the second computing device in a sensor based application coupled to the computing device.

In Example 60 the subject matter of Example 59 may include wherein the notification comprises raw sensor data.

In Example 61 the subject matter of any one of Examples 59 to 60 may include wherein the notification comprises model data.

In Example 62 the subject matter of any one of Examples 59 to 61 may include wherein the model data is state information describing a state of the first user.

In Example 63 the subject matter of any one of Examples 59 to 62 may include wherein the model data is action information describing an action of the user.

In Example 64 the subject matter of any one of Examples 59 to 63 may include wherein the sensor based application is a game and wherein the first and second notifications are inputs that act on an object from the game.

Example 65 includes at least one machine readable medium including instructions which when executed by a machine cause the machine to perform operations of any of the Examples 59 64.

Example 59 includes subject matter such as a device apparatus or machine comprising means for sending a registration message to a central computing device the registration message registering the first computing device with the central computing device means for sending a notification to the central computing device wherein the notification comprises data determined about a user of a second computing device from a forward facing sensor on the computing device and means for utilizing the data determined about the user of the second computing device in a sensor based application coupled to the computing device.

In Example 60 the subject matter of Example 59 may include wherein the notification comprises raw sensor data.

In Example 61 the subject matter of any one of Examples 59 to 60 may include wherein the notification comprises model data.

In Example 62 the subject matter of any one of Examples 59 to 61 may include wherein the model data is state information describing a state of the first user.

In Example 63 the subject matter of any one of Examples 59 to 62 may include wherein the model data is action information describing an action of the user.

In Example 64 the subject matter of any one of Examples 59 to 63 may include wherein the sensor based application is a game and wherein the first and second notifications are inputs that act on an object from the game.

