---

title: Scalable robust live streaming system
abstract: A system and method for a live streaming platform that can redundantly process input streams in parallel ingestion pipelines is disclosed herein. Ingested input streams in the parallel pipelines can be segmented using a stable segmentation function that creates identical segments in each of the streams in the pipelines. If errors occur, or there are disruptions in one or more of the input streams or pipelines, the live streaming platform can switch between the input streams on a per segment basis to provide reliable streaming feeds to a content distribution network. A master stream can be constructed from each of the master segments per a time period based on a reliability of each of the input streams and segments. Practicing pipeline affinity by selecting subsequent master segments from the same pipeline can minimize glitches.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09215260&OS=09215260&RS=09215260
owner: Google Inc.
number: 09215260
owner_city: Mountain View
owner_country: US
publication_date: 20140818
---
This application is a continuation of U.S. patent application Ser. No. 13 439 678 filed Apr. 4 2012 and entitled SCALABLE ROBUST LIVE STREAMING SYSTEM the entirety of which is incorporated herein by reference.

This disclosure relates generally to robust scalable live streaming and specifically to dynamically switching between coherent redundant live streams for increased reliability.

Live streaming current events over the Internet increases the demand for a reliable streaming infrastructure. Live streaming feeds are commonly used in such circumstances as major political speeches and events sporting events and other cultural happenings in which a large viewing audience is relying on the live streaming feed to be functioning properly. However due to the distributed nature of any processing and delivery system of this scale component failure is unavoidable and can interrupt or otherwise affect the quality of the output stream.

Mission critical live streaming on the web is done today by building redundancy by having separate hardware and or software encoders pushing roughly equivalent streams to be redundantly encoded. This encoding takes place in completely separate encoding pathways that produce separate primary and secondary streams. Failovers which are automatic switches to redundant streams attempt to minimize disruptions but since they use discrete and or diverse components glitch free failovers are generally unattainable.

The following presents a simplified summary of various aspects of this disclosure in order to provide a basic understanding of such aspects. This summary is not an extensive overview of all contemplated aspects and is intended to neither identify key or critical elements nor delineate the scope of such aspects. Its purpose is to present some concepts of this disclosure in a simplified form as a prelude to the more detailed description that is presented later.

Systems and methods disclosed herein relate to switching between redundant live streams that are processed in parallel ingestion pipelines. Disclosed herein is a system including a segmentation component that identifies segment boundaries in an ingested input stream and segments the input stream based on the segment boundaries. A buffer component buffers segments of a plurality of input streams wherein the buffered segments are indexed and stored in a memory. A master selection component selects a master buffered segment per a time period from among the buffered segments for delivery to a content distribution network.

The master selection component can select the buffered segment from among the buffered segments of the plurality of the input streams based on a reliability signal of the buffered segment. The master selection component can also switch to a different input stream for a subsequent master buffered segment in response to a reliability signal of the input stream falling below a threshold value. A transcoding component is also disclosed that transcodes the input stream into a plurality of output streams with different bitrates and formats.

Also disclosed herein is a method including identifying segment boundaries in an ingested input stream and segmenting the input stream based on the segment boundaries. The method can include buffering segments of a plurality of input streams wherein the buffering includes indexing and storing buffered segments in a memory. The method can also include selecting a master buffered segment per a time period from among the buffered segments for delivery to a content distribution network. The method can also include selecting a subsequent master buffered segment from a different input stream in response to receiving an indication of a timeout in the input stream.

Further disclosed herein is a non transitory computer readable medium comprising computer executable instructions that in response to execution cause a computing system to perform operations that include identifying segment boundaries in an ingested input stream and segmenting the input stream based on the segment boundaries. The operations can include buffering segments of a plurality of input streams wherein the buffering includes indexing and storing buffered segments in a memory. The operations can further include selecting a master buffered segment per a time period from among the buffered segments for delivery to a content distribution network.

The following description and the annexed drawings set forth in detail certain illustrative aspects of this disclosure. These aspects are indicative however of but a few of the various ways in which the principles of this disclosure may be employed. This disclosure is intended to include all such aspects and their equivalents. Other advantages and distinctive features of this disclosure will become apparent from the following detailed description of this disclosure when considered in conjunction with the drawings.

Various aspects of this disclosure are now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of one or more aspects. It should be understood however that certain aspects of this disclosure may be practiced without these specific details or with other methods components materials etc. In other instances well known structures and devices are shown in block diagram form to facilitate describing one or more aspects.

It is to be appreciated that in accordance with one or more implementations described in this disclosure live streaming input streams can be coherently processed in parallel ingestion pipelines. If errors occur during the ingestion and or processing of the input stream the live streaming and ingestion infrastructure can switch between the parallel input streams to provide reliable live streaming feeds to the content distribution network.

In an embodiment the live streaming platform can operate entirely within the cloud environment and thus the system can be provided invisibly to the end user. Providing the live streaming platform in the cloud environment means that the ingestion infrastructures can be servers that receive the incoming multicast live streams process the live streams and deliver a robust and stable stream to various players also based on servers that deliver the live stream to the end user. The end user can access the live stream via a web browser or lightweight application. Coherent streams can be created from multiple ingestion paths and upon a failure of any part of one of the streams a whole single stream can be reconstructed from the coherent streams.

Exact replicas of input streams can be processed in parallel ingestion pipelines and the input streams can be transcoded into desired output streams at different bitrates while preserving time information of the streams timestamps . The streams can be coherently segmented using a stable segmentation function that identifies segment boundaries based on minimizing the modulo of the timestamp with the target segment duration. This can be accomplished for example by initializing the segmentation process at a common key frame across all the sub streams resulting in identically segmented redundant input streams.

For each time period one segment can be selected from the redundant streams to be the master segment that is used to construct the single stream. This distributed master stream selection can be based on the availability or reliability of a particular segment for all bit rates. The algorithm used to select which of the segments is made available for the next step can minimize stream discontinuity by maintaining pipeline affinity whenever possible by selecting subsequent segments from the same ingestion pipeline.

The master stream selection operates between a reliable stream controller and the per pipeline chunk manager which communicate with the master periodically upon receipt of a new set of segments. One live chunk manager is selected as master for a given stream and the selected live chunk manager outputs the current segments to the next processing step indexing and storage . Non perfect copies of the stream can also be handled at input by exploiting time continuity. In this case some stream glitches are possible during a failover but the same stream affinity logic minimizes the occurrence of these artifacts.

Referring now to the drawings illustrates a block diagram of an example live streaming system in accordance with various aspects and implementations is shown. Live streaming infrastructure can be provided to ingest and or process live media feeds and distribute them to media players . Media players can interpret the video signals and display the output using the native media stack of each of the target platforms. Players can also include integrated monetization modules.

The live streaming infrastructure can include ingestion infrastructure origin infrastructure content distribution network and a stream event control application programming interface API . Ingestion infrastructure can receive incoming media feeds and redundantly process the live feeds in separate pipelines. Origin infrastructure can save the live media streams to memory and prepare the live streams for delivery to the content distribution network which delivers the live media stream to the media players . The stream control API can give broadcasting partners the ability to start and or stop an event configure monetization settings and in general manage the set of broadcast events and their lifecycle.

Turning now to a block diagram illustrating an example non limiting embodiment of a redundant ingestion system with parallel ingestion pipelines in accordance with various aspects and implementations is shown. In the ingestion infrastructure redundant live media streams are received at ingestion entry points and . Once received the redundant live media streams are ingested and processed by the parallel pipelines and and eventually saved to a memory in the origin infrastructure by live chunk managers e.g. before being distributed via a content distribution network .

The ingestion entry points and can receive multicast signals acquired through direct peering with the broadcast originator or via real time messaging protocol RMTP signals acquired through a worldwide network of ingestion servers. Ingestion entry points and can also receive input streams from hypertext transfer protocol HTTP based ingestion via resumable POST request and as a pre segmented stream independent POST with a session indicator . The Ingestion entry points and can also receive the live media streams from other sources commonly used for delivering live media feeds. Once the redundant live media streams are received parallel ingestion pipelines and can ingest and process the redundant live media streams in parallel. It is to be appreciated that while depicts pipelines and processing live streams from entry point and pipelines and are processing live streams from entry point there can be any combination of pipelines and entry points. In some embodiments there can be fewer or greater than two parallel pipelines per entry point and in other embodiments there can be more or less than two entry points.

Ingestion pipelines and can process and prepare the live streams for delivery to the content distribution network . Processing modules such as segmentation components buffering components and transcoding segments can be included in the ingestion pipelines and . The ingestion pipelines can also include packager and or encryption components to package the stream into a container format and or encrypt it. The pipelines can also include a delay component that can insert a delay into the live media stream.

The segmentation components in pipelines and can identify segment boundaries in the ingested input stream and segment the input stream based on the segment boundaries. The buffer components can buffer the segments of the parallel input streams in a memory and a master selection component in ingestion infrastructure can select a master buffered segment per a segment time period to be saved and delivered to the content distribution network . A live chunk manager that is associated with the pipeline that is selected for each buffered segment outputs the segment to the next step in the origin infrastructure for indexing and storage before delivery to the content distribution network . This arrangement of parallel ingestion pipelines scales robustness of the system at all layers from ingestion of the source material to encoding storage conversion into on demand assets publishing and streaming.

In some embodiments to maintain time continuity it is preferable to use the output from one of the parallel pipelines to be indexed and stored in memory for delivery via the content distribution network if there are no errors or timeouts in the stream. This pipeline affinity can minimize the number of potential glitches during failover switches to another pipeline. If there are errors in the stream though and one of the redundant streams from another parallel pipeline is selected having the streams segmented in parallel can minimize live stream disruptions.

Thus in referring to for example the input stream from ingestion pipeline can be the master stream that is written by live chunk manager to the memory. . Pipelines and have redundant streams that are parallel to the input stream of pipeline but are not selected unless the input stream of pipeline is disrupted. Upon disruption the master selection component in the ingestion infrastructure can select one of pipelines or and one of their associated live chunk managers to index and store their input streams as the master stream.

Turning now to a block diagram illustrating an example non limiting embodiment of a system that can segment redundant streams and select a master segment in accordance with various aspects and implementations is illustrated. System can include part of ingestion infrastructure with segmentation component and master selection component . Parallel ingestion pipelines with live media streams are shown at different stages of processing at and . It is to be appreciated that while shows one segmentation component and one master selection component in the ingestion infrastructure this is done for simplicity and each of the parallel ingestion pipelines can include segmentation components and master selection components.

Segmentation component can identify segment boundaries in an ingested input stream and then segment the input stream based on the segment boundaries. The segmentation component can segment each of the parallel ingested input streams in each of the pipelines as well or alternatively separate segmentation components can segment the separate input streams.

Segment component receives the un segmented input stream and identifies segments in the input stream. In some embodiments segment boundaries identified can be based on the number of frames i.e. start a new segment every n frames . Alternatively in other embodiments segment boundaries can be based on the types of frames i.e. start a new segment every intra frame or inter frame . Other segmentation functions can identify segment boundaries based on minimizing the modulo of the timestamp with the target segment duration.

In an aspect of the disclosure to maintain parallelism of the input streams the algorithm or function that segmentation component uses to identify segment boundaries should be stable over each of the input streams so that the segments boundaries identified and segmented are the same for each of the input streams. To accomplish this in some embodiments the segmentation component and or each of the individual segmentation components can start looking for segment boundaries at a common key frame. In other embodiments segmentation component can start segmenting at the beginning of a stream.

In another embodiment the segmentation component can use an algorithm that is robust to stream discontinuities. Therefore in the event of a failure or discontinuity of an input stream the parallelism of the segmenting of the input streams will not be interrupted.

Once segmentation component identifies the segments the input streams can be segmented and the segmented input streams are the result of the segmenting. There can be one segment in each of the input streams per time period. The time period can be based on the length of the segment or the length of the segment can be based on the length of the time period. Each of the segments in segmented input streams can be interchangeable such that a coherent master stream can be selected from one of the segments from one of the input streams per time period.

Master selection component selects a master segment per a time period from among the segments for delivery to a content distribution network. In some embodiments to maintain pipeline affinity and minimize glitches master selection component will select consecutive segments from the same pipeline e.g. to be master segments. Ingestion pipelines carry redundant streams and master stream is selected to be delivered by a live chunk manager e.g. to be indexed and stored in a memory e.g. .

In an aspect of the present disclosure master selection component will maintain pipeline affinity and continue to select segments from the same pipeline until a reliability signal of the master stream falls below a threshold value and the master selection component switches to a master segment from a different input stream. A received timeout can also trigger the master selection component to switch to a different input stream. In other embodiments master selection component can select a master segment from among all the segments per a time period based on a reliability signal of the buffered segment. In some cases the most reliable segment per a time period can be selected to be the master segment.

In a block diagram illustrating an example non limiting embodiment of a system that can select segments from various mirrored streams in accordance with various aspects and implementations is shown. In some embodiments maintaining pipeline and or stream affinity may not be possible or desirable. Master selection component can receive the segmented parallel ingestion pipelines from which to select the master segments. The parallel pipelines shown in have master segments selected by the master selection component where the master segments are distributed among the pipelines. Master selection component can select one segment per a time period based on a reliability signal of the segments or the reliability of the input stream at that time period. Thus master segments from a number of different streams can be used to construct the master stream that is eventually distributed by the content distribution network e.g. .

Turning now to a block diagram illustrating an example non limiting embodiment of a system that can buffer segments of parallel streams in a memory in accordance with various aspects and implementations is shown. A buffer component can be provided in ingestion infrastructure to buffer segments of a plurality of input streams from parallel ingestion pipelines into a memory . The buffered segments can be indexed and stored in the memory prior to or after selection by the master selection component e.g. .

It is to be appreciated that while depicts there being one buffer component and one memory storage for all of the pipelines there can be multiple buffer components and memory storages. For example there can be one buffer component per ingestion pipeline buffering the segments of each input stream into separate memory storages.

Turning now to a block diagram illustrating an example non limiting embodiment of a system that can transcode an input stream into multiple output streams in accordance with various aspects and implementations is shown. Transcoding component can be provided in ingestion infrastructure to transcode and or encode an input stream into a variety of output streams and . The input stream can be received in raw form e.g. MPEG 2 Transport Stream M2TS and transcoding component can encode the raw stream into a variety of output streams. The output streams can be in different container formats and or bitrates. The transcoding component can preserve time stamp information in each of the output streams.

In some embodiments transcoding component can split the input stream into multiple output streams in each of the ingestion pipelines. Each parallel ingestion pipeline would therefore have a variety of streams with different bitrates and or container formats. These streams are segmented and when the master selection component e.g. selects a master segment the master segment would include each of the various streams outputted by the transcoding component .

In an aspect of the present disclosure a timeout or a disruption in any of the transcoded streams in the segment can cause the master selection component to select a master segment from another redundant ingestion pipeline.

Moreover various acts have been described in detail above in connection with respective system diagrams. It is to be appreciated that the detailed description of such acts in can be and are intended to be implementable as methods and or in accordance with the following depicted method.

At segment boundaries in an ingested input stream are identified and the input stream is segmented e.g. by segmentation component based on the segment boundaries. Segment boundaries can be identified based on the number of frames i.e. start a new segment every n frames . Alternatively in other embodiments segment boundaries can be based on the types of frames i.e. start a new segment every intra frame or inter frame . Other segmentation functions can identify segment boundaries based on minimizing the modulo of the timestamp with the target segment duration.

Segment boundaries of a plurality of input streams can identified. To ensure that the input streams are processed in parallel the algorithm or function that is used to identify segment boundaries should be stable over each of the input streams so that the segments boundaries identified and segmented are the same for each of the input streams. To accomplish this in some aspects of the disclosure the segmenting and identifying processes can initiate at a common key frame across all of the input streams. Alternatively the identifying can be initiated from the beginning of the stream.

Once the segment boundaries are identified the streams can be segmented based on the boundaries. There can be one segment in each of the input streams per time period. The time period can be based on the length of the segment or the length of the segment can be based on the length of the time period. Each of the segments per a time period can be interchangeable such that a reconstructed master stream can be composed of any of the segments in the input streams per a time period.

At the segments of the plurality of input streams are buffered e.g. by buffer component wherein the buffering includes indexing and storing buffered segments in a memory. At one master buffered segment per a time period is selected e.g. by master selection components and from among the buffered segments for delivery to a content distribution network.

In some embodiments to maintain pipeline affinity and minimize glitches consecutive segments from the same pipeline can be selected to be master segments until a reliability of the master stream falls below a threshold or predetermined value and the master segment can be selected from a different input stream. A timeout in a segment or an input stream can also trigger a switch to a different input stream. In other embodiments a master segment can be selected from among all the segments per a time period based on a reliability signal of the buffered segment. In some cases the most reliable segment per a time period can be selected to be the master segment.

At an ingested input stream can be redundantly processed in separate ingestion pipelines. The ingested input stream can be mirrored between the separate ingestion pipelines. The separate ingested input streams can also be processed in parallel pipelines such that several levels of redundancy ensure that disruptions to one or more of the pipelines can be mitigated.

At segmentation of a plurality of redundant streams can be initialized at a common key frame. This ensures that the input streams are processed in parallel such that the identified segment boundaries are the same for each of the input streams. At a segmentation algorithm is employed to identify segment boundaries based on minimizing a modulo of a time stamp with a target segment duration.

At a master buffered segment is selected based on a reliability signal of the selected buffered segment. To maintain pipeline affinity subsequent master buffered segments can be selected from the same pipeline and or input stream until a reliability of the input stream or master buffered segment falls below a predetermined value. Alternatively the buffered segment per a time period with the highest reliability can be selected as a master buffered segment.

With reference to a suitable environment for implementing various aspects of this disclosure includes a computing device . It is to be appreciated that the computer can be used in connection with implementing one or more of the systems or component shown and described in connection with . The computing device includes a processing unit s a system memory and a system bus . The system bus couples system components including but not limited to the system memory to the processing unit . The processing unit s can be any of various available processors. Dual microprocessors and other multiprocessor architectures also can be employed as the processing unit s .

The system bus can be any of several types of bus structure s including the memory bus or memory controller a peripheral bus or external bus and or a local bus using any variety of available bus architectures including but not limited to Industrial Standard Architecture ISA Micro Channel Architecture MSA Extended ISA EISA Intelligent Drive Electronics IDE VESA Local Bus VLB Peripheral Component Interconnect PCI Card Bus Universal Serial Bus USB Advanced Graphics Port AGP Personal Computer Memory Card International Association bus PCMCIA Firewire IEEE 994 and Small Computer Systems Interface SCSI .

The system memory includes volatile memory and nonvolatile memory . The basic input output system BIOS containing the basic routines to transfer information between elements within the computing device such as during start up is stored in nonvolatile memory . By way of illustration and not limitation nonvolatile memory e.g. can include read only memory ROM programmable ROM PROM electrically programmable ROM EPROM electrically erasable programmable ROM EEPROM flash memory or nonvolatile random access memory RAM e.g. ferroelectric RAM FeRAM . Volatile memory e.g. includes random access memory RAM which acts as external cache memory. By way of illustration and not limitation RAM is available in many forms such as static RAM SRAM dynamic RAM DRAM synchronous DRAM SDRAM double data rate SDRAM DDR SDRAM enhanced SDRAM ESDRAM Synchlink DRAM SLDRAM direct Rambus RAM DRRAM direct Rambus dynamic RAM DRDRAM and Rambus dynamic RAM. Additionally the disclosed memory components of systems or methods herein are intended to include without being limited to including these and any other suitable types of memory.

Computing device can also include removable non removable volatile non volatile computer storage media. illustrates for example a disk storage . Disk storage includes but is not limited to devices like a magnetic disk drive flash drive floppy disk drive tape drive Jaz drive Zip drive LS 100 drive flash memory card or memory stick. The disk storage also can include storage media separately or in combination with other storage media including but not limited to an optical disk drive such as a compact disk ROM device CD ROM CD recordable drive CD R Drive CD rewritable drive CD RW Drive or a digital versatile disk ROM drive DVD ROM . To facilitate connection of the disk storage devices to the system bus a removable or non removable interface is typically used such as interface .

A user enters commands or information into the computing device through input device s . Input devices include but are not limited to a pointing device such as a mouse trackball stylus touch pad keyboard microphone joystick game pad satellite dish scanner TV tuner card digital camera digital video camera web camera and the like. These and other input devices connect to the processing unit through the system bus via interface port s . Interface port s include for example a serial port a parallel port a game port and a universal serial bus USB . Output device s use some of the same type of ports as input device s . Thus for example a USB port may be used to provide input to computing device and to output information from computing device to an output device . Output adapter is provided to illustrate that there are some output devices like monitors speakers and printers among other output devices which require special adapters. The output adapters include by way of illustration and not limitation video and sound cards that provide a means of connection between the output device and the system bus . It should be noted that other devices and or systems of devices provide both input and output capabilities such as remote computer s .

Computing device can operate in a networked environment using logical connections to one or more remote computers such as remote computer s . The remote computer s can be a personal computer a server a router a network PC a workstation a microprocessor based appliance a peer device or other common network node and the like and typically includes many or all of the elements described relative to computing device . For purposes of brevity only a memory storage device is illustrated with remote computer s . Remote computer s is logically connected to computing device through a network interface and then physically connected via communication connection . Network interface encompasses wire and or wireless communication networks such as local area networks LAN wide area networks WAN cellular networks etc. LAN technologies include Fiber Distributed Data Interface FDDI Copper Distributed Data Interface CDDI Ethernet Token Ring and the like. WAN technologies include but are not limited to point to point links circuit switching networks like Integrated Services Digital Networks ISDN and variations thereon packet switching networks and Digital Subscriber Lines DSL .

Communication connection s refers to the hardware software employed to connect the network interface to the bus . While communication connection is shown for illustrative clarity inside computing device it can also be external to computing device . The hardware software necessary for connection to the network interface includes for exemplary purposes only internal and external technologies such as modems including regular telephone grade modems cable modems and DSL modems ISDN adapters Ethernet cards and wireless networking cards.

In accordance with various aspects and implementations the computing device can be used segment redundant input streams and select a master segment from among the input streams per a time period. Computing device can also transcoded an input stream into output streams with varying bitrates and or container formats. As more fully disclosed herein in some implementations the computing device can include one or more processors e.g. that can be used to process data including processing data to perform various tasks e.g. identifying segment boundaries segmenting the input streams based on the segment boundaries buffering segments and indexing and storing the buffered segments in memory and selecting a master buffered segment per a time period from among the buffered segments etc. . The computing device can include a program component that can be associated with e.g. communicatively connected to the one or more processors. The program component can contain for example a segmentation component a buffer component a master selection component and a transcoding component and or other components which can respectively function as more fully disclosed herein to facilitate embodiments of the disclosure described herein.

The system includes a communication framework that can be employed to facilitate communications between the client s and the server s . The client s are operatively connected to one or more client data store s that can be employed to store information local to the client s . Similarly the server s are operatively connected to one or more server data store s that can be employed to store information local to the servers .

It is to be appreciated and understood that components as described with regard to a particular system or method can include the same or similar functionality as respective components e.g. respectively named components or similarly named components as described with regard to other systems or methods disclosed herein.

It is to be noted that aspects or features of this disclosure can be used with substantially any wireless telecommunication or radio technology e.g. Wi Fi Bluetooth Worldwide Interoperability for Microwave Access WiMAX Enhanced General Packet Radio Service Enhanced GPRS Third Generation Partnership Project 3GPP Long Term Evolution LTE Third Generation Partnership Project 2 3GPP2 Ultra Mobile Broadband UMB 3GPP Universal Mobile Telecommunication System UMTS High Speed Packet Access HSPA High Speed Downlink Packet Access HSDPA High Speed Uplink Packet Access HSUPA GSM Global System for Mobile Communications EDGE Enhanced Data Rates for GSM Evolution Radio Access Network GERAN UMTS Terrestrial Radio Access Network UTRAN LTE Advanced LTE A etc. Additionally some or all of the aspects described herein can be used with legacy telecommunication technologies e.g. GSM. In addition mobile as well non mobile networks e.g. the Internet data service network such as internet protocol television IPTV etc. can be used with aspects or features described herein.

While the subject matter has been described above in the general context of computer executable instructions of a computer program that runs on a computer and or computers those skilled in the art will recognize that this disclosure also can or may be implemented in combination with other program modules. Generally program modules include routines programs components data structures etc. that perform particular tasks and or implement particular abstract data types. Moreover those skilled in the art will appreciate that the inventive methods may be practiced with other computer system configurations including single processor or multiprocessor computer systems mini computing devices mainframe computers as well as personal computers hand held computing devices e.g. PDA phone microprocessor based or programmable consumer or industrial electronics and the like. The illustrated aspects may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. However some if not all aspects of this disclosure can be practiced on stand alone computers. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

As used in this application the terms component system platform interface and the like can refer to and or can include a computer related entity or an entity related to an operational machine with one or more specific functionalities. The entities disclosed herein can be either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a server and the server can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

In another example respective components can execute from various computer readable media having various data structures stored thereon. The components may communicate via local and or remote processes such as in accordance with a signal having one or more data packets e.g. data from one component interacting with another component in a local system distributed system and or across a network such as the Internet with other systems via the signal . As another example a component can be an apparatus with specific functionality provided by mechanical parts operated by electric or electronic circuitry which is operated by a software or firmware application executed by a processor. In such a case the processor can be internal or external to the apparatus and can execute at least a part of the software or firmware application. As yet another example a component can be an apparatus that provides specific functionality through electronic components without mechanical parts wherein the electronic components can include a processor or other means to execute software or firmware that confers at least in part the functionality of the electronic components. In an aspect a component can emulate an electronic component via a virtual machine e.g. within a cloud computing system. In the cloud computing system computing can be delivered as a service rather than a product. Thus resources software and information can be shared between computers and servers over a network. End users access cloud based applications through a web browser or other light weight desktop or mobile app while the business software and data are stored on servers at remote locations.

In addition the term or is intended to mean an inclusive or rather than an exclusive or. That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. Moreover articles a and an as used in the subject specification and annexed drawings should generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

As used herein the terms example and or exemplary are utilized to mean serving as an example instance or illustration. For the avoidance of doubt the subject matter disclosed herein is not limited by such examples. In addition any aspect or design described herein as an example and or exemplary is not necessarily to be construed as preferred or advantageous over other aspects or designs nor is it meant to preclude equivalent exemplary structures and techniques known to those of ordinary skill in the art.

Reference throughout this specification to one implementation or an implementation or one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the implementation or embodiment is included in at least one implementation or one embodiment. Thus the appearances of the phrase in one implementation or in an implementation or in one embodiment or in an embodiment in various places throughout this specification can but are not necessarily referring to the same implementation or embodiment depending on the circumstances. Furthermore the particular features structures or characteristics may be combined in any suitable manner in one or more implementations or embodiments.

Various aspects or features described herein can be implemented as a method apparatus system or article of manufacture using standard programming or engineering techniques. In addition various aspects or features disclosed in this disclosure can be realized through program modules that implement at least one or more of the methods disclosed herein the program modules being stored in a memory and executed by at least a processor. Other combinations of hardware and software or hardware and firmware can enable or implement aspects described herein including a disclosed method s . The term article of manufacture as used herein can encompass a computer program accessible from any computer readable device carrier or storage media. For example computer readable storage media can include but are not limited to magnetic storage devices e.g. hard disk floppy disk magnetic strips . . . optical discs e.g. compact disc CD digital versatile disc DVD blu ray disc BD . . . smart cards and flash memory devices e.g. card stick key drive . . . or the like.

As it is employed in the subject specification the term processor can refer to substantially any computing processing unit or device comprising but not limited to single core processors single processors with software multithread execution capability multi core processors multi core processors with software multithread execution capability multi core processors with hardware multithread technology parallel platforms and parallel platforms with distributed shared memory. Additionally a processor can refer to an integrated circuit an application specific integrated circuit ASIC a digital signal processor DSP a field programmable gate array FPGA a programmable logic controller PLC a complex programmable logic device CPLD a discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. Further processors can exploit nano scale architectures such as but not limited to molecular and quantum dot based transistors switches and gates in order to optimize space usage or enhance performance of user equipment. A processor may also be implemented as a combination of computing processing units.

In this disclosure terms such as store storage data store data storage database and substantially any other information storage component relevant to operation and functionality of a component are utilized to refer to memory components entities embodied in a memory or components comprising a memory. It is to be appreciated that memory and or memory components described herein can be either volatile memory or nonvolatile memory or can include both volatile and nonvolatile memory.

What has been described above includes examples of systems and methods of this disclosure. It is of course not possible to describe every conceivable combination of components or methods for purposes of describing this disclosure but one of ordinary skill in the art may recognize that many further combinations and permutations of this disclosure are possible. Furthermore to the extent that the terms includes has possesses and the like are used in the detailed description claims appendices and drawings such terms are intended to be inclusive in a manner similar to the term comprising as comprising is interpreted when employed as a transitional word in a claim.

