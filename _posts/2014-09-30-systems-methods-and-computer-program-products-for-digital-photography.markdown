---

title: Systems, methods, and computer program products for digital photography
abstract: A system, method, and computer program product are provided for digital photography. In use, a method and apparatus are provided for receiving, at least part of, a partially populated dynamic image object (DIO). Next, a first image is identified in the DIO. Then, a second image is identified in the DIO. Further, a synthetic image is generated based on the first image and the second image. Lastly, the synthetic image is stored in an object for use with a viewing parameter. Additional systems, methods, and computer program products are also presented.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09460125&OS=09460125&RS=09460125
owner: Duelight LLC
number: 09460125
owner_city: Sunnyvale
owner_country: US
publication_date: 20140930
---
This application claims priority to U.S. provisional patent application No. 61 960 945 filed Sep. 30 2013 and entitled SYSTEMS METHODS AND COMPUTER PROGRAM PRODUCTS FOR DIGITAL PHOTOGRAPHY the entire contents of which are incorporated herein by reference. Additionally this application is related to the following U.S. patent application the entire disclosures being incorporated by reference herein application Ser. No. 14 503 224 filed Sep. 30 2014 entitled SYSTEMS METHODS AND COMPUTER PROGRAM PRODUCTS FOR DIGITAL PHOTOGRAPHY. 

The present invention relates to photographic systems and more specifically to systems and methods for digital photography.

Traditional digital photography systems allow users to capture edit and share digital photographs. A sender may edit a digital photograph according to their personal preferences and share the edited digital photograph with a recipient such as through an email or social network service.

A system method and computer program product are provided for digital photography. In use a method and apparatus are provided for receiving at least part of a partially populated dynamic image object DIO . Next a first image is identified in the DIO. Then a second image is identified in the DIO. Further a synthetic image is generated based on the first image and the second image. Lastly the synthetic image is stored in an object for use with a viewing parameter. Additional systems methods and computer program products are also presented.

Embodiments of the present invention enable a wireless mobile device to share a dynamic image object DIO thereby enabling a recipient to modify their view of an image generated from the DIO using a IMO viewer that is configured to include an interactive user interface UI control. In certain embodiments the DIO viewer may comprise an independent application program. In other embodiments the DIO viewer may be implemented as a feature of another application having additional features. In one embodiment the wireless mobile device may be configured to cause a data service system to generate a DIO by processing one or more digital images transmitted from the wireless mobile device to the data service system.

In one embodiment a DIO may comprise a data object configured to include at least two digital images and may include metadata associated with the at least two digital images. In one embodiment the metadata may include information related to generating a display image based on combining the at least two digital images. The metadata may also include one or more functions used to generate the display image an additional image used to generate the display image or any combination thereof. In another embodiment a DIO may comprise a data object configured to include one digital image and metadata that may include one or more functions used to generate a display image from the one digital image. The DIO construct is described in greater detail below in .

In one embodiment a given DIO may be presented to a user through the wireless mobile device executing a DIO viewer and optionally presented similarly to other users through different wireless mobile devices or through any other technically feasible computing devices. While certain embodiments are described in conjunction with a wireless mobile device other embodiments employing different technically feasible computing devices configured to implement the techniques taught herein are within the scope and spirit of the present invention.

As shown at least part of a partially populated dynamic image object DIO is received. See operation . Next a first image is identified in the DIO. See operation . Additionally a second image is identified in the DIO. See operation . Further a synthetic image is generated based on the first image and the second image. See operation . Still yet the synthetic image is stored in an object for use with a viewing parameter. See operation .

In various embodiments the first image may be an ambient image and the second image may be a flash image. Of course in other embodiments the first image and the second image may be any type of image.

In the context of the present description a synthetic image includes any image that is based on a combination of at least two input images. In one optional embodiment such combination may be accomplished utilizing an image synthesis algorithm and or any process capable of combining two images together.

In some embodiments the object used for storing the synthetic image may include a dynamic image object. Additionally in other embodiments the object may store the first image the second image metadata image metadata e.g. data associated with the first image and or second image and or any other image etc. view behavior metadata generation behavior metadata and or any other information or data which may relate to any of the images in some manner.

In one embodiment the first image or the second image may be used to produce at least one processed image. In another embodiment the processed image may be stored in the object.

In the context of the present description a viewing parameter includes any parameter that is used to view an image. In one embodiment a viewing parameter may be used to view a synthetic image a processed image the first image the second image and or any other image. In another embodiment the viewing parameter may be user selectable. In one embodiment the viewing parameter may include device type screen size processor type amount of RAM input type and or any other feature which may affect how the image e.g. synthetic image etc. is displayed.

In various embodiments operating parameters associated with the viewing parameter may include an ability to control a blend or mix between a first image and a second image and or any number of images an exposure a brightness a color a contrast a sharpness a filter e.g. watercolor color selection etc. a saturation and or any other feature which may alter the resulting image in some manner.

Still yet in one embodiment a second synthetic image may be generated based on the first synthetic image and at least one of the first image or the second image. Of course any number of synthetic images may be created based on any previously created synthetic images and or based on a combination of a previously created synthetic image and the first image or the second image or another image. In one embodiment the second synthetic image may be stored in the object for use with a viewing parameter.

In one embodiment the object for use with a viewing parameter may be accessible over a network. For example in one embodiment the object may be stored initially on a mobile device. In some embodiments the mobile device may only store the object for a limited duration. In other embodiments the object may be sent to a server and transmitted via a network.

In another embodiment identifying the first image may include receiving the first image utilizing at least one server. In one embodiment the identifying the second image may include includes receiving the second image utilizing the at least one server. Further in one embodiment the synthetic image may be generated and stored utilizing the at least one server. In an additional embodiment he synthetic image may be generated and stored utilizing at least one client.

In one embodiment application code may be provided for utilizing the object to generate an output image such that the viewing parameter may be capable of being adjusted utilizing the application code.

As shown two or more images are identified. See operation . Additionally metadata associated with each of the two or more images is identified. See operation . Further a package of the two or more images and the metadata is created. See operation . Lastly the package is transmitted to a destination. See operation .

In one embodiment the metadata associated with each image may include data associated with the image e.g. resolution of image color of image compression type etc. camera e.g. model processor type etc. the lens e.g. make model etc. the user e.g. past behavior interacting with images and or the image system etc. connections associated with the user e.g. via a social network etc. and or any other data which may affect the image in some manner.

In various embodiments creating a package may include creating local URLs and or paths associated with data on the originating device. In this manner if the package is sent back to the original user at a later time the revised package may include only that data e.g. revised photo etc which was not originally included in the package. In another embodiment URLs and or paths may be created associated with cloud based information. For example in one embodiment data for rectifying chromatic aberrations associated with a particular lens may be stored in the cloud and may be accessed using a path and or URL associated with the identified lens.

In one embodiment the package may be transmitted immediately upon completion. In other embodiments the package may be transmitted based on bandwidth availability data allocation e.g. whether the user has already used up a set amount of network connectivity etc. user connections e.g. via social network etc. and or any other threshold or trigger associated with the user device and or image.

Wireless mobile device may comprise a smart phone configured to include a digital camera a digital camera configured to include wireless connectivity a reality augmentation device a laptop configured to include a digital camera and wireless connectivity or any other technically feasible computing device configured to include a digital camera and wireless connectivity.

Wireless access point is configured to communicate with wireless mobile device via digital radio link and to communicate with data network via any technically feasible transmission media such as any electrical optical or radio transmission media. For example wireless access point may communicate with data network through an optical fiber coupled to wireless access point and to a router system or a switch system within data network . A network link such as a wide area network WAN link is configured to transmit data between data network and a data center .

In various embodiments data network may include routers switches long haul transmission systems provisioning systems authorization systems and any technically feasible combination of communications and operations subsystems configured to convey data between network endpoints such as between wireless access point and data center . Additionally wireless mobile device may comprise one of a plurality of wireless mobile devices configured to communicate with data center via one or more wireless access points coupled to data network .

Data center may include without limitation a switch router and at least one data service system . Switch router is configured to forward data traffic between and among network link and each data service system . Switch router may implement any technically feasible transmission techniques such as Ethernet media layer transmission layer 2 switching layer 3 routing and the like. Switch router may comprise one or more individual systems configured to transmit data between data service systems and data network . In one embodiment switch router implements session level load balancing among plural data service systems .

In one embodiment each data service system may include at least one computation system and may also include one or more storage systems . In another embodiment each computation system may comprise one or more processing unit such as a central processing unit a graphics processing unit or any combination thereof. A given data service system may be implemented as a physical system comprising one or more physically distinct systems configured to operate together. Alternatively a given data service system may be implemented as a virtual system comprising one or more virtual systems executing on an arbitrary physical system. In certain scenarios data network is configured to transmit data between data center and another data center such as through network link .

Still yet in some embodiments network service system may be described in specific terms herein but any system of wireless mobile devices configured to communicate with one or more data service systems may be configured to implement one or more embodiments of the present invention. Certain embodiments of the present invention may be practiced with a peer to peer network such as an ad hoc wireless network established between two different mobile wireless devices. In such embodiments digital image data may be transmitted between two mobile wireless devices without having to send the digital image data to data center .

Processor complex may include one or more central processing unit CPU core one or more graphics processing unit GPU a memory controller coupled to memory subsystems such as volatile memory and NV memory a frame buffer controller coup to display unit and peripheral controllers coupled to input output devices sensor devices and the like. Processor complex may be configured to execute an operating system and an application program. The application program may include programming instructions directed to a CPU execution model programming instructions directed to a GPU execution model or any technically feasible combination thereof. In one embodiment the operating system is loaded for execution from NV memory .

In one embodiment strobe unit is integrated into wireless mobile device and configured to provide strobe illumination that is synchronized with an image capture event performed by digital camera . In an alternative embodiment strobe unit is implemented as an independent device from wireless mobile device and configured to provide strobe illumination that is synchronized with an image capture event performed by digital camera . Strobe unit may comprise one or more LED devices one or more Xenon cavity devices one or more instances of another technically feasible illumination device or any combination thereof. In one embodiment strobe unit is directed to either emit illumination or not emit illumination via a strobe control signal which may implement any technically feasible signal transmission protocol. Strobe control signal may also indicate an illumination intensity level for strobe unit .

In one usage scenario strobe illumination comprises at least a portion of overall illumination in a scene being photographed by digital camera . Optical scene information which may include strobe illumination reflected or reemitted from objects in the scene is focused onto an image sensor as an optical image. Image sensor within digital camera generates an electronic representation of the optical image. The electronic representation comprises spatial color intensity information which may include different color intensity samples fir red green and blue light. In alternative embodiments the color intensity samples may include without limitation cyan magenta and yellow spatial color intensity information. Persons skilled in the art will recognize that other sets of spatial color intensity information may be implemented without departing the scope of embodiments of the present invention. The electronic representation is transmitted to processor complex via interconnect which may implement any technically feasible signal transmission protocol.

Display unit is configured to display a two dimensional array of pixels to form a digital image for display. Display unit may comprise a liquid crystal display an organic LED display or any other technically feasible type of display. Input output devices may include without limitation a capacitive touch input surface a resistive tablet input surface buttons knobs or any other technically feasible device for receiving user input and converting the input to electrical signals. In one embodiment display unit and a capacitive touch input surface comprise a touch entry display system configured to display digital images and to receive user touch input. Input output devices may also include a speaker and may further include a microphone.

Non volatile NV memory is configured to store data when power is interrupted. In one embodiment NV memory comprises one or more flash memory chips or modules. NV memory may be configured to include programming instructions for execution by one or more processing units within processor complex . The programming instructions may include without limitation an application program an operating system OS user interface modules imaging processing and storage modules and modules implementing one or more embodiments of techniques taught herein. NV memory may include both fixed and removable devices. One or more memory devices comprising NV memory may be packaged as a module that can be installed or removed by a user. NV memory may be configured to store one or more digital images such as digital images sampled by digital camera . In one embodiment volatile memory comprises dynamic random access memory DRAM configured to temporarily store programming instructions image data and the like. Sensor devices may include without limitation an accelerometer configured to detect directional force an electronic gyroscope configured to detect motion or orientation a magnetic flux detector configured to detect orientation a global positioning system GPS module configured to detect geographic position or any combination thereof.

Wireless unit may include one or more digital radios configured to transmit and receive digital data. In particular wireless unit may implement wireless transmission standards known in the art as WiFi based on institute for electrical and electronics engineers IEEE standard 802.11 digital cellular telephony standards for data communication such as the well known 3G long term evolution LTE standards 4G standards or any technically feasible combination thereof. In one embodiment wireless mobile device is configured to transmit one or more digital photographs residing within either NV memory or volatile memory to an online photographic media service via wireless unit . In such an embodiment a user may possess credentials to access the online photographic media service and to transmit the one or more digital photographs for storage sharing and presentation by the online photographic media service. The credentials may be stored within or generated within wireless mobile device prior to transmission of the digital photographs. The online photographic media service may comprise a social networking service photograph sharing service or any other web based service that provides storage and transmission of digital photographs.

In one embodiment wireless mobile device comprises a plurality of digital cameras configured to sample multiple views of a scene. In one implementation a plurality of digital cameras is configured to sample a wide angle to generate a panoramic photograph. In another implementation a plurality of digital cameras is configured to sample two or more narrow angles to generate a stereoscopic photograph. In yet another implementation a plurality of digital cameras is configured to sample a plurality of focus points to generate a synthetic focus image. In still yet another embodiment a plurality of digital cameras is configured to sample a plurality of different exposures to generate a high dynamic range image.

In one embodiment kernel may include one or more kernel service modules and one or more device drivers configured to manage hardware devices and to present an abstracted programming interface to client software modules requesting access to the hardware devices. Kernel services modules may be configured to provide process control services memory management services and the like in one embodiment a camera driver is configured to manage operation of digital camera and a display driver is configured to manage operation of display unit . Another device driver not shown may be configured to manage operation of wireless unit and so forth. Certain device drivers may be configured to present a corresponding device as a system resource having functionality that is abstracted through an application programming interface API .

In some embodiments network services module may provide services related to network connectivity data transmission and data stream management. In one embodiment network services module implements network protocols such as the well known suite of protocols referred to in the art as Internet protocol IP . Network services module may also implement wireless communication protocols and control stacks such as those related to cellular communications LTE etc. and local network communications WiFi etc. . Network services module may be implemented as a collection of different service modules each configured to execute in conjunction with operating system .

In one embodiment file system may implement a file abstraction over unstructured or block level storage. For example in one embodiment file system may present an organized hierarchical file system of named files and directories that are mapped onto sequential storage blocks comprising a flash memory implementation of NV memory . In such an example application program may access files by name without regard to physical layout within NV memory .

In another embodiment window manager may include tools and subsystems for providing a data metaphor comprising windows and data objects for intuitive user interaction. Window manager may also implement a collection of interactive UI tools which may be called and configured by application program . Window manager may also implement a runtime environment for managing different events such as user input events such as certain user events that require a corresponding update to state. Additional system services may be implemented in system services . For example in one embodiment a runtime event manager may be implemented as a system service which is called by window manager .

Still yet in one embodiment application program may include programming instructions that implement tangible user interaction behaviors. For example in one embodiment application program may cause operating system to display a window with UI objects such as input widgets and one or more output display surfaces. In another embodiment the window and related UI objects may be displayed on display unit of . In one embodiment UI module may be configured to define and manage UI objects comprising an application user interface associated with application program . In a mode view controller application architecture UI module may implement view functions and controller functions. UI module may call window manager to implement certain functions. Certain model functions may be implemented by data management module and data processing module . Data management module may include a database subsystem for storing organizing retrieving and otherwise managing data objects such as digital photos and related metadata. Data management module may call certain system services modules for certain common data management operations. Data processing module may include without limitation image processing functions for operating on digital images. For example in one embodiment data processing module may include image compression functions such as JPEG compressor and extractor functions high dynamic range HDR functions for generating a digital image from an HDR stack image alignment operations for aligning related images image merge operations for combining data associated with related images such as HDR images or flash ambient images and the like.

In one embodiment application program is configured to execute within processor complex of . The application program may enable a user to cause digital camera to sample one or more digital images in response to a shutter release event. The one or more digital images are stored within NV memory . One exemplary shutter release event comprises a user activating a UI widget such as a UI button control. The one or more digital images may then be processed by data processing module and one or more resulting images stored to NV memory or volatile memory . One or more resulting images may be shared through a digital wireless connection facilitated by wireless unit .

Sharing an image may include transmitting image data from one user to one or more different users or from one device to one or more different devices. The process of sharing may be accomplished according to an arbitrary technique or chronology. For example a device may transmit image data to a server during one time interval after which the server makes the image data available to different devices. A different device may then retrieve the image data during a second time interval. The first time interval and the second time interval may be separated by an arbitrary time duration. In one embodiment sharing comprises a first step of transmitting image data from a first device to a server and a second step of transmitting image data from the server to a second device. In another embodiment sharing may comprise transmitting image data from the first device to the second device as a peer to peer transmission. In each embodiment an access control system such as an account login or account credentials system may implement controls on which users or which devices may access a particular set of image data.

In one embodiment processor complex may comprise one or more processing units coupled to memory subsystem which may include dynamic random access memory DRAM or any other technically feasible form of system memory. Each of the processing units may comprise a central processing unit CPU graphics processing unit GPU digital signal processor DSP or any technically feasible combination thereof. In one embodiment each GPU may comprise a plurality of thread processors configured to execute corresponding instances of one or more thread programs. Processing units within processor complex may be configured to execute programming instructions stored within memory subsystem local storage system a local cache not shown or any other technically feasible memory or storage subsystem.

In one embodiment network interface may implement an Ethernet interface and storage interface may implement a Fibre Channel interface. In other embodiments storage interface may implement a second Ethernet interface and a block level storage protocol or a file level storage protocol. In still other embodiments storage interface may implement a direct attachment storage protocol such as external serial advanced technology attachment e SATA .

In one embodiment storage system may be configured to store data within storage subsystems . A storage controller may be configured to manage data stored within storage subsystems . In one embodiment storage controller may comprise a processing unit not shown and storage adapters not shown coupled to storage subsystems . The processing unit may be configured to implement a file system a block storage system or any technically feasible combination thereof. Storage controller may implement any technically feasible storage protocol for networked or directly attached storage devices. Data may be written to storage subsystems or read from storage subsystems in response to a storage access request transmitted from computation system to storage system through storage controller .

In certain embodiments computation system may comprise virtual computation resources configured to be independent of specific hardware computation resources. For example in one embodiment a virtual machine may implement virtual processing units virtual storage interfaces virtual network interfaces and the like. Similarly storage system may comprise virtual storage resources configured to be independent of specific hardware storage resources. For example a virtual file system may implement virtual storage units mapped on to arbitrary physical storage resource. In another example a virtual object data store may implement object storage functions that are independent of underlying physical storage resources and may be independent of any underlying file system.

Applications may be configured to implement specific services related to generation of and sharing of a DIO. In one embodiment an application may be configured to receive and store a DIO discussed in greater detail below in . Application may be further configured to share a DIO. In one embodiment an application may be configured to receive and store image data for generating a DIO. Application may be further configured to share the generated DIO. In one embodiment an application may be configured to receive and store image data for generating a DIO. Application may then transmit the image data to an image processing server which may generate the DIO and transmit the DIO to application . Application may be further configured to share the DIO generated by the image processing server.

In one embodiment system API may comprise an API implemented by a virtual operating system which may be configured to execute on a virtual machine. In this way applications may be configured to execute independently with respect to specific physical hardware resources. As illustrated below in an application space may be implemented that is independent of specific physical resources allowing applications to execute as needed on available physical resources.

Data stores may be configured to store data for an application . For example application may be configured to store data within data store A through a file system interface. Alternatively application may be configured to store data within data store A through a data object interface. Each application and each data store within application space may be mapped to a corresponding physical resource. For example application may be mapped to a computation server while applications may be mapped to a computation server . Similarly data store A may be mapped to a first physical storage system while data store may be mapped to a second different physical storage system . In certain embodiments data store A and B are configured to substantially mirror stored data and physical storage system is disposed in a geographically different physical location from physical storage system . In such a configuration either data store A or data store B may be disabled such as due to a natural disaster but data availability within the application space is maintained for uninterrupted operation by a mirror copy. Computation servers may also be disposed in different geographical locations to enable continued availability of each application in the event a certain data center is disabled. Within the same data center different computation servers and different data stores may be configured to provide resource redundancy for continued operation such as continued operation following a fault condition associated with one or more computation servers .

In one embodiment each application may be configured for fully reentrant operation with each selected point of progress by each application recorded within a data store through a reliable transaction mechanism such as a database transaction of file journal transaction.

One or more wireless mobile devices may be configured to communicate with a corresponding instance of one or more applications within application space . For example during a given time span wireless mobile device may transmit image data to application which may concurrently or subsequently store the image data within data store . In one embodiment application may be configured to apply one or more image processing algorithms to inbound image data from wireless mobile device to generate associated processed image data which is then stored to data store .

In one embodiment one or more applications are mapped onto an instance of computation system for execution. Multiple instances of computation system may host an arbitrary set of mapped applications. A given data store may be mapped onto one instance of storage system while a different data store may be mapped onto an arbitrary instance of storage system . In certain embodiments a computation system may implement a storage application and a data store may comprise the storage application coupled to an instance of storage system .

In another embodiment each processed source image may be generated from a corresponding source image through an appropriate image processing algorithm. The image processing algorithm may implement without limitation resolution adjustment resizing level adjustment sharpness adjustment contrast adjustment color adjustment alignment adjustment or any combination thereof. Each synthetic image may be generated based on a combination of at least two input images through an image synthesis algorithm. The at least two input images may comprise one or more source images one or more processed source images one or more synthetic images or any combination thereof.

In one embodiment metadata may include image metadata and behavior metadata . Image metadata may include configuration information associated with one or more source images such as exposure conditions lens configuration geographic location information other sampling information or any combination thereof. Image metadata may also include information associated with how one or more images are generated. The one or more images may include one or more processed source images one or more synthetic images or any combination thereof. Behavior metadata may include view behavior metadata generation behavior metadata or any combination thereof. View behavior metadata may specify how image data should be viewed or displayed to a user by specifying functions for performing operations related thereto. Generation behavior metadata may specify how a processed source image a synthetic image or any combination thereof should be generated by specifying functions for performing image generation operations related thereto.

In one embodiment view behavior metadata may comprise a reference to a predefined function for combining one or more images from image data into a display image which may be displayed to a user such as through display unit of . For example view behavior metadata may specify a reference to a linear alpha blend operation to be performed on an ordered set of images comprising a processed source image a first synthetic image and a second synthetic image . In one implementation a value of alpha for the linear alpha blend operation may be determined by a real time continuous value UI control which the user may manipulate to achieve a desired resulting image. In another example view behavior metadata may specify a linear alpha blend operation to be performed on a processed source image and a synthetic image . In other examples view behavior metadata may specify non linear blend operations spatially variant blend operations such as gradient blends and the like. In one embodiment the real time continuous value UI control may comprise a linear slider illustrated below in .

In another embodiment view behavior metadata may comprise programming instructions to be performed for combining one or more images from image data into a display image which may be displayed to the user. In one example view behavior metadata may include programming instructions for generating pixels within the display image. The programming instructions may be specified according to any technically feasible programming language. For example view behavior metadata may include programming instructions specified as an OpenGL shader according to the well known language of OpenGL. In one embodiment a viewer application configured to display DIO may submit the OpenGL shader to an OpenGL compiler for execution by a GPU residing within processor complex to generate the display image. The OpenGL shader may receive as input a parameter determined by the real time continuous value UI control.

In one embodiment generation behavior metadata may comprise a reference to a predefined function for generating one or more processed source images generating one or more synthetic images or any combination thereof. For example generation behavior metadata may specify a reference to a blend operation configured to generate a synthetic image by combining a first processed source image and a second processed source image . The first processed source image may be generated from a corresponding source image sampled by digital camera of using ambient illumination. The second processed source image may be generated from a corresponding source image sampled by digital camera using both ambient illumination and strobe illumination provided by strobe unit . The processed source images may be aligned in a previously performed alignment step. In another example generation behavior metadata specifies a reference to an HDR blend operation that generates a synthetic image by combining processed source images comprising an aligned HDR image stack. Each processed source image may be generated by aligning a corresponding source image with other source images or other processed source images . Of course in other embodiments any technically feasible techniques may be implemented to combine images within the HDR image stack to generate one or more synthetic images .

In another embodiment generation behavior metadata may comprise programming instructions to be performed for generating one or more processed source images one or more synthetic images or any combination thereof. In one example generation behavior metadata may include programming instructions specified as an OpenGL shader according to the well known language of OpenGL. In certain embodiments a viewer application configured to display DIO may submit the OpenGL shader to an OpenGL compiler for execution by a GPU residing within processor complex to generate one or more synthetic images . The OpenGL shader may receive as input a parameter determined by a UI control as an algorithmic input parameter. Alternatively the OpenGL shader may operate according to default parameter settings appropriate to an associated image processing algorithm implemented by the OpenGL shader.

In one embodiment processed source image may comprise a digital photograph generated from a source image taken under ambient lighting conditions while processed source image comprises a digital photograph generated from a source image taken with both strobe illumination and ambient illumination. In another embodiment a synthetic image may be generated from the processed source images and stored within DIO . The synthetic image may be generated by combining source image and source image such as through a non linear per pixel contribution function an alpha opacity blend function and or any other technically feasible function or combination or functions suitable for combining images. In another embodiment two or more source images may comprise an HDR image stack sampled by digital camera . Metadata may be populated with alignment information for aligning the two or more source images in preparation for performing an HDR merge operation. DIO may further include a synthetic image comprising an HDR merge of the HDR image stack.

In certain embodiments two or more processed source images may be generated based on the same algorithm but with different corresponding algorithmic parameters. For example a first processed source image may be generated from source image by performing an intensity curve compensation operation to recover tone from shadows while a second processed source image may be generated from source image by performing an intensity curve compensation operation to recover tone from highlights. In one embodiment a DIO configured to present both processed source images may store the processed source images and . In an alternative embodiment the DIO may include source images and and additionally may include generation behavior metadata that specifies functions for performing the intensity curve compensation operations for generating processed source images and .

In one embodiment DIO may include one or more source images one or more processed source images and a shader function e.g. an OpenGL shader which may be stored within generation behavior metadata . The DIO viewer may use the generation behavior metadata to generate one or more synthetic images . In another embodiment the DIO viewer may implement viewing behavior based on view behavior metadata .

In one embodiment source images may be stored as difference images relative to a reference source image . Each source image may be generated from a corresponding difference image and the reference image . A given difference image may advantageously require less data than its corresponding source image . In one embodiment a difference operation may comprise a component color space numerical difference a chroma luminance color space difference and or any other technically feasible color space difference. A difference operation may further comprise a motion estimation operation relative to the reference source image. A difference operation may comprise an offset and or scale value per pixel or region the offset and or scale values being represented in a compressed format within the difference image. In another embodiment certain processed source images may be stored as difference images relative to a processed source image or a source image .

In certain embodiments a processed source image or a synthetic image may represent an intermediate algorithmic step and the synthetic image need not be rendered materialized into a memory buffer. Instead in such an embodiment each image represents an intermediate step within a processing pipeline and final pixel values for a displayed image may be computed by performing certain pipeline steps within a single shader pass thereby obviating any need intermediate buffers with intermediate image data. In certain embodiments metadata may be configured to include results of certain computations associated with generating a final image for display. For example metadata may include alignment parameters that when applied to source images expedite generating an HDR merge of source images . Alternatively source images may be aligned and stored as corresponding processed images .

In one embodiment source image may comprise a digital image captured by digital camera of under ambient lighting conditions and source image comprises a digital image captured by digital camera under flash and ambient lighting conditions. In an alternative embodiment source image may comprise a digital image captured by digital camera according to a first exposure while source image comprises a digital image captured by digital camera according to a second different exposure. In such an embodiment source images and may comprise a two image HDR image stack.

In one embodiment image processing functions and may perform without limitation color adjustments resolution adjustments and formatting adjustments. Image processing function may perform an image alignment operation to align processed source image with processed source image to generate synthetic image . Image processing function may be configured to combine processed source image and synthetic image based on a viewing parameter which may be specified by a user through a UI control.

In one embodiment DIO may include processed source image and synthetic image . A DIO viewer may be configured to perform image processing function which may be specified in view of behavior metadata based on the viewing parameter to generate synthetic image for display to the user. In an alternative embodiment DIO may include processed source images and . The DIO viewer may be configured to perform image processing function which may be specified in generation behavior metadata to generate synthetic image . The DIO viewer may be further configured to perform image processing function which may be specified in view behavior metadata based on the viewing parameter to generate synthetic image for display to the user.

In certain embodiments generating a synthetic image may require a sufficiently large computational load as to preclude real time generation of the synthetic image in response to the viewing parameter. In such embodiments one or more synthetic images may be generated once and provided to the DIO viewer for real time blending operations that may be feasibly performed in real time. For example in an embodiment where synthetic image comprises an aligned version of processed source image the alignment process may be computationally too intense to be computed in real time as a user adjusts the viewing parameter but synthetic image need only be created once prior to being viewed. Similarly a synthetic image generated through an HDR merge may be computationally intense to generate but need only be generated once. Once generated the HDR image may be blended in real time through a simpler image processing function configured to be responsive in real time to the viewing parameter.

In one embodiment image data comprising DIO may include processed source image synthetic image and synthetic image . Processed source image may be generated based on a source image sampled by digital camera using ambient illumination. Synthetic image may be generated from a corresponding source image sampled by digital camera using both ambient illumination and strobe illumination provided by strobe unit . Synthetic image may be aligned to processed source image . Additionally synthetic image may be generated by combining processed source image and synthetic image .

In one embodiment combining processed source image and synthetic image to generate synthetic image may comprise a non linear blend operation. A pixel pair may comprise one pixel from the processed source image and one corresponding pixel from the synthetic image . The non linear blend operation may assign a greater blending weight to one or the other pixel in the pixel pair based on relative intensity of the pixels comprising the pixel pair. In an alternative embodiment combining processed source image and synthetic image may comprise a linear blend operation such as an alpha blend operation. A level adjustment operation may be applied to an image resulting from the alpha blend operation. The level adjustment operation may be configured to brighten a certain range of intensity values darken a range of intensity values or any combination thereof. In certain embodiments combining processed source image and synthetic image may further comprise adjusting color within synthetic image according to color information from processed source image .

In one embodiment a DIO viewer may be configured to display a blended image comprising zero through full weight contributions from processed source image synthetic image and synthetic image . In one embodiment the DIO viewer may be configured to execute image processing function to generate synthetic image for display. Image processing function may implement any technically feasible blend function such as an alpha blend whereby the viewing parameter may determine an alpha value for each of three images comprising processed source image synthetic image and synthetic image . The three images may be conceptually layered so that the top image may be essentially copied to synthetic image when the top image has an alpha of one. In one embodiment if the top image is transparent alpha is zero and the middle image has an alpha of one then the middle image may be essentially copied to the synthetic image . The bottom image may be assigned an alpha of one. In another embodiment each alpha value for each image may be calculated from the viewing parameter which may be generated from a UI control such as a linear control. When the viewing parameter is assigned one extreme value such as from a fully left position of the control both the top image and the middle image may be assigned an alpha of zero giving the bottom image full weight in synthetic image . When the viewing parameter is assigned an opposite extreme value such as from a fully right position of the control the top image may be assigned an alpha of one. When the viewing parameter is assigned a mid point value such as from a mid position of the control the middle image may be assigned an alpha of one opaque and the top image may be assigned an alpha of zero transparent .

Wireless mobile device may be configured to compute the one or more processed source images the one or more synthetic images or any combination thereof to populate DIO . In certain configurations DIO may include a minimum set of images needed by a DIO viewer to generate a synthetic image for display such as synthetic image of . In one embodiment the DIO viewer may be configured to generate one or more synthetic images based on generation behavior metadata and to generate the synthetic image for display based on view behavior metadata .

After DIO has been populated with an appropriate set of images wireless mobile device may transmit the DIO to the data service system comprising any technically feasible computing system such as a server executing within a virtual machine. Data service system may be configured to share DIO with a computing device which may comprise any technically feasible computing platform such as a smartphone a tablet computer a laptop computer or a desktop computer or a server computer system. Such sharing may be directed by a user operating wireless mobile device which serves as a sharing source while computing device serves as a sharing target. Sharing may be performed asynchronously whereby wireless mobile device may transmit DIO to data service system for sharing at one time while computing device may retrieve the MO at some later point in time.

In one embodiment application program of may be configured to generate and share DIO . In such an embodiment the application program may be configured to transmit DIO to data service system . The application program may also be configured to execute image processing function to generate synthetic image within DIO and to further generate a synthetic image for display within wireless mobile device . In certain embodiments a user may select among predefined image processing functions to designate which image processing function or combination of functions should be executed as image processing function . A UI tool may be configured to present the predefined image processing functions and allow a user to select among the functions. The UI tool may define a menu system a searchable library system or any other technically feasible selection technique. Application program may implement a DIO viewer for viewing DIO within mobile device .

In certain embodiments a DIO viewer not shown executing within computing device may be configured to execute certain image processing functions specified within metadata to generate a local copy of one or more synthetic image . In such an embodiment synthetic image need not be populated within DIO . Computing synthetic image locally within computing device may advantageously reduce transmission time and net data transmitted between wireless mobile device and data service system as well as between data service system and computing device . In other embodiments the DIO viewer may be configured to receive processed source images and generate all downstream synthetic images locally potentially reducing transmission time and total transmitted data between wireless mobile device and computing device .

In one embodiment SID may be structured as a subset of a DIO of and may include at least one source image and metadata . In certain embodiments SID may include one or more processed source images and metadata . Data service system may store SID within a storage system such as storage system . Computation system may execute image processing function on SID to generate DIO comprising at least one synthetic image based on SID .

In one embodiment data processing function may be specified within metadata of SID . In certain embodiments metadata may specify references to image processing functions implemented within computation system . In other embodiments metadata may specify programming instructions that define image processing function . In an alternative embodiment data processing function may be specified by an application program not shown that may be associated with computation system and configured to execute image processing function .

In one embodiment data service system may transmit DIO to wireless mobile device . Metadata may include at least a portion of metadata as well as any additional metadata generated by computation system such as metadata generated by image processing function . In an alternative embodiment data service system may transmit synthetic image to wireless mobile device which may assemble a local copy of DIO from SID and synthetic image . Data service system may transmit metadata or differences between metadata and metadata to wireless mobile device for incorporation within DIO . Data service system may share DIO with a computing device . Such sharing may be directed by a user operating wireless mobile device . DIO may include a substantially minimum set of images needed by a DIO viewer. DIO may instead include a set of images needed by the DIO viewer to generate a display image while applying a substantially minimum computation effort.

Computation system may execute image processing function on images comprising SID to generate a synthetic image comprising DIO . In one embodiment data processing function may be specified within metadata . In certain embodiments metadata may specify references to image processing functions implemented within computation system . In other embodiments metadata may specify programming instructions that define image processing function . In an alternative embodiment data processing function may be specified by an application program not shown that is associated with computation system and configured to execute image processing function . Image processing server may transmit DIO to data service system which may store DIO such as within storage system .

In one embodiment data service system may transmit DIO to wireless mobile device . In an alternative embodiment data service system may transmit the synthetic image to wireless mobile device which may assemble a local copy of DIO from SID and synthetic image . Data service system may share DIO with a computing device . Such sharing may be directed by a user operating wireless mobile device . In one embodiment data service system may provide a web API that enables image processing server to access SID and to store DIO within data service system . In certain embodiments storage system may comprise system memory such as system memory residing within computation system . In one embodiment each SID and each DIO may be stored temporarily until DIO is transmitted to data service system for storage therein.

In another embodiment each SID and each DIO may be stored within data service system and may be associated with a specific account such as a user account which may be further associated with wireless mobile device . For example in one embodiment a user account may be used to organize which SID and DIO object s are associated with the user. The user account may further associate the user with a cellular services account which may be distinct from the user account. Of course in other embodiments any technically feasible authentication technique may be implemented to authenticate a particular user and authorize the user to access the account.

In one embodiment data services system may be configured to generate a usage record not shown that reflects how many DIOs were generated for a given user account. The usage record may be stored in storage system . The usage record may reflect which system such as data service system or image processing server generated a given DIO. Alternatively in another embodiment the usage record may reflect a net count of generated DIOs generated per system. Each system may maintain an independent usage record for example image processing server may maintain a usage record of how many DIOs it generated for a given user account. In certain embodiments the usage record may be used by a customer billing system. In this way the usage record may facilitate fee based image processing services. The fees may be billed through a cellular service agreement or separately to an unrelated user account. Of course in other embodiments any technically feasible billing system may be configured to read the usage record and generate account invoices based on the usage record.

One or more usage records may enable a commercial ecosystem to develop whereby one or more third parties may operate an image processing server . A given image processing server may be configured to implement proprietary image processing functions which may be commercially availed to a user operating wireless mobile device . One example of a proprietary image processing function may be an HDR image processing function which may be computationally too intense for wireless mobile device . Another example of a proprietary image processing function may be an image analysis and recognition function that may require a proprietary database of image data that may not be stored on wireless mobile device .

Method begins in step where an application program may receive an image stack comprising one or more images such as source images of or processed source images . In one embodiment the application program may comprise application program of configured to execute within processor complex of . In step the application program may generate a synthesized image such as synthesized image . The application program may also generate one or more processed source images such as a processed source image . In step the application program may construct the DIO based on at least the synthesized image. In step the application program may transmit the DIO to a server such as data service system of .

In step the application program may share the DIO. In one embodiment sharing the DIO may comprise the application program instructing the server to share the DIO. In an alternative embodiment the application program may share the DIO by transmitting the DIO to a peer application executing on a different device. In another alternative embodiment sharing the DIO may be implied as a consequence of the application program transmitting the DIO to the server. As discussed previously the process of sharing a DIO may include multiple steps with each step conducted at different asynchronous points in time.

Method begins in step where an application program receives an image stack such as SID of comprising one or more images. In one embodiment the application program may comprise application program of configured to execute within processor complex of . In step the application program may transmit the image stack to a server such as data service system . In step the application program may receive a DIO such as DIO from the server. In one embodiment the DIO may include at least one synthetic image . The application program may assemble a local copy of the DIO to include the at least one synthetic image . In step the application program may share the DIO as described above in step of .

Method begins in step where the data service system receives a DIO from the client device. In step the data service system may store the DIO within a storage system such as storage system . In step the data service system may share the DIO thereby enabling a sharing target such as computing device to access the DIO. The sharing target may display the DIO to a sharing user through a DIO viewer. In one embodiment sharing the DIO may be initiated by the client device implicitly with the transmission of the DIO to the data service system . In an alternative embodiment sharing the DIO may be initiated explicitly by the client device. For example in one embodiment the client device may store multiple DIOs within the data service system but only share selected DIOs by explicitly indicating to the data service system which DIOs need to be shared. In one embodiment sharing the DIO may comprise updating an associated web page that may be accessed by a sharing target. In another embodiment sharing may comprise generating an update event through a web API that is being accessed by the sharing target. In yet another embodiment sharing may comprise transmitting a universal resource locator URL to the sharing target. In still yet another embodiment sharing may comprise transmitting the DIO to the sharing target.

Method begins in step where the data service system receives an image stack from the client device. In step the data service system may store the image stack within a storage system such as storage system . In step the data service system may generate a synthetic image such as synthetic image within DIO . The synthetic image may be based substantially on images within the image stack. The data service system may also generate metadata associated with the synthetic image . In step the data service system may generate the DIO from the synthetic image and the image stack. In step the data service system may store the DIO in the storage system. In step the data service system may transmit the DIO to the client device. As discussed previously transmitting the DIO to the client device may involve transmitting the whole DIO or just synthetic images comprising the DIO needed to reconstruct a local copy of the DIO within the client device. In step the data service system may share the DIO with a sharing target such as computing device .

In one embodiment generating the synthetic image in step may further include generating a record of usage per user so that each generated synthetic image may be counted. The record may then be coupled to a billing system configured to accrue usage charges to a user account associated with the client device. In one embodiment the user may be provided with a selection of different image processing services each configured to generate the synthesized image according to a selected image processing function. In one embodiment each different image processing service may accrue different usage charges.

Method begins in step where the data service system receives an image stack from the client device. In step the data service system may store the image stack within a storage system such as storage system . In step the data service system may transmit the image stack to an image processing server such as image processing server . The image processing server may be configured to generate a synthetic image such as synthetic image which may be stored within DIO . In step the data service system may receive the DIO from the image processing server. In step the data service system may store the DIO in the storage system. In step the data service system may transmit the DIO to the client device. In step the data service system may share the DIO with a sharing target such as computing device .

In various embodiments DIO viewer may include a UI control configured to enable a user to enter a viewing parameter which may be depicted as a position of a control knob along a slide path . To change the viewing parameter the user may move control knob . In a touch screen implementation moving the control knob may involve the user touching and sliding the control knob. The control knob may remain in position after the user lifts their finger from the touch screen. In implementations based on a mouse or track pad the user may click on and drag the control knob. A combined image may be generated based on two or more images associated with the DIO and further based on the viewing parameter. The viewing parameter may change as the user slides the control knob creating a sequence of corresponding new viewing parameters. In one embodiment the DIO viewer may be configured to generate a new combined image based on the sequence of new viewing parameters. In this way the user may touch and hold their finger to the control knob and see changes to the combined image in real time as they slide the control knob along the slide path .

In one embodiment details for how the combined image should be generated may be specified in view behavior metadata such as view behavior metadata associated with the DIO . In another embodiment each of the two or more images that contribute to combined image may be associated with a corresponding anchor point along the slide path . An association between each one of the two or more images and a corresponding anchor point may be specified within the metadata. An order of the two or more images may be specified within the metadata. A position for each anchor point may be specified within the metadata along with an association between each anchor point and one image within the DIO . The one image may comprise one of a source image a processed source image or a synthetic image within the DIO .

In one embodiment the metadata may include information related to the control knob such as an initial position for control knob . In one embodiment the initial position may be established by a user while viewing a DIO within DIO viewer . When the user closes the DIO the DIO viewer may save the current position as the initial position when the DIO is next opened. The initial position may also be established based on a suggested position for the control knob . The suggested position may be computed by substantially optimizing a cost function associated with the combined image such as an exposure function color correctness function histogram function contrast function or any other cost function that may be computed from the combined image . The suggested position may be saved to the DIO when the DIO is initially generated. In one embodiment the suggested position is displayed as a marker even if the user changes the position of the control knob to establish a different initial position.

In certain embodiments the control knob may be animated to slide along slide path as an indication to the user that the control knob may be moved and to further indicated to the user what effect moving the control knob has on a resulting combined image . For example in one embodiment the control knob may be displayed in an initial position and then slide to a left extreme and then slide to a right extreme and then slide back to the initial position completing the animation. Alternatively in a separate embodiment the control knob may be displayed at the left extreme and then slide to the right extreme and then slide to the initial position completing the animation. As the control knob is animated along slider path combined image may be updated to reflect a current position for the control knob . In one embodiment the metadata may further include animation information such as the extreme left position and extreme right position along slide path how many animation cycles should be performed animation velocity for the control knob granularity of animation along slide path and the like.

In some embodiments the animation may be performed each time the user initially opens a particular DIO within the DIO viewer . The animation of control knob may enable a new user to quickly learn to use the control knob within the DIO viewer and any user may be provided a quick visual understanding of the extent of visual impact the control knob may have on a current DIO being presented to them.

DIO viewer may process the metadata such as by compiling or instantiating an OpenGL shader program used to generate combined image . Alternatively DIO viewer may invoke a compositing function or other shader program function that may be built into DIO viewer and distinct from the DIO. In one embodiment the compositing function may implement alpha opacity blending to generate combined image based on the two or more images and further based on an alpha value substantially determined by the viewing parameter.

In one embodiment shown here anchor point may correspond to one image from the DIO anchor point may correspond to a second image from the DIO and anchor point may correspond to a third image from the DIO. The first image may be conceptually behind the second image and the second image may be conceptually behind the third image. When control knob is positioned at anchor point combined image may substantially represent the first image. In this position the first image may be completely opaque while the second image may be fully transparent and the third image may be functionally fully transparent.

In another embodiment when control knob is positioned at anchor point combined image may substantially represent the second image. In this position the second image may be fully opaque and the third image may be fully transparent. When control knob is positioned between anchor points and combined image may represent a linear composition of the first image and the second image. In this position the third image may be functionally fully transparent. The linear composition may be generated using conventional alpha blending technique. The third image may be fully transparent while control knob is positioned within the inclusive range between anchor points and or the third image may be excluded from computing combined image when control knob is within this range. As control knob moves from anchor point to the third image may be composited with proportionally increasing opacity decreasing transparency .

While such an embodiment may implement a basic alpha blend operation for generating combined image different functions may be implemented for generating combined image without departing the scope and spirit of embodiments of the present invention. Furthermore programming instructions specified within the metadata may define specific functions for generating combined image based on two or more images within the DIO and further based on the viewing parameter derived from a position of control knob . For example in one embodiment the position of control knob may have a nonlinear relationship with a viewing parameter controlling the generation of combined image . In certain embodiments more than one UI control may be implemented to provide corresponding viewing parameters.

In one embodiment DIO viewer may be configured to generate a synthetic image such as synthetic image prior to presenting a combined image to the user. In such an embodiment DIO viewer may load source images such as source images processed source images or any combination thereof comprising the DIO and may generate one or more synthetic images associated with the DIO. DIO viewer may generate the one or more synthetic images based on the metadata or based on a predetermined image processing function. In one embodiment the image processing function may receive a parameter from a user such as through a UI control.

In one embodiment DIO viewer may be implemented as a software application such as application program of executing on a computation platform such as wireless mobile device . A display image comprising the combined image and the UI control may be generated on display unit of .

In another embodiment DIO viewer may be implemented as a control script executing as dynamic behavior associated with a web page. Here at least one source image and at least one synthetic image may be loaded in conjunction with loading the web page and a local compositing function may generate the combined image .

In one embodiment DIO viewer may present a UI control such as a share button within display image . When the user indicates that a DIO should be shared such as by pressing the share button the DIO may be shared as described previously. The DIO may be shared in conjunction with a particular user account. In one embodiment a given DIO may reside within wireless mobile device and pressing the share button may cause the wireless mobile device to transmit the DIO to a data service system such as data service system alternatively pressing the share button may cause the wireless mobile device to transmit the DIO to a sharing target such as computing device of .

In an alternative embodiment a given DIO may reside within the data service system and pressing the share button while viewing the DIO within DIO viewer may cause the data service system to avail the DIO to other users who may have access to DIOs associated with the user account. For example in one embodiment the DIO viewer may transmit a command to the data service system to avail the DIO to other users. The command may identify a specific DIO through any technically feasible identifier such as an unique number or name to other users.

In one embodiment an application program that implements a UI control is configured to illustrate a corresponding effect of the UI control through a sequence of frames comprising a control animation. The control animation may illustrate any technically feasible function for the UI control. The animation sequence may be executed when a particular application view is first presented. The animation sequence may also be executed when a particular control is made active. For example in mobile devices with limited screen space an application program may allow the user to have one or a small number of UI controls active at any one time and to select among different UI controls to be made active. When the user selects a particular UI control the application program may animate the UI control to illustrate to the user what effect the UI control has within the application program. This technique may be practiced for any type of function associated with any type of application program the DIO viewer providing one exemplary implementation of this technique. Embodiments of the present invention therefore enable any application program that provides a real time UI control to advantageously indicate the effect of the UI control to a user by animating the control while displaying a corresponding effect.

In one embodiment of the DIO viewer a camera roll may implement a collection of DIOs that may be browsed by a user and selected for display by the DIO viewer . In one embodiment an input gesture such as a horizontal swipe gesture causes the DIO viewer to display a different DIO within the camera roll. Each DIO within the camera roll may be assigned a position within a sequence of DIOs comprising the camera roll and a left swipe may select a subsequent DIO for display in the sequence while a right swipe may select a previous DIO for display in the sequence. Once a DIO is selected for display the DIO viewer may display the DIO. The DIO viewer may then animate control knob in conjunction with displaying the DIO. The DIO viewer may further allow the user to move the control knob to adjust combined image . Additionally the DIO viewer may allow the user to share a DIO such as by pressing the share button .

In one embodiment a camera application may implement a camera view and a DIO view comprising a DIO viewer . When a user is framing their picture the camera application may display a live preview of the picture. When the user takes their picture the camera application may generate a DIO from their picture. Upon generating the DIO the camera application may transition to a view display implemented as DIO viewer . The user may view their image as a DIO within the DIO viewer . If the user then enters a swipe gesture the camera application may select an adjacent DIO within the camera roll for display within the DIO viewer .

In another embodiment a DIO viewer may be embedded within a webpage. For example in one embodiment a package of viewing elements may be sent to a client station the viewing elements including metadata associated with the photos the one or more images necessary to construct the HDR image and code or modifying the resulting image based on input from a user. In one embodiment the code may use in some manner webGL to enable manipulation of the images e.g. blending of the two or more images etc. .

In one embodiment a user may receive additional features on the webpage based on a level of access. For example in one embodiment a user may have a premium service wherein additional features associated with the webpage are presented to the user including the ability to modify the exposure ambient light strobe e.g. flash etc. light blending of the two or more images brightness contrast saturation color scheme and or any other element which may be separately controlled.

Still yet in one embodiment the bandwidth associated with a user may control the user s ability to interact with the webpage. For example in one embodiment the greater the bandwidth associated with the user the greater the number of options and or features presented to the user.

Of course in other embodiments if a user does not have a premium account e.g. the user only has a limited or free account etc. then limited access to the features and or options may be presented. For example in one embodiment a user using a free account may have the ability to control the blending of the two or more images but lack the ability to separately control any other element. In some embodiments the free account may be associated with any control and or feature.

In one embodiment the client side interaction associated with the DIO includes the ability to package up the image data metadata and then transmit such information to a central server. In one embodiment the server side interaction may include receiving a DIO package e.g. including the image data metadata etc. and rendering the package according to the functions and parameters specified. Of course in other embodiments the seer may take any further actions on the DIO package including recognition of objects within the image determination of locations or information based on the objects within the image and or perform any other action which may be relevant to the DIO package.

In some embodiments the DIO package rendered by the server may be used as the basis for creating a webpage including a DIO viewer. In other embodiments the DIO viewer may be integrated or embedded within a social network or any other webpage or network system including manipulation of resulting images such as HDR images. In one embodiment the social network may be used to store any amount of data associated with the DIO viewer including the initial image data metadata rendering instructions processing code resulting image and or any other data associated with the DIO viewer. In other embodiments the storing of any data associated with the DIO may occur on a temporary basis e.g. sharing of the DIO viewer is limited to only one week etc. or may be on an indefinite or undefined basis as well.

In another embodiment the metadata which is initially transferred from the client side to the server side may include exposure information lens configuration slider positions default settings filters to be applied and or any other information which may be used to control the image data in some manner.

While the foregoing is directed to embodiments of the invention other and further embodiments of the invention may be devised without departing from the basic scope thereof. For example aspects of the present invention may be implemented in hardware or software or in a combination of hardware and software. One embodiment of the invention may be implemented as a computer program product for use with a computer system. The program s the program product define functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Illustrative computer readable storage media include but are not limited to i non writable storage media e.g. read only memory devices within a computer such as CD ROM disks readable by a CD ROM drive flash memory ROM chips or any type of solid state non volatile semiconductor memory on which information is permanently stored and ii writable storage media e.g. a hard disk drive or any type of solid state random access semiconductor memory on which alterable information is stored. Such computer readable storage media when carrying computer readable instructions that direct the functions of the present invention are embodiments of the invention.

