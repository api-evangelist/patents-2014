---

title: Trainable sensor-based gesture recognition
abstract: In many computing scenarios, a device comprises at least one sensor, and is configured to recognize a gesture performed by a user according to the sensor output of the sensor, and to perform a particular action upon recognizing the gesture. However, many devices are preconfigured with such gestures, and the recognition is specific to the sensors of the device, and is not specific to the manner in which a particular user performs the gesture. Presented herein are techniques for enabling a device to recognize a new gesture by monitoring the sensor output of any sensors provided by the device while the user performs the gesture, optionally requesting repeated gesture performances until reaching a recognition confidence. Once trained to recognize the gesture according to the sensor outputs of the particular sensors of the device, the device may subsequently recognize the gesture performed by the user and execute an associated action.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09405377&OS=09405377&RS=09405377
owner: Microsoft Technology Licensing, LLC
number: 09405377
owner_city: Redmond
owner_country: US
publication_date: 20140315
---
Within the field of computing many scenarios involve a gesture performed by a user and recognized by a sensor of a device. In many such scenarios the device features one or more sensors such as an accelerometer a microphone and or a touch sensitive display. The device may be preprogrammed by a manufacturer to recognize a number of gestures performed by the user such as raising the phone the ear performing a pinch gesture on the touch sensitive display and placing the phone face down on a horizontal surface. The device may be programmed e.g. by identifying a model sensor output of a sensor when a gesture is performed by a typical user such that when a particular user performs the gesture in a similar manner as a typical user the device is capable of recognizing the gesture by comparing the sensor output with that of the model sensor output representing the gesture.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

While the configuration of a device with a set of preprogrammed gestures may enable a convenient mode of user input such recognition features of the device are often not significantly configurable and in particular are not adaptable to the user. For example many such recognizers are statically trained to detect sensor output that approximates a typical example of the gesture resulting in a recognition process that inaccurate both in false negatives e.g. failing to recognize a performed gesture because the user performs it differently than the typical user and in false positives e.g. making the range of sensor outputs associated with a gesture so broad that non gestural changes are incorrectly interpreted as gestures . Moreover the gesture preferences of the user are often not portable among the user s devices or adaptable to changes in the set of sensors available to a device.

Presented herein are techniques that enable the configuration of a device by a user to recognize a new gesture and to assign the new gesture to an action to be performed upon detecting the gesture during a recognition mode. In accordance with these techniques while in a recognition mode the device monitors the sensor output of the one or more sensors of the device while the user performs a gesture and identifies a set of identified sensor outputs that correspond to the gesture. The device may then accept an association of an action with the gesture that is to be performed when the device detects the identified sensor outputs of the sensors. In this manner the device may enable the user to specify new gestures to calibrate a gesture according to the particular manner performed by the user and or to configure the associations of gestures and actions performable by the device in accordance with the techniques presented herein.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are shown in block diagram form in order to facilitate describing the claimed subject matter.

Accordingly during use the user may perform a gesture such as shaking the device . The device may monitor the sensor output of the respective sensors and may compare the model sensor output with the sensor outputs of the respective sensors to detect the gesture . Upon such detection the device may perform the action associated with the performed gesture . In this manner the device may enable the performance of gestures by the user to control the operation of the device .

However it may be appreciated that when a device is preconfigured by a manufacturer or developer to recognize gestures performed by a user in accordance with the exemplary scenario of a variety of disadvantages may arise.

As a first example the manner in which a typical user performs a gesture may not correspond with that of the particular user . For example for a gesture such as shaking the device different users may perform the shaking with different duration frequency intensity and direction. It may be difficult to configure the device to recognize the shake gesture as performed by any user without increasing the rate of false positives in the recognition process e.g. simply interpreting any manner of shaking the device as the gesture may cause the device to perform the action during other events such as a vibration of the device while carried in a pocket .

As a second example a user may wish to create a new gesture that the sensors of a device are capable of recognizing. However devices configured as illustrated in the exemplary scenario of may be capable only of recognizing the specific set of predefined gestures and may not provide the ability of a user to define and describe a new gesture . Additionally a user may wish to associate a new or previously recognized gesture with a particular action but the device may not robustly permit the user to specify associations between a gesture and an action e.g. the device may be preprogrammed to associate the pinch touch based gesture only with the zoom out action and may not permit the user to reassign this gesture to another action .

As a third example a user may use a set of devices or may switch from a first device to a second device . The user may still want to utilize the gestures that were defined on the first device while using a second device but the preprogrammed set of recognized gestures and associated actions on the second device may differ from that provided by the first device . That is devices do not typically exchange information about which gestures a user utilizes and the actions responsive to such gestures .

As a fourth example the set of sensors on a particular device may change or may differ between a first device and a second device of the user . It may therefore be difficult for a device to translate the recognition of the gesture using a first sensor or sensor set to the recognition of the gesture using a second sensor or sensor set even if the second sensor is just as capable of recognizing the gesture as the first sensor . For these and other reasons the preconfiguration of the device to recognize gestures as provided by the manufacturer or developer of the device without significant ability of the user to adjust the recognized gestures and performed actions may result in limitations in the usability of the device by the user .

As further illustrated in the exemplary scenario of during a recognition mode the user may perform the gesture . The device may compare the sensor output of the sensors with the identified sensor output associated with each gesture as determined during the training mode . Upon detecting a match the device may determine that the gesture has been performed and may perform the action associated with the gesture . In this manner the device enables the user to teach new gestures to the device and to train the device in recognizing the particular manner in which the user performs known gestures in accordance with the techniques presented herein.

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to apply the techniques presented herein. Such computer readable media may include e.g. computer readable memory devices involving a tangible device such as a memory semiconductor e.g. a semiconductor utilizing static random access memory SRAM dynamic random access memory DRAM and or synchronous dynamic random access memory SDRAM technologies a platter of a hard disk drive a flash memory device or a magnetic or optical disc such as a CD R DVD R or floppy disc encoding a set of computer readable instructions that when executed by a processor of a device cause the device to implement the techniques presented herein. Such computer readable media may also include as a class of technologies that excludes computer readable memory devices various types of communications media such as a signal that may be propagated through various physical phenomena e.g. an electromagnetic signal a sound wave signal or an optical signal and in various wired scenarios e.g. via an Ethernet or fiber optic cable and or wireless scenarios e.g. a wireless local area network WLAN such as WiFi a personal area network PAN such as Bluetooth or a cellular or radio network and which encodes a set of computer readable instructions that when executed by a processor of a device cause the device to implement the techniques presented herein.

An exemplary computer readable medium that may be devised in these ways is illustrated in wherein the implementation comprises a computer readable memory device e.g. a CD R DVD R or a platter of a hard disk drive on which is encoded computer readable data . This computer readable data in turn comprises a set of computer instructions that are executable on a processor of a device and that cause the device to operate according to the principles set forth herein. In a first such embodiment the execution of the instructions on a processor of a device may cause a device to perform a method of configuring a device to perform actions in response to the detection of gestures performed by a user such as the exemplary method of . In a second such embodiment the execution of the instructions on a processor may implement one or more components of a system for performing actions in response to gestures performed by a user such as the exemplary system of the exemplary device . Many such computer readable media may be devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

The techniques discussed herein may be devised with variations in many aspects and some variations may present additional advantages and or reduce disadvantages with respect to other variations of these and other techniques. Moreover some variations may be implemented in combination and some combinations may feature additional advantages and or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments e.g. the exemplary first method of the exemplary device and or the exemplary system of and the exemplary computer readable memory device of to confer individual and or synergistic advantages upon such embodiments.

A first aspect that may vary among embodiments of these techniques relates to the scenarios wherein such techniques may be utilized.

As a first variation of this first aspect the techniques provided herein may be implemented on a variety of device such as workstations servers laptops tablet and palmtop factor mobile devices mobile phones portable gaming devices portable media players media display devices such as televisions appliances home automation devices medical devices and wearable computing devices such as eyewear headsets earpieces and wristwatches.

As a second variation of this first aspect the techniques provided herein may be used with many types of sensors providing many types of sensor output such as cameras providing still or moving images microphones providing samplings of ambient sound touch sensitive displays providing touch input from the user via a digit or stylus motion detectors providing a detection of motion temperature sensors providing a temperature reading lidar detectors providing lidar data biometric sensors providing a biometric identifier of a user accelerometers or gyroscopes providing readings of the orientation and or motion of the device and compasses providing a directional orientation of the device .

As a third variation of this first aspect the techniques presented herein enable devices to detect many types of gestures including manipulation of the orientation and or motion of the device a physical interaction of the user with the device such as drawing a gesture on a touch sensitive display of the device or squeezing a pressure sensitive element of the device a manual gesture performed with a hand or arm of the user such as a hand sign a sound performed by the user such as blowing into a microphone of the device and a facial expression posture or gait of the user .

As a fourth variation of this first aspect the techniques presented herein enable devices to perform a variety of actions in response to such gestures such as invoking an application sending a message displaying an image or text on a display of the device or activating a peripheral device such as a light emitting diode LED attached to the device .

As further illustrated in the exemplary scenario of a gesture profile service may be provided to store the gesture profile of the first device and to deliver the gesture profile to the other devices each of which may apply the gesture profile using the sensors of each device . The second device may also have an accelerometer sensor and may be capable of utilizing the identified sensor output identified by the accelerometer sensor of the first device . However the third device may only have a compass sensor that is not capable of utilizing the identified sensor output of an accelerometer sensor to detect the gesture . Accordingly the third device may ask the user to retrain the device in order to recognize the gesture and upon receiving an acceptance form the user may enter the training mode to identify the identified sensor output of the compass sensor to detect the gestures . Alternatively the third device and or the gesture profile service may detect the mismatch between the compass sensor of the third device and the accelerometer sensor of the first device and may attempt to translate the identified sensor output of each gesture for the accelerometer sensor into an identified sensor output of the compass sensor for use by the third device . In this manner the gesture profile service may enable the set of devices of the user to recognize and respond to gestures performed by the user in accordance with the techniques presented herein.

A third aspect that may vary among embodiments of the techniques presented herein involves the initiation of a training mode of the device in order to identify the identified sensor output of the respective sensors of the device for the respective gestures to be performed by the user .

As a first variation of this third aspect a device may transition to a training mode at the request of the user or upon an initial activation of the device such as a setup process for a newly acquired device .

As a second variation of this third aspect a device may transition to a training mode upon detecting a change in the set of sensors accessible to the device such as the addition to the device of an added sensor. The addition change and or removal of sensors may alter the manner in which the device detects gestures performed by the user e.g. a device may adequately detect a gesture with the identified gesture output of a first sensor but may more accurately detect the gesture by also using the identified gesture output for a second added sensor . Accordingly upon such detection the device may transition to the training mode to detect the identified sensor output of the added sensor while the user performs the gesture .

As a fourth variation of this third aspect the device may detect that one or more sensors of the device are miscalibrated e.g. a camera may be slightly rotated from a prior orientation . For example the sensor may be providing sensor data that is not consistent with the sensor data of other sensors that is not consistent with past sensor data from the same sensor or with an anticipated result in a particular context. While such miscalibration may alter the sensor data and may impair the detection of a match with an identified sensor output the device may remain capable of using the sensor to detect the gesture if retrained. Accordingly upon detecting such a miscalibration of a sensor the device may transition to the training mode to retrain the device to recognize the gestures .

As a fifth variation of this third aspect a device may receive a gesture profile e.g. from a second device or a gesture profile service specifying a gesture that is identified according to an identified sensor output that is not compatible with the sensors of the first device such as the third device in the exemplary scenario of . Accordingly the device may transition to the training mode to train the sensor to recognize the gesture . These and other variations may be utilized to prompt a device to transition to a training mode in order to detect new gestures or to adjust the detection or response of known gestures in accordance with the techniques presented herein.

A fourth aspect that may vary among embodiments of the techniques presented herein involves the configuration of the training mode of the device to identify the identified sensor output for respective gestures and the actions to be performed in response thereto.

As a first variation of this fourth aspect many types of learning techniques may be included in a training mode in order to identify from one or more sensor outputs of one or more sensors while the user performs a gesture the identified sensor output enabling the identification of the gesture . Such learning techniques may include e.g. evaluation by statistical techniques such as arithmetic mean median mode and standard deviation Bayesian algorithms fuzzy logic artificial neural networks and genetic algorithms.

As a second variation of this fourth aspect the training mode may involve two or more gesture performances of the gesture by the user e.g. the user may repeatedly perform the gesture in order to enable higher recognition accuracy. The device may during the respective at least two gesture performances of the gesture by the user monitor the sensors to detect the identified sensor outputs identifying the gesture during the gesture performance and determine the identified sensor output according to the identified sensor outputs of the respective gesture performances e.g. as a statistical mean of the identified sensor outputs with a precision recognition threshold identifying the range of deviation in the identified sensor output . In one such variation the device may compare the identified sensor outputs during the respective gesture performances to determine a recognition confidence and may instruct the user to repeat the gesture performance while the recognition confidence is above a recognition confidence threshold and upon determining that the recognition confidence is within the recognition confidence threshold the device may associate the identified sensor output with the gesture .

As a third variation of this fourth aspect the training mode may be invoked by the user and the device may presume that a gesture is being performed by the user between training start request and a training completion request. The device may therefore analyze the sensor output of the respective sensors to determine the identified sensor output of the sensors for the gesture during this training period and may transition back to recognition mode upon completing such identification. As a further variation the device may identify at least one restricted period during the training period i.e. that is shorter than the entire training period when the gesture is being performed by the user . For example the device may detect during the training period a pause at the beginning of the training period before the user performs the gesture a pause between respective gesture performances of the gesture and or a pause at the end of the training period after the user has completed performing the gesture . The device may therefore select the identified sensor output only during the restricted period s .

As a fourth variation of this fourth aspect where the device comprises at least two sensors the training mode may involve determining the identified sensor outputs using the sensor outputs of the respective sensors . As one such variation the device may utilize both sensors together to detect the gesture e.g. while the user shakes the device an accelerometer may detect changes in the motion of the device while a speaker detects fluctuations in the sound of air moving past the speaker that are concurrent with the changes in motion detected by the accelerometer. In accordance with this variation while the user performs the gesture the device may monitor the respective sensors to detect the identified sensor outputs of the sensors that together identify the gesture and may store the identified sensor outputs of each sensor in the memory of the device . During a recognition mode the device may monitor the sensor outputs of the respective at least two sensors for comparison with the corresponding identified sensor outputs in order to detect the gesture .

As a sixth variation of this fourth aspect during the training mode a device may request the user to identify the sensors that are capable of detecting a particular gesture . For example the user may understand that a particular gesture such as shaking the device is more readily detectable by an accelerometer sensor than a light sensor and may specify this distinction to assist the training mode of the device . Upon receiving at least one selected sensor from the user the device may monitor only the selected sensors while the user performs the gesture to detect the identified sensor output identifying the gesture and may store only the identified sensor outputs of the selected sensors .

As a further example of this sixth variation of this fourth aspect respective sensors of the device are associated with one or more sensor modalities e.g. a light sensor may detect changes in light levels a motion sensor may detect motion near the device a biometric sensor may detect a biometric feature of a user such as a facial expression and a still camera may detect changes in light levels nearby motion and biometric features of the user . The device may therefore identify the sensor modalities of the respective sensors and may present to the user options of which types of sensor modalities correspond to the gesture that the user wishes to have recognized e.g. recognize a motion based gesture a light based gesture or a biometric gesture . While the user performs the gesture the device may monitor only the sensors that are associated with the selected sensor modality and may store in the memory only the identified sensor outputs of such sensors . Many such variations may be included in the training mode of a device in order to determine the identified sensor outputs that enable a recognition of a gesture in accordance with the techniques presented herein.

A fifth aspect that may vary among embodiments of the techniques presented herein involves the manner of performing actions in response to the recognition of a gesture .

As a first variation of this sixth aspect an action may be associated with a context of the device such as an executing mode an application or an application state of the device . For example a recognized gesture may cause a first action to be performed if the device is executing a first application and a second action if the device is executing a second application e.g. shaking the device while using an email application causes the email application to fetch new mail while shaking the device while using a media playing application causes the media playing application to skip to a next media item in a playlist . Accordingly in response to the detection of a gesture the device may detect a current device context and may perform an action that is associated both with the gesture and the current device context of the device .

The techniques discussed herein may be devised with variations in many aspects and some variations may present additional advantages and or reduce disadvantages with respect to other variations of these and other techniques. Moreover some variations may be implemented in combination and some combinations may feature additional advantages and or reduced disadvantages through synergistic cooperation. The variations may be incorporated in various embodiments to confer individual and or synergistic advantages upon such embodiments.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB Firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

As used in this application the terms component module system interface and the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course those skilled in the art will recognize many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein.

Moreover the word exemplary is used herein to mean serving as an example instance or illustration. Any aspect or design described herein as exemplary is not necessarily to be construed as advantageous over other aspects or designs. Rather use of the word exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X employs A or B is intended to mean any of the natural inclusive permutations. That is if X employs A X employs B or X employs both A and B then X employs A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims may generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form.

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure which performs the function in the herein illustrated exemplary implementations of the disclosure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application. Furthermore to the extent that the terms includes having has with or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising. 

