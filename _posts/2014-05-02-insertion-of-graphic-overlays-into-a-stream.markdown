---

title: Insertion of graphic overlays into a stream
abstract: A particular method includes receiving, at a media server, a request for a first rendition of a stream. The method also includes generating a portion of the first rendition. Generating the portion of the first rendition includes determining whether one or more first overlay images are enabled and inserting the one or more first overlay images into one or more frames of the portion of the first rendition conditioned on the one or more first overlay images being enabled. The method further includes sending the portion of the first rendition to a computing device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09350780&OS=09350780&RS=09350780
owner: WOWZA MEDIA SYSTEMS, LLC
number: 09350780
owner_city: Golden
owner_country: US
publication_date: 20140502
---
The present application is a continuation of and claims priority to U.S. patent application Ser. No. 13 842 464 filed Mar. 15 2013 and entitled INSERTION OF GRAPHIC OVERLAYS INTO A STREAM the content of which is incorporated by reference in its entirety.

The popularity of the Internet coupled with the increasing capabilities of personal mobile electronic devices has provided consumers with the ability to enjoy multimedia content almost anytime and anywhere. For example live e.g. sports events and video on demand VOD content e.g. television shows and movies can be streamed via the Internet to personal electronic devices e.g. computers mobile phones and Internet enabled televisions .

When content is streamed via the Internet a content provider may overlay additional information on a video stream. For example a logo of the content provider e.g. television channel streaming website et. may be overlaid on the video stream. Due to the variety of device types device sizes and encoding technologies available to consumers overlay processing may be complex when performed by a content provider. Overlays may also be performed by a client device receiving the stream. For example a media player may overlay video controls e.g. pause play rewind fast forward etc. on top of the video stream being played. However the client device may have access to limited information regarding the stream and may thus be restricted to generating fairly basic overlays.

Systems and methods of inserting graphic overlays e.g. pictures and or text into a stream are disclosed. Advantageously overlays may be inserted by a media server that acts as a transcoding intermediary between a live stream provider and a destination device. For example the media server may receive a stream and may generate multiple versions e.g. bitrates and frame sizes of the stream for adaptive streaming. The media server may provide a flexible application programming interface API driven framework for overlays. Overlays may be added before and or after video scaling is performed by the media server. For example adding overlays before video scaling is performed may provide better performance because images are added to only one stream. Conversely adding overlays after video scaling may provide better looking results e.g. a specific overlay image can be provided for each frame size . Adding overlays after video scaling may also enable overlay granularity. For example more images may be inserted into high bitrate stream than into a low bitrate stream.

The media server may include one or more processors and various components that are executable by the processor s . The media server may correspond to software application s that perform media serving or processing hardware systems e.g. servers that support or perform media serving and processing or any combination thereof. Thus various operations described with reference to the media server or components thereof may be implemented using hardware software e.g. instructions executable by the processor s or any combination thereof.

The media server may be accessible via a network e.g. the Internet . The media server may be located at a content distribution site may be part of a cloud network or content delivery network may be located in an individual customer or user premises or may be in some other location. The media server may include one or more network interfaces . For example the network interface s may include input interface s and output interface s that are configured to receive data and to send data respectively. In a particular embodiment the network interface s may be wired and or wireless interfaces that enable the media server to communicate data via a network such as the Internet. For example the network interface s may include an Ethernet interface a wireless interface compatible with an Institute of Electrical and Electronics Engineers IEEE 802.11 e.g. Wi Fi protocol or other wired or wireless interfaces. In the embodiment of the media server receives a live stream from a capture source e.g. a camera or a video encoder .

As used herein a live stream may differ from a video on demand VOD stream. A VOD stream originates from or corresponds to content that is available in its entirety at a stream source when a packet of the VOD stream is sent. For example a VOD stream may correspond to a movie or television show that is stored at a storage device. A live stream corresponds to content that is not available in its entirety when a packet of the live stream is sent. For example a live stream may be used to transmit audio and or video content corresponding to an event as the event is being captured e.g. in real time or near real time . Examples of such events may include but are not limited to in progress sporting events musical performances video conferences and webcam feeds. It should be noted that a live stream may be slightly delayed with respect to the event being captured in accordance with government or industry regulations such as delay regulations enforced by the Federal Communications Commission FCC .

The media server may also include one or more encoders decoders and transcoders each of which may be implemented using hardware or software. For example one or more of the encoder s decoder s and transcoder s may be implemented using Java classes e.g. executable by a Java Virtual Machine JVM C instructions C instructions etc. The decoder s may decode data received by the media server . For example the decoder s may decode received streams e.g. live audio only video only or audio video streams and files e.g. VOD items . The encoder s may encode data that is to be transmitted by the media server . The encoder s and decoder s may thus enable the media server to process data in accordance with multiple coding technologies and protocols.

For example the media server may support video encoding types including but not limited to H.264 On2 VP6 Sorenson Spark Screen video Screen video 2 motion picture experts group MPEG 2 MPEG 2 and MPEG 4 Part 2. The media server may support audio encoding types including but not limited to advanced audio coding AAC AAC low complexity AAC LC AAC high efficiency HE AAC G.711 MPEG Audio Layer 3 MP3 Speex Nellymoser Asao and AC 3.

The media server may support communication e.g. adaptive streaming and non adaptive streaming protocols including but not limited to hypertext transfer protocol HTTP live streaming HLS HTTP dynamic streaming HDS smooth streaming and MPEG dynamic adaptive streaming over HTTP MPEG DASH also known as international organization for standardization ISO international electrotechnical commission IEC 23009 1 . The media server may also support real time messaging protocol RTMP and variants thereof real time streaming protocol RTSP real time transport protocol RTP and MPEG 2 transport stream MPEG TS . Additional audio formats video formats coder decoders CODECs and or protocols may also be supported.

In a particular embodiment the media server is configured to support adaptive streaming Adaptive streaming is a media transmission mechanism that enables a receiving device to dynamically request different versions of a stream in response to changing network conditions. For example one of the playback devices e.g. a desktop or laptop computing device a television or set top box a smartphone or a tablet computer may initiate an adaptive streaming session with the media server . The media server may send a manifest to the initiating device e.g. the computing device . The manifest may include information describing each of a plurality of renditions of a stream item that are available for adaptive streaming. As used herein a rendition of a live stream may correspond to a particular version of the live stream. Each rendition of a live stream may have a different bitrate e.g. video bitrate and or audio bitrate . Renditions may also differ from each other with respect to other audio and video quality parameters such as frame size frame rate video CODEC audio CODEC number of audio channels etc. The media server may support adaptive streaming of multiple live streams to multiple devices as further described herein.

In the example of there are four available renditions of the live stream . This is illustrated in by four arrows between the media server and the playback devices . However it will be noted that only one of the arrows is solid whereas the remaining arrows are dashed. This is to indicate that although four renditions are available only one of the renditions may be sent to a particular playback device at any given time. Different renditions of the same live stream may be sent to different playback devices at the same time. In alternate embodiments more than four or fewer than four renditions may be available for adaptive streaming Upon receiving the manifest the computing device may determine which of the available renditions of the live stream should be requested from the media server . For example the computing device may make such a determination based on buffering processing capability at the computing device and or network conditions being experienced by the computing device .

Upon determining which rendition should be requested the computing device may transmit a request to the media server . The request may specify a particular portion e.g. portion X of the requested rendition. Depending on the adaptive streaming protocol in use the requested portion may correspond to a chunk of a rendition and or a group of pictures GOP . A chunk may refer to a fixed length duration e.g. ten seconds or variable length duration of a stream rendition. A group of pictures may refer to a collection of video frames that includes one or more intra coded frames I frames and one or more additional frames that include difference information relative to the one or more I frames e.g. P frame and or B frames . If there are no problems with receipt and playback of the requested portion the computing device may request a subsequent portion e.g. portion X 1 of the same rendition of the live stream . However if playback and or network conditions become worse the computing device may switch to a lower bitrate rendition by requesting subsequent portions of the lower bitrate rendition. Conversely if playback and or network conditions improve the computing device may switch to a higher bitrate rendition. The transcoder s may generate key frame aligned portions for the adaptive streaming renditions so that switching to a lower bitrate or higher bitrate rendition appears seamless e.g. does not result in noticeable visual glitches or dropped frames at the computing device .

The transcoder s may be configured to transcode the live stream or portions thereof to generate additional renditions of the live stream or portions thereof . The transcoder s may be configured to perform bitrate conversion CODEC conversion frame size conversion etc. Depending on a format of the live stream a playback format supported by a requesting device and or transcoding parameters in use a transcoding operation performed by the transcoder s may trigger a decoding operation by the decoder s and or a re encoding operation by the encoder s . In a particular embodiment parameters used by the transcoder s are stored in one or more transcoding templates . For example the transcoding template s may be computer readable files e.g. eXtensible markup language XML files that define transcoding parameters e.g. bitrate type of CODEC etc. for various stream renditions.

The media server may also transmit multiple renditions of streams to other servers . For example the media server may transmit stream renditions to another media server or to a server e.g. an edge server of a content delivery network CDN . In alternate embodiments more than four or fewer than four renditions may be transmitted.

When the media server supports adaptive streaming graphical overlays may be added to the live stream at various times during video processing. For example a graphical overlay may be added to the live stream before the live stream is transcoded into one or more of the multiple renditions. As another example a graphical overlay may be added to an individual rendition during or after transcoding. To illustrate the transcoder s may include a pre scale overlay module a video scaler and a post scale overlay module . The pre scale overlay module may insert one or more images into a decoded version of the live stream generated by the decoder s . As used herein an image inserted into a stream may include graphics data and or text data. The video scaler may scale the decoded version of the live stream into one or more scaled streams where each of the scaled streams has a different frame size e.g. resolution . The post scale overlay module may insert one or more images into the scaled streams prior to the encoder s encoding the scaled streams for adaptive bitrate delivery.

In a particular embodiment images to be inserted into a stream are retrieved from non volatile storage e.g. disk based storage at the media server. Images may also be retrieved from a remote device via a network e.g. the Internet or from a network file system NFS mounted storage device. Alternately or in addition overlays or portions thereof may be generated dynamically. For example an image for insertion into a stream may be generated on the fly based on data in the transcoding template s and or data or executable code e.g. code provided by a user such as an owner or administrator of the media server . To illustrate the transcoders s may be implemented using one or more Java base classes and a user may generate custom transcoding classes that inherit from the base classes. For example a custom class may be used to implement an overlay that is partially static and partially dynamic such as an overlay that includes a logo static and a current date and time dynamic . As used herein an overlay may be static when at least one image for the overlay is retrieved from a storage location. An overlay may be dynamic when at least one image for the overlay is generated programmatically e.g. at runtime of the media server . Additional examples of overlays are further described with reference to .

In a particular embodiment the transcoder s support an application programming interface API . The API may be used to provide code that is executable by the transcoder s during stream processing. For example such executable code may define overlay configuration information such as whether particular overlay graphics identified by the transcoding template s are to be inserted by the pre scale overlay module prior to video scaling by the video scaler or by the post scale overlay module after video scaling by the video scaler is completed. The API may also enable additional overlay configurations such as image rotation text animation fade in fade out effects etc.

During operation the media server may receive the live stream . The decoder s may decode the live stream to generate a decoded stream that is provided to the transcoder s . The pre scale overlay module may examine the transcoding template s and or executable code e.g. custom classes provided by an owner or administrator of the media server to determine whether any images are to be inserted into the decoded stream. For example each time a frame of the decoded stream is generated the pre scale overlay module may receive a callback. In response to the callback the pre scale overlay module may examine the transcoding template s and or the executable code to determine whether any overlay images for the decoded stream are enabled as further described with reference to . When one or more images are to be inserted into the decoded stream the pre scale overlay module may retrieve the images e.g. from the non volatile storage and or dynamically generate the images. The pre scale overlay module may insert the retrieved generated images into the decoded stream. When no images are to be inserted into the decoded stream the pre scale overlay module may pass through the decoded stream without modification.

The video scaler may receive the decoded stream including any overlay graphics and may scale the decoded stream to generate one or more scaled streams. Each of the scaled streams may have a different frame size e.g. resolution . In a particular embodiment the video scaler may generate the scaled streams in accordance with parameters indicated by the transcoding template s . For example the transcoding template s may identify the number of scaled streams and properties of each scaled stream to be generated by the video scaler as further described with reference to .

The post scale overlay module may receive the scaled streams and may determine based on the transcoding template s and or executable code e.g. custom classes provided by an owner or administrator of the media server whether any images are to be inserted into any of the scaled streams. For example each time a frame of a particular scaled stream is generated the post scale overlay module may receive a callback. In response to the callback the post scale overlay module may examine the transcoding template s and or the executable code to determine whether any overlay images for the particular scaled stream are enabled as further described with reference to . When one or more images are to be inserted into a particular scaled stream the post scale overlay module may retrieve the images e.g. from the non volatile storage and or dynamically generate the images. The post scale overlay module may insert the retrieved generated images into the particular scaled stream. When no images are to be inserted into a particular scaled stream the post scale overlay module may pass through the particular scaled stream without modification. The encoder s may receive the scaled streams including any overlay graphics and may encode each of the scaled streams for adaptive bitrate delivery. The system of may thus enable insertion of graphical overlays at a media server e.g. the media server during transcoding.

The live stream may be input into a decoder . In an illustrative embodiment the decoder may be one of the decoder s of . The decoder may receive the live stream and may decode the live stream e.g. extract audio and video data out of incoming packets of the live stream to generate a decoded stream . The decoder may output the decoded stream to a first overlay module .

In an illustrative embodiment the first overlay module may be the pre scale overlay module of . The first overlay module may insert one or more images into at least one frame of the decoded stream to generate an intermediate stream . Different images may be inserted into different locations of frames of the decoded stream . The first overlay module may operate in accordance with settings defined by overlay configuration information . For example the overlay configuration information may include the transcoding template s of executable code or any combination thereof. The overlay configuration information may identify specific overlay images overlay locations within a frame transparency levels etc. An example of the overlay configuration information is further described with reference to . The first overlay module may output the intermediate stream to a video scaler . When no images are to be inserted by the first overlay module the first overlay module may pass through the decoded stream as the intermediate stream .

In a particular embodiment the first overlay module retrieves an image from a storage device and inserts the retrieved image into the one or frames of the decoded stream . The image corresponds to a static overlay. Examples of static overlays include but are not limited to a watermark a logo and a static advertisement.

Alternately or in addition the first overlay module may dynamically generate overlay images based on information generated at the media server during stream processing information retrieved from an external source and or executable code provided by a user. For example dynamic overlays may be used to insert hidden watermarks to track stream origin and usage. As another example dynamic overlays may be used to overlay a number of stream viewers on top of the stream. As yet another example dynamic overlays may be used to add locale or usage specific overlays such as news tickers with local news based on a viewer s location local weather alerts emergency broadcast information etc. A dynamic overlay may also be used to indicate that there is an error or outage situation at a stream capture site.

The video scaler may receive the intermediate stream from the first overlay module and may scale e.g. resize the intermediate stream to generate one or more scaled streams. Scaling a stream may include changing a frame size e.g. resolution of the stream changing an aspect ratio of the stream adding or removing letterbox or any combination thereof. In a particular embodiment a frame of an input stream may be copied to a frame of an output rendition without scaling i.e. the video scaler may duplicate the input stream and the output rendition may be used to add overlays. For example to syndicate a stream to multiple destinations with destination specific overlays the stream may be duplicated by the video scaler and different overlays may be added to each rendition of the stream based on the destination of that rendition. If the first overlay module inserted any images into the intermediate stream the inserted images are scaled as well. In an illustrative embodiment the video scaler may be the video scaler of . In the example of the video scaler generates three scaled streams and from the intermediate stream . In alternate embodiments more than three or fewer than three scaled streams may be generated. Each of the scaled streams may have a different frame size aspect ratio and or letterbox settings. The scaled streams may each have a larger and or a smaller frame size than the live stream . Alternately the intermediate stream may be passed through unsealed as one of the scaled streams . Each of the scaled streams and may be provided to a corresponding second overlay module and respectively.

In an illustrative embodiment the second overlay modules may be the post scale overlay module of . Each of second overlay modules may insert one or more images into at least one frame of the corresponding scaled stream to generate a corresponding second intermediate stream . The second overlay modules may operate in accordance with settings defined by the overlay configuration information . For example each of the second overlay modules may operate according to overlay parameters included in a section of the overlay configuration information that is specific to the corresponding intermediate stream as further described with reference to . The second intermediate streams may be output to corresponding encoders . When no images are to be inserted a scaled stream may be passed through without modification.

In a particular embodiment each of the second overlay modules is configured to retrieve one or more images from the storage device for insertion into a scaled stream. Different images may be inserted into different scaled streams. Further a different number of images may be inserted into different scaled streams. For example more images may be inserted into a high frame size rendition of a stream and fewer images or zero images may be inserted into a low frame size e.g. for mobile devices rendition of the stream. For example as shown in the storage device may store a different size image for insertion into the different scaled streams . Using different size images for different scaled streams instead of a single image that is resized for the different scaled streams may result in better looking e.g. sharper text less blurry graphics etc. overlays.

Alternately or in addition each of the second overlay modules may dynamically generate overlay images based on information generated at the media server during stream processing information retrieved from an external source and or executable code provided in accordance with an API.

In a particular embodiment different overlay settings may be defined for each of the second overlay modules . For example different numbers and types of overlay graphics may be inserted into different streams. To illustrate a high definition HD version of a live stream corresponding to a televised football game may include multiple static and dynamic overlays such as a television channel logo and a scoreboard including down and distance information and scores from other games. A low resolution version of the live stream for streaming to mobile devices may include the logo but not the scoreboard because the scoreboard may be difficult to read at low resolution. Different overlay settings may also be used for different purposes or audiences e.g. syndicating a stream to different destinations or audiences with different destination specific or audience specific overlays .

The encoders may receive and encode the second intermediate streams to generate encoded streams. Each of the encoded streams may correspond to a rendition of the live stream that is available for adaptive streaming. For example in the three encoders generate three renditions of the live video stream . One or more of the encoded streams may be sent to destination devices e.g. one or more of the playback devices of and or one or more of the servers of via adaptive streaming protocols e.g. HLS HDS smooth streaming and or MPEG DASH .

Although the foregoing description is associated with insertion of graphics on top of a live video stream the described techniques may also be used to implement underlays. For example a video stream may have a z order e.g. layer depth of zero. An image having a positive z order may be inserted into a corresponding layer on top of the video stream. However an image having a negative z order may be inserted into a corresponding layer underneath the video stream. To illustrate during a business presentation images corresponding to presentation slides may have a negative z order and may be placed underneath and a live video stream of a presentation speaker which may be scaled to fit into a corner of the resulting output stream similar to a picture in picture video .

In a particular embodiment the first overlay module and or the second overlay modules also supports pinching of video to accommodate overlay images. For example in some situations it may be preferable to pinch or squeeze a video instead of covering up a part of the video with an overlay image e.g. an advertisement . Thus a frame of video may be pinched and an overlay image may be added to the vacated region of the frame.

It should be noted that the division of various functions between the components of the media server in is for illustration only. In alternate embodiment one or more functions may be performed by a single component. For example the first overlay module may be part of the decoder and the second overlay modules may be part of the encoders . Various buffering points may be implemented as well. For example the decoder may buffer frames of decoded video for ingestion by the video scaler and the video scaler may buffer scaled frames for ingestion by the encoders .

The system of may thus provide a flexible API driven framework for overlays. Overlays may be added before and or after video scaling is performed by the media server . For example adding overlays before video scaling may provide better performance because images are added to only one stream. Conversely adding overlays after video scaling may provide better looking results. Adding overlays after video scaling may also enable overlay granularity. For example more images may be inserted into high bitrate stream than into a low bitrate stream. The system of may also enable monetization of live stream overlays. For example an advertiser may be charged a fee for insertion of static or dynamic advertising into adaptive bitrate renditions of a live stream.

In a particular embodiment a media server e.g. the media server of may support instantiation of one or more transcoding modules e.g. the transcoder s of . Each instantiated transcoding module may correspond to one or more executable software classes. A transcoding module may be added to a video processing flow for an application associated with a particular live stream. Thus when multiple live streams are being received by a media server multiple applications may be running and each of the applications may or may not include a transcoding module in their video processing flow. Each transcoding module may have its own transcoding configuration e.g. the transcoding template s of . Thus overlay settings defined for one application i.e. live stream may not be applied to other applications e.g. other live streams .

The overlay configuration information for a particular live stream may include audio video and overlay settings for various renditions of the live stream that are to be generated for adaptive streaming. For example the overlay configuration information may include settings for a first rendition and a second rendition .

The first rendition is a high quality rendition that has a name 720p a frame size of 1280 720 pixels a video bitrate of 1.3 megabits per second H.264 encoding AAC audio encoding 5.1 audio channels i.e. 5 surround channels and 1 base channel and an audio bitrate of 96 kilobits per second. In two overlays are defined for the first rendition and both overlays are enabled. The first overlay corresponds to a logo and the second overlay corresponds to a scoreboard. Overlay settings for each overlay include a z order an image path that may be used to retrieve an image a display opacity in percent a display location e.g. coordinates that the image is to be inserted into a video frame and a display alignment e.g. a horizontal alignment of left right or centered and a vertical alignment of top bottom or centered . In a particular embodiment the overlay settings also include an option to Check For Updates. When enabled this option may cause the media server to periodically check for updates to the overlay image. The time period for checking for updates may be programmable by a user or may be fixed e.g. 750 milliseconds . For example the Check For Updates option for the scoreboard overlay is enabled. As data for the scoreboard changes e.g. the current score changes an updated image for the scoreboard may be pushed to the storage location identified by the image path for the scoreboard. By checking for updates to the scoreboard image up to date scoreboard information may be inserted into the rendition .

The second rendition is a lower quality rendition that has a name 240p a frame size of 320 240 pixels a video bitrate of 350 kilobits per second H.264 encoding AAC audio encoding 2 audio channels and an audio bitrate of 60 kilobits per second. Both the logo overlay and the scoreboard overlay are defined for the second rendition but only the logo overlay is enabled.

In a particular embodiment overlay insertion is sticky. That is once an image is inserted in a particular location of a frame of a video stream the image continues to be inserted into every subsequent frame of the video stream at the same location until the overlay configuration is changed e.g. the location is changed the overlay is disabled etc. .

The method may include receiving a live stream at a media server at and decoding the live stream to generate a decoded stream at . For example in the media server may receive the live stream and the decoder may decode the live stream to generate the decoded stream .

The method may also include selectively inserting one or more first images into at least one frame of the decoded stream to generate an intermediate stream at . For example the one or more first images may include static images that are retrieved from data storage and or dynamically generated images. In a particular embodiment the media server may determine whether or not to insert images into the decoded stream based on settings that are stored at the media server and correspond to the live stream e.g. the transcoding template s of the overlay configuration information of and or the overlay configuration information of . When the settings indicate that no images are to be added to the decoded stream the decoded stream may be passed through as the intermediate stream.

The method may further include scaling the intermediate stream to generate scaled stream s at and selectively inserting one or more second images into at least one frame of a scaled stream to generate a second intermediate stream at . In a particular embodiment the media server may determine whether or not to insert images into the scaled stream based on the settings for the live stream e.g. the transcoding template s of the overlay configuration information of and or the overlay configuration information of . When the settings indicate that no images are to be added to the scaled stream the scaled stream may be passed through as the second intermediate stream.

The method may include encoding the second intermediate stream to generate an encoded stream and sending the encoded stream to a computing device via an adaptive streaming protocol at . It should be noted that a media server e.g. the media server of may generate multiple such encoded streams. For example each of the encoded streams may correspond to a rendition of the live stream that is available for adaptive streaming from the media server to a computing device. Thus the steps may be performed e.g. in parallel for each of multiple renditions of the live video stream.

Although one or more of the foregoing embodiments describe inserting graphical overlays into live streams the described systems and methods may also be used to insert graphical overlays into other types of streams. For example the described systems and methods may be used to insert graphical overlays into a video on demand VOD stream that corresponds to VOD content that is encoded on the fly for delivery from a media server e.g. the media server of . As another example graphical overlays may be inserted into a stream that is generated based on a playlist of VOD assets.

In accordance with various embodiments of the present disclosure one or more methods functions and modules described herein may be implemented by software programs executable by a computer system. Further implementations can include distributed processing component object distributed processing and or parallel processing.

Particular embodiments can be implemented using a computer system executing a set of instructions that cause the computer system to perform any one or more of the methods or computer based functions disclosed herein. A computer system may include a laptop computer a desktop computer a server computer a mobile phone a tablet computer a set top box a media player one or more other computing devices or any combination thereof. The computer system may be connected e.g. using a network to other computer systems or peripheral devices. For example the computer system or components thereof can include or be included within any one or more of the media server of the desktop laptop computing device of the TV set top box of the smartphone of the tablet computer of the media server stream relay server of a server e.g. edge server of the CDN of or any combination thereof.

In a networked deployment the computer system may operate in the capacity of a server or as a client user computer in a server client user network environment or as a peer computer system in a peer to peer or distributed network environment. The term system can include any collection of systems or sub systems that individually or jointly execute a set or multiple sets of instructions to perform one or more computer functions.

In a particular embodiment the instructions can be embodied in a non transitory computer readable or processor readable medium. The terms computer readable medium and processor readable medium include a single medium or multiple media such as a centralized or distributed database and or associated caches and servers that store one or more sets of instructions. The terms computer readable medium and processor readable medium also include any medium that is capable of storing a set of instructions for execution by a processor or that cause a computer system to perform any one or more of the methods or operations disclosed herein. For example a computer readable or processor readable medium or storage device may include random access memory RAM flash memory read only memory ROM programmable read only memory PROM erasable programmable read only memory EPROM electrically erasable programmable read only memory EEPROM registers a hard disk a removable disk a disc based memory e.g. compact disc read only memory CD ROM or any other form of storage medium or device.

In a particular embodiment a method includes receiving a stream at a media server. The method also includes scaling the stream at the media server to generate a scaled stream where the scaled stream has a different frame size e.g. a larger frame size or a smaller frame size than the stream. The method further includes inserting one or more images into one or more frames of the scaled stream. The method includes encoding the scaled stream including the one or more images to generate an encoded stream. The method also includes sending the encoded stream to a computing device via an adaptive streaming protocol.

In another particular embodiment a media server includes a processor and a decoder configured to decode a stream to generate a decoded stream. The media server also includes a first overlay module executable by the processor to insert one or more first images into at least one frame of the decoded stream to generate an intermediate stream. The media server further includes a video scaler configured to scale the intermediate stream to generate a scaled stream. The media server includes a second overlay module executable by the processor to insert one or more second images into at least one of frame of the scaled stream to generate a second intermediate stream. The media server also includes an encoder configured to encode the second intermediate stream to generate an encoded stream. The media server further includes a network interface configured to send the encoded stream to a computing device via an adaptive streaming protocol.

In another particular embodiment a computer readable storage device stores instructions that when executed by a computer cause the computer to receive a stream at a media server and to decode the stream to generate a decoded stream. The instructions when executed by the computer also cause the computer to insert one or more first images into at least one frame of the decoded stream to generate an intermediate stream. The instructions when executed by the computer further cause the computer to scale the intermediate stream to generate a scaled stream. The instructions when executed by the computer cause the computer to insert one or more second images into at least one of frame of the scaled stream to generate a second intermediate stream. The instructions when executed by the computer also cause the computer to encode the second intermediate stream to generate an encoded stream. The instructions when executed by the computer further cause the computer to send the encoded stream to a computing device via an adaptive streaming protocol.

The illustrations of the embodiments described herein are intended to provide a general understanding of the structure of the various embodiments. The illustrations are not intended to serve as a complete description of all of the elements and features of apparatus and systems that utilize the structures or methods described herein. Many other embodiments may be apparent to those of skill in the art upon reviewing the disclosure. Other embodiments may be utilized and derived from the disclosure such that structural and logical substitutions and changes may be made without departing from the scope of the disclosure. Accordingly the disclosure and the figures are to be regarded as illustrative rather than restrictive.

Although specific embodiments have been illustrated and described herein it should be appreciated that any subsequent arrangement designed to achieve the same or similar purpose may be substituted for the specific embodiments shown. This disclosure is intended to cover any and all subsequent adaptations or variations of various embodiments. Combinations of the above embodiments and other embodiments not specifically described herein will be apparent to those of skill in the art upon reviewing the description.

The Abstract of the Disclosure is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition in the foregoing Detailed Description various features may be grouped together or described in a single embodiment for the purpose of streamlining the disclosure. This disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather as the following claims reflect inventive subject matter may be directed to less than all of the features of any of the disclosed embodiments.

The above disclosed subject matter is to be considered illustrative and not restrictive and the appended claims are intended to cover all such modifications enhancements and other embodiments which fall within the scope of the present disclosure. Thus to the maximum extent allowed by law the scope of the present disclosure is to be determined by the broadest permissible interpretation of the following claims and their equivalents and shall not be restricted or limited by the foregoing detailed description.

