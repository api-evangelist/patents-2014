---

title: Image anomaly detection in a target area using polarimetric sensor data
abstract: A methodology for detecting image anomalies in a target area for classifying objects therein, in which at least two images of the target area are obtained from a sensor representing different polarization components. The methodology can be used to classify and/or discriminate manmade objects from natural objects in a target area, for example. A data cube is constructed from the at least two images with the at least two images being aligned, such as on a pixel-wise basis. A processor computes the global covariance of the data cube and thereafter locates a test window over a portion of the data cube. The local covariance of the contents of the test window is computed and objects are classified within the test window when an image anomaly is detected in the test window. For example, an image anomaly may be determined when a matrix determinant ratio of the local covariance and the global covariance exceeds a probability ratio threshold. The window can then be moved, e.g., by one or more pixels to form a new test window in the target area, and the above steps repeated until all of the pixels in the data cube have been included in at least one test window.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09495594&OS=09495594&RS=09495594
owner: The United States of America as represented by the Secretary of the Army
number: 09495594
owner_city: Washington
owner_country: US
publication_date: 20140605
---
This application claims priority of U.S. Provisional Application No. 61 847 592 filed Jul. 18 2013 the contents of which are incorporated herein by reference in its entirety.

The invention described herein may be manufactured used and licensed by or for the United States Government without the payment of royalties thereon.

The present invention relates generally to image anomaly detection in a target area and more particularly to a methodology for analyzing polarimetric sensor data of the target area to detect image anomalies. The methodology can be used for classifying and or discriminating between object classes in the target area such as manmade objects and natural objects for example.

Detection of anomalies using data produced by remote sensing technologies represents a critical technology for many applications including intelligence surveillance and reconnaissance. Some conventional methods have utilized linearly polarized infrared or thermal radiances of the target area.

Most if not all of conventional infrared anomaly detection systems are based on the premise that manmade objects such as tanks trucks and any other equipment tend to retain thermal energy hence to increase their temperatures from continuous and direct exposure to the environment and or a major source of thermal energy e.g. the sun more rapidly than natural objects do such as grass ground trees foliage and the like. The result from this rapid heat retention by manmade objects is that these objects also dissipate thermal energy more rapidly than natural objects do.

Over a daily period manmade objects within the target area typically absorb and thus emit infrared thermal energy more rapidly than natural objects do beginning at sunrise and continuing throughout the day until a few hours after sunset. This trend difference between the two object classes continues throughout the night until the next sunrise when the diurnal cycle is repeated. Consequently the emission of infrared energy or radiation by manmade objects in the target area and potential thermal feature separation of these manmade objects from natural objects is highly dependent upon the time of day. In addition manmade surfaces are also known for emitting polarized infrared radiance independently of their emission rate as these surfaces tend to be smooth relative to the length of infrared electromagnetic waves in corresponding regions of the spectrum. This is in contrast to surfaces of natural objects where their emitted radiance generally yields no favoritism to any particular polarization as these natural surfaces are rough not smooth relative to the same infrared electromagnetic wavelengths.

Existing infrared polarimetric anomaly detection systems may utilize polarimetric imagery from passive sensors in which four infrared polarization filtered pixel images of the target area are obtained by these sensors. These systems output and process imagery in the form known in the remote sensing community as the Stokes polarization parameters S S S or Stokes vector using the four infrared polarization filtered pixel images I I I I as input where the subscripts of I label the corresponding polarization component angles these relationships are expressed as

Of the three Stokes parameters Sis usually considered the most effective in detecting manmade objects in the target area which is believed to be overwhelmingly composed by natural objects. However when the probability distribution function of the Stokes Sparameter is plotted the Sparameter for manmade objects often heavily overlaps the probability distribution function for natural objects such that separation in the Sdomain of manmade objects from natural objects in the target area is difficult if not impossible to achieve. The overlapping of the probability distribution functions of the Stokes Sparameter for manmade objects and natural objects also varies as a function of the time of day. Thus anomaly detection at certain time periods e.g. early morning not only is very difficult but it is also highly prone to error e.g. false positives .

Still other methods have been attempted to detect and separate manmade objects in a target area from natural objects also in the target area. These other methods have included analysis of the DOLP metric the Fresnel ratio as well as multispectral polarimetric measurements. None of these methods however have significantly improved the detection of manmade objects in the target area as compared with the analysis of the Stokes Sparameter using data produced by either a passive or active sensor from a short range between sensor and objects in a controlled laboratory environment. Moreover the use of Stokes Sparameter has also been shown to be significantly less effective when data are collected in an uncontrolled outdoor environment especially when a passive sensor is used for data acquisition at a range greater than 200 m. In practice commercial and military remote sensing surveillance applications require ranges to be greater than 300 m and users executing surveillance operations favor the application of passive rather than active sensors for reasons to be explained later. Local surface orientation constructive and destructive measurement interferences are often cited as sources of performance degradation using passive Stokes Smeasurements from an uncontrolled outdoor environment.

Using remote sensing polarimetric data embodiments of the present invention present a methodology for detecting image anomalies in a target area for classifying objects therein between classes. The methodology can be used to discriminate object classes in the target area such as manmade objects from natural objects in a target area for example.

According to exemplary method of the present invention at least two images of the target area are first obtained from a sensor such as a passive polarimetric LWIR sensor. These two images are obtained at different polarization angles such as at 0 degrees and 90 degrees. Such images may be obtained of the target area by rotating a polarization filter associated with the sensor by the desired angular shift of the polarization components for instance. While multiple polarization filtered pixel images of the target area with each image at a different polarization angle may be used in practice only two images at polarizations offset from each other by 90 degrees i.e. 0 and 90 have proven sufficient to correctly discriminate manmade objects from natural objects in accordance with embodiments of the present invention.

The images are received by a computer for processing. A data cube is constructed in memory by the computer processor using the at least two polarization filtered images so that the infrared images are aligned such as on a pixel wise basis.

After creation of the data cube the computer processor is then used to compute a global covariance of the composite image from the entire data cube. Any conventional algorithm that estimates covariance matrices may be used to compute the global covariance of the data cube. Thereafter a test window that is much smaller in size than the images of the target area e.g. 10 pixels by 10 pixels is then located over a portion of the data cube. To begin the test window may be first located at one corner of the data cube for instance. The processor is then used to compute a local covariance of the content of that test window using the same covariance matrix estimation algorithm used to compute the global covariance.

Objects in the content of the test window are declared anomalies when a ratio of the determinant of the local covariance over the determinant of the global covariance exceeds a probability ratio threshold. And as an example a Bayes decision rule can be used to form the probability ratio test. The window is then moved within the target area by one or more pixels to form a new but possibly overlapping test window where the probability ratio test is repeated for the new test window. The entire process is repeated until all pixels in the data cube have been included in at least one test window.

With reference first to a sensor is shown and oriented to collect data from an exemplary target area . The sensor data then may be used to detect certain anomalies in the target area. This target area for example may contain manmade objects such as military tanks other equipments or buildings installations as well as natural objects such as trees and the natural flora within the test area . Trees and flora often confuse surveillance systems that are designed to autonomously detect the presence of manmade objects targets in a natural environment and sometimes these natural objects can partially obscure these targets making them difficult to be detected even by the naked eye or by some other means. Human clothes can potentially be detected since they are manmade objects. Configuring sensors to operate in certain regions of the electromagnetic spectrum data from said sensors can potentially be exploited using tailored methods to detect manmade objects as anomalies in a target area dominated by the presence of natural objects . The methodology of this invention can enable the standalone computer to discriminate manmade objects from natural objects in a target area and depending on the sensor s operating wavelengths this discriminant capability may apply to both daytime and nighttime.

The sensor may be configured to detect radiance for example in various bands or sub bands of the infrared visible or ultraviolet regions of the electromagnetic spectrum. The infrared region of the spectrum is of particular interest for surveillance applications because it covers beyond the region of the spectrum that is visible by the human naked eye while potentially offering discriminant features between manmade and natural objects. This region includes sub bands of near infrared 0.75 1.4 m shortwave infrared 1.4 3 m midwave infrared 3 8 m LWIR 8 15 and far infrared 20 1 000 m . In the preferred embodiment of the present invention the sensor is configured to detect LWIR radiation since LWIR is a region of the spectrum in which useful data can be produced by a passive sensor during daytime and nighttime a highly desired capability for both commercial and military surveillance applications.

While both active and passive sensors could be used as mentioned earlier the preferred embodiment of this invention is to make sensor a passive sensor because this type of sensor does not require the transmission of artificial signals as it is required for active sensors or the application of additional illumination such as a laser aimed at the direction of specific objects in the target area both of which could potentially give away the illumination source sensor s or laser s position depending on the system operational arrangement . It is also worth noting that if a typical narrowband laser beam is employed to provide the additional illumination the operation would require a human subject or machine to accurately aim the laser beam at potential target objects in the scene of interest defeating the purpose of the deployment of a surveillance system to a scenario where no information about the scene is known a priori this is usually the case for most of the commercial and military surveillance applications. Passive sensors in contrast are designed to passively detect reflected or emitted radiances from all objects in the target area which makes a passive sensor more suitable than an active sensor for wide area surveillance applications while potentially never giving away the sensor s location to enemies or foes who may be searching for a known wavelength energy pulse width etc. from transmitted signals associated with active devices.

The sensor outputs data in the form of an image composed of pixels for instance. It could be a still camera or video camera in many embodiments.

The polarization of detected radiance by the sensor can play an important role in detecting the presence of manmade objects in the target area as image anomalies under the assumption that the target area primarily consists of image data of a natural environment.

By convention the polarization of electromagnetic waves refers to the polarization of the electric field. Electromagnetic waves which can be approximated as a plane wave in free space or in an isotropic medium propagates as a transverse wave i.e. both the electric and magnetic fields are perpendicular to the wave s direction of travel. The oscillation of these fields may be in a single direction i.e. linear polarization or the field may rotate at the optical frequency i.e. circular or elliptical polarization . When polarization is exhibited the direction of the fields rotation does determine the specified polarization and by using a clockwise or counterclockwise convention the fields rotation can be specified by the resulting angle e.g. 0 degree 45 degree . Linear circular and elliptical polarization associated with a particular angle is referred to as polarization component.

In some embodiments a polarization filter is employed immediately in front of the optical lens of the sensor so that the sensor can only output image data that correspond to specific radiance polarization components allowed by the mechanical rotation of filter relative to the sensor s optical lens. The filter may be rotatable such as positioned on a mechanism that will mechanically rotate e.g. clockwise and or counterclockwise so that the polarizer filter can obtain different polarization components from the target scene. The main axis angle of the filter with respect to a non rotating main axis optical lens of sensor determines the polarization angle detected by the sensor . Thus with the filter oriented at an angle of 0 degrees the sensor outputs image pixel data of the intensity of the infrared image of the test area for a polarization of 0 degrees. Conversely rotation of the filter by 90 degrees will result in the sensor outputting pixel intensity data to a programmed computer and so forth. It will be understood of course that the filter angles of 0 and 90 degrees are by way of example only and that other angles of polarization of the filter may be used provided however that at least two different polarization angles are used to obtain at least two polarization filtered pixel images of the target area .

In other embodiments the sensor may be configured to output image data using a predetermined format that linearly combines subsets of individual polarization components of the detected radiance. Most of the commercially available polarimetric sensors are designed to directly output data in this predetermined format known in the scientific community as the Stokes parameters S S and S. The Stokes parameters are defined as follows 

where I denotes the intensity at each pixel location and for the different polarization angles illustrated in this case 0 degrees 45 degrees 90 degrees and 135 degrees. Thus from this data format the intensity I for each pixel at each polarization angle may be computed by the computer from the Stokes parameters according to an existing formula 0.5 cos 2 sim 2 .

Using the formula immediately above the Stokes parameter configured output of sensor can be converted to images representing individual polarization components of radiance and in accordance with embodiments of the present invention at least two images are required to represent different polarization angles which are then used for further processing.

With reference to after at least two pixel images representing different polarization components 90 degrees apart have been obtained of the target area either by a direct means through sensor or by a mathematical conversion internally processed in the sensor for computing the intensity from the Stokes parameters according to the above equation the pixel images are then fed as data to the computer which is programmed to create a data cube . It is noted that if the sensor is configured to output Stokes parameters images but it is not configured to internally compute the intensity conversions then these may be computed by the computer before the data cube can be created. The computer includes one or more processors as known in the art. Modules having processor executable instructions can be stored in a non transient memory device associated with the one or more processors in the computer . In some implementations software code instructions firmware or the like may be stored on a computer or machine readable storage media having computer or machine executable instructions executable by the processor s . The processor s may be a programmable processor or micro processor such as for example a field programmable gate array FGPA or an application specific integrated circuit ASIC processor. Computer might also be an image processor associated with the sensor . The methodology disclosed herein may be implemented and executed by an application using any one of the existing programming languages. Of course any number of hardware implementations programming languages and operating hardware platforms may be used without departing from the spirit or scope of the invention. As such the description or recitation of any specific hardware implementation programming language and or operating platform herein is exemplary only and should not be viewed as limiting.

The data cube may be thought of as a multi dimensional array of values stored in memory. It may be constructed by the computer using as input two or more pixel images representing different polarization components of the target area . As shown the data cube may be formed of a pixel image representing the corresponding 0 degree polarized radiances a pixel image representing the corresponding 45 degree polarized radiances a pixel image representing the corresponding 90 degree polarized radiances and a pixel image representing the corresponding 135 degree polarized radiances. The order of the polarization component images may be arbitrary for constructing the data cube thus the ordering thereof does not matter.

In order to form the data cube the pixel images are virtually stacked upon each other as illustrated diagrammatically in so that pixels at row i and column j for each image are co registered or aligned with each other pixel wise for each and every pixel in the pixel images . In other words the pixels at the row and column position i j of each of the polarization filtered pixel images are aligned with each other for all values of i and j throughout the entire image. In doing so a composite image of the target area in the form of a data cube consisting of all four of the pixel images is obtained such that each pixel in this composite image represents a vector of four components i.e. radiance values corresponding to the different polarization components. The spatial area of the data cube may be large e.g. 320 by 256 pixels and is directly dependent on the number of detectors featured in the sensor s focal plane array.

Although four pixel images are illustrated in in practice satisfactory results have been shown by using only two pixel images namely pixel image for polarization of 0 degrees and pixel image for polarization of 90 degrees. If two pixel images are used the difference between the polarization angles should preferably be of 90 degrees. Some examples of preferred pairs are 0 90 45 135 etc. Beyond this constraint two or more pixel images representing different polarizations may be used in any order for constructing the data cube without deviation from the spirit or scope of the present invention.

With reference to the computer as programmed determines after initiation at step whether or not the sensor outputs polarization component imagery directly or the Stokes parameters S S and S. If the sensor outputs the polarization component image directly step proceeds directly to step . Otherwise step branches to step where the polarization component imagery is computed from the Stokes parameters as described above and step then proceeds to step . At step the data cube is formed.

After the data cube is formed step proceeds to step where the computer computes the global covariance of the entire data cube . The covariance provides a measure of the strength of the correlation among variates in the data cube . In one embodiment the global covariance may be calculated in accordance with the following 

Since a sample from the data cube is a set of vectors in this case each vector consists of two components at equals 0 degrees and equals 90 degrees. The covariance matrix shows the variance of each component and the correlation level between the two components . When two samples represented here as polarization component 0 and 90 degrees xand x are independent from each other correlation is zero i.e. information contained in a sample does not influence the information contained in the other sample. Highest positive correlation yields the value of 1 and highest negative correlation yields the value of 1.

After the global covariance is computed using the entire data cube step proceeds to step . At step a virtual window is located over a spatial area of the data cube to define a test sample. The test window is relatively smaller in size compared to the data cube e.g. 10 pixels by 10 pixels. The window may begin at one corner of the cube e.g. the upper left hand corner of the cube although other starting locations for the window may be similarly used. Step then proceeds to step .

At step the contents of the test window are selected as the test sample. Step then proceeds to step where the local covariance is computed for the test sample which may be computed in the same fashion as the global covariance was computed at step . Step then proceeds to step .

At step the local covariance computed at step is compared with the global covariance computed at step to determine whether the determinant of the local covariance via the test window is greater than the determinant of the global covariance of the entire data cube . The determinant is a known metric that yields a single real value representing a measure of power of a given covariance. For instance an image anomaly may be identified when a ratio of the local covariance and the global covariance determinants exceeds a probability ratio threshold. If so the spatial location of the test window in the data cube would be indicative of containing a manmade object rather than a natural object based on this ratio of determinants feature. More particularly the determinant of a covariance matrix estimated from manmade object samples in this case was found to be much greater than the determinant of covariance matrices from natural object samples or

In order to determine if the covariance determinant of the local test window is much greater than the covariance determinant of the overall test cube the following formula may be applied to test data x 

If the Bayes decision rule is applied to the local and global covariance determinants under the assumption that the probability distribution function of the data is Gaussian then the formula above is reduced to 

With reference again to step after determining whether or not an anomaly exists in the test window proceeds to step which determines whether or not all pixel locations in the target area have been included in at least one test window. If not step proceeds to step where the test window is moved a predetermined number of pixels e.g. one pixel in the horizontal direction. Step then proceeds back to step where steps are repeated until all of the pixels in the composite image from the data cube have been included in at least one test window. If so step proceeds to step and the method is finished.

The test window can virtually move by one pixel in the horizontal direction until an entire row of windows across the target area have been encased in a test window. The test window then moves back to the beginning of the row moves down one pixel and then proceeds horizontally across the target area until all of the pixels are included in at least one test window and more typically multiple test windows. While it may be preferable that the test window is moved in single pixel increments in some embodiments other increments of moving the test window may be utilized without deviation from the spirit or scope of the invention.

It is noted that other known covariance tests might be used to calculate the global and or local covariance as alternatives to those discussed above.

In practice the method of the present invention has been found to detect the presence of manmade or artificial objects from the natural background clutter in a target area with very low probability of error.

Once manmade objects targets are automatically detected using the methodology in this invention the spatial locations of these potential targets in the composite image may be passed forward in the form of emphasized locations on a display or as a sound alert for a higher level decision by the user. Or they are passed forward to another machine for further processing for instance the targets spatial locations may be used as the focus of attention for additional processing by some other more advanced pattern recognition method that attempts to perform target identification tasks. An effective focus of attention methodology can significantly reduce the number of false positives in advanced automatic target recognition systems.

The comparison of the covariance of the test windows with the global covariance of the composite image of the target area has proven successful in discriminating manmade objects from natural objects without the necessity of human analysis and with very low error rates. And since this invention does not assume knowing a priori the scales spatial areas of objects in the imagery this invention is suitable for uncontrolled outdoor environment in typical airborne or fixed surveillance applications from a nadir viewing perspective or from a slant viewing perspective it works for close short and far ranges.

Although the performance of the present invention is range independent there is a practical limit. The scale of any given target in the spatial area of the input image must be sufficiently large relative to the test window size so that the radiances of the given target can have an impact on the local covariance estimation. It is believed that in the case of a target scale being smaller than some 25 of the test window area the impact of this target on the estimation of the local covariance will likely decrease. This case could cause the local covariance to be more similar to the global covariance. Target scales greater than the test window area are fine which reinforces the claim of range independent performance of the present invention.

Since the entire method of the present invention is carried out by a programmed computer the method of the present invention may be rapidly practiced without human intervention or the introduction of human error. Additionally the method of the present invention is able to accurately differentiate manmade objects from natural objects regardless of the time of day.

Having described our invention however many modifications thereto will become apparent to those skilled in the art to which it pertains without deviation from the spirit of the invention as defined by the scope of the appended claims.

