---

title: Traffic flow classification
abstract: Systems and methods are disclosed for classifying traffic flows. A traffic agent operable to collect classification information for one or more traffic flows may be deployed at an end host communicatively coupled to a data-center network. The traffic agent, deployed in a user space independent of the operating system, may compare the classification information for a given traffic flow to a metric value. Where the classification information achieves a certain threshold indicated by the metric value, the traffic agent may classify the traffic flow as an elephant flow. In some examples, a library may be included with the traffic agent that may include a modified send function. The modified send function may provide classification information to the traffic agent indexed to the traffic flow for which it is called so that the traffic agent may analyze the classification information to potentially provide a classification for the traffic flow.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09426072&OS=09426072&RS=09426072
owner: ROBIN SYSTEMS, INC.
number: 09426072
owner_city: San Jose
owner_country: US
publication_date: 20140321
---
This application claims the benefit of and hereby incorporates by reference U.S. Provisional Application Ser. No. 61 876 045 filed on Sep. 10 2013.

This invention relates to networking and more particularly to the classification of traffic flows in data center networks.

Traffic across a data center network may be characterized in terms of traffic flows. A traffic flow may be thought of as a series of interrelated frames or packets sent from a common source computer in the data center network to a common destination in the data center network. Traffic flows may come in many different sizes. Typically most traffic flows are short in duration and or bursty. Such short traffic flows are often referred to because of the relatively small times and or amounts of information being transferred by these traffic flows as mice flows Other traffic flows however may transfer larger amounts of information potentially over longer periods of time. On account of the relatively large amounts of time involved and or the relatively large amounts of information being transferred during these relatively large traffic flows these large traffic flows are often referred to as elephant flows. 

The presence of these differing types of traffic flows in a common data center network may have implications for the performance of the data center network. Although elephant flows are typically more rare than mice flows typically the majority of the packets being transferred in a data center network pertain to elephant flows. The presence of such elephant flows across a substantially fixed path in the data center network for a relatively long amount of time may for example cause congestion in the data center network.

It will be readily understood that the components of the present invention as generally described and illustrated in the Figures herein can be arranged and designed in a wide variety of different configurations. Thus the following more detailed description of the embodiments of the invention as represented in the Figures is not intended to limit the scope of the invention as claimed but is merely representative of certain examples of presently contemplated embodiments in accordance with the invention. The presently described embodiments will be best understood by reference to the drawings wherein like parts are designated by like numerals throughout.

Referring to a portion of a data center network is depicted. The data center network may be deployed with one or more switches routers hubs and or the like . These network devices may be communicatively connected to one another by one or more uni or bi directional links as depicted in . As can be appreciated the topography depicted in is not limiting. The data center network and or the network devices therein may facilitate without limitation east west traffic flows. For example as discussed below the data center network and or the network devices may facilitate east west traffic flows in the sense of flows between servers in the data center . However north south flows such as without limitation flows between one or more clients and one or more servers and or other hierarchical flows may be possible.

A network host also referred to as an end host may be connected to the data center network via one or more uni or bi directional links. Furthermore a network host may be any form of computing device connected to the data center network capable of providing data receiving data storing data and or processing data for and or from a user and or other node in the data center network . Without limitation and for purposes of illustration only a server may provide an example of a network host . Another non limiting example may include a set of Solid State Drives SSDs .

Processes common in data center networks such as cloning backup virtual machine migration and the shuffle phase of a Hadoop implementation to name a few non limiting examples may generate a large traffic flow such as an elephant flow . The portion of the data center network depicted in is depicted with an elephant flow . The elephant flow is denoted with an elephant symbol and the series of thick bold lines describing a path through the data center network for the elephant flow from a network host in the first set of network hosts through a first switch a second switch a third switch and a fourth switch to another host in another set of end hosts in the data center network .

Within the data center network a physical end host such as the top most end host of the fourth set of end hosts may serve as a source and or a destination for one or more traffic flows with a source Internet Protocol IP address and or destination IP address. In such examples the end host may support multiple ports . A port may be a communication endpoint that may serve to provide a software construct specific to an application and or process to allow the specific application and or process to facilitate the sharing of a physical connection for the host to a packet switched data center network . Furthermore a port may facilitate one or more transmission layer protocols such as without limitation Transmission Control Protocol TCP .

An individual port may have a unique identification number such as without limitation a sixteen bit port identification number. A unique traffic flow may be defined by a unique combination such as without limitation a unique tuple such as without limitation representing a single connection between source and destination. As can be appreciated there may be multiple traffic flows between the same source and destination where the multiple traffic flows may be at least in part differentiated by one or more port numbers involved. In some embodiments a traffic flow may also be defined by a corresponding transport layer protocol used in the connection for the traffic flow. A traffic flow within a physical node such as without limitation an end host can be defined by a unique tuple such as without limitation a tuple of the form discussed above.

A large flow or an elephant flow may be defined in many different ways. For example such flows may be defined in terms of an interval of time over which a traffic flow persists. They may be defined in terms of a data rate for a traffic flow derived by an amount of data transferred in a given time interval. An additional non limiting example may include an aggregate size of data transferred during the flow. A further non limiting example may include a known process for large flows to which a given traffic flow belongs.

Values for one or more of these metrics may vary according to the data center network . Indeed values may be changed dynamically according to network needs. However one non limiting way to begin to think about determining such values provided by way of example and not limitation may include determining a value for one or more metrics such as data transmitted transmission rate and or flow duration below which a certain percentage of traffic flows say for example 80 or 90 can be characterized. In such examples an elephant flow may be considered to be any traffic flow above this value.

Additionally or in the alternative in some examples a value may be arrived at by looking at a certain percentage of packets or data that are transmitted in the data center network for one or more values for one or more metrics. Since elephant flows although more rare than mice flows often transmit the majority of packets one or more values may be determined where the predetermined percentage of packets or data is transferred by traffic flows with values at or above those selected. By way of another non limiting example one or more values may be selected and or fine tuned in relation to effects on network performance.

Non limiting examples of values for exemplary metrics within a non limiting example of a data center network may include 1 MB of data with respect to size 5 MBps with respect to a rate and or 100 micro seconds with respect to duration. As can be appreciated however any number of different values may be selected for a wide variety of metrics based on different types of data center networks and or demands placed on such data center networks . Indeed in some examples different categories of large elephant flows may be defined such as by way of example and not limitation baby elephant flows regular elephant flows and or extra large elephant flows.

Also depicted in is a mouse flow . The mouse flow indicated by the mouse symbol describes a path through the data center network indicated by the series of slightly emboldened connections from a network host within the first set of network hosts to a first network device to a second network device to a third network device to another edge device and then to another network host in a second set of network hosts . A mouse flow may also be defined in many different ways. For example a mouse flow may be any flow that is not an elephant flow . However in other examples in which more than two types of traffic flows are possible a mouse flow may be specifically defined. Such definitions may be arrived at by evaluating considerations discussed above with respect to elephant flows from an inverse perspective. Additional considerations may also play a role.

As can be appreciated both the elephant flow and the mouse flow not only enter the data center network through the same network device but they are directed from the common network device to a common second network device . This confluence of the elephant flow and the mouse flow may be problematic for a number of reasons. To aid in the discussion of potential problems a network buffer queue at the common entry edge device at which the confluence occurs is depicted in the expanded view provided for .

A network buffer queue may be an inbound network switch buffer queue an outbound network switch buffer queue or a logical combination of the two. Similarly analogous network buffers may be described with respect to routers and or other types of network devices . Different buffers may correspond to multiple different paths through a network device . A network buffer may be implemented as a First In First Out queue and or shared memory for storing frames in examples involving switches packets in examples involving routers and or the like.

As indicated by the large clock symbol of the elephant flow relative to the size of the clock symbol associated with the mouse flow the duration of the elephant flow may be relatively large. Because of the a large duration of the elephant flow which may have been initiated prior to the mouse flow one or more buffers relevant to the confluence of the elephant flow and the mouse flow may fill up with several elephant frames packets . A subsequent mouse frame packet may therefore need to wait for one or more of these elephant frames packets before being transmitted.

Unfortunately not only may such waits arising from the presence of an elephant flow slow down one or more mouse flows but mice flows may typically be associated with processes that may be sensitive to latency. The higher sensitivities to latency associated with mice flows therefore may result in additional negative implications. Further the greater prevalence of mice flows which may account for without limitation 90 of traffic flows in the data center network may mean that many mice flows may be negatively impacted by a single elephant flow . Because despite their relative scarcity elephant flows may account for as much as 90 of the data transmission in a data center network the periods of time during which an elephant flow may congest one or more network paths may often be significant.

Furthermore in scenarios where an elephant flow contributes to the filling up of a network buffer data from one or more additional mouse flows and or elephant flows may not be transmitted and or stored in the relevant network buffer as indicated by the circle symbol with a bar through it. As a result either a frame packet currently in the buffer s memory will need to be dropped or the incoming frame packet will be dropped. Of course either scenario is undesirable.

Additionally approaches to traffic engineering commonly applied in data centers such as Equal Cost Multi Path ECMP while well suited to large numbers of mice flows without elephant flows may not be well suited to optimize performance in data center networks with one or more elephant flows . Such mice flow approaches may do little to orchestrate specific paths for individual mice flows . The short durations of mice flows may not lend themselves to orchestrating such individualized paths.

The longer durations of elephant flows however may provide many opportunities to improve the performance of data center networks in which they may occur through orchestrating specific paths for one or more of such elephant flows and or other traffic flows in relation to the elephant flow s . However achieving such performance gains and or mitigating the problems discussed above may first require the identification of an elephant flow . The following figure discusses various previous approaches to identifying detecting and or classifying large flows and or elephant flows together with discussions revealing shortcomings of such approaches.

Referring to portions of a data center network are depicted together with approaches to the detection identification and or classification of elephant flows . The portion of the data center network may include network devices such as switches routers hubs and the like together with one or more sets of network hosts . In some examples such as examples where the network is configured to operate with open flow the network may include a controller operable to dynamically alter tables and or flow paths in the data center network . The controller may be utilized to optimize performance by dynamically altering tables at network devices to configure flow paths in ways that may reduce congestion that may arise from the presence of one or more elephant flows once one or more elephant flows are detected.

To detect large flows previous approaches such as HEDERA and HELIOS have included something like a monitoring module . A monitoring module may be configured to maintain statistics for individual traffic flows. Such statistics may measure sizes rates and or the like for individual traffic flows. Periodic polling of these statistics may be performed by a controller either by requesting or receiving the statistics from one or more network devices in such scenarios. The controller may learn therefore of traffic flows with large values with respect to one or more relevant metrics. For example the large values for the first and the sixth statistical units in are indicative of elephant flows .

Such approaches however may require significant amounts of overhead at individual switches and or network devices to track individual traffic flows. Such overhead may include individual flow table entries for each traffic flow being monitored. Considering that a network device in a data center network with a thousand or so network hosts may see tens of thousands of flow arrivals per second the overhead requirements can be significant. As the size of the data center network increases the size of the overhead required may grow exponentially preventing such approaches from being scalable. Furthermore the limited bandwidth available on links between network elements and or network elements and the controller may create a traffic management bottleneck.

Sampling approaches provide an alternative that may be more scalable. According to such approaches a collector module at the controller may obtain information from sample frames packets from the various ports at a switch or other network device . Some of such approaches rely on sampling features such as sFlow to collect this polling information which may include header information for the sampled frames packets . By sampling frames packets as opposed to tracking individual traffic flows sampling approaches may be able to reduce overhead.

However the rates at which sampling is performed such as one in a thousand packets per frame to keep overhead down and reduce data transfers to the collector module and or controller reduce the accuracy with which an elephant flow may be detected. What is more sampling the frames packets at such rates means that large numbers of frames packets must be transmitted for a sufficiently large fraction of those frames packets to allow a an elephant flow to be detected in the sample information provided to the collector . For example in scenarios consistent with a sampling rate of one in a thousand an elephant flow may need to transmit ten thousand frames packets or about fifteen megabytes of data before the elephant flow may be reliably detected. Therefore some elephants may not be detected and where they are detected they may have already congested the network for a significant period of time. Furthermore such sampling approaches require significant overhead at the controller .

In scenarios where one or more end hosts support virtualization and a v switch for multiple Virtual Machines VMs statistics may be collected at the v switch . Indeed open v switch already supports per flow granularity. However this v switch approach is only applicable where v switches are supported. Such an approach cannot be applied ubiquitously across a data center network that may include network hosts that do not support v switchs a possibility that increases with the size of the data center network . Furthermore v switchs are typically implemented in hypervisors. Therefore reliance on v switches may impose the lack of flexibility delays additional overhead and reduced numbers of VMs typically associated with hypervisors on the data center network . Perhaps software switches could be developed to sit outside of a hypervisor but such solutions would themselves require significant overhead for their implementation.

Furthermore the proceeding approaches all rely on detection at the data center network which is inherently removed from the hosts where traffic flows originate. If a system waits until a traffic flow is already introduced into the data center network before classifying the traffic flow as an elephant flow the elephant flow will already impact the data center network before the detection process can even begin. To address this inherent latency with network based approaches some approaches rely solely on applications running at the network hosts and or the VMs to classify traffic flows.

In such examples an application may be provided with something like an identification module . Since applications are responsible for generating traffic flows applications are in a good position to have knowledge about the size duration rate and such characteristics of the flows. Therefore applications may be configured to determine whether a frame packet belongs to a large elephant flow based on predetermined criteria. The identification module may identify frames packets that meet the criteria and tag them with an identifier for example with a set of bits in a header space.

Although such approaches address the classification problem with little demand upon a data center network they can present many logistical challenges. For example individual applications must be tailored to provide handle such classification. Furthermore the criteria for large elephant flows may vary from data center network to data center network and or within a single data center network over time. Establishing and or updating such criteria across a data center network is a non trivial matter. This is particularly true in data centers making such approaches unpractical.

As can be appreciated previous approaches to the detection identification and or classification of large elephant flows present significant drawbacks that make their application problematic and or impractical for many data center networks . Such drawbacks include overhead in the data center network inflexibility latency in classification reliability issues and logistical challenges among others. Therefore novel approaches for addressing these issues are required. A brief overview of some of such innovations is provided below.

In some examples a traffic agent may be operable to be deployed at an end host communicatively coupled to a data center network removing the need for overhead at switches and or network devices overhead that would be greater at the switches due to the number of network hosts and or nodes to which they connect. The traffic agent may be further operable to be deployed within a user space independent of a kernel space of an operating system running on the end host . The user space may also store one or more additional applications. Such a traffic agent may be operable to monitor traffic flows originating at the end host .

To assist in the monitoring of traffic flows a collection module may be provided within the traffic agent. The collection module may be operable to collect packet classification information for one or more traffic flows originating at the end host . Furthermore a classification module may be provided within the traffic agent. The classification module may be operable to classify an individual traffic flow from the one or more traffic flows as an elephant flow where one or more values of the classification packet information for the individual traffic flow exceeds a corresponding threshold value for a flow metric.

In some examples a library may be added within the traffic agent. A send function may be provided with the library. The send function may be operable to send one or more frames packets pertaining to the individual traffic flow from a socket at the end host . In such examples the collection module may include the portion of the send function operable to copy classification packet information from a call to the send function for classification analysis by the classification module.

Certain examples may include a traffic agent. The traffic agent may further be operable to be deployed within a user space independent of a kernel space of an operating system on an end host. The traffic agent may be operable to monitor multiple computing instances supported by the end host . In such examples the collection module may further be operable to collect classification packet information for individual traffic flows from the multiple virtual computing instances which may be VMs . Additionally the classification module may further be operable to compare the classification packet information collected for the traffic flows from the multiple virtual computing instances to the threshold value for the flow metric. By means of the comparisons the classification module may make individual determinations with respect to individual traffic flows to classify a subset of the individual traffic flows as one or more elephant flows .

As can be appreciated many of the functionalities discussed with respect to previous approaches to elephant flow classification and with respect to many of the new functionalities discussed with respect to the novel and innovative approaches disclosed herein are described as taking place at modules. Throughout this application the functionalities discussed herein may be handled by one or more subsets of modules. With respect to the modules discussed herein aspects of the present innovations may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a module. Furthermore aspects of the presently discussed subject matter may take the form of a computer program product embodied in any tangible medium of expression having computer usable program code embodied in the medium.

With respect to software aspects any combination of one or more computer usable or computer readable media may be utilized. For example a computer readable medium may include one or more of a portable computer diskette a hard disk a random access memory RAM device a read only memory ROM device an erasable programmable read only memory EPROM or Flash memory device a portable compact disc read only memory CDROM an optical storage device and a magnetic storage device. In selected embodiments a computer readable medium may comprise any non transitory medium that may contain store communicate propagate or transport the program for use by or in connection with the instruction execution system apparatus or device.

Computer program code for carrying out operations of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. Aspects of a module and possibly all of the module that are implemented with software may be executed on a micro processor Central Processing Unit CPU and or the like. Any hardware aspects of the module may be implemented to interact with software aspects of a module.

Referring to a system for classifying traffic flows at an end host is depicted. A traffic agent which may be implemented as a module is depicted. The traffic agent may be operable to be deployed at the end host and may be operable to classify traffic flows. The end host may be communicatively connected to a data center network as depicted in by the communication links between the end host and the switch .

Placing the traffic agent at the end host to perform classification operations at the end host may remove the need for overhead within the data center network such as at high density switching Application Specific Integrated Circuits ASICs where elephant flows have traditionally been detected. Network elements lend themselves to detection operations because this is where such elephant flows are actually handled and directed along their flow paths. Furthermore a single network element may be configured to perform such detection without any assumptions about the network end hosts where the elephant flows are generated. However as data center networks become larger and larger the required overhead becomes more and more significant and even limiting.

As discussed above previous approaches to remove the load of classification operations from the data center network have relied upon the applications residing at end hosts themselves to classify the frames packets that they generate. However relying on applications requires insuring that applications will provide this functionality a logistical impossibility for many scenarios. One possible solution may be to provide an application independent traffic agent as proposed above at individual end hosts .

Regardless of the independence of such a traffic agent from applications placement of the detection operations at end hosts may involve configuring all substantially all or a significant number of such hosts to perform classification operations. Such levels of participation by end hosts may be logistically involved. As coordination among end hosts increases generally however certain levels of participation for end hosts in configurations for such coordinated activities may already be present and would be less complicated than enabling multiple applications at multiple hosts to perform these functions.

Various approaches to traffic engineering provide non limiting examples of such coordination. Approaches to providing classes with different levels of priority for traffic provide additional examples. Also end hosts in a data center network making use of a Hadoop approach may be configured to support task trackers and or data nodes consistent with a Hadoop framework. In some examples software may be provided to these end hosts operable to support such aspects of the Hadoop framework. Therefore a sufficiently light weight traffic agent may be provided with such software to be deployed to provide coordinated capabilities at a cluster of network hosts in a data center network . In other examples the traffic agent may be deployed independently.

An end host on which a traffic agent may be deployed may also have an operating system deployed thereon. Such a traffic agent may be operable to reside within user space . Deploying the traffic agent within the user space may be counterintuitive.

As discussed in more detail below one or more socket buffers from which information about traffic flows may be gleaned may typically reside within a kernel space for an operating system . Combining the traffic agent with an operating system deployed on network hosts to support the functionalities of those network hosts may remove logistical concerns about the installation of the traffic agent across network hosts in the data center network . However as discussed in greater detail below approaches that rely on the operating system may reduce overall flexibility.

The traffic agent may be operable to monitor one of more traffic flows generated at the end host indefinitely and or for a period of time. Furthermore the traffic agent may be operable to compile classification information for a traffic flow and or compare the classification information for the traffic flow to one or more values for one or more metrics. Where the classification information achieves a predetermined level relative to the one or more values for the one or more metrics for the given traffic flow the traffic agent may classify the given traffic flow as an elephant flow .

By placing the traffic agent to handle the classification of traffic flows within user space some examples may take advantage of the proximity to the application layer . In such examples the traffic agent and or an application interference module may access information relevant to the classification of a traffic flow that is not available in the kernel space . The traffic module may access such information via a collection module . The application information module which is discussed in more detail below with respect to may reside apart from or within the traffic agent and or the collection module . For purposes of providing non limiting examples such information may include information identifying a job to which a traffic flow pertains and or information identifying a particular application that triggers the traffic flow. The traffic agent may include the information it obtains in this way with the classification information .

The traffic agent possibly via the classification module may utilize aspects of the classification information obtained from the traffic agent s proximity to the application layer in the classification of the traffic flow to which the classification information pertains. For example the classification module may without limitation base a classification entirely on such information may use such information to improve the reliability of a classification and or may use the information to provide a classification with a finer degree of granularity within the overarching category of an elephant flow .

As discussed above there may be multiple different kinds of elephant flows and information derived from a close proximity to the application layer may be used to differentiate among these different types of elephant flows allowing different types of elephant flows to be treated differently. Such examples can be distinguished from previous approaches relying on applications to handle classification by the ability of the traffic agent and or the collection module and or the classification module to perform analysis derive classifications handle updates interact and adapt to different applications and or more.

By way of example and not limitation such classification packet information may include values provided for parameters of the send function . Not by way of limitation with respect to identifying individual traffic flows classification packet information may include a socket name an associated socket one or more Internet Protocol IP addresses one or more port numbers an end to end protocol a domain name a pointer to a buffer containing data to be transferred and or the like. Also by way of example and not limitation with respect to classifying an individual traffic flow classification packet information may include a length of bytes to be transferred.

In some examples the traffic agent may be provided with a collection module operable to collect classification packet information for one or more traffic flows. In some but not necessarily all examples the collection module may accomplish the collection of classification packet information by means of a library with an altered modified send function . When a call is made to the send function indicating a given socket buffer the classification packet information may be coordinated to a traffic flow at least in part by the classification packet information discussed above.

More particularly in some examples where the traffic agent includes such a library the library may make up a socket Application Programming Interface API or portion thereof operable to interface with a socket buffer which may reside within the kernel space of the operating system . The socket buffer may pertain to a TCP connection at a network layer . Additionally such a socket buffer may pertain to a particular port for the network host and or a given VM . Such a socket buffer may be operable to buffer multiple packets for one or more traffic flows which may be either elephant flows and or mice flows until such packets depicted as the package box in are sent to the data center network as part of a given flow.

As stated such a library may be provided with a modified or altered send function . The modified or altered send function may be modified to include a portion of code operable to copy classification information from a call of the send function . By copying the classification information the send function may enable the given traffic flow to be compiled by the traffic agent as part of the monitoring of the given traffic flow as performed by the traffic agent . The overhead involved with such a library and or in such modifications to a send function would be as can be appreciated de minimus.

In examples where the collection module is not provided with a library with a modified send function as discussed above the collection module may further comprise a socket intercept module. The socket interface module may be operable to intercept function calls pertaining to a pre existing socket API. By intercepting these function calls the socket intercept module may be operable to allow the collection module to copy classification information relevant to a given traffic flow.

In some examples the classification information copied and collected from a call to the send function may be sufficient for a classification module which may be provided with the traffic agent to analyze and classify a traffic flow. However in certain examples the traffic agent may include an aggregation module within the traffic agent . The aggregation module may be operable to aggregate multiple sets of classification packet information for a common traffic flow for analysis by a classification module . Again the classification packet information may be coordinated to a traffic flow at least in part by the information in the classification packet information itself. The aggregation module may provide multiple sets of flow statistics to the classification module . The classification module may compare the flow statistics to one or more threshold values for one or more metrics. Where the classification module determines that the flow statistics for an individual traffic flow achieve or cross the one or more threshold values the classification module may classify the traffic flow as an elephant large flow .

Some examples may involve a timing module may within the traffic agent . The timing module may be communicatively connected to the collection module and or the classification module . Such a timing module may be operable to track a timing interval over which classification packet information may be collected by the collection module for a given traffic flow and or considered by the classification module for a particular instance of a classification determination.

As more and more data center networks are built around and or include virtualized computing environments the implications of such computing environments become relevant to assessing an approach to classification. Several implications may be discovered for the application of the innovative approaches discussed above in a virtualized computing environment. An exploration of these implications is provided below in the following figures.

Referring to a traffic agent is depicted residing in a user space at an end host that supports a virtual computing environment with multiple virtualized computing instances . The traffic agent is contrasted with a kernel module within an operating system that is also at an end host that also supports virtual machines . The kernel module may be operable to perform detection identification and or classification functionalities similar to those of the traffic agent but from within an operating system .

More intuitive approaches may place classification operations within the operating system closer to the socket buffers where classification packet information may be obtained. However a comparison with such operating system based approaches in a virtualized computing environment highlights implications for finding ways to handle classification operations within the user space . For example by placing the classification operations in the operating system in a kernel module such as in a shim the classification of traffic flows for individual VMs rely on VM specific operating systems for those individual VMs . These operating systems are often referred to as guest operating systems because of their presence on an underlying host . One or more application s may run above such operating systems .

A hypervisor provides individual guest operating systems with a virtual operating platform and oversees the execution of the guest operating systems . Therefore approaches involving guest operating systems entail the presence of a hypervisor whether a type one hypervisor running directly on the hardware of an end host or a type two hypervisor running on a host operating system . Although hypervisors may be useful in deploying operating systems of differing types such as LINUX and WINDOWS hypervisors have significant costs. In scenarios involving a kernel module within the operating system the kernel module may rely on the hypervisor to carry out its functionality.

Owing to this reliance on the hypervisor the kernel module requires a hypervisor and may even require a particular type of hypervisor imposing limitations for the integration of different types of systems within a data center network configured to perform such classification and the scalability of such approaches. By placing the traffic agent in the user space the traffic agent may sit in close proximity to the application layer . In such examples a library may sit transparently under applications to inspect traffic flows of those applications.

In other words the traffic agent may be hypervisor agnostic. A traffic agent that is hypervisor agnostic may work in several different systems which may be integrated to achieve scale. Indeed a virtualization environment such as an Operating System OS virtualization environment without a hypervisor may be employed.

In an OS virtualization environment once the operating system has been booted an operating system virtualization environment may support elastic resource allocation. In other words resources such as virtualized computing instances may be supported which may be added on the fly without having to shut down the host and or engage in volume resizing. Conversely an approach employing a hypervisor may require a shutdown of a VM to allow a guest operating system to handle new resources such as without limitation through disk volume resizing and or repartitioning.

By placing the traffic agent in the user space additional advantages may be obtained. For example less CPU and memory resources may be relied upon. Such efficiencies may be achieved at least in part by inspections of traffic flows near the application layer .

Since the traffic agent is within a user space the traffic agent may be made operable to interface with a range of socket types provided by a range of different operating systems . In this way the approach may become highly portable as indicated by the flash drive icon in the expanded view of the first virtualized computing instance . By way of providing some examples and not limitation a virtualized computing instance may be a VM or an isolated container .

Referring to an application interface module is depicted together with a traffic agent deployed on an end host . Although the application interface module is depicted alongside the traffic agent the application interface module may reside within the traffic agent. The operating system of the end host may support multiple virtualized computing instances . The traffic agent may be further operable to monitor a plurality of traffic flows from the multiple virtualized computing instances . In such examples the traffic agent may monitor multiple socket buffers associated with the plurality of traffic flows from the computing instances 

The traffic agent may correlate the statistical units for the various traffic flows generated by the virtualized computing instances into traffic flow source sets . The traffic flows may have corresponding statistical units that qualify as large flows and or elephant flows indicated by the check marks. Because of the correlation between traffic flow source sets and virtualized computing instances such elephant and or large flows may be indexed to the virtualized computing instances from which they originate.

To further take advantage of the placement of the traffic agent at the end host the traffic agent may be configured to coordinate with approaches where one or more applications engage in classification operations. In some examples the traffic agent may work in concert with an application interface module . In such examples the application interface module may reside within the traffic agent and or be in communication with the traffic agent . The application interface module may be operable to perform one or more of several operations. For example the application interface module may be operable to extract classification packet information for a subject traffic flow from a request made to the end host and or a virtual computing instance running on the end host to generate the subject traffic flow.

Alternatively or additionally the application interface module may be operable to query an application running on the end host and or a virtual computing instance running on the end host . The traffic agent may query the application running on the end host for classification packet information for a traffic flow from the application . The traffic agent may be operable to receive classification packet information for one or more subject traffic flows from the application . The application interface module may further be operable to communicate the packet classification information to the classification module .

Referring to and methods are depicted for detecting identifying and or classifying traffic flows. The flowcharts in and illustrate the architecture functionality and or operation of possible implementations of systems methods and computer program products according to certain embodiments of the present invention. In this regard each block in the flowcharts may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It will also be noted that each block of the flowchart illustrations and combinations of blocks in the flowchart illustrations may be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

Where computer program instructions are involved these computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that may direct a computer or other programmable data processing apparatus to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instruction means which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program may also be loaded onto a computer or other programmable data processing apparatus to cause a series of operation steps to be performed on the computer or other programmable apparatus to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

Referring to methods are depicted for classifying a traffic flow as a large flow and or an elephant flow at an end host . Such methods may begin by collecting classification packet information for a traffic flow. The collection may be performed from within a user space at an end host communicatively coupled to the data center network . Such methods may proceed by comparing the classification packet information for the traffic flow to one or more values for one or more flow metrics.

A determination may be made as to whether the traffic flow achieves one or more threshold values with respect to the relevant metric value s . Where the answer to the determination is YES such methods may classify the traffic flow as a large flow and or an elephant flow and then end . As used herein the phrase to achieve a value may mean to equal that value or be greater than the value in some cases. In other cases the phrase may mean to equal that value or be less than that value. Where the answer is NO the methods may end . In some examples however where the answer is NO the methods may classify the traffic flows as some other type of flow such as a mouse flow .

Certain examples of the methods may inform classification of one or more traffic flows originating at the end host based on a flow type and or a priori information about that flow type. Also in examples of such methods employed in computing environments involving virtualization the collection step may involve collecting a set of classification packet information for each traffic flow of a plurality of traffic flows generated by a plurality of virtualized computing instances residing at the end host . In such methods the comparison step may involve comparing one or more values to of the set of classification information for each traffic flow of the plurality of traffic flows individually to the one or more predefined values for one or more flow metrics. By applying the determination step and or the classification step such examples of these methods may classify one or more large traffic flows achieving the flow metric value.

Referring to methods are depicted for collecting and aggregating packet classification information with a modified send function over a period of time for classification of a corresponding traffic flow. Such methods may begin by accessing a send function for a given traffic flow. In such examples methods may copy acquire packet classification information from a call to a send function for a given traffic flow to send frames packets from the end host over the data center network . Additionally a library may be provisioned to an end host that may include a send function operable to send frames packets from a socket at the end host and to copy capture classification information related to those frames packets .

A determination may be made about whether previous information has been collected and or copied for the given traffic flow. In such examples where the answer to the determination is NO the packet classification information may be recorded . Where that answer to the determination is YES the copied packet classification information may be aggregated with the previous information for the given traffic flow. Therefore packet classification information pertaining to a common traffic flow may be aggregated for classification analysis.

A determination may be made as to whether a threshold has been achieved by one or more values for the copied packet classification information and or previous information with respect to one or more metrics for traffic flows such as those discussed above. Where the answer to the threshold determination is YES such methods may classify the given traffic flow as a large flow and or an elephant flow and the processes may end . In certain examples classification may be informed by classification information of the traffic flow originating at the end host based on information about the traffic flow from an application generating the traffic flow. Where the answer to the determination is NO yet another determination may be made as to whether a time period for collecting information for the given traffic flow has expired.

Such examples may involve limiting collection of packet classification information for the given traffic flow for classification of the given traffic flow relative to one or more flow metrics to a set time period. Where the answer to the time period determination is NO methods may return to accessing a send function and or copying packet classification information . Where the answer is YES and the time period of the given traffic flow has expired methods may end .

In some of such examples methods may further involve dynamically changing the time period in response to conditions in the data center network . For example a time period may be increased or decreased to such as by way of a non limiting example according to a machine learning algorithm to improve network performance with respect to one or more metrics in response to different load conditions on the data center network .

It should also be noted that in some alternative implementations the functions noted in the blocks may occur out of the order noted in the figure. In certain embodiments two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. Alternatively certain steps or functions may be omitted if not needed.

The present invention may be embodied in other specific forms without departing from its spirit or essential characteristics. The described embodiments are to be considered in all respects only as illustrative and not restrictive. The scope of the invention is therefore indicated by the appended claims rather than by the foregoing description. All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.

