---

title: Computing device and an apparatus having sensors configured for measuring spatial information indicative of a position of the computing devices
abstract: Sensor fusion algorithm techniques are described. In one or more embodiments, behaviors of a host device and accessory devices are controlled based upon an orientation of the host device and accessory devices, relative to one another. A combined spatial position and/or orientation for the host device may be obtained based on raw measurements that are obtained from at least two different types of sensors. In addition, a spatial position and/or orientation for an accessory device is ascertained using one or more sensors of the accessory device. An orientation (or position) of the accessory device relative to the host computing device may then be computed based on the combined spatial position/orientation for the host computing device and the ascertained spatial position/orientation for the accessory device. The relative orientation that is computed may then be used in various ways to control behaviors of the host computing device and/or accessory device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09619071&OS=09619071&RS=09619071
owner: Microsoft Technology Licensing, LLC
number: 09619071
owner_city: Redmond
owner_country: US
publication_date: 20140910
---
This application is a continuation of and claims priority under 35 U.S.C 120 to U.S. patent application Ser. No. 14 018 286 filed Sep. 4 2013 titled A Computing Device and an Apparatus Having Sensors Configured for Measuring Spatial Information Indicative of a Position of the Computing Devices which is a continuation of and claims priority under 35 U.S.C 120 to U.S. patent application Ser. No. 13 651 272 filed Oct. 12 2012 titled Sensor Fusion Algorithm which is a continuation of and claims priority under 35 U.S.C 120 to U.S. patent application Ser. No. 13 471 202 filed May 14 2012 titled Sensor Fusion Algorithm which claims priority under 35 U.S.C. 119 e to the following U.S. Provisional Patent Applications the entire disclosures of each of these applications being incorporated by reference in their entirety 

U.S. Provisional Patent Application No. 61 606 301 filed Mar. 2 2012 and titled Input Device Functionality 

U.S. Provisional Patent Application No. 61 606 333 filed Mar. 2 2012 and titled Usage and Authentication 

U.S. Provisional Patent Application No. 61 613 745 filed Mar. 21 2012 and titled Usage and Authentication 

U.S. Provisional Patent Application No. 61 606 336 filed Mar. 2 2012 and titled Kickstand and Camera and

U.S. Provisional Patent Application No. 61 607 451 filed Mar. 6 2012 and titled Spanaway Provisional. 

Mobile computing devices have been developed to increase the functionality that is made available to users in a mobile setting. For example a user may interact with a mobile phone tablet computer or other mobile computing device to check email surf the web compose texts interact with applications and so on. Some mobile computing devices may connect to and interact with various accessory devices to provide different input techniques extend functionality and so forth. One challenge that faces developers of mobile computing devices is managing behaviors and interaction with accessory devices. For instance a host computing device may have limited control over how an accessory device behaves and thus actions of the accessory may sometimes interfere with operation of the host computing device. Moreover the user experience may be adversely affected by accessory devices that do not respond in a manner that is consistent with the host computing device. Thus integrated management of behaviors and interaction for accessory devices may be a challenging consideration for developers of mobile computing devices.

Sensor fusion algorithm techniques are described. In one or more embodiments behaviors of a host device and accessory devices are controlled based upon an orientation of the host device and accessory devices relative to one another. A combined spatial position and or orientation for the host device may be obtained based on raw measurements that are obtained from at least two different types of sensors. In addition a spatial position and or orientation for an accessory device is ascertained using one or more sensors of the accessory device. An orientation or position of the accessory device relative to the host computing device may then be computed based on the combined spatial position orientation for the host computing device and the ascertained spatial position orientation for the accessory device. The relative orientation that is computed may then be used in various ways to control behaviors of the host computing device and or accessory device.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used as an aid in determining the scope of the claimed subject matter.

Traditionally a host computing device may have limited control over how an associated accessory device behaves. Thus actions of the accessory may sometimes interfere with operation of the host computing device which may detract from the user experience. Accordingly integrated management of behaviors and interaction for accessory devices may be a consideration for developers of mobile computing devices.

Sensor fusion algorithm techniques are described. In one or more embodiments behaviors of a host device and accessory devices are controlled based upon an orientation of the host device and accessory devices relative to one another. A combined spatial position and or orientation for the host device may be obtained based on raw measurements that are obtained from at least two different types of sensors. In addition a spatial position and or orientation for an accessory device is ascertained using one or more sensors of the accessory device. An orientation or position of the accessory device relative to the host computing device may then be computed based on the combined spatial position orientation for the host computing device and the ascertained spatial position orientation for the accessory device. The relative orientation that is computed may then be used in various ways to control behaviors of the host computing device and or accessory device.

In the following discussion an example environment and devices are first described that may employ the techniques described herein. Example procedures are then described which may be performed in the example environment and by the devices as well as in other environments and by other devices. Consequently performance of the example procedures is not limited to the example environment devices and the example environment devices are not limited to performance of the example procedures.

The computing device for instance is illustrated as including an input output module . The input output module is representative of functionality relating to processing of inputs and rendering outputs of the computing device . A variety of different inputs may be processed by the input output module such as inputs relating to functions that correspond to keys of the input device keys of a virtual keyboard displayed by the display device to identify gestures and cause operations to be performed that correspond to the gestures that may be recognized through the accessory device and or touchscreen functionality of the display device and so forth. Thus the input output module may support a variety of different input techniques by recognizing and leveraging a division between types of inputs including key presses gestures and so on.

In the illustrated example the accessory device is a device configured as a keyboard having a QWERTY arrangement of keys although other arrangements of keys are also contemplated. Further other non conventional configurations for an accessory device are also contemplated such as a game controller configuration to mimic a musical instrument a power adapter and so forth. Thus the accessory device may assume a variety of different configurations to support a variety of different functionality. Different accessory devices may be connected to the computing device at different times. Moreover functionally of a particular accessory device may also be adapted to assume different configurations and capabilities such as through different selectable modes software firmware updates modular add on devices components and so forth. This may cause changes in the way keys or other controls for an accessory are laid out and also change the way on which inputs from the accessory are handled by the host and applications. For example an accessory device may be operable as keyboard and as a game controller by adaptively switching the kinds of keys controls displayed labels and positions of controls to assume different configurations at different times.

As previously described the accessory device is physically and communicatively coupled to the computing device in this example through use of a flexible hinge . The flexible hinge represents one illustrative example of an interface that is suitable to connect and or attach and accessory device to a host computing device . The flexible hinge is flexible in that rotational movement supported by the hinge is achieved through flexing e.g. bending of the material forming the hinge as opposed to mechanical rotation as supported by a pin although that embodiment is also contemplated. Further this flexible rotation may be configured to support movement in one direction e.g. vertically in the figure yet restrict movement in other directions such as lateral movement of the accessory device in relation to the computing device . This may be used to support consistent alignment of the accessory device in relation to the computing device such as to align sensors used to change power states application states and so on.

The flexible hinge for instance may be formed using one or more layers of fabric and include conductors formed as flexible traces to communicatively couple the accessory device to the computing device and vice versa. This communication for instance may be used to communicate a result of a key press to the computing device receive power from the computing device perform authentication provide supplemental power to the computing device and so on. The flexible hinge or other interface may be configured in a variety of ways to support multiple different accessory devices further discussion of which may be found in relation to the following figure.

As further illustrated in the computing device may include various applications that provide different functionality to the device. A variety of applications typically associated with computing devices are contemplated including but not limited to an operating system a productivity suite that integrates multiple office productivity modules a web browser games a multi media player a word processor a spreadsheet program a photo manager and so forth. The computing device further includes multiple host sensors that are configured to sense corresponding inputs responsive to manipulation of the computing device . Likewise the accessory device includes one or more accessory sensors that are configured to sense corresponding inputs generated responsive to manipulation of the accessory device .

In accordance with techniques described herein input obtained from the host sensors and accessory sensors may be processed and or combined according to a suitable sensor fusion algorithm to resolve an orientation of the accessory device and computing device one to another. In general input regarding position and or orientation from multiple different types of sensors is processed in combination to compute the orientation. The computed orientation may then be used to control behaviors of the host and accessory and perform various corresponding operations. A variety of different types of sensors and algorithms suitable to resolve the orientation may be employed as discussed in greater detail in relation to the following figures.

To further illustrate consider which depicts generally at an example computing device of in greater detail. In the depicted example the computing device is shown in a stand alone configuration without an accessory device being attached. In addition to the components discussed in relation to the example computing device of further includes a processing system and computer readable media that are representative of various different types and combinations of processing components media memory and storage components and or devices that may be associated with a computing device and employed to provide a wide range of device functionality. In at least some embodiments the processing system and computer readable media represent processing power and memory storage that may be employed for general purpose computing operations. More generally the computing device may be configured as any suitable computing system and or device that employ various processing systems and computer readable media additional details and examples of which are discussed in relation to the example computing system of .

The computing device may also implement selected device functionality through one or more microcontrollers . The microcontrollers represent hardware devices systems that are designed to perform a predefined set of designated tasks. The microcontrollers may represent respective on chip systems circuits having self contained resources such as processing components I O devices peripherals various types of memory ROM RAM Flash EEPROM programmable logic and so forth. Different microcontrollers may be configured to provide different embedded applications functionality that are implemented at least partially in hardware and perform corresponding tasks. The microcontrollers enable performance of some tasks outside of operation of a general purpose processing system and other applications components of the computing device or accessory device. Generally power consumption of the microcontrollers is low in comparison with operating a general purpose processing system for a device.

As further depicted the computing device may further include a sensor fusion module a behavior module and a sensor fusion application programming interface API to implement aspects of sensor fusion algorithm techniques described herein. The sensor fusion module generally represents functionality to apply a suitable sensor fusion algorithm as described above and below to derive an orientation that is based on input from multiple sensors. The sensor fusion module may operate to collect inputs regarding positions orientation etc. supplied via the various sensors process the inputs and compute a corresponding orientation that describe the spatial relationship of the computing device and an accessory device .

The behavior module represents functionality to control and or modify a variety of different behaviors associated with the computing device and or accessory devices based on the computed orientation. This may include but is not limited to managing power states consumption selecting operational modes or device states adjusting sensitivity of one or more sensors controlling interaction between the host accessory and or peripheral devices modifying device functionality enabling disabling network connections activating deactivating applications and or setting application states to name a few examples. These and other examples of behaviors that may be controlled based on a computed orientation are described in greater detail in relation to the example procedures discussed herein below.

The sensor fusion application programming interface API represents functionality to expose information regarding the computer orientation for use by applications . For example applications may utilize the sensor fusion API to request orientation information on demand and or subscribe to orientation updates from the sensor fusion module and or an associated notification system. The sensor fusion API may then interact with the sensor fusion module on behalf of the application to cause orientation information to be conveyed to the application . Applications may use orientation information in various ways example of which may be found in the discussion of an example procedure of below.

As previously mentioned various different types of sensors may be employed to implement the techniques described herein. A host computing device may include an array of sensors used to provide orientation information. By way of example and not limitation the host sensors for the example computing device of are depicted as including a gyroscope an accelerometer a magnetometer and a Hall Effect sensor . Various other sensors suitable to derive information regarding the position and or orientation may also be employed.

The connection portion is flexibly connected to a portion of the accessory device that includes the keys through use of the flexible hinge . Thus when the connection portion is physically connected to the computing device the combination of the connection portion and the flexible hinge supports movement of the accessory device in relation to the computing device that is similar to a hinge of a book. Naturally a variety of orientations may be supported some examples of which are described in the following section.

The connecting portion is illustrated in this example as including magnetic coupling devices mechanical coupling protrusions and a plurality of communication contacts . The magnetic coupling devices are configured to magnetically couple to complementary magnetic coupling devices of the computing device through use of one or more magnets. In this way the accessory device may be physically secured to the computing device through use of magnetic attraction. The connecting portion also includes mechanical coupling protrusions to form a mechanical physical connection between the accessory device and the computing device . The communication contacts are configured to contact corresponding communication contacts of the computing device to form a communicative coupling between the devices to facilitate various kinds of communications.

Having discussed an example environment in which embodiments may operate consider now some example device orientations in accordance with one or more embodiments.

The following discussion presents some example device orientations. As detailed different device orientations can be associated with different device power states different application states trigger different behaviors and so forth. The example orientations as well as other orientations may be determined using sensor fusion algorithm techniques described above and below. A determined orientation may then be used to drive different behaviors for the host and or the accessory.

This wrapping causes a portion of a rear of the computing device to remain exposed. This may be leveraged for a variety of functionality such as to permit a camera positioned on the rear of the computing device to be used even though a significant portion of the rear of the computing device is covered by the accessory device in the example orientation . Further to the example illustrated in the display device of the computing device may be determined to be oriented at an angle relative to the accessory device . In general the angle may change as the accessory device is manipulated into different positions. For example the angle as shown in can be determined to be approximately degrees. Other orientations may correspond to other angles and angle ranges may be established and associated with defined modes or states that may trigger different behaviors. Thus behaviors may be controlled based on the particular mode state that correspond to the current angle between the host and accessory.

An angle range is illustrated which corresponds to a closed position for the computing device . Thus if the computing device is positioned at an angle within the angle range relative to the accessory device the computing device can be determined to be in a closed position. A closed position can include an associated closed state where various functionalities behaviors for the computing device and accessory device can be modified accordingly based on the closed state.

Further illustrated is an angle range which may correspond to a typing orientation for the computing device . Thus if the computing device is positioned at an angle within the angle range relative to the accessory device the computing device can be determined to be in a typing orientation. Within this orientation the computing device and or the accessory device can placed in a typing power state where functionalities behaviors for the computing device and accessory device can be customized accordingly based on the typing state.

The orientations angle ranges power states and so forth discussed above are presented for purposes of illustration only. It is contemplated that a wide variety of different orientations device states and angle ranges may be implemented within the spirit and scope of the claimed embodiments.

Having discussed some example device orientations consider now some example procedures in accordance with one or more embodiments.

The following discussion describes sensor fusion algorithm techniques that may be implemented utilizing the previously described systems and devices. Aspects of each of the procedures may be implemented in hardware firmware software or a combination thereof. The procedures are shown as a set of blocks that specify operations performed by one or more devices and are not necessarily limited to the orders shown for performing the operations by the respective blocks. In portions of the following discussion reference may be made to the example operating environment of the example devices of and the example orientation shown in respectively.

Raw spatial positions for a host computing device are calculated independently using at least two different types of sensors block . The raw spatial positions are processed to obtain a combined spatial position for the host computing device block .

For example the sensor fusion module may be configured to implement a designated sensor fusion algorithm. Generally the sensor fusion algorithm is configured to aggregate information from an array of different kinds of host sensors employed by a computing device . The aggregation of multiple different sensing techniques and types of sensors may provide improved resolution of positions and may smooth errors that may be introduced by individual techniques and sensors. In at least some embodiments the sensor fusion algorithm is configured to calculate at least two independent computations of the raw spatial position of the computing device using different respective sensors. Multiple independent computations of the raw position may then be used to produce a combined spatial position. Each of the independent computations may employ one or more of the various types of host sensors described above and below. At least some of the sensors used for different independent computations are of different types. Thus the sensor fusion algorithm obtains input from a variety of different host sensors and combines this information to resolve the position of the computing device .

In one approach the computing device includes a gyroscope that may be used to obtain one of the independent computations of the raw position. Generally a gyroscope uses principles of angular momentum to calculate orientation and rotation. The gyroscope can be used to recognize movement within three dimensional space and may enable determination of position with respect to a reference object point such as the earth. Using input obtained from the gyroscope the sensor fusion module may operate to compute a raw spatial position for the computing device. The raw spatial position may be expressed as coordinates in a three dimensional coordinate system defined with x y and z axes relative to the reference object point e.g. the earth .

In particular the angular velocity input obtained from the gyroscope can be processed to determine angular positioning of the computing device. Initially the input from the gyroscope may be filtered to remove a low pass constant offset of the gyroscope. Such a low pass constant offset may be created if the gyroscope is stuck in a non zero position and is removed to prevent inaccuracy in the computation. The algorithm may integrate over multiple axes of the gyroscope e.g. x y and z axes to obtain a transform that describes a raw spatial position for the computing device. This processing may involve integrating angular velocity input from the gyroscope through a Runge Kutta integration algorithm or other suitable algorithm to obtain corresponding impulse data. The impulse data may be expressed as quaternions for the different axes which when multiplied together produce a quaternion that describes a transformation between the computing device and the earth or other selected reference object point with respect to their respective axes coordinate systems. This provides one independent version of the raw spatial position for the computing device .

Another independent computation of the raw spatial position may be obtained using an accelerometer and a magnetometer in combination. Here the accelerometer is configured as a three axes accelerometer that may be employed to derive two of the degrees of freedom of the device e.g. position with respect to the x axis and y axis . In the low pass the vector of acceleration is approximately 1 g down pointing to the center of the earth. The components of acceleration measured via the accelerometer may be obtained as distributed across each of the three axes. The components of acceleration can in turn be used to compute angles of the accelerometer device axes with respect to the low pass vector that points to the center of the earth. This provides two of the three degrees of freedom with respect to tilt or orientation of the device. In particular the accelerometer processing just described is used to resolve the tilt orientation of the x axis and y axis of the computing device .

Now the magnetometer may be employed to resolve the remaining degree of freedom with respect to tilt orientation of the device. The magnetometer may be initialized configured to act like a compass. In this approach the magnetometer can be used to compute a vector that is parallel to the ground e.g. the earth s surface . This vector points to magnetic north and can be used to determine rotation of the device with respect to the z axis. Now the tilt orientation of the x axis and y axis from the accelerometer and the rotation of the device with respect to the z axis from the magnetometer may be used to construct another quaternion that describes a transformation between the computing device and the earth or other selected reference object point with respect to their respective axes coordinate systems. This provides another independent way in which a raw spatial position for the computing device may be obtained. Other examples using different sensors and combination of sensors are contemplated. For example a global positioning satellite GPS radio may be used to provide some positioning data that may be used alone or in combination with other kinds of sensor data to compute the position orientation of the computing device .

Accordingly at least two different results for the raw spatial position are computed using the foregoing example techniques or other suitable techniques. The sensor fusion algorithm may be further configured to combine multiple independent computations of raw spatial position in various ways. The combining generally involves interpolating between two or more raw spatial positions to reduce or eliminate inaccuracies and or smooth the results. The interpolation produces a combined spatial position for the computing device that is based on two or more independently obtained raw spatial positions.

By way of example and not limitation results obtained using a gyroscope may be more precise in the short term relative to other sensors and position determination techniques. However small integration errors associated with the gyroscope computations may build up over time creating an increasingly larger offset that may result in inaccurate results in the long term. Thus interpolating the gyroscope results with other independently obtained results can effectively adjust for expected integration errors in the gyroscope results. In one approach a normalized linear interpolation is employed that may be biased towards the gyroscope results since these results are initially more precise and subject to less noise. Other independent results such as the results from the accelerometer magnetometer may be included in the interpolation to keep the gyroscope results in check and slowly adjust the bias for the combined result away from the gyroscope results and towards the other results over time. This produces a mathematically smooth transformation as the combined result.

A spatial position for an accessory device connected to the host computing device is ascertained using one or more sensors of the accessory device block . The spatial position for the accessory device may be computed in any suitable way including but not limited to the techniques described in relation to the computing device . Accessory sensors for different accessories may include any of the various types of sensors described herein. Accordingly different corresponding techniques may be used to ascertain spatial position of the accessory based on appropriate input from one or more accessory sensors . Different techniques may also be employed for different accessories based on the types of sensors that are included with the accessory. In general the sensor fusion module may be configured to obtain input from different sensors of the accessory over a suitable interface with the accessory and compute a corresponding spatial position based on the input.

In one particular example the sensor fusion module may compute a spatial position using an accelerometer associated with the accessory device . In this approach the accelerometer may be employed to resolve the tilt orientation with respect to the x axis and y axis of the accessory device . This may occur in a manner that is comparable to the computation of the same kind of information for the computing device using an associated accelerometer as described above.

In some arrangements the accessory device may be configured to connect to the computing device using a connection portion that is connectable to an interface of the computing device via a known location. For instance in the hinge example previously described at least some information regarding the position of the accessory device may be established based upon the known location and nature of the connection to the host device. Thus it may be sufficient to use the two degrees of freedom e.g. x axis and y axis position pitch and roll for the accessory device in such cases to resolve the position of the accessory relative to the host. It should be noted though that rotation with respect the z axis may also be computed for the accessory device in some embodiments using a magnetometer as discussed previously or using other sensors and techniques. This may be employed in configurations in which an accessory may still be manipulated in three dimensions even when connected to a host device such as by way of a ball and socket type connection.

An orientation of the accessory device relative to the host computing device is computed based on the combined spatial position for the host computing device and the ascertained spatial position for the accessory device block . The computed orientation may correspond to any of the different orientations discussed in relation to as wells as other possible orientations. Here a comparison can be made between the combined spatial position for the computing device and the ascertained spatial position of the accessory device to derive information regarding the orientation of the device one to another. In particular the combined spatial position indicates a transformation between how axes in a coordinate system for the computing device are oriented relative to axes associated with a reference coordinate system for the earth or other reference. Similarly the ascertained spatial position of the accessory device indicates a transformation between how axes in a coordinate system for the accessory device are oriented relative to axes of the reference coordinate system. Accordingly these two positions may be used to compute a transformation of the accessory device relative to the computing device that is independent of the reference coordinate system.

By way of example in some cases the orientation may be defined as an angle of the accessory device with respect the computing device as represented in . As also discussed previously different angles may be associated with different interaction states such as the closed state typing state and viewing state examples given above. The orientation may alternatively be expressed in another suitable manner such as using x y z coordinates.

Optionally the computed orientation may be verified using a Hall Effect sensor of the computing device . The Hall Effect sensor may be configured to utilize magnetic force to detect proximity between the computing device and the accessory device . For example the Hall Effect sensor may measure proximity based upon one or more magnets that are included with the computing device and or the accessory device . When the computing device is rotated to a closed position the Hall Effect sensor may be configured to align with and detect a magnet of the accessory device . When the computing device is positioned away from the accessory device in an open position the Hall Effect sensor may be unable to detect the magnet or the detected magnetic force may change as the computing device is rotated at different angles relative to the accessory device . The Hall Effect sensor provides another way in which the orientation may be determined. Thus the Hall Effect sensor may be used as an additional check on whether the orientation computed using other sensors is accurate. This additional check may be made before causing and or controlling some kinds of behaviors such as powering down the devices or switching off different components based on orientation.

One or more behaviors of the host computing device and accessory device are controlled based on the orientation that is computed block . Various behaviors and responsive actions may be driven based on a computed orientation of an accessory with respect to the host. The behavior module may be configured to obtain orientation results from the sensor fusion module and control various behaviors accordingly.

Controlling the behaviors may include at least power management operations for the computing device and or host device. Generally power management operations are configured to control power consumption and prolong battery life. For example the behavior module may cause changes in power modes states to occur based on particular orientations. This may include toggling the devices and or selected components on off according to a determined orientation. For example in a closed state both the host and accessory may be powered down or placed into a sleep mode. In another example the accessory may be powered down when the orientation corresponds to a viewing state. The accessory device may also automatically wake up in particular orientation such as when a typing state is detected. A variety of other power management examples are also contemplated that may occur in response to a computed orientation.

In another example controlling the behaviors may include selectively adjusting and or enabling disabling different sensors for the device according to the orientation. By way of example rotation of the accessory fully around to cover the backside of the host may be indicative of a game play state. In this arrangement it may be likely that an accelerometer may be used for gameplay whereas use of touch functionality for keyboard typing input from the accessory may be unlikely. According in this arrangement sensitivity of an accelerometer may be increased turned on and touch sensitivity may be decreased or disabled. In a typing state the opposite may be true and the accelerometer may be disabled or adjusted to less sensitivity and the touch sensitivity may be increased or re enabled. Thus sensitivity of sensors may be adjusted and particular sensors may be turned on off based on orientation. It should be noted that sensors that are controlled may include sensors involved in computation of the orientation as well as other sensors of the host or accessory.

In yet another example functionality that is activated for the accessory and or host may be modified based on the orientation. For example an accessory may be configured to act as game controller when wrapped around to the backside and transform to provide keyboard type inputs when in a typing orientation. In a further example reading gestures to scroll or turn pages via the accessory may be enabled by input across the accessory device in a viewing orientation and may be disabled for other states orientation. These kinds of changes in the functionality provided by an accessory may occur by selectively exposing enabling configuring or otherwise activating different controls functions and gestures according to different orientations.

Comparable changes to activate gestures touch keys and other functionality of the host computing device based on the orientation may also occur. For example gestures for manipulation of media content on the display may be active in some orientations e.g. viewing state or gaming state and deactivated in other scenarios. Some additional examples of modifications that may be made to functionality that is activated available for the computing device based on orientation include selectively enabling disabling network connections and or controlling interactions of the host with accessory devices and or peripheral devices e.g. printers streaming media devices storage devices based upon the computed orientation.

Additionally behaviors of applications may also be controlled based on a computed orientation. For example the behavior module may be configured to selectively activate or deactivate different applications based on the orientation. This may include toggling between applications operating in foreground and background processes launching and closing particular applications minimizing maximizing and so forth. Applications may also retrieve and or subscribe to receive updates of computed orientation that the applications may make use of in various ways some details of which are provided in relation to the following figure. Accordingly a wide variety of behaviors may be controlled based on a computed orientation of which the particular behaviors enumerated above are but as few illustrative examples.

An orientation of an accessory device relative to a host computing device is computed based on a combined spatial position for the host computing device and an ascertained spatial position for the accessory device block . This may occur in accordance with a designated sensor fusion algorithm as discussed in relation to the example procedure of above.

An interface is exposed that is operable by one or more applications to obtain the computed orientation block . The computed orientation is supplied to an application in response to receiving a request from the application via the interface block . In particular a computing device may include a sensor fusion application programming interface API that is operable to supply computed orientation information to applications . In one approach the sensor fusion API may provide orientation information on demand responsive to individual requests. In addition or alternatively the sensor fusion API may be configured to facilitate registration of applications to subscribe to receive orientation updates. In response to a request to subscribe the API may register an application with the sensor fusion module and or an associated notification system configured to supply notification messages to registered applications when orientation changes occur. The applications may then receive notification messages sent via the notification system that describe updates to the orientation.

The sensor fusion API may supply the orientation and or related information to application in various formats. For example the orientation may be in the form of a transform of the accessory device relative to the computing device as computed in the manner described above. In this case an application may process the supplied orientation information to obtain information in an appropriate format for the application such as an orientation angle or a defined orientation state corresponding to the computed orientation. In addition or alternatively the sensor fusion module may operate to compute an orientation state on behalf of applications. Thus information supplied via the sensor fusion API may include a state name or identifier that may be directly usable by the applications.

Applications may make use of orientation information supplied through the API in various ways. For instance an application may selectively modify a user interface and or functionality of the user interface for the application based on the orientation. This may include activating different controls menus gestures and or input modes for different respective orientations. For example a navigation menu that appears in one orientation typing keyboard input orientation may disappear in a viewing orientation. Further an application may be configured to include various modes and switch between the modes based on orientation. For example a messaging application may switch from a text input mode to a video mode in accordance with the computed orientation. In another example the application may modify the manner in which particular inputs are interpreted in different orientations. For instance a button press in a typing orientation may be used for alphanumeric entry whereas the same button may be used for content control functions in a viewing orientation. Other buttons keys and other controls may also be selectively enabled or disabled as the orientation changes. A variety of other examples are also contemplated.

Having considered the foregoing example procedures consider now a discussion of example systems and devices that may be employed to implement aspects of techniques in one or more embodiments.

The example computing device as illustrated includes a processing system one or more computer readable media and one or more I O interface that are communicatively coupled one to another. Although not shown the computing device may further include a system bus or other data and command transfer system that couples the various components one to another. A system bus can include any one or combination of different bus structures such as a memory bus or memory controller a peripheral bus a universal serial bus and or a processor or local bus that utilizes any of a variety of bus architectures. A variety of other examples are also contemplated such as control and data lines.

The processing system is representative of functionality to perform one or more operations using hardware. Accordingly the processing system is illustrated as including hardware element that may be configured as processors functional blocks and so forth. This may include implementation in hardware as an application specific integrated circuit or other logic device formed using one or more semiconductors. The hardware elements are not limited by the materials from which they are formed or the processing mechanisms employed therein. For example processors may be comprised of semiconductor s and or transistors e.g. electronic integrated circuits ICs . In such a context processor executable instructions may be electronically executable instructions.

The computer readable storage media is illustrated as including memory storage . The memory storage represents memory storage capacity associated with one or more computer readable media. The memory storage component may include volatile media such as random access memory RAM and or nonvolatile media such as read only memory ROM Flash memory optical disks magnetic disks and so forth . The memory storage component may include fixed media e.g. RAM ROM a fixed hard drive and so on as well as removable media e.g. Flash memory a removable hard drive an optical disc and so forth . The computer readable media may be configured in a variety of other ways as further described below.

Input output interface s are representative of functionality to allow a user to enter commands and information to computing device and also allow information to be presented to the user and or other components or devices using various input output devices. Examples of input devices include a keyboard a cursor control device e.g. a mouse a microphone a scanner touch functionality e.g. capacitive or other sensors that are configured to detect physical touch a camera e.g. which may employ visible or non visible wavelengths such as infrared frequencies to recognize movement as gestures that do not involve touch and so forth. Examples of output devices include a display device e.g. a monitor or projector speakers a printer a network card tactile response device and so forth. Thus the computing device may be configured in a variety of ways to support user interaction.

The computing device is further illustrated as being communicatively and physically coupled to an accessory device that is physically and communicatively removable from the computing device . In this way a variety of different accessory devices may be coupled to the computing device having a wide variety of configurations to support a wide variety of functionality. In this example the accessory device includes one or more controls which may be configured as press sensitive keys mechanically switched keys buttons and so forth.

The accessory device is further illustrated as including one or more modules that may be configured to support a variety of functionality. The one or more modules for instance may be configured to process analog and or digital signals received from the controls to determine whether an input was intended determine whether an input is indicative of resting pressure support authentication of the accessory device for operation with the computing device and so on.

Various techniques may be described herein in the general context of software hardware elements or program modules. Generally such modules include routines programs objects elements components data structures and so forth that perform particular tasks or implement particular abstract data types. The terms module functionality and component as used herein generally represent software firmware hardware or a combination thereof The features of the techniques described herein are platform independent meaning that the techniques may be implemented on a variety of commercial computing platforms having a variety of processors.

An implementation of the described modules and techniques may be stored on or transmitted across some form of computer readable media. The computer readable media may include a variety of media that may be accessed by the computing device . By way of example and not limitation computer readable media may include computer readable storage media and computer readable signal media. 

 Computer readable storage media may refer to media and or devices that enable persistent and or non transitory storage of information in contrast to mere signal transmission carrier waves or signals per se. Thus computer readable storage media refers to non signal bearing media. The computer readable storage media includes hardware such as volatile and non volatile removable and non removable media and or storage devices implemented in a method or technology suitable for storage of information such as computer readable instructions data structures program modules logic elements circuits or other data. Examples of computer readable storage media may include but are not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage hard disks magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or other storage device tangible media or article of manufacture suitable to store the desired information and which may be accessed by a computer.

 Computer readable signal media may refer to a signal bearing medium that is configured to transmit instructions to the hardware of the computing device such as via a network. Signal media typically may embody computer readable instructions data structures program modules or other data in a modulated data signal such as carrier waves data signals or other transport mechanism. Signal media also include any information delivery media. The term modulated data signal means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media include wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media.

As previously described hardware elements and computer readable media are representative of modules programmable device logic and or fixed device logic implemented in a hardware form that may be employed in some embodiments to implement at least some aspects of the techniques described herein such as to perform one or more instructions. Hardware may include components of an integrated circuit or on chip system microcontroller devices an application specific integrated circuit ASIC a field programmable gate array FPGA a complex programmable logic device CPLD and other implementations in silicon or other hardware. In this context hardware may operate as a processing device that performs program tasks defined by instructions and or logic embodied by the hardware as well as a hardware utilized to store instructions for execution e.g. the computer readable storage media described previously.

Combinations of the foregoing may also be employed to implement various techniques described herein. Accordingly software hardware or executable modules may be implemented as one or more instructions and or logic embodied on some form of computer readable storage media and or by one or more hardware elements . The computing device may be configured to implement particular instructions and or functions corresponding to the software and or hardware modules. Accordingly implementation of a module that is executable by the computing device as software may be achieved at least partially in hardware e.g. through use of computer readable storage media and or hardware elements of the processing system . The instructions and or functions may be executable operable by one or more articles of manufacture for example one or more computing devices and or processing systems to implement techniques modules and examples described herein.

Although the example implementations have been described in language specific to structural features and or methodological acts it is to be understood that the implementations defined in the appended claims is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as example forms of implementing the claimed features.

