---

title: Asynchronous processing of mapping information
abstract: Functionality is disclosed herein for providing an asynchronous processing service for processing storage mapping information. The asynchronous processing service is configured to receive a storage request including identification of a storage object and a description of a storage operation, perform the storage operation for the storage object in response to receiving the storage request, and asynchronously update mapping information for the performed storage operation.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09513833&OS=09513833&RS=09513833
owner: Amazon Technologies, Inc.
number: 09513833
owner_city: Seattle
owner_country: US
publication_date: 20140923
---
Online and other remote data storage solutions generally include remote storage systems where customers submit requests to remotely store data. The remote storage systems may include mapping information that records a physical location of portions of data that a particular customer has stored through the remote storage system. It follows therefore that as large amounts of data are stored the amount of mapping information is increased to account for the increase in stored information.

However while the remote storage systems may be able to process and store a large amount of data relatively quickly the mapping information may be processed more slowly depending upon available resources for calculation and updating of physical locations where data is stored. Furthermore as the volume of storage requests for any particular customer increases as a measure of transactions per second TPS if available resources for processing mapping information are not scaled to handle the higher TPS the storage requests may be denied trigger data handling errors or may be throttled to allow for mapping information to be successfully processed on the fly. It may however be difficult to scale the computing resources for processing mapping information to handle high TPS bursts of storage requests.

The following detailed description is directed to technologies for providing an asynchronous processing service. Utilizing the technologies described herein an asynchronous processing service can be implemented that provides functionality for queuing and processing unique storage keys for use in asynchronously updating a related keymap. As many storage requests are received processed and associated storage objects are stored physical location information may be processed asynchronously as related to the actual storage of the storage objects. In this manner storage objects can be physically stored quickly while the processing of mapping information may be completed at a later time. Through the utilization of such an asynchronous processing service a remote storage system or distributed computing system can handle a relatively large number of TPS while not necessarily having to scale up computing resources for processing mapping information on the fly.

According to one configuration presented herein an asynchronous processing service is provided that operates within or in conjunction with a service provider network. The asynchronous processing service is a network service that provides functionality for building an asynchronous processing queue or queues that durably stores unique keys and storage information to be processed asynchronously. The asynchronous processing queue or queues can be managed by the asynchronous processing service.

As will be described in greater detail below the asynchronous processing service also provides functionality for dequeuing the unique keys subsequent to and independent from successful completion of a storage operation for an associated storage object. The asynchronous processing service also provides functionality for determining if some storage requests can be processed in an asynchronous manner if resources are available to process mapping information to further delay processing of mapping information if storage requests include header information indicating asynchronous priority information and to provide other related functionality. Additional details regarding the various components and processes described above for implementing an asynchronous processing service for mapping information will be presented below with regard to .

It should be appreciated that the subject matter presented herein may be implemented as a computer process a computer controlled apparatus a computing system or an article of manufacture such as a computer readable storage medium. While the subject matter described herein is presented in the general context of program modules that execute on one or more computing devices those skilled in the art will recognize that other implementations may be performed in combination with other types of program modules. Generally program modules include routines programs components data structures and other types of structures that perform particular tasks or implement particular abstract data types.

Those skilled in the art will also appreciate that aspects of the subject matter described herein may be practiced on or in conjunction with other computer system configurations beyond those described herein including multiprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers handheld computers personal digital assistants e readers mobile telephone devices tablet computing devices special purposed hardware devices network appliances and the like. As mentioned briefly above the configurations described herein may be practiced in distributed computing environments where tasks may be performed by remote computing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

In the following detailed description references are made to the accompanying drawings that form a part hereof and that show by way of illustration specific configurations or examples. The drawings herein are not drawn to scale. Like numerals represent like elements throughout the several figures which may be referred to herein as a FIG. or FIGS. .

The system may also include an on demand data processing component configured to process data storage requests received from a customer and or a customer computing system in a synchronous manner while updating associated mapping information in an asynchronous manner. The on demand data processing component can be implemented as a network service in one configuration. As described in greater detail below the on demand data processing component requests storage operations such as get copy delete and or put and submits storage objects retrieved from the storage requests for storage in persistent storage .

The on demand data processing component may be a collection of computing resources configured to synchronously process requests to store and or access data. The on demand data processing component may operate using computing resources e.g. databases that enable the on demand data processing component to locate and retrieve data quickly so as to allow data to be provided in responses to requests for the data. For example the on demand data processing component may maintain stored data in a manner such that when a request for a data object is retrieved the data object can be provided or streaming of the data object can be initiated in a response to the request. As described more fully below data stored by the on demand data processing component may be organized into storage objects . The storage objects may have arbitrary sizes except perhaps for certain constraints on size. Thus the on demand data processing component may store numerous storage objects of varying sizes.

The customer can be a user or entity that subscribes to or utilizes the service provider network . The customer computing system can include any suitable host computer apparatus configured to communicate with the service provider network for example over a suitable data communications network . One particular non limiting example of a suitable computer apparatus is described more fully below with reference to .

Persistent storage can include any suitable storage including but not limited to physical media configured to receive and store storage object and to return an associated locator value or other unique identification information. According to one implementation the persistent storage may include a network based bucket based storage model where locator values for various storage objects may be grouped into buckets for administrative security or other purposes. The bucket based storage model may be organized based on a customer identification of the customer the locator value an associated bucket identification and or any other suitable information.

In some configurations the persistent storage may determine the locator value store the storage object and transmit the locator value to the on demand data processing component . The locator value determined by the persistent storage is unique to the storage object . The locator value includes data that describes a location of an associated storage object in persistent storage and related data or metadata. For example the locator value can include an offset or other location value.

The on demand data storage component can provide the locator value and any related storage information e.g. a description of a storage operation and or bucket related to the storage object e.g. as unique key and storage information to a keymap processing component . The keymap processing component is a software component configured to utilize resources of the service provider network to process a locator value to create update or otherwise modify a keymap index of mapping information. For example according to one configuration the keymap processing component is configured to update the keymap index according to the locator value and any associated storage information upon receipt of the locator value .

The keymap index may be a database a dynamic data structure or another type of data structure configured to store a respective keymap entry for each storage object stored in persistent storage . For a given storage object the respective keymap entry includes the locator value and a unique key provided by the customer corresponding to the stored storage object . Furthermore according to one configuration the keymap index is a sorted index that is sorted based upon an underlying bucket based organization of storage objects. Updating of the keymap index may include determining where to include the locator value and associated unique key based on the particular sorting of the keymap index after storing a new storage object . Updating of the keymap index can also include re sorting as necessary when performing a copy storage operation. Updating of the keymap index can also include removal of a locator value and the associated unique key when performing a delete storage operation. Additionally updating of the keymap index can include any other suitable operations depending upon the nature of a particular storage request e.g. get request copy request put request delete request and others .

As further shown in an asynchronous processing service is in operative communication with the on demand data processing component . According to one configuration the asynchronous processing service is configured to receive the unique key and storage information from the on demand data processing component instead of the keymap processing component . For example the on demand data processing component may determine that the keymap index should be updated or modified in an asynchronous manner. In this case rather than the keymap processing component receiving the unique key and storage information for processing concurrently with the storage requests the asynchronous processing service queues the unique key and storage information in one or more asynchronous processing queues . The unique key and storage information received in the asynchronous processing queue includes for example the unique key provided by the customer and information describing a storage operation requested through storage request and associated locator value . Other storage information may also be included and according to one configuration should include at least that information necessary to appropriately update the keymap index .

The asynchronous processing queues are durable data structures that are configured to receive and queue the unique key and storage information for asynchronous processing by the keymap processing component . As used herein the term durable as related to a data structure refers to a data structure with a relatively low probability of being lost or irretrievable. According to one configuration a durable data structure has a probability of less than a first threshold of being lost or irretrievable. According to other configurations a durable data structure at least includes erasure code to ensure recoverability of information is archived to ensure recoverability of information and or is replicated at one or more storage locations to ensure recoverability of information. Other implementations of durability may also be applicable depending upon the particular implementation of the asynchronous processing queues .

The asynchronous processing queues may be organized as first in first out FIFO queues. The asynchronous processing service can direct the asynchronous processing queues to transmit the unique key and storage information to the keymap processing component independent of the processing of storage requests by the on demand data processing component . Thereafter the keymap processing component can process the unique key and storage information in the manner described above while being asynchronous as compared to the storage of storage objects in persistent storage . Upon successful updating of the keymap index a storage notification can then be transmitted to the customer or customer computing system . The storage notification can include an indication that the storage request was successfully completed and any other suitable or desirable information. The storage notification is not transmitted to the customer computing system until both the storage operation i.e. creation deletion copying on a storage object has been completed and the keymap index has been updated accordingly.

As described above the asynchronous processing service utilizes one or more durable queues for handling processing of mapping information to be stored as keymap index . Further details regarding the operation of the storage service asynchronous processing service on demand data processing component and keymap processing component are provided below with reference to .

Responsive to receipt of the storage request the on demand data processing component can direct the persistent storage to perform the storage operation or operations described by the storage request at block . Thereafter the asynchronous processing service can create update or otherwise manipulate asynchronous processing queues at block . Thereafter the asynchronous processing service queues the unique key and storage information into one or more asynchronous processing queues at block .

As described above the asynchronous processing queues allow for mapping information contained in keymap index to be processed asynchronously with regard to the performance of storage operations at block . Accordingly the method may iterate through blocks and independently from processing of the unique keys and storage information queued in asynchronous processing queues . The asynchronous updating of mapping information and or keymap index is described more fully below with reference to .

As illustrated in the method includes determining if resources should be scaled to allow for faster processing of information queued in the asynchronous processing queues . For example due to the asynchronous and independent functioning provided by the asynchronous processing service resources available to the keymap processing component can be scaled without affecting the processing of storage operations shown in . Accordingly if the size priority or other attributes of information queued in asynchronous processing queues necessitate or otherwise deem additional resources desirable these resources can be scaled up at block . Furthermore if additional resources are not necessary or if for example lazy processing of the asynchronous processing queues is desirable resources may be scaled down at block .

Alternatively if no scaling either up or down is desirable or necessary the unique key and storage information may be asynchronously dequeued by the asynchronous processing service at block . Thereafter the keymap index can be updated by the keymap processing component at block . Additionally the customer submitting the request is notified of the complete request at block . The method may continually iterate by dequeuing of all unique key and storage information queued at the asynchronous processing queue s and updating the keymap index to reflect all dequeued unique key and storage information.

It is noted that the method and may function independently and accordingly provide asynchronous processing of mapping information. Furthermore although illustrated as being initially populated at block the asynchronous processing queue s may already have queued therein several other unique keys and related storage information prior to the queuing functions described with reference to block . It should be understood that these prior queued requests may all be processed asynchronously as compared to related storage operations performed by the persistent storage and or on demand data processing component .

Thus as described above the asynchronous processing service may enable asynchronous processing of unique key and storage information received from the on demand data processing component . However other functionality may also be realized through intelligent operation by the on demand data processing component . For example some storage requests may include asynchronous processing of the keymap index while others may include generally synchronous processing of keymap index depending upon information contained in the storage request and or other factors. Furthermore some storage requests may be requests during a high volume of transactions or high number of TPS. This is described more fully below with reference to and .

Upon determination of the priority information at block the customer computing system may create the storage requests including the storage object or objects at block and may append the priority information to the storage requests at block . According to one configuration the priority information can include a header value or flag indicating that mapping information for the storage request should be processed asynchronously. According to other configurations the priority information can include a value or set of values for an appropriate delay in the processing of the mapping information for the storage request .

The priority information header value and or flag can be arranged in any suitable manner. For example if the storage request is formatted to include a header the header can include async true to indicate mapping information for the storage request should be processed asynchronously or async false to indicate mapping information for the storage request should be processed as soon as possible. As an additional example a header can include async time to indicate an appropriate time delay that is acceptable for asynchronous processing of the mapping information of the storage request .

Other header information finer granularity of priority information and or any other suitable information may also be appropriate according to any particular implementation. Furthermore any suitable communication protocol can be used to create storage requests and therefore it should be understood that protocols such as representational state transfer REST Hypertext Transfer Protocol HTTP or others might be applicable. Therefore the particular examples disclosed herein should not be construed as limiting of all possible implementations. Upon appending of any appropriate priority information at block the storage request s are transmitted to the service provider network at block and the method may cease at block . Hereinafter processing of storage requests including storage requests having header information determination of high TPS and or other priority or asynchronous indications are described more fully with reference to .

Alternatively if the on demand data processing component determines that asynchronous processing of mapping information is indicated or otherwise appropriate the on demand data processing component directs the persistent storage to perform the storage request at block . For example a relatively high rate of TPS may trigger a need or desire for asynchronous processing at block . A relatively high rate of TPS may be determined by comparing a current rate of TPS to a threshold value. More than one threshold value comparison could be implemented if utilizing more than one asynchronous queue . Additionally a header value or flag may trigger a need or desire for asynchronous processing at block . Accordingly depending upon the particular information contained within the storage request as well as a rate of TPS the on demand processing component can determine whether to process the request asynchronously. Thereafter the asynchronous processing service queues the unique key and storage information in one or more asynchronous processing queues at block .

As described above the indication of asynchronous processing can include a priority indication of high low a time delay indication and or other information including a rate of TPS. Accordingly depending upon the particular priority the queuing of the unique key and storage information can be based on the particular priority. For example the asynchronous processing queues can include a high priority queue and a low priority queue. Thus high priority asynchronous storage requests can have associated unique key and storage information queued into the high priority queue. Similarly low priority asynchronous storage requests can have associated unique key and storage information queued into the low priority queue. Thereafter the asynchronous processing service can dequeue the high priority queue at a higher rate than the low priority queue at block and therefore the keymap index is updated according to the dequeuing order e.g. that follows the associated priority .

Additionally according to one configuration the asynchronous processing queues can be organized according to a time delay for processing of mapping information. The organizing can be based on a grouping of time delays such as a one hour delay a one day delay a one week delay or other delays. Thus asynchronous storage requests indicating a particular acceptable delay are queued into an associated asynchronous processing queue and the time delay of the queue is enforced through the asynchronous processing service . In this manner asynchronous processing of mapping information indicating a particular delay is processed within the particular delay period indicated in the associated storage request .

Additionally the asynchronous processing queues can be configured to be queued with unique keys and storage information based on a current rate of TPS. For example if a threshold rate of TPS is exceeded the unique keys and storage information can be processed asynchronously. Additionally more than one threshold can be implemented. Thus if a first threshold and a second threshold are exceeded an additional asynchronous queue with a different processing priority can be initiated. More or fewer threshold are also applicable and therefore these particular examples should not be construed as limiting.

Other forms of prioritization and determinations of asynchronous processing are also applicable according to any desired implementation of the functionality described herein. Accordingly although particular examples of thresholds for rates of TPS high low priority queues and or time delay based queues have been described it should be understood that modification to include more or fewer priorities different granularity of time delays and or other similar attributes are considered within the scope of this disclosure. Hereinafter different hardware configurations and operating environments capable of implementing one or more features described above are described in more detail.

The computing resources provided by the service provider network may include various types of computing resources such as data processing resources data storage resources networking resources data communication resources and the like. Each type of computing resource may be general purpose or may be available in a number of specific configurations. For example data processing resources may be available as physical computers or virtual machine instances in a number of different configurations. The virtual machine instances may be configured to execute applications including Web servers application servers media servers database servers and other types of applications. Data storage resources may include file storage devices block storage devices and the like. The service provider network might also be configured to provide various network services.

The computing resources provided by the service provider network are enabled in one implementation by one or more data centers A N which may be referred herein singularly as a data center or in the plural as the data centers . The data centers are facilities utilized to house and operate computer systems and associated components. The data centers typically include redundant and backup power communications cooling and security systems. The data centers might also be located in geographically disparate locations. One illustrative configuration for a data center that implements some of the technologies disclosed herein for integrating an asynchronous processing service within the service provider network will be described below with regard to .

The customers and other users of the service provider network may access the computing resources provided by the service provider network over a network such as a wide area network WAN . For example and without limitation a customer computing system might be utilized to access the service provider network by way of the network . It should be appreciated that a local area network LAN the Internet or any other networking topology known in the art that connects the data centers to remote customers and other users may be utilized. It should also be appreciated that combinations of such networks might also be utilized.

The server computers may be standard tower rack mount or blade server computers configured appropriately for providing the computing resources described herein. As mentioned above the computing resources might be data processing resources such as virtual machine instances or hardware computing systems data storage resources database resources networking resources and others. Some of the servers might also be configured to execute a resource manager capable of instantiating and or managing the computing resources. In the case of data storage services for example the resource manager might be a program configured to enable the execution of the bucket based storage model on computing resources for example. Server computers in the data center might also be configured to provide network services and other types of services some of which are described in detail below with regard to .

The data center shown in also includes a server computer F that may be utilized for executing some or all of the software components described above. For example and without limitation the server computer F might be configured to execute the asynchronous processing service which has been described in detail above. The server computer F might also be configured to execute other components and or store data for providing some or all of the functionality described herein including the on demand data processing component keymap processing component keymap index and or persistent storage .

In the example data center shown in an appropriate LAN is utilized to interconnect the server computers A F. The LAN is also connected to the network illustrated in . It should be appreciated that the configuration and network topology illustrated in has been greatly simplified and that many more computing systems software components networks and networking devices may be utilized to interconnect the various computing systems disclosed herein and to provide the functionality described above. Appropriate load balancing devices or other types of network infrastructure components might also be utilized for balancing a load between each of the data centers A N between each of the server computers A F in each data center and potentially between computing resources in each of the data centers . It should be appreciated that the configuration of the data center described with respect to is merely illustrative and that other implementations might be utilized.

It should be appreciated that customers of the service provider network may be an organization that may utilize the services provided by the service provider network . Additionally customers of the service provider network may be individuals that utilize the services provided by the service provider network . As shown in a customer may communicate with the service provider network through a network which may be a communication network such as the Internet an intranet or an Internet service provider ISP network. Communications from the customer computing system to the service provider network may cause the services provided by the service provider network to operate in accordance with configurations described or variations thereof.

As discussed briefly above the service provider network may provide various types of network services to its customers . The services provided by the service provider network in this example include a virtual computer system service A a block level data storage service B a cryptography service C a notification service E an authentication service F a policy management service G a task service H and potentially other services I. The service provider network may also provide the storage service and asynchronous processing service for use internally and by external customers. Additionally although not particularly illustrated it should be understood that the on demand data processing component could be configured in combination with the keymap processing component and or asynchronous processing service as a single identifiable service or could be otherwise abstracted as one or more of the services .

It is noted that not all configurations described include the services A I described with reference to and additional services may be provided in addition to or as an alternative to services explicitly described. Each of the services A I may include web service interfaces that enable a caller to submit appropriately configured API calls to the various services through web service requests. In addition each of the services may include service interfaces that enable the services to access each other e.g. to enable a virtual computer system of the virtual computer system service A to store data in or retrieve data from the on demand data storage service D and or to access block level data storage devices provided by the block level data storage service B . Additional details regarding the services A H shown in will now be provided.

The virtual computer system service A may be a collection of computing resources configured to instantiate virtual machine instances. For example a customer of the service provider network may interact with the virtual computer system service A via appropriately configured and authenticated API calls to provision and operate virtual computer systems that are instantiated on physical computing devices hosted and operated by the service provider network . The virtual computer systems may be used for various purposes such as to operate as servers supporting a website to operate business applications or generally to serve as computing resources for the customer. Other applications for the virtual computer systems may be to support database applications electronic commerce applications business applications and or other applications. Although the virtual computer system service A is shown in any other computer system or computer system service may be utilized in the service provider network such as a computer system or computer system service that does not employ virtualization or instantiation and instead provisions computing resources on dedicated or shared computers servers and or other physical devices.

The block level data storage service B may comprise computing resources that collectively operate to store data using block level storage devices and or virtualizations thereof . The block level storage devices of the block level data storage service B may for instance be operationally attached to virtual computer systems provided by the virtual computer system service A to serve as logical units e.g. virtual drives for the computer systems. A block level storage device may enable the persistent storage of data used generated by a corresponding virtual computer system where the virtual computer system service A may only provide ephemeral data storage.

The service provider network may also include a cryptography service C. The cryptography service C may utilize storage services of the service provider network to store encryption keys in encrypted form whereby the keys may be usable to decrypt customer keys accessible only to particular devices of the cryptography service C. The cryptography service C might also provide other types of functionality not specifically mentioned herein.

The service provider network might also provide a notification service E in some configurations. The notification service E may comprise a collection of computing resources collectively configured to provide a web service or other interface and browser based management console. The management console can be used to configure topics for which customers seek to receive notifications configure applications or people subscribe clients to the topics publish messages or configure delivery of the messages over clients protocol of choice i.e. HTTP e mail and short message service SMS among others . The notification service E may provide notifications to clients using a push mechanism without the need to periodically check or poll for new information and updates. The notification service E may further be used for various purposes such as monitoring applications executing in the virtual computer system service A workflow systems time sensitive information updates mobile applications and many others.

As illustrated in the service provider network in various configurations includes an authentication service F and a policy management service G. The authentication service F in one example is a computer system i.e. collection of computing resources configured to perform operations involved in authentication of users of the customer. For instance one of the services A E and G I may provide information from a user to the authentication service F to receive information in return that indicates whether or not the requests submitted by the user are authentic.

The policy management service G in one example is a computer system configured to manage policies on behalf of customers or internal users of the service provider network . The policy management service G may include an interface that enables customers to submit requests related to the management of policy. Such requests may for instance be requests to add delete change or otherwise modify policy for a customer or for other administrative actions such as providing an inventory of existing policies and the like.

The service provider network in various configurations is also configured with a task service H. The task service H is configured to receive a task package and to enable executing tasks as dictated by the task package. The task service H may be configured to use any resource of the service provider network such as instantiated virtual machines or virtual hosts for executing the task. The task service H may configure the instantiated virtual machines or virtual hosts to operate using a selected operating system and or a selected execution application in accordance with specified requirements.

The service provider network may additionally maintain other services I based at least in part on the needs of its customers. For instance the service provider network may maintain a database service is some configurations. A database service may be a collection of computing resources that collectively operate to create maintain and allow queries to be performed on databases stored within the service provider network . For example a customer of the service provider network may operate and manage a database from the database service by utilizing appropriately configured API calls. This in turn may allow the customer to maintain and potentially scale the operations in the database. Other services include object level archival data storage services services that manage and or monitor other services. The service provider network might also be configured with other services not specifically mentioned herein.

The computer includes a baseboard or motherboard which is a printed circuit board to which a multitude of components or devices may be connected by way of a system bus or other electrical communication paths. In one illustrative configuration one or more central processing units CPUs operate in conjunction with a chipset . The CPUs may be standard programmable processors that perform arithmetic and logical operations necessary for the operation of the computer .

The CPUs perform operations by transitioning from one discrete physical state to the next through the manipulation of switching elements that differentiate between and change these states. Switching elements may generally include electronic circuits that maintain one of two binary states such as flip flops and electronic circuits that provide an output state based on the logical combination of the states of one or more other switching elements such as logic gates. These basic switching elements may be combined to create more complex logic circuits including registers adders subtractors arithmetic logic units floating point units and the like.

The chipset provides an interface between the CPUs and the remainder of the components and devices on the baseboard . The chipset may provide an interface to a RAM used as the main memory in the computer . The chipset may further provide an interface to a computer readable storage medium such as a read only memory ROM or non volatile RAM NVRAM for storing basic routines that help to startup the computer and to transfer information between the various components and devices. The ROM or NVRAM may also store other software components necessary for the operation of the computer in accordance with the configurations described herein.

The computer may operate in a networked environment using logical connections to remote computing devices and computer systems through a network such as the local area network . The chipset may include functionality for providing network connectivity through a NIC such as a gigabit Ethernet adapter. The NIC is capable of connecting the computer to other computing devices over the network . It should be appreciated that multiple NICs may be present in the computer connecting the computer to other types of networks and remote computer systems.

The computer may be connected to a mass storage device that provides non volatile storage for the computer. The mass storage device may store system programs application programs other program modules and data which have been described in greater detail herein. The mass storage device may be connected to the computer through a storage controller connected to the chipset . The mass storage device may consist of one or more physical storage units. The storage controller may interface with the physical storage units through a serial attached SCSI SAS interface a serial advanced technology attachment SATA interface a fiber channel FC interface or other type of interface for physically connecting and transferring data between computers and physical storage units.

The computer may store data on the mass storage device by transforming the physical state of the physical storage units to reflect the information being stored. The specific transformation of physical state may depend on various factors in different implementations of this description. Examples of such factors may include but are not limited to the technology used to implement the physical storage units whether the mass storage device is characterized as primary or secondary storage and the like.

For example the computer may store information to the mass storage device by issuing instructions through the storage controller to alter the magnetic characteristics of a particular location within a magnetic disk drive unit the reflective or refractive characteristics of a particular location in an optical storage unit or the electrical characteristics of a particular capacitor transistor or other discrete component in a solid state storage unit. Other transformations of physical media are possible without departing from the scope and spirit of the present description with the foregoing examples provided only to facilitate this description. The computer may further read information from the mass storage device by detecting the physical states or characteristics of one or more particular locations within the physical storage units.

In addition to the mass storage device described above the computer may have access to other computer readable storage media to store and retrieve information such as program modules data structures or other data. It should be appreciated by those skilled in the art that computer readable storage media is any available media that provides for the non transitory storage of data and that may be accessed by the computer .

By way of example and not limitation computer readable storage media may include volatile and non volatile removable and non removable media implemented in any method or technology. Computer readable storage media includes but is not limited to RAM ROM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM flash memory or other solid state memory technology compact disc ROM CD ROM digital versatile disk DVD high definition DVD HD DVD BLU RAY or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium that can be used to store the desired information in a non transitory fashion.

The mass storage device may store an operating system utilized to control the operation of the computer . According to one configuration the operating system comprises the LINUX operating system. According to another configuration the operating system comprises the WINDOWS SERVER operating system from MICROSOFT Corporation. According to further configurations the operating system may comprise the UNIX operating system or one of its variants. It should be appreciated that other operating systems may also be utilized. The mass storage device may store other system or application programs and data utilized by the computer such as the storage service asynchronous processing service the on demand data processing component the keymap processing component and or any of the other software components and data described above. The mass storage device might also store other programs and data not specifically identified herein.

In one configuration the mass storage device or other computer readable storage media is encoded with computer executable instructions which when loaded into the computer transform the computer from a general purpose computing system into a special purpose computer capable of implementing the configurations described herein. These computer executable instructions transform the computer by specifying how the CPUs transition between states as described above. According to one configuration the computer has access to computer readable storage media storing computer executable instructions which when executed by the computer perform the various routines described above with regard to . The computer might also include computer readable storage media for performing any of the other computer implemented operations described herein.

The computer may also include one or more input output controllers for receiving and processing input from a number of input devices such as a keyboard a mouse a touchpad a touch screen an electronic stylus or other type of input device. Similarly the input output controller may provide output to a display such as a computer monitor a flat panel display a digital projector a printer a plotter or other type of output device. It will be appreciated that the computer may not include all of the components shown in may include other components that are not explicitly shown in or may utilize an architecture completely different than that shown in .

Based on the foregoing it should be appreciated that technologies for providing asynchronous processing of mapping information have been presented herein. Moreover although the subject matter presented herein has been described in language specific to computer structural features methodological acts and computer readable media it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features acts or media described herein. Rather the specific features acts and media are disclosed as example forms of implementing the claims.

The subject matter described above is provided by way of illustration only and should not be construed as limiting. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure. Various modifications and changes may be made to the subject matter described herein without following the example configurations and applications illustrated and described and without departing from the true spirit and scope of the present invention which is set forth in the following claims.

