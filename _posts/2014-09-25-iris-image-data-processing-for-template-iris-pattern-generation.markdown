---

title: Iris image data processing for template iris pattern generation
abstract: Systems, devices, methods, computer-readable media, techniques, and methodologies are disclosed for generating a template iris pattern using multiple image frames containing image data corresponding to detected light at different wavelengths along the electromagnetic (EM) spectrum including light in the infrared, near-infrared, and/or visible light bands.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09396394&OS=09396394&RS=09396394
owner: Amazon Technologies, Inc.
number: 09396394
owner_city: Seattle
owner_country: US
publication_date: 20140925
---
Biometrics refers to metrics that are related to human characteristics or traits and which can be used to identify or authenticate individuals. A biometric identifier may include any distinctive and measurable characteristic that may be used to label and describe individuals. Biometric identifiers may be broadly categorized into two categories identifiers that reflect physiological characteristics and identifiers that reflect behavioral characteristics. Physiological biometric identifiers may include fingerprints palm vein patterns facial features DNA sequences palm prints hand geometries iris patterns retinal blood vessel patterns or the like. Behavioral biometric identifiers may include typing rhythms handwriting styles gait vocal characteristics or the like. A number of performance metrics may be used to evaluate a biometric identifier and associated biometric system s capability to uniquely identify an individual. Such performance metrics may include for example a false acceptance rate a false rejection rate a failure to enroll rate a failure to capture rate a template capacity and so forth.

This disclosure relates to among other things systems devices methods computer readable media techniques and methodologies for generating a template iris pattern using multiple image frames containing image data corresponding to detected light at different wavelengths along the electromagnetic EM spectrum. Such wavelengths may include for example the infrared IR wavelength band of the EM spectrum the near infrared NIR wavelength band the visible wavelength VW band or the like.

The iris is a thin circular structure in the eye that is responsible for controlling the diameter and size of the pupil and thus the amount of light reaching the retina a light sensitive layer of tissue lining the inner surface of the eye and on which optics of the eye project an image of the visual world. The iris is typically strongly pigmented and may exhibit a range of colors. Melanin is a broad term that refers to a group of natural pigments found in most organisms. Two types of melanin eumelanin and pheomelanin may be responsible for the pigmentation of the iris. More particularly iris color may be due at least in part to the presence of varying amounts of eumelanin which produces a black or brown hue and pheomelanin which produces pink red yellow hues . Darker irises typically have larger concentrations of eumelanin and lighter irises typically have larger concentrations of pheomelanin. Although melanin is the primary determinant of iris color a number of other factors may impact iris color as well including texture fibrous tissue and blood vessels within the iris stroma.

The absorbance of melanin in the IR or NIR bands is typically negligible. However at shorter wavelengths within the VW band melanin may become excited and may reveal rich pigmentation details. In the VW band the albredo ratio of reflected radiation to incident radiation is typically low for darker irises and the iris image may become dominated by corneal specular reflections that may mask pigmentation details of darker irises. In the IR or NIR bands however rich textural details may be revealed for darker irises and corneal specular reflections may be simultaneously blocked.

In accordance with example embodiments of the disclosure one or more image sensors may be provided for capturing images of an iris. One or more IR or NIR cut off or band pass filters may be provided for reflecting or absorbing light within the IR or NIR bands or allowing light within the IR or NIR bands to pass through to the image sensor s . In addition sensor pixels of the image sensor s may have varying responses to different frequency bands. Through the use of different types of image sensor s and cut off or band pass IR or NIR filter s multiple image frames containing image data corresponding to different wavelength bands e.g. IR NIR VW bands may be captured. The image data contained in the multiple image frames may be combined according to image processing techniques described herein to generate an iris template pattern having an increased amount of pattern data and thus reduced false acceptance and false rejection rates. Hereinafter the shortened form IR NIR may be used to refer to light in the IR and or NIR bands or any component data or the like associated with light in the IR and or NIR bands. Further the term VW may be used to refer to light in the VW band or any wavelength that is neither in the IR band nor in the NIR band or any associated component data or the like.

In an example embodiment of the disclosure an image frame may be processed to generate a Laplacian pyramid for the image frame. In a first iteration of an algorithmic process for generating a Laplacian pyramid image data of an image frame may be low pass filtered using for example a Gaussian filter or the like to generate first filtered image data. The image data of an image frame may include for example an intensity of light e.g. a number of photons detected at each pixel of an image sensor for each of one or more wavelengths or wavelength bands. A band pass filter may then be applied to the image data of the image frame to generate second filtered image data. For example the first filtered image data may be subtracted from the image data to generate the second filtered image data. The second filtered image data obtained in this manner may correspond to a first level of the Laplacian pyramid. The first filtered image data may then be down sampled to reduce the number of pixels by for example an integer factor of 2. The down sampled image data may then serve as source image data for a subsequent iteration of the process for generating the Laplacian pyramid. This subsequent iteration may generate additional second filtered image data corresponding to a second level of the Laplacian pyramid. The process may continue for a predetermined number of iterations until N levels of the Laplacian pyramid are generated with each level corresponding to band pass filtered image data for a number of pixels reduced by a down sampling factor from the number of pixels for which band pass filtered image data was generated during a previous iteration of the process.

Laplacian pyramids may be generated for any number of IR NIR and or VW image frames. An IR NIR image frame as that term is used herein may include image data corresponding to detected light in the IR and or NIR bands. Further a VW image frame may include image data corresponding to detected light that is neither in the IR band nor in the NIR band e.g. light in the VW band . The image data represented by a Laplacian pyramid may be stored in any suitable data structure such as for example an ordered data structure including but not limited to an array a linked list an ordered list an ordered set a tree a heap and so forth. The filtered image data represented by any number of Laplacian pyramids corresponding to any number of IR NIR or VW image frames may be combined to generate composite image data. The composite image data may be represented by a composite image frame Laplacian pyramid. For example the pixel intensities for image data corresponding to a same pyramid level may be evaluated across multiple Laplacian pyramids. For each image pixel at a given pyramid level the Laplacian pyramid having the largest light intensity at any wavelength may be identified and that light intensity value which may correspond to the IR NIR or VW bands for example may be included as composite image data in a corresponding level of the composite image frame Laplacian pyramid. This process may be repeated for each pixel at each pyramid level. In this manner the composite image frame data represented by the composite image frame Laplacian pyramid may exhibit improved contrast and sharper iris patterns than any individual image frame.

After generating the composite image frame Laplacian pyramid an interpolation technique may be employed to generate final output image data from which an iris template pattern may be generated. The interpolation technique may begin by up sampling the composite image data at the highest level of the Laplacian pyramid e.g. the composite image data corresponding to the smallest number of pixels . The up sampled composite image data may then be summed with composite image data from the second highest level of the pyramid e.g. the composite image data corresponding to the next smallest number of pixels . The summed image may then serve as a source image for a subsequent iteration of the interpolation technique. In particular the summed image may be up sampled and summed with composite image data from the subsequent level of the pyramid to generate another summed image which may similarly serve as a source image for a next iteration of the technique. The process may be repeated until a final summed image is generated that is approximately equal in size to original image frames from which the composite image data was generated. This final summed image may then be summed with initial low pass filtered data to obtain the final output image data. The initial low pass filtered data may include any data obtained from low pass filtering any of the initial image data from which the constituent Laplacian pyramids used to generate the composite image frame Laplacian pyramid are generated.

Once final output image data is generated using the interpolation technique described above processing may be performed to identify a template iris pattern within the final output image data. More specifically a pupil region within the final output image data may be determined by comparing a first light intensity gradient between light intensity values in the final output image data for a first set of pixels and light intensity values in the final output image data for a second set of neighboring pixels to a first threshold value. In this manner a boundary of the pupil region may be determined based on whether the first light intensity gradient exceeds the first threshold value. An iris region of the final output image data may then be determined by comparing a second light intensity gradient between a light intensity values for a third set of pixels and light intensity values for a fourth set of neighboring pixels to a second threshold value. In this manner an outer boundary of the iris region may be determined based on whether the second light intensity gradient exceeds the second threshold value. The iris region may be defined by an inner boundary corresponding to the boundary of the pupil region and an outer boundary corresponding to where the iris interfaces with the sclera. For darker irises the first threshold value used to determine the boundary of the pupil region the inner boundary of the iris region may be less than the second threshold value used to determine the outer boundary of the iris region. Conversely for lighter irises the first threshold value may be greater than the second threshold value. Once the iris region is identified feature extraction processing may be performed on the iris region to generate a template iris pattern for subsequent biometric recognition using iris pattern matching.

Example embodiments of the disclosure provide a number of technical features or technical effects. For example systems methods and computer readable media in accordance with example embodiments of the disclosure provide iris pattern data with improved contrast and sharpness by combining image data corresponding to detected light at different wavelengths including for example light in the IR NIR or VW bands. As such example embodiments of the disclosure provide iris pattern data having an increased assortment of features that may be used for identification authentication purposes e.g. rings furrows freckles etc. for lighter and darker irises alike. It should be appreciated that the above examples of technical features and or technical effects of example embodiments of the disclosure are merely illustrative and not exhaustive.

One or more illustrative embodiments of the disclosure have been described above. The above described embodiments are merely illustrative of the scope of this disclosure and are not intended to be limiting in any way. Accordingly variations modifications and equivalents of embodiments disclosed herein are also within the scope of this disclosure. For example while example embodiments may be described in connection with obtaining iris template patterns having increased clarity sharpness and or detail embodiments of the disclosure are applicable to other contexts as well including but limited to obtaining images having increased clarity sharpness and or detail as part of a remote deposit capture process for example. The above described embodiments and additional and or alternative embodiments of the disclosure will be described in detail hereinafter through reference to the accompanying drawings.

An example anatomical structure of an eye is depicted in . The eye may include a pupil surrounded by an iris . The eye may further include a sclera . The iris may have a ring like shape defined by an inner boundary that corresponds to an outer boundary of the pupil and an outer boundary defined by an interface between the iris and the sclera .

Electromagnetic EM radiation may be reflected off of the various anatomical components of the eye . The EM radiation may include light in the IR NIR and or VW bands for example. One or more image sensors may be provided for detecting the EM radiation and generating corresponding image frames. The image sensor s may include any device configured to convert an optical image into an electrical signal including without limitation a charge coupled device CCD image sensor a complementary metal oxide semiconductor CMOS image sensor an N type metal oxide semiconductor NMOS image sensor or the like. The image sensor s may include multiple image sensors having varying responses to different frequency bands. In addition one or more IR NIR cut off or band pass filters may be provided for restricting IR NIR band light from reaching or allowing IR NIR band light to reach the image sensor s . In certain example embodiments an IR NIR cut off filter may be transitioned to a non blocking state in which IR NIR band light is permitted to reach an image sensor . Additionally or alternatively an IR NIR band pass filter may be provided that permits light in the IR NIR bands to reach an image sensor . It should be appreciated that IR NIR cut off or band pass filters may be used in any suitable combination to restrict IR NIR light from reaching an image sensor or to permit IR NIR light to pass through to an image sensor .

Through selective use of IR NIR cut off or band pass filter s the image sensor s may generate one or more IR NIR image frames and one or more VW image frames . Image processing techniques described herein may be applied to the IR NIR image frame s and the VW image frame s to generate final output image data from which a template iris pattern may be identified.

At block a counter may be initialized. In certain example embodiments the value to which the counter is initialized may be zero. In such example embodiments the counter may be incremented at each iteration of the method and the method may cease when the counter exceeds a threshold value such as a predetermined number of iterations of the method which may in turn correspond to a desired number of levels of the Laplacian pyramid to be generated. In certain example embodiments the desired number of levels may be determined as a function of the portion of the image frame occupied by the iris region. For example for larger iris regions a Laplacian pyramid having a greater number of levels may be generated. In addition image sharpness may be factor in determining the desired number of Laplacian pyramid levels. For example a greater number of Laplacian pyramid levels may be generated for images having greater sharpness.

Further it should be appreciated that the counter may be initialized to a different value in various other example embodiments. For example the counter may be initialized to the predetermined number of iterations of the method e.g. a desired number of levels of the Laplacian pyramid to be generated the counter may be decremented at each iteration and the method may cease when the counter equals zero. It should be appreciated that the above examples for counter initialization are merely illustrative and not exhaustive and that the counter may be initialized to any suitable value.

At block a determination may be made as to whether the counter exceeds a threshold above. As previously noted in those example embodiments in which the counter is initialized to zero the threshold value may correspond to a predetermined number of iterations of the method which may in turn correspond to a desired number of levels of the Laplacian pyramid to be generated.

In response to a negative determination the method may proceed to block . At block in a first iteration of the method initial image data may be selected as source image data. The initial image data may correspond to image data contained in an IR NIR image frame captured by an image sensor or image data contained in a VW image frame.

At block computer executable instructions code or the like of low pass filtering module s which will be described in more detail later in this disclosure in reference to may be executed by one or more processors to cause a low pass filter to be applied to the source image data to obtain first filtered image data. In certain example embodiments the low pass filter may be a Gaussian filter. A Gaussian filter may be a filter whose impulse response is a Gaussian function. Accordingly in such example embodiments application of the low pass filter to the source image data may include convolution of the source image data with a Gaussian function e.g. a Weierstrass transform as reflected by equation in . Convolution of the source image data with a Gaussian function may produce a blurred image and may be referred to as Gaussian blurring or Gaussian smoothing. Gaussian blurring has the effect of reducing high frequency components present in the image data and thus application of a Gaussian filter to the source image data corresponds to low pass filtering of the source image data. It should be appreciated that a Gaussian filter is merely an example type of low pass filter that may be applied at block and that any suitable low pass filter may be used.

At block computer executable instructions code or the like of band pass filtering module s may be executed by one or more processors to cause a band pass filter to be applied to the source image data using the first filtered image data in order to obtain second filtered image data. In certain example embodiments application of a band pass filter at block may include generating a difference image by subtracting the first filtered image data from the source image data. The difference image may include the second filtered image data. An equation for generating the difference image is depicted in .

At block the second filtered image data may be stored in an ordered data structure. The ordered data structure may include any of the example types of data structures described earlier and generally may include any data structure capable of representing the structure of a Laplacian pyramid such as Laplacian pyramid depicted in . By way of example and without limitation the second filtered image data may be stored at a particular location of an array. The index of the location at which the second filtered image data is stored may correspond to a particular level of the Laplacian pyramid . For example the second filtered image data generated as a result of a first iteration of the method may be stored at a location in the ordered data structure that corresponds to an initial level of the Laplacian pyramid .

At block computer executable instructions code or the like of the down sampling module s may be executed to down sample the first filtered image data. An example equation for down sampling the first filtered image data is depicted in . As shown in certain example embodiments down sampling the first filtered image data may include reducing a number of pixels in the first filtered image data by approximately . The down sampling performed at block on the first filtered image data and the low pass filtering performed at block may together constitute a decimation process for reducing the sampling rate of image signals corresponding to the first filtered image data. In certain example embodiments the down sampling may include combining signals corresponding to neighboring pixels. While down sampling by an integer factor of 2 is illustratively shown in it should be appreciated that the first filtered image data may be down sampled by any suitable value including any suitable integer or rational fraction.

Following a first iteration of the operations of blocks the counter may be incremented at block . The method may then proceed again to block where the now incremented counter may be compared against the threshold value. If the counter exceeds the threshold value the method may end. Alternatively if the counter does not exceed the threshold value which indicates that additional levels of the Laplacian pyramid are to be generated the method may again proceed to block . In a second iteration of the method the down sampled first filtered image data from the initial iteration of the method may be selected as the source image data. Similarly for each subsequent iteration of the method the down sampled first filtered image data from the previous iteration may be selected as the source image data at block .

In each iteration of the method subsequent to the initial iteration the down sampled first filtered image data from a previous iteration may be low pass filtered at block to obtain first filtered image data and may be band passed filtered at block using the first filtered image data to obtain second filtered image data. At block the second filtered image data may be stored in the ordered data structure at a subsequent location in the data structure corresponding to a subsequent level of the Laplacian pyramid . The second filtered image data may be down sampled at block and the down sampled image data may serve as the source image data for a next iteration if performed . The counter may again be incremented at block and the operations of blocks may be iteratively performed until a negative determination is made at block . Upon completion of a final iteration of method the second filtered image data corresponding to a highest level of the Laplacian pyramid may include image data for a smallest number of pixels compared to second filtered image data corresponding to any other level of the Laplacian pyramid .

It should be appreciated that the low pass filter and band pass filter applied as part of method may be applied to each image signal corresponding to each pixel in image data. As such the i j coordinate pairs depicted in may represent the respective coordinate pair in an X Y coordinate plane for each pixel having a corresponding light intensity value represented in image data. In certain example embodiments the filtered image data corresponding to each successive level of the Laplacian pyramid may include a greater number of high frequency components than the filtered image data corresponding to a previous level of the Laplacian pyramid .

At block a counter may be initialized. In certain example embodiments the value to which the counter is initialized may be zero. In such example embodiments the counter may be incremented at each iteration of the method and the method may cease when the counter exceeds a threshold value such as a predetermined number of iterations of the method which may in turn correspond to a number of levels of the Laplacian pyramids from which the composite image frame Laplacian pyramid depicted in is to be generated. It should be appreciated that the counter may be initialized to a different value in various other example embodiments. For example the counter may be initialized to the predetermined number of iterations of the method e.g. the number of levels of the Laplacian pyramids from which the composite Laplacian pyramid is to be generated the counter may be decremented at each iteration and the method may cease when the counter equals zero. It should be appreciated that the above examples for counter initialization are merely illustrative and not exhaustive and that the counter may be initialized to any value.

At block a determination may be made as to whether the counter exceeds a threshold above. As previously noted in those example embodiments in which the counter is initialized to zero the threshold value may correspond to a predetermined number of iterations of the method which may in turn correspond to a number of levels of the Laplacian pyramids from which the composite image frame Laplacian pyramid is to be generated.

In response to a negative determination at block the method may proceed to block . At block in a first iteration of the method first image data stored in a first ordered data structure at a first location having an index corresponding to the counter value may be selected. The first image data selected at block in a first iteration of the method may include for example IR NIR image data corresponding to an Llevel of the IR NIR image frame Laplacian pyramid . As previously noted the pyramid or any other Laplacian pyramid described herein may be represented in data storage using any suitable ordered data structure that indicates an order of image data corresponding to different levels of the pyramid .

At block second image data may be selected. The second image data may be stored in a second ordered data structure at a location that corresponds to the location at which the first image data is stored in the first ordered data structure. For example the second ordered data structure may store the image data corresponding to the VW image frame Laplacian pyramid . The second image data selected at block as part of a first iteration of the method may include for example VW band image data corresponding to an Llevel of the VW image frame Laplacian pyramid .

At block composite image data may be generated at least in part by selecting a respective maximum light intensity value from the first image data or the second image data for each pixel having light intensity values represented in the first and second image data. For example for any given pixel if the light intensity for that pixel e.g. the number of photons detected at a corresponding image sensor pixel is greater in the IR NIR image data than in the VW image data the light intensity value from the IR NIR image data may be selected for inclusion in the composite image data. Conversely if the light intensity value for a pixel is greater in the VW image data than in the IR NIR image data the light intensity value from the VW image data may be selected for inclusion in the composite image data. In this manner in a first iteration of the method composite image data may be generated for a first level Llevel of a composite image frame Laplacian pyramid based on image data at corresponding levels of the IR NIR image frame Laplacian pyramid and the VW image frame Laplacian pyramid .

At block the composite image data generated at block may be stored. The composite image data may be stored in a third ordered data structure corresponding to the composite image frame Laplacian pyramid . More specifically the composite image data generated at block may be stored at a location in the third ordered data structure that corresponds to the locations at which the first image data and the second image data are stored in the first ordered data structure and the second ordered data structure respectively. In this manner the composite image data corresponding to a particular level of the composite image frame Laplacian pyramid may be correlated to image data at corresponding levels of the IR NIR image frame Laplacian pyramid and the VW image frame Laplacian pyramid .

At block the counter may be incremented and the method may proceed again to block where the incremented counter may be compared against the threshold value. The method may proceed iteratively as long as the counter does not exceed the threshold value. At each subsequent iteration of the method image data having a maximum pixel intensity may be selected on a per pixel basis from the IR NIR image data or from the VW image data that respectively corresponds to subsequent levels of the IR NIR image frame Laplacian pyramid and the VW image frame Laplacian pyramid . The selected image data may be stored as composite image data for a corresponding level of the pyramid . For example in a second iteration of the method the maximum pixel intensities may be selected from the LIR NIR image data or the LVW image data to generate the Lcomposite image data. The method may proceed iteratively until it is determined at block that the counter exceeds the threshold value at which point composite image data has been generated for each level of the pyramid .

At block a counter may be initialized. In certain example embodiments the counter may be initialized to a largest index of an ordered data structure storing composite image data. The ordered data structure may store composite image data corresponding to the composite image frame Laplacian pyramid generated in accordance with the example method of for example. The counter may be decremented at each iteration of the method and the method may cease when the counter equals zero which may correspond to a scenario in which an up scaling operation has been performed with respect to all levels of the pyramid . It should be appreciated that the counter may be initialized to a different value in various other example embodiments. For example the counter may be initialized to zero and may be incremented at each iteration of the method . The method may then cease when the counter exceeds a threshold value corresponding to the number of levels in the pyramid . In such embodiments the appropriate composite image data may be accessed at each iteration of the method based on pre existing knowledge of the correspondence between the order in which the composite image data is stored in the ordered data structure and the levels of the pyramid . It should be appreciated that the above examples for counter initialization are merely illustrative and not exhaustive and that the counter may be initialized to any value.

At block a determination may be made as to whether the counter equals zero. In response to a negative determination the method may proceed to block . At block in a first iteration of the method composite image data stored in the ordered data structure at an index corresponding to the counter value may be selected as source image data. The source image data selected during a first iteration of the method may include the composite image data corresponding to the Llevel of the pyramid .

At block the source image data selected at block may be up sampled to generate up sampled composite image data . In certain example embodiments up sampling may include increasing the amount of source image data by an integer or rational number factor to generate intermediate source image data and may further include applying a low pass filter to the intermediate source image data e.g. convoluting the intermediate source image data with a Gaussian function to generate the up sampled composite image data . In certain example embodiments up sampling the source image may include interlacing zero intensity pixel values with the source image data.

At block the up sampled composite image data may be summed or otherwise combined with the composite image data corresponding to a next level of the pyramid e.g. the Llevel . In an example embodiment of the disclosure the composite image data may be identified by decrementing the counter at block and selecting composite image data stored in the ordered data structure at an index corresponding to the decremented counter value.

At block the summed image data may be stored and the method may again proceed to block where a determination may be made as to whether the counter equals zero. As long as the counter is non zero the operations at blocks may be performed iteratively. During each subsequent iteration of the method after the initial iteration the source image data selected at block may be the summed image data generated during a previous iteration of the method .

During a final iteration of the method a source image which may correspond to a summed image generated during a previous iteration of the method may be up sampled at block to generate a final up sampled image . The final up sampled image may not be summed with other composite image data because no additional levels of the pyramid may remain for processing. However the final up sampled image may be summed or otherwise combined with initial low pass filtered image data to generate final output image data . The initial low pass filtered image data may correspond to the low pass filtered image data generated at block during a first iteration of the example method in connection with generation of any of the constituent Laplacian pyramids used to generate the composite image data.

At block a pupil region in the final output image data may be identified. The pupil region may be identified by a comparing a first light intensity gradient between light intensity values for a first set of pixels and light intensity values for a second set of neighboring pixels to a first threshold value. If the first light intensity gradient exceeds the first threshold value it may be determined that the first set of pixels corresponds at least in part to a boundary of the pupil region. Certain assumptions may be made to assist in selecting various first and second sets of pixels. For example it may be assumed that the pupil region is roughly circular and upon selection of a first set of pixels the second set of neighboring pixels may be selected by moving radially outward from the first set of pixels.

At block the iris region in the final output image data may be identified by comparing a second light intensity gradient between light intensity values for a third set of pixels and light intensity values for a fourth set of neighboring pixels to a second threshold value. If the second light intensity gradient exceeds the second threshold value it may be determined that the third set of pixels corresponds at least in part to an outer boundary of the iris region. The inner boundary of the iris region may correspond to the boundary of the pupil region as determined at block .

Finally at block feature extraction processing may be performed on the iris region identified at block to generate a template iris pattern for the individual. The template iris pattern may be stored and used for subsequent biometric identification authentication.

The bus es may include at least one of a system bus a memory bus an address bus or a message bus and may permit exchange of information e.g. data including computer executable code signaling etc. between various components of the device . The bus es may include without limitation a memory bus or a memory controller a peripheral bus an accelerated graphics port and so forth. The bus es may be associated with any suitable bus architecture including without limitation an Industry Standard Architecture ISA a Micro Channel Architecture MCA an Enhanced ISA EISA a Video Electronics Standards Association VESA architecture an Accelerated Graphics Port AGP architecture a Peripheral Component Interconnects PCI architecture a PCI Express architecture a Personal Computer Memory Card International Association PCMCIA architecture a Universal Serial Bus USB architecture and so forth.

The memory of the device may include volatile memory memory that maintains its state when supplied with power such as random access memory RAM and or non volatile memory memory that maintains its state even when not supplied with power such as read only memory ROM flash memory ferroelectric RAM FRAM and so forth. In certain example embodiments volatile memory may enable faster read write access than non volatile memory. However in certain other example embodiments certain types of non volatile memory e.g. FRAM may enable faster read write access than certain types of volatile memory.

In various implementations the memory may include multiple different types of memory such as various types of static random access memory SRAM various types of dynamic random access memory DRAM various types of unalterable ROM and or writeable variants of ROM such as electrically erasable programmable read only memory EEPROM flash memory and so forth. The memory may include main memory as well as various forms of cache memory such as instruction cache s data cache s translation lookaside buffer s TLBs and so forth. Further cache memory such as a data cache may be a multi level cache organized as a hierarchy of one or more cache levels L1 L2 etc. .

The data storage may include removable storage and or non removable storage including but not limited to magnetic storage optical disk storage solid state storage and or tape storage. The data storage may provide non volatile storage of computer executable instructions and other data. The memory and the data storage removable and or non removable are examples of computer readable storage media CRSM as that term is used herein.

The data storage may store computer executable code instructions or the like that may be loadable into the memory and executable by the processor s to cause the processor s to perform or initiate various operations. The data storage may additionally store data that may be copied to memory for use by the processor s during the execution of the computer executable instructions. Moreover output data generated as a result of execution of the computer executable instructions by the processor s may be stored initially in memory and may ultimately be copied to data storage for non volatile storage.

More specifically the data storage may store one or more operating systems O S one or more database management systems DBMS and one or more program modules applications or the like such as for example one or more low pass filtering modules one or more band pass filtering modules one or more up sampling modules one or more down sampling modules one or more composite image data generation modules and one or more iris template pattern generation modules . The data storage may further store any of a variety of other types of modules. Further any program modules stored in the data storage may include one or more sub modules. Further any data stored in the data storage may be loaded into the memory for use by the processor s in executing computer executable code. In addition any data potentially stored in one or more datastores e.g. captured image data processed image data or iris template patterns may be accessed via the DBMS and loaded in the memory for use by the processor s in executing computer executable code.

The processor s may be configured to access the memory and execute computer executable instructions loaded therein. For example the processor s may be configured to execute computer executable instructions of the various program modules of the device to cause or facilitate various operations to be performed in accordance with one or more embodiments of the disclosure. The processor s may include any suitable processing unit capable of accepting data as input processing the input data in accordance with stored computer executable instructions and generating output data. The processor s may include any type of suitable processing unit including but not limited to a central processing unit a microprocessor a Reduced Instruction Set Computer RISC microprocessor a Complex Instruction Set Computer CISC microprocessor a microcontroller an Application Specific Integrated Circuit ASIC a Field Programmable Gate Array FPGA a System on a Chip SoC a digital signal processor DSP and so forth. Further the processor s may have any suitable microarchitecture design that includes any number of constituent components such as for example registers multiplexers arithmetic logic units cache controllers for controlling read write operations to cache memory branch predictors or the like. The microarchitecture design of the processor s may be capable of supporting any of a variety of instruction sets.

Referring now to functionality supported by the various program modules depicted in the low pass filtering module s may include computer executable instructions code or the like that responsive to execution by one or more of the processor s may cause a low pass filter to be applied to image data as part of for example the method for generating a Laplacian pyramid for an image. As previously described the low pass filter may include for example a Gaussian filter.

The band pass filtering module s may include computer executable instructions code or the like that responsive to execution by one or more of the processor s may cause a band pass filter to be applied to source image data using filtered data obtained from a low pass filtering operation in order to obtain band pass filtered data. In certain example embodiments application of a band pass filter may include generating a difference image by subtracting low pass filtered data from source image data.

The up sampling module s may include computer executable instructions code or the like that responsive to execution by one or more of the processor s may cause image data to be up sampled to increase the pixel density of the image data. The up sampling module s may be executed for example as part of the method for generating final output image data.

The down sampling module s may include computer executable instructions code or the like that responsive to execution by one or more of the processor s may cause image data to be down sampled to decrease the pixel density of the image data. The down sampling module s may be executed for example as part of the method for generating a Laplacian pyramid for an image frame.

The composite image data generation module s may include computer executable instructions code or the like that responsive to execution by one or more of the processor s may cause any of the operations of method to be performed.

The iris template pattern generation module s may include computer executable instructions code or the like that responsive to execution by one or more of the processor s may cause any of the operations of method to be performed.

Referring now to other illustrative components depicted as being stored in the data storage the O S may be loaded from the data storage into the memory and may provide an interface between other application software executing on the device and hardware resources of the device . More specifically the O S may include a set of computer executable instructions for managing hardware resources of the device and for providing common services to other application programs e.g. managing memory allocation among various application programs . The O S may include any operating system now known or which may be developed in the future including but not limited to any server operating system any mainframe operating system or any other proprietary or non proprietary operating system.

The DBMS may be loaded into the memory and may support functionality for accessing retrieving storing and or manipulating data stored in the memory data stored in the data storage and or data stored in the one or more datastores . The DBMS may use any of a variety of database models e.g. relational model object model etc. and may support any of a variety of query languages. The DBMS may access data represented in one or more data schemas and stored in any suitable data repository including but not limited to databases e.g. relational object oriented etc. file systems flat files distributed datastores in which data is stored on more than one node of a computer network peer to peer network datastores or the like. In those example embodiments in which the device is a mobile device the DBMS may be any suitable light weight DBMS optimized for performance on a mobile device. Referring to the example types of data depicted as being stored in the datastore s the captured image data may include any number of IR NIR and or VW image frames. The processed image data may include any data generated as a result of any of the image processing described herein e.g. filtered data corresponding to a Laplacian pyramid composite image data final output image data etc. . The iris template patterns may include template patterns generated from final output image data. It should be appreciated that data as that term is used herein includes computer executable instructions code or the like.

Referring now to other illustrative components of the device the one or more input output I O interfaces may facilitate the receipt of input information by the device from one or more I O devices as well as the output of information from the device to the one or more I O devices. The I O devices may include any of a variety of components such as a display or display screen having a touch surface or touchscreen an audio output device for producing sound such as a speaker an audio capture device such as a microphone an image and or video capture device such as a camera a haptic unit and so forth. Any of these components may be integrated into the device or may be separate. The I O devices may further include for example any number of peripheral devices such as data storage devices printing devices and so forth.

The I O interface s may also include an interface for an external peripheral device connection such as universal serial bus USB FireWire Thunderbolt Ethernet port or other connection protocol that may connect to one or more networks. The I O interface s may also include a connection to one or more antennas to connect to one or more networks via a wireless local area network WLAN such as Wi Fi radio Bluetooth and or a wireless network radio such as a radio capable of communication with a wireless communication network such as a Long Term Evolution LTE network WiMAX network 3G network etc.

The device may further include one or more network interfaces via which the device may communicate with any of a variety of other systems platforms networks devices and so forth. Such communication may occur via one or more networks including but are not limited to any one or more different types of communications networks such as for example cable networks public networks e.g. the Internet private networks e.g. frame relay networks wireless networks cellular networks telephone networks e.g. a public switched telephone network or any other suitable private or public packet switched or circuit switched networks. Further such network s may have any suitable communication range associated therewith and may include for example global networks e.g. the Internet metropolitan area networks MANs wide area networks WANs local area networks LANs or personal area networks PANs . In addition such network s may include communication links and associated networking devices e.g. link layer switches routers etc. for transmitting network traffic over any suitable type of medium including but not limited to coaxial cable twisted pair wire e.g. twisted pair copper wire optical fiber a hybrid fiber coaxial HFC medium a microwave medium a radio frequency communication medium a satellite communication medium or any combination thereof.

The sensor s sensor interface s may include or may be capable of interfacing with any suitable type of sensing device such as for example ambient light sensors inertial sensors force sensors thermal sensors image sensors magnetometers and so forth. Example types of inertial sensors may include accelerometers e.g. MEMS based accelerometers gyroscopes and so forth.

The device may be provided with antenna s not shown which may include any suitable type of antenna depending for example on the communications protocols used to transmit or receive signals via the antenna s . Non limiting examples of suitable antennas may include directional antennas non directional antennas dipole antennas folded dipole antennas patch antennas multiple input multiple output MIMO antennas or the like. The antenna s may be communicatively coupled to one or more transceivers or radio components not shown to which or from which signals may be transmitted or received.

It should be appreciated that the program modules applications computer executable instructions code or the like depicted in as being stored in the data storage are merely illustrative and not exhaustive and that processing described as being supported by any particular module may alternatively be distributed across multiple modules or performed by a different module. In addition various program module s script s plug in s Application Programming Interface s API s or any other suitable computer executable code hosted locally on the device and or hosted on other computing device s accessible via one or more networks may be provided to support functionality provided by the program modules applications or computer executable code depicted in and or additional or alternate functionality. Further functionality may be modularized differently such that processing described as being supported collectively by the collection of program modules depicted in may be performed by a fewer or greater number of modules or functionality described as being supported by any particular module may be supported at least in part by another module. In addition program modules that support the functionality described herein may form part of one or more applications executable across any number of systems or devices in accordance with any suitable computing model such as for example a client server model a peer to peer model and so forth. In addition any of the functionality described as being supported by any of the program modules depicted in may be implemented at least partially in hardware and or firmware across any number of devices.

It should further be appreciated that the device may include alternate and or additional hardware software or firmware components beyond those described or depicted without departing from the scope of the disclosure. More particularly it should be appreciated that software firmware or hardware components depicted as forming part of the device are merely illustrative and that some components may not be present or additional components may be provided in various embodiments. While various illustrative program modules have been depicted and described as software modules stored in data storage it should be appreciated that functionality described as being supported by the program modules may be enabled by any combination of hardware software and or firmware. It should further be appreciated that each of the above mentioned modules may in various embodiments represent a logical partitioning of supported functionality. This logical partitioning is depicted for ease of explanation of the functionality and may not be representative of the structure of software hardware and or firmware for implementing the functionality. Accordingly it should be appreciated that functionality described as being provided by a particular module may in various embodiments be provided at least in part by one or more other modules. Further one or more depicted modules may not be present in certain embodiments while in other embodiments additional modules not depicted may be present and may support at least a portion of the described functionality and or additional functionality. Moreover while certain modules may be depicted and described as sub modules of another module in certain embodiments such modules may be provided as independent modules or as sub modules of other modules.

One or more operations of the methods may have been described above as being performed by one or more components of the device or more specifically by one or more one or more program modules executing on such a device . It should be appreciated however that any of the operations of methods may be performed at least in part in a distributed manner by one or more other devices or systems or more specifically by one or more program modules applications or the like executing on such devices. In addition it should be appreciated that processing performed in response to execution of computer executable instructions provided as part of an application program module or the like may be interchangeably described herein as being performed by the application or the program module itself or by a device on which the application program module or the like is executing. While the operations of any of the methods may be described in the context of the illustrative device it should be appreciated that such operations may be implemented in connection with numerous other system configurations.

The operations described and depicted in the illustrative methods of may be carried out or performed in any suitable order as desired in various example embodiments of the disclosure. Additionally in certain example embodiments at least a portion of the operations may be carried out in parallel. Furthermore in certain example embodiments less more or different operations than those depicted in may be performed.

Although specific embodiments of the disclosure have been described one of ordinary skill in the art will recognize that numerous other modifications and alternative embodiments are within the scope of the disclosure. For example any of the functionality and or processing capabilities described with respect to a particular device or component may be performed by any other device or component. Further while various illustrative implementations and architectures have been described in accordance with embodiments of the disclosure one of ordinary skill in the art will appreciate that numerous other modifications to the illustrative implementations and architectures described herein are also within the scope of this disclosure.

Certain aspects of the disclosure are described above with reference to block and flow diagrams of systems methods apparatuses and or computer program products according to example embodiments. It will be understood that one or more blocks of the block diagrams and flow diagrams and combinations of blocks in the block diagrams and the flow diagrams respectively may be implemented by execution of computer executable program instructions. Likewise some blocks of the block diagrams and flow diagrams may not necessarily need to be performed in the order presented or may not necessarily need to be performed at all according to some embodiments. Further additional components and or operations beyond those depicted in blocks of the block and or flow diagrams may be present in certain embodiments.

Accordingly blocks of the block diagrams and flow diagrams support combinations of means for performing the specified functions combinations of elements or steps for performing the specified functions and program instruction means for performing the specified functions. It will also be understood that each block of the block diagrams and flow diagrams and combinations of blocks in the block diagrams and flow diagrams may be implemented by special purpose hardware based computer systems that perform the specified functions elements or steps or combinations of special purpose hardware and computer instructions.

Program modules applications or the like disclosed herein may include one or more software components including for example software objects methods data structures or the like. Each such software component may include computer executable instructions that responsive to execution cause at least a portion of the functionality described herein e.g. one or more operations of the illustrative methods described herein to be performed.

A software component may be coded in any of a variety of programming languages. An illustrative programming language may be a lower level programming language such as an assembly language associated with a particular hardware architecture and or operating system platform. A software component comprising assembly language instructions may require conversion into executable machine code by an assembler prior to execution by the hardware architecture and or platform.

Another example programming language may be a higher level programming language that may be portable across multiple architectures. A software component comprising higher level programming language instructions may require conversion to an intermediate representation by an interpreter or a compiler prior to execution.

Other examples of programming languages include but are not limited to a macro language a shell or command language a job control language a script language a database query or search language or a report writing language. In one or more example embodiments a software component comprising instructions in one of the foregoing examples of programming languages may be executed directly by an operating system or other software component without having to be first transformed into another form.

A software component may be stored as a file or other data storage construct. Software components of a similar type or functionally related may be stored together such as for example in a particular directory folder or library. Software components may be static e.g. pre established or fixed or dynamic e.g. created or modified at the time of execution .

Software components may invoke or be invoked by other software components through any of a wide variety of mechanisms. Invoked or invoking software components may comprise other custom developed application software operating system functionality e.g. device drivers data storage e.g. file management routines other common routines and services etc. or third party software components e.g. middleware encryption or other security software database management software file transfer or other network communication software mathematical or statistical software image processing software and format translation software .

Software components associated with a particular solution or system may reside and be executed on a single platform or may be distributed across multiple platforms. The multiple platforms may be associated with more than one hardware vendor underlying chip technology or operating system. Furthermore software components associated with a particular solution or system may be initially written in one or more programming languages but may invoke software components written in another programming language.

Computer executable program instructions may be loaded onto a special purpose computer or other particular machine a processor or other programmable data processing apparatus to produce a particular machine such that execution of the instructions on the computer processor or other programmable data processing apparatus causes one or more functions or operations specified in the flow diagrams to be performed. These computer program instructions may also be stored in a computer readable storage medium CRSM that upon execution may direct a computer or other programmable data processing apparatus to function in a particular manner such that the instructions stored in the computer readable storage medium produce an article of manufacture including instruction means that implement one or more functions or operations specified in the flow diagrams. The computer program instructions may also be loaded onto a computer or other programmable data processing apparatus to cause a series of operational elements or steps to be performed on the computer or other programmable apparatus to produce a computer implemented process.

Additional types of CRSM that may be present in any of the devices described herein may include but are not limited to programmable random access memory PRAM SRAM DRAM RAM ROM electrically erasable programmable read only memory EEPROM flash memory or other memory technology compact disc read only memory CD ROM digital versatile disc DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the information and which can be accessed. Combinations of any of the above are also included within the scope of CRSM. Alternatively computer readable communication media CRCM may include computer readable instructions program modules or other data transmitted within a data signal such as a carrier wave or other transmission. However as used herein CRSM does not include CRCM.

Although embodiments have been described in language specific to structural features and or methodological acts it is to be understood that the disclosure is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as illustrative forms of implementing the embodiments. Conditional language such as among others can could might or may unless specifically stated otherwise or otherwise understood within the context as used is generally intended to convey that certain embodiments could include while other embodiments do not include certain features elements and or steps. Thus such conditional language is not generally intended to imply that features elements and or steps are in any way required for one or more embodiments or that one or more embodiments necessarily include logic for deciding with or without user input or prompting whether these features elements and or steps are included or are to be performed in any particular embodiment.

