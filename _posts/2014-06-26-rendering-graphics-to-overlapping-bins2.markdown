---

title: Rendering graphics to overlapping bins
abstract: In an example, a method for rendering graphics data includes rendering pixels of a first bin of a plurality of bins, wherein the pixels of the first bin are associated with a first portion of an image, and rendering, to the first bin, one or more pixels that are located outside the first portion of the image and associated with a second, different bin of the plurality of bins. The method also includes rendering the one or more pixels associated with the second bin to the second bin, such that the one or more pixels are rendered to both the first bin and the second bin.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09569811&OS=09569811&RS=09569811
owner: QUALCOMM Incorporated
number: 09569811
owner_city: San Diego
owner_country: US
publication_date: 20140626
---
A device that provides content for visual presentation on an electronic display generally includes a graphics processing unit GPU . The GPU renders pixels that are representative of the content on a display. The GPU generates one or more pixel values for each pixel on the display and performs graphics processing on the pixel values for each pixel on the display to render each pixel for presentation.

The techniques of this disclosure generally relate to rendering graphics data. For example the techniques of this disclosure include rendering a series of overlapping bins. That is according to the techniques of this disclosure a GPU may render pixels of a bin that are associated with a particular portion of an image. The GPU may also render one or more pixels that are associated with another bin and located outside the first bin when rendering the first bin. The GPU may render those pixels again when rendering the other bin. The techniques of this disclosure may in some instances allow the GPU to perform filtering operations on pixels located near the edge of a bin e.g. by rendering one or more pixels located outside of the bin to be used as source pixels for performing filtering operations on the pixels located at the edge of the bin.

In an example a method for rendering graphics data includes rendering pixels of a first bin of a plurality of bins wherein the pixels of the first bin are associated with a first portion of an image rendering to the first bin one or more pixels that are located outside the first portion of the image and associated with a second different bin of the plurality of bins and rendering the one or more pixels associated with the second bin to the second bin such that the one or more pixels are rendered to both the first bin and the second bin.

In another example a device for rendering graphics data includes a memory storing the graphics data and one or more processors configured to render the graphics data. The one or more processors are configured to render pixels of the graphics data of a first bin of a plurality of bins wherein the pixels of the first bin are associated with a first portion of an image render to the first bin one or more pixels that are located outside the first portion of the image and associated with a second different bin of the plurality of bins and render the one or more pixels associated with the second bin to the second bin such that the one or more pixels are rendered to both the first bin and the second bin.

In another example a device for rendering graphics data includes means for rendering pixels of a first bin of a plurality of bins wherein the pixels of the first bin are associated with a first portion of an image means for rendering to the first bin one or more pixels that are located outside the first portion of the image and associated with a second different bin of the plurality of bins and means for rendering the one or more pixels associated with the second bin to the second bin such that the one or more pixels are rendered to both the first bin and the second bin.

In another example a non transitory computer readable medium has instructions stored thereon that when executed cause one or more processors to render pixels of a first bin of a plurality of bins wherein the pixels of the first bin are associated with a first portion of an image render to the first bin one or more pixels that are located outside the first portion of the image and associated with a second different bin of the plurality of bins and render the one or more pixels associated with the second bin to the second bin such that the one or more pixels are rendered to both the first bin and the second bin.

The details of one or more examples of the disclosure are set forth in the accompanying drawings and the description below. Other features objects and advantages will be apparent from the description and drawings and from the claims.

Traditional graphics processing unit GPU architectures may require a relatively large amount of data to be read from and written to system memory when rendering a frame of graphics data which may be referred to as an image . Mobile architectures may lack the bandwidth capacity required for processing entire frames of data. Accordingly tile based architectures have been developed that break an image into multiple tiles. The tiles are sized so that they can be processed using a relatively small amount e.g. 256 kB of high bandwidth on chip graphics memory. That is the size of each tile may depend on the amount of available on chip graphics memory. The image is then reconstructed after processing each tile individually.

Tile based rendering may be described with respect to a number of processing passes. For example when performing tile based rendering a GPU may perform a binning pass and a rendering pass. With respect to the binning pass the GPU may process an entire image and sort rasterized primitives such as triangles into tile sized areas that may be referred to as bins. For example the GPU processes a command stream for an entire image and assigns the rasterized primitives of the image to bins.

In some examples the GPU generates one or more visibility streams during the binning pass. A visibility stream indicates the primitives that are visible in the final image and the primitives that are invisible in the final image. For example a primitive may be invisible if it is obscured by one or more other primitives such that the primitive cannot be seen in the shaded finished image.

A visibility stream may be generated for an entire image or may be generated on a per bin basis e.g. one visibility stream for each bin . In general a visibility stream may include a series of 1 s and 0 s with each 1 or 0 being associated with a particular primitive. Each 1 indicates that the primitive is visible in the final image. Each 0 indicates that the primitive is invisible in the final image. The visibility stream may control the rendering pass described below . For example the visibility stream may be used to skip sequences of invisible primitives during rendering. Accordingly only the primitives that actually contribute to a bin i.e. that are visible in the final image are rendered and shaded thereby reducing shading operations.

In other examples a GPU may use a different process e.g. other than or in addition to the visibility streams described above to classify primitives as being located in a particular bin. In another example a GPU may output a separate list per bin of indices that represent only the primitives that are present in a given bin. For example the GPU may initially include all the primitives i.e. vertices in one data structure. The GPU may generate a set of pointers into the structure for each bin that only point to the primitives that are visible in each bin. Thus only pointers for visible indices are included in a per bin index list. Such pointers may serve a similar purpose as the visibility streams described above with the pointers indicating which primitives and pixels associated with the primitives are included and visible in a particular bin.

Each rendering pass may include a clear unresolve stage a rendering stage and a resolve stage. During the clear unresolve stage the GPU may initialize on chip memory for a new tile to be rendered. For example the GPU may initialize the on chip memory to a certain value clear or read values from external memory to the on chip memory unresolve . During the rendering stage the GPU may process the tile and store the processed tile to the on chip memory. That is the GPU may implement a graphics processing pipeline to determine pixel values and write the pixel values to the on chip memory. During the resolve stage the GPU may transfer the finished pixel values of the tile from the on chip memory to an external memory which may be referred to as a frame buffer. After finishing all of the tiles of an image e.g. storing all of the tiles of the image to the frame buffer the image is ready to be output e.g. displayed .

The GPU may perform one or more operations on images stored to the frame buffer. For example the GPU may scale an image stored to the frame buffer to change the resolution of the image. The GPU may perform such resolution scaling as a speed enhancement that has a quality performance tradeoff For example in some instances the GPU may render an image in a relatively lower resolution and scale the rendered image to a relatively higher resolution more quickly e.g. using fewer resources and or clock cycles than performing all of the operations needed to directly render the image at the higher resolution.

In order to perform scaling the GPU may apply a filter to an image stored in a frame buffer. For example as noted above the GPU may render each tile associated with an image to a frame buffer. Upon storing all of the tiles of the image to the frame buffer the GPU may copy and scale the image from a low resolution frame buffer to a higher resolution frame buffer. Accordingly in this example the GPU performs two copy operations including a first copy operation from on chip memory to the frame buffer when rendering each tile and a second copy operation from the low resolution frame buffer to the high resolution frame buffer.

Aspects of this disclosure may be used to eliminate the second copy operation. For example rather than scaling graphics data using a second copy operation at a frame buffer a GPU may use the techniques of this disclosure to scale graphics data when copying graphics data from on chip memory to a frame buffer. In this way the techniques may improve performance when scaling graphics data with a tile based renderer.

A GPU may apply to filter to a number of source pixels when scaling graphics data. For example the GPU may blend a number of pixels according to a particular filtering algorithm to generate interpolated pixels at sub pixel positions e.g. relative to original unfiltered pixel positions . Different filtering algorithms may require a different number of source pixels.

Certain filters e.g. such as the scaling filter as noted above may not be accurately applied in tile based rendering schemes. For example as noted above tile based rendering includes dividing an image into a number of tile sized bins and separately rendering the bins. After a GPU has rendered a bin and copied the data associated with the bin from the on chip memory to the frame buffer the GPU may no longer access that data. Accordingly the GPU may not access the source pixels needed for a particular filtering operation at the relative edges of a bin because the GPU may not access graphics data from multiple bins.

According to aspects of this disclosure a GPU may render a sequence of overlapping bins which may allow filtering to be performed in tile based rendering. For example the GPU may determine an initial binning configuration for an image. When rendering the image the GPU may render each bin as well as a number of pixels that may be used for filtering each bin e.g. such as a border region surrounding each bin and store the rendered pixels to an on chip memory. The GPU may then perform a filtering operation on the bin of graphics data e.g. a scaling operation when copying the rendered bin data from on chip memory to a frame buffer. The GPU may use the additional pixels of the border region when filtering the bin of graphics data. By filtering the graphics data using the additional pixels of the border region when copying the graphics data from the on chip memory to the frame buffer the GPU may avoid the copy operations that may be associated with filtering an image stored to the frame buffer.

While certain examples are described herein with respect to filtering graphics data for scaling the graphics data the techniques of this disclosure are not limited in this way. That is the techniques for rendering overlapping bins may be used in conjunction with a variety of different filters. In addition while certain techniques are described as being carried out by a GPU the techniques may be performed by a GPU a GPU driver e.g. as executed by a central processing unit CPU or a combination thereof.

In the example of computing device includes a central processing unit CPU having CPU memory a graphics processing unit GPU having GPU memory and one or more shading units a display unit a display buffer unit storing rendered data ren. data a user interface unit and a data storage unit . In addition storage unit may store GPU driver having compiler GPU program and locally compiled GPU program .

Examples of CPU include but are not limited to a digital signal processor DSP general purpose microprocessor application specific integrated circuit ASIC field programmable logic array FPGA or other equivalent integrated or discrete logic circuitry. Although CPU and GPU are illustrated as separate units in the example of in some examples CPU and GPU may be integrated into a single unit. CPU may execute one or more applications. Examples of the applications may include web browsers e mail applications spreadsheets video games audio and or video capture playback or editing applications or other applications that initiate the generation for image data to be presented via display unit .

In the example shown in CPU includes CPU memory . CPU memory may represent on chip storage or memory used in executing machine or object code. CPU memory may each comprise a hardware memory register capable of storing a fixed number of digital bits. CPU may be able to read values from or write values to local CPU memory more quickly than reading values from or writing values to storage unit which may be accessed e.g. over a system bus.

GPU represents one or more dedicated processors for performing graphical operations. That is for example GPU may be a dedicated hardware unit having fixed function and programmable components for rendering graphics and executing GPU applications. GPU may also include a DSP a general purpose microprocessor an ASIC an FPGA or other equivalent integrated or discrete logic circuitry.

GPU also includes GPU memory which may represent on chip storage or memory used in executing machine or object code. GPU memory may each comprise a hardware memory register capable of storing a fixed number of digital bits. GPU may be able to read values from or write values to local GPU memory more quickly than reading values from or writing values to storage unit which may be accessed e.g. over a system bus.

Display unit represents a unit capable of displaying video data images text or any other type of data for consumption by a viewer. Display unit may include a liquid crystal display LCD a light emitting diode LED display an organic LED OLED an active matrix OLED AMOLED display or the like.

Display buffer unit represents a memory or storage device dedicated to storing data for presentation of imagery such as computer generated graphics still images video frames or the like rendered data for display unit . Display buffer unit may represent a two dimensional buffer that includes a plurality of storage locations. The number of storage locations within display buffer unit may be substantially similar to the number of pixels to be displayed on display unit . For example if display unit is configured to include 640 480 pixels display buffer unit may include 640 480 storage locations storing pixel color and intensity information such as red green and blue pixel values or other color values.

Display buffer unit may store the final pixel values for each of the pixels processed by GPU . Display unit may retrieve the final pixel values from display buffer unit and display the final image based on the pixel values stored in display buffer unit .

User interface unit represents a unit with which a user may interact with or otherwise interface to communicate with other units of computing device such as CPU . Examples of user interface unit include but are not limited to a trackball a mouse a keyboard and other types of input devices. User interface unit may also be or include a touch screen and the touch screen may be incorporated as a part of display unit .

Storage unit may comprise one or more computer readable storage media. Examples of storage unit include but are not limited to a random access memory RAM a read only memory ROM an electrically erasable programmable read only memory EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices flash memory or any other medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a computer or a processor.

In some example implementations storage unit may include instructions that cause CPU and or GPU to perform the functions ascribed to CPU and GPU in this disclosure. Storage unit may in some examples be considered as a non transitory storage medium. The term non transitory may indicate that the storage medium is not embodied in a carrier wave or a propagated signal. However the term non transitory should not be interpreted to mean that storage unit is non movable. As one example storage unit may be removed from computing device and moved to another device. As another example a storage unit substantially similar to storage unit may be inserted into computing device . In certain examples a non transitory storage medium may store data that can over time change e.g. in RAM .

Storage unit stores a GPU driver and compiler GPU program and locally compiled GPU program . GPU driver represents a computer program or executable code that provides an interface to access GPU . CPU executes GPU driver or portions thereof to interface with GPU and for this reason GPU driver is shown in the example of as a dash lined box labeled GPU driver within CPU . GPU driver is accessible to programs or other executables executed by CPU including GPU program .

GPU program may include code written in a high level HL programming language e.g. using an application programming interface API . Examples of APIs include Open Computing Language OpenCL Open Graphics Library OpenGL and DirectX as developed by Microsoft Inc. In general an API includes a predetermined standardized set of commands that are executed by associated hardware. API commands allow a user to instruct hardware components of a GPU to execute commands without user knowledge as to the specifics of the hardware components.

GPU program may invoke or otherwise include one or more functions provided by GPU driver . CPU generally executes the program in which GPU program is embedded and upon encountering GPU program passes GPU program to GPU driver . CPU executes GPU driver in this context to process GPU program . That is for example GPU driver may process GPU program by compiling GPU program into object or machine code executable by GPU . This object code is shown in the example of as locally compiled GPU program .

In some examples compiler may operate in real time or near real time to compile GPU program during the execution of the program in which GPU program is embedded. For example compiler generally represents a unit that reduces HL instructions defined in accordance with a HL programming language to low level LL instructions of a LL programming language. After compilation these LL instructions are capable of being executed by specific types of processors or other types of hardware such as FPGAs ASICs and the like including e.g. CPU and GPU .

In the example of compiler may receive GPU program from CPU when executing HL code that includes GPU program . Compiler may compile GPU program to generate locally compiled GPU program that conforms to a LL programming language. Compiler then outputs locally compiled GPU program that includes the LL instructions.

GPU generally receives locally compiled GPU program as shown by the dashed lined box labeled locally compiled GPU program within GPU whereupon in some instances GPU renders one or more images and outputs the rendered images to display buffer unit . For example GPU may generate a number of primitives to be displayed at display unit . Primitives may include one or more of a line including curves splines etc. a point a circle an ellipse a polygon where typically a polygon is defined as a collection of one or more primitives or any other two dimensional 2D primitive. The term primitive may also refer to three dimensional 3D primitives such as cubes cylinders sphere cone pyramid torus or the like. Generally the term primitive refers to any basic geometric shape or element capable of being rendered by GPU for display as an image or frame in the context of video data via display unit .

GPU may transform primitives and other attributes e.g. that defines a color texture lighting camera configuration or other aspect of the primitives into a so called world space by applying one or more model transforms which may also be specified in the state data . Once transformed GPU may apply a view transform for the active camera which again may also be specified in the state data defining the camera to transform the coordinates of the primitives and lights into the camera or eye space. GPU may also perform vertex shading to render the appearance of the primitives in view of any active lights. GPU may perform vertex shading in one or more of the above model world or view space although it is commonly performed in the world space .

Once the primitives are shaded GPU may perform projections to project the image into a unit cube with extreme points as one example at 1 1 1 and 1 1 1 . This unit cube is commonly referred to as a canonical view volume. After transforming the model from the eye space to the canonical view volume GPU may perform clipping to remove any primitives that do not at least partially reside within the view volume. In other words GPU may remove any primitives that are not within the frame of the camera. GPU may then map the coordinates of the primitives from the view volume to the screen space effectively reducing the 3D coordinates of the primitives to the 2D coordinates of the screen.

Given the transformed and projected vertices defining the primitives with their associated shading data GPU may then rasterize the primitives. During rasterization GPU may apply any textures associated with the primitives where textures may comprise state data . GPU may also perform a Z buffer algorithm also referred to as a depth test during rasterization to determine whether any of the primitives and or objects are occluded by any other objects. The Z buffer algorithm sorts primitives according to their depth so that GPU knows the order in which to draw each primitive to the screen. When binning e.g. for tile based rendering shading may not be performed during rasterization. When rendering the primitives however GPU may compute and set colors for the pixels of the screen covered by the primitives. GPU then outputs rendered pixels to display buffer unit .

Display buffer unit may temporarily store the rendered pixels of the rendered image until the entire image is rendered. Display buffer unit may be considered as an image frame buffer in this context. Display buffer unit may transmit the rendered image to be displayed on display unit . While shown and described separately in some instances display buffer unit may form a portion of storage unit .

In some examples GPU may implement tile based rendering to render an image. For example GPU may implement a tile based architectures that renders an image by breaking the image into multiple portions referred to as tiles. The tiles may be sized based on the size of GPU memory . For example GPU may render a tile to GPU memory . Upon completion of the tile GPU may transfer the tile from GPU memory to storage unit and or display buffer unit as rendered data . After GPU has rendered all of the tiles associated with a frame in this way display buffer unit may output the finished image to display unit . Rendering images using multiple tiles may reduce the amount and or frequency of data transfer between GPU memory and storage unit .

When performing tile based rendering GPU driver may initially determine a binning configuration for rendering an image. For example GPU driver may determine a bin size based on the size of GPU memory . In addition GPU driver may apply a predetermined bin layout. For example GPU driver may set an initial bin in the upper left corner of an image. GPU driver may add bins from left to right and top to bottom of the image until the entire image has been divided into bins.

GPU driver also generates a command stream using GPU program . For example the command stream may contain instructions for rendering images from GPU program . GPU driver may add instructions to the command stream which are executed by GPU in the order in which they appear in the stream. The command steam may define the primitives that make up images from GPU program .

After the initial binning configuration and command stream has been set by GPU driver GPU may perform a binning pass and a rendering pass. With respect to the binning pass GPU may process an entire image and sort rasterized primitives into the bins of the initial binning configuration set by GPU driver . GPU may also generate a visibility stream or other information during the binning pass to indicate visible primitives which may be separated according to bin. For example GPU may generate a visibility stream that includes a series of 1 s and 0 s with each 1 indicating that associated pixels are visible in the final image and each 0 indicating that associated pixels are invisible in the final image. In other examples GPU may generate a per bin list of indices e.g. pointers to vertices that represent only the primitives that are present in a given bin. As described herein visibility information may generally refer to information such as visibility streams or other information that indicates which primitives and associated pixels are visible in a particular bin.

GPU driver may access the visibility information and generate command streams for rendering each bin. Accordingly the command streams may be set according to the initial binning configuration. That is the command streams may be generated and ordered so that GPU renders tiles of an image in the order of the initial binning configuration.

With respect to the rendering pass GPU may perform a clear unresolve stage a rendering stage and a resolve stage. During the clear unresolve stage GPU initializes GPU memory for a new tile to be rendered. During the rendering stage GPU may render the tile and store the rendered tile to GPU memory . That is GPU may perform pixel shading and other operations to determine pixel values for each pixel of the tile and write the pixel values to GPU memory . During the resolve stage GPU may transfer the finished pixel values of the tile from GPU memory to display buffer unit or storage unit .

GPU may perform one or more operations on rendered data that is stored to display buffer unit . For example GPU may filter rendered data that is stored to display buffer unit . In an example for purposes of illustration GPU may apply a scaling filter to rendered data to change the resolution of rendered data . Rendering data at a relatively lower resolution and scaling rendered data to a higher resolution may result in a performance enhancement with a quality cost because GPU may in some instances perform filtering operations more quickly than rendering the high resolution data.

In general GPU applies a filter to a number of source pixels when performing the filtering. For example GPU may execute a filtering kernel as described in greater detail for example with respect to to blend a number of pixels according to a particular filtering algorithm. In an example for purposes of illustration GPU may apply a filtering kernel to scale an image or portion of an image by generating a number of interpolated pixels. Different filtering algorithms may require a different number of source pixels.

However certain filters may not be directly and or accurately applied in tile based rendering schemes. For example as noted above tile based rendering includes dividing an image into a number of tile sized bins and separately rendering the bins. After GPU has rendered a bin and copied the data associated with the bin from GPU memory to display buffer unit GPU may no longer easily access that data e.g. without the latency associated with retrieving the data from display buffer unit . Accordingly GPU may not access the source pixels needed for a particular filtering operation at the relative edges of a bin because GPU does not have access to graphics data from multiple bins.

Accordingly in general filtering rendered data with a tile based renderer such as GPU involves an additional copy operation at display buffer unit . For example GPU may perform two copy operations including a first copy operation from GPU memory to display buffer unit when rendering each tile and a second copy operation from a first location in display buffer unit to a second location in display buffer unit . With respect to applying a scaling filter as an example after rendering all tiles of an image and storing the tiles to an initial location of display buffer unit GPU may apply a scaling filter to the image and copy the image to a second location of display buffer unit .

Aspects of this disclosure may be used to eliminate the second copy operation noted above. For example rather than filtering graphics data using a second copy operation at display buffer unit GPU may use the techniques of this disclosure to filter graphics data when copying the graphics data from GPU memory to display buffer unit . In this way the techniques may improve performance when filtering graphics data with a tile based renderer.

For example according to aspects of this disclosure GPU may render a sequence of overlapping bins. That is in an example for purposes of illustration GPU may render pixels of a first bin of a plurality of bins where the pixels of the first bin are associated with a first portion of an image. GPU may also include rendering to the first bin one or more pixels that are located outside the first portion and associated with a second different bin of the plurality of bins. GPU may also render the one or more pixels associated with the second bin to the second bin such that the one or more pixels are rendered to both the first bin and the second bin.

In general rendering to a bin may involve GPU shading pixels for a given portion of an image and storing the shaded pixels to GPU memory . For example GPU may perform a rendering pass in which GPU shades pixels for a portion of an image associated with a particular bin. However according to aspects of this disclosure GPU may also render one or more pixels that are located spatially outside of the portion of the image to the bin e.g. when rendering the particular bin and prior to rendering another different bin.

To be clear aspects of this disclosure allow one or more pixels of graphics data to be rendered with two separate bins. While a rasterized primitive may cross a tile boundary e.g. the primitive is visible in more than one bin typically GPU only assigns each pixel of the primitive to a single bin and renders each pixel once. That is as noted above GPU may generate visibility information during a binning pass that indicates visible pixels and may separate the visibility information according to bin. Hence GPU renders pixels a single time according to the visibility stream.

According to aspects of this disclosure GPU may render one or more pixels of an image to multiple different bins. That is GPU may render pixels of graphics data in a particular area of an image multiple times when rendering the image e.g. a single pixel is treated handled as occupying two bins . In example for purposes of illustration GPU may determine an initial binning configuration for an image. GPU may generate visibility information indicating the visible pixels of the bins. According to aspects of this disclosure GPU may mark pixels as being visible in multiple bins e.g. in multiple visibility streams. For example GPU may determine a border region that surrounds a given bin. The border region may include pixels of one or more other bins. GPU may mark the pixels of the border region as being visible in the given bin.

When rendering the given bin GPU renders the pixels of the bin as well as one or more pixels of the determined border region. For example as described in greater detail below GPU may determine a viewport for rendering the given bin that is larger than the given bin. GPU stores the rendered data including the one or more pixels of the border region to GPU memory . GPU may then apply a filter to the given bin when copying the rendered bin from GPU memory to display buffer unit e.g. during the above noted resolve stage . By filtering the graphics data using the additional pixels of the border region when copying the graphics data from GPU memory to display buffer unit GPU may avoid copy operations that may be associated with filtering an image stored to display buffer unit .

It should be understood that computing device is provided as merely an example and other computing devices performing the techniques of this disclosure may be arranged differently. For example while display buffer unit is shown and described separately from storage unit in other examples display unit buffer and storage unit may be incorporated into the same component.

Moreover it should be understood that computing device may include additional modules or units not shown in for purposes of clarity. For example computing device may include a transceiver unit for transmitting and receiving data and may include circuitry to allow wireless or wired communication between computing device and another device or a network. Computing device may also include a speaker and a microphone neither of which are shown in to effectuate telephonic communications in examples where computing device is a mobile wireless telephone such as a smartphone or a speaker and or a microphone where computing device is a media player or tablet computer. In some instances user interface unit and display unit may be external to computing device in examples where computing device is a desktop computer or other device that is equipped to interface with an external user interface or display.

Components of GPU may access GPU memory with relatively lower latency than accessing an external memory such as storage unit . For example GPU memory may be an on chip memory that is on chip with GPU and in relatively close proximity with GPU components and may be associated with a dedicated memory bus within GPU . To access data stored in storage unit in contrast GPU may have to share a memory bus with other components of computing device such as CPU which may result in a more limited available bandwidth.

To take advantage of the high bandwidth low latency GPU memory as described above GPU may render graphics using a tile based rendering architecture. GPU may divide an image which may also be referred to as a scene into smaller portions e.g. tiles . GPU memory may store data associated with a tile while GPU renders the tile. After rendering the tile GPU may resolve or copy the rendered pixel data from GPU memory to display buffer unit via a memory bus.

Command processor may be responsible for reading a command stream from GPU driver . For example as described above with respect to GPU driver may issue instructions for execution by GPU which may be referred to as a command stream. Command processor may read and or decode the instructions of the command stream. In some examples command processor may read from a buffer containing the instructions of the command stream. Command processor may also initiate execution of the instructions at GPU . For example command processor may feed instructions to a thread scheduler that schedules the instructions to be executed by processing units .

Processing units may include one or more processing units each of which may be a programmable processing unit or a fixed function processing unit. In some examples a programmable shader unit may include a plurality of processing units that are configured to operate in parallel e.g. as an SIMD pipeline. A programmable shader unit may have a program memory that stores shader program instructions and an execution state register e.g. a program counter register that indicates the current instruction in the program memory being executed or the next instruction to be fetched. The programmable shader units in processing units may include for example vertex shader units pixel shader units geometry shader units hull shader units domain shader units tessellation control shader units tessellation evaluation shader units compute shader units and or unified shader units.

Processing units may be responsible for executing instructions. For example processing units may be responsible for executing one or more shader programs. A shader program in some examples may be a compiled version of a program written in a high level shading language such as e.g. an OpenGL Shading Language GLSL a High Level Shading Language HLSL a C for Graphics Cg shading language etc. In some examples a shader program may be referred to as a shader kernel. In general the shader kernel may include program code that defines a task or function to be performed by GPU .

Hence processing units may be programmable shading units responsible for vertex geometry and pixel shading operations. For example one or more of processing units may be responsible for determining vertex positions of primitives e.g. triangles that make up a scene to produce a triangle mesh of the scene. In addition one or more of processing units may be responsible for generating primitives from the triangle mesh as well as pixel filling and shading operations.

Processing units may be configured identically or may be individually configured to perform a specific task. For example one of processing units may be designated as a binning shader that is responsible for binning operations while the remaining processing units may be responsible for performing the vertex geometry or pixel shading operations described above.

Rasterizer may include one or more fixed function processing units that are hard wired to perform certain functions. Although the fixed function hardware may be configurable via one or more control signals for example to perform different functions the fixed function hardware typically does not include a program memory that is capable of receiving user compiled programs. In some examples rasterizer may be configured to perform raster operations such as e.g. depth testing scissors testing alpha blending etc.

In addition rasterizer may receive vertex information and may generate a representation of primitives of a scene. In some examples rasterizer applies predefined rules to received vertex information to determine which primitives are visible in the final scene. Rasterizer may cull or remove any invisible primitives of the scene. For example rasterizer may perform z buffering which may also be referred to as depth testing to identify primitives that are covered by other primitives and therefore not visible in the final scene.

Visibility unit may include any combination of fixed function hardware components and or programmable processing units. Visibility unit may receive the rasterized data from rasterizer and generate visibility information. In some examples visibility unit may generate one or more visibility streams. To generate the visibility stream visibility unit may distribute each of the visible primitives as determined by rasterizer to bins. Each bin may represent a tile of the finished scene. In other examples visibility unit may generate a per bin list of indices e.g. pointers to vertices that represent only the primitives that are present in a given bin.

With respect to visibility streams visibility unit may generate a separate visibility stream for each of the bins. For example visibility unit may generate a visibility stream for a particular bin by setting flags to indicate which pixels of primitives of the particular bin are visible and which pixels of primitives of the particular bin are invisible. According to some aspects visibility unit may set a flag value of 1 to indicate that a primitive is visible in the final scene and a flag value of 0 to indicate that a primitive is not visible in the final scene. In some examples visibility unit may operate according to a course rasterization of an image. That is rather than indicating the visibility status of each pixel visibility unit may determine visibility information on a coarser scale e.g. for blocks of four pixels .

In any case visibility unit may generate a plurality of visibility streams comprising flags that indicate the visible pixels of the primitives of each of the bins. In some examples visibility unit may compress the visibility streams. For example visibility unit may apply a compression scheme to reduce large strings of 0 flags and reduce the amount of memory required to restore the visibility streams.

According to aspects of this disclosure visibility unit includes overlap unit . Visibility unit may use overlap unit when generating visibility information for bins. For example overlap unit may determine an overlap region for each of the bins. The overlap region may include one or more pixels that are located outside the boundary of a particular bin. The overlap region may include for example a number of pixels that neighbor a particular bin. Overlap unit may mark one or more pixels that are located outside a particular bin as being visible pixels that are to be rendered with the particular bin.

In some examples overlap unit may implement an overlap region having a fixed size. For example overlap unit may implement an overlap region of 16 pixels. In this example overlap unit may determine an overlap region that includes a border of pixels wide outside a bin under consideration that is pixels wide and neighbors the bin. In other examples overlap unit may dynamically determine an overlap region. For example as noted above different filters may require a different number of source pixels. According to aspects of this disclosure overlap unit may determine an overlap region based on a filter being used on the rendered data. That is for a filter that considers eight source pixels overlap unit may determine an overlap region that includes all eight source pixels.

Filter unit may include programmable or fixed function processing units for filtering rendered graphics data. For example filter unit may access rendered graphics data e.g. shaded pixels from GPU memory and apply one or more filters to the graphics data. Filter unit may apply as examples any combination of anti aliasing filters Gaussian filters Lanczos filters bicubic filters bilinear sinc filters or the like.

In some examples filter unit may apply one or more filters to scale rendered graphics data. For example filter unit may execute one or more scaling kernels to interpolate pixel data and increase or decrease the resolution of an image. In some examples a user e.g. an application developer may select a particular scaling function to be executed by filter unit e.g. using an API. The user may select a scaling filter based on a rate performance tradeoff That is the user may select a scaling filter that considers a relatively large number of pixels to increase the visual quality of the scaled graphics data or a scaling filter that considers fewer source pixels to increase the speed with which filtering unit filters the graphics data. Thus in some examples filter unit may not be hard coded to execute a particular filtering kernel and may instead adaptively apply a particular scaling function.

While filter unit is illustrated in as a separate processing unit for purposes of explanation it should be understood that filter unit may be highly integrated with other components of GPU and or CPU . For example in some instances the functions attributed to filter unit above may instead or additionally be performed by processing units . That is one or more programmable shader units of processing units may be configured to execute one or more filtering kernels for filtering rendered graphics data.

In operation as noted above GPU may render an image using a binning pass and a rendering pass. During the binning pass GPU and or GPU driver may divide an image into tile sized bins. Command processor may process a command stream for an entire image. Rasterizer may rasterize and sort rasterized primitives such as triangles defined by the command stream to the bins. In some examples rasterizer may perform a so called coarse rasterization. That is rather than performing the rasterization on a per pixel basis rasterizer may rasterize primitives using a coarser grain processing e.g. 2 2 pixel blocks .

Visibility unit generates visibility information during the binning pass. As noted above visibility information indicates which primitives are visible in a final image that is to be output to display buffer unit . A primitive may be invisible if it is obscured by one or more other primitives such that the primitive cannot be seen in the shaded finished image.

According to aspects of this disclosure overlap unit may modify the manner in which visibility unit generates visibility information. For example in general visibility unit may mark pixels of an image as being visible in only one bin. That is while a rasterized primitive may span more than one bin visibility unit assigns each pixel of the primitive to a single bin e.g. to a single visibility stream associated with a single bin. However according to aspects of this disclosure overlap unit may mark a single pixel as being visible in more than one bin e.g. more than one visibility stream . By marking the pixel as being visible in more than one bin e.g. more than one visibility stream GPU may render the same pixel with more than one bin such that at least a portion of the bins include overlapping visible pixels.

As noted above overlap unit may in some examples implement an overlap region having a fixed size. In other examples overlap unit may dynamically determine the number of pixels in an overlap region e.g. based on a filter being applied to the rendered pixels. Overlap unit may roughly size the overlap region to accommodate a wide variety of possible filters. That is overlap unit may overestimate the size of the overlap region without incurring a large processing penalty. For example because rasterizer may perform binning operations using a relatively coarse grain overlap unit may also determine an overlap region using a relatively coarse grain.

Following the binning pass GPU may sequentially render each of the bins including the respective overlap regions for the bins. Each rendering pass may include a clear unresolve stage a rendering stage and a resolve stage. During the clear unresolve stage GPU may initialize GPU memory for a new bin to be rendered. For example GPU may initialize GPU memory to a certain value clear or read values from display buffer unit or storage unit to GPU memory unresolve .

During the rendering stage GPU may process each bin and store each processed bin to GPU memory . For example GPU may implement a graphics processing pipeline e.g. using processing units to determine pixel values. GPU then writes the shaded pixels to GPU memory .

According to aspects of this disclosure GPU and or GPU driver may determine an overlap region in which pixels are rendered to more than one bin for the image. GPU may size the overlap region used during the rendering pass to be the same as or different than the overlap region used during binning For example GPU may implement an overlap region having a fixed size. In other examples GPU may dynamically determine the number of pixels in an overlap region e.g. based on a filter being applied to the rendered pixels.

In some examples according to aspects of this disclosure GPU may apply a finer grain overlap region at the rendering passes for each bin than at the binning pass. For example because pixel shading during rendering may consume more processing resources than the binning visibility pass GPU may apply a more precise overlap region at the rendering passes than the binning pass. In some examples GPU may apply a relatively smaller overlap region at the rendering pass than at the binning pass.

To implement the overlap region when rendering GPU and or GPU driver may determine a viewport that is larger than the bin size. For example GPU may determine scissor parameters e.g. to be applied by rasterizer that are larger than the bin size. In this example GPU may set scissor parameters that include the bin size and the size of the overlap region.

In an example for purposes of illustration assume that an interior bin covering an interior region of an image is pixels wide and an overlap region is four pixels wide. In this example GPU may determine a scissor area that is pixels wide e.g. the 40 pixel bin width and four pixels on each side of the bin for the overlap region . GPU may use the portion of the visibility information consistent with the scissor area to shade the visible pixels to the bin and overlap region and store the shaded pixels to GPU memory . For example GPU renders the bin using the 48 pixel width. Accordingly GPU may render the four pixels of each of the adjacent bins twice e.g. once with the current bin and once when rendering the adjacent bin .

GPU may repeat the process described above for each bin. That is GPU may determine the size of the bin. GPU may then determine scissor parameters that include the bin and the overlap region. GPU may then render the pixels identified by the scissor region and store the rendered pixels to GPU memory . In this way GPU may render a series of overlapping bins.

During the resolve stage GPU may transfer the finished pixel values of a bin from GPU memory to display buffer unit . According to aspects of this disclosure filter unit may apply a filter to the rendered pixels when transferring the graphics data from GPU memory to display buffer unit . For example because the rendered data includes the pixels of the bin and the pixels of the overlap region filter unit may accurately apply a filter to all pixels of the bin including the pixels located at the edges of the bin. That is filter unit may identify source pixels in the overlap region when filtering pixels within the bin. After transferring all of the rendered and scaled bins from GPU memory to display buffer unit the image is ready to be output e.g. displayed .

In this way GPU may use the techniques of this disclosure to render overlapping bins and accurately apply one or more filters to the bins without a separate copy at display buffer unit . In some examples GPU may use the techniques to scale rendered data when transferring graphics data from GPU memory to display buffer unit .

In some examples GPU may dynamically determine whether to implement the techniques for rendering overlapping bins at the time of rendering. For example a flag or other indication may be provided e.g. via an API command that signals whether GPU will apply a filter to rendered data of an image. In this example GPU may read the flag prior to rendering the image an perform the techniques described herein to render overlapping bins for the image.

GPU driver may generate a command stream defining image for rendering by GPU . The command stream may include instructions for rendering primitives of objects as well as an initial binning configuration containing bin bin bin and bin . In some examples as noted above GPU driver may determine the size of bins based on a size of GPU memory . For example GPU driver may size bins such that data associated with each of the bins may be stored at GPU memory . Using bin as an example bin has a bin boundary that defines the size area of bin .

GPU driver may use a predetermined bin arrangement to break image into bins . That is in the example GPU driver may arrange the bins from left to right and top to bottom of image . Accordingly GPU may render image from left to right and top to bottom initially rendering bin followed by bin bin and bin . GPU driver may be preconfigured to determine the initial binning configuration.

According to aspects of this disclosure GPU defines an overlap region for bin as an example by setting overlap boundary . In general overlap boundary follows the contour of bin boundary and overlap region includes the pixels between bin boundary and overlap boundary . As described in greater detail below overlap boundary may be set a fixed distance a fixed number of pixels from bin boundary or may be dynamically determined prior to rendering. The fixed distance may be predetermined or may be programmable e.g. using an API command. Overlap boundary may be the same for both a binning pass and a rendering pass or may be set to different distances for the binning pass and the rendering pass.

In general GPU may render the pixels of overlap region when rendering more than one bin. With respect to pixel as an example GPU may render pixel when rendering both bin and bin . That is GPU may render pixel when rendering bin because pixel is located in overlap region . GPU may also render pixel a second time when rendering bin because pixel is located in bin .

As described above GPU may implement the techniques for rendering overlapping bins when filtering rendered graphics data. In this example GPU may perform a binning pass on image to generate visibility information e.g. such as visibility streams for each of bins . GPU may then perform a series of rendering passes for each respective bin. The example below is described with respect to binning and rendering bin as an example but may be performed for each of bins .

During the binning pass overlap unit may determine overlap boundary as being a fixed distance from bin boundary . In an example for purposes of illustration overlap unit may determine that overlap boundary follows the contour of bin boundary and is eight pixels wide. In this example assuming a bin size of L W overlap unit may set overlap boundary based on W 8 L 8. In some examples overlap unit may determine overlap boundary based on the filter being applied to the rendered image .

After determining overlap boundary thereby defining overlap region overlap unit mark one or more pixels of overlap region as being visible pixels in bin . For example as noted above overlap unit may mark pixel as being a visible pixel in the visibility information for bin .

When rendering to bin GPU may render bin using a viewport that is expanded beyond bin boundary . For example rasterizer may determine scissor parameters that include at least some of overlap region . For example in some instances GPU may determine a viewport that is equal to overlap boundary determined during binning In other examples GPU may determine a viewport that is less than overlap boundary determined during binning GPU may determine the viewport in some examples based on the filter being applied to the rendered data.

In any case GPU may perform a rendering stage of the rendering pass to generate pixel values shade for pixels of bin . In addition according to aspects of this disclosure GPU may generate pixel values for pixels of overlap region that are marked as being visible pixels in the visibility information for bin and that are within the scissor parameters set by GPU . GPU may store the shaded pixels to GPU memory . In this way GPU may render both the pixels associated with bin and one or more pixels that are located spatially outside of bin e.g. one or more of the pixels of overlap region to bin .

During the resolve stage of the rendering pass of bin GPU may transfer the finished pixel values from GPU memory to display buffer unit . According to aspects of this disclosure filter unit may apply a filter to the rendered pixels when transferring the graphics data from GPU memory to display buffer unit . For example because the rendered data includes the pixels of bin and the pixels of overlap region or at least a portion of such pixels in instances in which the viewport is set smaller than overlap boundary filter unit may accurately apply a filter to all pixels of bin including the pixels located at the edges of bin . That is filter unit may identify source pixels in overlap region when filtering pixels within bin .

Again while described with respect to bin for purposes of example GPU may repeat the process for each of bins . After transferring all of the rendered and filtered bins from GPU memory to display buffer unit image is ready to be output e.g. displayed .

In the example of GPU and or GPU driver may determine an initial binning configuration . For example GPU may determine a bin size based on a size of GPU memory such that all of the pixel data associated with a bin can be stored to GPU memory during rendering. GPU may then divide the image into bins so that each of the pixels of the image is associated with one bin.

GPU may determine an overlap region for the bins . In general the overlap region allows GPU to render pixels to more than one bin. For example GPU may render the pixels of the bin as well as the pixels of the overlap region for the bin which may be spatially assigned in the binning configuration to a different bin. As described above GPU may determine the same or differently sized overlap regions when performing a binning pass and when performing the rendering passes of a rendering process. In some examples GPU may size the overlap region based on a filter being applied to the rendered graphics data.

GPU then renders a sequence of overlapping bins . For example when rendering a particular bin GPU may expand the area being rendered such that GPU shades one or more pixels that are located outside of the particular bin to the particular bin. That is GPU stores the shaded one or more pixels that are located outside of the particular bin to GPU memory with the pixels that are spatially located within the particular bin.

In an example for purposes of illustration GPU may render pixels of a first bin of a plurality of bins where the pixels of the first bin are associated with a first portion of an image. GPU may also render to the first bin one or more pixels that are located outside the first portion and associated with a second different bin of the plurality of bins. In addition GPU may render the one or more pixels associated with the second bin to the second bin such that the one or more pixels are rendered to both the first bin and the second bin.

GPU determines a filter for an image . For example GPU may determine that the rendered image is to be filtered after rendering all of the bins of the image. In some examples GPU may determine a scaling filter for the image that is operable to scale the resolution of the image. GPU may determine the scaling filter based on one or more commands included in a command stream.

GPU determines an overlap region for bins of the image . In general as described herein the overlap region defines an area in which pixels may be rendered to more than one bin. In some examples the overlap region may be a fixed size that is applied to each of the bins. In other examples GPU may size the overlap region based on the determined filter noted above.

GPU determines a binning configuration of an image with the overlap region . For example GPU may determine a bin size based on a size of GPU memory such that all of the pixel data associated with a bin can be stored to GPU memory during rendering. GPU may also consider the data of the overlap region that will be rendered to the bins such that all of the bin data as well as all of the overlap region data may be stored to GPU memory . GPU may then divide the image into bins so that each of the pixels of the image is associated with one bin.

GPU performs rasterization on the image and sorts rasterized primitives e.g. triangles to each of the determined bins . In some examples GPU may perform a so called coarse rasterization to sort primitives to each of the determined bins. That is rather than performing the rasterization on a per pixel basis GPU may rasterize the image on a per block of pixels basis.

GPU generates visibility information for the image e.g. one visibility stream per bin with one or more pixels of the image being visible in more than one bin in the overlap region . For example according to aspects of this disclosure GPU may generate a visibility information for a particular bin that indicates whether pixels located in the bin are visible and also indicates whether one or more pixels located outside of the bin but being rendered to the bin i.e. pixels of the overlap region are visible.

GPU clears and or unresolves local memory i.e. GPU memory . GPU also determines a filter for filtering the image being rendered . For example as described above with respect to GPU may determine that the rendered image is to be filtered after rendering all of the bins of the image. In some examples GPU may determine a scaling filter for the image that is operable to scale the resolution of the image. GPU may determine the scaling filter based on one or more commands included in a command stream.

GPU determines an overlap region . Again as noted above the overlap region defines an area in which pixels may be rendered to more than one bin. In some examples the overlap region may be a fixed size that is applied to each of the bins being rendered. In other examples GPU may size the overlap region based on the determined filter noted above. In some examples the overlap region may be sized differently for rendering than for binning as described for example with respect to .

GPU determines scissor parameters based on the overlap region . For example GPU may initially determine a viewport for pixels to be rendered that includes the pixels located within the bin being rendered. GPU may then expand the viewport to include pixels of the overlap region. GPU may set the scissor parameters to include the expanded viewport.

GPU shade sand stores pixels of the bin being rendered to local memory i.e. GPU memory . For example GPU may use a graphics processing pipeline to determine pixel values for each of the visible pixels of the bin being rendered. In addition GPU may determine pixel values for each of the pixels included in the determined overlap region. GPU may store the determined pixel values of the bin and the overlap region to GPU memory .

GPU may then filter the rendered pixel data using the determined filter and copy the filtered pixel data form local memory to a frame buffer e.g. display buffer unit . For example according to aspects of this disclosure GPU may filter the pixel data while copying the pixel data to the frame buffer such that another copy operation is not required at the frame buffer. GPU then determines whether the bin that was copied was the final bin of the image . If not GPU returns to step and renders the next bin of the image. If the bin that was copied was the final bin of the image GPU may move on to rendering the next image .

It should also be understood that depending on the example certain acts or events of any of the methods described herein can be performed in a different sequence may be added merged or left out all together e.g. not all described acts or events are necessary for the practice of the method . Moreover in certain examples acts or events may be performed concurrently e.g. through multi threaded processing interrupt processing or multiple processors rather than sequentially.

In one or more examples the functions described may be implemented in hardware software firmware or any combination thereof. If implemented in software the functions may be stored as one or more instructions or code on an article of manufacture comprising a non transitory computer readable medium. Computer readable media may include computer data storage media. Data storage media may be any available media that can be accessed by one or more computers or one or more processors to retrieve instructions code and or data structures for implementation of the techniques described in this disclosure. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices flash memory or any other medium that can be used to carry or store desired program code in the form of instructions or data structures and that can be accessed by a computer. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

The code may be executed by one or more processors such as one or more DSPs general purpose microprocessors ASICs FPGAs or other equivalent integrated or discrete logic circuitry. In addition in some aspects the functionality described herein may be provided within dedicated hardware and or software modules. Also the techniques could be fully implemented in one or more circuits or logic elements.

The techniques of this disclosure may be implemented in a wide variety of devices or apparatuses including a wireless handset an integrated circuit IC or a set of ICs e.g. a chip set . Various components modules or units are described in this disclosure to emphasize functional aspects of devices configured to perform the disclosed techniques but do not necessarily require realization by different hardware units. Rather as described above various units may be combined in a codec hardware unit or provided by a collection of interoperative hardware units including one or more processors as described above in conjunction with suitable software and or firmware.

Various examples have been described. These and other examples are within the scope of the following claims.

