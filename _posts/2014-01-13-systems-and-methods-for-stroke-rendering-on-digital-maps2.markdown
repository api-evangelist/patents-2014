---

title: Systems and methods for stroke rendering on digital maps
abstract: To provide smoothly scaleable map features on interactive digital maps, a first and a second sets of style parameters for rendering a map feature at a first zoom level and a second zoom level, respectively, are received. The first and second sets of style parameters are provided to a vertex shader. The vertex shader is configured to interpolate the first set of style parameters and the second set of style parameters to generate an interpolated set of style parameters for a certain zoom level between the first zoom level and the second zoom level, and render the map feature at the certain zoom level in accordance with the interpolated set of style parameters.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09542724&OS=09542724&RS=09542724
owner: GOOGLE INC.
number: 09542724
owner_city: Mountain View
owner_country: US
publication_date: 20140113
---
This application claims priority to U.S. Provisional Patent Application No. 61 844 388 filed on Jul. 9 2013 and titled System and Methods for Stroke Rendering when Generating a Digital Map the entire disclosure of which is hereby expressly incorporated by reference herein.

The present disclosure relates to interactive digital maps and more particularly to rendering representations of paths on digital maps at various zoom levels.

The background description provided herein is for the purpose of generally presenting the context of the disclosure. Work of the presently named inventors to the extent it is described in this background section as well as aspects of the description that may not otherwise qualify as prior art at the time of filing are neither expressly nor impliedly admitted as prior art against the present disclosure.

For information clarity roads bicycle paths transit lines and similar features are represented on digital maps in a stylized rather than a realistic form. For example the style in which a road segment is represented on a digital map can include a set of visual parameters such as the number of strokes e.g. one for the outline and one for the fill color per stroke attributes such as stroke width stroke color etc. The width of the stroke generally does not scale in proportion to the real life width of the road because doing so would make most roads invisible or barely visible at certain zoom levels.

In order to conserve bandwidth a network server typically provides definitions of styles for rendering roads and other map features at several discrete zoom levels. In some cases the network server does not provide style definitions for every discrete zoom level in the valid range. Thus for example the network server may provide style definitions for roads only at discrete zoom levels N and N 2 even if a client device at some point may display a digital map at zoom level N 1. Moreover on some devices such as smartphones and tablet computers capable of receiving gesture input zoom levels form a continuum rather than a discrete scale. It is therefore possible for a client device to display a digital map at zoom level 7.5 or 8.45 for example. However it is impractical for the server to attempt to provide style data to client devices for hundreds or thousands of fractional zoom levels.

When style information is unavailable for a certain zoom level it is difficult for the client device to estimate the visual parameters both accurately and efficiently and when estimates of visual parameters are not accurate or generated slowly there are noticeable abrupt transitions or popping between representations of roads as the user scales across certain zoom levels. In addition to sudden transitions in width e.g. from three pixels to six the user may notice abrupt displacement of graphics elements forming patterns on representations of roads such as repeating arrows indicating the direction of travel along one way streets. For example the user may notice that arrows jump around to make room for additional arrows or to close gaps left by arrows that were removed.

To render stylized roads and other features as discussed above a typical client device utilizes a hardware graphics renderer in a Graphics Processing Unit GPU that implements two pipeline shading stages vertex shaders that operate on vertices visible in a frame and fragment shaders that operate on fragments or sets of pixels that make up a frame. For example the client device can create a collection of triangles made up of points defined in two or three dimensions and pass the collection of triangles to the GPU. For each triangle T in the collection the GPU then can run a vertex shader on each vertex of triangle T and a fragment shader on each pixel enclosed by triangle T.

Modern hardware 3D graphics renderers such as an OpenGL ES renderer perform optimally when rendering state changes are minimal with respect to the amount of data being drawn. The basic I O model of these hardware renderers can be described as follows the renderers receive vertices and texture pixel data and produce fragments. Generally speaking to render a frame of information on a hardware graphics renderer the following steps are taken 1 the region in memory for storing bitmaps known as a framebuffer is cleared and 2 for each logical object in the rendered frame 2a vertex and texture data are prepared for rendering 2b the state of the graphics pipeline is set and 2c a draw function to draw the data is executed.

Step 2c above describes a common programming loop. Accordingly the fewer iterations there are of step 2c the better the software application will perform. This principle of maximizing rendering performance can be referred to as batching. To comply with the principle software applications must batch together as many like elements of graphics state and draw these like elements atomically.

Another important principle for maximizing performance is to minimize shading logic. Vertex shaders are executed once per vertex for objects visible in a frame being rendered whereas fragment shaders are executed once per output pixel fragment of the frame. A typical modern display may contain millions of pixels in an output frame and tens of thousands of vertices. To perform better software applications must reduce the complexity of these shaders that must be run so frequently.

Using the techniques of this application a software module can receive style parameters such as width color etc. for rendering stroke features at certain zoom levels from a network server. When rendering a digital map at a zoom level for which style parameters are unavailable the software module efficiently and accurately interpolates the available style parameters for the desired zoom level. To this end the software module in different embodiments encodes style information into style vertex attributes that augment a set of vertex attributes that contain spatial information or encodes style information into a texture and uses texture coordinate space transformation to resize a road for example.

Further using another technique of this application a software module can generate a pattern of a recurring graphics element along a path e.g. a sequence of arrows indicating the direction of travel on a one way road that smoothly scales up or down so that transitions from N instances of the graphics element to approximately N 2 instances or 2N instances of the graphics element within a viewport do not appear sudden. To this end the software module arranges multiple instances of the graphics element along the path at a high zoom level and displays some but not all of the instances of the graphics element at lower zoom levels at their original positions along the path.

More particularly one embodiment of these techniques is a method for providing smoothly scaleable map features on interactive digital maps. The method includes receiving a first and a second sets of style parameters for rendering a map feature at a first zoom level and a second zoom level respectively. The method further includes providing the first and second sets of style parameters to a vertex shader and configuring the vertex shader to i interpolate the first set of style parameters and the second set of style parameters to generate an interpolated set of style parameters for a certain zoom level between the first zoom level and the second zoom level and ii render the map feature at the certain zoom level in accordance with the interpolated set of style parameters.

Another embodiment of these techniques is a computing device including one or more processors a graphics processor and a non transitory computer readable memory. The memory stores first instructions that implement a mapping module which when executed on the one or more processors provides first and a second sets of style parameters for rendering a map feature on a digital map at a first zoom level and a second zoom level respectively to the graphics processors. The method also stores second instructions that implement a vertex shader which when executed on the graphics processors interpolates the first set of style parameters and the second set of style parameters to generate an interpolated set of style parameters for a certain zoom level between the first zoom level and the second zoom level and renders the map feature at the certain zoom level in accordance with the interpolated set of style parameters.

Still another embodiment of the techniques of this application is a method in a computing device for displaying patterns of recurring graphics on interactive digital maps. The method includes arranging multiple instances of a graphics element sequentially at respective positions along a path and displaying a first digital map including a first representation of the path at a first zoom level including displaying each of the plurality of instances of the graphics element. The method further includes displaying a second digital map including a second representation of the path at a second zoom level corresponding to lower magnification than the first zoom level including i displaying a first subset of the plurality of instances of the graphic element at their original positions along the path and ii not displaying a second subset of the plurality of instances of the graphic element wherein the second subset includes instances disposed between instances in the first subset along the path.

Yet another embodiment of these techniques is a method in a computing device for displaying patterns of recurring graphics on interactive digital maps. The method includes displaying a first digital map including a representation of a path at a first level of magnification displaying on the first digital map multiple instances of a graphics element arranged sequentially on the path including a first instance of the graphics element and a second instance of the graphics element that immediately follows the first instance on the path at points on the first digital map representing a first geographic location and a second geographic location respectively displaying at a second level of magnification higher than the first level a second digital map including a representation of at least a portion of the path and displaying the first instance and the second instance of the graphics element at points on the second digital map representing the first geographic location and the second geographic location respectively and a new instance of the graphics element disposed between the first instance and the second instance of the graphics element on the path.

Generally speaking style interpolation discussed in this application allow a client device to smoothly scale roads bicycle trails and other map features drawn on a digital map using stroke based rendering across zoom levels for which style information is unavailable at the client device. The client device can be for example a smartphone or a tablet computer that receives map data and style information from a network server. Depending on the hardware the operating system the scope of application programming interface API functions etc. different techniques discussed below can be better suited for different client devices.

According to one style interpolation technique a mapping software module operates in a computing device implements a graphics pipeline that includes vertex shaders and fragment shaders. The mapping application receives style parameters such as widths and colors of strokes and the number of strokes for rendering roads and or similar map features at certain zoom levels. To render the these map features at zoom levels for which style parameters are unavailable at the computing device the mapping software module encodes style parameters as style vertex attributes to augment a set of conventional vertex attributes which contain spatial position information and texture coordinates. The mapping software module then provides style vertex attributes for zoom level N and zoom level M to a vertex shader which interpolates the style parameters encoded in the style vertex attributes to generate style parameters for an intermediate zoom level i.e. a zoom level between zoom level N and zoom level M which may be discrete or fractional .

According to another technique a mapping software module encodes style parameters for zoom levels N and M in a texture which can be a two dimensional array that normally stores pixels as elements to define a bitmap. When a geographic area includes representations of roads of different types the mapping software module encodes respective style parameters for all road types in the area. The mapping software module generates maximally extruded road geometry to properly render the widest stroke among the possible stroke widths for all styles applied to the road and assigns a corresponding style index to each road centerline. In operation the vertex shader looks up style parameters and interpolates the parameters for the given zoom level which can be between zoom levels N and M. In particular the vertex shader interpolates the width and uses the interpolated width to transform texture coordinate space. The fragment shader in turn uses the transformed texture coordinates to sample a texture that defines portions of the road.

In this manner the mapping software module calculates road geometry once for multiple zoom levels and effectively stretches the texture to resize the road. In other words the mapping software module according to this technique transforms texture coordinate space rather than feature geometry.

Another technique of this disclosure allows a client device to smoothly scale patterns of repeating graphics elements arranged on a digital map along a certain path such as instances of an arrows repeated along a representation of a road. Similar to the approaches outlined above this technique does not require that the client device obtain and store definitions of the pattern for every possible zoom level at which the digital map can be displayed. Rather a software module on the client device arranges multiple instances of the graphics element along the path at a high zoom level and displays some but not all of the instances of the graphics element at lower zoom levels at their original positions along the path. Transitions from N instances of the graphics element to approximately N 2 instances or 2N instances of the graphics element within a viewport do not appear sudden. Thus in an example scenario a road overlaid with sequentially arranged arrows is displayed on a touchscreen device. As the user gradually zooms in on a road segment on which two instances of the arrow are visible the arrows continue to overlay their original geographic locations and accordingly travel apart as the zoom level increases. A new arrow fades in when the two original arrows are sufficiently far apart.

For further clarity an example computing system in which some or all of the techniques outlined above can be implemented is discussed with reference to .

Map data stored in the map database also can include descriptions of geometry for various other map features such as buildings parks and bodies of water text labels textures various forms of metadata etc. Some of these map features can be defined in a vector graphics format or another suitable scaleable format. In some cases map data also can include raster images in a bitmap format for example.

The map data server can organize and serve map data to client devices using any suitable scheme such as map tiling for example. Map tiles generally correspond to a two dimensional organization of geospatial data into a quadtree. Each tile at a given zoom level is divided into four tiles at the next level up to the highest level of magnification. Similarly three dimensional organization of geospatial data can be implemented using octrees. To map the surface of the Earth onto a plane Mercator or another suitable projection can be used.

The map database also stores style parameters for rendering roads at certain zoom levels. For example style parameters A A . . . describe style parameters for various styles at zoom level 14 and style parameters B B . . . describe style parameters for various styles at zoom level 17. Each set of style parameters can describe a respective color and width for each of several strokes. When providing road data to client devices the map data server can assign a style identifier to each road segment in a given map tile. For example the map data server can indicate that the segment of an interstate highway present in the map tile should be rendered using style a local road should be rendered using style a bicycle path should be rendered using style etc.

According to some implementations when the client device A or B requests map data for a certain geographic area to be displayed at zoom level Z the map data server style parameters and possibly other map data for the requested zoom level as well for the next zoom level Z 1. Further the map data server alternatively or additionally can provide some of the map data for the zoom level Z 1. Depending on the implementation the map data server can provide style parameters e.g. stroke 1 width 0x05 stroke 1 color 0xFFFF000 stroke 2 width 0x04 stroke 2 color 0x8000FF00 for several styles and at several zoom levels at the same time as the map data or during a separate session for retrieving style parameters.

For example the client device A may request map data for rendering a digital map of a geographic region R at zoom level 14 and the map data server can provide the map data for zoom level 14 along with style information for zoom levels 14 and 17 for each road visible at zoom level 14 or alternatively zoom levels 14 17 . Using these style parameters the client device A can scale representations of roads in the region R between zoom levels 14 and 17. More particularly the client device A can use the techniques discussed in more detail below to interpolate style parameters and display a certain road segment at zoom level 15 16 14.3 15.55 etc.

With continued reference to the map data server can be implemented as a single device or as a group of devices. One or more of these devices can include one or more processors a network interface and a non transitory computer readable memory that stores instructions executable on the one or more processors . For example a request processor can process requests from client devices A and B identify and retrieve relevant polylines and style parameters from the map database along with other relevant map data and transmit this data to the requesting client device.

Similarly the map database can be implemented in a single storage device or multiple storage devices. The communication network can include any suitable number of Internet links local area links long range wireless link short range wireless links etc.

In the example of the client devices A and B are portable devices such as smartphones or tablet computers for example. In general however the techniques for interpolating style parameters and rendering patterns of graphics can be utilized both in portable and non portable computing devices. The client devices A and B in this example are generally similar except that the client device A implements an interpolation technique that includes passing style parameters to a vertex shader in the form of vertex attributes and client device B implements an interpolation technique that includes encoding style parameters as a texture and transforming texture coordinate space. Further the client device B in this example implements a technique for generating smoothly scaleable patterns arranged along paths on digital maps.

The client device A includes one or more general purpose processors A a network interface A configured to communicate with other devices via the network a touchscreen A configured to receive gesture based input a non transitory computer readable memory A and a graphics card A that has buffer s . The client device B includes components A B that are generally similar to components A A respectively. In other implementations the client devices A and B can include additional components or conversely not include some of the components illustrated in .

The memory A of the client device A stores a mapping module A that generates interactive digital maps. Depending on the implementation the mapping application can operate as a standalone application or as a component of another application such as a web browser for example. The mapping module A includes a vertex attribute generator for zoom style groups . In operation the vertex attribute generator provides style parameters as vertex attributes to a style interpolating vertex shader that execute on the graphics card A. The vertex shader and a fragment shader then interpolate style parameters and render roads at specified zoom levels as discussed in more detail with reference to .

The memory B of the client device B stores a mapping module B that provides functionality similar to the mapping application A. The mapping module B includes a road geometry and style information texture generator that generates maximally extruded road geometry encodes style parameters as a texture and provides the texture to a style interpolating vertex shader . The vertex shader and a style interpolating fragment shader then interpolate style parameters and render roads at specified zoom levels as discussed in more detail with reference to .

The mapping module B also includes a patterned path generator that arranges multiple instances of an arrow or another graphics element along a path to eliminate sudden transitions in the display of the resulting pattern during scaling across zoom levels as discussed in more detail with reference to .

Referring to a graphics pipeline can be implemented in a graphics card or more generally a hardware configured specifically to render graphics. The pipeline includes a vertex shader and a fragment shader which can operate on a framebuffer . The vertex shader receives vertex attributes that include both conventional spatial parameters such as coordinates of vertices that make up a road centerline and texture coordinates and spatial parameters such as width color the number of strokes etc. The vertex shader during operation outputs values such as color that are passed to fragment shader in the form of so called varyings . The number of times Y the fragment shader executes can exceed the number of times X the vertex shader executes by a factor of 100 for example.

The graphics pipeline can be implemented in the graphics card A in the client device A for example. More specifically the vertex attribute generator operating in the mapping module A can generate the vertex attributes . The shaders and can be implemented as the shaders and respectively.

As illustrated in to render a frame of information in the graphics pipeline the framebuffer is cleared first at stage . At stage a logical object for drawing is selected. For example all road segments for a certain tile can be put into a Vertex Buffer Object VBO so as to be drawn with a one call to a draw function. In some cases if the amount of data does not fit into a single VBO the data is split into multiple VBOs. A corresponding style identifier can be encoded into each vertex to enable the vertex shader to look up style parameters for the vertex as this vertex is being drawn. As discussed below style parameters can include color and width definitions for various strokes associated with the style.

Further in one example implementation road data within a VBO is sorted by the following values plane grade stroke and z within grade where the z value controls the depth of a graphic . Thus for road segments in a tile having the same plane and grade all instances of stroke 0 are ordered first followed by all instances of stroke 1 etc. For two road segments having different plane and grade combinations strokes 0 1 etc. are ordered for the lower plane and grade combination first followed by strokes 0 1 etc. for the higher plane and grade combination.

Next vertex and texture data are prepared for rendering at stage . The graphics pipeline state is set at stage and a draw function is called at stage to execute the vertex shader and the fragment shaders. The graphics pipeline then performs the stages and for the next logical object until every logical object in the frame has been drawn.

As further illustrated in style information is encoded into style vertex attributes at block which can be executed on a general purpose processors such as the processor A of . As a more specific example the vertex attribute generator can execute block as part preparing the graphics pipeline at stage . The vertex shader then interpolates the data encoded into style vertex attributes at block as discussed in more detail with reference to .

Now referring to at least some of the blocks of an example method for generating parameters for the graphics pipeline of can be implemented in the vertex attribute generator for example as a set of software instructions that execute on the processor s A.

The method begins at block where style information is encoded into style vertex attributes. These style vertex attributes augment fixed vertex attributes that contain spatial position information related to an object such as Cartesian coordinates of the object. The style vertex attributes can include such as information as widths and colors for several strokes number of strokes etc. Referring back to a certain style vertex attribute can include style parameters A for road style S at zoom level 14 another style vertex attribute can include style parameters A for road style S at zoom level 14 and another style vertex attribute can include style parameters B for road style S at zoom level 17.

Style vertex attributes are grouped into containers that are separate but which can be combined interchangeably with conventional vertex attributes describing position at block . Further the grouping of style vertex attributes can be further delineated based on zoom levels. Again referring back to a style vertex attribute corresponding to style parameters A and a style vertex attribute corresponding to style parameters B both of which describe road style S at different zoom levels can form a zoom style group G which a vertex shader then can use to interpolate style parameters at least in the range between zoom level 14 and zoom level 17.

At block a zoom style group along with the corresponding conventional vertex attributes can be bound e.g. by executing appropriate function s supported by the graphics pipeline and the programming language to the vertex shader when a frame of a scene is rendered for the current zoom level of the virtual camera. Thus a zoom style group can be understood as a logical variable groups of vertex attribute data that can be interchangeably combined with canonical fixed vertex attribute data in accordance with the current zoom level.

For example the mapping module A of can process user input such as an instance of a pinch to zoom gesture applied to the touchscreen A and determine that the current zoom level for the camera should be 14.7. The mapping module A can obtain a polyline for a road segment visible in the viewport at zoom level 14.7 identify style S in which the road segment must be rendered and indicate to the vertex attribute generator that the zoom level should be 14.7. The vertex attribute generator in turn can select from among the available set of resources style parameters A and B for style S corresponding to zoom levels 14 and 17 respectively. The vertex attribute generator then can execute blocks to prepare vertex attributes for use by a vertex shader.

It is noted that if style parameters are available for zoom levels more proximate to the selected zoom level the mapping module A can use these parameters instead. Thus if style parameters for zoom levels 14 and 15 are available the mapping module A can select these parameters rather than style parameters for zoom levels 14 and 17 for rendering a road at zoom level 14.7.

When the frame of the scene is rendered successive style parameters which correspond to successive zoom levels are interpolated in a vertex shader in accordance with the current zoom level of the virtual camera block . The vertices and fragments of the road segments are then drawn at block .

Referring generally to it is noted that these techniques do not require fetching or dereferencing of style data in either the vertex or fragment shaders thus reducing the amount of shader logic and improving overall efficiency. Further by augmenting vertex attribute data with style parameters and referencing style parameters as attributes in the vertex shader the vertex attribute generator can combined strokes into large groups in accordance with the batching principle thereby further improving performance.

In operation a vertex shader receives e.g. as spatial vertex attributes road centerline data and a style identifier for the road centerline and retrieves style parameters for successive zoom levels for the specified style from the table . The vertex shader then interpolates these parameters for the current zoom level to determine stroke width color etc.

Rather than transforming road outline geometry the vertex shader in one embodiment uses the interpolated width to transform texture space coordinates as illustrated in more detail in . The vertex shader provides the transformed texture space coordinates to a fragment shader as varying for example .

To address aliasing issues and to render end caps for line segments the fragment shader in some embodiments also receive a tombstone shaped texture in a bitmap format for example. In some implementations however the texture can be shaped as a semi circle. In the shaded portions of the tombstone shaped texture represent the opacity of one and unshaded portions of the tombstone shaped texture represent the opacity of zero. When rendering lines the fragment shader can sample the tombstone shaped texture using coordinates in the transformed texture space to determine the alpha value for a pixel. The fragment shader need not rely on the tombstone shaped texture to determine the color of a pixel as pixel colors are interpolated between vertices based on the style information calculated in the vertex shader .

Referring now to example method for operating the graphics pipeline of can be implemented in the client device B of for example. As a more specific example at least some of the blocks of method can be implemented in the road geometry and style information texture generator .

At block a texture is constructed to represent a progression of styles e.g. zoom level 11 zoom level 12 for all roads in a certain unit of a digital map such as a map tile. Block can be executed for each map tile in a viewport. In at least some of the embodiments this progression of styles can be encoded similar to the texture of .

Next a maximally extruded road geometry for the relevant roads is generated at block . In other words for a given road centerline the most detailed outline geometry of the road possible for the available data is generated. A corresponding style index is assigned to each road centerline at block for use by the vertex shader. The maximally extruded road geometry then can be reused to render each stroke for the road so as to not transform road geometry in vertex or fragment shaders.

The data generated at blocks can be provided to a vertex shader which can fetch road width and color values for the corresponding strokes at the relevant zoom levels from the texture encoding style progression block . Similar to example discussed above with reference to in order to generate style parameters for a road in style S at zoom level 11.2 the vertex shader can retrieve style parameters for zoom levels 11 and 12 from the texture and interpolate these parameters.

At block the vertex shader can interpolate style parameters and transform coordinates in the texture space using the interpolated width values. After the vertex shader renders vertices the fragment shader at block can generate pixel colors for the fragments within roads and sample a tombstone shaped texture or another suitable texture describing end caps in accordance with the transformed coordinates to apply the alpha value to the pixels.

For additional clarity schematically illustrate the stretching of a texture to render a road segment at two different zoom levels Z and Z. A rendering includes maximally extruded outline geometry for a road represented by a centerline . Texture instances A B and C are mapped to screen space according to one set of coordinates at zoom level Z. On the other hand a rendering includes the same centerline at zoom level Z but each of the texture instances A B and C is transformed so as to cover a larger portion in screen space and thereby generate a wider representation of the road at a higher level of magnification of the corresponding digital map.

A vertex shader such as the vertex shader of can apply a uniform scale from 0.5 0.5 to the texture coordinate of a vertex. To this end the vertex shader can first offset each texture coordinate by 0.5 placing each coordinate in the range of 0.5 0.5 . The vertex shader then can use the inverse of the fractional interpolated width to scale the texture coordinates. For example if a stroke is half the width of the widest stroke a scale of factor of two is applied to the offset texture coordinate as illustrated on the right side of the texture coordinate space .

The vertex shader then offsets the result by 0.5 thereby placing the adjusted coordinates back into the original coordinate space. further illustrates in the lower portion of the drawing how the texture coordinate space affects of the mapping of the texture on road geometry.

To enable smooth transitions between zoom levels for patterns displayed along roads and other paths the patterned path generator of or another suitable software component can implement the technique discussed next with reference to .

Referring first to patterned path generator can arrange instances of an arrow graphic along a path . In general the patterned path generator can operate on any graphics element such as a dash a dot a two way arrow etc. The path in this example represents a one way street but in general can represent any type of a path or trajectory. When arranging instances of the arrow graphic the patterned path generator can use a maximally extruded outline of the path for example.

The arrow graphic can be stored as a texture for example. The patterned path generator in this case can use coordinate transformation in texture space discussed above.

The patterned path generator can arrange multiple instances of the arrow graphic at certain positions along the path at a high level of magnification. These positions remain fixed across multiple zoom levels. However the instances in some positions are displayed only at zoom levels in the first band of relatively low zoom levels level 1 some instances are displayed at zoom levels in the second band of higher low zoom levels level 2 as well in the first band and some instances are displayed at zoom levels in the third band of relatively high zoom levels level 3 as well as in the first band and the second band. Each band can include any desirable number of discrete and or fractional zoom levels and as many bands as desired can be defined.

In instances of the arrow graphic that are displayed for a band are marked with symbol X. Thus in band which can correspond to a relatively low level of magnification only three instances of the arrow graphic are displayed at a higher level of magnification in band twice as many instances of the arrow graphic are displayed and at an even higher level of magnification in band four times as many instances of the arrow graphic are displayed.

In the example illustrated in the number of arrows at each subsequent band doubles relative to the previous band. However any new number of arrows can be introduced in the next band of higher zoom levels.

As illustrated in the instances of the arrow graphic are effectively affixed to certain locations on a road segment and thus the arrows appear to travel apart as the user zooms in on a portion of the road segment to increase the zoom level from within the band to band .

As further illustrated in the patterned path generator can enlarge the instances of the arrow graphic as the zoom level increases. Thus the instance corresponds to the instance enlarged in accordance with the new zoom level. To this end the patterned path generator can transform the coordinates in the texture space without modifying the underlying road geometry.

Further the new instance of the arrow graphic can gradually fade in as the user zooms in from a zoom level within the band to a new zoom level within band . Similarly the instance can gradually fade out when the user zooms out from within band back to a zoom level within band . To this end the patterned path generator can gradually value the alpha value of the arrow graphic for example.

Depending on the implementation the fade in and fade out of arrow graphics can be controlled as a function of the user s zoom level and or the function of time. As a more specific example gradual fade in of the arrow graphic in one implementation is triggered when the zoom level crosses a certain boundary and the level of transparency of the arrow graphic then gradually decreases at a pre configured rate until the arrow graphic is fully opaque. In another implementation however arrow graphics can fade in and out faster when the user zooms in and out of map areas faster.

Thus rather than recalculating where arrows should be drawn at a new zoom level and rather than losing arrows altogether by zooming in on an area between two instances of the arrow graphic the patterned path generator gradually increases the density of arrows without sudden jumps. As a result patterns of arrows of other graphics elements scale up and down smoothly.

For additional clarity illustrates an example method for displaying patterns of recurring graphics on interactive digital maps. The method can be implemented in the patterned path generator of for example. For clarity the method is discussed below with reference to arrows overlaying a road. However it will be understood that this technique similarly can apply to other graphics elements and other paths.

At block multiple instances of the arrow graphic are sequentially arranged along a road centerline which can be maximally extruded so as to properly accommodate a high number of instances of the arrow graphic. At block a digital map including a representation of the road is displayed at a high zoom level corresponding to high magnification of the digital map . All the instances of the arrow graphic are displayed along the road at this zoom level.

After the zoom level of the digital map is lowered at block some but not all of the originally arranged instances of the arrow are displayed in their original positions i.e. at points on the digital map corresponding to the same geographic locations. As illustrated in every other arrow graphic can be omitted at the lower zoom level for example.

At block a digital map including a representation of a path is displayed at a first zoom level which can be relatively low. An initial set of instances of the graphics element can be displayed along the path at block . As discussed above this initial set can be selected from among the larger set of instances places along the centerline corresponding to the maximally extruded geometry of the path.

At block the digital map is displayed at a higher level of magnification. The new digital map can include at least a portion of the path displayed at blocks and . The initial set of instances of the graphics element is displayed at the original positions along the path. Of course these original positions will correspond to new positions on the user interface as the same geographic area is now viewed with larger magnification.

At block new instances of the graphics element fade in. These new instances are disposed between some of the instances in the initial set. Referring back to the instances and can define a portion of the first set which is displayed both at the lower zoom level and at the higher zoom level. The instance can be one of the new instances that fades in when the zoom level increases.

The following additional considerations apply to the foregoing discussion. Throughout this specification plural instances may implement components operations or structures described as a single instance. Although individual operations of one or more methods are illustrated and described as separate operations one or more of the individual operations may be performed concurrently and nothing requires that the operations be performed in the order illustrated. Structures and functionality presented as separate components in example configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements fall within the scope of the subject matter of the present disclosure.

Additionally certain embodiments are described herein as including logic or a number of components modules or mechanisms. Modules may constitute either software modules e.g. code stored on a machine readable medium or hardware modules. A hardware module is tangible unit capable of performing certain operations and may be configured or arranged in a certain manner. In example embodiments one or more computer systems e.g. a standalone client or server computer system or one or more hardware modules of a computer system e.g. a processor or a group of processors may be configured by software e.g. an application or application portion as a hardware module that operates to perform certain operations as described herein.

In various embodiments a hardware module may be implemented mechanically or electronically. For example a hardware module may comprise dedicated circuitry or logic that is permanently configured e.g. as a special purpose processor such as a field programmable gate array FPGA or an application specific integrated circuit ASIC to perform certain operations. A hardware module may also comprise programmable logic or circuitry e.g. as encompassed within a general purpose processor or other programmable processor that is temporarily configured by software to perform certain operations. It will be appreciated that the decision to implement a hardware module mechanically in dedicated and permanently configured circuitry or in temporarily configured circuitry e.g. configured by software may be driven by cost and time considerations.

Accordingly the term hardware should be understood to encompass a tangible entity be that an entity that is physically constructed permanently configured e.g. hardwired or temporarily configured e.g. programmed to operate in a certain manner or to perform certain operations described herein. Considering embodiments in which hardware modules are temporarily configured e.g. programmed each of the hardware modules need not be configured or instantiated at any one instance in time. For example where the hardware modules comprise a general purpose processor configured using software the general purpose processor may be configured as respective different hardware modules at different times. Software may accordingly configure a processor for example to constitute a particular hardware module at one instance of time and to constitute a different hardware module at a different instance of time.

Hardware and software modules can provide information to and receive information from other hardware and or software modules. Accordingly the described hardware modules may be regarded as being communicatively coupled. Where multiple of such hardware or software modules exist contemporaneously communications may be achieved through signal transmission e.g. over appropriate circuits and buses that connect the hardware or software modules. In embodiments in which multiple hardware modules or software are configured or instantiated at different times communications between such hardware or software modules may be achieved for example through the storage and retrieval of information in memory structures to which the multiple hardware or software modules have access. For example one hardware or software module may perform an operation and store the output of that operation in a memory device to which it is communicatively coupled. A further hardware or software module may then at a later time access the memory device to retrieve and process the stored output. Hardware and software modules may also initiate communications with input or output devices and can operate on a resource e.g. a collection of information .

The various operations of example methods described herein may be performed at least partially by one or more processors that are temporarily configured e.g. by software or permanently configured to perform the relevant operations. Whether temporarily or permanently configured such processors may constitute processor implemented modules that operate to perform one or more operations or functions. The modules referred to herein may in some example embodiments comprise processor implemented modules.

Similarly the methods or routines described herein may be at least partially processor implemented. For example at least some of the operations of a method may be performed by one or processors or processor implemented hardware modules. The performance of certain of the operations may be distributed among the one or more processors not only residing within a single machine but deployed across a number of machines. In some example embodiments the processor or processors may be located in a single location e.g. within a home environment an office environment or as a server farm while in other embodiments the processors may be distributed across a number of locations.

The one or more processors may also operate to support performance of the relevant operations in a cloud computing environment or as an SaaS. For example at least some of the operations may be performed by a group of computers as examples of machines including processors these operations being accessible via a network e.g. the Internet and via one or more appropriate interfaces e.g. application program interfaces APIs . 

The performance of certain of the operations may be distributed among the one or more processors not only residing within a single machine but deployed across a number of machines. In some example embodiments the one or more processors or processor implemented modules may be located in a single geographic location e.g. within a home environment an office environment or a server farm . In other example embodiments the one or more processors or processor implemented modules may be distributed across a number of geographic locations.

Some portions of this specification are presented in terms of algorithms or symbolic representations of operations on data stored as bits or binary digital signals within a machine memory e.g. a computer memory . These algorithms or symbolic representations are examples of techniques used by those of ordinary skill in the data processing arts to convey the substance of their work to others skilled in the art. As used herein an algorithm or a routine is a self consistent sequence of operations or similar processing leading to a desired result. In this context algorithms routines and operations involve physical manipulation of physical quantities. Typically but not necessarily such quantities may take the form of electrical magnetic or optical signals capable of being stored accessed transferred combined compared or otherwise manipulated by a machine. It is convenient at times principally for reasons of common usage to refer to such signals using words such as data content bits values elements symbols characters terms numbers numerals or the like. These words however are merely convenient labels and are to be associated with appropriate physical quantities.

Unless specifically stated otherwise discussions herein using words such as processing computing calculating determining presenting displaying or the like may refer to actions or processes of a machine e.g. a computer that manipulates or transforms data represented as physical e.g. electronic magnetic or optical quantities within one or more memories e.g. volatile memory non volatile memory or a combination thereof registers or other machine components that receive store transmit or display information.

As used herein any reference to one embodiment or an embodiment means that a particular element feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment.

Some embodiments may be described using the expression coupled and connected along with their derivatives. For example some embodiments may be described using the term coupled to indicate that two or more elements are in direct physical or electrical contact. The term coupled however may also mean that two or more elements are not in direct contact with each other but yet still co operate or interact with each other. The embodiments are not limited in this context.

As used herein the terms comprises comprising includes including has having or any other variation thereof are intended to cover a non exclusive inclusion. For example a process method article or apparatus that comprises a list of elements is not necessarily limited to only those elements but may include other elements not expressly listed or inherent to such process method article or apparatus. Further unless expressly stated to the contrary or refers to an inclusive or and not to an exclusive or. For example a condition A or B is satisfied by any one of the following A is true or present and B is false or not present A is false or not present and B is true or present and both A and B are true or present .

In addition use of the a or an are employed to describe elements and components of the embodiments herein. This is done merely for convenience and to give a general sense of the description. This description should be read to include one or at least one and the singular also includes the plural unless it is obvious that it is meant otherwise.

Upon reading this disclosure those of skill in the art will appreciate still additional alternative structural and functional designs for displaying paths at various zoom levels a client device through the disclosed principles herein. Thus while particular embodiments and applications have been illustrated and described it is to be understood that the disclosed embodiments are not limited to the precise construction and components disclosed herein.

