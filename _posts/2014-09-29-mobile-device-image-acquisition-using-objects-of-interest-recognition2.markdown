---

title: Mobile device image acquisition using objects of interest recognition
abstract: An approach is provided for acquiring images with camera-enabled mobile devices using objects of interest recognition. A mobile device is configured to acquire an image represented by image data and process the image data to identify a plurality of candidate objects of interest in the image. The plurality of candidate objects of interest may be identified based upon a plurality of low level features or “cues” in the image data. Example cues include, without limitation, color contrast, edge density and superpixel straddling. A particular candidate object of interest is selected from the plurality of candidate objects of interest and a graphical symbol is displayed on a screen of the mobile device to identify the particular candidate object of interest. The particular candidate object of interest may be located anywhere on the image. Passive auto focusing is performed at the location of the particular candidate object of interest.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09554030&OS=09554030&RS=09554030
owner: Yahoo! Inc.
number: 09554030
owner_city: Sunnyvale
owner_country: US
publication_date: 20140929
---
Embodiments relate generally to acquiring images using camera enabled mobile devices and more specifically to an approach for acquiring images using camera enabled mobile devices using objects of interest recognition.

The approaches described in this section are approaches that could be pursued but not necessarily approaches that have been previously conceived or pursued. Therefore unless otherwise indicated the approaches described in this section may not be prior art to the claims in this application and are not admitted to be prior art by inclusion in this section.

Many mobile devices such as smartphones tablet computing devices personal digital assistants and laptop computers include a camera allow users to easily and quickly acquire photos and then share the photos with others via email messaging and social network services. Despite the convenience provided by mobile devices equipped with a camera there are some drawbacks. Unlike conventional cameras that allow a user to manually change the focus or active focus cameras that use a separate sensor to measure focus many mobile devices use passive auto focusing to determine the correct focus without any user intervention. Passive auto focussing generally involves capturing and evaluating images at different lens positions and selecting a lens position that provides the best sharpness i.e. where adjacent pixels have the greatest difference in intensity regardless of the image content. Passive auto focussing does not work well with blurred images because the difference of intensity of adjacent pixels in blurred images is generally less than in clear images. It is not uncommon for users to experience delays and blurred images as they wait for the passive auto focussing to complete and even after completed an object of interest to a user may not be in the focus area. On many cameras and mobile devices the default focus area is fixed at the center of the display and visually indicated by a focus area symbol such as a rectangle circle etc. superimposed on the image. This forces a user to move or orient the mobile device so that an object of interest is within the focus area as indicated by the focus area symbol and then again wait for the passive auto focus process to complete. Alternatively some mobile devices allow a user to tap the screen at the location of an object of interest to move the focus area and the corresponding focus area symbol to that location. This avoids having to re orient the mobile device so that the object of interest is in the center of the display but requires that the user tap the screen.

In the following description for the purposes of explanation numerous specific details are set forth in order to provide a thorough understanding of the various embodiments. It will be apparent however to one skilled in the art that the embodiments may be practiced without these specific details. In other instances well known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the embodiments. Various aspects of embodiments are described hereinafter in the following sections 

An approach is provided for acquiring images with camera enabled mobile devices using objects of interest recognition. A mobile device is configured to acquire an image represented by image data and process the image data to identify a plurality of candidate objects of interest in the image. The plurality of candidate objects of interest may be identified based upon a plurality of low level features or cues in the image data. Example cues include without limitation color contrast edge density and superpixel straddling. A particular candidate object of interest is selected from the plurality of candidate objects of interest and a graphical symbol is displayed on a screen of the mobile device to identify the particular candidate object of interest. The particular candidate object of interest may be located anywhere on the image. Passive auto focusing is performed at the location of the particular candidate object of interest. The approach described herein may provide a more favorable user experience by focusing the image at the location of the particular candidate object of interest rather than only at a fixed location on the display of the mobile device such as the center of the display which may not include an object of interest to a user. The approach may be repeated continuously periodically or in response to a user selection on the mobile device to allow new candidate objects of interest to be identified for example after the mobile device has been moved or reoriented. In addition a user may select another location on the display that may for example contain an alternative object of interest to the user and passive auto focusing is performed at other location selected by the user.

Display may be implemented by any type of display that displays images and information to a user and may also be able to receive user input and embodiments are not limited to any particular implementation of display . Mobile device may have any number of displays of similar or varying types located anywhere on mobile device . Camera may be any type of camera and the type of camera may vary depending upon a particular implementation. As with display mobile device may be configured with any number of cameras of similar or varying types for example on a front and rear surface of mobile device but embodiments are not limited to any number or type of camera .

Computing architecture may include various elements that may vary depending upon a particular implementation and mobile device is not limited to any particular computing architecture . In the example depicted in computing architecture includes a processor and a memory . Processor may be any number and types of processors and memory may be any number and types of memories including volatile memory and non volatile memory that may vary depending upon a particular implementation. Computing architecture may include additional hardware firmware and software elements that may vary depending upon a particular implementation.

Communications interface may include computer hardware software or any combination of computer hardware and software to provide wired and or wireless communications links between mobile device and other devices and or networks. The particular components for communications interface may vary depending upon a particular implementation and embodiments are not limited to any particular implementation of communications interface .

Power power management component may include any number of components that provide and manage power for mobile device . For example power power management component may include one or more batteries and supporting computer hardware and or software to provide and manage power for mobile device .

Operating system executes on computing architecture and may be any type of operating system that may vary depending upon a particular implementation and embodiments are not limited to any particular implementation of operating system . Operating system may include multiple operating systems of varying types depending upon a particular implementation. Applications may be any number and types of applications that execute on computing architecture and operating system . Applications may access components in mobile device such as display camera computing architecture communications interface power power management component and other components not depicted in via one or more application program interfaces APIs for operating system . Applications may provide various functionality that may vary depending upon a particular application and embodiments are not limited to applications providing any particular functionality. Common non limiting examples of applications include social media applications navigation applications telephony email and messaging applications and Web service client applications. In the example depicted in applications include a camera application .

In step an image is acquired. For example camera application may use camera to acquire an image represented by image data. The image data may be stored in memory as image data . The image acquired by camera does not have to be in focus and may be a blurry image. According to one embodiment the image is acquired prior to passive auto focusing being performed because as described in more detail hereinafter the techniques used to identify objects of interest in an image are effective even when the acquired image is not a focused image.

In step the image data is processed to identify a plurality of candidate objects of interest in the image. For example as described in more detail hereinafter camera application may process the image data to identify a plurality of candidate objects of interest in the image based upon one or more cues in the image data . is a block diagram that depicts an image and candidate objects of interest COOI as determined by camera application after processing of the image data for the image acquired by the camera . The candidate objects of interest are physical objects in the image that are determined to be of interest to a user of mobile device and may include man made and natural objects. As indicated by the different shapes in the objects of interest may have different attributes and characteristics including without limitation different size shape color etc. In addition the candidate objects of interest may be physically separated or may overlapping for example as depicted by objects of interest .

In step a particular candidate object of interest is selected from the plurality of candidate objects of interest. For example camera application may select candidate object of interest as the particular candidate object of interest from the plurality of candidate objects of interest on the basis that candidate object of interest has the best analysis score relative to candidate objects of interest indicating that candidate object of interest is most likely to be of interest to a user of mobile device . In the example depicted in the particular candidate object of interest is not located in the center of display and instead is located in the upper right corner of display . Thus the particular candidate object of interest that is selected may be located anywhere in the image.

The particular candidate object of interest that has been selected may be visually identified on display of mobile device to visually indicate to a user of mobile device that the point of focus will be at the location of the particular candidate object of interest . The manner in which the particular object of interest is visually identified may vary depending upon a particular implementation and embodiments are not limited to any particular manner for visually indicating the particular candidate object of interest . For example a graphical symbol such as a rectangle circle one or more arrows etc. may be superimposed on display at the location of the particular candidate object of interest . As another example shading or a change in color or other attribute may be used to visually indicate the particular candidate object of interest .

In step passive auto focusing is performed at the location of the particular candidate object of interest. For example camera application may cause passive auto focusing to be performed at a center location of particular candidate object of interest . This may include camera application invoking a passive auto focusing process via one or more other applications functionality provided by operating system and camera and providing the location of candidate object of interest as the point of focus. Upon completion of the passive auto focusing the particular candidate object of interest will be in focus and the user may begin acquiring photos normally for example by selecting one or more graphical controls displayed on display or by using manual controls provided on mobile device .

The visual identification of the particular candidate object of interest may have stickiness with respect to the particular candidate object of interest meaning that the visual identification of the particular candidate object of interest may continue to visually identify the particular candidate object of interest as the mobile device is moved. For example suppose that the particular candidate object of interest is identified by a graphical rectangle superimposed over the particular candidate object of interest . As the mobile device is moved or reoriented and the particular candidate object of interest moves within display the rectangle may also be moved within display to continue to identify the particular candidate object of interest .

According to one embodiment a user may manually change the particular candidate object of interest from the particular candidate object of interest automatically selected by camera application . For example suppose that candidate object of interest has been selected as the particular candidate object of interest as previously described herein. Suppose further that a user of the mobile device selects candidate object of interest for example by touching the display at the location of candidate graphical object of interest using a finger or a stylus. In response to the user selection of candidate object of interest the visual identification of the particular candidate object of interest is changed from candidate object of interest to candidate object of interest as depicted in . In addition passive auto focusing may be again performed but at the location of the new particular candidate object of interest which in the present example is the location of candidate object of interest .

The process depicted in may be iteratively performed. For example the process depicted in may be repeated continuously repeated on a periodic basis or repeated in response to a user selection of a graphical control displayed on display or a manual control on mobile device . For example a graphical control may be displayed on display which when selected causes the process depicted in to be repeated. This may be useful for example when a user initiates the camera mode on mobile device and then after the particular candidate object of interest has been selected and the passive auto focusing process completed the user moves or reorients mobile device so that the particular candidate object of interest is no longer in the field of view of display . When the mobile device is moving or being reoriented repeating the process continuously may provide a more favorable user experience by refreshing the particular candidate object of interest at the fastest rate but will require more computational resources compared to repeating the process periodically or in response to a user selection of a control.

In the application automatically performs several steps. These include 1 acquiring an initial image represented by image data 2 analyzing the image data to identify a plurality of candidate objects of interest in the image 3 selecting from the plurality of candidate objects of interest a particular candidate object of interest that is most likely to be of interest to the user 4 displaying on the screen of the smart phone a graphical symbol to identify the particular candidate object of interest that was selected and 5 performing passive auto focusing at the location of the particular candidate object of interest. As previously mentioned here the initial image from which the plurality of candidate objects of interest is determined does not have to be a focused image since the low level cues identified in the image data are effective regardless of whether the image is a focused image or not.

In the present example a graphical symbol in the form of a rectangle is superimposed on the rubber duck to visually identify the rubber duck as the point of focus of the smartphone camera. The displaying on the screen of the smart phone of the graphical symbol to identify the particular candidate object of interest that was selected and the focus point of the camera may be performed prior to during or after the passive auto focusing that is performed at the location of the particular candidate object of interest.

In a new object in the form of a traffic cone is added into the field of view of the camera on the smartphone. Steps 1 through 5 described above with respect to are repeated to determine a new plurality of candidate objects of interest and to select a new particular candidate object of interest from the new plurality of candidate objects of interest. The repeating of steps 1 through 5 may be initiated automatically after a specified time or in response to a user request for example via a selection of a search button in the upper right corner of the screen of the smartphone a selection of another control on the smart phone or selection of a graphical icon displayed on the screen of the smart phone. After repeating the process any of the candidate objects of interest may be selected as the new particular candidate object of interest. The rubber duck previously selected as the particular candidate object of interest may again be selected as the particular i.e. the best candidate object of interest. Alternatively another candidate object of interest may be selected as the best candidate object of interest.

In after repeating the process the traffic cone is determined to be the new particular candidate object of interest i.e. the candidate object of interest that is most likely to be of interest to the user. As described in more detail hereinafter this may be determined based upon the traffic cone having a higher score than the rubber duck . Passive auto focusing has been performed at the location of the traffic cone and the graphical symbol is moved from the rubber duck to the traffic cone to visually indicate to the user that the point of focus is now at the location of the traffic cone .

According to one embodiment a user may select another location on the display of the mobile device as the point of focus for the camera. As depicted in a user may select the roll of tape as the point of focus for example by touching the screen of the smartphone using a finger or a stylus at the location of the roll of tape . In response to the user selection passive auto focusing is performed at the location selected by the user. As depicted in the graphical symbol is moved from the traffic cone to the roll of tape to visually indicate to the user that the point of focus for the camera of the smartphone has moved to the location selected by the user. Embodiments are not limited to a user selecting a particular visible object as a new point of focus as depicted and described in the aforementioned example and users may select any location on the screen of the mobile device as a new point of focus and passive auto focusing will be performed at that location.

According to one embodiment of the invention image data is analyzed to identify areas within the corresponding image referred to herein as bounding boxes. Each bounding box corresponds to a candidate object of interest as described herein. Each bounding box is evaluated based upon color contrast edge density and superpixel straddling cues and a score is determined for each of these cues. Bayesian classification is then used to sort the bounding boxes and the bounding box with the highest score is selected as the particular i.e. the best candidate object of interest.

In step a first or next bounding box is selected for processing. In step a color contrast score is determined for the selected bounding box. Color contrast is a useful cue because unique objects tend to have a different color distribution than their immediate surroundings. The color contrast score generally indicates the extent to which a bounding box is dissimilar in color with respect to its immediate surroundings and is computed as the Chi square distance between the LAB histogram of the bounding box and the LAB histogram of the immediate surroundings. Thus a bounding box that completely surrounds a unique object in an image would have a higher color contrast score than a bounding box where half of the bounding box included half of the unique object and the other half of the bounding box included the surrounding area. A bounding box that tightly surrounds the unique object would have the highest color contrast score. An example technique for determining a color contrast score for a bounding box is described in Measuring the Objectiveness of Image Windows by Bogdan Alexe Thomas Deselaers and Vittorio Ferrari the entire contents of which are incorporated herein by reference for all purposes.

In step an edge density score is determined for the selected bounding box. Edge density generally indicates the closed boundary characteristics of objects. An example technique for determining an edge density score for a bounding box is described in Measuring the Objectiveness of Image Windows by Bogdan Alexe Thomas Deselaers and Vittorio Ferrari.

In step a superpixel straddling score is determined for the selected bounding box. Like edge density superpixel straddling is also a way to evaluate the closed boundary characteristics of objects. In general since all pixels in a superpixel ideally belong to the same object a bounding box that straddles a superpixel will receive a lower superpixel score than a bounding box that completely contains a superpixel. An example technique for determining a superpixel score is described in Measuring the Objectiveness of Image Windows by Bogdan Alexe Thomas Deselaers and Vittorio Ferrari.

In step a determination is made whether more bounding boxes need to be processed. If so then control returns to step . If not then in Bayesian cue integration is used to combine the color contrast edge density and superpixel straddling cue scores and sort the bounding boxes and select the bounding box with the highest score as the particular i.e. the best candidate object of interest. As one example the technique described in Measuring the Objectiveness of Image Windows by Bogdan Alexe Thomas Deselaers and Vittorio Ferrari may be used.

Embodiments described herein for identifying objects of interest in images are effective for identifying a wide variety of object types without necessarily having any prior knowledge of what types of objects an image might contain. Example object types include without limitation man made objects facial and other human features and natural objects. In addition the use of multiple types of cues makes the approach effective for different types of images for example images that include man made objects with dominant edges as well as images of natural landscapes that include fewer or no objects with dominant edges. Furthermore the approach may be performed prior to focusing the mobile device camera or capturing a focused image.

The aforementioned approach may be performed continuously so that when a mobile device is operating in a camera mode the best candidate object of interest is continuously re determined and used as the point of focus for passive auto focusing. In some situations however for example on mobile devices with limited computational resources this may cause a delay in selecting new points of focus and may lead to an unfavorable user experience. For example the point of focus may begin to lag behind as a user moves or reorients the mobile device. As previously described herein the aforementioned approach may instead be performed periodically or in response to user input. In addition the approach itself may be adapted for applications where limited computational resources are available. For example the number of bounding boxes may be reduced. Also different combinations of cues may be used to reduce the consumption of computational resources. For example the edge density score may not be used. Other embodiments may include different combinations of cues.

Although the flow diagrams of the present application depict a particular set of steps in a particular order other implementations may use fewer or more steps in the same or different order than those depicted in the figures.

According to one embodiment the techniques described herein are implemented by one or more mobile devices that may be special purpose computing devices. The special purpose computing devices may be hard wired to perform the techniques or may include digital electronic devices such as one or more application specific integrated circuits ASICs or field programmable gate arrays FPGAs that are persistently programmed to perform the techniques or may include one or more general purpose hardware processors programmed to perform the techniques pursuant to program instructions in firmware memory other storage or a combination. Such special purpose computing devices may also combine custom hard wired logic ASICs or FPGAs with custom programming to accomplish the techniques. The special purpose computing devices may be desktop computer systems portable computer systems handheld devices networking devices or any other device that incorporates hard wired and or program logic to implement the techniques.

Computer system may be coupled via bus to a display such as a cathode ray tube CRT for displaying information to a computer user. Although bus is illustrated as a single bus bus may comprise one or more buses. For example bus may include without limitation a control bus by which processor controls other devices within computer system an address bus by which processor specifies memory locations of instructions for execution or any other type of bus for transferring data or signals between components of computer system .

An input device including alphanumeric and other keys is coupled to bus for communicating information and command selections to processor . Another type of user input device is cursor control such as a mouse a trackball or cursor direction keys for communicating direction information and command selections to processor and for controlling cursor movement on display . This input device typically has two degrees of freedom in two axes a first axis e.g. x and a second axis e.g. y that allows the device to specify positions in a plane.

Computer system may implement the techniques described herein using customized hard wired logic one or more ASICs or FPGAs firmware and or program logic or computer software which in combination with the computer system causes or programs computer system to be a special purpose machine. According to one embodiment those techniques are performed by computer system in response to processor processing instructions stored in main memory . Such instructions may be read into main memory from another computer readable medium such as storage device . Processing of the instructions contained in main memory by processor causes performance of the functionality described herein. In alternative embodiments hard wired circuitry may be used in place of or in combination with software instructions to implement the embodiments. Thus embodiments are not limited to any specific combination of hardware circuitry and software.

The term computer readable medium as used herein refers to any medium that participates in providing data that causes a computer to operate in a specific manner. In an embodiment implemented using computer system various computer readable media are involved for example in providing instructions to processor for execution. Such a medium may take many forms including but not limited to non volatile media and volatile media. Non volatile media includes for example optical or magnetic disks such as storage device . Volatile media includes dynamic memory such as main memory . Common forms of computer readable media include without limitation a floppy disk a flexible disk hard disk magnetic tape or any other magnetic medium a CD ROM any other optical medium a RAM a PROM and EPROM a FLASH EPROM any other memory chip memory cartridge or memory stick or any other medium from which a computer can read.

Various forms of computer readable media may be involved in storing instructions for processing by processor . For example the instructions may initially be stored on a storage medium of a remote computer and transmitted to computer system via one or more communications links. Bus carries the data to main memory from which processor retrieves and processes the instructions. The instructions received by main memory may optionally be stored on storage device either before or after processing by processor .

Computer system also includes a communication interface coupled to bus . Communication interface provides a communications coupling to a network link that is connected to a local network . For example communication interface may be a modem to provide a data communication connection to a telephone line. As another example communication interface may be a local area network LAN card to provide a data communication connection to a compatible LAN. Wireless links may also be implemented. In any such implementation communication interface sends and receives electrical electromagnetic or optical signals that carry digital data streams representing various types of information.

Network link typically provides data communication through one or more networks to other data devices. For example network link may provide a connection through local network to a host computer or to data equipment operated by an Internet Service Provider ISP . ISP in turn provides data communication services through the world wide packet data communication network now commonly referred to as the Internet . Local network and Internet both use electrical electromagnetic or optical signals that carry digital data streams.

Computer system can send messages and receive data including program code through the network s network link and communication interface . In the Internet example a server might transmit a requested code for an application program through Internet ISP local network and communication interface . The received code may be processed by processor as it is received and or stored in storage device or other non volatile storage for later execution.

In the foregoing specification embodiments have been described with reference to numerous specific details that may vary from implementation to implementation. Thus the sole and exclusive indicator of what is and is intended by the applicants to be the invention is the set of claims that issue from this application in the specific form in which such claims issue including any subsequent correction. Hence no limitation element property feature advantage or attribute that is not expressly recited in a claim should limit the scope of such claim in any way. The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense.

