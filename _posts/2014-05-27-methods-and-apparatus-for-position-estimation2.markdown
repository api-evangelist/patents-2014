---

title: Methods and apparatus for position estimation
abstract: Systems, apparatus and methods disclosed herein facilitate vision based mobile device location determination. In some embodiments, a method for estimating a position of a mobile device may comprise: detecting that the mobile device is in communication with at least one of a plurality of devices, where each of the plurality of devices associated with a corresponding device identifier. The capture of at least one image by an image sensor coupled to the mobile device may be triggered, based, in part on: the device identifier corresponding to the device in communication with the mobile device, and/or a field of view of the image sensor. A location of the mobile device may then be determined, based, in part, on the at least one captured image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09584980&OS=09584980&RS=09584980
owner: QUALCOMM Incorporated
number: 09584980
owner_city: San Diego
owner_country: US
publication_date: 20140527
---
In vision based positioning systems identification of landmarks and or points of interest in images may be used in conjunction with the known positions of the landmarks and or points of interest to estimate the location of a mobile device. Vision based positioning may be useful is situations where Global Navigation Satellite Systems GNSS such as the Global Positioning System GPS or other network based positioning techniques are less effective. For example GPS based positioning may not be effective within a building or in dense urban areas due to signal unavailability signal losses and or other factors. Landmark or vision based positioning may also provide an alternate location estimation technique that can be used to increase the reliability and accuracy of location estimates obtained using other techniques.

While vision based positioning of mobile devices can be useful there may be situations where user invocation of vision based positioning VBP may be cumbersome impractical or difficult. For example older users or young children may be able to make calls but may experience difficulty in using vision based positioning systems. In another instance during an emergency the user may not be in a state of mind and or have the time to invoke a vision based positioning application.

Therefore there is a need for systems and methods to enhance the usability of vision based location estimations provided by vision based positioning systems.

In some embodiments a method for estimating a position of a mobile device may comprise detecting that the mobile device is in communication with one of a plurality of devices wherein each of the plurality of devices is associated with a corresponding device identifier. The capture of at least one image by an image sensor coupled to the mobile device may be triggered based in part on a device identifier corresponding to the device communicating with the mobile device or a field of view of the image sensor or a combination thereof. A location of the mobile device may then be determined based in part on the at least one captured image.

In another aspect a mobile device may comprise a memory an image sensor and a processor coupled to the image sensor and the memory. In some embodiments the processor may be configured to detect that the mobile device is in communication with one of a plurality of devices each device in the plurality of devices associated with a corresponding device identifier and trigger the capture of at least one image by the image sensor. The capture of the at least one image may be triggered based in part on a device identifier corresponding to the device communicating with the mobile device or a field of view of the image sensor or a combination thereof. A location of the mobile device may be determined based in part on the at least one captured image.

In a further aspect a mobile device may comprise means for detecting that that the mobile device is in communication with one of a plurality of devices each device in the plurality of devices associated with a corresponding device identifier in the stored plurality of device identifiers and means for triggering the capture of at least one image by an image sensing means. The capture of the at least one image may be triggered based in part on the device identifier corresponding to the device in communication with the mobile device or a field of view of the image sensor means or a combination thereof. The mobile device may further comprise means for determining a location of the mobile device based in part on the at least one captured image.

Further in some embodiments a computer readable medium may comprise instructions which when executed by a processor may perform steps in a method for estimating a position of a mobile device. In some embodiments the steps may comprise detecting that the mobile device is in communication with one of a plurality of devices wherein each of the plurality of devices is associated with a corresponding device identifier and triggering the capture of at least one image by an image sensor coupled to the mobile device based in part on a device identifier corresponding to the device communicating with the mobile device or a field of view of the image sensor or a combination thereof. The steps mat further comprise determining a location of the mobile device based in part on the at least one captured image.

The detailed description set forth below in connection with the appended drawings is intended as a description of some exemplary non limiting embodiments and various other embodiments may be practiced and are envisaged as would be apparent to one of skill in the art. Embodiments described are provided merely as examples or illustrations of the present disclosure. The detailed description includes specific details for the purpose of providing a thorough understanding of the present disclosure. However it will be apparent to those skilled in the art that the present disclosure may be practiced without one or more of these specific details. In some instances well known structures and devices are not shown in block diagram form in order to avoid obscuring the concepts of the present disclosure. Acronyms and other descriptive terminology may be used merely for convenience and clarity and are not intended to limit the scope of the disclosure.

Vision based mobile device location techniques described herein may be implemented in conjunction with various wireless networks including wireless communication networks such as a wireless local area network WLAN a wireless personal area network WPAN wireless wide area network WWAN and so on. The term Vision Based Positioning VBP is used herein to refer to the determination of a location of the device based on one or more images captured by the device. In referring to the process of determining the location of a mobile device using a positioning system the terms location estimation locating and positioning are often used interchangeably.

The term landmark or point of interest POI refers to distinct features in the environment around the mobile device which may be natural or manmade and may be indoors or outdoors. POIs may include various objects with distinguishing features including structures kiosks buildings storefronts natural features signs of various types such as name boards office numbers store signs logos billboards etc. The terms landmark or POI are often used interchangeably. The locations of POIs may be known in advance and stored along with maps including visibility maps of and or related to the POI images of the POIs and distinctive features of the POIs identified in the stored images.

Typically the pose which is the position and orientation of the mobile device relative to one or more known landmarks in conjunction with the known position of the landmark POI may be used to estimate the location of the mobile device. When optical sensors such as image sensors on or coupled to mobile devices are used the position of the mobile device can be estimated based on the identification of known landmarks in images of the environment around the mobile device taken by the image sensor.

Mobile device may be stationary or mobile and may also be referred to as a mobile terminal mobile station a user equipment UE an access terminal AT a subscriber station a station STA etc. The term mobile device is also intended to include devices which communicate with a personal navigation device PND for example by using short range wireless infrared wireline connection or other connection regardless of whether signal reception assistance data reception and or position related processing occurs at the device s or at the PND. Also mobile device may be a cellular phone a personal digital assistant PDA a handheld device a wireless device a tablet a laptop computer a wireless modem a cordless phone a telemetry device a tracking device etc. which are capable of communication with a server such as via the Internet Wi Fi or other network and regardless of whether satellite signal reception assistance data reception and or position related processing occurs at the device at a server or at another device associated with the network. Any operable combination of the above is also considered a mobile device. 

Mobile device may for example include various functional units such as one or more processing units or processor s memory transceiver e.g. wireless network interface and as applicable an SPS receiver camera s optical sensor s image sensor hereinafter referred to as image sensor and non transitory computer readable medium which may comprise fixed and or removable media in an exemplary removable media drive not shown . The functional units in mobile device may be operatively coupled through one or more connections e.g. buses lines fibers links etc. . In certain example implementations all or part of mobile terminal may take the form of a chipset and or the like.

In some embodiments Satellite Positioning System SPS receiver in mobile device may be enabled to receive signals associated with one or more SPS resources. A satellite positioning system SPS typically includes a system of transmitters positioned to enable entities to determine their location on or above the Earth based at least in part on signals received from the transmitters which may be located on ground based control stations user equipment and or space vehicles. In a particular example such transmitters may be located on Earth orbiting Satellite Vehicles SVs . As used herein an SPS may include any combination of one or more global such as Galileo GPS GLONASS etc and or regional navigation satellite systems such as satellite systems such as QZSS Beidou IRNSS etc and or augmentation systems. Further SPS signals may include SPS SPS like and or other signals associated with such one or more SPS. Mobile device may be able to determine its position based on signals received from one or more SPS.

In some embodiments mobile device may also comprise transceiver which may include a transmitter enabled to transmit one or more signals over one or more types of wireless communication networks and a receiver to receive one or more signals transmitted over the one or more types of wireless communication networks. For example transmitter and receiver may be able to communicate with wireless networks including Wireless Local Area Networks WLANs Wireless Personal Area Networks WPANs Wireless Wide Area Networks WWANs cellular networks femtocells and various other types wireless communication networks.

WWANs or cellular networks may include a Code Division Multiple Access CDMA 1 networks a High Rate Packet Data HRPD network a Wideband CDMA WCDMA network a Global System for Mobile Communications GSM network a General Packet Radio Service GPRS network a Long Term Evolution LTE network or some other wireless network. GSM WCDMA and GPRS are part of Universal Mobile Telecommunications System UMTS . LTE is part of Evolved Packet System EPS . CDMA 1 and HRPD are part of cdma2000. GSM WCDMA GPRS and LTE are described in documents from a consortium named the 3rd Generation Partnership Project 3GPP . CDMA 1 and HRPD are described in documents from a consortium named the 3rd Generation Partnership Project 2 3GPP2 .

WLANs may include for example wireless networks compatible with the Institute of Electrical and Electronics Engineers IEEE 802.11x family of standards which may also be referred to as a Wi Fi network. Such a network may also include Access Points or Wireless Access Points APs or WAPs that couple wireless communication devices to the WLAN. APs acts as a central transmitter and receiver of WLAN radio signals. WPANs may include Bluetooth networks networks based on the IEEE 802.15x family of standards or some other types of networks.

In some embodiments mobile device may comprise image sensor such as optical sensor s a plurality of CCD or CMOS sensors and or image sensor which are hereinafter referred to as image sensor . Image sensor may convert an optical image into an electronic or digital image and may send captured images to processor s . In some embodiments image sensor may be housed in a wearable display which may be operationally coupled to but housed separately from processors and or other functional units in mobile device .

Image sensor may send captured images to processor s . In some embodiments Image sensor may comprise front facing and rear facing image sensor and may also incorporate CMOS sensors. In general image sensor may include color or grayscale image sensor video and or still cameras and or RGB D cameras which capture color images in a Red Green Blue RGB format along with per pixel depth information. In some embodiments an RGBD camera an ultrasonic sensor or another sensor may be able to determine depth or distance information for POIs in conjunction with the capture of images of the object by image sensor .

In one embodiment image sensor may comprise a front facing camera which may face the user during normal user operation of the device and a rear facing camera which may face away from the user during normal operation of the device. In one embodiment images captured by image sensor may be in a raw uncompressed format and may be compressed prior to being processed and or stored in memory and or medium . In some embodiments image compression may be performed by processor s using lossless or lossy compression techniques. In embodiments with RGB D cameras the image may be processed and stored along with the depth distance related information. In some embodiments the depth distance information may be used by processor s for location determination of mobile device .

In some embodiments processor s may also receive input from IMU . In some embodiments IMU may comprise 3 axis accelerometer s 3 axis gyroscope s and or magnetometer s . IMU may provide velocity orientation and or other position related information to processor s . In some embodiments IMU may output measured information in synchronization with the capture of each image frame by image sensor . In some embodiments the pose of image sensor relative to an image may be determined or corrected based in part on input from IMU . In some embodiments known intrinsic parameters and characteristics of image sensor such as the focal length of the lens image sensor focus distance etc. may be used in conjunction with input from IMU to assist with and or refine image sensor pose determination. In some embodiments the estimated pose of the mobile device relative to a POI corresponding POI and a confidence interval associated with the estimated pose may be determined based on the mobile device captured images. In some embodiments images captured by image sensor may be used to recalibrate or perform bias adjustments for IMU .

Processor s may be implemented using a combination of hardware firmware and software. In some embodiments processor s may represent one or more circuits configurable to perform at least a portion of a data signal computing procedure or process related to the operation of mobile device . Processor s may be capable of triggering the capture of images by image sensor in response to the sensing of one or more conditions receiving instructions data from receiver and or retrieving instructions data from memory and or computer readable medium and may respond to the instructions and or send data results using transceiver . Processor s may also be capable of processing various other received information either directly or in conjunction with one or more other functional blocks shown in . For example processor s may process images received from image sensor and or stored in memory or computer readable medium . For example processor s may implement VBP techniques. In some embodiments processor s may process images taken by image sensor to determine a location of mobile device . The images may be one or more still images or a video sequence. For example processor s identify one or more landmarks or POIs in the images and generate and or process one or more visibility maps based on the identified landmarks to determine a position of mobile device . Processor s may also obtain and use other information such as output from IMU and or depth information from image sensor prior location information based on SPS signals or trilateration based on Round Trip Time RTT and or Received Signal Strength Indicator RSSI measurements etc. during position determination of mobile device . Processor s may also be capable of performing various other functions described herein.

Processor s may be implemented within one or more application specific integrated circuits ASICs digital signal processors DSPs digital signal processing devices DSPDs programmable logic devices PLDs field programmable gate arrays FPGAs controllers micro controllers microprocessors embedded processor cores electronic devices other electronic units designed to perform the functions described herein or a combination thereof. For a firmware and or software implementation the methodologies may be implemented with modules e.g. procedures functions and so on that perform the functions described herein.

Any machine readable medium tangibly embodying instructions may be used in implementing the methodologies described herein. For example software code may be stored in a non transitory computer readable medium and or memory and may be retrieved and executed by processor s . A storage medium may be any available medium that can be accessed by a computer. By way of example and not limitation such non transitory computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a computer disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

In addition to storage on computer readable medium instructions and or data may be provided as signals on transmission media included in a communication apparatus. For example a communication apparatus may include a transceiver having signals indicative of instructions and data. The instructions and data are configured to cause one or more processors to implement the functions outlined in the claims. That is the communication apparatus includes transmission media with signals indicative of information to perform disclosed functions.

Memory may be implemented within processor s and or external to processor s . As used herein the term memory refers to any type of long term short term volatile nonvolatile or other memory and is not to be limited to any particular type of memory or number of memories or type of physical media upon which memory is stored. In some embodiments memory may hold configuration settings information about mobile device and functional units on mobile device such as part and version numbers capabilities etc code to facilitate the operation of mobile device and other tasks performed by processor s . For example memory may hold images map data information pertaining to POIs program data and results outputs of various sensors such as IMU proximity sensor etc. In general memory may represent any data storage mechanism.

Memory may also hold one or more databases such as a map database which may include 2 D and 3 D maps POI databases locations of POIs images of POIs features of POIs etc. In some embodiments the maps may include one or more POI visibility maps which may comprise a set of grid points. In some embodiments medium and or memory may comprise one or more databases that may hold information pertaining to various POI entities for a region around a current location of mobile device . In some embodiments POI related information may include images of the POIs locations of the POIs POI features for Scale Invariant Feature Transform SIFT Speeded Up Robust Features SURF or other image matching algorithms visibility maps for the POIs etc. In some embodiments information stored in databases in memory may retrieved from computer readable medium and or received over a wireless network. For example mobile device may receive map databases and or a POI database relevant to an area around a current location of mobile device over a wireless network or by loading relevant information from computer readable medium . Memory may include for example a primary memory and or a secondary memory. Primary memory may include for example a random access memory read only memory etc. While illustrated in as being separate from processor s it should be understood that all or part of a primary memory may be provided within or otherwise co located and or coupled to processor s . In one embodiment a server such as a location server may send map and POI databases for a serving cell or a region covered by a wireless network to mobile device when mobile device registers with the network or at some point thereafter.

Secondary memory may include for example the same or similar type of memory as primary memory and or one or more data storage devices or systems such as for example flash USB memory drives memory card drives disk drives optical disc drives tape drives solid state memory drives etc. In certain implementations secondary memory may be operatively receptive of or otherwise configurable to couple to a non transitory computer readable medium in a removable media drive not shown coupled to mobile device . In some embodiments non transitory computer readable medium may form part of memory and or processor s .

Further in certain example implementations mobile device may include a variety of other sensors such as a proximity sensor which may be one of several sensors shown in as sensor bank . In some embodiments the proximity sensor may provide signal or other indication based on the proximity of a section of mobile device to the user. For example in one embodiment proximity sensor may provide an indication when the speaker or earpiece of mobile device is proximate to and or in physical contact with the user. Proximity sensors may be electrical e.g. inductive or capacitive optical. e.g. infra red or laser magnetic or sonar. In some embodiments the proximity sensors may be passive e.g. by measuring some environmental characteristic to determine user proximity or active e.g. may generate signals and measure signal parameters to determine user proximity .

The output of proximity sensors may be binary e.g. near or far in contact or not in contact or may vary based on the distance of some specific section of mobile device e.g. the earpiece from the user. In some embodiments the output of a continuously varying proximity sensor may be thresholded to produce a binary output. In some embodiments the output of proximity sensor may be used by processor s to enable and or disable one or more applications on mobile device . In some embodiments the output of proximity sensor may be used at least in part to trigger location determination based on at least image captured by image sensor coupled to mobile device . For example a vision based location application on mobile device may be triggered. As another example in embodiments where image sensor is wearable mobile device may not comprise a proximity sensor or the output of the proximity sensor may be ignored and image based location determination and or a vision based location application may be triggered based on configuration settings that identify mobile device as having a wearable image sensor and or an image sensor with a typically available field of view and or other information provided by the an operating system application and or image sensor and or other criteria consistent with embodiments disclosed herein. Sensor bank may further include one or more additional sensors such as an ambient light sensor microphones acoustic sensors ultrasonic sensors etc.

Further mobile device may include a screen or display capable of rendering color images including 3D images. In some embodiments display may be used to display live images captured by image sensor AR images Graphical User Interfaces GUIs program output etc. In some embodiments display may comprise and or be housed with a touchscreen to permit users to input data via some combination of virtual keyboards icons menus or other Graphical User Interfaces GUIs user gestures and or input devices such as a stylus and other writing implements. In some embodiments display may be implemented using a Liquid Crystal Display LCD display or a Light Emitting Diode LED display such as an Organic LED OLED display. In other embodiments display may be a wearable display or a heads up display which may be operationally coupled to but housed separately from other functional units in mobile device . In some embodiments mobile device may comprise ports to permit the display of the MR images through a separate monitor coupled to mobile device .

Not all modules comprised in mobile device have been shown in . Exemplary mobile device may also be modified in various ways in a manner consistent with the disclosure such as by adding combining or omitting one or more of the functional blocks shown. For example in some configurations mobile device may take the form of a gaming or other devices that may not be configured to connect to a network or otherwise communicate either wirelessly or over a wired connection with another device. Thus embodiments disclosed herein may be used in a standalone AR system device for example in a mobile device that does not require communication with another device. As another example in embodiments where image sensor is wearable mobile device may not comprise a proximity sensor.

Mobile device may also receive location assistance information from server and or communicate with server during location determination. For example server may have map and POI information related to the area around a current location of mobile device . In some embodiments server may be part of a cellular network and may have map and POI related information for the serving cell and one or more neighboring cells. In some embodiments the map and POI related information may be held in one or more databases and may be sent to retrieved by and or downloaded to local storage on mobile device . For simplicity only one server and one mobile device are shown in . However in general there may multiple servers in communication with one or more mobile devices at any time.

For example if GPS or A GPS signals are unavailable within building the position of the user or mobile device just prior to entering building may be used to approximate the location of mobile device within building . In some embodiments when GPS A GPS signals are unavailable the most recent position fix obtained using SVs and or network may be used as one approximation of a prior position of the mobile device . In some instances the position of mobile device may be further refined from the approximation above based on information received IMU . However inaccuracies in location estimates may continue to arise because of errors or biases inherent in measurements by IMU . In some embodiments location determination based on at least one captured image and or vision based positioning may also be used to determine or refine the position of mobile device . For example when position determination by other methods is impaired location determination based on at least one captured image and or vision based positioning techniques may be used in a manner consistent with disclosed embodiments to refine the position of mobile device . In some embodiments the last or most recent position fix obtained using some combination of GPS A GPS trilateration network based positioning methods and or IMU based measurements may be used as an initial approximation of the location mobile device when performing location determination based on at least one captured image and or VBP.

Exemplary visibility map shows that region is visible to POI or conversely POI is visible to grid points in region and that shaded region visible to POI or conversely POI is visible to grid points in region . Thus in a grid point g x y is in the line of sight of POI if it lies in region or in the line of sight of POI if it lies in region . For example when mobile device takes captures an image of POI mobile device is in a line of sight of POI and therefore located in visibility region . In some instances mobile device may be in a line of sight of several POIs and a VBP application may trigger the capture of a plurality of images which may include some subset of the POIs.

Regions outside the shaded region are either not visible to the POI entity being considered or may not be considered because they may lie outside some visibility threshold. For example in some embodiments regions that are distant from the POI and or are at poor viewing angles may not be included in the visibility map and or may be eliminated from consideration in operations described herein.

In POIs and may be storefront signs and in some embodiments visibility maps and or may be generated using previously stored information in response to a picture of a storefront taken by an image sensor on the mobile device. For example if the image of the storefront sign captured by the user of the mobile device shows ABC BOOKS then the captured image may be processed to determine that the user is in front of an ABC BOOKS store entrance in a mall which may be in building . In some embodiments a subset of POIs may be identified as a match out of a plurality of POIs in a region by using mobile device captured images of POIs and comparing the mobile device captured images of each POI with stored POI images of the plurality of POIs in the region. For example mobile device may capture several images of POIs from a location the mobile device captured POI images may be matched with stored POI images and a subset of POIs may be identified as being shown in the mobile device captured images and therefore visible to mobile device .

Various image processing and computer vision techniques such as the Scale Invariant Feature Transform SIFT may be used to identify features in a POI image captured by the mobile device and correlate the identified features in the captured image with features in reference images of the POI stored in a database. In some embodiments the features selected for inclusion in a database may be highly distinctive to permit individual features to be matched with high probability against a large database of features from many images. Such matching or feature identification may be achieved by mobile device by a server such as server wirelessly coupled to mobile device or by mobile device in conjunction with one or more servers wirelessly coupled to mobile device and may be performed by some combination of hardware and or software.

In some embodiments SIFT may be used to extract distinctive and invariant features from images. These features may be used for robust matching of different views of an object or scene. In SIFT image features selected for matching may be invariant to image scaling and rotation. SIFT permits robust feature matching across a substantial range of affine distortion and through noise changes in 3D viewpoints and changes in illumination. Affine transformations pertain to image transformations which preserve straight lines so that all points lying on a line continue to lie on a line after transformation. Affine distortion occurs when a transformation distorts lines in an image so that the collinear points prior to the transformation are skewed to some degree about a line post transformation. SIFT algorithms are robust and tolerate affine distortion when performing feature matching. In one embodiment Optical Character Recognition OCR may be used to identify the POI and the viewing angle of the image sensor relative to the POI may be estimated based on the distortion of the bounding box of the text or based on the detected vanishing points.

In some embodiments the last known or most recent GPS position may used as an approximation of the location of mobile device and images of POIs in an area around the last known most recent GPS location may be searched for images corresponding to the image of POI captured by image sensor on mobile device . In some embodiments the position of mobile device may be further narrowed from the last known most recent GPS location based on information provided by IMU . In some embodiments mobile device may be able to connect to a WLAN through Access Points e.g. APs and within the mall building and network based positioning methods may be used to calculate an approximate location of mobile device . In general one or more techniques above may be used individually or combined in a manner consistent with disclosed embodiments to obtain an initial estimate of the location of mobile device . In some embodiments images associated with an area around the initial estimate of the location of mobile device may be searched to determine a correspondence with one or more image s taken by image sensor on mobile device .

Accordingly in one embodiment an area around the user s last known determined position may be searched for an image corresponding to POI . Once the storefront sign has been identified as ABC BOOKS it may be determined that there are two entrances given by POIs and to the ABC BOOKS store where the sign may be located. Visibility map may then be generated based on POIs and and regions and may be seen a possible locations of the mobile device and or the user because POIs and are visible from these regions.

In some embodiments the position of the user may be further refined based on a likelihood or probability relative to a POI such as POI that a user is at a specific grid point. In one embodiment the probability relative to a POI that a mobile device is at a specific grid point may be estimated based on an optimal or estimated viewing angle and or an optimal or estimated distance from which the POI can be seen.

In another embodiment when location determination based on at least one captured image using computer vision based techniques are applied to images captured by the mobile device and used for pose estimation then the probability relative to a POI that a mobile device is at a specific grid point may be estimated using the pose estimation and a confidence interval or accuracy associated with the pose estimation. In some embodiments mobile device pose estimation may be based in part on information provided by IMU . In some embodiments pose related information provided by IMU may be used in conjunction with computer vision based techniques. When mobile device pose estimation uses information provided by IMU then the probability relative to a POI that a mobile device is at a specific grid point may be estimated using the pose estimation and by adjusting the confidence interval based on the accuracy associated with the IMU hybrid pose estimation.

In a further embodiment the probability relative to a POI that a mobile device is at a specific grid point may be estimated based on knowledge of previous locations from where people have seen this landmark. For example a history based on information compiled from various information sources such as third party information sources which may include images associated with the POI in question may be used to determine a probability relative to the POI that a mobile device is at a specific grid point. For popular attractions there may be preferred vantage points from which pictures are typically taken or from which features associated with the POI that may be advantageously viewed. By comparing an image taken by mobile device with the images from one or more third party sources a probability relative to a POI that a mobile device is at a specific grid point may be ascertained. In some embodiments the images may be available from the Internet from various picture sharing social media web sites such as Flickr Picasa Facebook etc from image search engines such as Yahoo Google Bing etc. and or from a web site associated with the POI.

In some instances such as where pose estimation for a landmark POIis unavailable and no prior history of locations and images from where people have seen the landmark exists then in some embodiments an individual POI grid point weight wcan be assigned to each point g x y relative to an optimal or estimated viewing angle and or an optimal or estimated distance for viewing the landmark POI. In some instances the optimal viewing angle and or optimal distance may correspond to the viewing angle and or distance from which the landmark is viewed best. The optimal viewing angle and or distance to view the landmark may be determined empirically though heuristics or by other estimation techniques. For example an optimal view of a specific store may be from a distance of about 10 feet from the storefront and the optimal viewing angle of the store front could be directly facing the store front i.e. in the normal vector direction from the store front.

In some embodiments VBP techniques may obtain a location of mobile device as the centroid of region . In some embodiments the centroid may be based on the cumulative grid point weight of grid points in region . For example an estimate for the location of the mobile device user relative to a plurality of POIs may be obtained based on a cumulative grid point weight which represents the probability that a mobile device is at a specific grid point relative to the POIs under consideration. In some embodiments a cumulative grid point weight may be computed for each grid point in region . The cumulative grid point weight may be computed as a function of POI specific grid point weights associated with a grid point in a visibility map such as visibility map .

For example a cumulative grid point weight Wfor a grid point g x y on visibility maps may be computed as a function of the set of POI grid point weights w where wis the POI grid point weight of grid point g x y relative to corresponding the jPOI POI. For example a cumulative grid point weight Wfor a grid point g x y in region in visibility map may be computed based on POI grid point weights wrelative to POIs and .

In general for a set of M grid points and a subset of N POIs that are visible from a location of MS and given by POIthrough POI the cumulative grid point weight Wfor each grid point g x y 1 i M on a visibility map may be calculated as 1 wis the POI grid point weight of grid point g x y for corresponding jPOI 0 j N 1 and w w d w  where w dand w  are distance and angle based weights respectively for g x y for POI. For example for POIs and there are no grid points in region from which POI is visible and no grid points in region from which POI is visible. Therefore the cumulative weight of grid points in region relative to POIs and is zero. Conversely POIs and are visible from all grid points in region . Therefore each grid point in region may have a non zero cumulative weight relative to POIs and .

Accordingly the cumulative grid point weight for each grid point may be computed as a function of individual POI grid point weights for each POI in the subset of POIs. For example the function to compute the cumulative grid point weight for each grid point may be a product of the individual POI grid point weights of POI in the subset. In some embodiments the cumulative grid point weight may be computed for grid points in an area common to the visibility maps of the subset of POIs. Further in some embodiments the area common to the visibility maps of the subset of POIs is obtained from an intersection of visibility maps corresponding to the subset of POIs

where Wis the cumulative grid point weight for grid point g x y on the visibility map. The estimated location of the MS may be given as loc X loc Y . In the location of the MS is estimated as the grid point .

Based on the device identifier and or satisfaction of some other criteria a VBP application on mobile device may be invoked and one or more images by image sensor may be captured. For example during a phone call or other aural communication mobile device may be held against the ear with the rear image sensor facing away and typically having a wide view angle or wide field of view. Thus based in part on the field of view in some embodiments during communication with specified device identifiers such as during an emergency 911 call location determination may be initiated based on at least one image captured by image sensor . In some embodiments a VBP application may be automatically triggered one or more pictures or a video sequence by image sensor may be captured and the pictures video sequence may be used to determine a location of mobile device using VBP techniques consistent with embodiments described herein. In some embodiments a VBP application may be triggered when the call to the specified device identifiers such as a phone number is placed and or a call from one of the specified device identifiers is received. In some embodiments the VBP application may be triggered based on input from a proximity sensor. For example in a situation where a young child is lost or a person is disoriented when the child or person calls or is called by parents or guardians one or more pictures or a video sequence by image sensor may be captured and the pictures video sequence may be used to determine a location of mobile device . The pictures video sequence may also be transmitted to the device in communication with mobile device and or to a location server or other position determination entity.

In step a call or communication to or from mobile device from a device associated with a device identifier may be detected. In step it may be determined whether the called or calling device identifier e.g. a phone number is one of a specified set of previously designated device identifiers. If the called or calling device identifier is one of a specified set of previously designated device identifiers Y in step then sensor input may be obtained in step . If the called or calling device identifier is not one of a specified set of previously designated device identifiers N in step then the next communication may be awaited in step .

In some embodiments steps and may be optionally executed. In step sensor input may optionally be obtained. For example sensor input may be obtained by processor s from proximity sensor sensor bank . In some embodiments steps and may be omitted or not invoked or not executed . For example in embodiments where the configuration settings or other parameters may be used to infer or predict that a clear picture from image sensor on mobile device is normally available then steps and may be omitted without regard to input from any proximity sensor on mobile device .

In step if the input from proximity sensor sensor bank indicates that mobile device and or a portion of mobile device is not proximate to nor in contact with the user s body N in step then another iteration is begun in step where new sensor readings may be obtained.

In step if the input from proximity sensor sensor bank indicates that mobile device and or a portion of mobile device is proximate to and or in contact with the user s body Y in step or if configuration settings indicate image sensor field of view availability then in step the capture of one or more images video images by image sensor may be triggered and a position of mobile device may be determined based on the one or more images captured by image sensor . The input from proximity sensors and or configuration settings may be used to determine the available or likely field of view for image sensor . As shown in by the dashed lines rear facing image sensor typically has a large field of view when the phone is held against the ear. Similarly as shown in a wearable mobile device may have an image sensor whose field of view is typically wide.

For example any known VBP technique may be used in conjunction with method . For example one or more techniques disclosed in the following co pending commonly assigned U.S. patent application Ser. No. 13 794 316 entitled Methods and Apparatus for Position Estimation Ser. No. 13 486 359 entitled Logo Detection for Indoor Positioning and Ser. No. 13 829 099 entitled Pose Estimation Based on Peripheral Information may be used during VBP to obtain an estimated position of mobile device . The above identified applications are all hereby incorporated by reference in their entireties herein.

In some embodiments input from other sensors such as the ambient light sensor battery indicator available memory etc may be used to determine whether to trigger the flash and or to determine the number and or frequency and or resolution of captured images.

In step the estimated position of mobile device as determined by the VBP technique in step is sent to one or more specified parties. In some embodiments one or more of the images captured during VBP may be sent along the estimated position of mobile device . In some embodiments the images may be compressed prior to transmission the resolution of images captured by image sensor may be adjusted and or a subset of the number of images captured may be transmitted based on the available bandwidth signal strength and or a specified protocol used for communication and or user configuration settings. For example image compression may be increased and or lower resolution images captured and or a lower number of images transmitted if the available bandwidth is lower. In another embodiment one or more of the resolution of images compression scheme nature of images e.g. still or video number of images transmitted may be adjusted or specified based on some agreed upon communication protocol user configuration settings and or based upon input from an image based location determination application or VBP application.

In routine one or more POIs may be identified in an image captured by mobile device . In some embodiments the last known most recent location of mobile device may be used to obtain an initial estimate or approximation of the location of mobile device and the image captured by mobile device may be matched with images of POIs in a region around the initial estimate. In some embodiments a subset of POIs may be identified from a plurality of POIs in a POI database by matching mobile device captured images of each POI in the subset with a corresponding stored POI images. For example the stored POI images may be matched to corresponding mobile device captured images based in part on Scale Invariant Feature Transform SIFT techniques.

Next in step visibility maps corresponding to the one or more POI s identified in step may be generated. For example the visibility map may be generated using a plurality of vectors representing lines of emanating from the POI and ending at opaque barriers on the map and or at a predefined distance threshold which may be specified by maxRange . In some embodiments the plurality of vectors may further be limited by an angular threshold from a normal vector which may be specified by maxAngle . By integrating over the plurality of vectors a visibility region representative of the visibility map may be calculated. In some embodiments a visibility maps for POIs may be generated in advance stored and made available as part of a map and or POI database.

In step the algorithm may determine if additional images are present or may be requested. For example if there is ambiguity related to the POIs e.g. two POIs and associated with the ABC BOOKSTORE storefront additional images may be requested and or obtained and processed. If there are additional images to be processed Y in step then in step the next image may be selected and another iteration is begun in step .

If there are no more images N in step then in some embodiments an intersection of visibility maps may be computed in routine . In some embodiments the computation of the intersection of visibility maps may yield a set of grid points that define a region which may be used as an estimate of the location of mobile device . In some embodiments algorithm may terminate and invoke additional VBP methods to further refine or narrow the estimated location of mobile device . For example the centroid of the region obtained by the intersection of visibility maps may be used to narrow the position of mobile device . In some embodiments the centroid may be computed based on individual POI grid point weights wassigned to each point g x y relative to an optimal or estimated viewing angle and or an optimal or estimated distance for viewing the landmark POI.

In some embodiments in step a current mobile device location estimate may be obtained based in part on received location assistance information . In some embodiments for example if location assistance information is unavailable POI image database may be queried based in part on a prior or most recent mobile device location estimate . In some embodiments the prior or most recent mobile device location estimate may be based on the last known location of mobile device which in some instances may be augmented using input from IMU . In some embodiments location assistance information may be used in conjunction with prior or most recent mobile device location estimate to obtain an estimated position of mobile device . In step 

In step in some embodiments the current mobile device location estimate obtained in step may then be used along with one or more captured images to query POI image database . The captured image may be compared with stored images and a refined estimate of the location of mobile device may be obtained in step . For example various image processing and computer vision techniques using image descriptors such as SIFT SURF etc. may be used to identify features in a POI image captured by image sensor and correlate the identified features in the captured image with features in reference images of the POI stored in a database. The correlated features may be used in conjunction with mobile device location estimate from step to obtain a refined location of mobile device .

In step the refined location estimate may be used to obtain one or more visibility maps corresponding to a region around the refined location estimate. For example visibility maps for regions and may be obtained.

In step the intersection of visibility maps associated with POIs identified in the captured image may be determined. For example as shown in exemplary visibility map may be obtained based on the overlap or intersection between regions and . Visibility map shows the intersection given by region which is the set of likely positions of mobile device .

In step in some embodiments VBP techniques may obtain a location of mobile device as the centroid of region . In some embodiments the centroid may be based on the cumulative grid point weight of grid points in region . For example an estimate for the location of the mobile device user relative to a plurality of POIs may be obtained based on a cumulative grid point weight which represents the probability that a mobile device is at a specific grid point relative to the POIs under consideration. In some embodiments a cumulative grid point weight may be computed for each grid point in region . The cumulative grid point weight may be computed as a function of POI specific grid point weights associated with a grid point in a visibility map such as visibility map . In some embodiments the cumulative grid point weight and an estimated location of mobile device may be obtained using equations 1 and 2A 2B above.

Communications interfaces may include a variety of wired and or wireless connections that support wired transmission and or reception and if desired may additionally or alternatively support transmission and reception of one or more signals over one or more types of wireless communication networks. Communications interfaces may also include interfaces for communication with various other computers and peripherals. For example in one embodiment Communications interfaces may comprise network interface cards input output cards chips and or ASICs that implement one or more of the communication functions performed by server . Further server may receive mobile device related information including estimates of the location of mobile device such as the last known most recent location requests for location assistance images of POIs captured by mobile device etc. and or may also retrieve POI related information from websites through communications interfaces . For example in some embodiments communications interface s may be configured to receive the captured images of each POI in the subset from a mobile device. In some embodiments server may use communications interface to send POI related information including POI databases location assistance information position estimates etc. to mobile device . In general communications interfaces may be used to send and receive data control management and configuration information to one or more mobile devices.

Processor s may be implemented using a combination of hardware firmware and software. In some embodiments processor s may be capable of determining a location of a mobile device based in part on at least one captured image and may include a VBP determination module and or a location assistance module not shown to facilitate location determination of mobile device and or to provide location assistance information respectively. For example in one embodiment if image based location determination is being performed by mobile device or another network entity server may provide POI related information including POI databases as location assistance information. In one embodiment server may use VBP determination module to implement some portion of methods and or . In some embodiments the functionality in exemplary methods and may be combined in to a single module. Processor s may also be capable of processing various other types of information such as performing image processing using SIFT SURF etc. or other image matching algorithms to match POIs in images captured by mobile device with images of POIs stored on server either directly or in conjunction with one or more other functional blocks shown in . In some embodiments processor s may represent one or more circuits configurable to perform at least a portion of a data signal computing procedure or process related to the operation of server .

The methodologies described herein in flow charts and message flows may be implemented by various means depending upon the application. For example these methodologies may be implemented in hardware firmware software or any combination thereof. For a hardware implementation the processor s may be implemented within one or more application specific integrated circuits ASICs digital signal processors DSPs digital signal processing devices DSPDs programmable logic devices PLDs field programmable gate arrays FPGAs processors controllers micro controllers microprocessors electronic devices other electronic units designed to perform the functions described herein or a combination thereof.

For a firmware and or software implementation the methodologies may be implemented with modules e.g. procedures functions and so on that perform the functions described herein. Any machine readable medium tangibly embodying instructions may be used in implementing the methodologies described herein. For example software may be stored in media drive which may support the use of non transitory computer readable media including removable media. Program code may be resident on non transitory computer readable media or memory and may be read and executed by processor unit s . Memory may be implemented within processor s or external to processor s . As used herein the term memory refers to any type of long term short term volatile nonvolatile or other memory and is not to be limited to any particular type of memory or number of memories or type of media upon which memory is stored.

If implemented in firmware and or software the functions may be stored as one or more instructions or code on a non transitory computer readable medium and or memory . Examples include computer readable media encoded with a data structure and computer readable media encoded with a computer program. For example non transitory computer readable medium including program code stored thereon may include program code to support robust position estimation using VBP and or to provide location assistance to mobile device in a manner consistent with disclosed embodiments.

Non transitory computer readable media includes a variety of physical computer storage media. A storage medium may be any available medium that can be accessed by a computer. By way of example and not limitation such non transitory computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disc storage magnetic disk storage or other magnetic storage devices or any other medium that can be used to store desired program code in the form of instructions or data structures and that can be accessed by a computer disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Other embodiments of non transitory computer readable media include flash drives USB drives solid state drives memory cards etc. Combinations of the above should also be included within the scope of computer readable media.

In addition to storage on computer readable medium instructions and or data may be provided as signals on transmission media to communications interfaces which may store the instructions data in memory storage and or relay the instructions data to processor s for execution. For example communications interfaces may receive wireless or network signals indicative of instructions and data. The instructions and data may cause one or more processor s to be configured to implement one or more functions outlined in the claims. That is the communication apparatus includes transmission media with signals indicative of information to perform disclosed functions.

Memory may represent any data storage mechanism. Memory may include for example a primary memory and or a secondary memory. Primary memory may include for example a random access memory read only memory nonvolatile RAM etc. While illustrated in this example as being separate from processor s it should be understood that all or part of a primary memory may be provided within or otherwise co located coupled with processor s . Secondary memory may include for example the same or similar type of memory as primary memory and or storage such as one or more data storage devices or systems including for example hard disk drives optical disc drives tape drives a solid state memory drive etc. In some embodiments storage and or memory may comprise one or more databases that may hold information pertaining to various POI entities for locations served by server . In some embodiments POI related information may include images of the POIs locations of the POIs POI features for SIFT or other image matching algorithms visibility maps for the POIs etc. In some embodiments information in the databases may be read used and or updated by processor s during various computations including methods for robust VBP mobile device position estimation for generating location assistance data and or for computing estimated locations of mobile devices etc.

In certain implementations secondary memory may be operatively receptive of or otherwise configurable to couple to a non transitory computer readable medium in media drive . As such in certain example implementations the methods and or apparatuses presented herein may take the form in whole or part of a media drive that may include non transitory computer readable medium with computer implementable instructions stored thereon which if executed by processor s may be operatively enabled to perform all or portions of the example operations as described herein.

In some embodiments portions of method may be performed by mobile device and or server . In some embodiments processor s and or may perform portions of method .

In some embodiments in step a communication between the mobile device and at least one of a plurality of devices where each of the plurality of devices is associated with a corresponding device identifier may be detected. For example the device identifier may take the form of a phone number.

Next in step the capture of at least one image by an image sensor coupled to the mobile device may be triggered based in part on the device identifier corresponding to the device or a field of view of the image sensor or some combination thereof. In some embodiments the prediction of the camera s field of view may be based in part on input from a proximity sensor on the mobile device indicating that a section of the mobile device is within a threshold proximity of a user of the mobile device. In some embodiments the prediction of image sensor field of view may be based in part on input from a proximity sensor on the mobile device indicating that a section of the mobile device is in contact with a user of the mobile device. In some embodiments the prediction of image sensor field of view may be based in part on a configuration of the mobile device indicating that a field of view is available for the image sensor. In some embodiments the capture of the at least one image may be triggered using a rear facing image sensor which may in some instance be capable of capturing video images.

In step a location of the mobile device may be determined based in part on the at least one captured image. For example VBP for the mobile device may be initiated based in part on the at least one captured image. In some embodiments a location of the mobile device may be determined based at least in part on the output of the VBP. In some embodiments the determined location of the mobile device may be transmitted to a device associated with the at least one device identifier and in communication with the mobile device. In some embodiments one or more of the captured images which may include video images may also be transmitted to the device associated with the at least one device identifier and in communication with the mobile device.

In some embodiments VBP may comprise identifying in the at least one captured image a subset of Points of Interest POIs in a plurality of POIs the subset of POIs being identified by comparing the at least one captured image with stored POI images wherein each POI in the subset is associated with a corresponding visibility map and determining an estimated location of the mobile device based at least in part on an intersection of visibility maps corresponding to each POI in the subset.

