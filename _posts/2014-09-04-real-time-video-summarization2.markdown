---

title: Real time video summarization
abstract: System, apparatus, method, and computer readable media for on-the-fly captured video summarization. A video stream is incrementally summarized in concurrence with generation of the stream by a camera module. Saliency of the video stream summary is maintained as the stream evolves by updating the summary to include only the most significant frames. In one exemplary embodiment, saliency is determined by optimizing an objective function including terms that are indicative of both the diversity of a selection, and how representative the selection is to the processed portion of the video data corpus. A device platform including a CM and comporting with the exemplary architecture may provide video camera functionality at ultra-low power, and/or with ultra-low storage resources, and/or with ultra-low communication channel bandwidth.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09639762&OS=09639762&RS=09639762
owner: Intel Corporation
number: 09639762
owner_city: Santa Clara
owner_country: US
publication_date: 20140904
---
A digital camera is a component often included in commercial electronic media device platforms. Digital cameras are now available in wearable form factors e.g. video capture earpieces video capture headsets video capture eyeglasses etc. as well as embedded within smartphones tablet computers and notebook computers etc.

The introduction of streaming video from mobile digital cameras has ushered in an era having an unprecedented volume of video data. Consider an application where the user wears a pair of glasses fitted with a video camera. The camera captures video streams depicting the activities of the user throughout the day. The user may be interested in viewing a synopsis of the main events of a particular day. However manual analysis of such large amounts of data is intractable and automated data processing techniques have not kept pace with the need.

For example automated video summarization algorithms that attempt to abstract the main occurrences and provide a succinct representation of a captured video typically require access to an entire pre recorded video file and generate a summary of this static atomic unit. Such a technique however relies on large processing storage resources to first encode archive and decode the entire stream duration originally captured at potentially high frame rates e.g. 25 frames second or more . If such processing storage resources are not present natively within the video recording platform which may become the default for ultra low power platforms e.g. headsets and other wearable forms an entire video stream needs to be transferred from a camera platform to a backend machine e.g. cloud server for processing. Such a transfer however entails a heavy load on communication channels and is impractical for many device platforms and use cases.

Video recording platform architectures and techniques capable of automatically summarizing video in real time on the fly as a video stream arrives progressively over time from camera module hardware present on the platform are therefore advantageous.

One or more embodiments are described with reference to the enclosed figures. While specific configurations and arrangements are depicted and discussed in detail it should be understood that this is done for illustrative purposes only. Persons skilled in the relevant art will recognize that other configurations and arrangements are possible without departing from the spirit and scope of the description. It will be apparent to those skilled in the relevant art that techniques and or arrangements described herein may be employed in a variety of other systems and applications beyond what is described in detail herein.

Reference is made in the following detailed description to the accompanying drawings which form a part hereof and illustrate exemplary embodiments. Further it is to be understood that other embodiments may be utilized and structural and or logical changes may be made without departing from the scope of claimed subject matter. Therefore the following detailed description is not to be taken in a limiting sense and the scope of claimed subject matter is defined solely by the appended claims and their equivalents.

In the following description numerous details are set forth however it will be apparent to one skilled in the art that embodiments may be practiced without these specific details. Well known methods and devices are shown in block diagram form rather than in detail to avoid obscuring more significant aspects. References throughout this specification to an embodiment or one embodiment mean that a particular feature structure function or characteristic described in connection with the embodiment is included in at least one embodiment. Thus the appearances of the phrase in an embodiment or in one embodiment in various places throughout this specification are not necessarily referring to the same embodiment. Furthermore the particular features structures functions or characteristics described in the context of an embodiment may be combined in any suitable manner in one or more embodiments. For example a first embodiment may be combined with a second embodiment anywhere the particular features structures functions or characteristics associated with the two embodiments are not mutually exclusive.

As used in the description of the exemplary embodiments and the appended claims the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will also be understood that the term and or as used herein refers to and encompasses any and all possible combinations of one or more of the associated listed items.

As used throughout the description and in the claims a list of items joined by the term at least one of or one or more of can mean any combination of the listed terms. For example the phrase at least one of A B or C can mean A B C A and B A and C B and C or A B and C.

The terms coupled and connected along with their derivatives may be used herein to describe functional or structural relationships between components. It should be understood that these terms are not intended as synonyms for each other. Rather in particular embodiments connected may be used to indicate that two or more elements are in direct physical optical or electrical contact with each other. Coupled may be used to indicated that two or more elements are in either direct or indirect with other intervening elements between them physical optical or electrical contact with each other and or that the two or more elements co operate or interact with each other e.g. as in a cause an effect relationship .

Some portions of the detailed descriptions provide herein are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. Unless specifically stated otherwise as apparent from the following discussion it is appreciated that throughout the description discussions utilizing terms such as calculating computing determining estimating storing collecting displaying receiving consolidating generating updating or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s circuitry including registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

While the following description sets forth embodiments that may be manifested in architectures such system on a chip SoC architectures for example. Implementation of the techniques and or arrangements described herein are not restricted to particular architectures and or computing systems and may be implemented by any architecture and or computing system for similar purposes. Various architectures employing for example multiple integrated circuit IC chips and or packages and or various computing devices and or consumer electronic CE devices such as set top boxes smartphones etc. may implement the techniques and or arrangements described herein. Further while the following description may set forth numerous specific details such as logic implementations types and interrelationships of system components logic partitioning integration choices etc. claimed subject matter may be practiced without such specific details. Furthermore some material such as for example control structures and full software instruction sequences may not be shown in detail in order not to obscure the material disclosed herein.

Certain portions of the material disclosed herein are implemented in hardware for example as logic circuitry in a graphics processor. Certain other portions may be implemented in hardware firmware software or any combination thereof. At least some of the material disclosed herein may also be implemented as instructions stored on a machine readable medium which may be read and executed by one or more processors graphics processors and or central processors . A machine readable medium may include any medium and or mechanism for storing or transmitting information in a form readable by a machine e.g. a computing device . For example a machine readable medium may include read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices electrical optical acoustical or other similarly non transitory tangible media.

One or more system apparatus method and computer readable media is described below for real time captured video summarization. In real time captured video summarization a video stream is incrementally summarized in concurrence with generation of the stream. The summarization algorithm is operable without access to an entire video at any given time instead observing it in segments sequentially over a period of time. Indeed in one exemplary embodiment where analyzed portions of a video corpus are discarded overwritten by newly collected portions frames included in a summary may have no analog within the surviving portion of the video corpus. As described further below frames newly received from a CM and frames previously assessed are candidate summary frames iteratively evaluated for saliency as the data stream is received. Saliency of the stream summary is maintained as the stream evolves by updating the summary to include only the most significant frames. In one exemplary embodiment saliency is determined by optimizing an objective function including terms that are indicative of both the diversity of a selection and how representative the selection is to the processed portion of the video data corpus.

Multiple iterations of a summarization algorithm are to be executed in a time window spanning a CM s output of a first video frame to a last frame of a given series of consecutively captured frames comprising a continuous video stream. Rate requirements for real time summarization are therefore a function of a frame rate associated with a camera hardware module CM . As described below a device platform including a CM and comporting with the exemplary architecture may provide video camera functionality at ultra low power and or with ultra low storage resources and or with ultra low communication channel bandwidth. As also described below a device platform including a CM and comporting with the exemplary architecture may enhance a user s video camera experience even where processing power and or storage and or communication resources are not at a particular premium.

As further illustrated the platform hosting the CM may also display a representation of the stored stream summary e.g. a set of image files at operation . Alternatively or additionally at operation the platform hosting the CM may further transmit a representation of the stored stream summary e.g. a set of image files to a remote destination e.g. a cloud server . For exemplary embodiments in accordance with method therefore exposed video data frames received from the CM that are not selected as summary frames e.g. 1 000 000 or more video data frames are discarded e.g. overwritten by newer streamed video frames in a circular buffer implementation reducing platform storage and or transmission channel resource requirements by three or four orders of magnitude. For further embodiments where the summarization operation is upstream of a video stream encoding process encoding engine resources and or power is also reduced. With adequate quality of the automated stream summary a handful of image frames resulting from a day s continuous recording may serves as a valuable visual catalogue of the day s events.

In the exemplary embodiment illustrated in frame scoring logic includes both coverage scoring logic and diversity scoring logic . Coverage scoring logic is to compute coverage scores based on frame feature vectors. A coverage score is a metric quantifying how well a given frame represents other frames to which it is compared. Diversity scoring logic is to compute diversity scores based on the frame feature vectors. A diversity score is a metric quantifying how distinct a frame is from other frames to which it is compared. Selection logic is then to solve an objective function that is dependent on both coverage and diversity scores with the solution representing for example the set of frames with maximum coverage and maximum diversity. As such the selected summary should cover most of the video while also including the most distinct elements. In alternate embodiments one or more of coverage scoring logic and diversity scoring logic may be further combined with additional scoring logic circuitry. Selection logic is then to solve an alternate objective function for example following the rationale further described below in the context of the exemplary embodiment.

Platform includes CM . In the exemplary embodiment CM further includes a camera sensor . Sensor may be a QXGA WQXGA or QSXGA format digital image device for example. Camera sensor may provide a color resolution of 10 bits or more per pixel is operable to capture continuous video frames progressively. Sensor may have a pixel frequency of 170 MHz or more. Camera sensor may include an RGB Bayer color filter an analog amplifier an A D converter other components to convert incident light into a digital signal corresponding to raw image data. Sensor may be controlled to operate a rolling shutter or electronic focal plane shutter process where pixels are read out progressively in a line sequential fashion for a frame. In exemplary video embodiments sensor outputs multiple consecutively exposed frames. CM outputs at raw video data associated with the consecutively exposed frames in conformance with any known streaming protocol such as a MIPI or other protocol. Streamed raw video data is input to ISP . ISP is to receive and analyze frames of raw video data during the horizontal and or vertical blanking periods associated with CM . During raw image data processing ISP may perform one or more of noise reduction pixel linearization and shading compensation for example.

Processed video data may be buffered in a FIFO manner for example with a circular buffer. DSP is to fetch sets segments of consecutively exposed frames received into the buffer from CM before new frames output by CM overwrite them. illustrates consecutively exposed frames in a video stream in accordance with one or more embodiment. illustrate sets of frames generated from the video stream depicted in in accordance with an embodiment. In a first embodiment illustrated by temporally adjacent sets are non overlapping with each set including n frames that are exclusive of any frames included in other sets. In a second embodiment illustrated by temporally adjacent sets are overlapping with each set including n 1 frames that are inclusive of frames included in another set. For the first embodiment the stream summarization process will be iterated once for every n frames exposed by a CM. For the second embodiment the stream summarization process will be iterated once for every frame exposed by the CM. Depending on the summarization technique employed and the resources implementing the technique the amount of frame redundancy between adjacent sets may be varied between the two embodiments illustrated in . In exemplary RT video stream summarization method described further below adjacent sets are non overlapping e.g. .

Segmentation of the streaming video is useful for providing some scene consistency with respect to objects in each set of frames to be analyzed by the video summarization system. In exemplary embodiments the number of frames included in each segment is static and predetermined with all sets of frames including n consecutive frames. The number of consecutive frames in each set may be controlled through subsystem drivers within a kernel space of an operating system OS instantiated by a central processing unit CPU . Access to the number of consecutive frames may be provided though a RT summarization control parameter within an application layer executing in a user space of the OS. DSP may utilize scene shot change detection logic in the segmentation process. Shot boundary detection algorithms attempt to detect the junction between two video shots. They typically compute a difference metric like pixel gray level differences statistical differences histogram differences or motion vectors between every two consecutive images in a video stream and a shot boundary is assumed when the difference exceeds a pre determined threshold. In exemplary embodiments however DSP generates frame sets that include far fewer frames than a typical scene. Hence if scene detection is utilized each scene will be further divided in to multiple frame sets for the downstream summarization process. In embodiments the number of frames n in each set is less than 100 advantageously less than 50 and more advantageously between 10 and 30 frames.

Sets of frames are output to hardware accelerator which in the exemplary embodiment includes fixed function logic circuitry implementing RT video summarization system . Embodiments employing fixed function logic are well suited to summarizing received video data frames at pace with a high exposure frame rate while consuming minimal power. In an alternative embodiment however or any known programmable processor including DSP a core of CPU an execution unit of a graphics processor or other similar vector processor may be utilized to implement the logic of RT video summarization system introduced in . In an exemplary embodiment where hardware accelerator implements the RT video summarization system upstream of video data frame encoding summary frames may be output from accelerator back to DSP for encoding as still frames. Encoded representations of summary frames from HW accelerator A are sent as stream summary frame data to storage display transmission pipeline . In one exemplary storage pipeline embodiment stream summary frame data is output to memory storage e.g. NVR DRAM etc. which may be separate or a part of a main memory accessible to CPU . Alternatively or in addition storage display transmission pipeline is to transmit summary frame data off device platform .

Method begins with receiving a new set of n consecutively exposed video frames contained in a video segment V. At operation a current stream summary comprising batch of one or more k stream summary frames is accessed. In exemplary embodiments the stream summary frame number k is static and predetermined. The number of stream summary frames may be controlled for example through subsystem drivers within a kernel space of an operating system OS instantiated by a central processing unit CPU . Access to the number of consecutive frames may be provided through a RT summarization control parameter within an application layer executing in a user space of the OS. In embodiments the number of steam summary frames k is less than 1000 advantageously less than 100 and more advantageously between 10 and 30 frames.

Each frame in the batch of k stream summary frames was previously selected during one or more prior iteration of method . illustrates a RT video summarization model that is implemented by one or more embodiment of method . As shown in stream summary comprises a selection of video data frames limited to a predetermined number of summary frame slots. With k slots available k incumbent stream summary frames summarize any number of prior frame sets that were exposed and processed through the summarization process earlier in time. For example a snapshot of stream summary includes incumbent frame i from set V most recently processed incumbent frame i j from a frame set V 3 etc. Looking forward in time any number of new frame sets will be exposed and processed through the summarization process later in time e.g. beginning with set V and ending with V m . In response to receiving each new frame set e.g. V V 1 etc. a summarization iteration is performed where the incumbent k stream summary frames and n non incumbent frames are the batch of candidate frames for selection through application of an objective function . With each iteration one or more incumbent frame may retain a slot within stream summary and one or more incumbent frame may be evicted from stream summary in preference of a non incumbent frame included in a new set e.g. set V 1 .

As further illustrated in each of the candidate frames n k from operations and are scored at operation . Each non incumbent frame in a new set of frames received from the CM is scored with respect to the other frames in the new set and with respect to each incumbent frame. At operation the batch including one or more summary frame is selected from the candidate frame pool including the non incumbent and the incumbent frames. The objective function is solved at operation to compute the reward loss associated with a given selection of summary frames. Candidate frames are selected based on the solution that optimizes the frame scoring for the selection. At operation the batch of k stream summary frames is updated in response to the selection of frames made at operation differing from the batch of k stream summary frames accessed at operation . Updating the stream summary at operation includes adding at least each selected non incumbent frame to the summary. In an exemplary embodiment the addition of the non incumbent frame may entail replacing an incumbent frame flushed out of the summary in preference for the non incumbent frame. In further embodiments where a frame and a coverage score is to be stored for each stream summary slot and as described in more detail below updating the stream summary at operation further includes adding to the stream summary a coverage score associated with each non incumbent frame selected. For example a coverage score associated with an evicted incumbent frame may be overwritten with the coverage score associated with the newly selected frame. The updated batch of k summary frames is stored to memory at operation . If the end of stream EOS has not been reached method returns to operation for a subsequent iteration. If the EOS has been reached method ends with the stream summary frames stored.

In the above embodiment when an incumbent summary frame is evicted due to the arrival of newer a more informative frame the incumbent summary frame is removed from further consideration. In embodiments having sufficient available memory however the incumbent summary frame s flushed at the summary update operation is stored to a secondary memory location to potentially enhance the quality of a final video summary generated by method . Secondary storage operation is illustrated in with dashed line to emphasize that retention of all summary frames iteratively generated during video streaming is optional. For those embodiments where all summary frames are retained upon reach an EOS condition method proceeds to operation where a secondary selection of L summary frames is made. In the exemplary embodiment operation entails solving the same objective function solved at the primary selection operation based on the frame scores previously generated at operation and the feature vector associated with each stored summary frame. The number of final selected frames L may be equal to or larger than the batch of k summary frames and may be a configurable value in the same manner as the values of n and k. The secondary selection operation is among the set of salient frames stored over time both to the memory slots associated with the batch of k summary frames and the those stored to secondary memory slots. Thus method becomes a two tier process in which salient frames are first filtered out from video segments and final summary frames are then selected from all salient frames.

Method continues with operation where a coverage vector c of dimension n k is computed. One exemplary embodiment of operation is further illustrated in as method . The feature vectors for all frames of a video segment V are received at operation . Operation is then iterated to compute one non incumbent coverage score for each frame i with respect to n 1 other non incumbent frames. Element i in the coverage vector c is computed for a received frame set Vas max 1 where wdenotes the similarity between the feature vectors associated with the pair of frames i and j in the frame set V. While there are many techniques for measuring similarity of two vectors the inventors have found the cosine similarity metric to work well for HOG feature vectors. The similarity metric utilized in method may be controlled for example through subsystem drivers within a kernel space of an operating system OS instantiated by a central processing unit CPU . Access to the similarity metric may be further provided through a RT summarization control parameter within an application layer executing in a user space of the OS. Computation of the maximum value of the similarity metric for each frame in the new frame set V advantageously limits the coverage score to a vector. At operation each c i computed at operation is added or joined as a new element to the coverage vector c.

Method continues with receiving incumbent coverage scores c k associated with the k incumbent stream summary frames at operation . In the exemplary embodiment the incumbent coverage scores c k are fetch from memory having been stored from prior iterations of method which invoked method . At operation the n elements of coverage vector c are joined with the k stored coverage scores c k so that the coverage vector c that encompasses all candidate frames incumbent and non incumbent .

Returning to method continues at operation where a 2D diversity matrix is computed. The diversity matrix includes a diversity score for each frame in the newly received set V with respect to the other frames in the set and with respect to each incumbent frame. The diversity score is a metric indicative of distance between the feature vectors computed at operation . For the exemplary embodiment where the feature vector is a HOG vector the diversity score is indicative of a distance between color histograms for pairings of all frames in the candidate pool. One exemplary embodiment of operation is further illustrated in as method . As shown in the feature vectors for all frames of a video segment V are again received at operation . Additionally the feature vectors for all k summary frames are received at operation . At operation distances between all exclusive pairs of n k feature vectors are computed to populate the diversity matrix D with element i j computed as 2 where dis the distance metric between frames i and j. The distance metric dmay be any known in the art such as but not limited to the Euclidean Chi squared and Mahalanobis distance. In the exemplary embodiment where the feature vectors are HOG vectors the Chi squared distance metric has been found to be advantageous for generating diversity matrix D. The like the similarity metric the distance metric utilized in method may be controlled for example through subsystem drivers within a kernel space of an operating system OS instantiated by a central processing unit CPU . Access to the distance metric may be further provided through a RT summarization control parameter within an application layer executing in a user space of the OS.

Returning to method continues at operation where the batch of stream summary frames are selected for the current iteration based the coverage and diversity scores for the selection. One exemplary embodiment of operation is further illustrated in as method . Coverage vector c and diversity matrix D are received at operations . At operation and optimization vector x is to identify a set of k frames with maximal coverage and maximal mutual diversity. Considering a binary vector x of dimension n k in which element i denotes whether frame i is to be included in the stream summary. Because of the dimensionality of the coverage and diversity scores the selection can thus be formalized as the integer quadratic programming QP problem 

The solution to equation 3 however is NP hard if integer constraints are placed on the variable vector x. Therefore in advantageous embodiments the integer constraints are relaxed and allowed to be continuous where every element in the vector x is constrained to be a real number between 0 and 1. Equation 3 is then readily solvable using any known QP solver. The top k entries in the solution vector may then be set to 1 and the remainder set to 0 to reconstruct the integer solution. This optimization vector identifies the non incumbent frames and incumbent frames to be discarded 0 valued elements and selected as summary frames 1 valued elements .

Returning to method then ends with the storing k summary frames at operation . In advantageous embodiments for each frame stored at operation the corresponding coverage score is stored in association with the frame to facilitate a subsequent comparison with a next set of frames e.g. to be read in at in . One non selected incumbent frame is removed replaced in the stream summary for each non incumbent frame selected. Any coverage score associated with the non selected incumbent frame is also removed replaced.

System includes a device platform that may implement all or a subset of the various streaming video camera summarization methods and any of the RT streaming video summarization systems described above in the context of . In various exemplary embodiments video processor executes RT video summarization algorithms. Video processor includes logic circuitry implementing RT video summarization system to iteratively generate sets of video summary images synchronously with video frame data streamed from CM for example as described elsewhere herein. In some embodiments one or more computer readable media may store instructions which when executed by CPU and or video processor cause the processor s to execute one or more RT video summarization algorithm such as any of those described in detail above. One or more image data frame exposed by CM may then be stored in memory as streamed video summary data.

In embodiments device platform is coupled to a human interface device HID . Platform may collect raw image data with CM which is processed and output to HID . A navigation controller including one or more navigation features may be used to interact with for example device platform and or HID . In embodiments HID may include any television type monitor or display coupled to platform via radio and or network . HID may include for example a computer display screen touch screen display video monitor television like device and or a television.

Under the control of one or more software applications device platform may display user interface on HID . Movements of the navigation features of controller may be replicated on a display e.g. HID by movements of a pointer cursor focus ring or other visual indicators displayed on the display. For example under the control of software applications the navigation features located on navigation controller may be mapped to virtual navigation features displayed on user interface .

In embodiments device platform may include any combination of CM chipset processors memory storage applications and or radio . Chipset may provide intercommunication among processors memory video processor applications or radio .

One or more of processors may be implemented as one or more Complex Instruction Set Computer CISC or Reduced Instruction Set Computer RISC processors x86 instruction set compatible processors multi core or any other microprocessor or central processing unit CPU .

Memory may be implemented as a volatile memory device such as but not limited to a Random Access Memory RAM Dynamic Random Access Memory DRAM or Static RAM SRAM . Memory may also be implemented as a non volatile storage device such as but not limited to flash memory battery backed up SDRAM synchronous DRAM magnetic memory phase change memory and the like.

Radio may include one or more radios capable of transmitting and receiving signals using various suitable wireless communications techniques. Such techniques may involve communications across one or more wireless networks. Example wireless networks include but are not limited to wireless local area networks WLANs wireless personal area networks WPANs wireless metropolitan area network WMANs cellular networks and satellite networks. In communicating across such networks radio may operate in accordance with one or more applicable standards in any version.

In embodiments system may be implemented as a wireless system a wired system or a combination of both. When implemented as a wireless system system may include components and interfaces suitable for communicating over a wireless shared media such as one or more antennas transmitters receivers transceivers amplifiers filters control logic and so forth. An example of wireless shared media may include portions of a wireless spectrum such as the RF spectrum and so forth. When implemented as a wired system system may include components and interfaces suitable for communicating over wired communications media such as input output I O adapters physical connectors to connect the I O adapter with a corresponding wired communications medium a network interface card NIC disc controller video controller audio controller and the like. Examples of wired communications media may include a wire cable metal leads printed circuit board PCB backplane switch fabric semiconductor material twisted pair wire co axial cable fiber optics and so forth.

The RT streaming video summarization architecture and associated summarization processes as described herein may be implemented in various hardware architectures cell designs or IP cores. 

As described above system may be embodied in varying physical styles or form factors. further illustrates embodiments of a mobile handset device in which system may be embodied. In embodiments for example device may be implemented as a mobile computing device having wireless capabilities. A mobile computing device may refer to any device having a processing system and a mobile power source or supply such as one or more batteries for example. Examples of a mobile computing device may include an ultra laptop computer tablet touch pad portable computer handheld computer palmtop computer personal digital assistant PDA cellular telephone combination cellular telephone PDA television smart device e.g. smartphone tablet or smart television mobile internet device MID messaging device data communication device and so forth. Examples of a mobile computing device also may include computers and or media capture transmission devices configured to be worn by a person such as a wrist computer finger computer ring computer eyeglass computer belt clip computer arm band computer shoe computers clothing computers and other wearable computers. In various embodiments for example a mobile computing device may be implemented as a smart phone capable of executing computer applications as well as voice communications and or data communications. Although some embodiments may be described with a mobile computing device implemented as a smart phone by way of example it may be appreciated that other embodiments may be implemented using other wireless mobile computing devices as well. The embodiments are not limited in this context.

As shown in mobile handset device may include a housing with a front and back . Device includes a display an input output I O device and an integrated antenna . Device also may include navigation features . Display may include any suitable display unit for displaying information appropriate for a mobile computing device. I O device may include any suitable I O device for entering information into a mobile computing device. Examples for I O device may include an alphanumeric keyboard a numeric keypad a touch pad input keys buttons switches microphones speakers voice recognition device and software and so forth. Information also may be entered into device by way of microphone not shown or may be digitized by a voice recognition device. Embodiments are not limited in this context. Integrated into at least the back is camera e.g. including a lens an aperture and an imaging sensor and a flash both of which may be components of a CM through which streaming video is exposed and output to the video summarization system as described elsewhere herein.

Embodiments described herein may be implemented using hardware elements software elements or a combination of both. Examples of hardware elements or modules include processors microprocessors circuitry circuit elements e.g. transistors resistors capacitors inductors and so forth integrated circuits application specific integrated circuits ASIC programmable logic devices PLD digital signal processors DSP field programmable gate array FPGA logic gates registers semiconductor device chips microchips chip sets and so forth. Examples of software elements or modules include applications computer programs application programs system programs machine programs operating system software middleware firmware routines subroutines functions methods procedures software interfaces application programming interfaces API instruction sets computing code computer code code segments computer code segments data words values symbols or any combination thereof. Determining whether an embodiment is implemented using hardware elements and or software elements may vary in accordance with any number of factors considered for the choice of design such as but not limited to desired computational rate power levels heat tolerances processing cycle budget input data rates output data rates memory resources data bus speeds and other design or performance constraints.

One or more aspects of at least one embodiment may be implemented by representative instructions stored on a machine readable storage medium. Such instructions may reside completely or at least partially within a main memory and or within a processor during execution thereof by the machine the main memory and the processor portions storing the instructions then also constituting a machine readable storage media. Programmable logic circuitry may have registers state machines etc. configured by the processor implementing the computer readable media. Such logic circuitry as programmed may then be understood to be physically transformed into a system falling within the scope of the embodiments described herein. Instructions representing various logic within the processor which when read by a machine may also cause the machine to fabricate logic adhering to the architectures described herein and or to perform the techniques described herein. Such representations known as cell designs or IP cores may be stored on a tangible machine readable medium and supplied to various customers or manufacturing facilities to load into the fabrication machines that actually make the logic or processor.

While certain features set forth herein have been described with reference to embodiments this description is not intended to be construed in a limiting sense. Hence various modifications of the implementations described herein as well as other implementations which are apparent to persons skilled in the art to which the present disclosure pertains are deemed to be within the spirit and scope of the present disclosure.

In one or more first embodiment a captured video data stream summarization method includes receiving a stream of consecutively exposed video data frames from a camera hardware module CM . The method includes iteratively evaluating a stream summary comprising one or more of the video data frames based on each new set of frames received from the CM. The evaluating further includes scoring each non incumbent frame in a new set of frames received from the CM with respect to the other frames in the new set and with respect to each incumbent frame included in the stream summary from a prior iteration. The evaluating further includes selecting frames from a pool including the non incumbent and the incumbent frames based on a solution to an objective function that optimizes the frame scoring for the selection. The method further includes updating the stream summary stored in a memory in response to selecting a non incumbent frame in preference over an incumbent frame.

In furtherance of the one or more first embodiment scoring each non incumbent frame further includes computing a feature vector for each frame in the new set. Scoring each non incumbent frame further includes computing a non incumbent coverage score based on the feature vectors for each frame in the new set with respect to the other frames in the new set. Scoring each non incumbent frame further includes computing a diversity score based on the feature vectors for each frame in the new set with respect to the other frames in the new set and with respect to each incumbent frame. The method further includes selecting one or more frame further comprises populating a predetermined number of summary frame slots with the incumbent frames and the non incumbent frames associated with a solution to the objective function that maximizes the coverage scores and diversity scores for the selection.

In furtherance of the embodiment immediately above the feature vector is based on histograms of oriented gradient HOG . Computing the non incumbent coverage score comprises determining a coverage vector including a maximum value of a similarity metric for each frame in the new set. Computing the diversity score comprises determining a 2D diversity matrix comprising the distance between color histograms for pairings of all frames in the pool.

In furtherance of any of the first embodiments updating the stream summary further includes adding to the stream summary each non incumbent frame selected and adding to the stream summary a coverage score associated with each non incumbent frame selected. Scoring each non incumbent frame further includes computing a feature vector for each frame in the set. Scoring each non incumbent frame further includes computing a non incumbent coverage score based on the feature vectors for each frame in the set with respect to the other frames in the set. The method further includes computing a 2D diversity matrix based on the feature vectors the matrix including a diversity score for each frame in the in the set with respect to the other frames in the set and with respect to each incumbent frame. Selecting one or more frame further includes computing a coverage vector by joining the non incumbent coverage scores with the stored coverage scores. Selecting one or more frame further includes solving an objective function including the coverage vector and the diversity matrix for an optimization vector having the maximum diversity score and maximum coverage score. Selecting one or more frame further includes selecting the non incumbent frames and incumbent frames identified by the optimization vector.

In furtherance of the one or more first embodiment updating the stream summary further include adding to the stream summary each non incumbent frame selected. Updating the stream summary further includes adding to the stream summary a coverage score associated with each non incumbent frame selected. Updating the stream summary further includes dropping from the stream summary one non selected incumbent frame for each non incumbent frame selected. Updating the stream summary further includes dropping from the stream summary a coverage score associated with each non selected incumbent frame removed from the stream summary.

In furtherance of the embodiment immediately above the stream summary comprises a predetermined number of stream summary frame slots. Each incumbent frame occupies one of the summary frame slots. Updating the stream summary further includes swapping the contents of a summary frame slot associated with an incumbent frame flushed in preference for non incumbent frame. The method further includes overwriting video data frames summarized by the stream summary with more recently exposed video data frame data.

In furtherance of the embodiment immediately above the method further includes storing to a secondary memory each frame and associated coverage value removed from a stream summary slot. The method further includes performing a secondary selection of frames from a pool of frames including those associated with the summary frame slots and those stored to the secondary memory based on a solution to the objective function that optimizes the frame scoring for a predetermined number of slots of a secondary stream summary. The method further includes storing the frames from the secondary selection to the memory.

In furtherance of the first embodiment the stream received from the CM is associated with a frame rate and the evaluating is iterated at a rate at least equal to the frame rate divided by a predetermined number of frames included in each new set.

In furtherance of the first embodiment the method further includes storing to a secondary memory a representation of the stream having more frames than the stream summary and indexing the stream representation based on the stream summary.

In one or more second embodiment a video data stream capture and summarization system includes a camera hardware module CM to generate a stream of consecutively exposed video data frames. The system includes logic circuitry coupled to the CM to iteratively evaluate a stream summary comprising one or more of the frames based on each new set of received from the CM. The logic circuitry further includes frame scoring logic to score each non incumbent frame in a new set of frames received from the CM with respect to the other frames in the new set and with respect to each incumbent frame included in the stream summary from a prior iteration. The logic circuitry further includes frame selection logic to select frames from a pool including the non incumbent and the incumbent frames based on a solution to an objective function that optimizes the frame scoring for the selection. The system includes logic circuitry to update the stream summary stored in a memory in response to selecting a non incumbent frame in preference over an incumbent frame.

In furtherance of the second embodiment the frame scoring logic is further to compute a feature vector for each frame in the new set. The frame scoring logic is further to compute a non incumbent coverage score based on the feature vectors for each frame in the new set with respect to the other frames in the new set. The frame scoring logic is further to compute a diversity score based on the feature vectors for each frame in the new set with respect to the other frames in the new set and with respect to each incumbent frame.

In furtherance of the second embodiment the frame scoring logic is further to compute a feature vector for each frame in the new set the feature vector based on histograms of oriented gradient HOG . The frame scoring logic is further to compute a non incumbent coverage score based on the feature vectors for each frame in the new set with respect to the other frames in the new set by determining a coverage vector including a maximum value of a similarity metric for each frame in the new set. The frame scoring logic is further to compute a diversity score based on the feature vectors for each frame in the new set with respect to the other frames in the new set and with respect to each incumbent frame by determining a 2D diversity matrix comprising the distance between color histograms for pairings of all frames in the pool.

In furtherance of the second embodiment the logic circuitry to update the stream summary is to add to the stream summary each non incumbent frame selected and add to the stream summary a coverage score associated with each non incumbent frame selected. The frame scoring logic is further to compute a feature vector for each frame in the set. The frame scoring logic is further to compute a non incumbent coverage score based on the feature vectors for each frame in the set with respect to the other frames in the set The frame scoring logic is further to compute a coverage vector by joining the non incumbent coverage scores with the stored coverage scores. The frame scoring logic is further to compute a 2D diversity matrix based on the feature vectors the matrix including a diversity score for each frame in the in the set with respect to the other frames in the set and with respect to each incumbent frame. The frame selection logic is further to solve an objective function including the coverage vector and the diversity matrix for an optimization vector having the maximum diversity score and maximum coverage score and select the non incumbent frames and incumbent frames identified by the optimization vector.

In furtherance of the second embodiment the logic circuitry to update the stream summary is to add to the stream summary each non incumbent frame selected add to the stream summary a coverage score associated with each non incumbent frame selected drop from the stream summary one non selected incumbent frame for each non incumbent frame selected and drop from the stream summary a coverage score associated with each non selected incumbent frame removed from the stream summary.

In furtherance of the embodiment immediately above the stream summary is associated with a predetermined number of stream summary frame slots. Each incumbent frame occupies one of the summary frame slots. The logic circuitry to update the stream summary is to swap the contents of a summary frame slot associated with an incumbent frame flushed in preference for non incumbent frame. The system further includes a circular buffer to overwrite video data frames summarized by the stream summary with more recently exposed video data frame data

In furtherance of the embodiment immediately above the system further includes a secondary memory to store each frame and associated coverage value removed from a stream summary slot. The frame selection logic is to perform a secondary selection of frames from a pool of frames including those associated with the summary frame slots and those stored to the secondary memory based on a solution to the objective function that optimizes the frame scoring for the selected frames.

In one or more third embodiment a computer readable storage media has instructions stored thereon which when executed by a processor cause the processor to perform the method recited in any of the first embodiments.

In furtherance of the third embodiment a computer readable storage media has instructions stored thereon which when executed by a processor causes the processor to perform a method including iteratively evaluating a stream summary comprising one or more of video data frames from a stream of consecutively exposed video data frames based on each new set of frames received. The evaluating further includes scoring each non incumbent frame in a new set of frames received from the CM with respect to the other frames in the new set and with respect to each incumbent frame included in the stream summary from a prior iteration. The media further causes the processor to perform a method including selecting frames from a pool including the non incumbent and the incumbent frames based on a solution to an objective function that optimizes the frame scoring for the selection. The instructions further cause the processor to perform a method including updating the stream summary stored in a memory in response to selecting a non incumbent frame in preference over an incumbent frame.

In furtherance of the embodiment immediately above the media further includes instructions stored thereon which when executed by the processor further cause the processor to perform the method further including updating the stream summary by adding to the stream summary each non incumbent frame selected adding to the stream summary a coverage score associated with each non incumbent frame selected scoring each non incumbent frame by computing a feature vector for each frame in the set and computing a non incumbent coverage score based on the feature vectors for each frame in the set with respect to the other frames in the set. The method further includes computing a 2D diversity matrix based on the feature vectors the matrix including a diversity score for each frame in the in the set with respect to the other frames in the set and with respect to each incumbent frame. The method further includes selecting one or more frame by computing a coverage vector by joining the non incumbent coverage scores with the stored coverage scores solving an objective function including the coverage vector and the diversity matrix for an optimization vector having the maximum diversity score and maximum coverage score and selecting the non incumbent frames and incumbent frames identified by the optimization vector.

In furtherance of embodiment above the feature vector is based on histograms of oriented gradient HOG . The method further includes computing the non incumbent coverage score comprises determining a coverage vector including a maximum value of a similarity metric for each frame in the new set and computing the diversity score comprises determining a 2D diversity matrix comprising the distance between color histograms for pairings of all frames in the pool.

In furtherance of the third embodiment the media further includes instructions which when executed cause the system to perform the method further including storing to a secondary memory each frame and associated coverage value removed from a stream summary slot performing a secondary selection of frames from a pool of frames including those associated with the summary frame slots and those stored to the secondary memory based on a solution to the objective function that optimizes the frame scoring for a predetermined number of slots of a secondary stream summary and storing the frames from the secondary selection to the memory.

In one or more fourth embodiment a video data stream capture and summarization system includes a video recording means to generate a stream of consecutively exposed video data frames. The system includes a video summarization means coupled to the video recording means to iteratively evaluate a stream summary comprising one or more of the frames based on each new set of received from the video recording means by performing any one of the methods in the first embodiment.

In furtherance of the fourth embodiment the video summarization means further includes a frame scoring means to score each non incumbent frame in a new set of frames received from the video recording means with respect to the other frames in the new set and with respect to each incumbent frame included in the stream summary from a prior iteration. The summarization means further includes a frame selection means to select frames from a pool including the non incumbent and the incumbent frames based on a solution to an objective function that optimizes the frame scoring for the selection. The video summarization means further includes a summary updating means to update the stream summary stored in a memory in response to selecting a non incumbent frame in preference over an incumbent frame.

In furtherance of the embodiment immediately above the summary updating means is to add to the stream summary each non incumbent frame selected and add to the stream summary a coverage score associated with each non incumbent frame selected. The frame scoring means is further to compute a feature vector for each frame in the set compute a non incumbent coverage score based on the feature vectors for each frame in the set with respect to the other frames in the set compute a coverage vector by joining the non incumbent coverage scores with the stored coverage scores and compute a 2D diversity matrix based on the feature vectors the matrix including a diversity score for each frame in the in the set with respect to the other frames in the set and with respect to each incumbent frame. The frame selection means is further to solve an objective function including the coverage vector and the diversity matrix for an optimization vector having the maximum diversity score and maximum coverage score and select the non incumbent frames and incumbent frames identified by the optimization vector.

In furtherance of the embodiment immediately above the system further includes a secondary memory to store each frame and associated coverage value removed from a stream summary slot and the frame selection means is to perform a secondary selection of frames from a pool of frames including those associated with the summary frame slots and those stored to the secondary memory based on a solution to the objective function that optimizes the frame scoring for the selected frames.

It will be recognized that the embodiments are not limited to the exemplary embodiments so described but can be practiced with modification and alteration without departing from the scope of the appended claims. For example the above embodiments may include specific combination of features. However the above embodiments are not limited in this regard and in embodiments the above embodiments may include undertaking only a subset of such features undertaking a different order of such features undertaking a different combination of such features and or undertaking additional features than those features explicitly listed. Scope should therefore be determined with reference to the appended claims along with the full scope of equivalents to which such claims are entitled.

