---

title: Systems, pipeline stages, and computer readable media for advanced asynchronous pipeline circuits
abstract: Systems, pipeline stages, and computer readable media for advanced asynchronous pipeline circuits are disclosed. According to one aspect, the subject matter described herein includes a configurable system for constructing asynchronous application specific integrated data pipeline circuits. The system includes multiple modular circuit stages that are connectable with each other using transitional signaling and with other circuit elements to form multi-stage asynchronous application-specific integrated data pipeline circuits for asynchronously passing data through a series of stages based on a behavior implemented by each stage. The modular circuit stages each include sets of logic gates connected to each other for implementing the behaviors, the behaviors including at least one of conditional split, conditional select, conditional join, merge without arbitration, and stage arbitration.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08872544&OS=08872544&RS=08872544
owner: The University of North Carolina at Chapel Hill
number: 08872544
owner_city: Chapel Hill
owner_country: US
publication_date: 20140310
---
This application is a divisional of U.S. patent application Ser. No. 13 001 034 filed Apr. 5 2011 which is a national stage application under 35 U.S.C. 371 of PCT Patent Application No. PCT US2009 049109 filed Jun. 29 2009 which claims the benefit of U.S. Provisional Patent Application Ser. No. 61 076 355 filed Jun. 27 2008 the disclosure of each of which is incorporated herein by reference in its entirety.

This invention was made with government support under Contract No. KT3408 awarded by the Defense Advanced Research Projects Agency DARPA . The government has certain rights in the invention.

The subject matter described herein relates to methods and systems for implementing pipelined processing. More particularly the subject matter described herein relates to systems pipelines stages and computer readable media for advanced asynchronous pipeline circuits.

As synchronous designs are increasingly facing challenges due to fundamental limitations of clocking the VLSI design community has recently turned towards asynchronous logic to mitigate the challenges of global clock distribution in large complex high speed systems. Asynchronous design offers several potential benefits such as lower power consumption higher performance greater robustness and significantly better modularity all of which make asynchronous circuits a promising alternative to synchronous design.

When the problems that arise when using a global synchronous clock became apparent the VLSI community started looking towards solving problems in asynchronous domain due to its inherent advantages. The main difference in the synchronous and asynchronous ideologies is the way timing between various modules is maintained. In a synchronous pipeline for example clocking gives a timing reference which dictates the completion of different stages. In asynchronous pipelines however timing is inferred by communication between the adjacent stages in the pipeline. This is referred to as handshaking. Handshaking protocols define the control behavior of asynchronous pipeline.

There are many areas where asynchronous circuits demonstrate clear advantages over their synchronous counterparts. Lower emissions of electromagnetic noise no clock distribution saving area and power no clock skew robustness to environmental variations e.g. temperature and power supply or transistor variations better modularity and better security are just some of the properties for which most asynchronous designs have shown advantages over synchronous ones.

There are many different flavors of asynchronous design. However the most commonly used approaches differ mainly in the following design choices.

The most popular form in recent years has been dual rail encoding with level sensitive signaling. Full delay insensitivity is still achieved but there must be a return to zero phase in each transaction and therefore more power is dissipated than with transition signaling. The advantage of this approach over transition signaling is that the logic processing elements can be much simpler familiar logic gates process levels whereas the circuits required to process transitions require state and are generally more complex.

The protocol sequence is also shown as the timing diagram at the bottom of . At time T1 sender places valid data on databus . At time T2 after some delay sufficient to allow the signals on databus to stabilize sender causes a transition to occur on REQ . Receiver may use the transition of REQ to internally capture e.g. latch the values on databus . At time T3 after some delay sufficient to allow receiver to guarantee that the data on databus has been properly latched receiver may cause a transition to occur on ACK to indicate to sender that the data has been successfully received by receiver after which time sender may release the data meaning that sender need not maintain the valid data on databus . In some cases sender may stop driving databus sometimes referred to as tri stating the bus.

There have been a number of implementations of asynchronous pipelines each approach having particular drawbacks. For example Sutherland Sun 89 describes 2 phase micro pipelines that are elegant but expensive and slow. Molnar Sutherland et al. 9701 describes a pipeline that is fast but requires fine grain transistor sizing to achieve delay equalization and then needs extensive post layout simulation to verify complex timing constraints. Schuster et al. ISSCC 00 describes a asynchronous pipeline that has very complex timing requirements and circuit structures. Williams 86 and Martin 97 describe dynamic pipelines that have no explicit latches and low latency but have poor cycle time i.e. throughput limited .

However behavior that is more sophisticated than a simple fork or simple join is desired. Accordingly in light of these disadvantages associated with conventional implementations of asynchronous pipelines there exists a need for improved systems pipeline stages and computer readable media for advanced asynchronous pipeline circuits using transitional signaling.

According to one aspect the subject matter described herein includes a configurable system for constructing asynchronous application specific integrated data pipeline circuits using transitional signaling. The system includes multiple modular circuit stages that are connectable with each other and with other circuit elements to form multi stage asynchronous application specific integrated data pipeline circuits for asynchronously passing data through a series of stages based on a behavior implemented by each stage. The modular circuit stages each include sets of logic gates connected to each other for implementing the behaviors the behaviors including at least one of conditional split conditional select conditional join merge without arbitration and stage arbitration.

According to another aspect the subject matter described herein includes an asynchronous application specific integrated data pipeline circuit including a plurality of modular circuit stages that are connected with each other using transitional signaling and with other circuit elements to form multi stage asynchronous application specific integrated data pipeline circuits for asynchronously passing data through a series of stages based on a behavior implemented by each stage the modular circuit stages each including sets of logic gates connected to each other for implementing the behaviors the behaviors including at least one of conditional split conditional select conditional join merge without arbitration and stage arbitration.

According to another aspect the subject matter described herein includes an asynchronous pipeline stage for implementing a conditional split. The stage includes a data latch for receiving data from a first data input and sending the received data to at least one of a plurality of data outputs and a data latch controller for controlling the data latch where the data latch controller receives a first data request using transitional signaling and a selection request selects one data request output from a plurality of data request outputs based on the value of the selection request and sends the data request to the selected data request output. Controlling the latch includes changing the latch to a closed mode in response to receipt of the first data request and the selection request and changing the latch to a transparent mode in response to receipt of a data acknowledge associated with the selected data request output.

According to another aspect the subject matter described herein includes an asynchronous pipeline stage for implementing a conditional select. The stage includes a data latch for receiving data from at least one of a plurality of data inputs and for sending the received data to a data output and a data latch controller for controlling the data latch where the data latch controller receives a selection request selects one data request input from a plurality of data request inputs based on the value of the selection request receives a data request using transitional signaling from the selected data request input and sends the data request to a data request output. Controlling the latch includes changing the latch to a closed mode in response to receipt of the data request from the selected data request input and the selection request and changing the latch to a transparent mode in response to receipt of a data acknowledge associated with the selected data request output.

According to another aspect the subject matter described herein includes an asynchronous pipeline stage for implementing a conditional join. The stage includes a data latch for receiving data at each of a plurality of data inputs and for sending data from a selected one of the plurality of data inputs to a data output and a data latch controller for controlling the data latch where the data latch controller receives a selection request selects one data request input from a plurality of data request inputs based on the value of the selection request receives a data request using transitional signaling from the selected data request input and sends the data request to a data request output. Controlling the latch includes changing the latch to a closed mode in response to receipt of the data request from the selected data request input and the selection request and changing the latch to a transparent mode in response to receipt of a data acknowledge associated with the selected data request output.

According to another aspect the subject matter described herein includes an asynchronous pipeline stage for implementing a merge without arbitration. The stage includes a data latch for receiving data at each of a plurality of data inputs and for sending the received data to a data output and a data latch controller for controlling the data latch where the data latch controller receives data requests from a plurality of data request inputs respectively associated with the plurality of data inputs and sends each received data request to a first data request output without arbitrating between the plurality of data request inputs. Controlling the latch includes changing the latch to a closed mode in response to receipt of the selection request and any of the data requests from the plurality of data request inputs and changing the latch to a transparent mode in response to receipt of a data acknowledge associated with the first data request output.

According to another aspect the subject matter described herein includes an asynchronous pipeline stage for implementing a stage arbitration. The stage includes a data latch for receiving data at each of a plurality of data inputs each data input being associated with a respective data output and a data latch controller for controlling the data latch where the data latch controller receives a selection input and data requests from a plurality of data request inputs selects one of the plurality of data request inputs based on a value of the selection input and sends the data present at the selected data request input to a data request output associated with the selected data request input. Controlling the latch includes sending the data value that is present at the selected data input to the data output associated with the selected data input.

The subject matter described herein for asynchronous application specific integrated data pipeline circuits may be implemented in hardware software firmware or any combination thereof. As such the terms function or module as used herein refer to hardware software and or firmware for implementing the feature being described. In one exemplary implementation the subject matter described herein may be implemented using a computer readable medium having stored thereon computer executable instructions that when executed by the processor of a computer perform steps. Exemplary computer readable media suitable for implementing the subject matter described herein include disk memory devices chip memory devices programmable logic devices and application specific integrated circuits. In addition a computer readable medium that implements the subject matter described herein may be located on a single device or computing platform or may be distributed across multiple devices or computing platforms.

In accordance with the subject matter disclosed herein systems pipeline stages and computer readable media are provided for advanced asynchronous pipeline circuits including basic circuit level building blocks for implementing a set of behaviors including conditional split conditional select conditional join merge without arbitration and stage arbitration.

As used herein the term conditional split refers to a behavior in which data present at one input is sent to only one of multiple outputs selected according to a select value present at another input. For example a conditional split pipeline stage also referred to herein as a conditional split stage may receive data from a previous pipeline stage and send the received data to one or the other but not both of two next pipeline stages based on the value of a select input. The select value may be provided by the previous stage the next stage or some other logic. In one embodiment the select value and the data value could be bundled together onto the same channel i.e. the data itself includes the routing information . In other embodiments the select value could be a value provided by the system without any handshaking e.g. a global or external input or a local value that changes infrequently . A conditional split differs from a simple split in that a conditional split sends the input to only one of the many outputs while a simple split sends the input to all of the many outputs. An embodiment of a conditional split stage will be described in more detail in below.

As used herein the term conditional select refers a behavior in which data present at one of many inputs may be sent to a single output where the one input is selected from the many inputs based on a select value. In one embodiment the select value is the value present at a dedicated select input. For example a conditional select pipeline stage also referred to herein as a conditional select stage may have two data input channels a third input channel that provides the select value and one output channel. The value present on the select input will determine which of the two input channels data will be read and sent to the output channel. A conditional select differs from a simple join in that a conditional select chooses one of many inputs and sends the selected input s data to the output while a simple join merges the two inputs. Furthermore a simple join performs the merge operation only when it has received requests from all of the multiple previous stages while a conditional select only waits for a request from previous stage associated with the selected input. An embodiment of a conditional select stage will be described in more detail in below.

As used herein the term conditional join refers to a behavior in which data present at all of many inputs is read but data from only one of the inputs is sent to an output based on a select value. A conditional join stage is similar to a conditional select stage except that all input channels are read even though data from only one of them is forwarded. Data from the remaining input channels is discarded. An embodiment of a conditional join stage will be described in more detail in below.

As used herein the term merge without arbitration refers to a behavior in which data from multiple inputs is merged and sent to a single output without performing any arbitration between the multiple inputs. For example a merge without arbitration pipeline stage also referred to herein as a merge stage may have two input channels and one output channel. Data is read from whichever input channel has new data and then sent to the output. No arbitration is provided it is assumed that the input channels are mutually exclusive. A merge without arbitration differs from a simple join in that a simple join performs the merge operation only when it has received requests from all of the multiple previous stages while a merge without arbitration sends to its output data from whichever input it has last received a request. An embodiment of a merge stage will be described in more detail in below.

As used herein the term stage arbitration refers to a behavior in which data present on one of many input channels the input channel being selected based on a select value is sent to the input channel s corresponding output channel. For example a stage arbitration pipeline stage also referred to herein as an arbitration stage may have two input channels two output channels and a select input. Only one input channel is read at any time and its value is sent to its corresponding output channel. This circuit can be combined with the merge without arbitration behavior above to produce a merge with arbitration. A stage arbitration differs from a both a simple split and a simple join in that a stage arbitration maintains a one to one association between in input and its corresponding output while a simple split implements a one to many association and a simple join implements a many to one association. An embodiment of an arbitration stage will be described in more detail in below.

The simple split and join stages may be collectively referred to as basic MOUSETRAP stages or simply MOUSETRAP stages while the conditional split conditional select conditional join merge without arbitration and stage arbitration stages may be collectively referred to as advanced MOUSETRAP stages .

The conditional split and conditional select are designed to work together to implement an if then else construct without speculation i.e. data is only sent along the chosen path . In particular the conditional split first sends data along one of two paths based on a Boolean value thereby splitting one data stream into two. Subsequently based on that Boolean value the conditional select receives data from the correct path thereby recombining the two data streams into one. The conditional split and conditional select can also be used separately i.e. not necessarily as a pair .

The conditional join is designed to work with a simple fork stage to implement an if then else construct with speculation i.e. data is sent along both paths and the correct computed value is chosen later . In particular the fork stage replicates an incoming data stream into two outgoing data streams. Subsequently the conditional join reads the results from both the streams and passes along the correct value based on the Boolean condition and discards the other.

The merge stage which simply interleaves two mutually exclusive data streams into one is useful for implementing several useful functions e.g. i a routing network where conditional splits can route a data item into one of two or more directions and merge stages can combine or recombine multiple streams into one and ii pipelined for while loops where data cycling inside a ring must be merged with new data entering the ring. If mutual exclusion is not guaranteed at the system level an arbitration stage can be added before the merge stage.

The circuit level implementation and behavior for each of the advanced asynchronous pipeline circuits described above will now be described in more detail. In addition equations for forward latency the time between the arrival of a request and the generation of the request and reverse latency the time between the arrival of an incoming acknowledge and the generation of an outgoing acknowledge are provided. In some cases an equation for the hold time constraint is also provided when it is more restrictive than the constraint for basic MOUSETRAP stages.

In one embodiment each channel has one or more data lines and at least one request line. For example a data input channel will have one or more data inputs and at least one request input. A data output channel will have one or more data outputs and at least one request output.

In the embodiment illustrated in conditional split stage has a data input D a select input B a data request input REQD and select request input REQB . Since the embodiment illustrated in has only two outputs data output Q0 and Q1 select input B is a Boolean value Conditional split stage waits for both REQD and REQB to be ready and toggles only one of the outgoing request lines REQ0 or REQ1 depending on the value of select input B . The data input D is simply copied to both data outputs Q0 and Q1 each of which goes a separate next stage. Conditional split stage receives acknowledgements ACK0 and ACK1 from the next stages connected to Q0 and Q1 respectively.

Using the channel terminology describe above conditional split stage has one input channel consisting of data input D and data request input REQD another input channel consisting of select input B and select request input REQB . Conditional split stage has two data output channels a first data output channel consisting of data output Q0 and request output REQ0 and a second data output channel consisting of data output Q1 and request output REQ1 .

A C Element operates according to the following description if all of the C Elements inputs are the same value the output of the C Element becomes that value. Thus if all inputs are logic 1 the output becomes logic 1 and if all inputs are logic 0 the output becomes logic 0 . For any other combination of inputs the C Element does not change output value but instead maintains the last value that was output by the C Element. This behavior makes the C Element very useful for transition based logic. The C element may be modeled by an unclocked set reset flip flop where the set input signal is a logical AND of all inputs to the C element and the reset input signal is a logical AND of all inverted inputs to the C element.

Select input B is used to invert one of the incoming acknowledgement signals ACK0 or ACK1 to produce the appropriate requests on REQ0 and REQ1 . Negative edge triggered flip flops FF0 and FF1 are used to latch outgoing requests REQ0 and REQ1 respectively this prevents changes on the ACK0 and ACK1 lines from producing spurious requests. One or more latches LD in the data path i.e. between data input D and data outputs Q0 and Q1 can be controlled with enable signal EN . In one embodiment enable signal EN is high active i.e. when EN is 1 data latch is active closed and when EN is 0 data latch is inactive open . The latencies exhibited by this implementation are as follows Forward latency Reverse latency Conditional split stage may include a reset or initialization input init .

While the circuits illustrated in used typical timing assumptions further delay optimization is possible with more aggressive timing assumptions. In particular the circuit illustrated in shows a revised forward path to produce the signal REQ0 . A similar path is used for producing the other signal REQ1 . The embodiment of conditional split stage illustrated in is based on a timing assumption that the latch must be disabled before a spurious request can race through. Using this implementation the forward latency is as follows Forward latency 

Another basic logic implementation was generated using a logic synthesis tool such as Petrify . By modeling the behavior of the circuit and synthesizing using Petrify a circuit with a more optimized forward path was generated. Boolean equations are provided below gate level circuit implementations can be produced directly from these equations. The equations for signals REQ0 and REQ1 are as follows where the signal REQ is assumed to represent the combination of the incoming data request input REQD and select request input REQB combined using C element 

A generalized implementation was also created using Petrify . The generalized C element implementation for the forward path is as follows 

In one embodiment relative timing optimizations can be applied to the circuit based on designer knowledge of the relative arrival times of signals. In one embodiment select input B may be a global constant that is assumed to be stable and will therefore not have any associated request. In this case the circuit becomes simpler as C element becomes unnecessary and may be removed. In other cases select input B may be part of input data D i.e. the data item carries routing information in such cases too there is only one request and C element may be removed. In one embodiment C element may be removed to improve cycle time. For example a MOUSETRAP simple join stage may explicitly join select input B and data input D and the joined values are sent as one joined request to conditional split stage .

For clarity of description the data path will henceforth be omitted from Figures and the description will focus primarily on the stage handshaking signals e.g. request signals and acknowledge signals.

In the embodiment illustrated in conditional select stage has a first input request REQ0 and its associated acknowledge ACK0 a second input request REQ1 and its associated acknowledge ACK1 a select input B its select request input REQB and its associated acknowledge ACKB . Conditional select stage has an output request REQ2 and its associated acknowledge ACK2 . In one embodiment conditional select stage may have an initialization or reset input INIT which may initialize latches such as L0 which latches REQ0 and L1 which latches REQ1 .

After initialization latches L0 and L1 are opaque. The value of B selects which of the two latches L0 and L1 will be made transparent. When the request associated with the select latch arrives i.e. REQ0 if L0 is selected and REQ1 if L1 is selected the request is sent to the next stage via REQ2 and latches L0 and L1 once again become opaque.

In the embodiment illustrated in request latches L0 and L1 are held opaque by NOR gates until the select input B arrives and become transparent only when all of the following are true select input B has arrived the value of B selects a given data path and the next stage is ready . The gate that most closely corresponds to the controller XNOR in a simple MOUSETRAP stage is the XOR . The following equations describe the latencies for the embodiment illustrated in 

In one embodiment the data path can be constructed using multiplexors with select input B as the select line. When the selected data input request and the select input requests are present a latch enable signal may close the latch to store the current value. For example in the embodiment illustrated in latches L0 and L1 can be controlled with the NEXTREADY signal.

Alternative embodiments may include various options and optimizations. For example the logic to open and close latches L0 and L1 shown in using XOR XNOR and NOR may be alternatively implemented using a two level sum of products form to reduce delays. In one embodiment select input B may be a global constant that is assumed to be stable and will therefore not have any associated request in which case XNOR is unnecessary and may be removed. In this case since the output of XNOR is no longer present three input XNOR and XNOR may be replaced with two input XNORs.

In the embodiment illustrated in conditional join stage has the following channels a select input B and its associated select input request REQB two data input channels including data input D0 and its request REQ0 and data input D1 and its respective data input request and REQ1 and one data output channel data output Q its associated output request REQ2 and its associated acknowledgement ACK2 . REQ2 also operates as the acknowledgements to the input channels i.e. ACKB ACK0 and ACK1 . In one embodiment conditional join stage may have an initialization or reset input INIT which may initialize latches such as latch which stores the combination of request inputs latch which stores the value of select input B latch which stores the value of data input D0 and latch which stores the value of data input D1 .

In one embodiment conditional join stage waits for select input B and all data inputs D0 and D1 to be ready i.e. it receives a transition on REQB REQ0 and REQ1 . Conditional join stage acknowledges all inputs once the data is latched. Multiplexer multiplexes the latched data based on the latched value of select input B .

In one embodiment C elements and combine all incoming requests REQB REQ0 and REQ1 into one request. The following equations describe the latencies for the embodiment illustrated in Forward latency Reverse latency 

In one embodiment the selection of data values can also take place before the latches. This reduces the total number of latches but also creates the timing assumption that the data will arrive in time to be selected before the latches become opaque.

In the embodiment illustrated in merge stage has two input channels and one output channel. For simplicity the datapath portion of merge stage is omitted. Thus the embodiment illustrated in includes data input requests REQ0 and REQ1 data input acknowledgements ACK0 and ACK1 data output request REQ2 and data output acknowledgment ACK2 . In one embodiment merge stage may have an initialization or reset input INIT which initializes latches such as latch which stores the combination of request inputs latch which stores the value of select input B latch which stores the value of data input D0 and latch which stores the value of data input D1 .

In one embodiment an incoming request on either REQ0 or REQ1 will trigger a toggle on outgoing request line REQ2 . This assumes that the two requests will not come simultaneously. In the embodiment illustrated in XOR is used to combine the two incoming requests REQ0 and REQ1 such that a toggle on exactly one incoming request line will lead to a toggle on the output request. The latch control XNOR which generates latch enable signal EN works similarly to a simple MOUSETRAP stage. The following equations describe the latencies for the embodiment illustrated in Forward latency Reverse latency 

In one embodiment the datapath used with merge stage depends on the previous stages used in the system. For example an arbitration stage just before the merge stage may perform the merging of the datapath in which case latch enable signal EN may be used to latch the data in the datapath. In this case the data can simply be latched with latch enable signal EN . If the datapath has not already been merged however the two incoming datapaths may be multiplexed to give one output data value.

In the embodiment illustrated in arbitration stage has two channels. Channel 0 includes request input REQIN0 request output REQOUT0 acknowledge input ACKIN0 and acknowledge output ACKOUT0 . Request input REQIN0 passes through two latches L0 and L1 to become both REQOUT0 and also ACKOUT0 . Latches L0 and L1 have complimentary latch enable signals LE0 and LE0B such that when one latch is open the other latch is closed and vice versa.

Likewise channel 1 includes request input REQIN1 request output REQOUT1 acknowledge input ACKIN1 and acknowledge output ACKOUT1 . Channel 1 includes two latches latch L2 latch L3 which have complimentary latch enable signals LE1 and LE1B . The operation of channel 1 is essentially identical to the operation of channel 0 except for the source of the latch enable signals and the description of the operation of channel 1 will not be included here.

In the embodiment illustrated in arbitration stage operates as a 2 phase wrapper around a mutually exclusive mutex element . Arbitration stage allows the earlier request that arrives on either channel to pass through and ignores subsequent requests until the current handshake cycle is complete. In the embodiment illustrated in based on whichever of REQIN0 or REQIN1 is received first arbitration stage sends a request out on one of the two outgoing request lines REQOUT0 or REQOUT1 .

In one embodiment operation begins with the first set of latches i.e. latches and in transparent mode and the second set of latches i.e. latches and in opaque mode. When a request arrives for a particular channel the first latch of that channel becomes opaque the second latch in the same channel becomes transparent and mutex element will become unresponsive to new incoming requests. The acknowledge returning from the next stage connected to that channel e.g. ACKIN0 or ACKIN1 re enables mutex element so that incoming requests can once again be processed. The following equations describe the latencies for the embodiment illustrated in Forward latency Reverse latency 

Depending on the next stages used in the embodiment arbitration stage may either maintain two separate data paths and requests or it may merge the data paths. If two separate data paths are required then the data latches on paths 0 and 1 will use the latch enable signals LE0 and LE1 respectively. If the paths should be merged only a single latch enable signal may be required.

It will be understood that various details of the subject matter described herein may be changed without departing from the scope of the subject matter described herein. Furthermore the foregoing description is for the purpose of illustration only and not for the purpose of limitation.

