---

title: Congestion sensitive path-balancing
abstract: Encapsulated packets may be generated for different packets transmitted between a source instance and destination instance in a computer system. The source instance and destination instance may be implemented by different physical hosts linked by multiple network paths. Congestion of the multiple network paths may be determined and path-balancing polices may be implemented in response to the determined congestion. Each encapsulation packet comprises contents of a corresponding packet, and one or more data values selected in accordance with a path-balancing policy. The data values added to one encapsulation packet may differ from those added to another. Different network paths to the destination may be selected for different encapsulation packets of a given transmission based at least in part on the added data values.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09509616&OS=09509616&RS=09509616
owner: Amazon Technologies, Inc.
number: 09509616
owner_city: Seattle
owner_country: US
publication_date: 20141124
---
This application incorporates by reference for all purposes the full disclosure of co pending U.S. patent application Ser. No. 14 552 248 filed concurrently herewith entitled SELECTIVE ENABLING OF SEQUENCING FOR ENCAPSULATED NETWORK TRAFFIC .

Many companies and other organizations operate computer networks that interconnect numerous computing systems to support their operations such as with the computing systems being co located e.g. as part of a local network or instead located in multiple distinct geographical locations e.g. connected via one or more private or public intermediate networks . For example data centers housing significant numbers of interconnected computing systems have become commonplace there are private data centers that are operated by and on behalf of a single organization and public data centers that are operated by entities as businesses to provide computing resources to customers. Some public data center operators provide network access power and secure installation facilities for hardware owned by various customers while other public data center operators provide full service facilities that also include hardware resources made available for use by their customers. As the scale and scope of typical data centers has increased the tasks of provisioning administering and managing the physical computing resources have become increasingly complicated.

The advent of virtualization technologies has provided benefits with respect to managing large scale computing resources for many customers with diverse needs allowing various computing resources to be efficiently and securely shared by multiple customers. For example virtualization technologies may allow a single physical computing machine to be shared among multiple users by providing each user with one or more computer instances hosted by the single physical computing machine with each such virtual machine being a software simulation acting as a distinct logical computing system that provides users with an experience as if they were the sole operators and administrators of a given hardware computing resource while also providing application isolation and security among the various virtual machines. Furthermore some virtualization technologies are capable of providing virtual resources that span two or more physical resources such as a single virtual machine with multiple virtual processors that spans multiple distinct physical computing systems.

Operators of networks that enable clients to use hundreds or thousands of virtualized resources within a given data center or spread over multiple data centers often set up interconnect topologies that offer multiple parallel physical network paths between a given pair of virtualized resources. However many conventional approaches to networking may end up underutilizing the bandwidth available for any given high volume data transfer e.g. by using only a small subset of the parallel paths available. As a result of the lack of balance in the network traffic application performance may suffer in at least some cases and the return on the operator s investment in the high bandwidth interconnect infrastructure may be less than satisfactory.

In the following description various embodiments will be described. For purposes of explanation specific configurations and details are set forth in order to provide a thorough understanding of the embodiments. However it will also be apparent to one skilled in the art that the embodiments may be practiced without the specific details. Furthermore well known features may be omitted or simplified in order not to obscure the embodiment being described.

Techniques described and suggested relate to congestion sensitive mechanisms for enabling path balancing of network traffic between two endpoints of a service provider network. Path balancing network traffic may cause the network traffic to be routed in such a way that the routing components of the service provider network distributes the network traffic of a particular transmission described in greater detail below among several different physical paths. For example path balancing may cause two packets of the same transmission to be routed along different paths of the service provider network. The network traffic may be part of a transmission between a destination computer instance and a source computer instance described in greater detail below. The network traffic may travel across the service provider network which is configured to balance traffic across various components of the service provider network based at least in part on network congestion measured at the various components. Various methods and computing devices may be used to balance traffic on the service provider network such as encapsulating packet traveling across the network such that two or more packets of a transmission follow different network paths. The encapsulation techniques described may help increase for a given transmission between two endpoints within the service provider network the utilization levels of multiple physical network paths available and thereby help to improve the overall performance of computer systems being implemented using the service provider network s resources. The service provider network may be a network set up by an entity such as a company or other organization to provide one or more network accessible services accessible via the Internet and or other networks to a distributed set of users as described herein.

Various techniques may be used to measure congestion of the service provider network at various locations and or devices within the service provider network. In various embodiments the routing components of the service provider network are configured to mark any packet above a threshold in the routing component s queue. Marking the packet may include setting a particular flag or bit field in the header or other portion of the packet. The flag may be received by the destination physical host or virtualization layer of the physical host and a return packet may be marked with a similar flag e.g. the same bit field in the header and provided to the source physical host. Upon receipt of the return packet with the flag the virtualization layer of the physical host may enable path balancing for the transmission associated with the received return packet. Other methods for measuring congestion may be used in connection with the present disclosure. For example the service provider may operate a congestion service configured to monitor congestion across the various components of the service provider network and determine whether to enable path balancing for a given transmission. The congestion service may obtain congestion and or load information from the various components of the service provider network. For example the congestion service may obtain information from routing components indicating average and or current length of the queue of packets waiting for transmission.

In various embodiments network load generated by a computer instance may be measured and used to determine whether to enable path balancing for a particular transmission. For example if a computer instance is transmitting data at 10 Gbits per second the service provider or component thereof such as a virtual machine management service may enable path balancing for transmissions including the computer instance. In another example if the aggregate bitrate for a set of computer instances operated by a user is above a threshold then path balancing may be enabled for the set of computer instances. In various embodiments if the service provider or component thereof determines to enable path balancing for a computer instance and or transmission the service provider or component thereof may than determine whether to enable sequencing for the computer instance and or transmission. For example if network congestion as indicated by a routing component is above a threshold value the source virtualization layer may enable path balancing. The destination virtualization layer may then determine to enable sequencing for the transmission based at least in part on a selection provided by the user.

As the data packets travel across the service provider network the data packets may be received at the routing component . The routing component may include switches e.g. intelligent switches equipped with routing functionality routers and or various other types of networking devices described in greater detail below. Furthermore the routing component may be configured to provide congestion information to various other computing devices connected to the service provider network . For example the routing component may be configured to provide explicit congestion notification ECN to the destination virtualization layer. ECN may enable end to end notification of network congestion without requiring the destination virtualization layer to drop packets. ECN may be used between two ECN enabled endpoints e.g. virtualization layers of the physical host when the underlying network infrastructure e.g. routing components also supports ECN. The routing component may set a mark in the Internet Protocol IP header instead of dropping a packet in order to signal impending congestion. In various embodiments the receiver of the packet echoes the congestion indication to the source physical host or component thereof such as the virtualization layer. In various embodiments the receipt of mark IP header may cause the source virtualization layer to enable path balancing.

As illustrated in the routing component may include a path balancing threshold configured to enable path balancing for at least a portion of the traffic and or transmission received by the routing component . For example the path balancing threshold may be configured such that any packet above the path balancing threshold in the queue of the routing component is marked using the above mentioned ECN. In yet another example the routing component may be configured to transmit a notification in response to a number of packets in the routing component s queue being above the path balancing threshold . The routing component may transmit the notification directly to the source virtualization layer and or physical host or to a congestion service operated by the service provider. The notification may indicate congestion at the routing component . Furthermore the path balancing threshold may be configured as a percentage of the total size of the queue and or a level of congestion at which the routing component may drop additional received packets.

In various embodiments the routing component may determine congestion based at least in part on load generated by the computer instance and or physical host . For example the routing component may determine an average bitrate over an interval of time for the computer instance and or the physical host . If the average bitrate is over the path balancing threshold the routing component may enable path balancing for the computer instance or other transmission received from the physical host . The routing component may enable path balancing by transmitting a notification to the source virtualization layer indicating network congestion. Similarly the physical host may also measure congestion based at least in part on load generated by the computer instance such as the average bitrate described above. If the physical host determines there is network congestion the physical host may then enable path balancing by transmitting a notification to the source virtualization layer indicating network congestion. The virtualization layer may then encapsulate traffic transmitted from the source the encapsulation causing two or more packets of the transmission to travel different paths in the service provider network described in greater detail below.

A virtualization layer executing on the physical host enables the system hardware to be used to provide computational resources upon which one or more computer instances may operate. For example the virtualization layer may enable a virtual machine to access system hardware on the physical host through virtual device drivers on the virtual machine . The virtualization layer may include a hypervisor or virtualization software and or hardware. The virtualization layer may also include an instance of an operating system dedicated to administering the computer instances running on the physical host . Each virtualization layer may include its own networking software stack responsible for communication with other virtualization layers and at least in some embodiments also responsible for implementing network connectivity between the computer instances running on the physical host and other computer instances running on other physical hosts . Furthermore the physical host may host multiple virtualization layers of the same or different types on the same physical host . The virtualization layer may be any device software or firmware used for providing a virtual computing platform for the computer instances . The virtual computing platform may include various virtual computer components such as one or more virtual CPUs virtual memory and the like. The computer instances may be provided to the users of the service provider and the users may run an operating system or an application on the computer instances . Further the service provider may use one or more of its own computer instances for executing its applications. At least a portion of the computer instances may execute kernel level components for one or more other computer instances . For example a particular computer instance may execute a parent partition configured to manage one or more child partitions executed by other computer instance where the particular computer instance and the other computer instances are supported by the same virtualization layer.

The control planes may be a computer instance supported by the virtualization layer . Although one control plane is shown in multiple control planes may be supported by a virtualization layer in accordance with the present disclosure. The control planes may execute various operations using virtual computer components provided by the virtualization layer . The control planes may receive commands and other information from the virtual machine management service . The commands and other information may be included in an application programming interface API call from the virtual machine management service to the control plane . The virtual machine management service may enable the users to manage and operate the computer instances .

For example the user may transmit a request to the virtual machine management service to terminate all computer instances operated by the user . The request may be an API call including information corresponding to the user and computer instances . The virtual machine management service may determine the corresponding control planes for the computer instances included in the request and transmit a terminate command to the control plane . The virtual machine management service may be implemented in at least some embodiments enabling a variety of client applications to run at virtual computer servers or computer instances instantiated on behalf of the users . The computer instances may each comprise a virtual machine with its own operating system comprising a networking software stack and multiple such instances may be hosted on a given physical host at a service provider network data center.

Many applications executed on behalf of users may involve transmissions of large amounts of data between source and destination application components running on respective computer instances often at different physical hosts . For example a content management application or an online video application may need to transfer gigabytes of data between a source computer instance running on a physical host and a destination computer instance running on a different physical host . A given physical host may be configurable to accommodate multiple computer instances several of which may be used for network intensive applications simultaneously. In order to be able to handle large amounts of network traffic between computer instances at different physical hosts in at least some embodiments dense multi path multi layer interconnect topologies such as fat trees VL2 Virtual Layer 2 topologies BCube topologies or other topologies based on Clos networks may be set up by provider network operators described in greater detail below in connection with . Such interconnect topologies may support for example multiple tens of gigabits per second of peak available bandwidth between at least some pairs of physical hosts .

However such dense topologies may not always result in optimal distribution of network traffic across the multiple paths available between sources and destinations and in practice underutilization of the available bandwidth may be observed. Some conventional routing techniques such as various forms of ECMP or equal cost multi path routing may rely for example on selecting the next hop for a given packet based on some set of header field values of the packet such as the 5 tuple value of source IP address destination IP address source port destination port protocol ID of the networking protocol in use . The values in the header fields may be used as input for a hash function for example and the output of the hash function may be used to select the next hop or link for the packet. For different TCP IP Transmission Control Protocol Internet Protocol connections schemes that rely on selecting hops based on functions of header field values may succeed in distributing traffic across multiple paths because some of the header field values would typically differ e.g. a different IP address or port may be used for connection 1 than for connection 2 . However for a given TCP IP connection the 5 tuple header field values may be identical for all packets and consequently a routing technique that uses hashing or some similar technique on such header field values may always select the same hop for different packets of the connection. Often some connections involve much greater amounts of data transfer than others that is data transfer amounts may not be uniformly distributed among different connections. As a result some links of the dense interconnected multi path network may end up being much more heavily utilized than others. Additionally encapsulation protocols may increase the utilization of certain links more than others in the interconnected multi path network.

In order to improve the overall utilization of dense multi path interconnected network an encapsulating mechanism may be implemented. Such a mechanism may involve the instantiation of an encapsulating intermediary e.g. at the virtualization layers of the sending and receiving physical hosts . The encapsulating intermediary may receive or intercept packets generated by the networking stacks at the computer instances at which the sending application component runs. Such received intercepted packets may be considered baseline packets. The encapsulating intermediary may add specially constructed header field values to the baseline packets to form corresponding encapsulation packets. An encapsulation packet may thus be considered an outer packet or a containing packet for the corresponding baseline packet and a baseline packet may be considered an inner or contained packet of the corresponding encapsulation packet. The added header field values may be determined in accordance with a path balancing policy e.g. in such a way that the routing components of the interconnected multi path network end up distributing different encapsulation packets of the same transmission among several different physical paths. For example in one embodiment the virtualization layer may add an IP header e.g. with the IP address for the correct destination physical host as well as one or more randomly selected User Datagram Protocol UDP header field values to a baseline TCP IP packet to form an encapsulation packet. The added UDP header field values may include for example a randomly selected source port number and or a randomly selected destination port number. When a routing component such as a node of the interconnected multi path network receives an encapsulation packet in at least some implementations the routing component may analyze the contents of the UDP and IP headers in order to select the next hop along which the encapsulation packet is to be used. The routing component may analyze the outermost headers of the encapsulation packet for example and may regard the contained baseline TCP packet as the body of the packet. As the UDP header field values were randomly selected different encapsulation packets for the same applications TCP IP connection may end up being directed along different paths thereby distributing the data traffic for a single connection among multiple paths. It is noted that techniques other than random selection may be used for selecting the values of the added header fields in at least some embodiments e.g. an algorithm that increments the UDP sender port value for every packet of a given transmission may be used in some embodiments or a technique that determines the UDP header packet based on other factors such as contents of the TCP baseline packets may be used. In another example the virtualization layer may determine a new UDP port in response to congestion and or load on the interconnected multi path network as opposed to determining a new UDP port for each packet. The distribution of the traffic among different physical paths may be accomplished using any of various techniques that generally assign different values to the added header fields for respective baseline packets in various embodiments.

At the receiving physical host e.g. at the physical host where the destination application component of the TCP IP connection executes within one of the computer instances an unpacking component of the virtualization layer may be responsible for stripping the added header field values from the encapsulation packet to extract the baseline TCP IP packet and for passing on the baseline packet to the networking stack of the destination computer instance . In several embodiments a single component of the virtualization layer may be responsible for the encapsulating and unpacking functionality e.g. such as an encapsulation de encapsulation intermediary described in greater detail below . A given virtualization layer may be responsible for adding header field values to outgoing packets and extracting baseline packets from incoming packets. An encapsulating intermediary may be a component of the virtualization layer or the physical host that performs both the encapsulation and unpacking functions depending on the direction of the traffic flow. For example the encapsulating intermediary may be a software component of the virtualization layer and may be provided to the virtualization layer by the virtual machine management service . The user may select various networking options e.g. packet sequencing for computer instances operated by the user the virtual machine management service may then provide the virtualization layer associated with the computer instances with information sufficient to enable the networking options selected by the user .

In at least some embodiments in addition to ensuring that multiple paths are used for different packets of a given transmission and that the packets are routed to the correct destination physical host the encapsulating intermediary may be configurable to perform additional functions. For example in at least one embodiment in which encapsulation involves using headers of a protocol such as UDP that does not guarantee in order delivery of packets the encapsulating intermediary may also generate a sequence number to be added to a baseline packet to form an encapsulation packet. At the receiving end when the encapsulation packets are unpacked the encapsulating intermediary may make a best effort attempt to use the sequence numbers to deliver the corresponding baseline packets in order to the receiving computer instance s networking stack. Thus in some embodiments from the application perspective a TCP IP connection that guarantees in order delivery may be set up between the source computer instance and the destination computer instance at respective physical hosts . The encapsulating and or de encapsulating mechanism may make it appear to the routing components of the interconnected multi path network as though a set of UDP packets e.g. with different UDP port numbers for different packets is being transmitted rather than a set of TCP packets. At the receiving physical host s visualization layer the encapsulating intermediary may in some embodiments store the encapsulation packets temporarily in a buffer to help with in order delivery described in greater detail below. The encapsulating intermediary may in some embodiments use the sequence numbers added by the sending encapsulation intermediary to attempt to deliver the baseline TCP IP packets to the destination computer instance in the correct sequence i.e. in the same sequence in which the TCP IP packets were sent by the source computer instance . In some embodiments depending on the size of the buffer and or on real time traffic conditions the encapsulating intermediary may not be able to deliver all the extracted baseline packets in order. In such a scenario the networking stack of the destination computer instance may request retransmissions of the missing packets using the standard procedures used for the networking protocol in use between the source and destination instance network stacks e.g. either by an explicit retransmission request or implicitly by not sending acknowledgements for the missing packets which would lead the sending networking stack to retransmit the undelivered packets . In some embodiments the sequence number added by the encapsulating intermediary may be determined based at least in part on a sequence number already incorporated within the baseline packet e.g. if the baseline packet is a TCP packet the TCP packet s sequence number originally set at the networking stack of the source computer instance may be used to derive the sequence number added by the encapsulating intermediary .

In some embodiments the operating systems in use at the source and destination computer instances may support large jumbo packet sizes or frame sizes. In such embodiments the encapsulation intermediary may be configured to break up into smaller pieces a given jumbo baseline packet generated by the source computer instances such that several different encapsulation packets are transmitted corresponding to a single jumbo baseline packet. Similarly at the receiving side the encapsulating intermediary may be configured in some such embodiments to combine the pieces of a given baseline jumbo packet before passing on the packet to the networking stack at the destination computer instance . The encapsulation intermediary may combine multiple different baseline packets generated by one or more source computer instances on the same physical host and destined for one or more computer instances on the same destination physical host into a single encapsulation packet such that several different baseline packets are transmitted in a single encapsulation packet. At the receiving side the encapsulating intermediary may be configured to unpack the multiple baseline packets and pass them to the respective networking stack s for the destination computer instance s .

In at least some embodiments path balancing using encapsulation may not be implemented for all the network transmissions from or to a given application component for all the network transmissions from or to a given computer instance or for all the packets transmitted between a given pair of hosts. Instead the encapsulation intermediary may determine based on any of several factors whether path balancing is to be used for a given set of packets e.g. for a given TCP IP connection or for packets belonging to several different TCP IP connections. Such factors may include for example an expected amount of data to be transferred the identity of the sending or receiving client e.g. path balancing may be applied to data transfers of some clients but not others based on the expected volumes of data transfers of the clients or based on contractual relationships established with the clients the one or more attributes of the application involved in the transfer an estimate of the number of alternative paths available between the source and destination load along one or more network paths network congestion as measured at one or more intermediary routing components of the network network congestion measured at a central computer system monitoring congestion on one or more intermediary routing components of the network or an estimate of the number of hops or links involved in the data transfer.

In some embodiments path balancing may be implemented at the user s request e.g. a user may submit a balancing request indicating that the maximum amount of parallelism possible be used for the client s data transfers. In some embodiments the determination as to whether to use path balancing and or packet sequencing may be made based at least in part on one or more attributes of the user or the user s computer instances . The one or more attributes may include budget limits e.g. users may be charged more for path balanced data transfers and a given client interested in optimized data transfers may be able to designate a budget to be used for path balanced transfers average bitrate for the computer instances operated by the user average amount of data transferred per interval of time for at least one computer instance operated by the user an aggregate amount of data transferred by the user s computer instances or one or more user account settings selected by the user through a management console of the virtual machine management service . In various embodiments the encapsulation mechanism will stop using path balancing techniques for the user once the designated budget is exhausted.

A path balancing policy may include the factors to be considered in determining whether path balancing is to be attempted as well as the logic to be used to determine values of fields to be added to baseline packets in the cases where path balancing is used. For example the virtual machine management service or other service of the service provider may determine if path balancing is enabled and whether to enable packet sequencing so that the destination computer instance s receives the baseline packets in order. In some embodiments several different path balancing policies may be implemented e.g. different policies may be applied for different client categories different application categories or different data centers of the service provider network. It is noted that at least in some embodiments even if a decision to attempt path balancing is made for a transmission it may not be the case that the traffic of that transmission is necessarily uniformly distributed across all the available paths. Such a scenario may result due to any of several factors for example because routing components may estimate different costs for some of the alternative paths and select some paths in preference to others based on cost or because the header field values added by the encapsulation mechanism do not happen to lead to a uniform distribution.

It is noted that an encapsulation intermediary may be used for purposes not directly related to path balancing in at least some embodiments. In some such embodiments for example in which virtualized networking is supported arbitrary client selected network addresses which may be unrelated to the IP addresses associated with the physical host s virtualization layer may be assigned to various computer instances at a given physical host . In order to direct client traffic to the appropriate destination computer instances the virtualization layers at the physical hosts may be configured to add some set of network headers e.g. IP headers with the IP addresses of the destination physical hosts to the baseline packets regardless of whether path balancing techniques similar to those described herein are being used. Furthermore additional encapsulation fields may be added to the baseline packets e.g. fields that identify the user s on whose behalf data is being transmitted which may be used for billing purposes or monitoring purposes.

As described above in some embodiments the encapsulation intermediary on the sending side of a transmission may be implemented at the same physical host e.g. within a virtualization layer at the same physical host as the application component whose data is being transmitted. In other embodiments however an encapsulation intermediary may be implemented at a different device than the physical host at which the source application runs for example at one or more routing components of the interconnected multi path network. Similarly the encapsulation intermediary on the receiving side of the transmission may be implemented at a different device such as an interconnect device than the physical host at which the receiving application runs. In various embodiments the source and or destination applications execute on a non virtualized compute server e.g. on a physical server that does not have a virtualization layer installed.

The encapsulation fields e.g. the fields added to the baseline packets for the purpose of path balancing may not necessarily correspond to headers for networking protocols of the Internet protocol suite. For example if the routing components of the interconnected multi path network are capable of parsing other types of fields than TCP UDP or IP header fields and using such other fields for routing decisions values may be generated for such other types of fields by the encapsulating intermediary of the virtualization layer . In some embodiments other networking protocols e.g. protocols other than TCP UDP or IP are used for path balancing and or more generally for transmissions between source and destination application components of the service provider network. Path balancing techniques similar to those described above may also be employed even if either the source application component or the destination application component is being implemented outside the service provider network e.g. in a user data center at which equivalents of the encapsulation intermediaries have been installed at one or more devices.

As shown at least some subset of the hosts may be linked via a dense multi path multi layer internal interconnected network that includes a plurality of different physical paths between pairs of hosts . As illustrated in the dense interconnected network is shown as comprising a number of distinct layers including outer layers i.e. layers directly connected to hosts comprising interconnect nodes and inner layers not directly connected to hosts comprising a different class of interconnect nodes and . The outer layer nodes may differ from the inner layer nodes and such as the physical arrangement of the nodes e.g. outer layer nodes may be arranged in racks physically close to the racks at which hosts are housed the number of nodes per rack the number of distinct in and or out ports at each node the performance capabilities e.g. bandwidth and or latency of the physical links leading into and or out of the nodes and so on. In some embodiments the outer layer nodes are referred to as bricks and the inner layers are referred to collectively as a fabric. Furthermore at least a portion of the outer layer nodes may be included as a component of the host . In other embodiments nodes used for various interconnected layers may have similar capabilities e.g. each of the nodes of the interconnected network may be identical. Various different types of topologies may be used for the dense interconnect in different embodiments such as fat trees VL2 topologies BCubes high radix network fabric topologies or various other types of topologies based on Clos networks. The interconnect nodes and or may comprise for example switches e.g. intelligent switches equipped with routing functionality routers and or various other types of networking devices in different embodiments. In at least some embodiments the interconnected nodes and or may comprise inexpensive commodity hardware and or software components.

As illustrated in at least a subset of the hosts may comprise a respective virtualization layer . The virtualization layer at a given host may include for example a hypervisor and or a special instance of an operating system that is designated for administrative uses such as a control plane described above in connection with as opposed to operating system instances at computer instances being used for user applications . Each host with a virtualization layer may be capable of instantiating one or more computer instances . Each such instance may include a respective instance of an operating system including a networking stack for one or more network protocols such as TCP UDP and IP protocols of the Internet suite. Each instance may be allocated to a respective user e.g. for use for one or more applications or application components.

Network traffic between the applications running at different instances may take the following general path as depicted in . The source application s data may be organized into baseline packets at the source instance s networking stack with each baseline packet including a body the application data or a portion thereof and a set of headers depending on the specific networking protocols being used for the transmission . Any appropriate network protocol may be used for a given network transmission which may comprise a sequence of packets sent from a source application or application component to a destination application or application component. For example a connection oriented protocol such as TCP may be used for a network transfer between application components or a connectionless protocol such as UDP may be used. The baseline packets may be passed e.g. via virtual network interfaces to the virtualization layer at the source host .

In some embodiments the virtualization layer may comprise one or more subcomponents responsible for determining based at least in part on criteria of a path balancing policy or sequencing policy in use whether a path balancing technique and or sequencing technique is to be employed for a given network transmission between a source computer instance and destination computer instance . At least for those network transmissions for which path balancing is to be implemented an encapsulation intermediary component at the virtualization layer may add one or more data fields such as UDP and or IP header fields to a baseline packet to generate an encapsulation packet. Furthermore at least for those network transmissions for which sequencing is to be implemented an encapsulation intermediary component at the virtualization layer and or the source instance s networking stack may add one or more data fields such as a sequencing flag and sequence number. In the case of a network transfer for which a TCP connection was established between the source and destination for example and one or more UDP headers were added during encapsulation the encapsulation packet may appear to be a UDP packet whose body contents happen to include a complete TCP packet with its own headers . In the case of a network transfer for which UDP was used at the source computer instance a new set of UDP headers may be added for encapsulation so that the encapsulation packet may include two sets of UDP headers one set added by the encapsulating intermediary of the virtualization layer and one set generated at the source computer instance . The encapsulating intermediary may select values for the added header fields in accordance with the path balancing policy such that routing components involved in selecting hops or links for the encapsulation packets select different hops for different encapsulation packets corresponding to a single transmission. For example in one embodiment if the network transmission is between source application of instance at host and destination application at instance of host randomly selected UDP source port numbers may be added as encapsulated field values by virtualization layer so that nodes and or of the interconnected network transmit successive encapsulation packets of the transmission along different combinations of physical links e.g. along paths selected based on a hash value obtained at least in part from the added random header values . The local routing decisions within various interconnected layers may thus be based on the added on field values without necessarily having to change routing logic of the interconnected components. At the same time an IP header also added by the encapsulating intermediary may have the correct IP address of the destination host s virtualization layer so that the encapsulation packets ultimately at least in the absence of packet loss reach the correct destination host.

Once an encapsulation packet reaches the destination host s virtualization layer an encapsulating intermediary may extract the baseline packet from the encapsulation packet e.g. by stripping the added fields and pass on the baseline packet to the networking stack at the computer instance at which the destination application runs. It is noted that although for ease of explanation unidirectional network traffic has been discussed herein similar techniques may be used in either direction for bi directional traffic in at least some embodiments with the roles of the source and destination elements reversed for different subsets of the bi directional traffic. In some embodiments the source and destination applications rely on in order delivery of the baseline packets as in the case of TCP connections while the encapsulation headers correspond to a protocol such as UDP that does not guarantee in order delivery sequence numbers may be added as part of the encapsulation procedure. Furthermore the sequence numbers may be added as a result of a setting or selection made by a user as described above. For example the user may select an operating system to be executed by the computer instance that is able to manage out of order packet delivery and therefore the virtual machine management service may configure the source computer instance to transmit packets without sequencing information in the baseline packets or the encapsulation headers. In yet another example the user may select an option for the user s computer instances such that if a path balancing policy is implemented for transmission of the computer instances then sequencing information is to be added to the baseline packets and or the encapsulation headers for transmission to the computer instances and or from the computer instances .

The encapsulating intermediary at the destination virtualization layer may receive an encapsulation packet out of order. The destination virtualization layer may therefore buffer one or more encapsulation packets at least for a predetermined time interval in an attempt to provide the extracted baseline packets to the destination computer instance in the expected order. If the missing encapsulation packets are not received in the time interval one or more baseline packets may nevertheless be delivered out of order to the destination instance and the networking stack at the destination instance may take the appropriate steps in response to the out of order delivery e.g. by not sending acknowledgements for the missing packets or by requesting retransmissions of the missing packets per the network protocol being used . It is noted that from the perspective of source application and destination applications source computer instance and destination computer instances and the interconnected nodes and or no changes may be required for path balancing to be implemented in the depicted embodiment.

In the embodiment shown in network transfers within the service provider network i.e. between different hosts may be completed using the dense interconnected network . Network transmissions to from other destinations outside the provider network may involve the use of external networks e.g. via additional links between the internal interconnected network and the external networks. In some embodiments the use of encapsulation based path balancing techniques is limited to transfers for which both the source and destination are within the service provider network . A destination within the provider network may not be a final destination. For example a destination may be an edge device of interconnected network for sending network traffic out to an external network . The encapsulation based path balancing techniques as described herein may be employed between a source and an edge device within the service provider network but the added encapsulation may be removed once the traffic is sent to the external network . Dense multi path interconnected networks may be in use at several different data centers of the service provider network and path balancing may be used to try to increase bandwidth utilization of the interconnected networks even if the source and destination are at different data centers i.e. even if some of the links involved in the transmission do not form part of a dense interconnected network such as when the traffic flows over an external network between two data centers of the service provider . In at least some embodiments encapsulation based path balancing is employed even if either the source the destination or both the source and destination are outside the service provider network . For example an encapsulating de encapsulating module may be provided for installation at devices within user networks so that path balancing of the kind described here is enabled even if a source or destination lies within a user network rather than the service provider network . It is noted that although the virtualization layers of include the encapsulating intermediary similar encapsulating and de encapsulating functionality may be implemented using software and or hardware other than virtualization layers components in at least some embodiments. In various embodiments each host has two links to the outer layer nodes of the interconnected network although a different number of links may be used in other embodiments. In at least some embodiments in which multiple links are available between hosts and a dense interconnected network the encapsulating intermediaries may balance traffic corresponding to a given network transmission among the host to interconnect links as well e.g. using random or round robin selection. Path balancing policies may not necessarily be implemented for all the packets of a given network transmission. For example traffic may flow over a long lasting TCP connection for days or weeks and network conditions may change in such a way during that period that it may not always be advisable to attempt path balancing for all packets. Path balancing may be switched on and off as needed during the lifetime of the network transmission depending for example on criteria specified in the path balancing policies in use and or one or more setting of a user account corresponding to the flow.

As described above a number of different types of dense multi path interconnected network topologies may be used in different embodiments including fat trees VL2 topologies BCube topologies and the like. By way of example illustrates a system in which alternate network paths available between a pair of hosts connected by a fat tree interconnect according to at least some embodiments. In the depicted embodiment hosts are each linked to a first layer or Tier 1 of switches . Switches of the first layer are each linked to two hosts and to two second layer Tier 2 switches . Each second layer switch is in turn linked to two third layer Tier 3 switches . Each third layer switch may be linked to three different second layer switches . It is noted that for clarity shows a much simplified example and that in many practical large scale implementations the link fan out between different switch layers e.g. and or and or between the switches and the hosts may be much higher than that shown in the number of layers or tiers may also be higher. Each of the links shown in may support bandwidths of several gigabits second e.g. 10 Gbits second .

Several different physical network paths are available for traffic between source host and destination host as illustrated in . One such path is illustrated in as a dashed line between two hosts . As the number of layers and or the link fan out increases many more alternative paths may be possible between a given pair of hosts connected via such dense interconnected networks. In at least some embodiments at least some of the interconnect nodes such as Tier 1 Tier 2 or Tier 3 switches or may be configured to select the next link to be used for a given packet based on the contents of packet headers that they can parse and or based on estimates of the costs of using each of the available links. The routing related costs of different links between the interconnected nodes may typically be determined to be equivalent. If all the links available are deemed to be of equivalent cost link selection may be based primarily on packet header contents. Different types of packet headers may be used for link selection in different embodiments for example headers comprising source and destination port numbers source and destination IP addresses protocol identifiers or other types of header fields. By inserting different header field values for different encapsulation packets of the same transmission e.g. different packets for the same TCP connection the traffic may be distributed uniformly or nearly uniformly among the alternative paths. The extent of the overall uniformity achieved and the overall improvement in average interconnected link utilization levels may vary depending on the mechanisms used for determining the header field values e.g. the extent to which the added header field values are themselves uniformly distributed relative timings and sizes of different transmissions and or other factors.

When data is to be transferred from the source application to some other application component located at the different instance application data payload e.g. the data to be transferred at the application to application level may be passed to instance networking stack which may be part of an operating system in use for computer instance at source host . The instance networking stack may in some embodiments depending on the size of the application data payload and or the packet size limits of the protocol in use partition the application payload into smaller pieces such that each of the pieces can be included within a respective baseline packet . The application data component may form the body of the baseline packet and a set of headers such as a TCP header and an IP header in the case where a TCP connection is being used generated by the instance networking stack may be included in the baseline packet . Headers corresponding to different combinations of layers of the protocol being used may be incorporated within the baseline packet by the instance networking stack . For example if the OSI Open Systems Interconnect model is used a data link layer header may also be included in the baseline packet in addition to a transport layer e.g. TCP header and a network layer e.g. IP header.

The baseline packet may be transmitted towards the destination computer instance by the instance networking stack over a network interface accessible from computer instance . The networking interface may comprise a virtual interface set up by virtualization layer such that the baseline packet can be intercepted or received by the encapsulating module . The encapsulating module may be configured to make several types of decisions regarding the baseline packets of a given transmission. For example the encapsulating module may determine whether path balancing is to be attempted for the transmission based on factors such as one or more attributed of the user on whose behalf the data transfer is being performed an indication of the number of alternate paths available to the destination the approximate number of hops involved budget limits or based on client requests or client settings. For example if the aggregated bitrate of all the computer instances associated with the user is above a threshold path balancing may be enabled for the transmission. Furthermore if the user has enabled sequencing for transmission to the user s computer instances the encapsulating module may add sequencing information to the baseline packet .

If path balancing is to be implemented the encapsulating module may then determine one or more values are to be added to the baseline packets in accordance with the path balancing policy in use to generate the corresponding encapsulation packets . For example the encapsulating module may determine whether UDP source or destination port numbers are to be added whether sequence numbers are to be added so that an attempt to deliver baseline packets in order can be made at the destination or whether other fields are to be added. For each type of field for which a value is to be added the encapsulating module may further be configured to determine the specific value to be added for each given baseline packet . For example a UDP source port number and a sequence number is to be added the source port number may be selected at random from a range of allowed source port numbers and the sequence number may be determined based on either a counter maintained per transmission by the encapsulating module or derived from a sequence number already included in the baseline packet e.g. a TCP sequence number . In some embodiments the encapsulating module is also configured to add additional fields e.g. an IP header or values that may be required to ensure that the encapsulation packet reaches the correct destination host via the interconnected network. As illustrated in the encapsulation packet includes the baseline packet as its body a set of extra headers added for path balancing and perhaps other purposes and sequencing information . The sequencing information may be included in the set of extra headers or may be included in a separate set of headers. The encapsulation packet may then be transmitted to the dense multi path interconnected network where a routing component may be configured to interpret the values added by the encapsulating module to determine at least a portion of the route e.g. one or more interconnect links to be used for the encapsulation packet . Depending on the techniques used to determine the added field values different encapsulation packets of the same transmission may have different field values and hence different network links selected for their transmission towards the destination hosts.

The virtualization layer may also reassemble jumbo packets into the baseline packet before providing the baseline packet to the instance network stack . Furthermore the virtualization layer may be configurable such that the timeout duration packets stored in the buffer may be adjusted. For example the user may transmit an API call to the computing resource service provider indicating a timeout duration for one or more computer system instances operated by the user. In another example the destination instance may be configured to determine a timeout duration based at least in part on the performance of the destination application . The virtual machine management service described above may be configured to set the timeout duration during initialization of the destination instance based at least in part on an image of the destination instance and or one or more settings of the destination instance . Additionally the timeout duration may be modified during execution of the destination application . For example the control plane described above or other component of the computing resource service provider may determine to increase or decrease the timeout duration based at least in part on various attributes of the destination instance source instance or dense multi path interconnected network. For example if the destination application or other component of the destination host detects packet delay variation the timeout duration may be adjusted. Packet delay variation may include any detected difference in end to end e.g. source to destination one way delay between selected packets in the transmission with any lost packets being ignored for the purposes of detecting the difference. In some embodiments the packet delay variation is detected as jitter by the destination application or other component of the destination host. In various embodiments the timeout duration is adjusted based at least in part on a distance between the source and the destination. For example if the source host is geographically located in Los Angeles and the destination host is geographically located in New York the timeout duration may be longer than if the destination host is geographically located in San Diego. Additionally the timeout duration may be determined based at least in part on a moving average of a subset of the packets received. For example the timeout duration may be an average of the amount of time the last N packets took to travel from the source host to the destination host where N is a positive integer or an average of the amount of time packets in the last minute or other length of time took to travel from the source host to the destination host. The average may also be measured per transmission i.e. a transmission comprising a set of packets or for all packets received at the destination from any source. The time for a packet to travel from the source to the destination may be measured as round trip time such as a TCP round trip estimator.

The sequencing information may include sequence numbers inserted in the encapsulation packets by the source the encapsulating module e.g. the encapsulating module of may be used at the destination the encapsulating module to deliver baseline packets in the correct order. If the baseline packet is not received in the expected order at the instance networking stack it may respond by issuing a retransmission request or the source instance networking stack may determine based on a lack of an acknowledgement that a baseline packet has been lost and may initiate retransmission without a retransmission request having been received from the destination instance networking stack . The instance networking stack may assemble an application data payload e.g. by combining the contents of several different baseline packets and provide it to a destination application at the destination instance .

An encapsulation intermediary such as an encapsulating module may generate values for one or more additional fields to be added to the baseline packet to form a corresponding encapsulation packet . As illustrated in the additional encapsulation fields may include for example an IP header a UDP header that includes one or more randomly generated port numbers or other fields that can be used for hop selection by a routing component a sequence number which itself may be derived at least in part from headers of the baseline packet in some embodiments e.g. from the TCP sequence number of the baseline packet and or other fields used for other aspects of the encapsulation protocol in use. Such additional encapsulation fields may for example comprise client identifiers monitoring related information e.g. tags that can be used to classify packets based on application type and or billing related metadata. For the encapsulation packet the body may comprise the entire baseline packet including the baseline headers as illustrated in . In some embodiments not all the values added by the source encapsulation intermediary need be header fields i.e. some added fields may be included in portions of the encapsulation packet that may be considered part of the body rather than the headers. At the destination encapsulation intermediary the baseline packet may be extracted and the baseline body may be transferred by the instance networking stack to the destination application.

The service provider or component thereof may then determine network congestion based at least in part on the collected network information . Network congestion may be determined based at least in part on congestion detected at one or more routing components of the service provider network. Network congestion may also be determined indirectly based at least in part on network load information corresponding to transmissions from one or more physical hosts. For example as described above an average bitrate may be calculated for a set of computer instances operated by a user the average bitrate may be used by the service provider as an indication of an amount of congestion at any given component of the service provider network. A representative value may be determined based at least in part on the collected network information the representative value corresponding to a level of congestion at one or more components of the service provider network. Furthermore the collected network information may be associated with a single transmission. For example as described above ECN may be used to determine congestion at a routing component of the service provider network. The ECN notifications generated by the routing component may be associated with a single network transmission and source virtualization layer and the destination virtualization layer may be responsible for determining congestion and enabling path balancing in response to the determined congestion.

If congestion is detected the service provider or component thereof such as the source virtualization layer may enable patch balancing for one or more network flows . Whether a threshold has been exceeded indicating congestion may be determined based at least in part on the representative value calculated for congestion on the service provider network. Additionally congestion may be detected based on one or more messages received from routing components or other components of the service provider network. If congestion is not detected the service provider may continue to collect network information . Once congestion has been detected the service provider may then enable path balancing for one or more network flows by at least encapsulating packets as described above. For example the virtual machine management service may send a command to a virtualization layer causing the virtualization layer to modify the UDP port number included in the encapsulation header for transmissions from a particular computer instance. In another example the virtualization layer may be configured to alter the UDP port number for each packet received from a computer instance.

Once path balancing is enable the service provider may determine if sequencing is required for the computer instance for which the transmission path has been altered. For example the user associated with the computer instance may have selected one or more options for the networking environment corresponding to the user s computer instances. The one or more options may have indicated that for computer instances for which path balancing is enabled also enable sequencing such that the computer instance receives packets in order. In another example the virtual machine management service may determine whether to enable sequencing based at least in part on one or more attributes of the computer instance such as applications executed by the computer instance or operating system of the computer instance. If sequencing is required the virtualization layer may then enable sequencing for the computer instances or network flows for which path balancing was enabled . Enabling sequencing may include adding sequence numbers and setting a sequence flag to one or more encapsulation headers and or baseline packet headers. Furthermore sequencing may require adding additional sequence information to the base line networking headers as described above. Values for the sequencing fields may be determined by the virtualization layer or component thereof such as the encapsulation intermediary. Once path balancing and or sequencing has been enabled for the computer instances or transmissions of the computer instances the virtualization layer may then transmit encapsulated packers over the service provider network .

As shown the source host and the destination host may be linked via a dense multi path multi layer internal interconnected network that includes a plurality of different physical paths between the source host and the destination host . As illustrated in the dense interconnected network is shown as comprising a number of distinct layers including outer layers i.e. layers directly connected to hosts comprising interconnect nodes and inner layers not directly connected to hosts comprising a different class of interconnected nodes and . The nodes and may be nodes as described above in connection with . Returning to when path balancing is enable the nodes and may be configured to route packets between the source host and the destination host along different network paths as illustrated in . For example the virtualization layer of the source host may be configured to encapsulate baseline packets from the source application as described above. The encapsulated packets may contain information in the header causing the encapsulated packets to be routed between different nodes of the dense interconnected network .

The illustrative environment includes at least one application server and a data store . It should be understood that there can be several application servers layers or other elements processes or components which may be chained or otherwise configured which can interact to perform tasks such as obtaining data from an appropriate data store. Servers as used herein may be implemented in various ways such as hardware devices or virtual computer systems. In some contexts servers may refer to a programming module being executed on a computer system. As used herein unless otherwise stated or clear from context the term data store refers to any device or combination of devices capable of storing accessing and retrieving data which may include any combination and number of data servers databases data storage devices and data storage media in any standard distributed virtual or clustered environment. The application server can include any appropriate hardware software and firmware for integrating with the data store as needed to execute aspects of one or more applications for the client device handling some or all of the data access and business logic for an application. The application server may provide access control services in cooperation with the data store and is able to generate content including but not limited to text graphics audio video and or other content usable to be provided to the user which may be served to the user by the web server in the form of HyperText Markup Language HTML Extensible Markup Language XML JavaScript Cascading Style Sheets CSS or another appropriate client side structured language. Content transferred to a client device may be processed by the client device to provide the content in one or more forms including but not limited to forms that are perceptible to the user audibly visually and or through other senses including touch taste and or smell. The handling of all requests and responses as well as the delivery of content between the client device and the application server can be handled by the web server using PHP Hypertext Preprocessor PHP Python Ruby Perl Java HTML XML or another appropriate server side structured language in this example. It should be understood that the web and application servers are not required and are merely example components as structured code discussed herein can be executed on any appropriate device or host machine as discussed elsewhere herein. Further operations described herein as being performed by a single device may unless otherwise clear from context be performed collectively by multiple devices which may form a distributed and or virtual system.

The data store can include several separate data tables databases data documents dynamic data storage schemes and or other data storage mechanisms and media for storing data relating to a particular aspect of the present disclosure. For example the data store illustrated may include mechanisms for storing production data and user information which can be used to serve content for the production side. The data store also is shown to include a mechanism for storing log data which can be used for reporting analysis or other such purposes. It should be understood that there can be many other aspects that may need to be stored in the data store such as page image information and access rights information which can be stored in any of the above listed mechanisms as appropriate or in additional mechanisms in the data store . The data store is operable through logic associated therewith to receive instructions from the application server and obtain update or otherwise process data in response thereto. The application server may provide static dynamic or a combination of static and dynamic data in response to the received instructions. Dynamic data such as data used in web logs blogs shopping applications news services and other such applications may be generated by server side structured languages as described herein or may be provided by a content management system CMS operating on or under the control of the application server. In one example a user through a device operated by the user might submit a search request for a certain type of item. In this case the data store might access the user information to verify the identity of the user and can access the catalog detail information to obtain information about items of that type. The information then can be returned to the user such as in a results listing on a web page that the user is able to view via a browser on the user device . Information for a particular item of interest can be viewed in a dedicated page or window of the browser. It should be noted however that embodiments of the present disclosure are not necessarily limited to the context of web pages but may be more generally applicable to processing requests in general where the requests are not necessarily requests for content.

Each server typically will include an operating system that provides executable program instructions for the general administration and operation of that server and typically will include a computer readable storage medium e.g. a hard disk random access memory read only memory etc. storing instructions that when executed by a processor of the server allow the server to perform its intended functions. Suitable implementations for the operating system and general functionality of the servers are known or commercially available and are readily implemented by persons having ordinary skill in the art particularly in light of the disclosure herein.

The environment in one embodiment is a distributed and or virtual computing environment utilizing several computer systems and components that are interconnected via communication links using one or more computer networks or direct connections. However it will be appreciated by those of ordinary skill in the art that such a system could operate equally well in a system having fewer or a greater number of components than are illustrated in . Thus the depiction of the system in should be taken as being illustrative in nature and not limiting to the scope of the disclosure.

The various embodiments further can be implemented in a wide variety of operating environments which in some cases can include one or more user computers computing devices or processing devices which can be used to operate any of a number of applications. User or client devices can include any of a number of general purpose personal computers such as desktop laptop or tablet computers running a standard operating system as well as cellular wireless and handheld devices running mobile software and capable of supporting a number of networking and messaging protocols. Such a system also can include a number of workstations running any of a variety of commercially available operating systems and other known applications for purposes such as development and database management. These devices also can include other electronic devices such as dummy terminals thin clients gaming systems and other devices capable of communicating via a network. These devices also can include virtual devices such as virtual machines hypervisors and other virtual devices capable of communicating via a network.

Various embodiments of the present disclosure utilize at least one network that would be familiar to those skilled in the art for supporting communications using any of a variety of commercially available protocols such as Transmission Control Protocol Internet Protocol TCP IP User Datagram Protocol UDP protocols operating in various layers of the Open System Interconnection OSI model File Transfer Protocol FTP Universal Plug and Play UpnP Network File System NFS Common Internet File System CIFS and AppleTalk. The network can be for example a local area network a wide area network a virtual private network the Internet an intranet an extranet a public switched telephone network an infrared network a wireless network a satellite network and any combination thereof.

In embodiments utilizing a web server the web server can run any of a variety of server or mid tier applications including Hypertext Transfer Protocol HTTP servers FTP servers Common Gateway Interface CGI servers data servers Java servers Apache servers and business application servers. The server s also may be capable of executing programs or scripts in response to requests from user devices such as by executing one or more web applications that may be implemented as one or more scripts or programs written in any programming language such as Java C C or C or any scripting language such as Ruby PHP Perl Python or TCL as well as combinations thereof. The server s may also include database servers including without limitation those commercially available from Oracle Microsoft Sybase and IBM as well as open source servers such as MySQL Postgres SQLite MongoDB and any other server capable of storing retrieving and accessing structured or unstructured data. Database servers may include table based servers document based servers unstructured servers relational servers non relational servers or combinations of these and or other database servers.

The environment can include a variety of data stores and other memory and storage media as discussed above. These can reside in a variety of locations such as on a storage medium local to and or resident in one or more of the computers or remote from any or all of the computers across the network. In a particular set of embodiments the information may reside in a storage area network SAN familiar to those skilled in the art. Similarly any necessary files for performing the functions attributed to the computers servers or other network devices may be stored locally and or remotely as appropriate. Where a system includes computerized devices each such device can include hardware elements that may be electrically coupled via a bus the elements including for example at least one central processing unit CPU or processor at least one input device e.g. a mouse keyboard controller touch screen or keypad and at least one output device e.g. a display device printer or speaker . Such a system may also include one or more storage devices such as disk drives optical storage devices and solid state storage devices such as random access memory RAM or read only memory ROM as well as removable media devices memory cards flash cards etc.

Such devices also can include a computer readable storage media reader a communications device e.g. a modem a network card wireless or wired an infrared communication device etc. and working memory as described above. The computer readable storage media reader can be connected with or configured to receive a computer readable storage medium representing remote local fixed and or removable storage devices as well as storage media for temporarily and or more permanently containing storing transmitting and retrieving computer readable information. The system and various devices also typically will include a number of software applications modules services or other elements located within at least one working memory device including an operating system and application programs such as a client application or web browser. It should be appreciated that alternate embodiments may have numerous variations from that described above. For example customized hardware might also be used and or particular elements might be implemented in hardware software including portable software such as applets or both. Further connection to other computing devices such as network input output devices may be employed.

Storage media and computer readable media for containing code or portions of code can include any appropriate media known or used in the art including storage media and communication media such as but not limited to volatile and non volatile removable and non removable media implemented in any method or technology for storage and or transmission of information such as computer readable instructions data structures program modules or other data including RAM ROM Electrically Erasable Programmable Read Only Memory EEPROM flash memory or other memory technology Compact Disc Read Only Memory CD ROM digital versatile disk DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the system device. Based on the disclosure and teachings provided herein a person of ordinary skill in the art will appreciate other ways and or methods to implement the various embodiments.

The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense. It will however be evident that various modifications and changes may be made thereunto without departing from the broader spirit and scope of the invention as set forth in the claims.

Other variations are within the spirit of the present disclosure. Thus while the disclosed techniques are susceptible to various modifications and alternative constructions certain illustrated embodiments thereof are shown in the drawings and have been described above in detail. It should be understood however that there is no intention to limit the invention to the specific form or forms disclosed but on the contrary the intention is to cover all modifications alternative constructions and equivalents falling within the spirit and scope of the invention as defined in the appended claims.

The use of the terms a and an and the and similar referents in the context of describing the disclosed embodiments especially in the context of the following claims are to be construed to cover both the singular and the plural unless otherwise indicated herein or clearly contradicted by context. The terms comprising having including and containing are to be construed as open ended terms i.e. meaning including but not limited to unless otherwise noted. The term connected when unmodified and referring to physical connections is to be construed as partly or wholly contained within attached to or joined together even if there is something intervening. Recitation of ranges of values herein are merely intended to serve as a shorthand method of referring individually to each separate value falling within the range unless otherwise indicated herein and each separate value is incorporated into the specification as if it were individually recited herein. The use of the term set e.g. a set of items or subset unless otherwise noted or contradicted by context is to be construed as a nonempty collection comprising one or more members. Further unless otherwise noted or contradicted by context the term subset of a corresponding set does not necessarily denote a proper subset of the corresponding set but the subset and the corresponding set may be equal.

Conjunctive language such as phrases of the form at least one of A B and C or at least one of A B and C unless specifically stated otherwise or otherwise clearly contradicted by context is otherwise understood with the context as used in general to present that an item term etc. may be either A or B or C or any nonempty subset of the set of A and B and C. For instance in the illustrative example of a set having three members the conjunctive phrases at least one of A B and C and at least one of A B and C refer to any of the following sets A B C A B A C B C A B C. Thus such conjunctive language is not generally intended to imply that certain embodiments require at least one of A at least one of B and at least one of C each to be present.

Operations of processes described herein can be performed in any suitable order unless otherwise indicated herein or otherwise clearly contradicted by context. Processes described herein or variations and or combinations thereof may be performed under the control of one or more computer systems configured with executable instructions and may be implemented as code e.g. executable instructions one or more computer programs or one or more applications executing collectively on one or more processors by hardware or combinations thereof. The code may be stored on a computer readable storage medium for example in the form of a computer program comprising a plurality of instructions executable by one or more processors. The computer readable storage medium may be non transitory.

The use of any and all examples or exemplary language e.g. such as provided herein is intended merely to better illuminate embodiments of the invention and does not pose a limitation on the scope of the invention unless otherwise claimed. No language in the specification should be construed as indicating any non claimed element as essential to the practice of the invention.

Embodiments of this disclosure are described herein including the best mode known to the inventors for carrying out the invention. Variations of those embodiments may become apparent to those of ordinary skill in the art upon reading the foregoing description. The inventors expect skilled artisans to employ such variations as appropriate and the inventors intend for embodiments of the present disclosure to be practiced otherwise than as specifically described herein. Accordingly the scope of the present disclosure includes all modifications and equivalents of the subject matter recited in the claims appended hereto as permitted by applicable law. Moreover any combination of the above described elements in all possible variations thereof is encompassed by the scope of the present disclosure unless otherwise indicated herein or otherwise clearly contradicted by context.

All references including publications patent applications and patents cited herein are hereby incorporated by reference to the same extent as if each reference were individually and specifically indicated to be incorporated by reference and were set forth in its entirety herein.

