---

title: Haptic trigger control system
abstract: A system that controls a haptic effect experienced at a trigger is provided. The system receives a haptic effect definition including haptic data. The system further receives trigger data including at least one of: a position of a trigger of a peripheral device; or a range of the trigger of the peripheral device. The system further determines whether a trigger condition is reached based on the received trigger data. The system further sends a haptic instruction and the haptic effect definition to the peripheral device when the trigger condition is reached. The system further causes a haptic output device (or multiple haptic output devices) to produce haptic effects that are based on the haptic effect definition at the peripheral device in response to the haptic instruction.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09619029&OS=09619029&RS=09619029
owner: Immersion Corporation
number: 09619029
owner_city: San Jose
owner_country: US
publication_date: 20141112
---
This application claims priority of U.S. Provisional Patent Application Ser. No. 61 904 342 filed on Nov. 14 2013 the disclosure of which is hereby incorporated by reference.

One embodiment is directed generally to a device and more particularly to a device that produces haptic effects.

Video games and video game systems have become extremely popular. Video game devices or controllers typically use visual and auditory cues to provide feedback to a user. In some interface devices kinesthetic feedback such as active and resistive force feedback and or tactile feedback such as vibration texture and heat is also provided to the user more generally known collectively as haptic feedback or haptic effects. Haptic feedback can provide cues that enhance and simplify a user s interaction with a video game controller or other electronic device. Specifically vibration effects or vibrotactile haptic effects may be useful in providing cues to users of video game controllers or other electronic devices to alert the user to specific events or provide realistic feedback to create greater sensory immersion within a simulated or virtual environment.

Other devices such as medical devices automotive controls remote controls and other similar devices where a user interacts with a user input element to cause an action also benefit from haptic feedback or haptic effects. For example and not by way of limitation user input elements on medical devices may be operated by a user outside the body of a patient at a proximal portion of a medical device to cause an action within the patient s body at a distal end of the medical device. Haptic feedback or haptic effects may be employed to alert the user to specific events or provide realistic feedback to the user regarding an interaction of the medical device with the patient at the distal end of the medical device.

One embodiment is a system that controls a haptic effect experienced at a peripheral device. The system receives a haptic effect definition including haptic data. The system further receives trigger data including at least one of a position of a trigger of a peripheral device or a range of the trigger of the peripheral device. The system further determines whether a trigger condition is reached based on the received trigger data. The system further sends a haptic instruction and the haptic effect definition to the peripheral device when the trigger condition is reached. The system further causes a haptic output device or multiple haptic output devices to produce haptic effects that are based on the haptic effect definition at the peripheral device in response to the haptic instruction.

One embodiment is a system that provides haptic feedback that is experienced at a peripheral device such as a game controller or gamepad. For example the system can provided a trigger haptic effect that is experienced at a trigger of a controller or some other peripheral device. The trigger haptic effect can complement rumble haptic effects that are also experienced at the controller or other peripheral device. As another example the system can provide a general haptic effect that is experienced at a user input element of the controller gamepad or other peripheral device. A wide variety of haptic feedback sensations can be created such as detents vibrations textures and stiffness. The haptic feedback sensations can complement a game application or other software application that can also be executed by the system. The haptic feedback sensations can be suited for a specific genre of game such as first person shooter fantasy roleplay racing or sports. In an alternate embodiment a peripheral device such as a game controller or gamepad can have discrete isolated vibration regions on the handles of the peripheral device.

The system can first receive a haptic effect definition. The system can further receive trigger data such as a position and or range of a trigger or positional information from the trigger or some other user input element e.g. joystick etc. . Examples of such trigger data can include placing the trigger in a specific position sweeping the trigger through a specific position placing the trigger within a specific range or sweeping the trigger through a specific range. The system can modify the haptic effect definition based on the received trigger data. The system can optionally further modify the haptic effect definition based on spatialization data such as a direction and or flow of a haptic effect that is based on the haptic effect definition. The system can then cause one or more motors or actuators of the controller gamepad or other peripheral device to play or otherwise output haptic feedback based on the modified haptic effect definition thus causing haptic feedback to be experienced. In other words the system can cause the controller gamepad or other peripheral device to playback a haptic effect based on the haptic effect definition. As understood by one of ordinary skill in the relevant art playback is the act or instance of reproducing data e.g. audio data video data or haptic data . Thus in one example the system can cause an overall trigger haptic effect to be experienced at a trigger of the controller.

In one embodiment the system can include a number of haptic presets that can be selected such as trigger haptic effect presets. The system can include a comprehensive library of haptic presets. Each selected haptic effect preset can be modified within a graphical user interface. The modified haptic effect preset can be compiled and executed within an execution of a game application or other software application where a controller gamepad or other peripheral device can product a haptic effect such as a trigger haptic effect.

In another embodiment the system can include a manual content driven toolset. The toolset allows a user to design haptic effect definitions alongside audio effect definitions. The system can then encode the haptic effect definitions into haptic files that can have an audio format or that can be stored alongside audio files. A decoder that resides in a controller gamepad or other peripheral device can subsequently decode the encoded haptic effect definitions. Further the designed haptic effect definitions can be loaded into a trigger engine and or a spatialization engine in order to launch haptic effects based on the designed haptic effect definitions. The trigger engine can allow haptic effect launches to be mapped to trigger movement or other trigger behavior and the spatialization engine can move each haptic effect around to create the sensation of haptic effects originating from a specific direction. The trigger engine and or the spatialization engine can be made available in an offline tool where a user can graphically interact with the engines and feel the haptic playback within the controller gamepad or other peripheral device in their hand once the haptic effects are loaded into the engine.

In yet another embodiment the system can include an automatic content driven toolset. The toolset can automatically convert audio effect definitions into haptic effect definitions. The toolset can receive the audio effect definitions as audio files. The toolset can modify one or more parameters to control the conversion of the audio effect definition into a haptic effect definition. As an example the one or more parameters can include a an audio file parameter that identifies the audio file containing the audio effect definition to be converted b a conversion control parameter that defines how the audio data of the audio effect definition gets divided into two or more distinct frequency bands which are then applied to two or more distinct outputs e.g. low rumble motor or actuator middle rumble motor or actuator and trigger motor or actuator c a dynamic parameter that controls a magnitude mapping from an audio effect definition to a haptic effect definition and can adjust a noise floor and dynamics range either stretching or squashing the dynamics as desired and d a magnitude or strength parameter that controls an ultimate magnitude or strength of the haptic effect definition. In an alternate embodiment rather than receiving an audio effect definition the toolset can receive a haptic instruction that can be converted into a haptic effect definition. The haptic instruction can take the form of a gameplay parameter received by a gaming application such as a rate of fire from a weapon within a game that can determine a duration of a haptic effect a key frame in an animation within a game that can determine a start point and a stop point for the haptic effect animation data for a directionality on an axis for the haptic effect a damage amount for a weapon within the game that can determine a magnitude of the haptic effect etc. Further the converted haptic effect definition can be loaded into a trigger engine and or a spatialization engine in order to launch haptic effects based on the designed haptic effect definition as previously described. The trigger engine and or the spatialization engine can be made available in an offline tool as previously described.

In yet another embodiment the system can include a haptic effect studio engine. A haptic effect studio can be provided to allow a user to define a haptic effect definition for a specific motor or actuator. The designed haptic effect definition can be loaded into a trigger engine and or a spatialization engine in order to launch haptic effects based on the designed haptic effect definition as previously described. The trigger engine and or the spatialization engine can be made available in an offline tool as previously described.

A computer readable medium may be any available medium that can be accessed by processor and may include both a volatile and nonvolatile medium a removable and non removable medium a communication medium and a storage medium. A communication medium may include computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and may include any other form of an information delivery medium known in the art. A storage medium may include RAM flash memory ROM erasable programmable read only memory EPROM electrically erasable programmable read only memory EEPROM registers hard disk a removable disk a compact disk read only memory CD ROM or any other form of a storage medium known in the art.

In one embodiment memory stores software modules that provide functionality when executed by processor . The modules include an operating system that provides operating system functionality for system as well as the rest of an overall device in one embodiment. The modules further include a haptic trigger control module that controls a haptic effect experienced at a trigger or some other user input element. In certain embodiments haptic trigger control module can comprise a plurality of modules where each module provides specific individual functionality for controlling a haptic effect experienced at a trigger or some other user input element. System will typically include one or more additional application modules to include additional functionality such as peripheral firmware which can provide control functionality for a peripheral device such as a controller .

System in embodiments that transmit and or receive data from remote sources further includes a communication device such as a network interface card to provide mobile wireless network communication such as infrared radio Wi Fi or cellular network communication. In other embodiments communication device provides a wired network connection such as an Ethernet connection or a modem.

System is operably connected to controller . Controller is a peripheral device used to provide input to system . Controller can be operably connected to system using either a wireless connection or a wired connection. Controller can further include a local processor which can communicate with system using either a wireless connection or a wired connection. Alternatively controller may be configured to not include a local processor and all input signals and or output signals associated with controller can be handled and processed directly by processor of system .

Controller can further include one or more digital buttons one or more analog buttons one or more bumpers one or more directional pads one or more analog or digital sticks one or more driving wheels and or one or more user input elements that can be interacted with by a user and that can provide input to system . Controller can also include one or more analog or digital trigger buttons or triggers that can further be interacted with by the user and that can further provide input to system . As is described below in greater detail controller can further include a motor or another type of actuator or haptic output device configured to exert a bi directional push pull force on at least one trigger of controller .

Controller can also include one or more actuators or other types of haptic output devices. The local processor of controller or processor in embodiments where controller does not include a local processor may transmit a haptic signal associated with a haptic effect to at least one actuator of controller . The actuator in turn outputs haptic effects such as vibrotactile haptic effects kinesthetic haptic effects or deformation haptic effects in response to the haptic signal. The haptic effects can be experienced at a user input element e.g. a digital button analog button bumper directional pad analog or digital stick driving wheel or trigger of controller . Alternatively the haptic effects can be experienced at an outer surface of controller . The actuator includes an actuator drive circuit. The actuator may be for example an electric motor an electro magnetic actuator a voice coil a shape memory alloy an electro active polymer a solenoid an eccentric rotating mass motor ERM a linear resonant actuator LRA a piezoelectric actuator a high bandwidth actuator an electroactive polymer EAP actuator an electrostatic friction display or an ultrasonic vibration generator. An actuator is an example of a haptic output device where a haptic output device is a device configured to output haptic effects such as vibrotactile haptic effects electrostatic friction haptic effects kinesthetic haptic effects or deformation haptic effects in response to a drive signal. In alternate embodiments the one or more actuators within controller can be replaced by some other type of haptic output device.

Controller can further include one or more speakers. The local processor of controller or processor in embodiments where controller does not include a local processor may transmit an audio signal to at least one speaker of controller which in turn outputs audio effects. The speaker may be for example a dynamic loudspeaker an electrodynamic loudspeaker a piezoelectric loudspeaker a magnetostrictive loudspeaker an electrostatic loudspeaker a ribbon and planar magnetic loudspeaker a bending wave loudspeaker a flat panel loudspeaker a heil air motion transducer a plasma arc speaker and a digital loudspeaker.

Controller can further include one or more sensors. A sensor can be configured to detect a form of energy or other physical property such as but not limited to sound movement acceleration bio signals distance flow force pressure strain bend humidity linear position orientation inclination radio frequency rotary position rotary velocity manipulation of a switch temperature vibration or visible light intensity. The sensor can further be configured to convert the detected energy or other physical property into an electrical signal or any signal that represents virtual sensor information and controller can send the converted signal to the local processor of controller or processor in embodiments where controller does not include a local processor. The sensor can be any device such as but not limited to an accelerometer an electrocardiogram an electroencephalogram an electromyograph an electrooculogram an electropalatograph a galvanic skin response sensor a capacitive sensor a hall effect sensor an infrared sensor an ultrasonic sensor a pressure sensor a fiber optic sensor a flexion sensor or bend sensor a force sensitive resistor a load cell a LuSense CPS155 a miniature pressure transducer a piezo sensor a strain gage a hygrometer a linear position touch sensor a linear potentiometer or slider a linear variable differential transformer a compass an inclinometer a magnetic tag or radio frequency identification tag a rotary encoder a rotary potentiometer a gyroscope an on off switch a temperature sensor such as a thermometer thermocouple resistance temperature detector thermistor or temperature transducing integrated circuit microphone photometer altimeter bio monitor camera or a light dependent resistor.

A housing of controller is shaped to easily accommodate two hands gripping the device either by a left handed user or a right handed user. Those skilled in the art would recognize that controller is merely an example embodiment of a controller of similar shape and size to many gamepads currently available for video game console systems such as a Microsoft Xbox One controller or a PlayStation DualShock controller and that controllers with other configurations of user input elements shapes and sizes may be used including but not limited to controllers such as a Wii remote or Wii U Controller Sony SixAxis controller or Sony Wand controller as well as controllers shaped as real life objects such as tennis rackets golf clubs baseball bats and the like and other shapes or controllers with a display or head mounted display.

Controller includes several user input elements including an analog or digital stick a button and a trigger . As used herein user input element refers to an interface device such as a trigger button analog or digital stick or the like which is manipulated by the user to interact with host computer . As can be seen in and as known to those skilled in the art more than one of each user input element and additional user input elements may be included on controller . Accordingly the present description of a trigger for example does not limit controller to a single trigger. Further the block diagram of shows only one 1 of each of analog or digital stick button and trigger . However those skilled in the art would understand that multiple analog or digital sticks buttons and triggers as well as other user input elements may be used as described above.

As can be seen in the block diagram of controller includes a targeted actuator or motor to directly drive each of the user input elements thereof as well as one or more general or rumble actuators operably coupled to housing in a location where a hand of the user is generally located. More particularly analog or digital stick includes a targeted actuator or motor operably coupled thereto button includes a targeted actuator or motor operably coupled thereto and trigger includes a targeted actuator or motor operably coupled thereto. In addition to a plurality of targeted actuators controller includes a position sensor operably coupled to each of the user input elements thereof. More particularly analog or digital stick includes a position sensor operably coupled thereto button includes a position sensor operably coupled thereto and trigger includes a position sensor operably coupled thereto. Local processor is operably coupled to targeted actuators as well as position sensors of analog or digital stick button and trigger respectively. In response to signals received from position sensors local processor instructs targeted actuators to provide directed or targeted kinesthetic effects directly to analog or digital stick button and trigger respectively. Such targeted kinesthetic effects are discernible or distinguishable from general or rumble haptic effects produced by general actuators along the entire body of the controller. The collective haptic effects provide the user with a greater sense of immersion to the game as multiple modalities are being simultaneously engaged e.g. video audio and haptics. Further details of a controller configured to produce haptics are described in greater detail in application Ser. No. 14 258 644 filed Apr. 22 2014 entitled GAMING DEVICE HAVING A HAPTIC ENABLED TRIGGER herein incorporated by reference in its entirety.

Device includes game input management code . Game input management code includes a set of computer readable instructions that manage input provided by controller in the context of a game application or other type of application executed within device . Device further includes peripheral input application programming interface API . Peripheral input API includes a set of computer readable functions or routines that allow game input management code to interact with peripheral firmware in order to receive and manage input provided by controller . Device further includes rumble API . Rumble API includes a set of computer readable functions or routines that allow game input management code to interact with peripheral firmware in order to transmit rumble instructions to one or more rumble motors or rumble actuators of controller e.g. rumble motors L and R as illustrated in . A rumble instruction can cause a rumble motor or rumble actuator of controller to produce a general or rumble haptic effect.

Device further includes trigger haptic effect API identified in as API . Trigger haptic effect API includes a set of computer readable functions or routines that are exposed to game input management code and that allow game input management code to interact with peripheral firmware in order to transmit haptic instructions to controller such as trigger instructions to one or more triggers of controllers e.g. triggers L and R as illustrated in . A haptic instruction can cause one or more targeted motors or targeted actuators of controller to produce a haptic effect at one or more user input elements of controllers . A trigger instruction is a specific type of haptic instruction that can cause one or more targeted motors or targeted actuators of controller e.g. motors L and R as illustrated in to produce a trigger haptic effect at one or more triggers of controllers e.g. triggers L and R as illustrated in . A trigger haptic effect is a specific type of haptic effect that is experienced at a trigger of a controller such as controller . Trigger haptic effect API can store one or more trigger haptic effect definitions. A haptic effect definition is a data structure that includes haptic data such as a haptic signal that is pre defined and that can be stored within a storage such as a haptic file or haptic stream and that can be sent to one or more rumble motors rumble actuators targeted motors or targeted actuators to produce a haptic effect at a component or user input element of controller . The haptic data can include one or more attributes of the corresponding haptic effect where the attributes can be stored as parameters. Example parameters of a haptic effect definition include an amplitude parameter a frequency parameter a waveform parameter an envelope parameter a magnitude or strength parameter and a duration parameter. A trigger haptic effect definition is a specific type of haptic effect definition that can be sent to one or more motors or actuators of controller e.g. motors L and R as illustrated in to produce a trigger haptic effect at one or more triggers of controllers e.g. triggers L and R as illustrated in .

According to the embodiment trigger haptic effect API can allow game input management code to interact with direct playback crossover trigger engine and spatialization engine and can further manage direct playback crossover trigger engine and spatialization engine according to requests invoked by game input management code . Further trigger haptic effect API can store data required for communication with peripheral firmware and required for generation of one or more trigger haptic effects. In an alternate embodiment trigger haptic effect API can reside within peripheral firmware rather than device . Trigger haptic effect API is further described below in greater detail in conjunction with .

Device further includes direct playback crossover . Direct playback crossover receives haptic data as input produces haptic data as output and transmits haptic data to one or more targeted motors or targeted actuators of controller e.g. motors L and R as illustrated in . In certain embodiments direct playback crossover can output the input haptic data directly without modifying a format of the input haptic data. This results in an as is playback of the input haptic data. In other embodiments direct playback crossover can convert the haptic data that is input from a first format to a second format and can further output the converted haptic data. Depending on the type of playback direct playback crossover can optionally use a programmable crossover to convert the haptic data. By converting the haptic data device can deconstruct the haptic effect and playback the haptic effect at multiple actuators faithfully. In one embodiment the format of the haptic data can be a Haptic Elementary Stream HES format. A HES format is a file or data format for representing haptic data that can be streamed to a device. The haptic data can be represented in a manner that is identical or similar to how uncompressed sound is represented although the haptic data can be encrypted within the HES format. Thus the haptic data can be stored in a haptic file or haptic stream where a format of the haptic file or haptic stream is an HES format. In other words the HES format can be used by the haptic file or haptic stream to represent the haptic data in a haptic format. In an alternate embodiment direct playback crossover can reside within peripheral firmware rather than device . Direct playback crossover is further described below in greater detail in conjunction with .

Device further includes trigger engine . Trigger engine can receive haptic data such as a trigger haptic effect definition and can modify the haptic data based on data such as trigger data e.g. trigger data as illustrated in received from controller . Trigger data is data that includes one or more parameters that indicate a position and or range of one or more triggers of controller e.g. triggers L and R as illustrated in . Trigger engine can further transmit haptic instructions to controller . For example trigger engine can transmit trigger instructions to one or more triggers of controller e.g. triggers L and R as illustrated in . As previously described a trigger instruction can cause one or more targeted motors or targeted actuators of controller e.g. motors L and R as illustrated in to produce a trigger haptic effect at one or more triggers of controllers e.g. triggers L and R as illustrated in . Thus in one embodiment by modifying the haptic data of the trigger haptic effect definition trigger engine can cause a specific trigger haptic effect to be experienced at a trigger based on a position and or range of the trigger. In another embodiment by modifying the haptic data of the trigger haptic effect definition trigger engine can scale a trigger haptic effect for one or more targeted motors or targeted actuators of controller e.g. motors L and R as illustrated in based on a position and or range of the trigger. Trigger engine can further store one or more haptic effect definitions such as trigger haptic effect definitions. In an alternate embodiment trigger engine can reside within peripheral firmware rather than device . Trigger engine is further described below in greater detail in conjunction with .

Device further includes spatialization engine identified in as spatialisation engine . Spatialization engine can receive haptic data such as a trigger haptic effect definition and can modify the haptic data based on spatialization data. Spatialization data can include data that indicates a desired direction and or flow of a haptic effect such as a trigger haptic effect. In certain embodiments spatialization engine can receive spatialization data that includes a direction and or flow from game input management code . Further spatialization data can also include one or more positions of one or more hands of a user located on controller . In certain embodiments spatialization engine can receive spatialization data that includes one or more hand positions from controller . Further in certain embodiments spatialization engine can receive spatialization data that includes a position of a user s character within a game application as communicated by game input management code .

According to the embodiment spatialization engine can modify the haptic data so that a haptic effect such as a trigger haptic effect is scaled for one or more rumble motors or rumble actuators of controller e.g. rumble motors L and R as illustrated in and that the haptic effect is also scaled for one or more targeted motors or targeted actuators of controller e.g. motors L and R as illustrated in . In other words spatialization engine can modify the haptic data that is sent to each motor or actuator and thus modify the haptic effect that is experienced at each motor or actuator in order to convey a sense of direction and flow of an overall haptic effect. For example in order to emphasize a haptic effect experienced at a motor or actuator spatialization engine may scale one or more portions of the haptic effect. For example spatialization engine may scale haptic data that is sent to the motor or actuator that causes the haptic effect to be experienced causing the haptic effect to be more pronounced e.g. increased magnitude duration etc. . Additionally spatialization engine may scale haptic data that is sent to other motors or actuators causing other haptic effects that are experienced at those motors or actuators to be less pronounced e.g. decreased magnitude duration etc. . In certain embodiments spatialization engine can modify the haptic data in real time. Further in certain embodiments spatialization engine can have non linear relationships between inputs and motor or actuator outputs in order to exaggerate an overall trigger haptic effect. In an alternate embodiment spatialization engine can reside within peripheral firmware rather than device . Spatialization engine is further described below in greater detail in conjunction with .

Device further includes encoder . Encoder encodes haptic data received from direct playback crossover trigger engine and or spatialization engine into a format. In one embodiment the format can be an HES format. Encoder further transmits the encoded haptic data to peripheral firmware .

Peripheral firmware includes decoder and crossover . Decoder and crossover receives the encoded haptic data from encoder and decodes the encoded haptic data. In certain embodiments decoder and crossover computes a programmable crossover in order to decode the encoded haptic data. In some of these embodiments decoder and crossover computes the programmable crossover in real time. Peripheral firmware further includes trigger control . Trigger control is a low level control API for one or more targeted motors or targeted actuators of controller e.g. motors L and R as illustrated in . Trigger control can receive a trigger instruction from device can convert the trigger instruction into a low level trigger instruction for a specified targeted motor or targeted actuator of controller and can transmit the low level trigger instruction to the specified targeted motor or targeted actuator of controller . The low level trigger instruction can cause the specified targeted motor or targeted actuator to produce a trigger haptic effect at a specified trigger of controller .

Peripheral firmware further includes trigger data . Trigger data as previously described is data that includes one or more parameters such as one or more parameters that indicate a position and or range of one or more triggers of controller e.g. triggers L and R as illustrated in . Trigger data can be received from controller by peripheral firmware . Peripheral firmware can further store trigger data and can further transmit trigger data to device . Peripheral firmware further includes other gamepad functions which are functions of controller that can be managed by peripheral firmware . Such functions can include wired wireless communications input reporting protocol implementation power management etc. Peripheral firmware further includes rumble control . Rumble control is a low level control API for one or more rumble motors or rumble actuators of controller e.g. rumble motors L and R as illustrated in . Rumble control can receive a rumble instruction from device can convert the rumble instruction into a low level rumble instruction for a specified rumble motor or rumble actuator of controller and can transmit the low level trigger instruction to the specified rumble motor or rumble actuator of controller .

Controller includes triggers L and R. Controller further includes gear boxes L and R and motors L and R. Motor L and gearbox L are operably coupled to trigger L within controller . Likewise motor R and gearbox R are operably coupled to trigger R within controller . When motor L receives a trigger instruction motor L and gearbox L collectively cause a trigger haptic effect to be experienced at trigger L. Likewise when motor R receives a trigger instruction motor R and gearbox R collectively cause a trigger haptic effect to be experienced at trigger R. According to the embodiment peripheral firmware sends trigger instructions to motors L and R of controller using drive electronics . Controller further includes potentiometers L and R. Potentiometer L can detect a position and or range of trigger L and can further send the detected position and or range of trigger L to peripheral firmware as trigger data. Likewise potentiometer R can detect a position and or range of trigger R and can further send the detected position and or range of trigger R to peripheral firmware as trigger data. In one embodiment potentiometers L and R can each be replaced with another type of position sensor such as a hall effect sensor. Controller further includes rumble motors L and R. When rumble motor L receives a rumble instruction rumble motor L causes a haptic effect to be experienced along a left body of controller . Likewise when rumble motor R receives a rumble instruction rumble motor R cause a haptic effect to be experienced along a right body of controller . According to the embodiment peripheral firmware sends rumble instructions to rumble motors L and R of controller using rumble drive electronics .

In an alternate embodiment one or more targeted motors or targeted actuators can be operably coupled to one or more user input elements such as one or more digital buttons one or more analog buttons one or more bumpers one or more directional pads one or more analog or digital sticks one or more driving wheels of controller . According to the alternate embodiment peripheral firmware can sends instructions to the one or more targeted motors or targeted actuators causing the one or more targeted motors or targeted actuators to produce haptic effects that are experienced at the one or more user input elements of controller .

User interface further includes effect definitions . According to the embodiment the user can save a modified haptic effect definition as a new haptic effect definition where the new haptic effect definition is displayed within effect definitions . The new haptic effect definition can be stored within a haptic file or haptic stream. In one embodiment a format of the haptic file or haptic stream can be an HES format. The new haptic effect definition can further be exported to an external haptic file or external haptic stream. User interface further includes a play button . Interacting with play button can cause the system to output a haptic effect at a controller that can be operably controlled to user interface . If the haptic effect is a trigger haptic effect the system can output the trigger haptic effect at a trigger of the controller. The haptic effect can be a selected pre defined haptic effect definition or a selected new haptic effect definition.

User interface further includes trigger engine area . Trigger engine area is an editable visual area that can visualize a trigger haptic effect that is generated by a trigger engine such as trigger engine of . As previously described a trigger engine can receive a trigger haptic effect definition and can modify the trigger haptic effect definition based on a position and or range of a trigger of a controller. Thus trigger engine area can display a visualization of the trigger including an actual position of the trigger. Further trigger engine area can display a position and or range of the trigger that is defined for a trigger haptic effect definition where the position and or range can cause the trigger engine to modify the trigger haptic effect definition. A user can edit the position and or range of the trigger that is defined for the trigger haptic effect definition. User interface further includes spatialization engine area . Spatialization engine area is an editable visual area that can visualize a trigger haptic effect that is originally generated by the trigger engine and further modified by a spatialization engine such as spatialization engine of . As previously described the spatialization engine can modify the trigger haptic effect definition so that a trigger haptic effect is scaled for one or more targeted motors targeted actuators rumble motors or rumble actuators of a controller. Thus spatialization engine area can display a visualization of the controller. The spatialization engine area can further display a visualization of the trigger haptic effect experienced at each targeted motor targeted actuator rumble motor or rumble actuator of the controller. A user can edit a scaling of the trigger haptic effect that is experienced at each targeted motor targeted actuator rumble motor or rumble actuator of the controller.

The crossover input warp algorithm can reside either in the device itself or reside on the opposite side of a communications link executing on a processor different from that of the device. The crossover input warp algorithm may also separate the input data haptic or audio into two bands where lower frequencies are separated and then optionally further transformed before being applied to one or more actuator outputs and higher frequencies are separated and then optionally transformed before being applied to a number of actuators distinct from those used for the lower frequency separated data. This type of data separation could occur on an arbitrary number of frequency bands and actuator outputs. In alternate embodiments the input data audio or haptic can be separated into multiple overlapping frequency regions which are then each optionally transformed and applied to a number of output actuators. Another set of embodiments could create a number of signal strength bands where the input data audio or haptic is separated according to output power or strength such as through peak detection RMS calculations etc. and these separated data streams are each applied to one or more distinct sets of actuators. In alternate embodiments the input data audio or haptic can be separated according to output power or strength such as through peak detection RMS calculations etc. into distinct but overlapping data streams instead of completely distinct streams where the strength filtering algorithms capture overlapping regions of strength optionally apply the transformations and apply each of the outputs to a number of output actuators.

The system can further send the encoded audio effect definition or the encoded haptic effect definition to a human interface device HID interpreter that resides on controller . HID interpreter receives and interprets the encoded audio effect definition or the encoded haptic effect definition in order to provide a trigger haptic effect at a trigger of controller . In one embodiment a system can further modify the encoded audio effect definition or the encoded haptic effect definition using a trigger engine such as trigger engine of and or a spatialization engine such as spatialization engine of before the system sends the encoded audio effect definition or the encoded haptic effect definition to HID interpreter of controller .

Once a user of the system has authored a trigger haptic effect using audio authoring component the user can preview the trigger haptic effect. The preview functionality can allow for further customization of the trigger haptic effect. Upon previewing the trigger haptic effect the system can send the authored audio effect definition to four channel output driver where four channel output driver can stream the audio effect definition as four channels of audio data. In one embodiment four channel output driver can be a four channel ASIO output driver. In an alternate embodiment four channel output driver can be replaced by another driver that streams the audio effect definition as any plural number of channels of audio data such as six or eight channels of audio data.

Further the system can send the audio stream to audio to haptic converter where audio to haptic converter can convert the audio effect definition of the audio stream into a haptic effect definition using a haptic conversion algorithm. In one embodiment each separate channel of the audio effect definition that corresponds to a motor or actuator can be converted into a channel of a haptic effect definition. Example haptic conversion algorithms are described in the following patents or patent applications all of which are hereby incorporated by reference in their entirety U.S. Pat. Nos. 7 979 146 8 000 825 8 378 964 U.S. Pat. App. Pub. No. 2011 0202155 U.S. Pat. App. Pub. No. 2011 0215913 U.S. Pat. App. Pub. No. 2012 0206246 U.S. Pat. App. Pub. No. 2012 0206247 U.S. Pat. App. Pub. No. 2013 0265286 U.S. Pat. App. Pub. No. 2013 0131851 U.S. Pat. App. Pub. No. 2013 0207917 U.S. Pat. App. Pub. No. 2013 0335209 U.S. Pat. App. Pub. No. 2014 0064516 U.S. patent application Ser. Nos. 13 661 140 13 785 166 13 788 487 14 078 438 14 078 442 14 078 445 14 051 933 14 020 461 14 020 502 14 277 870 and 14 467 184.

The system can further send the converted haptic effect definition to HES multi channel encoder where multi channel encoder can encode the converted haptic effect definition into an external format such as an HES format. The system can further send the encoded and converted haptic effect definition to trigger controller interface I F that resides on controller . Trigger controller I F can receive and interpret the encoded and converted haptic effect definition in order to preview the authored trigger haptic effect at a trigger of controller .

In this embodiment the system can provide audio authoring component where audio authoring component is identical to audio authoring component . Once a user of the system has authored a trigger haptic effect using audio authoring component the user can save the trigger haptic effect. Upon saving the trigger haptic effect the system can export the audio effect definition as separate audio files . In one embodiment where the audio effect definition includes four channels audio files can include four audio files. In an alternate embodiment where the audio effect definition includes another number of channels audio files can include that number of separate audio files. In certain embodiments audio files can be a Waveform Audio File WAV format. The system can further send audio files to a HES encoder graphical user interface GUI where HES encoder GUI can encode audio files into a single audio file. In one embodiment the audio file can be an HES format. Further the system can send the audio file to audio to haptic converter where audio to haptic converter can convert the audio effect definition of the audio file into a haptic effect definition using a haptic conversion algorithm. In one embodiment each separate channel of the audio effect definition that corresponds to a motor or actuator can be converted into a channel of a haptic effect definition. The system can further send the converted haptic effect definition to HES multi channel encoder where multi channel encoder can encode the converted haptic effect definition into an external format such as an HES format. The system can further store the encoded and converted haptic effect definition within a haptic file . In one embodiment haptic file can be an HES file.

Once a user of the system has authored a trigger haptic effect using audio authoring component the user can preview the trigger haptic effect. Upon previewing the trigger haptic effect the system can send the authored audio effect definition to single channel output driver where single channel output driver can stream the audio effect definition as a single channel of audio data. In one embodiment single channel output driver can be a single channel ASIO output driver. Further the system can send the audio stream to audio to haptic converter where audio to haptic converter can convert the audio effect definition of the audio stream into a haptic effect definition using a haptic conversion algorithm. In one embodiment each separate channel of the audio effect definition that corresponds to a motor or actuator can be converted into a channel of a haptic effect definition. Even further the system can send the converted haptic effect definition to crossover GUI where crossover GUI can apply a crossover input warp algorithm to separate the converted haptic effect definition into three different channels that can be mapped to three different outputs such as 1 a low frequency rumble motor or rumble actuator 2 a medium frequency rumble motor or rumble actuator or 3 a high frequency targeted motor or targeted actuator .

The system can further send the converted haptic effect definition to HES multi channel encoder where multi channel encoder can encode the converted haptic effect definition into an external format such as an HES format. The system can further send the encoded and converted haptic effect definition to trigger controller I F that resides on controller . Trigger controller I F can receive and interpret the encoded and converted haptic effect definition in order to preview the authored trigger haptic effect at a trigger of controller .

In this embodiment the system can provide audio authoring component where audio authoring component is identical to audio authoring component . Once a user of the system has authored a trigger haptic effect using audio authoring component the user can save the trigger haptic effect. Upon saving the trigger haptic effect the system can export the audio effect definition as a single audio file . In certain embodiments audio file can be a WAV format. The system can further export crossover settings . The system can further send audio file to a HES encoder GUI where HES encoder GUI can encode audio file and crossover settings into a single audio file. In one embodiment the audio file can be an HES format. The system can further send the audio file to HES single channel and crossover encoder where single channel and crossover encoder can encode the audio file into an external format such as an HES format. The system can further store the encoded audio file within a haptic file . In one embodiment haptic file can be an HES file.

According to the embodiment the system can send the four channels of the haptic effect definition included within haptic file to strength control where strength control can modify a strength or magnitude of the haptic data included within each channel of the haptic effect definition. The system can then send the four channels of the haptic effect definition to front back F B spatialization where F B spatialization can modify the haptic data included within each channel of the haptic effect definition based on spatialization data. The spatialization data can include a direction and or flow of a haptic effect. In one embodiment the direction and or flow of the haptic effect can be a frontwards or backwards direction. Further spatialization data can include one or more hand positions. According to the embodiment F B spatialization can modify the haptic data included within each channel so that a haptic effect is scaled for each motor or actuator. The system can then send channel LR to low rumble motor identified in as LowR motor and can further send channel MR to medium rumble motor identified in as MidR motor . The haptic data contained within channel LR can cause low rumble motor to produce a general or rumble haptic effect and the haptic data contained within channel MR can cause medium rumble motor to produce a general or rumble haptic effect.

The system can further send channels LT and RT to left right L R spatialization where L R spatialization can modify the haptic data included within channels LT and RT based on spatialization data. The spatialization data can include a direction and or flow of a haptic effect. In one embodiment the direction and or flow of the haptic effect can be a left or right direction. Further spatialization data can include one or more hand positions. According to the embodiment L R spatialization can modify the haptic data included within each channel so that a haptic effect is scaled for each motor or actuator. The system can then send channel LT to left trigger targeted motor identified in as LT motor and can further send channel RT to right trigger targeted motor identified in as RT motor . The haptic data contained within channel LT can cause left trigger targeted motor to produce a trigger haptic effect at a left trigger and the haptic data contained within channel RT can cause right trigger targeted motor to produce a trigger haptic effect at a right trigger.

According to the embodiment the system can send the channel of the haptic effect definition included within haptic file and the one or more crossover parameters also included within haptic file to programmable crossover . Programmable crossover can apply a crossover input warp algorithm using the one or more crossover parameters to separate the channel into three different channels a low frequency channel a medium frequency channel and a high frequency channel. The low frequency channel includes a portion of the haptic data included within the haptic effect definition that includes one or more low frequencies. The medium frequency channel includes a portion of the haptic data included within the haptic effect definition that includes one or more medium frequencies. The high frequency channel includes a portion of the haptic data included within the haptic effect definition that includes one or more high frequencies.

The system can then send the three channels of the haptic effect definition to F B spatialization where F B spatialization can modify the haptic data included within each channel of the haptic effect definition based on spatialization data. The spatialization data can include a direction and or flow of a haptic effect. In one embodiment the direction and or flow of the haptic effect can be a frontwards or backwards direction. Further spatialization data can include one or more hand positions. According to the embodiment F B spatialization can modify the haptic data included within each channel so that a haptic effect is scaled for each motor or actuator. The system can then send the low frequency channel to low rumble motor identified in as LowR motor and can further send the middle frequency channel to medium rumble motor identified in as MidR motor . The haptic data contained within the low frequency channel can cause low rumble motor to produce a general or rumble haptic effect and the haptic data contained within the medium frequency channel can cause medium rumble motor to produce a general or rumble haptic effect.

The system can further send the high frequency channel to L R spatialization where L R spatialization can modify the haptic data included within the high frequency channel based on spatialization data. In one embodiment the direction and or flow of the haptic effect can be a left or right direction. Further spatialization data can include one or more hand positions. According to the embodiment L R spatialization can modify the haptic data included within the channel so that a haptic effect is scaled for each motor or actuator. The system can then send the high frequency channel to left trigger targeted motor identified in as LT motor and can also send the high frequency channel to right trigger targeted motor identified in as RT motor . The haptic data contained within the high frequency channel can cause left trigger targeted motor to produce a trigger haptic effect at a left trigger and the haptic data contained within the high frequency channel can cause right trigger targeted motor to produce a trigger haptic effect at a right trigger.

According to the embodiment the system can send the four channels of the audio effect definition included within audio file to audio to haptic converter where audio to haptic converter can convert the audio effect definition into a haptic effect definition using a haptic conversion algorithm. In one embodiment each separate channel of the audio effect definition can be converted into a channel of a haptic effect definition. In the illustrated embodiment channel LR can be converted using a peak decimation filter with a range of less than 60 hertz Hz channel MR can be converted using a peak decimation filter with a value of 60 Hz and channels LT and RT can each be converted using a peak decimation filter with a range of 200 Hz 2 kHz.

The system can further send the four channels of the converted haptic effect definition to encoder decoder where encoder decoder can encode each channel of the converted haptic effect definition into an external format such as an HES format. The system can then send the four encoded channels of the converted haptic effect definition to F B spatialization where F B spatialization can modify the converted haptic data included within each encoded channel of the converted haptic effect definition based on spatialization data. The spatialization data can include a direction and or flow of a haptic effect. In one embodiment the direction and or flow of the haptic effect can be a frontwards or backwards direction. Further spatialization data can include one or more hand positions. According to the embodiment F B spatialization can modify the converted haptic data included within each encoded channel so that a haptic effect is scaled for each motor or actuator. The system can then send encoded channel LR to low rumble motor identified in as LowR motor and can further send encoded channel MR to medium rumble motor identified in as MidR motor . The converted haptic data contained within channel LR can cause low rumble motor to produce a general or rumble haptic effect and the converted haptic data contained within channel MR can cause medium rumble motor to produce a general or rumble haptic effect.

The system can further send encoded channels LT and RT to L R spatialization where L R spatialization can modify the converted haptic data included within encoded channels LT and RT based on spatialization data. The spatialization data can include a direction and or flow of a haptic effect. In one embodiment the direction and or flow of the haptic effect can be a left or right direction. Further spatialization data can include one or more hand positions. According to the embodiment L R spatialization can modify the haptic data included within each channel so that a haptic effect is scaled for each motor or actuator. The system can then send channel LT to left trigger targeted motor identified in as LT motor and can further send channel RT to right trigger targeted motor identified in as RT motor . The haptic data contained within channel LT can cause left trigger targeted motor to produce a trigger haptic effect at a left trigger and the haptic data contained within channel RT can cause right trigger targeted motor to produce a trigger haptic effect at a right trigger.

According to the embodiment the system can send the channel of the audio effect definition included within audio file and in one embodiment the one or more crossover parameters also included within audio file to programmable crossover . Programmable crossover can apply a crossover input warp algorithm in one embodiment using the one or more crossover parameters to separate the channel into three different channels a low frequency channel a medium frequency channel and a high frequency channel. Programmable crossover can further convert the audio effect definition into a haptic effect definition using a haptic conversion algorithm. In one embodiment each separate channel of the audio effect definition can be converted into a channel of a haptic effect definition. In the illustrated embodiment the low frequency channel can be converted using a peak decimation filter with a range of less than 60 hertz Hz the medium frequency channel can be converted using a peak decimation filter with a value of 60 Hz and the high frequency channel can each be converted using a peak decimation filter with a range of 200 Hz 2 kHz.

The system can further send the three channels of the converted haptic effect definition to encoder decoder where encoder decoder can encode each channel of the converted haptic effect definition into an external format such as an HES format. The system can then send the three channels of the haptic effect definition to F B spatialization where F B spatialization can modify the haptic data included within each channel of the haptic effect definition based on spatialization data. The spatialization data can include a direction and or flow of a haptic effect. In one embodiment the direction and or flow of the haptic effect can be a frontwards or backwards direction. Further spatialization data can include one or more hand positions. According to the embodiment F B spatialization can modify the haptic data included within each channel so that a haptic effect is scaled for each motor or actuator. The system can then send the low frequency channel to low rumble motor identified in as LowR motor and can further send the middle frequency channel to medium rumble motor identified in as MidR motor . The haptic data contained within the low frequency channel can cause low rumble motor to produce a general or rumble haptic effect and the haptic data contained within the medium frequency channel can cause medium rumble motor to produce a general or rumble haptic effect.

The system can further send the high frequency channel to L R spatialization where L R spatialization can modify the haptic data included within the high frequency channel based on spatialization data. In one embodiment the direction and or flow of the haptic effect can be a left or right direction. Further spatialization data can include one or more hand positions. According to the embodiment L R spatialization can modify the haptic data included within the channel so that a haptic effect is scaled for each motor or actuator. The system can then send the high frequency channel to left trigger targeted motor identified in as LT motor and can also send the high frequency channel to right trigger targeted motor identified in as RT motor . The haptic data contained within the high frequency channel can cause left trigger targeted motor to produce a trigger haptic effect at a left trigger and the haptic data contained within the high frequency channel can cause right trigger targeted motor to produce a trigger haptic effect at a right trigger.

Using user interface a user can create one or more trigger definitions where a trigger definition defines a condition that causes a trigger haptic effect to be generated or modified. In some embodiments a condition can be a position of a trigger where the position is within trigger input range . In other embodiments a condition can be a range of the trigger where the range is within trigger input range . User interface includes threshold trigger definition which is an example of a trigger definition. Threshold trigger definition causes a trigger haptic effect that is based on a specified trigger haptic effect definition to be generated when the trigger reaches a specified position where the specified position is in the illustrated embodiment. Threshold trigger definition can define that the trigger haptic effect be generated only on a press of the trigger only on a release of the trigger or both a press and a release of the trigger. In an alternate embodiment threshold trigger definition can be replaced with a position trigger definition that causes a trigger haptic effect that is based on a specified trigger haptic effect definition to only be generated when the trigger resides at a specified position as opposed to simply reaching the specified position. User interface further includes range trigger definition which is another example of a trigger definition. Range trigger definition causes a trigger haptic effect that is based on a specified trigger haptic effect definition to be generated when the trigger reaches a specified range where the specified range is 164 to 255 in the illustrated embodiment.

User interface includes flow . Flow allows a user to programmatically manage a flow of a trigger haptic effect. A flow is a temporal start of playback offset modification to delay playback on individual targeted motors targeted actuators rumble motors or rumble actuators of a controller. Alternatively a flow can be a duration modification to modify a duration of a haptic effect experienced at targeted motors targeted actuators rumble motors or rumble actuators of a controller. For example a flow can be defined so that haptic playback first begins on a left targeted motor or targeted actuator then subsequently begins on a middle rumble motor or rumble actuator and then further begins on a right targeted motor or targeted actuator. In this example a flow of the overall trigger haptic effect is left to right as a user of a controller first experiences the haptic playback of the overall trigger haptic effect at the left of the controller then at the middle of the controller and then at the right of the controller. A flow can be from left to right or vice versa front to back or vice versa or a combination of the two. Thus a flow can define a haptic playback vector. Flow can be visualized within user interface as an arrow that can be placed horizontally vertically or diagonally within user interface . Thus by interacting with flow a user can modify one or more delays applied to various motors or actuators of the controller to stagger haptic playback.

User interface further includes direction . Direction allows a user to programmatically modify a direction of a trigger haptic effect. A direction is a magnitude or strength modification to emphasize a front back and or left right bias or balance among various motors or actuators of a controller. Alternatively a direction can be a frequency modification. For example a direction can be defined so that haptic playback of the trigger haptic effect is the strongest at the right of the controller. Direction can be visualized within user interface as a point within a two dimensional grid or space defined by two axes. Thus by interacting with direction a user can modify magnitudes or strengths applied to various motors or actuators to emphasize a left right and or front back bias or balance .

User interface further includes strength . Strength allows a user to programmatically modify a magnitude or strength of an overall trigger haptic effect either before or during playback. Strength can be visualized within user interface as a slider. Thus by interacting with strength a user can modify an overall magnitude or strength of a trigger haptic effect. User interface further includes play speed . Play speed allows a user to programmatically modify a play speed or rate at which a system such as system of processes a trigger haptic effect definition of a trigger haptic effect in order to playback the trigger haptic effect. Play speed can be visualized within user interface as a slider. Thus by interacting with play speed a user can modify a play speed or rate of a trigger haptic effect. User interface further includes loop . Loop allows a user to programmatically modify whether a playback of a trigger haptic effect loops or not. Loop can be visualized within user interface as a button. Thus by interacting with loop a user can control a looping of a trigger haptic effect. Further details of a spatialization engine are further described below in greater detail in conjunction with .

According to the embodiment trigger haptic effect API can be accessed by application which is a software application such as a game application that can be executed on a system such as system of . Further trigger haptic effect API can access an effect library where effect library can include one or more haptic effect definitions such as haptic effect definition identified in as effect . As previously described an example of a haptic effect definition is a trigger haptic effect definition. Further trigger haptic effect API includes one or more device definitions such as device definition identified in as device . A device definition includes device data that defines a hardware device such as a controller gamepad or other peripheral device where a haptic effect is to be played. Trigger haptic effect API further includes one or more timer definitions such as timer definition identified in as timer . A timer definition includes timer data that defines a time period where all haptic effect definitions registered to a specific hardware device are updated. Trigger haptic effect API further includes trigger definition identified in as trigger . A trigger definition includes trigger data that defines a trigger of a specific hardware device. Trigger haptic effect API further includes protocol definition identified in as protocol . A protocol definition describes a protocol of a communication interface used by trigger haptic effect API to communicate with a specific hardware device. Using protocol definition trigger haptic effect API can communicate with device firmware identified in as FW where device firmware is firmware for the specific hardware device. Using device firmware trigger haptic effect API can further communicate with hardware device identified in as HW where hardware device is the specific hardware device.

In one embodiment application can access device definition to acquire a target hardware device i.e. HW where a haptic effect is to be played. By accessing device definition application can further access timer definition trigger definition and protocol definition . Application can further access haptic effect definition from effect library to instantiate a haptic effect. Application can further cause the haptic effect be played at the target hardware device i.e. HW by sending an instruction to the target hardware device i.e. HW via trigger haptic effect API and FW .

The architecture further includes trigger engine . As previously described trigger engine can receive a trigger haptic effect definition and can modify the trigger haptic effect definition based on trigger data such as a position and or range of a trigger of a controller. The architecture further includes trigger hardware interface identified in as trigger HW interface . Trigger hardware interface is a communication interface that allows trigger engine to receive trigger data from a peripheral device such as a controller or gamepad. The architecture further includes spatialization engine . As previously described spatialization engine can modify a haptic effect definition such as a trigger haptic effect definition so that a haptic effect such as a trigger haptic effect is scaled for one or more targeted motors targeted actuators rumble motors or rumble actuators of a controller. The architecture further includes basis effect rendering engine . Basis effect rendering engine renders a haptic effect such as a trigger haptic effect for a motor or actuator based on a haptic effect definition such as a trigger haptic effect definition. The architecture further includes actuator hardware interface identified in as actuator HW interface . Actuator hardware interface is a communication interface that allows basis effect rendering engine to send haptic data included within the rendered haptic effect to a motor or actuator to cause the motor or actuator to play the haptic effect.

One type of a built in haptic effect definition is static haptic effect definition identified in as static . Static haptic effect definition is a set of one or more periodic or magnitude sweep effect definitions that produce a static haptic effect that does not change over time. Examples include a car crash a rocket launcher and a user interface confirmation. Static haptic effect definition can be called directly by application based on events within a game. A static haptic effect produced by static haptic effect definition can be used as a trigger haptic effect.

Another type of a built in haptic effect definition is dynamic haptic effect definition identified in as dynamic . Dynamic haptic effect definition is an algorithm that receives one or more parameters as input and produces a continuously changing haptic effect i.e. a dynamic haptic effect . Examples include an engine s revolutions per minute RPM a snowboard and an explosion. A static haptic effect definition can be turned into a dynamic haptic effect definition by including a vector i.e. distance and direction and an input position state of one or more buttons or axes . A dynamic haptic effect can be based on game variables that can be passed from application . A dynamic haptic effect can also be based on controller input such as trigger input.

Another type of a built in haptic effect definition is direct control haptic effect definition identified in as direct control . In a direct control scenario direct control haptic effect definition can be defined in a way that allows direct rendering to the output device with very little processing applied to direct control haptic effect definition as it travels through core effect library . In this scenario direct control haptic effect definition can include a number of distinct data channels that corresponds to and maps exactly to a number of output actuators on an output device. Alternately direct control haptic effect definition can contain a number of distinct data channels that exceeds the number of available output actuators on the output device and core effect library can select a number of channels where each channel is selected such that it best maps to a particular actuator in the output device and core effect library can then transmit the selected channels data to the mapped actuators.

The system further includes core effect library identified in as core . Core effect library includes one or more haptic effect definitions identified in as FX . Haptic effect definitions can include trigger haptic effect definitions identified in as trigger effects . Examples of haptic effect definitions can include explosion haptic effect definitions RPM haptic effect definitions snowboard haptic effect definitions and other haptic effect definitions. Core effect library further includes mixer identified in as mixer prioritization . Mixer can mix or prioritize one or more haptic effect definitions.

The system further includes low level API . Low level API can receive an instruction to play a haptic effect based on a haptic effect definition and can convert the instruction to a low level instruction that can be interpreted by a controller . An example of low level API is Xbox API by Microsoft Corporation and an example of controller is Xbox controller by Microsoft Corporation.

User interface further includes timeline . According to the embodiment a user can select a haptic effect preset displayed within open effects and timeline can display a graphical representation of the haptic effect definition that is represented by the selected haptic effect preset. In the illustrated embodiment the haptic effect definition includes four channels with each channel including haptic data that is mapped for a specific output e.g. 1 targeted motor or actuator for a right trigger 2 targeted motor or actuator for a left trigger 3 right rumble motor or actuator and 4 left rumble motor or actuator and each channel being displayed along the timeline. However in other embodiments the haptic effect definition can include any number of channels. Further a user can modify one or more channels of the selected haptic effect definition by interacting with one or more display elements within timeline . By modifying one or more channels of a haptic effect definition one can modify one or more attributes of a corresponding haptic effect.

User interface further includes effect properties . Effect properties is an editable visual area that can visualize a trigger haptic effect that is generated by a trigger engine such as trigger engine of . As previously described a trigger engine can receive a trigger haptic effect definition and can modify the trigger haptic effect definition based on a position and or range of a trigger of a controller. Thus effect properties can display a visualization of the trigger including an actual position of the trigger. Further effect properties can display a position and or range of the trigger that is defined for a trigger haptic effect definition where the position and or range can cause the trigger engine to modify the trigger haptic effect definition. A user can edit the position and or range of the trigger that is defined for the trigger haptic effect definition. Further effect properties can display a list of triggers for a controller so the user can edit the trigger that is defined for the trigger haptic effect definition. Even further effect properties can display a magnitude or strength of the trigger haptic effect definition and a user can modify the magnitude or strength .

User interface further includes spatialization . Spatialization is an editable visual area that can visualize a trigger haptic effect that is originally generated by the trigger engine and further modified by a spatialization engine such as spatialization engine of . As previously described the spatialization engine can modify the trigger haptic effect definition so that a trigger haptic effect is scaled for one or more targeted motors targeted actuators rumble motors or rumble actuators of a controller. Thus spatialization can display a visualization of the controller. Spatialization can further display a visualization of the trigger haptic effect experienced at each targeted motor targeted actuator rumble motor or rumble actuator of the controller. A user can edit a scaling of the trigger haptic effect that is experienced at each targeted motor targeted actuator rumble motor or rumble actuator of the controller as well as edit a scaling of a source of the trigger haptic effect.

User interface includes plotter . Plotter takes a haptic effect definition specified by a user as input and sends the haptic data includes within the haptic effect definition through adapter layer to trigger API layer . Trigger API layer sends back individual channel data that plotter displays within user interface . Render takes input from controller GUI and starts a haptic player render loop. The input is routed through adapter layer which has callbacks setup with trigger API layer to and relay controller input such as button and trigger input sent from controller . Adapter layer can also communicate with plotter while the render loop is running to update user interface . Controller GUI can also select controller using controller selector and can show what is connected. Controller GUI can also set up a trigger activation point. Further importer exporter can take input audio files and convert them to a haptic file. In one embodiment an audio file is a WAV file. Further adapter layer can be embedded within user interface or can be a separate library. When adapter layer is a separate library adapter layer can be a separate C library.

The system further includes haptic engine . Haptic engine is a high level API that can utilize a low level API to perform the playing of a haptic effect and to add haptic effects to game application . Haptic engine can load start stop and render a haptic effect. Haptic engine can interface with haptic effect parser to parse get information about a haptic effect. Haptic engine can further interface with haptic mixer to start or stop an effect and modify a mixer buffer. Haptic engine can further interface with haptic device handler to get a device handle of and render haptic effects on a controller gamepad or other peripheral device.

The system further includes haptic effect parser . Haptic effect parser includes an API that can load a haptic effect in memory verify its format and obtain information about the haptic effect such as size duration and haptic data. The system further includes haptic mixer . Haptic mixer supports playback of multiple haptic effects at the same time. The system further includes haptic device handler . Haptic device handler can initiate and manage communication with a controller gamepad or other peripheral device. Haptic device handler can interface with a Universal Serial Bus USB communication layer and obtain a device handle of the controller gamepad or other peripheral device. Haptic device handler can further initialize several state machine structures critical for haptic effect playback.

The system further includes trigger haptic report handler . Trigger haptic report handler can package haptic data into USB HID packets according to a trigger communication protocol. The system further includes platform compliant USB HID library . Platform compliant USB HID library includes one or more computer readable routines to interface with USB HID and Bluetooth HID class of controllers gamepads or other peripheral devices. The system further includes peripheral firmware identified in as gamepad firmware . Peripheral firmware is firmware for a controller gamepad or other peripheral device. The system further includes peripheral input reader identified in as gamepad input reader . Peripheral input reader receives peripheral input that is sent by the controller gamepad or other peripheral device. Peripheral input reader further interprets the peripheral input and sends the peripheral input to game application .

In one embodiment a controller gamepad or other peripheral device can have a customized protocol for conveying haptic data and for driving individual motors or actuators. Accordingly an audio driver can be provided that receives an audio file that includes a haptic effect authored as an audio effect definition from an audio authoring component and that sends the audio data included within the audio file to the controller gamepad or other peripheral device. In one embodiment the audio authoring component can be a Pro Tools product by Avid Technology Inc. The audio driver can get loaded during a boot up process. The audio driver can expose a necessary number of audio channels in order to make haptic effect definitions possible for using all the motors or actuators in the controller gamepad or other peripheral device. The audio driver can further work in user space and can be accessible to all user space audio editing playback applications. The audio driver can further read the audio data that an audio authoring component sends to the controller gamepad or other peripheral device. The audio driver can further perform necessary processing on the audio data being presented and can convert the audio data into haptic data such as actuator drive values. The audio driver can further communicate the haptic data to the controller gamepad or other peripheral device over a communication interface.

According to the embodiment a controller gamepad or other peripheral device can include four actuators. Two actuators can be used as trigger actuators influencing haptic feedback on triggers. The trigger actuators can be bi directional. Two kinds of direction events can happen with the trigger actuators PUSH and PULL. The PUSH and PULL directions can be relative to a user s finger on the trigger. Two other actuators can be used as rumble actuators influencing general haptic feedback or rumble feedback within the controller gamepad or other peripheral device. The rumble actuators can be uni directional. More specifically the rumble actuators can spin in either a clockwise direction or a counter clockwise direction but not both directions. The direction of the motion can be dependent on the controller and or the drive electronics of the controller.

In one embodiment an audio format chosen for a 16 bit PCM can be 44.1 KHz. The audio driver can receive the audio data from an audio authoring component convert the audio data into haptic data e.g. drive values and communicate the haptic data to the controller accordingly.

Subsequently trigger protocol packet manager obtains drive values for all the actuators e.g. all four actuators and packages the drive values as data packets such as USB HID packets according to a trigger communication protocol. Further XPC handler receives the data packets from trigger protocol packet manager and sends the data packets to XPC service which is a background service. At XPC service receives the data packets and at sends the data packets to to a controller identified in as haptic trigger gamepad over a USB interface.

The flow begins and proceeds to . At an audio effect definition including audio data is converted into a haptic effect definition including haptic data. In one embodiment the haptic effect definition can define a haptic effect that can be experienced at a user input element of a peripheral device or that can be experienced at the peripheral device. Further in one embodiment a user input element can be a trigger and a peripheral device can be a controller or gamepad. The flow then proceeds to . At the haptic effect definition is received. In one embodiment the haptic effect definition can be a trigger haptic effect definition. Further in an embodiment the haptic effect definition can recreate a haptic effect of a different format. The flow then proceeds to .

At the haptic data of the haptic effect definition is modified based on received spatialization data. The spatialization data can include at least one of a direction of the haptic effect or a flow of the haptic effect. In certain embodiments the modifying the haptic data of the haptic effect definition can include scaling at least one of a magnitude of the haptic data a frequency of the haptic data or a duration of the haptic data. The flow then proceeds to . At trigger data is received. The trigger data can include at least one of a position of the trigger of the peripheral device or a range of the trigger of the peripheral device. The flow then proceeds to .

At it is determined whether a trigger condition is reached based on the received trigger data. The flow then proceeds to . At the haptic data of the haptic effect definition is encoded. In certain embodiments the haptic data of the haptic effect definition can be encoded within an audio file or audio stream. The flow then proceeds to .

At a haptic instruction and the haptic effect definition are sent to the peripheral device. In certain embodiments the haptic instruction and the haptic effect definition can be sent to the peripheral device when the trigger condition is reached. In these embodiments the haptic instruction can be a trigger instruction. In certain embodiments the sending the haptic effect definition to the peripheral device can include directly sending the haptic data of the haptic effect definition to the peripheral device. In other embodiments the sending the haptic effect definition to the peripheral device can include 1 converting the haptic data of the haptic effect definition from a first format to a second format and 2 sending the converted haptic data of the haptic effect definition to the peripheral device. The flow then proceeds to .

At the encoded haptic data of the haptic effect definition is decoded. In certain embodiments the encoded haptic data can be decoded by computing a programmable crossover. The flow then proceeds to . At the haptic instruction causes a haptic output device to produce a haptic effect based on the haptic effect definition at the peripheral device. In certain embodiments the haptic instruction can cause the haptic output device to produce the haptic effect based on the haptic effect definition at the user input element of the peripheral device. In certain embodiments the haptic instruction can be a trigger instruction the haptic effect definition can be a trigger haptic effect definition the haptic output device can be a targeted haptic output device and the targeted haptic output device can produce the haptic effect at a trigger of the peripheral device. In certain embodiments the targeted haptic output device can be a targeted actuator. In some of those embodiments the targeted actuator can be a targeted motor. Further in certain embodiments the haptic instruction can cause multiple haptic output devices to produce multiple haptic effects based on the haptic effect definition at the peripheral device. The flow then ends.

In an embodiment as previously described a spatialization engine can receive haptic data such as a trigger haptic effect definition and can modify the haptic data based on spatialization data where spatialization data can include one or more parameters. Thus the spatialization engine can localize or spatialize haptic effects. More specifically the spatialization engine can produce a haptic effect that conveys a distance of the haptic effect by scaling or attenuating the haptic effect on an actuator or motor based on the distance of the haptic effect. The spatialization engine can further produce a haptic effect that conveys movement on a controller gamepad or other peripheral device by delaying or scaling the haptic effect on different actuators or motors. The spatialization engine can be a component of an API or library or can be implemented in firmware for a controller gamepad or other peripheral device.

Device includes effect library where effect library can include one or more haptic effect definitions. In the embodiment these haptic effect definitions can be identified as unspatialized haptic effect definitions as they are haptic effect definitions that have not been modified by a spatialization engine. Device further includes game where game is a software application such as a game application that can be executed on the system. According to the embodiment game can generate one or more spatialization parameters where the one or more spatialization parameters can define a position velocity direction and or flow of a haptic effect defined by a haptic effect definition that is stored within effect library .

Device further includes spatialization engine identified in as haptic spatialization engine where effect library can send one or more unspatialized haptic effect definitions to spatialization engine and where game can send one or more spatialization parameters to spatialization engine . Spatialization engine can receive the one or more unspatialized haptic effect definitions and can modify the one or more unspatialized haptic effect definitions based on the one or more spatialization parameters. According to the embodiment spatialization engine can modify the one or more unspatialized haptic effect definitions so that one or more haptic effects are scaled or attenuated for one or more actuators of controller where the one or more modified haptic effect definitions can be identified as spatialized haptic effect definitions. In other words spatialization engine can modify the haptic effect definition that is sent to each actuator of actuators and thus modify the haptic effect that is experienced at each actuator of actuators in order to convey a sense of position velocity direction and or flow of the haptic effect. Spatialization engine can subsequently send the one or more spatialized haptic effect definitions to controller . Controller can subsequently send each spatialized haptic effect definition to each actuator of actuators where each actuator can produce a spatialized haptic effect.

Device includes effect library where effect library can include one or more haptic effect definitions identified as unspatialized haptic effect definitions. Device further includes game where game is a software application such as a game application that can be executed on the system. According to the embodiment game can generate one or more spatialization parameters where the one or more spatialization parameters can define a position velocity direction and or flow of a haptic effect defined by a haptic effect definition that is stored within effect library .

Controller includes spatialization engine identified in as haptic spatialization engine where effect library can send one or more unspatialized haptic effect definitions to spatialization engine and where game can send one or more spatialization parameters to spatialization engine . Spatialization engine can receive the one or more unspatialized haptic effect definitions and can modify the one or more unspatialized haptic effect definitions based on the one or more spatialization parameters where the one or more modified haptic effect definitions are identified as spatialized haptic effect definitions. Spatialization engine can subsequently send each spatialized haptic effect definition to each actuator of actuators where each actuator can produce a spatialized haptic effect.

Thus in one embodiment a system can provide a haptic control architecture that can generate a haptic effect that is experienced at a peripheral device such as a controller or gamepad. The haptic effect can be a trigger haptic effect that is experienced at a trigger of the peripheral device. The trigger haptic effect can be customized by the haptic control architecture based on trigger data that is received by the system where the trigger data can include a position and or range of the trigger. The trigger haptic effect can be further spatialized by the haptic control architecture so that the trigger haptic effect is scaled at each motor or actuator of the peripheral device so that the trigger haptic effect includes a sense of directionality and or flow. By incorporating haptic feedback experienced at a peripheral device and in particular haptic feedback experienced at a trigger of the peripheral device into a gaming application that is executed by the system a more realistic and immersive gaming experience can be provided.

The features structures or characteristics of the invention described throughout this specification may be combined in any suitable manner in one or more embodiments. For example the usage of one embodiment some embodiments certain embodiment certain embodiments or other similar language throughout this specification refers to the fact that a particular feature structure or characteristic described in connection with the embodiment may be included in at least one embodiment of the present invention. Thus appearances of the phrases one embodiment some embodiments a certain embodiment certain embodiments or other similar language throughout this specification do not necessarily all refer to the same group of embodiments and the described features structures or characteristics may be combined in any suitable manner in one or more embodiments.

One having ordinary skill in the art will readily understand that the invention as discussed above may be practiced with steps in a different order and or with elements in configurations which are different than those which are disclosed. Therefore although the invention has been described based upon these preferred embodiments it would be apparent to those of skill in the art that certain modifications variations and alternative constructions would be apparent while remaining within the spirit and scope of the invention. In order to determine the metes and bounds of the invention therefore reference should be made to the appended claims.

