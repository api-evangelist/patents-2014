---

title: Distributed system architecture using event stream processing
abstract: A system and method for performing event stream processing is described. A plurality of event streams are received from a plurality of input adapters, at least a first input adapter of the plurality of input adapters being located on a separate and distinct virtual machine than a second input adapter of the plurality of input adapters. Event stream data from the first input adapter and event stream data from the second input adapter are transformed into data of a single data type. The transformed data is stored in an in-memory database. Then real-time analysis is performed on the transformed data by accessing windows of the transformed data from the in-memory database based on rules defined in the event stream processing engine.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09548910&OS=09548910&RS=09548910
owner: SAP SE
number: 09548910
owner_city: Walldorf
owner_country: DE
publication_date: 20140521
---
This document generally relates to systems and methods for use with a distributed system architecture. More specifically this document relates to methods and systems for a distributed system architecture using event stream processing.

Event stream processing ESP is a set of technologies designed to assist the construction of event driven information systems. ESP technologies can include event visualization event databases event driven middleware and event processing languages or complex event processing CEP . ESP deals with the task of processing multiple streams of event data with the goal of identifying the meaningful events within those streams. ESP enables applications such as algorithmic trading in financial services radio frequency identification RFID event processing applications fraud detection process monitoring and location based services in mobile devices. Within an ESP system a continuous data stream comprising multiple consecutive data items is pushed through a query. Results of the query are subsequently pushed out of the system. While ESP systems generally work well for smaller to medium sized systems scaling becomes a problem in larger systems. Specifically function bundles deployed on multiple virtual machines are not able to transfer and process data in an efficient enough manner to ensure reliability and speed in high frequency event stream scenarios such as high frequency securities trading and real time sales reporting.

The description that follows includes illustrative systems methods techniques instruction sequences and computing machine program products that embody illustrative embodiments. In the following description for purposes of explanation numerous specific details are set forth in order to provide an understanding of various embodiments of the inventive subject matter. It will be evident however to those skilled in the art that embodiments of the inventive subject matter can be practiced without these specific details. In general well known instruction instances protocols structures and techniques have not been shown in detail.

In an example embodiment a complex event processing CEP engine is used as a routing and data transformation engine in a cloud environment to achieve better performance modularization and extensibility. Data can be published to the CEP engine via adapters without being hosted on the same virtual machine and without utilizing restrictive tenant concepts. Restrictive tenant concepts will be described in more detail below. Data can be pulled from other clouds by the CEP engine. Multiple disparate data types flowing from various providers can be transformed inside the CEP engine into a standard for consumption. Processed data can then be stored in an in memory database and read from windows which improves performance. Duplicates can then be checked for and advanced business process modeling techniques can be performed using CEP in real time in an efficient and speedy manner allowing the system to handle high frequency events.

The ESP engine can also communicate with an internal database A. In an example embodiment the ESP engine acts as a routing and data transformation engine that operates with the internal database A to allow for the publishing of data for CEP via adapters without being hosted on the same virtual machine and without using restrictive tenant concepts to allow for significantly increased performance in scaled scenarios.

While this database A is labeled as internal it is possible that the database A resides on separate hardware than the ESP engine . The distinction between an internal database A and external database A C is that the internal database A can be more natively supported for communication purposes with the ESP engine . In an example embodiment the internal database A and ESP engine are both designed by the same software provider whereas the external databases A C are designed by other software providers. The communication between the ESP engine and the internal database A can be performed via one or more output adapters . It should be noted that in some example embodiments the output adapters may be unnecessary. Additionally the ESP engine can communicate with for example operational applications B spreadsheets or visualization applications C and reporting business intelligence BI tools D.

In an example embodiment the internal database A is an in memory database. An in memory database is a database management system that primarily relies on main memory for computer data storage. It is contrasted with database management systems that employ a disk storage mechanism.

Also depicted is a studio used to perform modeling by accessing the in memory database management system . In an example embodiment integration of ESP functionality e.g. storing of event information into the internal database A occurs through studio . The studio can allow complex analysis to be performed on data drawn from not only real time event data and windows but also from stored database information.

The in memory database management system can comprise a number of different components including index server XS engine statistics server preprocessor server and name server . These components can operate on a single computing device or can be spread among multiple computing devices e.g. separate servers .

The index server contains the actual data and the engines for processing the data. The index server also coordinates and uses all the other servers.

The XS engine allows clients to connect to the database system using web protocols such as Hypertext Transfer Protocol HTTP .

The statistics server collects information about status performance and resource consumption from all the other server components. The statistics server can be accessed from the studio to obtain the status of various alert monitors.

The preprocessor server is used for analyzing text data and extracting the information on which the text search capabilities are based.

The name server holds information about the database topology. This is used in a distributed system with instances of the database on different hosts. The name server knows where the components are running and which data is located on which server.

Between the ESP engine and the in memory database management system an architecture is provided that can work at both the machine time scale as well as at the human time scale. The XS engine which can include a definition language can be used to provide human computer interactions. The XS engine can communicate directly with the ESP engine and the index server . The index server can be used for data analysis of past events.

The interaction between the ESP engine XS engine and index server allows the architecture to provide high speed analysis from various data sources without the data sources or their corresponding adapters residing on the same virtual machine and without using restrictive tenant concepts. In an example embodiment the ESP engine is able to access all of the streamed data over the course of a day or at least be tightly integrated with the index server so that the two together can access all of the streamed data over the course of a day. In the latter case a large channel can be provided between the ESP engine and the index server to absorb the entire data stream so the entire data stream can be persisted in the index server . A second smaller channel can be provided from the index server back to the ESP engine so that the ESP engine can combine the historical data calculation of the index server with real time stream calculations from the ESP engine . Both the ESP engine and the index server can also open channels to the XS engine so that the ESP engine and index server can respond to any human agent requests.

As stated earlier this solution does not require the data sources or their adapters to be hosted on the same virtual machine. Additionally this solution does not need to rely on a restrictive tenant arrangement. A restrictive tenant arrangement is one where each customer tenant is provided a dedicated space on a common shared architecture and each customer tenant is restricted to only accessing that particular dedicated space. While this dedicated space can be spread out over multiple physical machines in a cloud or cloud like environment each customer tenant is still dedicated particular space and is restricted to access only that dedicated space.

Additionally the ESP engine can act to transform multiple disparate data types flowing from the different input data streams A E via adapters A E. These can be transformed into a single data type for use by the in memory database management system to allow for easy and efficient analysis. In an example embodiment the transformation can be to a standard data type. The ESP engine can also act to check for duplicates in the transformed data and perform advanced business process modeling.

Traditional ESP functionality allows for event data to be analyzed in the form of both real time streams and windows. Traditional ESP functionality also includes the ability to join streams and windows. In an example embodiment however these windows are read directly from an in memory database significantly improving performance. Additionally through data integration the ESP engine can also allow joining streams and windows with database tables. This allows for the possibility of including persisted data in real time continuous queries.

The ESP engine can access the table data during joins as needed and fetch table data in real time. Alternatively table data can be cached based on user configuration.

The ESP engine can also store and utilize one or more defined rules which can be executed in real time to act on the data from the input data streams A E. These rules can be defined by for example an administrator wishing to perform certain analysis or filtering of the event data. The rules can be for example mathematical models or business semantics. The rules can also define how the ESP engine interacts with the index server and or XS engine .

The client requests can be analyzed and executed by a set of components summarized as request processing and execution control . The SQL processor checks the syntax and semantics of the client SQL statements and generates a logical execution plan. Multidimensional expressions MDX is a language for querying and manipulating multidimensional data stored in Online Analytical Programming OLAP cubes. As such an MDX engine is provided to allow for the parsing and executing of MDX commands. A planning engine allows applications e.g. financial planning applications to execute basic planning operations in the database layer. One such operation is to create a new version of a dataset as a copy of an existing dataset while applying filters and transformations. Aspects described above of the present solution can be implemented in the planning engine . Specifically the planning engine can be used to persist real time streaming information from an ESP engine as well as provide real time analysis of event stream information stored in the relational stores .

A calc engine implements the various SQL script and planning operations. The calc engine creates a logical execution plan for calculation models derived from SQL script MDX planning and domain specific models. This logical execution plan can include for example breaking up a model into operations that can be processed in parallel.

Each SQL statement can be processed in the context of a transaction. New sessions are implicitly assigned to a new transaction. The transaction manager coordinates database transactions controls transactional isolation and keeps track of running and closed transactions. When a transaction is committed or rolled back the transaction manager informs the involved engines about this event so the engines can execute needed actions. The transaction manager also cooperates with a persistence layer to achieve atomic and durable transactions.

An authorization manager is invoked by other database system components to check whether the user has the specified privileges to execute the requested operations. The database system allows for the granting of privileges to users or roles. A privilege grants the right to perform a specified operation on a specified object.

The persistence layer ensures that the database is restored to the most recent committed state after a restart and that transactions are either completely executed or completely undone. To achieve this goal in an efficient way the persistence layer uses a combination of write ahead logs shadow paging and save points. The persistence layer also offers a page management interface for writing and reading data to a separate disk storage and also contains a logger that manages the transaction log. Log entries can be written implicitly by the persistence layer when data is written via the persistence interface or explicitly by using a log interface.

An example will be provided herein of a banking environment. is a block diagram illustrating a system for use in a banking environment in accordance with this example embodiment. This diagram presents a simplified version of the components described above with respect to . The system includes an in memory database management system having an index server and an XS engine . The XS engine can perform tasks such as a credit check and a risk assessment . These tasks can be performed for example in anticipation of a securities trade. For example a customer can be on the phone with a trade desk asking to perform a securities trade. The trade desk can then use the XS engine to perform a credit check and risk assessment for the customer which can then be performed and results displayed in less than a second. Essentially the trade desk can ask a question of the XS engine while on the phone with the customer and receive an immediate answer. The customer data can be synced to the XS engine from either the index server or other systems. This could be a batch or a real time update based on executions.

After satisfying the customer s and trade desk s questions the trade desk can negotiate an order with the customer. The trade desk is able to look at real time calculations from the ESP engine based on event data from the trading system to meet the customer s need in almost instantaneous fashion. These calculations are run on high volumes of real time data feeds from trading systems to the ESP engine . Once the trade desk executes a negotiated order best price match for trade the execution data is written from the ESP engine to the index server as well as any other systems of choice using a high performance output adapter . This data may include outstanding orders and executions . This high performance output adapter can be designed specifically to be used with the in memory database management system and can be built into the ESP engine .

Notably the ESP engine acts as a bridge between the trading system and the in memory database management system and also as a bridge between the index server and the XS engine .

At operation event stream data from the first input adapter and event stream data from the second input adapter can be transformed into a single data type. In one example the event stream data from the second input adapter can be changed into the data type of the event stream data from the first input adapter . In another example the event stream data from the first input adapter can be changed into the data type of the event stream data from the second input adapter . In another example the event stream data from the first input adapter and the event stream data from the second input adapter can both be changed into a data type not used by either the event stream data from the first input adapter or the event stream data from the second input adapter . The organization of the event stream data from both the first input adapter and the second input adapter can be altered so that the formats are identical e.g. the beginnings of similar or identical fields line up . In an example embodiment operation can be performed by an ESP engine such as the ESP engine of .

At operation the transformed data is stored in an in memory database. In an example embodiment operation can be performed by an in memory database management system such as in memory database management system of or more precisely by the index server of .

At operation real time analysis is performed on the transformed data by accessing windows of the transformed data from the in memory database based on rules defined in the event stream processing engine. In an example embodiment this real time analysis can be performed by the ESP engine of based on input from the XS server of .

In an example embodiment the ESP engine and the in memory database management system are part of a first cloud. In such a case the ESP engine is able to process event streams of data from the first cloud as well as from other clouds and can also retrieve additional non event stream information from other clouds for use in executing the rules for processing the event stream information from the adapters in the first cloud.

Certain embodiments are described herein as including logic or a number of components modules or mechanisms. Modules can constitute either software modules e.g. code embodied 1 on a non transitory machine readable medium or 2 in a transmission signal or hardware implemented modules. A hardware implemented module is a tangible unit capable of performing certain operations and can be configured or arranged in a certain manner. In example embodiments one or more computer systems e.g. a standalone client or server computer system or one or more processors can be configured by software e.g. an application or application portion as a hardware implemented module that operates to perform certain operations as described herein.

In various embodiments a hardware implemented module can be implemented mechanically or electronically. For example a hardware implemented module can comprise dedicated circuitry or logic that is permanently configured e.g. as a special purpose processor such as a field programmable gate array FPGA or an application specific integrated circuit ASIC to perform certain operations. A hardware implemented module can also comprise programmable logic or circuitry e.g. as encompassed within a general purpose processor or other programmable processor that is temporarily configured by software to perform certain operations. It will be appreciated that the decision to implement a hardware implemented module mechanically in dedicated and permanently configured circuitry or in temporarily configured circuitry e.g. configured by software can be driven by cost and time considerations.

Accordingly the term hardware implemented module should be understood to encompass a tangible entity be that an entity that is physically constructed permanently configured e.g. hardwired or temporarily or transitorily configured e.g. programmed to operate in a certain manner and or to perform certain operations described herein. Considering embodiments in which hardware implemented modules are temporarily configured e.g. programmed each of the hardware implemented modules need not be configured or instantiated at any one instance in time. For example where the hardware implemented modules comprise a general purpose processor configured using software the general purpose processor can be configured as respective different hardware implemented modules at different times. Software can accordingly configure a processor for example to constitute a particular hardware implemented module at one instance of time and to constitute a different hardware implemented module at a different instance of time.

Hardware implemented modules can provide information to and receive information from other hardware implemented modules. Accordingly the described hardware implemented modules can be regarded as being communicatively coupled. Where multiple of such hardware implemented modules exist contemporaneously communications can be achieved through signal transmission e.g. over appropriate circuits and buses that connect the hardware implemented modules . In embodiments in which multiple hardware implemented modules are configured or instantiated at different times communications between such hardware implemented modules can be achieved for example through the storage and retrieval of information in memory structures to which the multiple hardware implemented modules have access. For example one hardware implemented module can perform an operation and store the output of that operation in a memory device to which it is communicatively coupled. A further hardware implemented module can then at a later time access the memory device to retrieve and process the stored output. Hardware implemented modules can also initiate communications with input or output devices and can operate on a resource e.g. a collection of information .

The various operations of example methods described herein can be performed at least partially by one or more processors that are temporarily configured e.g. by software or permanently configured to perform the relevant operations. Whether temporarily or permanently configured such processors can constitute processor implemented modules that operate to perform one or more operations or functions. The modules referred to herein can in some example embodiments comprise processor implemented modules.

Similarly the methods described herein can be at least partially processor implemented. For example at least some of the operations of a method can be performed by one or processors or processor implemented modules. The performance of certain of the operations can be distributed among the one or more processors not only residing within a single machine but deployed across a number of machines. In some example embodiments the processor or processors can be located in a single location e.g. within a home environment an office environment or as a server farm while in other embodiments the processors can be distributed across a number of locations.

The one or more processors can also operate to support performance of the relevant operations in a cloud computing environment or as a software as a service SaaS . For example at least some of the operations can be performed by a group of computers as examples of machines including processors these operations being accessible via a network e.g. the Internet and via one or more appropriate interfaces e.g. application program interfaces APIs . 

Example embodiments can be implemented in digital electronic circuitry or in computer hardware firmware software or in combinations of them. Example embodiments can be implemented using a computer program product e.g. a computer program tangibly embodied in an information carrier e.g. in a machine readable medium for execution by or to control the operation of data processing apparatus e.g. a programmable processor a computer or multiple computers.

A computer program can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module subroutine or other unit suitable for use in a computing environment. A computer program can be deployed to be executed on one computer or on multiple computers at one site or distributed across multiple sites and interconnected by a communication network.

In example embodiments operations can be performed by one or more programmable processors executing a computer program to perform functions by operating on input data and generating output. Method operations can also be performed by and apparatus of example embodiments can be implemented as special purpose logic circuitry e.g. a field programmable gate array FPGA or an application specific integrated circuit ASIC .

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other. In embodiments deploying a programmable computing system it will be appreciated that both hardware and software architectures require consideration. Specifically it will be appreciated that the choice of whether to implement certain functionality in permanently configured hardware e.g. an ASIC in temporarily configured hardware e.g. a combination of software and a programmable processor or a combination of permanently and temporarily configured hardware can be a design choice. Below are set out hardware e.g. machine and software architectures that can be deployed in various example embodiments.

The example computer system includes a processor e.g. a central processing unit CPU a graphics processing unit GPU or both a main memory and a static memory which communicate with each other via a bus . The computer system can further include a video display unit e.g. a liquid crystal display LCD or a cathode ray tube CRT . The computer system also includes an alphanumeric input device e.g. a keyboard or a touch sensitive display screen a user interface UI navigation device e.g. a mouse a disk drive unit a signal generation device e.g. a speaker and a network interface device .

The disk drive unit includes a machine readable medium on which is stored one or more sets of instructions and data structures e.g. software embodying or utilized by any one or more of the methodologies or functions described herein. The instructions can also reside completely or at least partially within the main memory and or within the processor during execution thereof by the computer system the main memory and the processor also constituting machine readable media .

While the machine readable medium is shown in an example embodiment to be a single medium the term machine readable medium can include a single medium or multiple media e.g. a centralized or distributed database and or associated caches and servers that store the one or more instructions or data structures. The term machine readable medium shall also be taken to include any tangible medium that is capable of storing encoding or carrying instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present disclosure or that is capable of storing encoding or carrying data structures utilized by or associated with such instructions . The term machine readable medium shall accordingly be taken to include but not be limited to solid state memories and optical and magnetic media. Specific examples of machine readable media include non volatile memory including by way of example semiconductor memory devices e.g. erasable programmable read only memory EPROM electrically erasable programmable read only memory EEPROM and flash memory devices magnetic disks such as internal hard disks and removable disks magneto optical disks and CD ROM and DVD ROM disks.

The instructions can further be transmitted or received over a communications network using a transmission medium. The instructions can be transmitted using the network interface device and any one of a number of well known transfer protocols e.g. HTTP . Examples of communication networks include a local area network LAN a wide area network WAN the Internet mobile telephone networks plain old telephone POTS networks and wireless data networks e.g. WiFi and WiMax networks . The term transmission medium shall be taken to include any intangible medium that is capable of storing encoding or carrying instructions for execution by the machine and includes digital or analog communications signals or other intangible media to facilitate communication of such software.

Although an embodiment has been described with reference to specific example embodiments it will be evident that various modifications and changes can be made to these embodiments without departing from the broader spirit and scope of the disclosure. Accordingly the specification and drawings are to be regarded in an illustrative rather than a restrictive sense. The accompanying drawings that form a part hereof show by way of illustration and not of limitation specific embodiments in which the subject matter can be practiced. The embodiments illustrated are described in sufficient detail to enable those skilled in the art to practice the teachings disclosed herein. Other embodiments can be utilized and derived therefrom such that structural and logical substitutions and changes can be made without departing from the scope of this disclosure. This Detailed Description therefore is not to be taken in a limiting sense and the scope of various embodiments is defined only by the appended claims along with the full range of equivalents to which such claims are entitled.

Such embodiments of the inventive subject matter can be referred to herein individually and or collectively by the term invention merely for convenience and without intending to voluntarily limit the scope of this application to any single invention or inventive concept if more than one is in fact disclosed. Thus although specific embodiments have been illustrated and described herein it should be appreciated that any arrangement calculated to achieve the same purpose can be substituted for the specific embodiments shown. This disclosure is intended to cover any and all adaptations or variations of various embodiments. Combinations of the above embodiments and other embodiments not specifically described herein will be apparent to those of skill in the art upon reviewing the above description.

