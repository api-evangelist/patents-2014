---

title: Editing digital notes representing physical notes
abstract: In one example, a method includes receiving a digital note of a plurality of digital notes generated based on image data comprising a visual representation of a scene that includes a plurality of physical notes such that each of the plurality of digital notes respectively corresponds to a particular physical note of the plurality of physical notes, wherein each of the physical notes includes respective recognizable content. In this example, the method also includes receiving user input indicating a modification to one or more visual characteristics of the digital note. In this example, the method also includes editing, in response to the user input, the one or more visual characteristics of the digital note. In this example, the method also includes outputting, for display, a modified version of the digital note that includes the one or more visual characteristics.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09274693&OS=09274693&RS=09274693
owner: 3M INNOVATIVE PROPERTIES COMPANY
number: 09274693
owner_city: St. Paul
owner_country: US
publication_date: 20141015
---
This application claims the benefit of U.S. Provisional Application No. 61 891 442 filed Oct. 16 2013 the entire content of which is incorporated by reference herein in its entirety.

The present disclosure relates to note content capturing recognition extraction and or management tools and systems.

Paper notes have been broadly used in recording sharing and communicating ideas and information. For example during a collaboration session e.g. brainstorming session participants write down ideas on Post It notes whiteboard or paper and then share with one another. In addition people commonly use notes throughout the day to memorialize information or content which the individual does not want to forget. As additional examples people frequently use notes as reminders of actions or events to take in the future such as to make a telephone call revise a document or to fill out a time sheet.

For example in many situations people participate in a collaboration session by writing information on paper based notes such as Post It notes. Paper Post It notes can readily be removed from a dispenser pad of sticky back paper Post It notes and applied to various surfaces such as whiteboards documents the tops of desks telephones or the like. Information can be written on paper Post It notes either before or after the paper Post It notes are detached from their dispenser pad or attached to their target surfaces. Paper Post It notes can be easily moved from one surface to another such as between documents or between documents and the tops of desks they can overlap edges or boundaries of documents they can be layered and they can be moved with the objects to which they are attached.

Software programs currently exist which permit computer users to generate software based notes in digital form and to utilize the digital notes within computing environments. For example a computer user may create digital notes and attach the digital notes to an electronic document a desktop or an electronic workspace presented by the computing environment. The computer user may manipulate the notes allowing the notes to be created deleted edited saved and selectively viewed. The computer user may move such a note within a document or between documents and or the desktop by cutting the note from a document storing the note in a clipboard and then pasting the note to another area of the same document or to a different document. In this way the software programs provide a virtual representation of notes and allow an individual to utilize the digital notes in a manner similar to physical notes that he or she may use on a daily basis.

In general the disclosure describes techniques for creating and manipulating software notes representative of physical notes.

In one example a method includes receiving by one or more processors of a device a digital note of a plurality of digital notes generated based on image data comprising a visual representation of a scene that includes a plurality of physical notes such that each of the plurality of digital notes respectively corresponds to a particular physical note of the plurality of physical notes wherein each of the physical notes includes respective recognizable content receiving by the one or more processors user input indicating a modification to one or more visual characteristics of the digital note editing by the one or more processors and in response to the user input the one or more visual characteristics of the digital note and outputting by the one or more processors and for display a modified version of the digital note that includes the one or more visual characteristics.

In another example computing device includes a memory configured to store digital notes and one or more processors. In this example the one or more processors are configured to receive a digital note of a plurality of digital notes generated based on image data comprising a visual representation of a scene that includes a plurality of physical notes such that each of the plurality of digital notes respectively corresponds to a particular physical note of the plurality of physical notes wherein each of the physical notes includes respective recognizable content receive user input indicating a modification to one or more visual characteristics of the digital note edit in response to the user input the one or more visual characteristics of the digital note and output for display a modified version of the digital note that includes the one or more visual characteristics.

In another example a computing system includes means for receiving a digital note of a plurality of digital notes generated based on image data comprising a visual representation of a scene that includes a plurality of physical notes such that each of the plurality of digital notes respectively corresponds to a particular physical note of the plurality of physical notes wherein each of the physical notes includes respective recognizable content means for receiving user input indicating a modification to one or more visual characteristics of the digital note means for editing in response to the user input the one or more visual characteristics of the digital note and means for outputting for display a modified version of the digital note that includes the one or more visual characteristics.

In another example a computer readable storage medium stores instructions that when executed cause one or more processors of a device to receive a digital note of a plurality of digital notes generated based on image data comprising a visual representation of a scene that includes a plurality of physical notes such that each of the plurality of digital notes respectively corresponds to a particular physical note of the plurality of physical notes wherein each of the physical notes includes respective recognizable content receive user input indicating a modification to one or more visual characteristics of the digital note edit in response to the user input the one or more visual characteristics of the digital note and output for display a modified version of the digital note that includes the one or more visual characteristics.

The details of one or more examples of the disclosure are set forth in the accompanying drawings and the description below. Other features objects and advantages of the disclosure will be apparent from the description and drawings and from the claims.

The present disclosure describes techniques for creating and manipulating software notes representative of physical notes. For example techniques are described for recognizing physical notes present within a physical environment capturing information therefrom and creating corresponding digital representations of the physical notes referred to herein as digital notes or software based notes. Further at least some aspects of the present disclosure are directed to techniques for managing multiple notes such as storing retrieving editing the digital notes categorizing and grouping the digital notes or the like.

In general notes can include physical notes and digital notes. Physical notes generally refer to physical objects with a general boundary and recognizable content. Physical notes can include the resulting objects after people write draw or enter via other type of inputs on the objects for example paper white board or other objects accepting the inputs. By way of examples physical notes can include hand written Post It notes paper or film white board with drawings posters and signs. In some cases physical notes can be generated using digital techniques e.g. printing onto printable Post It notes or printed document. In some cases one object can include several physical notes. For example several ideas can be written on separate areas of a single piece of poster paper or a white board. In some implementations to facilitate the recognition of these notes marks such as lines shapes colors symbols markers or stickers can be applied to the edges of the notes. Physical notes can be two dimensional or three dimensional. Physical notes can have various shapes and sizes. For example a physical note may be a 7.62 7.62 cm 3 3 inches note a physical note may be a 66.04 99.06 cm 26 39 inches poster and a physical note may be a triangular metal sign. In some cases physical notes may have known shapes and or sizes that conform to standards such as legal A A and other size standards and known shapes which may not be limited to geometric shapes such as stars circles rectangles or the like. In other cases physical notes may have non standardized sizes and or irregular shapes.

Digital notes generally refer to digital objects with information and or ideas. Digital notes can be generated using digital inputs. Digital inputs can include for example keyboards touch screens digital cameras digital recording devices stylus digital pens or the like. In some cases digital notes may be representative of physical notes.

In some cases digital notes may be representative of physical notes used in a collaboration space. Collaboration space generally refers to a gathering area allowing more than one person to brainstorm such as sharing ideas and thoughts with each other. The collaboration space can also represent a virtual space allowing a group of persons to brainstorm such as sharing ideas and thoughts remotely besides the gathering area. The collaboration space may be referred to as workspaces or the like.

In some examples the plurality of physical notes of workspace may comprise notes of different color. In other examples the plurality of physical notes of workspace may comprise at least one note including fiducial markings such as markings at the upper right and lower left corners of the note. In other examples the plurality of physical notes of workspace may comprise at least one note having one color for the body of the note and another color for the border of the note. In other examples notes from the plurality of physical notes of workspace may be arranged so that they overlap such as being arranged in a stacked overlapping relationship. In other examples notes from the plurality of physical notes of workspace may be arranged adjacently.

In the example implementation mobile device includes among other components an image capture device and a presentation device . In addition although not shown in mobile device may include one or more processors microprocessors internal memory and or data storage and other electronic circuitry for executing software or firmware to provide the functionality described herein.

In general image capture device is a camera or other component configured to capture image data representative of workspace and notes positioned therein. In other words the image data captures a visual representation of an environment such as workspace having a plurality of visual notes. Although discussed as a camera of mobile device image capture device may comprise other components capable of capturing image data such as a video recorder an infrared camera a CCD Charge Coupled Device array a laser scanner or the like. Moreover the captured image data can include at least one of an image a video a sequence of images i.e. multiple images taken within a time period and or with an order a collection of images or the like and the term input image is used herein to refer to the various example types of image data.

Presentation device may include but not limited to an electronically addressable display such as a liquid crystal display LCD or other type of display device for use with mobile device . In some implementations mobile device generates the content to display on presentation device for the notes in a variety of formats for example a list grouped in rows and or column a flow diagram or the like. Mobile device may in some cases communicate display information for presentation by other devices such as a tablet computer a projector an electronic billboard or other external device.

As described herein mobile device and the software executing thereon provide a platform for creating and manipulating digital notes representative of physical notes . For example in general mobile device is configured to process image data produced by image capture device to detect and recognize at least one of physical notes positioned within workspace . In some examples the mobile device is configured to recognize note s by determining the general boundary of the note s . After a note is recognized mobile device extracts the content of at least one of the one or more notes where the content is the visual information of note .

As further described below mobile device may implement techniques for automated detection and recognition of physical notes and extraction of information content or other characteristics associated with each of the physical notes. For example mobile device may allow user fine grain control over techniques used by mobile device to detect and recognize physical notes . As one example mobile device may allow user to select between marker based detection techniques in which one or more of notes includes a physical fiducial mark on the surface of the note or non marker based techniques in which no fiducial mark is used.

In addition mobile device provide user with an improved electronic environment for generating and manipulating corresponding digital notes representative of physical notes including removing background or other image related artifacts from the notes. As another example mobile device may provide mechanisms allowing user to easily add digital notes to and or delete digital notes from a set of digital notes representative of the brainstorming activity associated with workspace . In some example implementations mobile device provides functionality by which user is able to record and manage relationships between groups of notes .

In some example implementations mobile device provides functionality by which user is able to export the digital notes to other systems such as cloud based repositories e.g. cloud server or other computing devices e.g. computer system or mobile device .

In the example of mobile device is illustrated as a mobile phone. However in other examples mobile device may be a tablet computer a personal digital assistant PDA a laptop computer a media player an e book reader a wearable computing device e.g. a watch eyewear a glove or any other type of mobile or non mobile computing device suitable for performing the techniques described herein.

In this example mobile device includes various hardware components that provide core functionality for operation of the device. For example mobile device includes one or more programmable processors configured to operate according to executable instructions i.e. program code typically stored in a computer readable medium or data storage such as static random access memory SRAM device or Flash memory device. I O may include one or more devices such as a keyboard camera button power button volume button home button back button menu button or presentation device as described in . Transmitter and receiver provide wireless communication with other devices such as cloud server computer system or other mobile device as described in via a wireless communication interface as described in such as but not limited to high frequency radio frequency RF signals. Mobile device may include additional discrete digital logic or analog circuitry not shown in .

In general operating system executes on processor and provides an operating environment for one or more user applications commonly referred to apps including note management application . User applications may for example comprise executable program code stored in computer readable storage device e.g. data storage for execution by processor . As other examples user applications may comprise firmware or in some examples may be implemented in discrete logic.

In operation mobile device receives input image data and processes the input image data in accordance with the techniques described herein. For example image capture device may capture an input image of an environment having a plurality of notes such as workspace of having of notes . As another example mobile device may receive image data from external sources such as cloud server computer system or mobile device via receiver . In general mobile device stores the image data in data storage for access and processing by note management application and or other user applications .

As shown in user applications may invoke kernel functions of operating system to output a graphical user interface GUI for presenting information to a user of mobile device. As further described below note management application may construct and control GUI to provide an improved electronic environment for generating and manipulating corresponding digital notes representative of physical notes . For example note management application may construct GUI to include a mechanism that allows user to easily add digital notes to and or deleting digital notes from defined sets of digital notes recognized from the image data. In some example implementations note management application provides functionality by which user is able to record and manage relationships between groups of the digital notes by way of GUI .

In this example user application includes image processing engine that provides image processing and object recognition functionality. Image processing engine may include image communication module note identification module digital note generation module and note enhancement module . In addition image processing engine includes image processing Application Programming Interfaces APIs that provide a library of image manipulation functions e.g. image thresholding masking filtering edge detection and the like for use by the other components of image processing engine .

In general image data may be stored in data storage device . In this example note management application stores images within data storage device . Each of images may comprise pixel data for environments having a plurality of physical images such as workspace of .

As described herein note identification module processes images and identifies i.e. recognizes the plurality of physical notes in the images. The input image may be processed by note identification module using marker and or non marker detection processes. Digital note generation module generates digital notes corresponding to the physical notes recognized within images . For example each of digital notes corresponds to one of the physical notes identified in an input image . During this process digital note generation module may update database to include a record of the digital note and may store within the database information e.g. content captured from boundaries of the physical note within the input image as detected by note identification module . Moreover digital note generation module may store within database metadata associating the digital notes into one or more groups of digital notes.

Note enhancement enables editing and or enhancement of digital notes such as digital notes generated by digital note generation module . For instance note enhancement module may include a process or processes that enhance the extracted information from the input image. As one example note enhancement module may include a process or processes to enhance the extracted information from the input image in accordance with the techniques of . As another example note enhancement module may by invoked by note editor to enable editing of digital notes in accordance with the techniques of . Note enhancement module may be configured to receive digital notes from data storage and store edited digital notes to data storage . In some examples note enhancement module may store an edited and or enhanced digital note to data storage by storing the digital note along with one or more objects that correspond to edits and or enhancements of the digital note e.g. shape layer objects of .

Image communication module controls communication of image data between mobile device and external devices such as cloud server computer system mobile device or image capture device . In some examples image communication modules may for example allow a user to communicate processed or unprocessed images of environments and or digital notes and associated information extracted therefrom including metadata from database . In some examples image communication module exports this data to a zip file that may be communicated by FTP HTTP email Bluetooth or other mechanism.

In the example of note management application includes user interface that constructs and controls GUI . As described below user interface may in some examples output for display an input image overlaid with the plurality of digital notes where each of the digital notes is overlaid in place of a corresponding physical note. In addition user interface may display a group of digital notes that has been designated by the user. This group of digital notes may be for example a subset of the digital notes recognized in a particular input image . User interface may display this designated group set of the digital notes on a second portion of GUI and allow user to easily add or remove digital notes from the designated group.

In some example implementations user interface provides a note editor that allows a user to edit the overlay image and or the digital notes. For instance note editor may allow a user to edit the digital notes in accordance with the techniques of B. In some examples note editor may invoke one or more components of image processing engine such as note enhancement module to perform edits on the digital notes.

Additional example details of note management application for detecting and recognizing physical notes are described in U.S. Patent Application 61 844 140 filed Jul. 9 2013 entitled SYSTEMS AND METHODS FOR NOTE RECOGNITION AND MANAGEMENT USING COLOR CLASSIFICATION U.S. Patent Application 61 844 152 filed Jul. 9 2013 entitled SYSTEMS AND METHODS FOR NOTE CONTENT EXTRACTION AND MANAGEMENT USING SEGMENTED NOTES and U.S. Patent Application 61 844 176 filed Jul. 9 2013 SYSTEMS AND METHODS FOR NOTE CONTENT EXTRACTION AND MANAGEMENT BY SEGMENTING NOTES the entire contents of each of which are incorporated herein by reference.

Digital note generation module extracts content of the one of the plurality of notes to create sub images . In some examples digital note generation module can apply image transformation to at least part of the input image before extracting content. In some other examples digital note generation module can apply image enhancement or another image processing technique such as removing a background of the underlying workspace or changing the color of each note in the plurality of notes to improve the quality of the extracted content or sub images . For instance digital note generation module can apply image enhancement in accordance with the techniques of . In yet other examples digital note generation module can further recognize text and figures from the extracted content or sub images. Digital note generation module stores the enhanced extracted content or sub images to data storage of mobile device and may communicate the digital notes to cloud server or other computer system . Program code or other executable instructions for causing a programmable processor to perform process may be stored within a computer readable storage of mobile device .

Digital note generation module may further recognize text and figures from the extracted content or sub images not shown in . Digital note generation module and or note enhancement module may store the enhanced extracted content or sub images to data storage of mobile device and may subsequently communicate the original image data and or digital notes including extracted information and metadata to cloud server or computer system as described in .

As further described below physical notes having borders that are different in color from the body of the notes provide a form of a fiducial mark that may be used for color segmentation and detection of the physical notes. As fiducial marks in some examples the border color may be selected to provide good color separation from the background color such as a white or black border color that is different from the background body color of the note. As further examples the border color and the body color may be selected to be complementary colors so as to provide good color separation such as use of cyan borders or other fiducial marks on a yellow note thereby providing high color contrast to facilitate identification of the physical note.

In other examples fiducial marks may be constructed using an invisible ink that may only be visible to the image processing engine. As another example retro reflective material may be used on the notes as a fiducial mark that may be responsive to a flash from the imaging device.

Upon receiving the input image as described in note management application executing on mobile device cloud server or computer system identifies a plurality of overlapping physical notes by using a color detection module which may be a component of note identification module . The color detection module may convert the input image to a desirable color space not shown in . An example applicable color space includes but not limited to RGB red green and blue LAB e.g. Hunter 1948 L a b color space CIE 1976 L a b color space CMYK cyan magenta yellow and key black HSV hue saturation and value HSL hue saturation and lightness HSI hue saturation and intensity sRGB standard red green and blue color space. Next the color detection module may apply one or more classification functions to color values for each pixel in the input image not shown in . The classification functions can be computed using optional training steps. The classification algorithms for the color detection module can be for example linear discriminant analysis quadratic classifier Gaussian Mixture Models Boosted Decision Trees Support Vector Machines or the like. Using the classification algorithms indicators indicative of color classes for each pixel in the image not shown in are generated. A color class includes a particular range of wavelength or can be an other color class referring to any other color besides the color classes of interest. For example a color class can be magenta yellow blue orange etc. An indicator can be represented by for example a number a code a symbol an alphanumerical token a color value a grayscale value or the like. In another example technique may also use a shape detection module and a pattern detection module as described in .

In another example a computer system may be configured to execute any variation of techniques . In another example a non transitory computer readable medium including instructions that cause a programmable processor to execute may execute any variation of techniques .

In overlapping notes A C are the same color and are segmented using a color detection module as described in and as shown in of . Optionally the mass of plurality of overlapping notes A C may be filled during the color detection module analysis as shown as mass D in of . The right angled corners of the mass of plurality of notes A C are detected using correlation templates of . The peaks of the correlation templates are located off center and are used to determine the corners of the mass of plurality of notes A C as shown in of . The corners of the mass of plurality of notes A C with marks applied to one or more corners along at least a part of the boundary and have corresponding correlation peaks are used to determine the correlated corners A A B B C and C and the orientation of each note in the mass of plurality of notes A C as shown in of . In another example the technique may optionally include performing geometric correction and cropping techniques to the mass of plurality of notes A C based on the orientation of each note in the mass of plurality of notes A C. In another example the marks can be a different color border such as a white border along the boundary of the note. In another example technique may further include determining whether at least one of the plurality of notes in the input image includes one or more marks in the mass of plurality of notes A C by comparing one or more marks to marks in a database.

In and the input image does contain one or more marks so technique may include utilizing a marker detection module with the color detection module to determine the boundary of each note segment. In based on the correlated corners A A B B C and C the boundaries of segments A C of the mass can be determined of . In some cases the marker detection module can determine the relative positions of marks which can be used to determine the boundaries of the plurality of note segments A C. The content of note segments A C of the mass can extracted from the plurality of note segments A C using the determined boundaries of . In some cases each piece of content is extracted from a corresponding note segment. In another example the extracted contents of note segments A C are used to generate a plurality of digital notes corresponding to the boundary of each note in the plurality of overlapping notes identified in the input image and the plurality of digital notes include information represented by the plurality of note segments A C in the input image. In another example the extracted contents of note segments A C are used to generate a plurality of segmented digital notes corresponding to the boundary of each note in the plurality of overlapping notes identified in the input image and the plurality of segmented digital notes include information represented by the plurality of note segments A C in the input image.

In one example as illustrated in a user such as user of activates marker detection control before directing note management application to capture or otherwise process an input image. By activating marker detection toggle to utilize a marker detection module user directs image processing engine of note management application to segment a plurality of detected overlapping physical notes based on fiducial markers associated with the notes. The user may activate a marker detection control prior to capturing the input image of the workspace or may activate marker detection control after the workspace is captured but prior to a processing of the input image to utilize a marker detection module to segment the plurality of overlapping notes based on fiducial markers. In this example the note in the input image contains mark which can be a barcode a color code a color a matrix code a color block a different color border or the like.

In general the marker detection module uses one or more marks to determine the boundary of the note. In some cases the note may be slanted in the input image not shown in . In some other cases the input image may be taken with geometric distortion. The marker detection module may use the determined boundary of mark or a portion of mark to determine the necessary image transformation and correction to the input image to obtain the content of the note.

In another case as illustrated in the user may elect to disable marker detection control to not include a marker detection module in the note recognition technique. In response image processing engine of note management module may invoke any one or more non marker based note detection algorithms such as identifying the plurality of physical notes based on shapes defined by perimeters of the plurality of notes in the input image identifying the plurality of notes according to color spaces associated with background colors of the plurality of notes and or identifying the plurality of notes according to a pattern recognition algorithm.

For purposes of example marker detection control is shown as a toggle UI element having an on state and an off state although other UI elements could be used such as radio buttons drop down lists and the like.

In the example illustrated by a mobile device includes a graphical user interface with a first portion region and a second portion region . Note management application displays within first portion of graphical user interface the input image captured from a workspace where the input image typically provides a visual representation of a workspace having a plurality of physical notes. Note management application displays within second portion a set of digital images generated from the physical notes within the input image as recognized by note management application .

In addition note management application may display on the first portion of graphical user interface the digital notes and enhanced sub images associated therewith overlaid on the original input image where each of the plurality of digital notes is presented in place of the corresponding physical note recognized by the note management application. This may for example aid the user in associating the digital notes with their respect physical notes in the workspace.

Each note in the plurality of digital notes on first portion and second portion of the graphical user interface may be selected by a user input for deletion from the set of digital notes. As illustrated between the selected digital note in the second portion of the graphical user interface may be deleted from the second portion of the graphical user interface and remain in the first portion of the graphical user interface. In another example the selected digital note may be deleted from both the first portion and the second portion of the graphical user interface. In another example the selected digital note may be deleted from the first portion of the graphical user interface and remain in the second portion of the graphical user interface.

In the example technique illustrated by note management application processes an input image of workspace that in this example includes a plurality of notes separated into groups based on distance. In this example note management application identifies an indication of one or more groups based on the distances between each of the recognized notes and a threshold distance as determined by mobile device . That is note management application may determine clusters of physical notes within the input image and based on the clusters logically associate the digital notes into groups of digital notes. In some examples note management application may compute a 2D grid or 3D array of position data associated with objects within the input image and for each recognized physical note determine an absolute position and boundary for the note within the 2D or 3D space and thereby compute a complete representation of the workspace. Based on this information note management application can determine minimum distances between each physical note within the virtual space and based on the distances determine groupings of the corresponding digital notes corresponding to the physical notes. In other examples note management application may determine groupings based on a threshold value which may be a threshold distance or a threshold ratio pre determined by a user or calculated by mobile device .

In some examples note management application may be configured to detect a template of group indicators. For example if the user places a printed template on the wall with a known design note management application may automatically establish the location of the physical notes relative to the printed template. In one example the template may be a calendar and the notes may represent tasks or events placed on the calendar. Upon processing an image of the workspace including the template and plurality of physical notes note management application determines the task event as taking place on a specific date based on the location of the note within the template. Templates could either be printed and adhered to the wall or simply projected onto the wall surface.

Moreover although described by way of example to detection of physical group indicators detected within an input image the technique may be applied to detection of one or more group indicators gestured or otherwise entered by the user upon interacting with a presence sensitive display of mobile device or other device.

In some examples techniques may include using multiple detection modules to recognize notes and extract the content of the plurality of notes such as a color detection module a shape detection module and a pattern detection module as described in . In one example of the color detection module the technique may include using color spaces such as the RGB HSV CIELAB etc. to identify regions of interest corresponding to the notes for color recognition. In other examples of the shape detection module and the pattern detection module the notes are further distinguished in their shape and due to the presence of unique patterns detected by shape recognition e.g. Hough transform shape context etc. and pattern recognition algorithms e.g. Support Vector Machine cross correlation template matching etc. respectively. These algorithms help filter out unwanted objects in the input image or other sources of notes content and leave only those regions of interest corresponding to the notes.

In some examples techniques may further include a computing device such as cloud server computer system and or mobile devices which are configured to gather content and group indications of the plurality of notes and display the plurality of notes according to the grouping or order of the notes as shown in . In another example a computer system may be configured to execute any variation of techniques . In another example a non transitory computer readable medium including instructions that cause a programmable processor to execute may execute any variation of techniques .

In accordance with one or more techniques of this disclosure a device such as mobile device of may receive an input image . In some examples one or more processors may execute an image processing engine e.g. image processing engine of to receive image data comprising a visual representation of a scene that includes a plurality of physical notes that each include respective recognizable content. For instance processor of mobile device may execute image processing engine to receive image data e.g. as image data of comprising a visual representation of scene that includes a plurality of physical notes that each include respective recognizable content e.g. physical notes A C of . In some examples the image data may be an example of an image of images of .

As one example image processing engine may receive the image data from a camera of mobile device such as image capture device of . For instance a user of mobile device such as user may use image capture device to take a picture of a plurality of physical notes.

As another example image communication module of image processing engine may receive the image data from one or more external devices such as another mobile device e.g. mobile device of a cloud server e.g. cloud server a computer system e.g. computer system and the like. For instance a user of another device may take a picture of a plurality of physical notes and cause the other device to send the picture to mobile device e.g. via e mail multimedia message and the like .

As another example image processing engine may receive the image data from a storage device of mobile device such as data storage device . For instance data storage device may store image data previously captured by image capture device and or image data previously received from one or more external devices.

In any case image processing engine may identify a plurality of notes represented by the input image . For instance note identification module of image processing engine may recognize note features using a color detection module a shape detection module and a pattern detection module and subsequently determine the general boundary of the note. In some examples a pattern detection module can identify each of the plurality of physical notes represented in the input image using one or more pattern recognition algorithms such as a support vector machine algorithm a cross correlation algorithm and a template matching algorithm for example. In some examples note identification module may utilize a shape detection module to identify at least one of the plurality of notes based on shapes defined by perimeters of the plurality of notes in the input image. In some examples note identification module may identify the plurality of notes according to color spaces associated with background colors the plurality of notes. In some examples note identification module may utilize a pattern detection module to identify at least one of the plurality of notes. In some examples the pattern detection module may include pattern recognition algorithms such as a support vector machine algorithm a cross correlation algorithm and or a template matching algorithm. In some examples the plurality of notes in the input image may include one or more of a 7.62 7.62 centimeter cm 3.0 3.0 inch note a 66.04 99.06 cm 26.0 39.0 inch poster a triangular metal sign a sticker and a 22.59 27.94 cm 8.5 11 inch sheet of paper.

Digital note generation module may generate based on the identified plurality of notes a plurality of digital notes that each respectively correspond to a particular physical note of the plurality of physical notes . For instance digital note generation module may extract respective content of the plurality of identified notes to create a plurality of sub images. As illustrated in the example of digital note generation module may extract content from physical note C to create sub image .

Note enhancement module may enhance each of the plurality of digital notes . In some aspects note enhancement module may enhance one or more of the digital notes by correcting shadows lighting rotation and scaling of notes in the respective input image. In some examples while the physical note to which a particular sub image corresponds may have a uniform background color the background of the particular sub image may not be a uniform color e.g. due to lighting conditions when the image data was captured quantization errors etc. . . . . As such in some examples note enhancement module may enhance the particular sub image by setting each pixel corresponding to the background of the particular sub image to a uniform color e.g. pixel value . In some examples note enhancement module may set the background of the particular sub image to a uniform color in accordance with the techniques of . In some examples note enhancement module may enhance one or more of the digital notes by correcting one or more of shadows lighting rotation and or scaling of notes in the input image.

In some examples note management application may enable a user to modify and or edit the digital note. For instance note editor of user interface may enable a user of mobile device to edit the digital note in accordance with the techniques of .

As discussed above in some examples note enhancement module of note management application may apply the image enhancement techniques of to set the background of a sub image to a uniform color.

As discussed above digital note generation module may identify a plurality of physical notes from image data that includes a visual representation of a scene that includes the plurality of physical notes where each physical note includes respective recognizable content and extract a sub image that corresponds to a particular physical note from the image data. In some examples the extracted sub image may be considered to be a digital note. Digital note generation module may store the plurality of digital notes to a digital data storage device such as data storage of e.g. for retrieval by a user. In accordance with one or more techniques of this disclosure note enhancement module may identify a foreground region of the digital note . For instance note enhancement module may identify the foreground region as the region that includes content that corresponds to the respective recognizable content of the physical note to which the digital note corresponds. As illustrated in the example of note enhancement module may identify foreground region .

Note enhancement module may identify a background region of the digital note . For instance in some examples note enhancement module may identify the background region as the parts of the digital note that are not included in the foreground region. As illustrated in the example of note enhancement module may identify background region . In some examples note enhancement module may first identify background region and then identify foreground region based on the identified background region . In other examples note enhancement module may first identify foreground region and then identify background region based on the identified foreground region . In some examples note enhancement module may identify the foreground region and or the background region of the particular digital note in accordance with the techniques of .

In any case note enhancement module may determine a uniform background color for the digital note . For instance in some examples note enhancement module may select a pixel value for the uniform background color as an average or median color value of pixels included in the background region of the digital note.

Note enhancement module may set pixels included in the background region of the digital note to the determined uniform background color . As one example note enhancement module may replace pixel values of the pixels included in the background region of the digital note with a pixel value corresponding to the determined uniform background color. As another example note enhancement module may store to a data structure a bitmap mask that identifies the background region along with an indication of the determined uniform background color such that the digital note may be rendered with the uniform background color without overwriting the original data. By setting the background of a digital note to a uniform color note enhancement module may improve the visual quality of the digital note when the digital note is rendered for display. For instance the visual quality of enhanced digital note may be greater than digital note . In this way note enhancement module may improve the quality of the extracted content or sub images.

Mobile device may receive a digital note of a plurality of digital notes generated based on image data comprising a visual representation of a scene that includes a plurality of physical notes such that each of the plurality of digital notes respectively corresponds to a particular physical note of the plurality of physical notes which each include respective recognizable content. For instance as illustrated in mobile device may receive digital note which corresponds to a physical note with recognizable content i.e. a hand written to do list of Buy milk and Wash laundry .

In accordance with one or more techniques of this disclosure a device such as mobile device may output a digital note for display . For instance the device may output an enhanced digital note generated in accordance with the techniques of and or . As illustrated in the example of note editor of mobile device may output graphical user interface GUI A that includes digital note which as discussed above corresponds to a physical note with recognizable content Buy milk and Wash laundry. 

Note editor may receive user input to edit the digital note . As one example note editor may receive an indication that a user of the device performed a gesture to draw a line on the digital note with a virtual pen. In some examples the digital notes may be modified using free form writing or drawing by touching a dragging a finger on a touch screen such as a touch screen of mobile device . Alternatively the user can perform the user input on a desktop or laptop using a mouse pointer clicking and dragging . Note editor may store data indicative of gestures created by free form writing or drawing in memory and display an image representing the data indicative of gestures as layers overlaid on the digital note. For example as illustrated in note editor may store data indicative of one or more gestures e.g. strokes created by free from writing or drawing as objects such as shape layer objects A C. In some examples note editor may store the objects as JavaScript Object Notation JSON data objects Extensible Markup Language XML objects or other data objects. Since the strokes created by free form writing or drawing can be stored in memory erasing or undoing the strokes is also possible. In some examples note editor may invoke note enhancement module to perform one or more operations related to note editing. For instance note editor may invoke image enhancement module to store the data indicative of the gestures.

As another example note editor may receive an indication that the user of the device has selected an updated background color. In some examples as the background pixels can be tracked over time note editor may invoke note enhancement module to replace the tracked background pixels with the new color i.e. after other edits have been made to the digital note such as edits that may cause a background pixel to become a foreground pixel . One or all of these functionalities can be provided in the form of buttons such as touch enabled buttons included in the GUI. For instance as illustrated in each of GUIs B F may include text entry tool digital pen tool background color tool undo button and color selection area .

In any case responsive to receiving the user input note editor may output for display an updated version of the digital note based on the user input . As illustrated in the example of responsive to receiving an indication that the user of mobile device performed a gesture to draw a line on the digital note with a virtual green pen i.e. that the user selected digital pen tool selected green selected from color selection area and performed a gesture in the shape of a checkmark note editor may output GUI B that includes a green line in the shape of a checkmark. As discussed above the stroke corresponding to the green line may be stored as a data object in a data structure such as shape layer object A. In this way note editor may enable a user to edit a digital note that corresponds to a physical note. As shown in the example of techniques of this disclosure enable a user to write a to do list on a physical note take a photo of the physical note to create a digital note corresponding to the physical note and digitally check off items from the to do list originally written on the physical note.

In some examples note editing module may determine a mask that indicates which pixels of digital note are background pixels and which pixels of digital note are foreground pixels. In some examples the mask may be a bitmap with a binary value for each pixel of digital note where a first binary value indicates that a particular pixel is a foreground pixel and a second binary value indicates that the particular pixel is a background pixel.

In some examples when invoked by note editor to edit the digital note digital note editing module may update the mask that indicates which pixels of the digital note are foreground background pixels based on the user input. For instance before the user input that corresponds to the green line the mask may indicate that the pixels corresponding to the green line are background pixels. After receiving the user input that corresponds to the green line digital note editing module may update the mask such that the pixels corresponding to the green line are indicated as foreground pixels.

In some examples note editor may continue to receive additional user input and continue to output for display updated versions of the digital note based on the additional user input . As illustrated in the example of responsive to receiving an indication that the user of mobile device performed a gesture to draw a line on the digital note with a virtual red pen i.e. that the user selected digital pen tool selected red from color selection area and performed a gesture in the shape of a line crossing out the Wash laundry to do item note editor may output GUI C that includes a red line crossing out the Wash laundry to do item. As discussed above note editor may store or may invoke note enhancement module to store the stroke corresponding to the red line as an object such as shape layer object B which may be rendered into GUI C along with shape layer object A and digital note . In this way the device may store the editing information separately from the digital note.

In some examples digital note editing module may receive user input to edit the digital note by the user typing content onto the digital note. For instance the user may select text entry tool which may cause the device to display a virtual keyboard via which the user may enter the word Vacuum. As illustrated in the example of responsive to receiving an indication that the user of mobile device typed in the word Vacuum on the digital note with a keyboard e.g. a virtual keyboard or physical keyboard note editor may output GUI D that includes text spelling out the word Vacuum. In some examples note editor may provide an interface by which the user can select characteristics of the text to be typed e.g. font color or may modify the characteristics of the text after typing. As discussed above note editor may store or may invoke note enhancement module to store the text as an object such as shape layer object C which may be rendered into GUI D along with shape layer objects A B and digital note .

In some examples the user may desire to undo one or more of the edits made. For instance in the example of the user may desire to undo inserting the word Vacuum. As such the user may select undo button to undo the previously made edit. As illustrated in the example of responsive to receiving an indication that the user of mobile device performed a gesture to select undo button note editor may output GUI E that does not include the text spelling out the word Vacuum. As the text may be stored as a separate object such as shape layer object C the device may simply render GUI E without shape layer object C.

In some examples the user may desire to edit the digital note by changing the background color of the digital note. For instance the user may select background color tool and select a new background color from a selection of background color options displayed in background color selection area . As illustrated in the example of responsive to receiving an indication that the user of mobile device has selected an updated background color note editor may update the background color of the digital note and output GUI F that includes the digital note with the updated background color. For instance note editor may invoke note enhancement module to update the background color of the digital note. In some examples the updated background color may be selected from a group of colors that corresponds to colors in which the physical notes are actually available. In some examples the updated background color may be selected from a group of colors consisting of background colors of the plurality of digital notes generated based on a single scene e.g. a scene that includes a plurality of physical notes one of which corresponds to the digital note currently being edited . In this way in examples where the notes are grouped by background color the user may move digital notes between groups with maintaining the uniformity of background colors within each group.

In some examples the updated background color selected by the user may not be visually compatible with the color of one or more foreground objects e.g. original content Buy milk Wash laundry and modified content such as the green check mark next to Buy milk the red line crossing out Wash laundry and the black text Vacuum . For instance the updated background color may make one or more of the foreground objects harder to read. For example the updated background color may decrease the contrast ratio between a particular foreground object and the background of the digital note. In accordance with one or more techniques of this disclosure note editor may automatically modify or invoke note enhancement module to automatically modify the color of one or more foreground objects based on the updated background color. In this way note editor may enable editing of the background color of the digital note without sacrificing the readability of the one or more foreground objects. Example details of how note editor may modify the color of the one or more foreground objects are discussed below with reference to .

In some examples as opposed to overwriting the image data of the digital note with the edits the device may store information corresponding to each edit as a separate data object which may be used to render the digital note. For instance as illustrated in the example of note editor may store information corresponding to the green line in the shape of a checkmark as shapeLayer Object 0 A. Similarly note editor may store information corresponding to the red line crossing out Wash laundry as shapeLayer Object 1 B and information corresponding to the text Vacuum as shapeLayer Object 2 C. In some examples shape layer objects A C may be stored in a container along with digital note . For instance note editor may store shape layer object A as a set of coordinates that correspond to the location and shape of the line i.e. the check mark and an indication that the line is green. Similarly note editor may store digital note by storing the original image data i.e. the photograph of the physical note to which digital note corresponds along with the foreground background mask and an indication of a uniform background color as discussed above with reference to .

As such note editor may enable the user to undo an edit without modifying the underlying image data of the digital note. In some examples the rendering order may be first in first out meaning that earlier created objects are rendered under later created objects.

Note editor may responsive to receiving user input that indicates an updated background color set a background color of enhanced digital note to the updated background color. For instance note editor may invoke note enhancement module to set the background color of enhanced digital note to the updated background color. As one example where the updated background color is purple note editor may generate colored digital note A by setting the background color of enhanced digital note to purple. As another example where the updated background color is lime green note editor may generate colored digital note B by setting the background color of enhanced digital note to lime green. As another example where the updated background color is orange note editor may generate colored digital note C by setting the background color of enhanced digital note to orange. As another example where the updated background color is yellow note editor may generate colored digital note D by setting the background color of enhanced digital note to yellow. However as discussed above in some examples the updated background color may not be visually compatible with the color of foreground object i.e. Electric blue written in a dark blue .

In accordance with one or more techniques of this disclosure the device may automatically modify the color of one or more foreground objects based on the updated background color. For instance note editor may select an updated foreground color as a function of the updated background color and set a color of one or more foreground objects to the updated foreground color. In some examples note editor may select the updated foreground color such that a contrast ratio between the updated foreground color and the updated background color is greater than a contrast ratio between a current foreground color and the updated background color.

In some examples note editor may select the updated foreground color based on a current foreground color and the updated background color. In some examples note editor may update the color of one or more foreground objects on a pixel by pixel level e.g. may modify pixel values of each respective pixel of the foreground objects based on pixel values of the corresponding respective pixels of the foreground colors and based on the value of the background color. For instance the color of some pixels of foreground objects may be influenced by the previous background color. By updating the color of the pixels of the foreground objects on a pixel by pixel level and based on the updates and previous background colors note editor may improve the visual appearance of the digital note.

As one example note editor may select the updated foreground color in accordance with equations 1 15 below where Lis the current L value of the ipixel of a foreground object ais the current a value of the ipixel of the foreground object bis the current b value of the ipixel of the foreground object Lnewis the updated L value of the ipixel of the foreground object anewis the updated a value of the ipixel of the foreground object bnewis the updated b value of the ipixel of the foreground object.

In this example note editor can compute an updated value Lnew anew bnew of the ipixel of the foreground object as a function of the old value L a b of the ipixel of the foreground object the old note background color L a b and the updated background color L a b . The constant 60 in the denominator of equation 9 is one example value and other values can be chosen for the denominator. The constant value of equation 9 can be chosen to select a value that gives good visual results. For instance using a lower value for the constant of equation 9 may cause the updated values for the pixel to retain more of the old note background color. Similarly using a higher value for the constant of equation 9 may cause the updated values for the pixel to retain less of the old note background color. diff diff and diffmay be thought of as representing a vector direction in which the new color is going. The updated value Lnew anew bnew reflects how the foreground color values are moved along this vector translation.

In some examples note editor may identify a foreground region of the digital note and a background region of the digital note e.g. in order to modify the colors of the foreground region and the background region. As discussed above in some examples note editor invoke note enhancement module to identify the foreground region and or the background region of a digital note in accordance with the techniques of .

In some examples once the background region is identified note editor may enable editing functionality. For instance note editor may enable editing functionality on digital notes that correspond to physical notes as it will be possible to determine what the true background pixels are and the changes i.e. edits can be monitored as new foreground pixels. illustrates examples of changing the note color of images of physical notes. As illustrated in note editor may re color foreground pixels of colored digital notes A D e.g. to have a mix of old background color and new background color. Alternatively note editor may select the updated foreground color to be a color that is a complementary color to the updated background color based on RGB or LAB color wheel. This selection may increase the contrast.

As one example note editor may generate improved digital note A by modifying the color of the foreground object i.e. Electric blue based on the updated background color of purple to generate modified foreground object A having a first modified color. As another example note editor may generate improved digital note B by modifying the color of the foreground object i.e. Electric blue based on the updated background color of green to generate modified foreground object B having a second modified color. As another example note editor may generate improved digital note C by modifying the color of the foreground object i.e. Electric blue based on the updated background color of orange to generate modified foreground object C having a third modified color. As another example note editor may generate improved digital note D by modifying the color of the foreground object i.e. Electric blue based on the updated background color of yellow to generate modified foreground object D having a fourth modified color. In this way as shown by foreground objects A D i.e. Electric blue are easier to read on improved digital notes A D than on colored digital notes A D respectively. In some examples noted editor may select the first second third and or fourth modified colors based on the respective selected background color in accordance with equations 1 15 above. Although shown for purposes of example with the foreground objects having a uniform color throughout the object in some examples pixel values of individual pixels of the foreground objects are modified based on the new selected background color and the original pixel value of the respective pixel.

In accordance with one or more techniques of this disclosure a device such as mobile device of may receive a digital note that corresponds to a physical note of a plurality of physical notes . For instance note enhancement module of may receive a digital note of a plurality of digital notes generated in accordance with the techniques of and or e.g. digital note editing module may receive the digital note from data storage . In some examples the digital note may be a bitmap image that corresponds to a particular physical note of the plurality of physical notes. In some examples note enhancement module may assume that the digital note has a primary note color i.e. a background color and one or more secondary colors used in writings and drawings on the note i.e. foreground colors . Using this assumption the device may apply a graph based color segmentation algorithm . In some examples the device may apply the graph based color segmentation algorithm described in Felzenszwalb and Huttenlocher International Journal of Computer Vision Volume 59 Number 2 September 2004 available at http www.cs.cornell.edu dph papers seg ijcv.pdf the entirety of which is hereby incorporated by reference. In some examples the color segmentation algorithm may generate multiple contiguous segments based on color and proximity of pixels. It is possible to get multiple segments on the same foreground or background color because of color changes induced by shadow lighting changes etc. In some examples note enhancement module may fuse these segments together based on a size threshold.

The device may identify the foreground regions of the digital note . For instance note enhancement module may perform a logical OR operation to all of the individual foreground segments to generate a foreground mask. Some example resulting masks are shown in . For instance as illustrated in note enhancement module may generate foreground mask based on digital note . Such a foreground mask can be used to separate the writing drawing from the background color. This can enable variable enhancement options for foreground and background e.g. for visually pleasing notes. Additionally as discussed above note enhancement module may digitally change the background color of the note after a physical note was captured.

In accordance with one or more techniques of this disclosure a device such as mobile device of may implement a hierarchical adaptive thresholding algorithm to extract binary masks of images of notes to separate the foreground from the background while providing low false positives artifacts . This algorithm can also be generalized to other images where there is a foreground present in noisy but uniform background.

In some examples the device may use dynamic scale selection. For instance as opposed to pre computing the adaptive threshold masks in all scales the device may compute the scales specifically for each connected component dynamically as necessary. In addition in some examples the device may integrate hypotheses for shadow in the background pixel relabeling steps i.e. steps of .

Various approaches may be used for enhancing images to improve their aesthetics and to remove undesirable effects such as shadows noise etc. . . . Among these binarization is an approach for creating layers of foreground and background in images to obtain high levels of contrast. Usually binarization is performed to extract an object of interest and provide it more contrast with respect to its background. Such binarization can be thought of as direct foreground detection agnostic to its visual characteristics as long as the background exhibits uniformity in color. In some examples binarization may be used to extract ventricular regions from cineangiograms e.g. Chow C. K. and T. Kaneko Automatic boundary detection of the left ventricle from cineangiograms Computers and biomedical research 5.4 1972 388 410 . For instance local windows across the image may be used to compute intensity histograms and compute thresholds dynamically. Pixels beyond these computed thresholds may be binarized as foreground. Simpler alternatives may be derived which replace computing full intensity histograms with computing approximate measures such as the mean median or average of the maximum and minimum values in the window. Such methods have also been used for document binarization see e.g. Sauvola Jaakko and Matti Pietik inen. Adaptive document image binarization. Pattern Recognition 33.2 2000 225 236 the entirety of which is hereby incorporated by reference. Integral image based computing methods may improve efficiency of the thresholding process see e.g. Shafait Faisal Daniel Keysers and Thomas M. Breuel. Efficient implementation of local adaptive thresholding techniques using integral images. DRR 6815 2008 681510 . An extensive survey comparing image thresholding techniques is provided in Sezgin M Sankur B Survey over image thresholding techniques and quantitative performance evaluation . J. Electron. Imaging. 0001 13 1 146 168 the entirety of which is hereby incorporated by reference.

In accordance with one or more techniques of this disclosure note enhancement module may use a hierarchical adaptive thresholding approach to enhance images of notes e.g. digital notes that correspond to physical notes . In some examples digital notes may have a uniform background color along with foreground content created often using different types of writing instruments. As such digital notes may comply with the requirements for achieving good binarization results. However direct application of adaptive thresholding for binarizing the digital note into foreground and background may not often produce desirable results. For example as illustrated in digital note may be an example result of obtaining a binarization using adaptive thresholding of original digital note . In the example of the device may use a window size of 21 21 pixels for adaptive thresholding an image size of 500 500 pixels i.e. original digital note is 500 pixels wide by 500 pixels tall . For other image sizes the window size may be scaled accordingly. In some examples the window size may be linearly scaled. In some examples the window size may be non linearly scaled.

This particular window size i.e. 21 21 for an image size of 500 500 pixels may result in very clean backgrounds with low false positives background wrongly predicted as foreground . However the particular window size may result in high false negatives foreground wrongly predicted as background . In some examples the device may decrease the number of high false negatives by increasing the window size for the adaptive thresholding process. For instance digital note may be an example result of obtaining a binarization using adaptive thresholding of original digital note using a larger window size than the window size used to generate digital note .

As shown in digital note the foreground objects are fully extracted. However digital note also includes multiple artifacts that are inaccurately extracted as foreground. In this process a device may perform a contrast stretch operation with the determination of the foreground and background. The background may have increased brightness V in the HSV color space and the foreground may have decreased brightness. This operation may make the artifacts look worse. In order to remedy this the device may perform a hierarchical search on multiple scales of adaptive thresholding. For instance the device may perform a hierarchical search on multiple scales of adaptive thresholding in accordance with the techniques of .

Step 1 The device may produce the adaptive threshold masks across various scales starting from native scale s and in octaves s 2 s 4 s 8 etc. .

Step 2 The device may use the native scale s as the seed of the hierarchical search . In some examples foreground objects missed in the native scale cannot be retrieved in lower scales. However for solid foreground objects the contour obtained in native scale can be used as a seed for searching in lower scales in some examples. In this step the device may perform a connected components extraction on the mask obtained at native scale 

Step 4 The device may sample background pixels surrounding the bounding box . In some examples the device may use 10 of the bounding box width height to define a local background neighborhood that defines which pixels are sampled in step . In some examples the device may only use pixels identified in the original mask as background pixels i.e. pixels in the original mask that correspond to 0 as these are the background pixels.

Step 5 The device may compute the average local background color i.e. using the sampling from Step 4 . In some examples the pixels are represented by the LAB color space and the device may only use the a and b components to compute the average local background color. In some examples the pixels are represented by an alternate chroma color space.

Step 6 The device may compute the average of the foreground pixels in the current connected component 

Step 7 The device may take each background pixel in the current connected component and compare the a and b values to the background average computed in Step 5 and the foreground average computed in step 6 . If the value is closer to the foreground value than background value and the pixel is a foreground pixel in the mask at scale s current 2 where s current is the current scale then assign the current pixel to the foreground .

Step 8 The device may determine the amount of change in the mask of each connected component. If the amount of change is greater than a certain threshold e.g. 70 the device may repeat Steps 3 to 7 at lower scales until the change is less than the threshold .

This process results in a hierarchically modified mask. One example of the change in the mask across different scales for digital note of is illustrated in . As illustrated by mask may represent a mask for digital note at a first scale which may be the native scale mask may represent a mask for digital note at a second scale mask may represent a mask for digital note at a third scale and mask may represent a mask for digital note at a fourth scale.

In accordance with one or more techniques of this disclosure a device such as mobile device of may receive an input image . In some examples one or more processors of the device may execute an image processing engine e.g. image processing engine of to receive image data comprising a visual representation of a scene that includes a plurality of physical notes that each include respective recognizable content. For instance processor of mobile device may execute image processing engine to receive image data e.g. as image data of comprising a visual representation of scene that includes a plurality of physical notes that each include respective recognizable content e.g. notes A C of . In some examples image data may be an example of an image of images of . In some examples operation may be an example of operation of .

In any case the device may perform pixel wise color classification . For instance the device may execute one or more color classification algorithms e.g. based on Linear Non Linear Discriminant Analysis to detect and distinguish different colored regions in the input image.

The device may perform morphological processing and extract connected components . For instance the device may perform morphological processing to remove regions that do not conform to one or more constraints e.g. shapes ratios sizes etc. . As one example the device may remove regions that are non rectangular.

In some examples each of the physical notes represented by the input image may have a plurality of differently colored regions. For instance as illustrated in each of notes A C may include a first colored region A C collectively first colored regions or yellow regions respectively and a second colored region A C collectively second colored regions or blue regions respectively. In some examples the input image may include one or more regions that are not associated with any of the notes. For instance as illustrated in input image may include region which is not associated with any of notes . However as illustrated in region may be similar to a region of second colored regions .

In accordance with one or more techniques of this disclosure the device may exploit the fact that the notes include a plurality of differently colored regions to improve the accuracy at which the notes may be identified recognized. For instance the device may perform color pair matching to e.g. pair the regions . As one example the device may execute a Hungarian Algorithm to perform the color pair matching based on the assumption that each note includes a single first colored region and a single second colored region. For instance when executing the Hungarian Algorithm the device may verify if the distance between a first colored region e.g. first colored regions of and a second colored region e.g. second colored regions of is the shortest among all possible distances between that first second colored region with other first second colored regions. In some examples if the distances are shortest mutually the device may consider the regions to be a pair. Also the device may not assign outliers such as region of to any pair. This may be a natural consequence of the Hungarian Algorithm. The device may pair the first colored region closest to the outlier i.e. first colored region C with the outlier e.g. outlier because there exists another second colored region which is closer to the first colored region.

If the device achieves color pairing the device may extract digital notes from the input image . For instance the device may extract a digital note for each pair of regions. As illustrated in the device may extract a digital note for each note of notes .

In some examples the device may perform rotation and or inversion adjustment on the extracted digital notes . In some examples the device may determine an orientation of the note based on a line that joins features e.g. centroids of a pair of regions. For instance the device may determine an angle formed by the line and a Y axis of the digital note and rotate the digital note based on the determined angle to compensate. As illustrated in the example of the device may determine line that joins centroid of first colored region B with centroid of second colored region B of note B. The device may determine angle formed by line and Y axis . Based on angle the device may rotate digital note B. For instance if angle is 20 degrees the device may rotate digital note B counter clockwise 20 degrees.

A method comprising receiving by one or more processors of a device a digital note of a plurality of digital notes generated based on image data comprising a visual representation of a scene that includes a plurality of physical notes such that each of the plurality of digital notes respectively corresponds to a particular physical note of the plurality of physical notes wherein each of the physical notes includes respective recognizable content receiving by the one or more processors user input indicating a modification to one or more visual characteristics of the digital note editing by the one or more processors and in response to the user input the one or more visual characteristics of the digital note and outputting by the one or more processors and for display a modified version of the digital note that includes the one or more visual characteristics.

The method of example 1 wherein receiving the user input comprises receiving user input that indicates additional content for the digital note editing the one or more visual characteristics of the digital note comprises creating a layer object that includes the additional content and outputting the modified updated version of the digital note comprises outputting the modified version of the digital note such that the layer object that includes the additional content is displayed on top of content corresponding to the respective recognizable content of the physical note to which the digital note corresponds.

The method of any combination of examples 1 2 wherein the additional content is first additional content the layer object is a first layer object of a plurality of layer objects and the modified version of the digital note is a first modified version of the digital note the method further comprising responsive to receiving user input indicating second additional content creating a second layer of the plurality of layer objects that includes the second additional content and outputting for display a second modified version of the digital note such that the second layer object that includes the second additional content is displayed on top of the first layer object that includes the first additional content.

The method of any combination of examples 1 3 further comprising responsive to receiving user input to remove the second layer object from the updated version of the digital note outputting for display a third modified version of the digital note such that the second additional content included in the second layer object is not displayed.

The method of any combination of examples 1 4 wherein receiving the user input that indicates the additional content comprises receiving one or more of a sequence of typed characters and a stroke gesture.

The method of any combination of examples 1 5 wherein receiving the user input comprises receiving user input that indicates an updated background color editing the one or more visual characteristics of the digital note comprises setting a background color of the digital note to the updated background color.

The method of any combination of examples 1 6 further comprising identifying for the digital note a foreground region that includes content corresponding to recognizable content of the physical note to which the digital note corresponds wherein at least a portion of the content of the foreground region is associated a foreground color and modifying the foreground color.

The method of any combination of examples 1 7 wherein receiving the user input comprises receiving user input that indicates an updated foreground color and modifying the foreground color comprises setting the foreground color to the updated foreground color in response to receiving user input that indicates the updated foreground color.

The method of any combination of examples 1 8 wherein modifying the foreground color comprises automatically modifying the foreground color as a function of the updated background color.

The method of any combination of examples 1 9 wherein prior to modifying the foreground color a plurality of pixels included in the foreground region have current foreground pixel colors and wherein modifying the foreground color comprises modifying colors of the plurality of pixels included in the foreground region by at least selecting by the one or more processors and for each pixel of the plurality of pixels included in the foreground region an updated foreground pixel color such that a contrast ratio between the updated foreground pixel color and the updated background color is greater than a contrast ratio between the current foreground pixel color and the updated background color and setting each respective pixel of the plurality of pixels to the selected respective updated foreground pixel color.

The method of any combination of examples 1 10 further comprising identifying subsequent to identifying the foreground region of the digital note a background region of the digital note by at least identifying pixels of the digital note not included in the foreground region as the background region.

The method of any combination of examples 1 10 further comprising identifying a background region of the digital note by at least identifying pixels of the digital note not included in the foreground region as the background region wherein identifying the foreground region is performed subsequent to identifying the background region and wherein identifying the foreground region for the particular digital note comprises identifying pixels of the particular digital note not included in the background region as the foreground region.

The method of any combination of examples 1 12 wherein receiving the digital note of the plurality of digital notes comprises receiving by the one or more processors and from a camera of the device the image data comprising the visual representation of the scene that includes the plurality of physical notes and generating by the one or more processors and based on the image data the plurality of digital notes that each respectively correspond to the particular physical note of the plurality of physical notes.

The method of any combination of examples 1 13 further comprising enhancing by the one or more processors the digital note of the plurality of digital notes by at least identifying for the digital note a foreground region that includes content corresponding to the respective recognizable content of the physical note to which the digital note corresponds identifying a background region of the digital note and setting pixel values from the background region of the particular digital note to a uniform background pixel value.

The method of any combination of examples 1 14 wherein the physical note to which the digital note corresponds includes a first colored region and a second colored region the method further comprising identifying for the digital note the first colored region and a second colored region determining an angle formed by an axis of the digital note and a line connecting a feature of the first colored region and a feature of the second colored region and rotating the digital note based on the determined angle.

A computing device comprising a memory configured to store digital notes and one or more processors configured to receive a digital note of a plurality of digital notes generated based on image data comprising a visual representation of a scene that includes a plurality of physical notes such that each of the plurality of digital notes respectively corresponds to a particular physical note of the plurality of physical notes wherein each of the physical notes includes respective recognizable content receive user input indicating a modification to one or more visual characteristics of the digital note edit in response to the user input the one or more visual characteristics of the digital note and output for display a modified version of the digital note that includes the one or more visual characteristics.

The computing device of example 16 wherein the one or more processors are configured to perform the method any combination of examples 1 15.

A computing system comprising means for receiving a digital note of a plurality of digital notes generated based on image data comprising a visual representation of a scene that includes a plurality of physical notes such that each of the plurality of digital notes respectively corresponds to a particular physical note of the plurality of physical notes wherein each of the physical notes includes respective recognizable content means for receiving user input indicating a modification to one or more visual characteristics of the digital note means for editing in response to the user input the one or more visual characteristics of the digital note and means for outputting for display a modified version of the digital note that includes the one or more visual characteristics.

The computing system of example 18 further comprising means for performing the method any combination of examples 1 15.

A computer readable storage medium storing instructions that when executed cause one or more processors of a device to receive a digital note of a plurality of digital notes generated based on image data comprising a visual representation of a scene that includes a plurality of physical notes such that each of the plurality of digital notes respectively corresponds to a particular physical note of the plurality of physical notes wherein each of the physical notes includes respective recognizable content receive user input indicating a modification to one or more visual characteristics of the digital note edit in response to the user input the one or more visual characteristics of the digital note and output for display a modified version of the digital note that includes the one or more visual characteristics.

The computer readable storage medium of example 20 further storing instructions that cause the one or more processors to perform the method any combination of examples 1 15.

A method comprising receiving by a computing device an input image of an environment having a plurality of physical notes processing the input image with the computing device to identify the plurality of physical notes in the input image generating by the computing device a plurality of digital notes corresponding to the plurality of notes identified in the input image wherein the plurality of digital notes include information represented by the plurality of notes in the input image displaying on a first portion of a graphical user interface of the computing device the input image overlaid with the plurality of digital notes in place of the identified plurality of notes and displaying by the computing device a set of one or more of the plurality of digital notes on a second portion of the graphical user interface wherein each of the digital notes in the set of digital notes displayed in the second portion corresponds to a respective one of the plurality of digital notes displayed in the first portion and overlaid on the input image.

The method of example 21 further comprising receiving by the computing device a user input selecting for deletion at least one of the plurality of digital notes displayed in the first portion of the graphical user interface and removing by the computing device and from the set of digital notes displayed in the second portion of the graphical user interface digital notes that correspond to the digital notes of the first portion of the graphical user interface selected for deletion.

The method of any combination of examples 22 23 wherein the plurality of digital notes from the first portion is greater than the plurality of digital notes in the second portion the method further comprising receiving by the computing device a user input selecting at least one of the digital notes from the first portion that is not displayed in the second portion and adding by the computing device the selected digital note from the first portion to the set of digital notes displayed on the second portion.

The method of any combination of examples 22 24 further comprising receiving by the computing device a user input selecting a subset of the plurality of digital notes and grouping by the computing device the selected subset of digital notes to form one or more groups.

The method of any combination of examples 22 25 wherein the one or more groups are organized accordingly to a group hierarchy defined by the user input.

A non transitory computer readable medium comprising instructions for causing a programmable processor to execute the method of any of examples 22 26.

A computing device comprising a processor an image collection module executable by the processor and configured to receive an input image of an environment having a plurality of physical notes an image processing engine executable by the processor and configured to identify the plurality of physical notes in the input image and generate a plurality of digital notes corresponding to the plurality of notes identified in the input image wherein the plurality of digital notes include information represented by the plurality of notes in the input image and a graphical user interface configured to display the input image overlaid with the plurality of digital notes in place of the identified plurality of notes on a first portion of the graphical user interface and to display a set of one or more of the digital notes on a second portion of the graphical user interface.

The device of example 29 wherein the image collection module includes an image capture device configured to capture the input image.

The device of any combination of examples 29 30 wherein the image collection module includes a communication interface configured to receive the input image.

The device of any combination of examples 29 31 wherein the communication interface includes a wireless communication device configured to receive the input image.

The device of any combination of examples 29 32 wherein the communication interface includes a wired communication device configured to receive the input image.

The device of any combination of examples 29 33 wherein the user interface is further configured to receive a user input selecting for deletion at least one of the plurality of digital notes displayed in the first portion of the graphical user interface and remove from the set of digital notes displayed in the second portion of the graphical user interface any of the digital notes that correspond to the digital notes of the first portion of the graphical user interface selected for deletion.

The device of any combination of examples 29 34 wherein the plurality of digital notes from the first portion is greater than the plurality of digital notes in the second portion the image processing engine is further configured to receive a user input selecting at least one of the plurality of digital notes from the first portion that is not in the second portion and add the selected plurality of digital notes from the first portion to the second portion.

The device of any combination of examples 29 35 wherein the image processing engine is further configured to receive a user input selecting at least one of the plurality of digital notes between the first portion and the second portion and group the selected plurality of digital notes between the first portion and the second portion to form one or more groups.

The device of any combination of examples 29 36 wherein the one or more groups are organized accordingly to a group hierarchy defined by the user input.

The device of any combination of examples 29 37 wherein the image processing engine is further configured to display indications of the one or more groups in conjunction with the plurality of digital notes presented on the first portion.

The device of any combination of examples 29 38 wherein the image processing engine is further configured to display indications of the one or more groups in conjunction with the plurality of digital notes presented on the second portion.

A method comprising receiving by a computing device an input image identifying by the computing device a plurality of notes in the input image editing by the computing device background colors from one or more of the plurality of notes identified in the input image generating by the computing device a plurality of digital notes corresponding to the plurality of notes identified in the input image the plurality of digital notes incorporating the edited background colors storing by the computing device the plurality of digital notes to a digital data storage device for retrieval by a user wherein the plurality of digital notes include information represented by the plurality of notes in the input image.

The method of example 40 wherein the computing device utilizes a shape detection module to identify at least one of the plurality of notes based on shapes defined by perimeters of the plurality of notes in the input image

The method of any combination of examples 40 41 wherein identifying the plurality of notes in the input image includes identifying the plurality of notes according to color spaces associated with background colors the plurality of notes.

The method of any combination of examples 40 42 wherein the computing device utilizes a pattern detection module to identify at least one of the plurality of notes wherein the pattern detection module is comprised of pattern recognition algorithms including at least one of a group consisting of a support vector machine algorithm a cross correlation algorithm and a template matching algorithm.

The method of any combination of examples 40 43 wherein generating the plurality of digital notes further comprises correcting by the computing device shadows lighting rotation and scaling of notes in the input image.

The method of any combination of examples 40 44 wherein the input image includes at least one of a group consisting of a digital image a digital video and a continuous digital scan.

The method of any combination of examples 40 45 wherein the plurality of notes in the input image includes at least one of a group consisting of a 7.62 7.62 centimeter cm note a 66.04 99.06 cm poster a triangular metal sign a sticker and a 8.5 11 in sheet of paper.

The method of any combination of examples 39 45 wherein generating the plurality of digital notes includes for each of the plurality of digital notes incorporating in the digital note visual information of the corresponding note in the input image.

A non transitory computer readable medium comprising instructions for causing a programmable processor to execute the method of any combination of examples 40 47.

A computing device comprising an image collection module configured to receive an input image an image processing engine configured to identify a plurality of notes in the input image received by the image collection module and generate a plurality of digital notes corresponding to the plurality of notes identified in the input image wherein the plurality of digital notes include information represented by the plurality of notes in the input image and a digital data storage device configured to store the plurality of digital notes generated by the image processing module for retrieval by a user.

The device of example 50 wherein the image collection module includes an image capture device configured to capture the input image.

The device of any combination of examples 50 51 wherein the image collection module includes a communication interface configured to receive the input image.

The device of any combination of examples 50 52 wherein the communication interface includes a wireless communication device configured to receive the input image.

The device of any combination of examples 50 53 wherein the communication interface includes a wired communication device configured to receive the input image.

The device of any combination of examples 50 54 wherein the digital data storage device is configured to store the input image.

The device of any combination of examples 50 55 wherein the image processing engine includes a shape detection module configured to identify at least one of the plurality of notes based on shapes defined by perimeters of the plurality of notes in the input image.

The device of any combination of examples 50 56 wherein the image processing engine is further configured to identify the plurality of notes in the input image includes identifying the plurality of notes according to color spaces associated with background colors the plurality of notes.

The device of any combination of examples 50 57 wherein the image processing engine includes a pattern detection module configured to identify at least one of the plurality of notes wherein the pattern detection module is comprised of pattern recognition algorithms including at least one of a group consisting of a support vector machine algorithm a cross correlation algorithm and a template matching algorithm.

The device of any combination of examples 50 58 wherein the image processing engine is further configured to correct shadows lighting rotation and scaling of notes in the input image.

The device of any combination of examples 50 59 wherein the input image includes at least one of a group consisting of a digital image a digital video and a continuous digital scan.

The device of any combination of examples 50 60 wherein the plurality of notes in the input image includes at least one of a group consisting of a 7.62 7.62 centimeter cm note a 66.04 99.06 cm poster a triangular metal sign a sticker and a 8.5 11 in sheet of paper.

The device of any combination of examples 50 61 wherein the image processing engine is further configured to for each of the plurality of digital notes incorporate in the digital note visual information of the corresponding note in the input image.

The techniques described in this disclosure may be implemented at least in part in hardware software firmware or any combination thereof. For example various aspects of the described techniques including the disclosed mobile device cloud and or computer system may be implemented within one or more processors including one or more microprocessors digital signal processors DSPs application specific integrated circuits ASICs field programmable gate arrays FPGAs or any other equivalent integrated or discrete logic circuitry as well as any combinations of such components.

Such hardware software and firmware may be implemented within the same device or within separate devices to support the various techniques described in this disclosure. In addition any of the described units modules or components may be implemented together or separately as discrete but interoperable logic devices. Depiction of different features as modules or units is intended to highlight different functional aspects and does not necessarily imply that such modules or units must be realized by separate hardware firmware or software components. Rather functionality associated with one or more modules or units may be performed by separate hardware firmware or software components or integrated within common or separate hardware firmware or software components.

The techniques described in this disclosure may also be embodied or encoded in a computer readable medium such as a transitory or non transitory computer readable storage medium containing instructions. Instructions embedded or encoded in a computer readable medium including a computer readable storage medium may cause one or more programmable processors or other processors such one or more processors included in a control system to implement one or more of the techniques described herein such as when instructions included or encoded in the computer readable medium are executed by the one or more processors. Non transitory computer readable storage media may include random access memory RAM read only memory ROM programmable read only memory PROM erasable programmable read only memory EPROM electronically erasable programmable read only memory EEPROM flash memory a hard disk a compact disc ROM CD ROM a floppy disk a cassette magnetic media optical media or other computer readable media. In some examples an article of manufacture may comprise one or more computer readable storage media.

Various examples of this disclosure have been described. These and other examples are within the scope of the following claims.

