---

title: Focus position estimation
abstract: A method for lens position estimation can include receiving from a lens driver a drive current value representing a current to be provided to a motor to position a camera lens of an electronic device, detecting an orientation of the electronic device using a motion sensor, determining a gravity vector based upon the orientation, and computing an estimated value of a lens position of the camera lens of the electronic device based upon the drive current value and gravity vector.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09210317&OS=09210317&RS=09210317
owner: Apple Inc.
number: 09210317
owner_city: Cupertino
owner_country: US
publication_date: 20140714
---
The present application is a continuation of and claims priority to U.S. patent application Ser. No. 13 327 335 filed on Dec. 15 2011 which is herein incorporated by reference in its entirety.

The present invention relates to estimating the focus position of a camera lens within an electronic device.

Many electronic devices include cameras with focus capabilities. An electronic device including a camera may include manual focus auto focus or both. Exemplary electronic devices include but are not limited to mobile telephones personal digital assistants portable music players portable video players and portable computer systems such as laptops notebooks and tablet computers. During a manual focus or auto focus operation a lens driver in the camera adjusts the focus position of the camera lens which is the distance between the center of the camera lens and the sensor imaging plane. The focus position of a camera lens may be used by applications such as within imaging or computer vision applications. The focus position can be used within these applications to determine geometric information such as the distance of an object from the camera for example.

During a focus operation the focus position of the camera lens is adjusted using a lens driver which is powered using a drive current. The value of the drive current can be used to estimate the focus position. However estimating the focus position based solely upon a measured drive current can lead to inaccurate results due to variables such as the orientation of the electronic device. Thus a need exists for an improved technique of accurately estimating a focus position for a camera lens.

Embodiments of the present invention provide techniques for estimating the focus position of a camera lens. A drive current value may be received from a lens driver. An orientation of an electronic device may be detected using a motion sensor. A gravity vector based upon the orientation may then be determined. A drive current offset may be determined based upon the gravity vector. The drive current value may be combined with the calculated drive current offset to create a normalized drive current. A lens position value associated with a camera lens of the electronic device may be computed based upon the normalized drive current.

The motion sensor may output data representing an orientation of the system . The processor may derive a gravity vector from the motion sensor data representing the lens s orientation in space. The motion sensor may be provided as a accelerometer a gyroscope or a compass. In an embodiment a gravity vector is derived from an accelerometer using a low pass filter of motion sensor data. The calibration memory may store data representing drive current calibration factors based on the lens s orientation in space.

The processor represents processing capability of the system to derive a lens position based on drive current data output by the lens driver and motion sensor data . The processor may determine a gravity vector or value based upon motion sensor data . For example gravitational pull affecting the lens driver may change based upon the orientation of the device. The effect of gravity may influence the drive current value received by the processor from the lens driver. The processor may use a gravity vector to determine a drive current offset which may be positive or negative. The processor may combine the drive current offset with the drive current data to calculate a normalized drive current. In an embodiment the processor may calculate a lens position value associated with a camera lens of an electronic device based upon the normalized drive current.

The processor may be embodied by a central processing unit of the electronic device in which the camera system is provided. Alternatively the processor may be embodied by processing logic within an integrated circuit of the device for example an integrated circuit that includes the lens driver . In either embodiment the system may output data representing the lens s position to other components within the device such as an operating system or applications not shown within the device. In an embodiment lens position data may be output to one or more applications within the device via an application programming interface API . An API may be one or more software abstraction layers that allow high level applications to interface with software and hardware. Examples of software may be operating systems firmware web applications or standalone software products. Examples of hardware may be central processing units modems Wi Fi cards global positioning systems or display screens.

In an embodiment the lens position may be output to components within the device to perform various functions. In an embodiment the lens position may be used to calculate the distance between an electronic device and an object. The distance d may be calculated using a lens position p and a focal length f using the following equation 1 d 1 f 1 p . In an embodiment the lens position may be used by one or more imaging applications such as a video application. A video application may use lens position information for functions such as video stabilization.

The normalized current value may be input to a drive curve calibrator . The drive curve calibrator may output a value representing a position of the camera lens based on the normalized current value .

In practice the orientation calibrator may be implemented as a look up table that stores offset values for the camera and is indexed by gravity vector values. The look up table may store offset values derived from a predetermined calibration operation representing changes in offset current required at each orientation to drive a lens to a predetermined position within its field of displacement. Each orientation would be matched to a predetermined gravity vector. During operation when a gravity vector is input to the orientation calibrator an offset may be read from the look up table corresponding to an entry with a closest matching gravity vector. Alternatively when an input gravity vector does not match exactly an index value to the look up table an offset value may be interpolated from two or more matching indices.

Similarly in practice the drive curve calibrator may be implemented as a look up table that stores lens positions for the camera indexed by current values. The look up table may store data representing a lens s position at various drive current values. Typically the lens position data is obtained during a calibration operation in which various drive current values are applied to a lens and the lens position is measured. Alternatively the calibration operation may be performed to cause a lens system to focus on a given object at various distances from a camera. which requires the auto focus system to move the lens to a variety of focus positions corresponding to the object distances. The drive current may be measured at each of the lens positions and stored in the look up table.

During the calibration operation the lens s orientation with respect to gravity may be maintained at a predetermined position. By way of example the lens may be set to face up in a horizontal position. At this position gravitational pull on the lens may require additional drive current to drive the lens to a predetermined position than when no gravitational pull is present as the driver is working against gravity. A lens set to face down in a horizontal position often requires less drive current to drive the lens to a predetermined position than when no gravitational pull is present as the driver is working with gravity.

At step a motion sensor may detect an orientation of an electronic device. The orientation of the electronic device may be detected using one or multiple motion sensors which may include an accelerometer gyroscope or a compass. In the case of an accelerometer the orientation of the electronic device may be derived using a low pass filter of the accelerometer.

At step a gravity vector may be determined based upon the detected orientation. The gravity vector may represent a value associated with the gravitational pull experienced by the lens driver at a particular detected orientation. In the case of an accelerometer the gravity vector of the electronic device may be derived using a low pass filter of the accelerometer output along the z axis. In another embodiment the gravity vector may be determined using a predetermined look up table that stores gravity vectors for the camera indexed by camera orientation values. Each orientation may be matched to a predetermined gravity vector.

At step a drive current offset may be determined. The drive current offset may represent a value used to compensate for the gravitational pull experienced by a lens driver at a particular orientation. During operation when a gravity vector is determined an offset may be read from a predetermined look up table corresponding to an entry with a closest matching gravity vector. Alternatively when an input gravity vector does not match exactly an index value to the look up table an offset value may be interpolated from two or more matching indices.

At step a normalized drive current may be calculated using the drive current value from step and the drive current offset determined in step . The drive current offset may be a positive or negative value thus combining the drive current offset with the drive current value may result in an increased or decreased normalized drive current.

At step a lens position may be calculated using the normalized drive current. In practice the lens position may be calculated from a predetermined a look up table that stores lens positions for the camera indexed by current values. The look up table may store data representing a lens s position at various drive current values. Typically the lens position data is obtained during a calibration operation in which various drive current values are applied to a lens and the lens position is measured. Alternatively the calibration operation may be performed to cause a lens system to focus on a given object at various distances from a camera which requires the auto focus system to move the lens to a variety of focus positions corresponding to the object distances. The drive current may be measured at each of the lens positions and stored in the look up table.

Once calculated the lens position may be utilized by hardware within an electronic device or one or more software applications within an electronic device. In an embodiment the lens position may be used to calculate the distance between an electronic device and an object. The distance d may be calculated using the focus position p and the focal length f using the following equation 1 d 1 f 1 p . In an embodiment the lens position may be used by one or more imaging applications such as a video application. A video application may use lens position information for functions such as video stabilization.

Processor may be any suitable programmable control device or general or special purpose processor or integrated circuit and may execute instructions necessary to carry out or control the operation of many functions such as the generation and or processing of image metadata as well as other functions performed by electronic device . Processor may for instance drive display and may receive user input from user interface . Processor may also for example be a system on chip such as an application s processor such as those found in mobile devices or a dedicated graphics processing unit GPU . Processor may be based on reduced instruction set computer RISC or complex instruction set computer CISC architectures or any other suitable architecture and may include one or more processing cores.

Memory may include one or more different types of storage media used by processor to perform device functions. Memory may include for example cache read only memory ROM and or random access memory RAM . Communications bus may provide a data transfer path for transferring data to from or between at least storage device memory processor and camera circuitry . User interface may allow a user to interact with electronic device . For example user interface can take a variety of forms such as a button keypad dial a click wheel or a touch screen.

Non transitory storage device may store media e.g. image and video files computer program instructions or software preference information device profile information and any other suitable data. Storage device may include one more storage mediums including for example magnetic disks fixed floppy and removable and tape optical media such as CD ROMs and digital video disks DVDs and semiconductor memory devices such as Electrically Programmable Read Only Memory EPROM and Electrically Erasable Programmable Read Only Memory EEPROM .

Video codec may be a hardware device a software module or a combination of hardware and software that enables video compression and or decompression of digital video. For example video codec may implement the H.264 video standard. Communications bus may be any one or more communication paths and employ any technology or combination thereof that is appropriate for the particular implementation.

Software may be organized into one or more modules and be written in any suitable computer programming language or more than one language . When executed by for example processor such computer program code or software may implement one or more of the methods described herein.

Various changes in the materials components circuit elements as well as in the details of the illustrated operational methods are possible without departing from the scope of the following claims. For instance processor may be implemented using two or more program control devices communicatively coupled. Each program control device may include the above cited processors special purpose processors or custom designed state machines that may be embodied in a hardware device such as an application specific integrated circuit ASIC or a field programmable gate array FPGA .

In the above description for purposes of explanation numerous specific details have been set forth in order to provide a thorough understanding of the inventive concepts. As part of the this description some structures and devices may have been shown in block diagram form in order to avoid obscuring the invention. Reference in the specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the invention and multiple references to one embodiment or an embodiment should not be understood as necessarily all referring to the same embodiment.

It will be appreciated that in the development of any actual implementation as in any development project numerous decisions must be made to achieve the developers specific goals e.g. compliance with system and business related constraints and that these goals will vary from one implementation to another. It will also be appreciated that such development efforts might be complex and time consuming but would nevertheless be a routine undertaking for those of ordinary skill in the lens position estimation and digital imagery field having the benefit of this disclosure.

It is to be understood that the above description is intended to be illustrative and not restrictive. For example the above described embodiments may be used in combination with each other. Many other embodiments will be apparent to those of skill in the art upon reviewing the above description. The scope of the invention therefore should be determined with reference to the appended claims along with the full scope of equivalents to which such claims are entitled. In the appended claims the terms including and in which are used as the plain English equivalents of the respective terms comprising and wherein. 

