---

title: Synchronization of haptic effect data in a media transport stream
abstract: A method for synchronizing haptic effects with at least one media component in a media transport stream includes identifying a series of video frames containing imaging information and/or a series of audio frames containing sound information in the media transport stream; identifying a series of haptic frames containing force feedback information in the media transport stream; and synchronizing the force feedback information in response to the imaging information and/or sound information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09615002&OS=09615002&RS=09615002
owner: IMMERSION CORPORATION
number: 09615002
owner_city: San Jose
owner_country: US
publication_date: 20140414
---
This application is a continuation application of U.S. patent application Ser. No. 11 583 483 filed Oct. 18 2006 which claims the benefit of priority from U.S. Provisional Patent Application Ser. No. 60 728 551 filed Oct. 19 2005 the contents of both of which are hereby incorporated herein by reference in their entireties.

The present invention relates to the field of haptics. More particularly the present invention relates to haptic effects encoded in media transport streams.

To improve the interface between a user and a machine incorporating haptic effects into the interface along with audio video media has become more and more prevalent in recent years. Haptic effects such as vibrations can be felt by a user and may typically be related to an event trigger such as the depressing of a key on a device or the playing of ring tones to announce an incoming call or the receipt of a text message on a cellphone and the like. Generally media playback can be complemented with vibrations. However conventional methods of implementing haptic effects have some problems when playing a haptic signal along with a media signal over a period of time.

One such problem is the need to synchronize playback between haptic signals and other media signals such as video and or audio signals. Typically the audio engine video engine and the haptic engine operate on different clocks. There is usually no built in synchronization mechanism during playback of haptic video and audio signals. Although for example at the beginning of a playback the haptic signal and the media signal may start within a few milliseconds of one another and as such are adequately synchronized these signals can usually drift out of sync in a fairly short period of time.

Another such problem is that it can be difficult to randomly access a point in a media transport stream having both media and haptic signals. In other words it is difficult to synchronize the haptic signals with media signals when a user begins the playback of a portion of the media transport stream at a random point without access to any data that may occur before this point in the media transport stream.

As such what is needed is a solution that provides a mechanism to synchronize haptic effects with other media e.g. audio and video which can operate at or from any point in a media transport stream containing both haptic and media information.

A method and apparatus for synchronizing haptic effects with other media components i.e. video and or audio in a media transport stream is disclosed. The method includes identifying a series of video frames containing imaging information and or a series of audio frames containing sound information in the media transport stream identifying a series of haptic frames containing force feedback information in the media transport stream and synchronizing the force feedback information in response to the imaging information and or sound information.

Additional features and benefits of the present invention will become apparent from the detailed description figures and claims set forth below.

Embodiments of the present invention are described herein in the context of a method system and apparatus for communicating a media transport stream including haptic information. Those of ordinary skill in the art will realize that the following detailed description of the present invention is illustrative only and is not intended to be in any way limiting. Other embodiments of the present invention will readily suggest themselves to such skilled persons having the benefit of this disclosure. Reference will now be made in detail to implementations of the present invention as illustrated in the accompanying drawings. The same reference indicators will be used throughout the drawings and the following detailed description to refer to the same or like parts.

In the interest of clarity not all of the routine features of the implementations described herein are shown and described. It will of course be appreciated that in the development of any such actual implementation numerous implementation specific decisions must be made in order to achieve the developer s specific goals such as compliance with application and business related constraints and that these specific goals will vary from one implementation to another and from one developer to another. Moreover it will be appreciated that such a development effort might be complex and time consuming but would nevertheless be a routine undertaking of engineering for those of ordinary skill in the art having the benefit of this disclosure.

In accordance with the present invention the components process steps and or data structures described herein may be implemented using various types of operating systems computing platforms computer programs and or general purpose machines. In addition those of ordinary skill in the art will recognize that devices of a less general purpose nature such as hardwired devices field programmable gate arrays FPGAs application specific integrated circuits ASICs or the like may also be used without departing from the scope and spirit of the inventive concepts disclosed herein. Where a method comprising a series of process steps is implemented by a computer or a machine and those process steps can be stored as a series of instructions readable by the machine they may be stored on a tangible medium such as a computer memory device e.g. ROM Read Only Memory PROM Programmable Read Only Memory EEPROM Electrically Eraseable Programmable Read Only Memory FLASH Memory Jump Drive and the like magnetic storage medium e.g. tape magnetic disk drive and the like optical storage medium e.g. CD ROM DVD ROM paper card and paper tape and the like and other known types of program memory.

The present invention is generally directed to a mechanism for synchronizing haptic effect tracks with other media tracks contained in a multi track media transport stream to generate synchronized multimedia effects. Haptic information in a series of frames in a media transport stream is identified and time stamps corresponding thereto are determined in accordance with a master time code signal embedded in the media transport stream. Each media transport stream frame containing haptic information is subsequently assigned a time stamp so that it will be used to activate an actuator at a proper time responsive to the time stamp to generate a haptic effect in accordance with the haptic information.

Encoder for one example is capable of encoding or generating video frames from video block audio frames from audio block and haptic frames from haptic block and integrating them into a media transport stream in accordance with for example a commercially available media transport protocol such as Moving Picture Experts Group Compression Standard Version 4 MPEG 4 and the like. In other words video frames audio frames and haptic frames are encoded or packaged into a media transport stream and that media transport stream is subsequently transmitted to a user designated destination over a communications medium . It should be noted that integrating timed haptic information into various frames can apply to any media transport stream format and is not limited to a particular file type protocol or media player hardware environment.

Communications medium can be a line or wire communications medium a wireless communications medium or a hybrid wire and wireless communications medium. The video frames from video block and audio frames from audio block form respectively a video component and an audio component or collectively a media component of the media transport stream. The haptic frames form a haptic component of the media transport stream. Receiver which could be a media player such as a phone or PC is capable of receiving a media transport stream over a communications medium . In one embodiment the media transport stream is stored in a memory such as a conventional digital video recorder a network messaging center or the like prior to being received by receiver . In another embodiment the haptic signal transported by the media transport stream is compressed or encrypted to enhance the data security.

Receiver includes a decoder a video block an audio block and a haptic block . Video block audio block and haptic block in one embodiment are used to store video frames audio frames and haptic frames respectively. Receiver may be a cellular phone a SmartPhone a PDA a PC a transmitter receiver device or the like which is capable of receiving media transport streams over communications medium . Upon receipt of the media transport stream receiver parses video frames audio frames and haptic frames from the media transport stream and sends video frames to video block audio frames to audio block and haptic frames to haptic block . It should be noted that video frames in video block audio frames in audio block and haptic frames in haptic block contain substantially similar information to video frames in video block audio frames in audio block and haptic frames in haptic block respectively. It should be further noted that video frames in video block audio frames in audio block and haptic frames in haptic block may have where appropriate different data formats from corresponding video frames in video block audio frames in audio block and haptic frames in haptic block although they may contain similar information.

It should also be noted that transmitter and receiver may be similar devices that both contain similar capabilities for transmitting and receiving.

During operation media sync layer synchronizes the disparate media by delivering frames of each media type to the appropriate codec or player at a time specified by the master time code or a timing table. A set of frames representing the entire timeline is transmitted to media player via the media transport stream. Upon receipt of the media transport stream media player evaluates and separates audio video and haptic data or frames from the media transport stream. Media sync layer subsequently assigns time stamps or initial time to each haptic frame according to a master time code whereby the time stamps can be used to send haptic effect timing and definitions to Haptic Unit which can activate an actuator or multiple actuators at the proper time.

A function of API is to initiate haptic effects at the correct time since each haptic frame is a self contained haptic effect which does not rely on other frames. An advantage of having a self contained haptic frame is that it permits a user to randomly access a haptic frame or a media frame when using Media Player and ensure that the system will still be able to generate a synchronized multimedia output including image sound and haptic effects.

Video component includes a stream of a plurality of sequential video frames such as frame V. Audio component includes a stream of a plurality of sequential audio frames such as frames A and A. Haptic component also includes a stream of a plurality of sequential haptic frames such as frames H H and so on. While the frame formats may be different between the video audio and haptic frames the frames within the component will be configured in accordance with a common protocol. For example haptic frame H is substantially the same size as haptic frame H. In another embodiment the time span covered by H and H are for example 200 ms each but their physical memory footprints are usually different. It should be noted that the haptic frame sizes in one embodiment are determined by the length of time as oppose to physical capacity.

Referring back to at time stamp to haptic frame H audio frame A and video frame V begin playback at substantially the same time. Although haptic frame H finishes playing at time stamp t haptic effects defined in frame H might still be playing beyond time t. At time stamp t haptic frame H starts to be processed for playing. It should be noted that the initial time or time stamp at which haptic frame H is played corresponds to a time determined from the master time code. Assigning a time stamp to a haptic frame allows the haptic frame such as frame H to begin playback independent from the time at which the preceding haptic frame such as frame H is finished playing. Thus if haptic frame H has finished playing prior to time stamp t no haptic effects will be played until haptic frame H is played at time stamp t. At time stamp t. haptic frame H and audio frame A will be played. At time stamp t haptic frame H video frame V and audio frame A will be played.

Encoding time stamps within the haptic frames enable a user to randomly access a haptic frame which is still able to synchronize its haptic effect s with other media components.

For example if a user were to fast forward to time for example the player would wait until time tbefore playing the next haptic frame nH. Prior to that no haptic effects would be instance played. Similarly the player would wait until t which in this instance is equivalent to t before playing the next audio frame nA. Similarly the player would wait until tto play the next video frame nV. In addition to this one embodiment allows the media sync layer to specify playback to begin at exactly time t n in which case media sync layer transmits Haptic frame n 1 H and specifies a time offset of tn t 1 H to Haptic Unit . Haptic Unit then communicates this time offset to API when attempting to playback theistic frame n 1 H.

Each haptic frame is allowed to contain multiple haptic effects. The parameters that define and schedule these haptic effects are capable of offsetting haptic effects to be played back within a frame. In other words the time offset between the haptic effects is relative to the start of the frame not the start of the file or media transport stream. Scheduling individual effects within a frame is the responsibility of the device playing the sounds images and haptic effects. Since the sync layer of the device schedules playback of video audio and haptic frames any drift between the different media can be corrected at the start of each frame.

The master time code is used by a media player to coordinate the reception and playback of all frames or data packets it receives for a file. The frame length in time can be selected and fixed during normal operation. In one embodiment a range of frame length between 100 to 300 ms milliseconds is used depending on the nature of the data and user s preferences. In some special operations a 1 ms frame length may be used to meet some extremely tight synchronization requirements. It should be noted that the cost associated with an 1 ms frame length can be high because it requires a significantly increased bandwidth usage. Generally a longer frame length means less frames need to be synchronized with media effects which implies a greater chance to cause the haptic effects to be out of synchronization with the media effects. The media effects indicate effects other than haptic effects such as video and or audio effects. On the other hand although a shorter frame length provides a better and tighter synchronization with the other media effects it requires more processing power and higher network bandwidth to handle the increased sync process between the haptic and media effects. The media transport stream referred to herein may be any appropriate media transport stream such as MP3 MP3 or MPEG4 MP4 or the like.

Each haptic frame is assigned with an initial time or a time stamp at which associated haptic effect s should be played at a proper time according to a master time code . Master time code may be embedded in the media transport stream as discussed earlier. In one embodiment time stamps associated with the haptic information are generated in response to a user s input. In another embodiment time stamps associated with the haptic information are generated in accordance with predefined algorithms based on the other media components. In yet another embodiment time stamps associated with the haptic information can be generated according to a combination inputs from a user and predefined algorithms in view of other media components. In one embodiment time stamps are not assigned to frames that do not contain the haptic information. For example the data base omits a frame if it does not contain haptic information.

The size of a haptic frame or a haptic sample in one embodiment can be 8 16 25 32 64 or 128 bytes depending on the complexity of the haptic effect. For example some haptic frames include vibration sound and or vibration video data correlated to specific sounds and or video frames respectively. In one embodiment a haptic frame contains information required to render at least one haptic effect and a time stamp indicating the starting time of the haptic effect. It should be noted that a haptic frame may be omitted if haptic information is not present in a frame.

Haptic frame is an exemplary layout of a frame in which it contains a haptic effect definitions and a series of call haptic effect instructions . In one embodiment haptic effect definition includes controlling information such as the duration parameter and the start delay parameters. Each call haptic effect instruction may contain information about magnitude attack intensity fade intensity and specific type of haptic effect. It should be noted that a haptic frame is capable of initiating multiple haptic effects. It should be further noted that a haptic effect may continue playing beyond the frame length or time span of the frame. In one embodiment Call haptic effect instructions specify the haptic effect definition to be played contained within as well as a frame time offset parameter that controls how far into the frame playback commences.

A frequency period or periodic type can be constant force square wave triangle wave sine wave saw tooth wave inverted saw tooth wave or any combination of the above stated waveforms. It should be noted that a different frequency period provides different haptic feedback. For example waveform could be in a range from 0.1 Hertz to 1000 Hertz wherein different frequencies provide different haptic sensations.

In operation the haptic effect caused by waveform is defined in terms of its attack level attack time fade level and fade time . When it is time to execute waveform the execution process specifies the base intensity or magnitude of the haptic effect its duration whether it is to be played periodically and if so how often it is to be re started. The information defining a particular haptic effect is in one embodiment downloaded periodically to a playing device with every frame. It should be noted that waveform is only an example and those of ordinary skill in the art will now readily understand that such haptic effects may be defined in any number of ways.

The present invention includes various processing steps which will be described below. The steps described herein may be embodied in machine or computer executable instructions. These instructions in turn may be used to cause a general purpose or special purpose system which is programmed with these instructions to perform the steps described herein. Alternatively the steps described herein may be performed by specific hardware components that contain hard wired logic for performing the steps or by any combination of programmed computer components and custom hardware components. While embodiments of the present invention will be described with reference to a wireless communications network the method and apparatus described herein is equally applicable to other network infrastructures or other data communications environments including wired.

At block the process determines time stamps according to a master time code embedded in the media transport stream. In one embodiment a time stamp is a point of time on a timeline according to the master time code and it is used to trigger execution of haptic effects defined in a haptic frame. In accordance with one embodiment of the present invention a time stamp is assigned to a haptic frame so that the haptic frame will be executed at a time indicated by the time stamp. The process then moves to the next block.

At block the process assigns various time stamps to various haptic frames wherein the time stamps indicate when to activate one or more actuators to generate haptic effects according to the haptic information stored in the haptic frames. In one embodiment the time stamps are assigned according to the audio and video information. Also the process is capable of assigning a sub time stamp that is an offset of the time stamp within a single haptic frame. After block the process proceeds to the next block.

At block the process defines haptic effect information for each haptic effect in response to the haptic information in the haptic frames. In one embodiment the process encodes the haptic effect information in response to the other media information such as video and or audio signals. In another embodiment the process encodes the haptic effect information in response to one of several predefined algorithms selected by a user. It should be noted that each haptic frame can contain multiple haptic effects starting at different times. It should be further noted that the process is capable of activating an actuator according to the haptic effect information and also maintaining the haptic effect according to an associated time stamp.

While embodiments and applications of this invention have been shown and described it would be apparent to those skilled in the art having the benefit of this disclosure that many more modifications than mentioned above are possible without departing from the inventive concepts herein. The invention therefore is not to be restricted except in the spirit of the appended claims.

