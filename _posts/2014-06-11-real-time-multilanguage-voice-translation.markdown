---

title: Real time multi-language voice translation
abstract: A system may be configured to allow for the translation of content, obtained and/or presented by a media cast device, to different languages. The translation may be performed based on translating the text of closed captioning information provided with the content, and generating audio based on the text. The translation may be performed independent of music or sound effects, such that only speech is replaced, without affecting other portions of the audio.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09477657&OS=09477657&RS=09477657
owner: VERIZON PATENT AND LICENSING INC.
number: 09477657
owner_city: Basking Ridge
owner_country: US
publication_date: 20140611
---
Media cast devices may be used to access web based content such as Internet video content and cast the content to a display device such as a television. Content may often be presented with closed captions which may be a textual representation of audio associated with the content. Closed captions are generally provided in a single language.

The following detailed description refers to the accompanying drawings. The same reference numbers in different drawings may identify the same or similar elements.

Media cast devices may be used to access web based content such as Internet video content on demand programming and or other types of content. Situations may arise in which multiple different users desire to access content via the same cast device e.g. in the same room and or the same household . In some of these situations the different users may desire to listen to audio in different languages. For instance one user may only understand English while another user may only understand Spanish.

As provided herein some implementations may allow for the presentation of different audio streams for content accessed via a media cast device. For example as shown in a media cast device may receive a content stream e.g. a video content stream from an Internet based video content provider . The content stream may include for example video audio and closed captioning information. The audio and the closed captioning information may be for instance in the same language e.g. English . Assume that three users desire to watch the content but that the users desire to listen to the audio of the content in three different languages French Spanish and English.

In accordance with some implementations the media cast device may provide a video portion of the content stream to a television and audio in different languages may be played by one or more other devices e.g. smart phones associated with different users . For instance the media cast device may output closed captioning information e.g. the closed captioning information originally included in the content stream to a first smart phone Smart phone . As described below the first smart phone may include a translation component which may translate text associated with the English closed captioning information to text in other languages i.e. Spanish and French in this example . The translation component may perform a text to speech conversion technique in order to generate audio tracks i.e. Spanish and French audio tracks in this example based on the translated text. The first smart phone may output the generated audio tracks in accordance with user preferences. For example the Spanish audio track may be provided to the television the English audio track may be provided to a second smart phone Smart phone . Further the French audio track may be played at the first smart phone.

As described below different audio tracks corresponding to different portions of audio may be provided. For example the content stream may be associated with a speech audio track and a separate music and sound effects audio track. The translation component may in some implementations replace the speech audio track with translated speech while leaving the other audio track s unaffected thereby preserving as much of the original audio as possible. In some implementations the translation component may intelligently replace audio in situations where separate speech and music sound effects tracks are not provided. For example when multiple audio channels are provided e.g. center left right rear left and rear right the translation component may replace one audio channel with translated speech e.g. the center channel while leaving the other channels unaffected. In other implementations the translation component may perform other types of processing in order to preserve as much of the original sound track as possible while translating the speech.

User device may include any computation and communication device such as a wireless mobile communication device that is capable of communicating with one or more networks e.g. network . For example user device may include a radiotelephone a personal communications system PCS terminal e.g. a device that combines a cellular radiotelephone with data processing and data communications capabilities a personal digital assistant PDA e.g. that can include a radiotelephone a pager Internet intranet access etc. a smart phone a laptop computer a tablet computer a camera a television a set top device STD a personal gaming system a wearable device and or another type of mobile computation and communication device. User device may receive connectivity to network via services provided by a service provider such as an Internet service provider ISP . An ISP may in some implementations be a wireless telecommunications provider e.g. a cellular telecommunications provider .

User device may be used as a control device and or as a presentation device. For example as described herein when used as a control device user device may provide instructions to media cast device to obtain content such as web based video content. When used as a presentation device user device may present e.g. via a display device and or via an audio output device such as a set of speakers web based content obtained by media cast device . As described herein user device may in some implementations include translation component or may implement a portion of translation component . In some implementations user device may include some or all of media cast device .

Media cast device may include a computation and communication device which may obtain content such as web based video content from content provider . For example media cast device may be communicatively coupled to a control device which may instruct media cast device to obtain particular content from content provider . Media cast device may also be communicatively coupled to a presentation device to which media cast device may provide some or all of the obtained content. Media cast device may further be communicatively coupled to translation component to which media cast device may provide portions of obtained content e.g. audio information and or closed captioning information . As described herein media cast device may in some implementations include translation component or may implement a portion of translation component .

Content provider may include one or more devices that provide content to media cast device . For example content provider may be associated with a subscription based service via which content such as on demand video programming content may be obtained. Content provider may output requested content to media cast device . As described below the content may be outputted as a set of logical streams such as a video stream one or more audio streams and a closed captioning stream.

Translation component may include one or more devices that generate one or more translated audio streams based on content obtained from content provider . In some implementations translation component may be implemented as part of user device e.g. may be implemented via logic and or hardware associated with user device . In some implementations translation component may be implemented as part of media cast device e.g. may be implemented via logic and or hardware associated with media cast device . In some implementations translation component may be implemented separately from user device and or media cast device . As described below translation component may perform a text based translation of speech related audio and may perform text to speech conversion techniques in order to generate translated audio streams.

Network may include one or more networks via which user device media cast device content provider and or translation component may communicate. For example network may include an evolved packet system EPS that includes a Long Term Evolution LTE network and or an evolved packet core EPC network that operate based on a third generation partnership project 3GPP wireless communication standard. The LTE network may be or may include a radio access network RAN that includes one or more base stations some or all of which may take the form of an eNodeB eNB via which user device and or another device may communicate with the EPC network. The EPC network may include one or more serving gateways SGWs mobility management entities MMEs and or packet data network PDN gateways PGWs and may enable user device to communicate with a PDN e.g. the Internet and or an IP Multimedia Subsystem IMS core network. The IMS core network may manage authentication session initiation account information a user profile etc. associated with user device .

Network may additionally or alternatively include a wide area network WAN a metropolitan area network MAN the Internet a fiber optic based network and or a combination of these or other types of networks. Network may include one or more wireless networks in addition to or in lieu of an LTE network. For example network may include a Code Division Multiple Access CDMA 2000 1 network a second generation 2G wireless network a third generation 3G wireless network a fourth generation 4G wireless network a fifth generation 5G wireless network a Wi Fi wireless network e.g. a network that operates according to an Institute of Electrical and Electronics Engineers IEEE 802.11 based standard and or another wireless network. In some implementations network may be communicatively coupled to one or more other networks.

Control interface may serve as an interface between media cast device and a control device. For example as mentioned above the control device may be or may be implemented by user device . Control interface may be an implementation of an application programming interface API via which control interface can receive instructions such as instructions to obtain particular content from a control device. Media cast device may output information to the control device such as closed captioning and or audio data that corresponds to obtained content. For example as described below diversification module may identify or extract the closed captioning and or audio data to provide to the control device.

Content acquisition module may include an interface e.g. an IP interface and or an implementations of another API between media cast device and content provider . Content acquisition module may request and receive content based on instructions received from a control device. As mentioned above particular content may be associated with multiple logical streams such as a video stream an audio stream and or a closed captioning stream. As described below the obtained content may in some situations not include closed captioning information.

Diversification module may diversify streams corresponding to content obtained via content acquisition module . For example diversification module may identify or extract different streams associated with the obtained content. Diversification module may in some implementations include a set of decoders and or other type of logic that are capable of identifying audio video and or closed captioning portions of content obtained from content provider . An example of the operation of diversification module is shown in . As shown diversification module may receive a content stream e.g. as obtained from content provider . Diversification module may distinctly output a video portion of the stream one or more audio portions of the stream e.g. one audio portion that corresponds to sound effects and or music and another audio portion that corresponds to speech and closed captioning CC data.

In some implementations the content stream received from content provider may include metadata or other identifying information based on which diversification module may be able to differentiate speech audio from other types of audio e.g. sound effects and or music . In some implementations the content stream received from content provider may not include such metadata. In some such implementations diversification module may intelligently extract speech related audio content from the content stream. For example diversification module may extract audio relating to certain frequencies such as frequencies that are commonly associated with human speech as the speech related audio stream. As another example the audio content received from media cast device may include multiple different channels which may correspond to different portions of a surround sound configuration such as a 3.1 configuration a 5.1 configuration a 7.1 configuration etc. . Diversification module may heuristically or intelligently identify one or more channels as a speech related channel. For example diversification module may identify or denote that a center channel should be considered to be a speech related audio channel. Diversification module may in other implementations extract the speech related audio stream using one or more other techniques. In some implementations diversification module may forgo identifying separate speech related and sound effects music audio streams.

Returning to presentation interface may be an implementation of an API and or another type of interface via which media cast device may communicate with a presentation device such as a particular user device . Media cast device may output via presentation interface video content and or audio content such as a sound effects music stream and or a speech related audio stream to the presentation device.

Media cast device interface may be an implementation of an API and or another type of interface via which translation component receives audio and or closed captioning information from media cast device . The audio may for example correspond to speech related audio content. In some implementations translation component may receive closed captioning information from media cast device and may not receive audio content from media cast device while in some implementations translation component may receive audio content from media cast device and may not receive closed captioning information from media cast device . In some implementations translation component may receive both audio content and closed captioning information from media cast device .

In situations where translation component receives speech related audio content from media cast device speech to text module may perform speech recognition and or other techniques in order to generate a textual representation of speech associated with the audio content. In some implementations media cast device interface may include synchronization information when generating text based on speech such that the timing of the speech may be preserved. As mentioned above in some implementations translation component may not receive speech related audio content and or may receive closed captioning information. In some such implementations speech to text module may not perform speech to text functions and or may not be present.

Translation module may translate text that corresponds to speech associated with audio content. For example translation module may translate text generated by speech to text module and or may translate closed captioning text from one language to another. Translation module may perform the translation based on a set of preferences e.g. user preferences that specify which language or languages to which the text should be translated. In some implementations speech to text module may synchronize the translated text based on synchronization information included in the closed captioning information e.g. information specifying when certain text should be displayed and or based on synchronization information generated by speech to text module . Additionally or alternatively the translation may be performed in real time. For example when translation module receives text translation module may perform the translation as quickly as possible e.g. may not intentionally introduce any delay when generating the translation .

Text to speech module may generate audio based on the translated text generated by translation module . The generated audio may thus correspond to translated audio based on the original audio provided by media cast device . The audio may be generated in real time e.g. as soon as text to speech module receives the text generated by translation module .

Presentation interface may be an implementation of an API and or another type of interface via which translation component communicates with one or more presentation devices e.g. one or more user devices . Translation component may output the translated audio e.g. as generated by text to speech module and or other content e.g. video content sound effects music audio content etc. to a presentation device. Translation component may output the content via presentation interface based on preferences or configuration settings which specify which presentation device s are associated with which language s . Since the various components of translation component may act in real time or near real time the translated audio may be provided to presentation devices in real time and or near real time. Thus multiple different presentations devices my receive video and or translated audio content at approximately the same time thus potentially giving multiple users a shared viewing experience of content associated with different languages. Network bandwidth e.g. bandwidth associated with a connection between media cast device and content provider may be saved compared to implementations where content provider provides multiple audio streams e.g. that correspond to different languages . Further translation component may provide enhanced functionality such as translation to languages not offered by content provider .

Process may include receiving at content from a content provider. For example as described above with respect to content acquisition module media cast device may obtain content from content provider . The content may be obtained based on for example an instruction received from a control device.

Process may also include identifying and or extracting at a video stream one or more audio streams and closed captioning information. For example as discussed above with respect to diversification module media cast device may identify and or extract video audio and or closed captioning information from the content received from content provider . As also discussed above in some situations distinct audio streams e.g. separate speech related audio content and sound effects music content may not be identified or extracted and or closed captioning information may not be identified and or extracted.

Process may further include outputting at closed captioning information and or a speech related audio stream to a translation component. For example as described above with respect to control interface the extracted or identified closed captioning information and or speech related audio stream may be provided to translation component .

Process may additionally include outputting at a video stream to a presentation device. For example as described above with respect to presentation interface media cast device may output a video portion of the content obtained from content provider to a particular user device that acts as a presentation device. In some implementations media cast device may output the video stream to multiple user devices to one or more control devices and or to translation component .

Process may include receiving at a set of language preferences and or presentation device configuration information. For example translation component may receive the language preferences and or presentation device configuration information from a user of translation component . The language preferences and or presentation device configuration information may specify a set of languages and the presentation device configuration may specify which language s correspond to which presentation devices. The presentation device configuration may specify for example that a first user device is associated with a first language that a second user device is associated with a second language and so on. In some implementations one presentation device may be associated with multiple languages. In some such implementations the presentation device may further process or output multiple translated audio streams in a manner determined by for example a user of the presentation device e.g. one audio stream may be played via a first set of headphones while the other audio stream is played via a second set of headphones etc. .

Process may also include receiving at closed captioning information and or a speech related audio stream. For example as described above with respect to media cast device interface translation component may receive the closed captioning information and or speech related audio from media cast device .

Process may further include generating at text corresponding to the audio stream if closed captioning information is unavailable. For instance as described above with respect to speech to text module translation component may perform speech recognition in order to generate a textual representation of speech associated with the audio. In some implementations text may not be generated at such as when closed captioning information is received at .

Process may additionally include translating at the text based on language preferences. For example as described above with respect to text to speech module translation component may translate the text received at or generated at to text associated with one or more other languages as specified in the language preferences.

Process may also include generating at one or more audio streams based on the translated text. For example as described above with respect to text to speech module translation component may generate audio e.g. translated audio in real time based on the translated text.

Process may further include outputting at the one or more audio streams to one or more presentation devices based on the presentation device configuration. For example as described above with respect to text to speech module translation component may output translated audio to the one or more presentation devices in the manner specified by the presentation device configuration information.

The content provider may provide at . the content to the media cast device. For example the content may be provided as multiple logical portions and or as a single logical stream from which multiple portions may be extracted and or identified . For example a first portion may correspond to video a second portion may correspond to audio and a third portion may correspond to closed captioning information. As mentioned above audio content may include multiple different logical streams and or an audio stream from which multiple different portions can be extracted and or identified such as speech related audio and music sound effects.

As further shown in the media cast device may output at . closed captioning information to Smart phone . The media cast device may also output at . the sound effects FX music audio to a presentation device e.g. a television . The television may have been previously designated as a presentation device to which the video and sound effects music should be provided.

Smart phone may implement functionality associated with translation component and may generate translated audio streams based on the closed captioning information. Smart phone may output at . the translated speech audio to the television and to another smart phone Smart phone . The translated speech audio may for example correspond to different languages. That is audio corresponding to a first language may be provided to the television while audio corresponding to a different language may be provided to Smart phone . In some implementations Smart phone may also play translated speech audio e.g. the same audio as one of the other presentation devices and or speech audio associated with a different language . In some implementations the outputting at . and . may be done in a synchronized manner such that translated speech audio matches the original timing of original audio content and or matches the timing of the video content.

As shown in Smart phone may output at . a content instruction to a media cast device which may request at . the content from a content provider. The content provider may provide at . the content to the media cast device. In the example shown in the media cast device may implement functionality associated with translation component . For example the media cast device may generate translated audio streams in a manner similar to that described above.

The media cast device may output at .. .. and .. video and audio including respective translated speech to a set of presentation devices. For example the media cast device may output the video and audio to Smart phone at .. to Smart phone at .. and to a television at .. . In some implementations the media cast device may output video to fewer than all of the presentation devices e.g. only to the television .

As shown in Smart phone may output at . a content instruction to a media cast device which may request at . the content from a content provider. The content provider may provide at . the content to the media cast device. The media cast device may output at . the content e.g. the video content the audio content and the closed captioning information to Smart phone . Smart phone may generate translated audio content and may output at .. and .. the video and the translated audio content to a set of presentation devices e.g. a television at .. and Smart phone at .. .

While specific examples were described above with respect to in practice other implementations are possible. Further in some situations a particular presentation device may be associated with an original language associated with obtained content. In some such situations the original audio may be passed through to the particular presentation device e.g. audio on which translation functions have not been performed .

Bus may include one or more communication paths that permit communication among the components of device . Processor may include a processor microprocessor or processing logic that may interpret and execute instructions. Memory may include any type of dynamic storage device that may store information and instructions for execution by processor and or any type of non volatile storage device that may store information for use by processor .

Input component may include a mechanism that permits an operator to input information to device such as a keyboard a keypad a button a switch etc. Output component may include a mechanism that outputs information to the operator such as a display a speaker one or more light emitting diodes LEDs etc.

Communication interface may include any transceiver like mechanism that enables device to communicate with other devices and or systems. For example communication interface may include an Ethernet interface an optical interface a coaxial interface or the like. Communication interface may include a wireless communication device such as an infrared IR receiver a Bluetooth radio or the like. The wireless communication device may be coupled to an external device such as a remote control a wireless keyboard a mobile telephone etc. In some embodiments device may include more than one communication interface . For instance device may include an optical interface and an Ethernet interface.

Device may perform certain operations relating to one or more processes described above. Device may perform these operations in response to processor executing software instructions stored in a computer readable medium such as memory . A computer readable medium may be defined as a non transitory memory device. A memory device may include space within a single physical memory device or spread across multiple physical memory devices. The software instructions may be read into memory from another computer readable medium or from another device. The software instructions stored in memory may cause processor to perform processes described herein. Alternatively hardwired circuitry may be used in place of or in combination with software instructions to implement processes described herein. Thus implementations described herein are not limited to any specific combination of hardware circuitry and software.

The foregoing description of implementations provides illustration and description but is not intended to be exhaustive or to limit the possible implementations to the precise form disclosed. Modifications and variations are possible in light of the above disclosure or may be acquired from practice of the implementations.

For example while series of blocks have been described with regard to the order of the blocks may be modified in other implementations. Further non dependent blocks may be performed in parallel.

The actual software code or specialized control hardware used to implement an embodiment is not limiting of the embodiment. Thus the operation and behavior of the embodiment has been described without reference to the specific software code it being understood that software and control hardware may be designed based on the description herein.

Even though particular combinations of features are recited in the claims and or disclosed in the specification these combinations are not intended to limit the disclosure of the possible implementations. In fact many of these features may be combined in ways not specifically recited in the claims and or disclosed in the specification. Although each dependent claim listed below may directly depend on only one other claim the disclosure of the possible implementations includes each dependent claim in combination with every other claim in the claim set.

Further while certain connections or devices are shown in practice additional fewer or different connections or devices may be used. Furthermore while various devices and networks are shown separately in practice the functionality of multiple devices may be performed by a single device or the functionality of one device may be performed by multiple devices. Further multiple ones of the illustrated networks may be included in a single network or a particular network may include multiple networks. Further while some devices are shown as communicating with a network some such devices may be incorporated in whole or in part as a part of the network.

To the extent the aforementioned embodiments collect store or employ personal information provided by individuals it should be understood that such information shall be used in accordance with all applicable laws concerning protection of personal information. Additionally the collection storage and use of such information may be subject to consent of the individual to such activity for example through well known opt in or opt out processes as may be appropriate for the situation and type of information. Storage and use of personal information may be in an appropriately secure manner reflective of the type of information for example through various encryption and anonymization techniques for particularly sensitive information.

Some implementations are described herein in conjunction with thresholds. The term greater than or similar terms as used herein to describe a relationship of a value to a threshold may be used interchangeably with the term greater than or equal to or similar terms . Similarly the term less than or similar terms as used herein to describe a relationship of a value to a threshold may be used interchangeably with the term less than or equal to or similar terms . As used herein exceeding a threshold or similar terms may be used interchangeably with being greater than a threshold being greater than or equal to a threshold being less than a threshold being less than or equal to a threshold or other similar terms depending on the context in which the threshold is used.

No element act or instruction used in the present application should be construed as critical or essential unless explicitly described as such. An instance of the use of the term and as used herein does not necessarily preclude the interpretation that the phrase and or was intended in that instance. Similarly an instance of the use of the term or as used herein does not necessarily preclude the interpretation that the phrase and or was intended in that instance. Also as used herein the article a is intended to include one or more items and may be used interchangeably with the phrase one or more. Where only one item is intended the terms one single only or similar language is used. Further the phrase based on is intended to mean based at least in part on unless explicitly stated otherwise.

