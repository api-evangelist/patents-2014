---

title: Cognitive neuro-linguistic behavior recognition system for multi-sensor data fusion
abstract: Embodiments presented herein describe techniques for generating a linguistic model of input data obtained from a data source (e.g., a video camera). According to one embodiment of the present disclosure, a sequence of symbols is generated based on an ordered stream of normalized vectors generated from the input data. A dictionary of words is generated from combinations of the ordered sequence of symbols based on a frequency at which combinations of symbols appear in the ordered sequence of symbols. A plurality of phrases is generated based an ordered sequence of words from the dictionary observed in the ordered sequence of symbols based on a frequency by which combinations of words in ordered sequence of words appear relative to one another.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09639521&OS=09639521&RS=09639521
owner: Omni AI, Inc.
number: 09639521
owner_city: Dallas
owner_country: US
publication_date: 20140811
---
This application claims benefit of U.S. Provisional Patent Application Ser. No. 61 864 274 filed Aug. 9 2013 which is incorporated herein by reference in its entirety.

Embodiments described herein generally relate to surveillance more particularly to analyzing and learning behavior based on a variety of input data.

Many currently available surveillance and monitoring systems e.g. video surveillance systems SCADA systems and the like are trained to observe specific activities and alert an administrator after detecting those activities. However such systems require advance knowledge of what actions and or objects to observe. The activities may be hard coded into underlying applications or the system may train itself based on provided definitions. In other words unless the underlying code includes descriptions of certain behaviors the system is incapable of recognizing such behaviors.

In addition many surveillance systems e.g. video surveillance systems require a significant amount of computing resources including processor power storage and bandwidth. For example typical video surveillance systems require a large amount of computing resources per camera feed because of the typical size of video data. Given the cost of the resources such systems are difficult to scale.

One embodiment presented herein includes a method for generating a linguistic model of input data obtained from a data source. The method generally includes generating a sequence of symbols based on an ordered stream of normalized vectors generated from the input data. A dictionary of words is generated from combinations of the ordered sequence of symbols based on a frequency at which combinations of symbols appear in the ordered sequence of symbols. A plurality of phrases is generated based an ordered sequence of words from the dictionary observed in the ordered sequence of symbols based on a frequency by which combinations of words in ordered sequence of words appear relative to one another.

Another embodiment includes a computer readable storage medium having instructions which when executed on a processor performs an operation for generating a linguistic model of input data obtained from a data source. The operation generally includes generating a sequence of symbols based on an ordered stream of normalized vectors generated from the input data. A dictionary of words is generated from combinations of the ordered sequence of symbols based on a frequency at which combinations of symbols appear in the ordered sequence of symbols. A plurality of phrases is generated based an ordered sequence of words from the dictionary observed in the ordered sequence of symbols based on a frequency by which combinations of words in ordered sequence of words appear relative to one another.

Still another embodiment includes a system having a processor and a memory storing a program which when executed on the processor performs an operation for generating a linguistic model of input data obtained from a data source. The operation generally includes generating a sequence of symbols based on an ordered stream of normalized vectors generated from the input data. A dictionary of words is generated from combinations of the ordered sequence of symbols based on a frequency at which combinations of symbols appear in the ordered sequence of symbols. A plurality of phrases is generated based an ordered sequence of words from the dictionary observed in the ordered sequence of symbols based on a frequency by which combinations of words in ordered sequence of words appear relative to one another.

To facilitate understanding identical reference numerals have been used where possible to designate identical elements that are common to the figures. It is contemplated that elements and features of one embodiment may be beneficially incorporated in other embodiments without further recitation.

Embodiments presented herein describe a behavior recognition system. The behavior recognition system may be configured with one or more data collector components that collect raw data values from different data sources e.g. video data building management data SCADA data . For example a behavior recognition system may be configured for video surveillance. The behavior recognition system may include a data collector component that retrieves video frames in real time separates foreground objects from background objects and tracks foreground objects from frame to frame. The data collector component may normalize the video frame data into numerical values e.g. falling within a range from 0 to 1 with respect to a given data type .

In one embodiment the behavior recognition system includes a neuro linguistic module that performs neural network based linguistic analysis on the data collected. Specifically for each type of data observed the neuro linguistic module creates and refines a linguistic model of the normalized data. The behavior recognition system uses the linguistic model to describe what is being observed.

To generate the linguistic model the neuro linguistic module receives normalized data values and organizes the data into clusters. Further the neuro linguistic module generates symbols e.g. letters corresponding to each cluster. Thus input values associated with a given cluster are assigned a symbol.

The neuro linguistic module generates a lexicon i.e. builds a dictionary of observed combinations of symbols e.g. words based on a statistical distribution of symbols identified in the input data. Specifically the neuro linguistic module may identify patterns of symbols in the input data at different frequencies of occurrence.

Using words from the dictionary the neuro linguistic module generates phrases based on probabilistic relationships of each word occurring in sequence relative to other words. For example the neuro linguistic module may identify a relationship between a given three letter word that frequently appears in sequence with a given four letter word and so on.

The syntax allows the behavior recognition system to learn identify and recognize patterns of behavior without the aid or guidance of predefined activities. Unlike a rules based surveillance system which contains predefined patterns of what to identify or observe the behavior recognition system learns patterns by generalizing input and building behavior memories of what is observed. Over time the behavior recognition system uses these memories to distinguish between normal and anomalous behavior reflected in observed data.

For instance the neuro linguistic module builds letters words nouns adjectives verbs etc. phrases and estimates an unusualness score for each identified letter word or phrase. The unusualness score for a letter word or phrase observed in input data indicates how infrequently the letter word or phrase has occurred relative to past observations. Thus the behavior recognition system may use the unusualness scores to both identify and measure how unusual a current syntax is relative to a stable model of symbols i.e. letters a stable model of words built from the symbols i.e. a dictionary and a stable model of phrase built from the words i.e. a syntax collectively the neuro linguistic model.

In addition as the neuro linguistic module receives more input data the neuro linguistic module may decay reinforce and generate letters words and syntax phrases over time. In parlance with the machine learning field the neuro linguistic module learns on line as new data is received and occurrences either increase decrease or appear.

The CPU retrieves and executes programming instructions stored in the memory as well as stores and retrieves application data residing in the storage . In one embodiment the GPU implements a Compute Unified Device Architecture CUDA . Further the GPU is configured to provide general purpose processing using the parallel throughput architecture of the GPU to more efficiently retrieve and execute programming instructions stored in the memory and also to store and retrieve application data residing in the storage . Taking advantage of the parallel computing elements of the GPU allows the behavior recognition system to better process large amounts of incoming data e.g. input from a video and or audio source . As a result the behavior recognition system may scale with relatively less difficulty.

The sensor management module provides one or more data collector components. Each of the collector components is associated with a particular input data source e.g. a video source a SCADA supervisory control and data acquisition source an audio source etc. The collector components retrieve or receive depending on the sensor input data from each source at specified intervals e.g. once a minute once every thirty minutes once every thirty seconds etc. . The sensor management module controls the communications between the data sources. Further the sensor management module normalizes input data and sends the normalized data to the sensory memory component .

The sensory memory component is a data store that transfers large volumes of data from the sensor management module to the machine learning engine . The sensory memory component stores the data as records. Each record may include an identifier a timestamp and a data payload. Further the sensory memory component aggregates incoming data in a time sorted fashion. Storing incoming data from each of the data collector components in a single location where the data may be aggregated allows the machine learning engine to process the data efficiently. Further the behavior recognition system may reference data stored in the sensory memory component in generating alerts for anomalous activity. In one embodiment the sensory memory component may be implemented in via a virtual memory file system in the memory . In another embodiment the sensory memory component is implemented using a key value share.

The machine learning engine receives data output from the sensor management module . Generally components of the machine learning engine generate a linguistic representation of the normalized vectors. As described further below to do so the machine learning engine clusters normalized values having similar features and assigns a distinct symbol to each cluster The machine learning engine may then identify recurring combinations of symbols i.e. words in the data. The machine learning engine then similarly identifies recurring combinations of words i.e. phrases in the data.

Note however illustrates merely one possible arrangement of the behavior recognition system . For example although the input data sources are shown connected to the computer system via network the network is not always present or needed e.g. an input source such as a video camera may be directly connected to the computer system .

The persistence layer includes multiple data stores that maintain information used by different components of the behavior recognition system . For example the persistence layer includes data stores that maintain information describing properties of the various sensors associated with the behavior recognition system system properties and properties of the data collector components further described below . Other data stores may maintain learning model information system events and behavioral alerts. In addition the sensory memory component resides in the persistence layer .

The machine learning engine itself includes a neuro linguistic module and a cognitive module . Generally the neuro linguistic module performs neural network based linguistic analysis of normalized input data to describe activity observed in the data. However rather than describing the activity based on pre defined objects and actions the neuro linguistic module generates a custom language based on symbols e.g. letters identified in the input data. Once the set of symbols reaches a statistically mature state the neuro linguistic module builds a dictionary by identifying combinations of letters e.g. words occurring in sequence in the input data. After the dictionary has matured the neuro linguistic module identifies set of percepts e.g. a syntax collection of phrases based on relationships indicating probabilities of different words from the dictionary being observed in sequence with one another.

The cognitive module evaluates the symbols words and phrases as input identified by the neuro linguistic module . The cognitive module identifies patterns of behavior described in the identified phrases. The cognitive module evaluates activity occurring in the linguistic representation of the data and stores activity as memories. Over time the symbols words and phrases generated from the observed data reach a mature state. Thereafter upon observing subsequent events in the data streams the cognitive module is able to detect anomalous activity and generate alerts.

As shown the sensor management module may include a variety of data collector components . One example is a video driver . The video driver may retrieve input data from a video feed i.e. frames of video and evaluate the frames to separate foreground objects from background objects track foreground objects evaluate appearance and kinematic features etc. The video driver normalizes the extracted data and information into numerical values e.g. within a range of 0 to 1 relative to the type of data. The video driver sends a vector of the normalized data to the sensory memory component at specified intervals.

Another example is a supervisory control and data acquisition SCADA driver . The SCADA driver receives readings from SCADA sensors e.g. temperature sensors viscosity sensors etc. . The SCADA driver normalizes the obtained readings into numerical values e.g. within a range of 0 to 1 relative to the type of sensor. The SCADA driver sends a vector of the normalized sensor readings as a group to the sensory memory component .

Other examples may include an audio driver for extracting audio feed data a traffic driver for receiving automobile traffic data e.g. obtained at intersections expressways etc. a big data driver for receiving large amounts of complex data and an information security driver for receiving network and security related data. Of course the sensor management module may support other types of data collector components . In one embodiment the sensor management module provides an external application programming interface API and a software development kit SDK that allows users to develop data collector components .

The sensor manager is a system service that loads initializes and controls the data collector component . For example the sensor manager may through an API call start or stop the operation of any given data collector component . For example when a client application requests a video feed to be added to the machine learning engine the sensor manager identifies details for the feed that were stored at the time the data collector component was registered. The sensor manager then sends the details to the video driver . In turn the video driver starts the video feed and begins retrieving video input data.

In one embodiment the data collector components send normalized data to the sensory memory component . The data collector components may send the data values along with other information associated with the value such as a timestamp a boxcar average and historical high and low values. As stated the sensory memory component is a data store that transfers large volumes of data from the sensor management module to the machine learning engine . The sensory memory component maintains a historical buffer that stores numerous transactions per data collector component. Further the sensory memory component aggregates incoming sensory data in a time sorted fashion. In one embodiment the sensory memory component transmits the aggregated data to the neuro linguistic module .

The sensory memory component is associated with data stores in the persistence layer that maintain information about various aspects of the behavior recognition system . For example the persistence layer includes sensor properties system properties server properties and driver properties . The sensor properties provide information describing sensors associated with the data collector components such as a maximum range for types of data serial numbers of devices associated with the data collector components name information location information assigned computing device etc. The system properties provide configuration information that governs the execution of processes running in the computing system such as system configuration settings used during initial set up of the computing system . The server properties summarize information about the computing system e.g. UUID machine ID amount of storage amount of memory etc. . The driver properties describe information about the data collector components such as configuration and operation information.

Further the persistence layer may include additional data stores. For example the persistence layer may include a housekeeping store learning models store system events store behavior alerts store and analysis metadata store . The housekeeping store maintains data about the system and sensors. The learning models store maintains models that pertain to the learning memories generated by the cognitive module . The system events store maintains event data that describes observations. The behavior alerts store maintains event data that describes anomalous activity that accompany alerts sent to a user. For example in a video surveillance context the behavior alerts store may include video clips of activity identified as anomalous by the cognitive module as well as other metadata associated with the event such as time location etc. The analysis metadata store maintains information associated with data evaluated by each of the data collector components . The analysis metadata store may include visualizations of the evaluated data. For example in the video surveillance case the analysis metadata store may include images of video frames and contour maps corresponding to each image.

In one embodiment each of the data stores maintained in the persistence layer other than the sensory memory component may be implemented as a database e.g. a NoSQL database.

Method begins at step where the video driver retrieves data from the source input device. In this case the video driver may retrieve video frames from a video source such as a video camera positioned to observe a particular location such as a hotel lobby. Further the video driver identifies data values to send to the sensory memory component . To do so the video driver may evaluate the video frames to separate foreground objects from background objects measure appearance and kinematic information of the identified foreground objects and track foreground objects moving across the scene i.e. the field of view of the camera . As a result the video driver ascertains values to be sent to the sensory memory component such as values for the appearance and kinematic information.

At step the video driver normalizes each data value to a numerical value falling within a range e.g. between 0 to 1 relative to the type of that data value. For example values associated with kinematic features are normalized from 0 to 1 relative to other values associated kinematic features. Doing so results in each value being converted to a common format that allows the neuro linguistic module to recognize recurring events in the video stream.

After normalizing the values at step the video driver identifies additional data associated with the normalized values such as a timestamp of a given value an average associated with the data type of the value and historical high and low values for that data type. Doing so allows the video driver to readjust the normalization in the event that the video source is modified. Specifically the video driver references the identified historical values and averages to readjust the normalization.

At step the video driver sends a vector of the normalized values and associated data to the sensory memory component . As stated the sensory memory component stores the normalized values and associated data. The neuro linguistic module may then retrieve the normalized values from the sensory memory component and perform linguistic analysis thereafter.

The DTM component retrieves the normalized data vectors from the sensory memory component and stages the data in the pipeline architecture provided by the GPU .

The classification analyzer component evaluates the normalized data organized by the DTM component and maps the data on a neural network. In one embodiment the neural network is a combination of a self organizing map SOM and an adaptive resonance theory ART network. The neural network clusters the data by identifying features of the normalized vector data which occur repeatedly in association with each other.

The mapper component identifies symbols i.e. builds an alphabet of letters based on the clustered data. Specifically the mapper component determines a statistical distribution of the clustered data and assigns a symbol to data input belonging to a same cluster. A symbol is the building block of the linguistic model defined by the neuro linguistic module . In one embodiment a symbol provides a fuzzy as used in the artificial intelligence field representation of the data belonging to a given cluster. The symbol may be described as a letter of an alphabet.

Further the mapper component is adaptive. That is the mapper component may identify new symbols corresponding to new clusters generated from the normalized data as such clusters are reinforced to a point where they become statistically relevant. The mapper component learns on line and may merge similar observations to a more generalized symbol. As stated the mapper component assigns a symbol to a generated cluster. Thereafter as additional observations which map to that cluster are observed mapper component outputs instances of the symbol assigned to that cluster. Once a given cluster matures the mapper component begins sending that symbol to the lexical analyzer component in response to normalized data that matches the cluster. In one embodiment the mapper component limits the set of symbols that can be sent to the lexical analyzer component to the most statistically relevant clusters. In practice outputting symbols i.e. letters assigned to the top thirty two clusters has shown to be effective. However other amounts may also prove effective such as the top sixty four or 128 most frequently occurring symbols. Note over time the most frequently observed symbols may change as different clusters increase in statistical significance as well as when new clusters become statistically relevant.

In one embodiment the mapper component evaluates an unusualness score for identified symbols. The unusualness score is based on the frequency of a given symbol relative to other symbols that the mapper component identifies. The unusualness score may increase or decrease over time as the neuro linguistic module receives more observed data.

The mapper component sends a stream of the symbols e.g. letters timestamp data unusualness scores and statistical data e.g. a representation of the cluster associated with a given symbol to the lexical analyzer component . The lexical analyzer component builds a dictionary based on symbols output from the mapper component . In practice the mapper component may need approximately 5 000 observations i.e. normalized vectors of input data to generate a stable alphabet of symbols.

The lexical analyzer component builds a dictionary for the linguistic model by identifying combinations of symbols e.g. words from the symbols transmitted by the mapper component . The lexical analyzer component identifies repeating patterns and sub patterns of letters and calculates frequencies of the patterns occurring throughout the symbol stream. The combinations of symbols may represent a particular activity event etc e.g. Start Stop Turn Enter Exit etc . Of course to the system the event is an arbitrary sequence of symbols assigned to clusters that has been observed to have statistical significance.

In one embodiment the lexical analyzer component limits the length of words in the dictionary to allow the lexical analyzer component to identify a number of possible combinations without adversely affecting the performance of the behavior recognition system . Further the lexical analyzer component uses a sliding window based on the maximum length to identify words for the dictionary. For example assume the maximum length of a word may be five symbols. In this case the lexical analyzer component may use a sliding window of ten symbols to identify words and sub words within the words within the window. In practice limiting a word to a maximum of five or six symbols has shown to be effective.

Like the mapper component the lexical analyzer component is adaptive. That is the lexical analyzer component may learn decay and generate words over time. Further the lexical analyzer component may determine an unusualness score for each word based on how frequently the word occurs in the data. For instance a word X that appears rarely in the data may have a higher unusualness score than a word Y that appears commonly in the data. The unusualness score may increase or decrease over time as the neuro linguistic module receives more data.

In addition as additional observations i.e. symbols are passed to the lexical analyzer component and identified as a given word the lexical analyzer component may determine that the word has matured. Once a word has matured the lexical analyzer component may output observations of that word to the PAM component . In one embodiment the lexical analyzer component limits the words sent to the PAM component to the most statistically relevant words. In practice outputting occurrences of the top 1 000 most frequently occurring words has shown to be effective. Note over time the most frequently observed words may change as the observations of incoming letters change in frequency.

Once the lexical analyzer component has built the dictionary i.e. identifies words that have a dynamically determined statistical relevance the lexical analyzer component sends data that includes a stream of the symbols words timestamp data unusualness scores and statistical calculations to the PAM component . The PAM component builds a syntax of phrases with a strong set of words output from the lexical analyzer component . In practice lexical analyzer component may obtain a dictionary of meaningful words after receiving approximately 15 000 observations i.e. input symbols .

The PAM component identifies a syntax of phrases based on the sequence of words output from the lexical analyzer component . Specifically the PAM component retrieves the words identified by the lexical analyzer component and generates a connected graph where the nodes of the graph represent the words and the edges represent a relationship between the words. The PAM component may reinforce or decay the links based on the frequency that the words output by the mapper component are connected with one another in a data stream.

Similar to the mapper component and the lexical analyzer component the PAM component determines an unusualness score for each identified syntax phrase based on how frequently the phrase occurs in the data. For instance a phrase X that occurs rarely in the data may have high unusualness score whereas a phrase Y that occurs commonly in the data may have a low unusualness score. The unusualness score may increase or decrease over time as the neuro linguistic module receives more data.

The PAM component identifies syntax of phrases from the ordered observations of words output from the lexical analyzer component . As observations of words corresponding to a given phrase accumulate the PAM component may determine that the given phrase has matured i.e. reached a measure of statistical relevance after many observations. The PAM component may output observations of that phrase to the cognitive module . The PAM component sends data that includes a stream of the symbols words phrases timestamp data unusualness scores and statistical calculations to the semantic memory of the cognitive module . In practice the PAM component may obtain a meaningful set of phrases after observing about 5000 words from the lexical analyzer component . The semantic memory may reliably identify complex phrases from the phrases output by the PAM component .

The initial set of generated letters words and phrases forms a neuro linguistic model of the input data stream that the behavior recognition system uses to compare subsequent observations of letters words and phrases against the generated model. The neuro linguistic module updates the linguistic model as new data is received. Further the neuro linguistic module may compare a currently observed syntax to the model. That is after building a stable set of letters the neuro linguistic module may build a stable model of words e.g. a dictionary . In turn the neuro linguistic module may be used to build a stable model of phrases e.g. a syntax . Thereafter when the neuro linguistic module receives subsequent normalized data the module can output an ordered stream of symbols words and phrases all of which can be compared to the stable model to identify interesting patterns or detect deviations occurring in the stream.

At step the classification analyzer component clusters the normalized vectors based on values that occur repeatedly in association with one another. In addition the mapper component generates symbols to associate with each cluster. The mapper component also evaluates the frequency that each symbol occurs in the data stream. Thereafter the mapper component determines a unusualness score for each symbol. The mapper component continues to identify symbols and evaluate statistical frequencies of the identified symbols.

At step the lexical analyzer component generates combinations of symbols for a dictionary to be used in the linguistic module. To do so the lexical analyzer component identifies repeating patterns and sub patterns of letters and calculates frequencies of the patterns occurring throughout the symbol stream. Further the lexical analyzer component determines an unusualness score for each word based on the calculated frequencies. The lexical analyzer component continues to identify words and evaluate statistical frequencies of the identified words.

At step the PAM component generates a percept syntax of the identified words based on probabilistic relationships between the words. Further the PAM component calculates frequencies of phrases occurring in the data stream. The PAM component calculates an unusualness score for each phrase based on the frequencies. The PAM component continues to identify phrases and evaluate statistical frequencies of the identified phrases.

At step the PAM component sends the generated letter word and phrase data along with the respective unusualness scores to the cognitive module .

Generally the workspace provides a computational engine for the machine learning engine . For example the workspace may retrieve relevant memories from the episodic memory and the longterm memory select codelet templates to execute etc. Further the workspace receives the symbols words and syntax phrases as well as unusualness scores from the neuro linguistic module and stores these data in the semantic memory .

The workspace retrieves the neurolinguistic data from semantic memory and disseminates this data to different portions of the cognitive module as needed.

The episodic memory stores linguistic observations related to a particular episode in the immediate past and may encode specific details such as the what and the when of a particular event.

In contrast the long term memory may store generalizations of the observed data. Thus the long term memory generalizations of the linguistic data with particular episodic details stripped away. In this way when a new observation occurs memories from the episodic memory and the long term memory may be used to relate and understand a current event i.e. the new event may be compared with past experience leading to both reinforcement decay and adjustments to the information stored in the long term memory over time. In a particular embodiment the long term memory may be implemented as an ART network and a sparse distributed memory data structure. Importantly however this approach does not require the different events to be defined in advance.

The codelet templates provide a collection of executable codelets or small pieces of code that evaluate different sequences of events to determine how one sequence may follow or otherwise relate to another sequence. More generally a codelet may detect interesting patterns from the linguistic analysis. By repeatedly scheduling codelets for execution copying memories and percepts to from the workspace the cognitive module performs a cognitive cycle used to observe and learn about patterns of behavior that occur within the scene.

The anomaly component evaluates unusualness scores sent by the neuro linguistic module to determine whether to issue an alert in response to some abnormal activity indicated by the unusualness scores. Specifically the anomaly component is provides probabilistic histogram models e.g. an unusual lexicon model an unusual syntax model and an unusual model which represent the unusualness scores. The anomaly component may store scores by encoding the scores into a compressed format. The anomaly component may send alert data to the system events store and the behavior alerts store . The save and restore component is a data store that receives and maintains different states of the linguistic model from the model repository .

The cognitive module performs learning analysis on the linguistic content delivered to semantic memory i.e. the identified symbols words phrases by comparing new observations to the learned patterns kept in semantic memory and then estimating the rareness of these new observations.

Specifically the anomaly component evaluates the unusualness scores of each of the symbols words and phrases to identify abnormal occurrences in the observed data. Once an anomalous observation has been identified the anomaly component may issue an alert e.g. notify an administrator or user of the behavior recognition system .

One embodiment of the present disclosure is implemented as a program product for use with a computer system. The program s of the program product defines functions of the embodiments including the methods described herein and can be contained on a variety of computer readable storage media. Examples of computer readable storage media include i non writable storage media e.g. read only memory devices within a computer such as CD ROM or DVD ROM disks readable by an optical media drive on which information is permanently stored ii writable storage media e.g. floppy disks within a diskette drive or hard disk drive on which alterable information is stored. Such computer readable storage media when carrying computer readable instructions that direct the functions of the present disclosure are embodiments of the present disclosure. Other examples media include communications media through which information is conveyed to a computer such as through a computer or telephone network including wireless communications networks.

In general the routines executed to implement the embodiments of the present disclosure may be part of an operating system or a specific application component program module object or sequence of instructions. The computer program of the present disclosure is comprised typically of a multitude of instructions that will be translated by the native computer into a machine readable format and hence executable instructions. Also programs are comprised of variables and data structures that either reside locally to the program or are found in memory or on storage devices. In addition various programs described herein may be identified based upon the application for which they are implemented in a specific embodiment of the disclosure. However it should be appreciated that any particular program nomenclature that follows is used merely for convenience and thus the present disclosure should not be limited to use solely in any specific application identified and or implied by such nomenclature.

As described embodiments herein provide techniques for generating a linguistic model of input data via a behavior recognition system. Once generated the behavior recognition system analyzing and learning behavior based on the linguistic model to distinguish between normal and abnormal activity in observed data. Advantageously this approach does not relying on predefined patterns to identify behaviors and anomalies but instead learns patterns and behaviors by observing a scene and generating information on what it observes.

While the foregoing is directed to embodiments of the present disclosure other and further embodiments of the disclosure may be devised without departing from the basic scope thereof and the scope thereof is determined by the claims that follow.

