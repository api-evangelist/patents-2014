---

title: Synchronizing video content with extrinsic data
abstract: Disclosed are various embodiments for associating and synchronizing extrinsic data with video content at particular points of time in the video content. A user interface is rendered that facilitates a selection from extrinsic data items that are associated with a video content feature that is currently being presented to a user. A user selection of a particular extrinsic data item is received through the user interface, and a time in the video content feature is determined corresponding to the user selection. An association is then generated between the particular extrinsic data item and the time in the video content feature.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09357267&OS=09357267&RS=09357267
owner: IMDb.com
number: 09357267
owner_city: Seattle
owner_country: US
publication_date: 20140326
---
This application is a continuation of and claims priority to co pending U.S. patent application entitled SYNCHRONIZING VIDEO CONTENT WITH EXTRINSIC DATA filed on Sep. 7 2011 and assigned application Ser. No. 13 227 097 which is incorporated herein by reference in its entirety.

People often want more information about the movies and other video content they are watching. To this end people may search the Internet to find out more information about the video content. This information may include for example biographies of actors production information trivia goofs and so on.

The present disclosure relates to associating and synchronizing extrinsic data with video content. Consumers of video content such as movies television shows etc. often would like additional information about what they are seeing. The additional information may relate to trivia mistakes or further information about what is currently being shown such as actors appearing on screen and or other information. The additional information may involve biographies filmographies pictures audio clips video clips and or other forms of rich content. The additional information referred to herein as extrinsic data may be available in a database that may be accessed through a web site. However the extrinsic data may not be associated with any specific time in the movie making it difficult to locate extrinsic data that is relevant to what is currently being shown.

Various embodiments of the present disclosure facilitate associating extrinsic data items with video content features at specific times. In some embodiments the associations may be crowd sourced and then validated through various approaches. Once obtained extrinsic data items may be displayed in conjunction with the video content feature so that their appearance is synchronized according to the stored validated extrinsic data time associations. User interfaces for obtaining the associations and presenting the extrinsic data items may be displayed along with the video content within a single client device. Alternatively the user interfaces may be rendered in a different client device from a device that is presenting the video content. In the following discussion a general description of the system and its components is provided followed by a discussion of the operation of the same.

With reference to shown is a networked environment according to various embodiments. The networked environment includes one or more computing devices in data communication with a plurality of clients . . . N by way of a network . The network includes for example the Internet intranets extranets wide area networks WANs local area networks LANs wired networks wireless networks or other suitable networks etc. or any combination of two or more such networks. The networked environment may also include one or more content display devices such as televisions video projectors and so on which may or may not be coupled to the network . In one embodiment one or more of the clients may be in data communication with the content display device by way of another local network e.g. Bluetooth infrared Wi Fi etc. that may be separate from the network .

The computing device may comprise for example a server computer or any other system providing computing capability. Alternatively a plurality of computing devices may be employed that are arranged for example in one or more server banks or computer banks or other arrangements. For example a plurality of computing devices together may comprise a cloud computing resource a grid computing resource and or any other distributed computing arrangement. Such computing devices may be located in a single installation or may be distributed among many different geographical locations. For purposes of convenience the computing device is referred to herein in the singular. Even though the computing device is referred to in the singular it is understood that a plurality of computing devices may be employed in the various arrangements as described above.

Various applications and or other functionality may be executed in the computing device according to various embodiments. Also various data is stored in a data store that is accessible to the computing device . The data store may be representative of a plurality of data stores as can be appreciated. The data stored in the data store for example is associated with the operation of the various applications and or functional entities described below.

The components executed on the computing device for example include a content delivery service an extrinsic data association service a content enhancement service and other applications services processes systems engines or functionality not discussed in detail herein. The content delivery service is executed to serve up or stream video content to clients and or client display devices . The content delivery service may support a resume functionality such that playback of video content may be stopped at a point in the video content on one device and later resumed at that point on the same device or a different device.

The extrinsic data association service is executed to facilitate the association of extrinsic data with particular times within video content. To this end the extrinsic data association service may generate data for a user interface that presents various options for extrinsic data to a user. From the options the user may select one or more extrinsic data items to associate with a particular time in the playback of the video content. The extrinsic data association service may be configured to validate the user supplied association through various approaches as will be described.

The content enhancement service is executed to present extrinsic data items in synchronization with video content according to stored associations of the extrinsic data with the video content. To this end the content enhancement service may determine the time in the video content as it is being presented to the user and obtain extrinsic data items associated with the video content relative to that time. The extrinsic data items may be presented on a distinct display alongside the video content overlaid on top of the video content or in some other manner in conjunction with the video content.

The data stored in the data store includes for example a content library user data fingerprint data an extrinsic data library and potentially other data. The content library may include multiple video content features such as movies television shows video clips and or other forms of video content. It is noted that the content library may be absent in some embodiments as the computing device may maintain the extrinsic data and video content associations and not actually present the content.

The user data includes various data associated with users of the system. The user data may include one or more watchlists that indicate video content features that the users are interested in watching. The user data may also include one or more resumption times which correspond to times in video content features at which the video content feature was paused or stopped. In one embodiment the user data may indicate a reputation or feedback score for the user that may be employed in assessing the validity of extrinsic data associations created by the users.

The fingerprint data may include for example audio fingerprinting data and or video fingerprinting data that may be employed in some embodiments to identify video content features that are being presented to users and or to identify times dialogue or scenes within the video content features . The fingerprint data may include script information that may be used to identify times in video content features from subtitles or recognized audio. Although the fingerprint data is depicted as being within the data store in some embodiments portions of the fingerprint data may be stored within the clients to facilitate identification of video content features or times in the video content feature .

The extrinsic data library includes extrinsic data items that are associated with the video content features . The extrinsic data items may correspond to metadata about the video content features that is not obtained directly from the video content features . In other words the extrinsic data items may be obtained from an external source such as a source of curated data. This is in contrast to intrinsic data which may be obtained from the video or audio of video content features . Non limiting examples of the extrinsic data items may include names or descriptions of performers in the video content features biographies or filmographies of the performers commentary trivia mistakes user comments images and or other data. The extrinsic data items may include curated data that is professionally managed verified or is otherwise trustworthy.

Stored along with the extrinsic data items may be extrinsic data time associations . The extrinsic data time associations are user generated associations between extrinsic data items and specific times in the running of a video content feature . In some embodiments the time may be represented as a frame number or a range of frame numbers in the video content feature . The extrinsic data time associations may also indicate an association of extrinsic data items with a specific graphical position on one or more video frames of the video content feature .

As an example the extrinsic data time associations may indicate which performers appear on screen at a point fifteen minutes into the running of a video content feature . As another example the extrinsic data time associations may indicate that a certain goof or mistake is associated with a point 45 minutes and twenty seconds into the running of a video content feature . In various embodiments the user generated extrinsic data time associations may undergo a validating procedure before they are considered valid.

The clients are representative of a plurality of client devices that may be coupled to the network . Each client may comprise for example a processor based system such as a computer system. Such a computer system may be embodied in the form of a desktop computer a laptop computer personal digital assistants cellular telephones smartphones set top boxes network enabled televisions music players web pads tablet computer systems game consoles electronic book readers or other devices with like capability. Each client may include a respective display . . . N. The display may comprise for example one or more devices such as cathode ray tubes CRTs liquid crystal display LCD screens gas plasma based flat panel displays LCD projectors or other types of display devices etc.

Each client may be configured to execute various applications such as a browser a respective content access application . . . N a respective content enhancement application . . . N and or other applications. The browser may be executed in a client for example to access and render network pages such as web pages or other network content served up by the computing device and or other servers. The content access application is executed to obtain and render for display video content features from the content delivery service other servers and or local storage media. The content enhancement application is executed to facilitate user generation of extrinsic data time associations as well as to present extrinsic data items in synchronization with the video content features .

In some embodiments the content access application and or the content enhancement application may correspond to code that is executed in the browser or plug ins to the browser . In other embodiments the content access application and or the content enhancement application may correspond to standalone applications such as mobile applications. In some scenarios the content access application and the content enhancement application may be executed on different clients for one user. The client may be configured to execute applications beyond those mentioned above such as for example mobile applications email applications instant message applications and or other applications.

Next a general description of the operation of the various components of the networked environment is provided. To begin users at clients access video content features through content display devices or through content access applications executed in clients . The video content features accessed through the content display devices may be obtained through multi channel television video on demand optical disc or other media. Where a content access application is employed to access video content features the video content features may be served up by the content delivery service potentially from a watchlist of the user.

The content enhancement application executed in the client is able to track the progress of the video content feature through communication with the content access application content delivery service or the content display device . In some embodiments the content enhancement application may be equipped to recognize video content features presented in the environment of the user via audio and or video fingerprinting. The video content features may also be identified through subtitle information program identifier information and or other information available from a content display device or a content access application . Ultimately a time in the video content feature is determined. It is noted that a movie or other video content feature may have multiple versions with different running times so the specific version of the video content feature may be identified.

The extrinsic data association service is configured to send user interface data to the content enhancement application in order to present a user interface for selecting from various extrinsic data items . When an extrinsic data item is selected an association between a time in the video content feature and the extrinsic data item may be reported by the content enhancement application to the extrinsic data association service . The extrinsic data association service may record the association as an extrinsic data time association in the data store .

The extrinsic data association service may be configured to validate the user generated association before it can be presented to other users. In some cases the validation may depend at least in part on a reputation score associated with the user. In one embodiment the user generated association is considered valid if it is not a statistical outlier compared to similar user generated associations. Under a crowd sourcing model many different users may supply similar user generated associations which may be used to indicate a valid association if the user generated associations are generally in agreement. In another embodiment the user generated association may be presented to other users to confirm its correctness manually. Whether the user supplies valid associations may affect the reputation score of the user.

It is noted that the extrinsic data time associations correspond to relatively high quality data despite being user generated. This is in part because the extrinsic data items may already be correlated or associated with the video content features . As a non limiting example a user would be unable to specify that Martin Sheen is an actor in a scene of the movie Ferris Bueller s Day Off because there is no existing association between Martin Sheen and the movie. However Charlie Sheen is an actor in the movie and the user would be able to specify that Charlie Sheen is in a scene in the movie. Accordingly the extrinsic data association service preempts potential confusion between Martin Sheen and Charlie Sheen with respect to Ferris Bueller s Day Off. Similarly in another non limiting example a user may be unable to specify that Charlie Chaplin appears in a movie in 1999 because the extrinsic data library indicates that Charlie Chaplin does not appear in any movies after 1967.

When a user views the video content feature the content enhancement application is configured to render the extrinsic data items that are associated with specific times in the video content feature . For example a balloon box bar etc. may be rendered on top of or in conjunction with the video content feature to show extrinsic data items that are relevant to the current time period in the video content feature . In one embodiment the user may be viewing the video content feature on one device and viewing the extrinsic data items on another device. The content enhancement service is configured to send data that implements rendering of the related extrinsic data items to the content enhancement application .

Although a specific structure may be described herein that defines the server side roles e.g. of the content delivery service the extrinsic data association service and the content enhancement service and client side roles e.g. of the content access application and the content enhancement application it is understood that various functions may be performed at the server side or the client side. As a non limiting example the identity of the video content feature may be determined in the computing device or in the client . Additionally although various embodiments are described with respect to video content which may include audio content it is understood that the principles of the present disclosure may also be applied to audio content without a corresponding video component.

Turning now to shown is one example of a client rendering a user interface in connection with a content display of a content display device in the networked environment . In this non limiting example the client corresponds to a mobile device such as a smartphone or tablet computer and the content display device corresponds to a theater projector or a television. A user of the client is currently watching a video content feature on the content display device . Concurrently the client executes the content enhancement application to render additional information about the video content feature embodied in time relevant extrinsic data items .

A title in user interface indicates that the user is currently being presented with a video content feature entitled World of the Gorillas. The identity of the video content feature may be ascertained through communication with an application programming interface API of the content display device e.g. through a Bluetooth infrared or other network . Alternatively the identity may be ascertained through video or audio fingerprinting analysis performed by the content enhancement application using the fingerprint data . To this end the content enhancement application may capture the audio and or video of the video content feature .

The user interface may display the current time in the video content feature which in this example is 43 minutes and 10 seconds. A prompt introduces a plurality of selection options and . The prompt in this example asks the question who is currently shown in the film The selection options and each correspond to one or more extrinsic data items that may be associated with the current time in the video content feature . In this example each selection option indicates a respective performer with corresponding character in the video content feature . Although the selection options are shown as selectable buttons the selection options may be selected through various user interface components. In one embodiment images associated with the respective selection option e.g. headshots for the performers etc. may also be presented.

Moving on to shown is one example of a screen rendered on a display of a client in the networked environment . The screen includes the content display from with the user interface of being rendered alongside in visual association with the content display. In this example the content display is rendered by a content access application which is executed in the same client as the content enhancement application that renders the user interface . Accordingly the content enhancement application is able to render the user interface on top of or alongside the video content feature . In one embodiment the user selection may be made by selecting a location on the screen . The location on the video frame of the video content feature may be recorded as part of the selection. This may facilitate showing the associated extrinsic data items relative to a specific location on the screen

With reference to shown is another example of a screen rendered on a display of a client in the networked environment . Unlike the screen presents extrinsic data time associations instead of obtaining them. To this end rendered extrinsic data items and are shown superimposed on the screen in visual association with the content display .

Rendered extrinsic data item is a trivia item that indicates that the scene that is currently shown was filmed on location in the Mojave Desert. Rendered extrinsic data item indicates that the character of Augustus which is played by Ted Smalls is currently on the screen. In various embodiments the rendered extrinsic data items may include selectable components to obtain and or display further information e.g. images biographies filmographies etc. for performers . In some embodiments the user interface may be shown along with rendered extrinsic data items .

Referring next to shown is a flowchart that provides one example of the operation of a portion of the content delivery service according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the content delivery service as described herein. As an alternative the flowchart of may be viewed as depicting an example method implemented in the computing device according to one or more embodiments.

Beginning with box the content delivery service obtains a request from a client to stream or otherwise download a video content feature . In box the content delivery service determines whether the video content feature was previously stopped or paused by the user or otherwise interrupted. If the video content feature was stopped paused or interrupted the content delivery service moves to box and identifies a time in the video content feature at which streaming was previously stopped. In box the content delivery service establishes a starting time in the video content feature for the user as being the time in the video content feature at which streaming was previously stopped. This time may be obtained from the respective resumption time in the user data . The content delivery service then continues to box .

If the content delivery service instead determines in box that the video content feature was not previously stopped by the user the content delivery service moves from box to box . In box the content delivery service establishes a starting time in the video content feature for the user as being the beginning of the video content feature . The content delivery service then proceeds to box .

In box the content delivery service commences streaming of the video content feature to the client at the established starting time in the video content feature . In box the content delivery service determines whether the streaming of the video content feature has been stopped or otherwise interrupted before completion. If so the content delivery service continues to box and records the time at which the streaming was stopped as a resumption time in the user data for the user. Thereafter the portion of the content delivery service ends. Although the flowchart of shows the time at which streaming is stopped as being recorded in box the time in the video content feature may be continuously determined and recorded in other embodiments. If streaming has instead completed the portion of the content delivery service ends.

Turning now to shown is a flowchart that provides one example of the operation of a portion of the extrinsic data association service according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the extrinsic data association service as described herein. As an alternative the flowchart of may be viewed as depicting an example method implemented in the computing device according to one or more embodiments.

Beginning with box the extrinsic data association service identifies a video content feature that is being presented to a user. Such a video content feature may be presented to the user via a content display device or a client . The extrinsic data association service may identify the video content feature via communication with the content delivery service if applicable or the content enhancement application executed in the client .

In some embodiments the video content feature may be directly identifiable by a unique identifier title dialogue etc. In other embodiments information such as user location video content provider etc. may be employed to narrow down the possibilities to ease identification of video content features . As a non limiting example knowledge of what movies are showing in a particular movie theater where the user is located e.g. with location determined by global positioning system GPS etc. may be used in determining the video content feature . As another non limiting example knowledge of what titles are currently being shown on channels of a cable television provider may be used in determining the video content feature .

In box the extrinsic data association service determines the extrinsic data items in the extrinsic data library regarding the video content feature . The extrinsic data items that are determined may correspond to a subset of the extrinsic data items that are associated with the video content feature for example a subset of the extrinsic data items that are thought to pertain to a particular time or slice of time in the video content feature .

In box the extrinsic data association service sends data to the client associated with the user that facilitates a user selection from the extrinsic data items that were determined in box . In box the extrinsic data association service obtains a selection by the user of one or more of the extrinsic data items . In box the extrinsic data association service determines the time and or video frame number in the video content feature relative to which the user selection was made. To this end a timecode or frame number may be sent to the extrinsic data association service from the client along with the selection. Alternatively the extrinsic data association service may communicate with the content delivery service to determine the time associated with a streaming instance of the video content feature .

In box the extrinsic data association service validates the association of the selected extrinsic data items and the time in the video content feature . To this end the extrinsic data association service may compare previous user associations to determine whether the current association is a statistical outlier. Also the extrinsic data association service may obtain feedback from other users to determine the validity of the current association. Further the extrinsic data association service may refer to a reputation score associated with the user to evaluate at least in part whether the current association is trustworthy.

Upon determining that the current association is valid the extrinsic data association service stores the association of the selected extrinsic data items and the time in the video content feature in box . The association may be stored as an extrinsic data time association . In other embodiments the extrinsic data time association may undergo asynchronous post processing to determine validity. In box the extrinsic data association service determines whether the user makes another selection. If the user makes another selection the extrinsic data association service returns to box and obtains the next selection. If the user does not make another selection the portion of the extrinsic data association service ends.

Moving on to shown is a flowchart that provides one example of the operation of a portion of the content enhancement service according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the content enhancement service as described herein. As an alternative the flowchart of may be viewed as depicting an example method implemented in the computing device according to one or more embodiments.

Beginning with box the content enhancement service identifies a video content feature that is being presented to the user. For example the content enhancement service may communicate with the content delivery service or the content enhancement application executed in a client to determine the identity of the video content feature . In box the content enhancement service determines a current time in the video content feature .

In box the content enhancement service identifies extrinsic data items in the extrinsic data library that are associated with the video content feature at the current time in the video content feature. The content enhancement service may refer to the extrinsic data time associations to make this determination. Alternatively the content enhancement service may review the extrinsic data time associations and identify in advance at which times the extrinsic data items are to be presented relative to the video content feature .

In box the content enhancement service may filter the extrinsic data items that were identified in box . For example it may be distracting or otherwise problematic to display too many of the extrinsic data items at a certain time or during a scene of the video content feature . Accordingly the content enhancement service may be configured to filter the extrinsic data items by relevance popularity and or other criteria. Scores for the extrinsic data items may be crowd sourced in a similar manner to the extrinsic data time associations and validations thereof. Popularity relevance etc. may be determined explicitly by voting implicitly by number of confirmations that an association is correct and so on. In one embodiment the extrinsic data items are filtered to meet a predetermined threshold for relevance which excludes the extrinsic data items that do not meet the threshold. In some embodiments the less relevant extrinsic data items may be presented in an abbreviated or otherwise minimized format.

In box the content enhancement service sends the extrinsic data items or a description thereof to a client associated with the user. The extrinsic data items are to be rendered by a content enhancement application relative to the current time in the video content feature . For example the content enhancement service may show an extrinsic data item that is associated with a point in time 15 minutes into a video content feature exactly at 15 minutes at 15 minutes 30 seconds or at some other time relative to the point of association so as to maintain a logical synchronization of the extrinsic data with the content.

In box the content enhancement service determines whether extrinsic data items for another time in the video content feature are to be processed. If so the content enhancement service returns to box and determines the next time. If another time is not to be processed the portion of the content enhancement service ends. Although the content enhancement service is described as processing times discretely it is understood that the process may be continuous in some embodiments or prompted by pre identified times that are associated with extrinsic data items .

Referring next to shown is a flowchart that provides one example of the operation of a portion of the content enhancement application according to various embodiments. In particular the portion of the content enhancement application relates to user generation of extrinsic data time associations . It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the content enhancement application as described herein. As an alternative the flowchart of may be viewed as depicting an example method implemented in the client according to one or more embodiments.

Beginning with box the content enhancement application identifies the video content feature that is currently being presented to the user. The video content feature may be presented to the user through a content access application executed in the same client a different client or some other content access device . To this end the content enhancement application may identify the video content feature via an application programming interface API of the content access application or the content access device . In some embodiments the content enhancement application may identify the video content feature in the physical environment surrounding the client using audio fingerprinting or other techniques.

In box the content enhancement application obtains user interface data from the extrinsic data association service over the network . In box the content enhancement application renders a user interface according to the user interface data. The user interface facilitates a user selection from a group of extrinsic data items that are associated with the video content feature . For example the group of extrinsic data items may include all of the performers who appear in the video content feature a selection of trivia items a selection of goofs and so on.

In box the content enhancement application obtains a user selection of one or more of the extrinsic data items . For example the user may select a particular performer trivia item goof etc. that is associated with the current scene or time in the video content feature . In box the content enhancement application determines the current time in the video content feature . The time may be determined through an API of the content access application content access device or through fingerprinting or another technique.

In box the content enhancement application reports the user selection and the time in the video content feature that is associated with the user selection to the extrinsic data association service over the network . The content enhancement application may also report a graphical position to the extrinsic data association service . The graphical position which may correspond to the user selection is relative to a frame in the video content feature . In box the content enhancement application determines whether another selection is to be made. If another selection is to be made the content enhancement application returns to box and obtains another selection of an extrinsic data item . In some cases the content enhancement application may obtain additional user interface data to facilitate a selection from a different set of extrinsic data items . If no other selection is to be made the portion of the content enhancement application ends.

Continuing now to shown is a flowchart that provides one example of the operation of another portion of the content enhancement application according to various embodiments. In particular the other portion of the content enhancement application relates to presentation of extrinsic data items at appropriate times in conjunction with a video content feature . It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the other portion of the content enhancement application as described herein. As an alternative the flowchart of may be viewed as depicting an example method implemented in the client according to one or more embodiments.

Beginning with box the content enhancement application identifies a video content feature that is being presented to the user through a content access application or through a content access device . If the video content feature is being presented through a content access application the content access application may be executed on the same client or a different client from the content enhancement application . In box the content enhancement application determines the current time in the video content feature .

In box the content enhancement application obtains extrinsic data items that are associated with the video content feature at the current time from the content enhancement service over the network . In some cases the content enhancement application may obtain extrinsic data items that are associated with the video content feature at future times as well. In box the content enhancement application presents the extrinsic data items that are associated with the current time or time period in the video content feature . Where the video content feature is being rendered on the display of the same client as the content enhancement application the extrinsic data item may be rendered on top of as an overlay alongside or otherwise in visual association with the rendered video content feature .

In box the content enhancement application determines whether the video content feature has finished. If the video content feature has not finished the content enhancement application returns to box and determines another current time in the video content feature . Otherwise if the video content feature has finished the portion of the content enhancement application ends. Although the time comparison is described as being performed discretely for a time or range of time it is understood that it may be performed continuously potentially in anticipation of future times in the video content feature . Also it may be that the content enhancement service may push associated extrinsic data items to the content enhancement application in advance for an entire video content feature or a portion of time in the video content feature .

With reference to shown is a schematic block diagram of the computing device according to an embodiment of the present disclosure. The computing device includes at least one processor circuit for example having a processor and a memory both of which are coupled to a local interface . To this end the computing device may comprise for example at least one server computer or like device. The local interface may comprise for example a data bus with an accompanying address control bus or other bus structure as can be appreciated.

Stored in the memory are both data and several components that are executable by the processor . In particular stored in the memory and executable by the processor are the content delivery service the extrinsic data association service the content enhancement service and potentially other applications. Also stored in the memory may be a data store and other data. In addition an operating system may be stored in the memory and executable by the processor .

It is understood that there may be other applications that are stored in the memory and are executable by the processor as can be appreciated. Where any component discussed herein is implemented in the form of software any one of a number of programming languages may be employed such as for example C C C Objective C Java JavaScript Perl PHP Visual Basic Python Ruby Delphi Flash or other programming languages.

A number of software components are stored in the memory and are executable by the processor . In this respect the term executable means a program file that is in a form that can ultimately be run by the processor . Examples of executable programs may be for example a compiled program that can be translated into machine code in a format that can be loaded into a random access portion of the memory and run by the processor source code that may be expressed in proper format such as object code that is capable of being loaded into a random access portion of the memory and executed by the processor or source code that may be interpreted by another executable program to generate instructions in a random access portion of the memory to be executed by the processor etc. An executable program may be stored in any portion or component of the memory including for example random access memory RAM read only memory ROM hard drive solid state drive USB flash drive memory card optical disc such as compact disc CD or digital versatile disc DVD floppy disk magnetic tape or other memory components.

The memory is defined herein as including both volatile and nonvolatile memory and data storage components. Volatile components are those that do not retain data values upon loss of power. Nonvolatile components are those that retain data upon a loss of power. Thus the memory may comprise for example random access memory RAM read only memory ROM hard disk drives solid state drives USB flash drives memory cards accessed via a memory card reader floppy disks accessed via an associated floppy disk drive optical discs accessed via an optical disc drive magnetic tapes accessed via an appropriate tape drive and or other memory components or a combination of any two or more of these memory components. In addition the RAM may comprise for example static random access memory SRAM dynamic random access memory DRAM or magnetic random access memory MRAM and other such devices. The ROM may comprise for example a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other like memory device.

Also the processor may represent multiple processors and the memory may represent multiple memories that operate in parallel processing circuits respectively. In such a case the local interface may be an appropriate network that facilitates communication between any two of the multiple processors between any processor and any of the memories or between any two of the memories etc. The local interface may comprise additional systems designed to coordinate this communication including for example performing load balancing. The processor may be of electrical or of some other available construction.

Although the content delivery service the extrinsic data association service the content enhancement service the content access application the content enhancement application and other various systems described herein may be embodied in software or code executed by general purpose hardware as discussed above as an alternative the same may also be embodied in dedicated hardware or a combination of software general purpose hardware and dedicated hardware. If embodied in dedicated hardware each can be implemented as a circuit or state machine that employs any one of or a combination of a number of technologies. These technologies may include but are not limited to discrete logic circuits having logic gates for implementing various logic functions upon an application of one or more data signals application specific integrated circuits having appropriate logic gates or other components etc. Such technologies are generally well known by those skilled in the art and consequently are not described in detail herein.

The flowcharts of show the functionality and operation of an implementation of portions of the content delivery service the extrinsic data association service the content enhancement service and the content enhancement application . If embodied in software each block may represent a module segment or portion of code that comprises program instructions to implement the specified logical function s . The program instructions may be embodied in the form of source code that comprises human readable statements written in a programming language or machine code that comprises numerical instructions recognizable by a suitable execution system such as a processor in a computer system or other system. The machine code may be converted from the source code etc. If embodied in hardware each block may represent a circuit or a number of interconnected circuits to implement the specified logical function s .

Although the flowcharts of show a specific order of execution it is understood that the order of execution may differ from that which is depicted. For example the order of execution of two or more blocks may be scrambled relative to the order shown. Also two or more blocks shown in succession in may be executed concurrently or with partial concurrence. Further in some embodiments one or more of the blocks shown in may be skipped or omitted. In addition any number of counters state variables warning semaphores or messages might be added to the logical flow described herein for purposes of enhanced utility accounting performance measurement or providing troubleshooting aids etc. It is understood that all such variations are within the scope of the present disclosure.

Also any logic or application described herein including the content delivery service the extrinsic data association service the content enhancement service the content access application and the content enhancement application that comprises software or code can be embodied in any non transitory computer readable medium for use by or in connection with an instruction execution system such as for example a processor in a computer system or other system. In this sense the logic may comprise for example statements including instructions and declarations that can be fetched from the computer readable medium and executed by the instruction execution system. In the context of the present disclosure a computer readable medium can be any medium that can contain store or maintain the logic or application described herein for use by or in connection with the instruction execution system. The computer readable medium can comprise any one of many physical media such as for example magnetic optical or semiconductor media. More specific examples of a suitable computer readable medium would include but are not limited to magnetic tapes magnetic floppy diskettes magnetic hard drives memory cards solid state drives USB flash drives or optical discs. Also the computer readable medium may be a random access memory RAM including for example static random access memory SRAM and dynamic random access memory DRAM or magnetic random access memory MRAM . In addition the computer readable medium may be a read only memory ROM a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other type of memory device.

It should be emphasized that the above described embodiments of the present disclosure are merely possible examples of implementations set forth for a clear understanding of the principles of the disclosure. Many variations and modifications may be made to the above described embodiment s without departing substantially from the spirit and principles of the disclosure. All such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims.

