---

title: Garbage collection and other management of memory heaps
abstract: A memory heap management facility is provided that is able to perform various management tasks, including, but not limited to, garbage collection, compaction, and/or re-ordering of objects within a heap. One or more of these management tasks improve system performance by limiting movement of pages in and out of virtual memory. The garbage collection technique selectively performs garbage collection such that certain objects, such as old but live, infrequently referenced objects, are not garbage collected each time garbage collection is performed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09430153&OS=09430153&RS=09430153
owner: INTERNATIONAL BUSINESS MACHINES CORPORATION
number: 09430153
owner_city: Armonk
owner_country: US
publication_date: 20141022
---
One or more aspects relate in general to virtual memory of a computing environment and in particular to managing memory heaps of the virtual memory.

Virtual memory heaps are used by various object oriented managed runtime environments including but not limited to the Java Virtual Machine JVM runtime environment Microsoft Common Language Runtime CLR environment and the Smalltalk environment as examples. The heap is the primary memory resource for such environments.

Each heap provides memory for objects of the environment and thus may be referred to as an object heap. An object heap includes many objects each of which is for instance an instance of a class such as a JAVA class. A heap is managed by managing the memory space of the heap including performing garbage collection to reclaim memory space that is no longer used by the objects of the heap and reallocating new objects.

Shortcomings of the prior art are overcome and additional advantages are provided through the provision of a computer program product for facilitating management of memory heaps. The computer program product includes a storage medium readable by a processing circuit and storing instructions for execution by the processing circuit for performing a method. The method includes for instance selecting a heap section of a memory heap to be examined for garbage collection the heap section comprising a plurality of groups the plurality of groups defined such that groups include objects of particular types a particular type being defined based on frequency of reference of the objects within a group selecting one or more groups of the plurality of groups of the heap section to be examined for garbage collection the selecting being based on the particular type of the one or more groups determining whether garbage collection is to be performed for the selected one or more groups and performing garbage collection on the selected one or more groups based on the determining indicating garbage collection is to be performed for the selected one or more groups.

Methods and systems relating to one or more aspects are also described and claimed herein. Further services relating to one or more aspects are also described and may be claimed herein.

Additional features and advantages are realized through the techniques described herein. Other embodiments and aspects are described in detail herein and are considered a part of the claimed aspects.

In one or more aspects a memory heap management facility is provided that is able to perform various management tasks including but not limited to garbage collection compaction and or re ordering of objects within a heap. One or more of these management tasks improve system performance by limiting movement of pages in and out of virtual memory.

In the examples described herein the memory heaps are Java memory heaps however aspects of the invention are equally applicable to other types of heaps such as those used by CLR Smalltalk and or others.

One example of a computing environment to incorporate and use one or more aspects of a memory heap management facility is described with reference to . Referring to in one example a computing environment is based on the z Architecture offered by International Business Machines IBM Corporation Armonk N.Y. The z Architecture is described in an IBM Publication entitled z Architecture Principles of Operation Publication No. SA22 7832 09 10Edition September 2012 which is hereby incorporated by reference herein in its entirety.

Z ARCHITECTURE and IBM as well as POWER POWERVM and POWERPC referenced below are registered trademarks of International Business Machines Corporation Armonk N.Y. Other names used herein may be registered trademarks trademarks or product names of International Business Machines Corporation or other companies.

As one example computing environment includes a processor e.g. a central processing unit CPU communicatively coupled to memory and an input output I O subsystem . I O subsystem is further communicatively coupled to external I O devices that may include for example data input devices sensors and or output devices such as displays.

Memory includes for instance one or more caches at least one control utility such as an operating system e.g. z Linux offered by International Business Machines Corporation Armonk N.Y. and a hypervisor used to manage virtual memory. One example of such a hypervisor is PowerVM offered by International Business Machines Corporation.

CPU includes for instance one or more virtual machines such as one or more Java Virtual Machines JVMs and may include one or more Java application programming interfaces APIs . Each virtual machine includes for instance a memory manager that performs a number of management tasks including garbage collection compaction and or object re ordering also referred to as swapping herein as examples. The virtual machine further includes in one embodiment a bytecode verifier used to verify bytecode compiled from source code and an interpreter and or Just In Time JIT compiler used for compilation.

Another embodiment of a computing environment to incorporate and use one or more aspects of a memory heap management facility is described with reference to . In this example a computing environment includes for instance a native central processing unit CPU a memory and one or more input output devices and or interfaces coupled to one another via for example one or more buses and or other connections. As examples computing environment may include a PowerPC processor or a Power Systems server offered by International Business Machines Corporation Armonk N.Y. an HP Superdome with Intel Itanium II processors offered by Hewlett Packard Co. Palo Alto Calif. and or other machines based on architectures offered by International Business Machines Corporation Hewlett Packard Intel Oracle or others.

Native central processing unit includes one or more native registers such as one or more general purpose registers and or one or more special purpose registers used during processing within the environment that include information that represents the state of the environment at any particular point in time. Further native CPU may include for instance one or more virtual machines such as one or more Java Virtual Machines and may include one or more Java APIs .

Moreover native central processing unit executes instructions and code that are stored in memory . In one particular example the central processing unit executes emulator code stored in memory . This code enables the computing environment configured in one architecture to emulate one or more other architectures. For instance emulator code allows machines based on architectures other than the z Architecture such as PowerPC processors Power Systems servers HP Superdome servers or others to emulate the z Architecture and to execute software and instructions developed based on the z Architecture.

Further details relating to emulator code are described with reference to . Guest instructions stored in memory comprise software instructions e.g. correlating to machine instructions that were developed to be executed in an architecture other than that of native CPU . For example guest instructions may have been designed to execute on a z Architecture processor but instead are being emulated on native CPU which may be for example an Intel Itanium II processor. In one example emulator code includes an instruction fetching routine to obtain one or more guest instructions from memory and to optionally provide local buffering for the instructions obtained. It also includes an instruction translation routine to determine the type of guest instruction that has been obtained and to translate the guest instruction into one or more corresponding native instructions . This translation includes for instance identifying the function to be performed by the guest instruction and choosing the native instruction s to perform that function.

Further emulator code includes an emulation control routine to cause the native instructions to be executed. Emulation control routine may cause native CPU to execute a routine of native instructions that emulate one or more previously obtained guest instructions and at the conclusion of such execution return control to the instruction fetch routine to emulate the obtaining of the next guest instruction or a group of guest instructions. In one or more examples the guest instructions may include instructions to perform one or more aspects of the memory heap management facility described herein including but not limited to providing Java virtual machines and or performing garbage collection compaction and or re ordering of objects in a heap. Execution of the native instructions may include loading data into a register from memory storing data back to memory from a register or performing some type of arithmetic or logic operation as determined by the translation routine.

Each routine is for instance implemented in software which is stored in memory and executed by native central processing unit . In other examples one or more of the routines or operations are implemented in firmware hardware software or some combination thereof. The registers of the emulated processor may be emulated using registers of the native CPU or by using locations in memory . In embodiments guest instructions native instructions and emulator code may reside in the same memory or may be disbursed among different memory devices.

As used herein firmware includes e.g. the microcode millicode and or macrocode of the processor. It includes for instance the hardware level instructions and or data structures used in implementation of higher level machine code. In one embodiment it includes for instance proprietary code that is typically delivered as microcode that includes trusted software or microcode specific to the underlying hardware and controls operating system access to the system hardware.

The computing environments described above are only examples of computing environments that can be used. Other environments including but not limited to other types of partitioned environments non partitioned environments and or emulated environments may be used embodiments are not limited to any one environment or to any particular architecture.

Each environment utilizes virtual memory which is managed by the hypervisor and makes the physical memory of the environment appear larger than it is. A portion of the virtual memory is used for memory heaps that provide memory for objects of an object oriented managed runtime environment.

In one example each Java Virtual Machine JVM uses a large memory heap to store active Java objects. Garbage collection is run on each of these heaps in order to reclaim memory space that is no longer being used not alive objects and to reallocate the space to new objects. The combination of a large number of JVMs used in systems large heaps used by the JVMs and previous garbage collection techniques leads to a very large memory working set at the hypervisor level.

It is desirable to provide a large virtual memory heap to each JVM since a large virtual memory heap helps ensure that the JVM does not run out of memory and does not spend a large amount of CPU time for garbage collection of Java objects that are not alive. Certain operating systems such as z Linux can offer a large virtual memory space in order to provide each JVM with a large memory heap. It is possible for the sum of the desired virtual memory for all of the operating system images to greatly exceed the physical memory on the hardware system used.

The hypervisor provides the virtual memory system that enables the over commitment of physical memory. For previous JVMs however this over commitment of memory does not work well at the hypervisor level. Current garbage collection techniques used by previous JVMs end up touching too many pages in the heap too often. The result at the hypervisor level is a constant movement of virtual memory pages from disk to memory and back along with reduced system performance due to the associated CPU overhead. With current garbage collection techniques many virtual memory pages are swapped from disk just so that the garbage collector can mark very old objects that are not otherwise being referenced often by the applications running in the JVM. Thus in accordance with an aspect of the present invention a technique is provided in which old but still live infrequently referenced objects on the Java heap are collected together and left mostly undisturbed and untouched by garbage collection operations so that the virtual memory pages that they occupy can be swapped out to disk for long periods of time.

In one embodiment the garbage collection technique of one or more aspects of the present invention is optimized for multiple JVMs running in multiple operating system instances where the operating system images are themselves running in virtual servers. Real memory is saved at the hypervisor level by enabling a very high level of memory over commitment. This is achieved in one or more aspects without causing very high virtual memory paging rates and by optimizing the memory references of the virtual machines that the hypervisor is supporting especially the garbage collection of those virtual machines.

One example of a memory heap in accordance with one or more aspects is described with reference to . In this particular example the heap is a Java memory heap which is a portion of a memory address space that includes a range of addresses.

Referring to a memory heap includes a plurality of heap sections . In this example there are 32 heap sections however in other examples there may be more or less heap sections. In one embodiment additional heap sections may be added dynamically as previous heap sections become full or if certain subsections e.g. page groups described below of the heap sections become full. The heap sections may be of the same size as one another or varying sizes. Each heap section includes for instance metadata for that heap section referred to as local metadata and one or more page groups also referred to as groups each of which includes one or more memory objects. The objects in the page groups are grouped in one example based on how frequently the objects are used. In this example there are eight page groups however in other embodiments there may be more or less than eight page groups and or the grouping may be based on other criteria. Further the use of the term page group or group is for convenience only to indicate that objects within a heap section are placed together and or moved within a heap section based on a particular criteria such as relative reference rates. There may not be an actual group configuration. The term is used to indicate one or more objects of a selected criteria such as a particular reference rate.

In one embodiment as a particular example groups and of a heap section include frequently referenced and or newly created objects while groups and include for instance very rarely referenced objects groups and include rarely referenced objects and the other groups include objects in between those characterizations on a sliding scale. The characterizations of frequently referenced very rarely referenced and rarely referenced are based on one or more defined threshold values and or other criteria. The characterizations are relative to one another in which frequently referenced objects are referenced more often e.g. by some metric than rarely referenced objects and rarely referenced objects are referenced more often e.g. by some metric than very rarely referenced objects etc. Although in this example certain groups have certain characteristics e.g. very rarely referenced rarely referenced frequently referenced other groups may have the same or similar characteristics. For instance page group may have very rarely referenced objects as in groups and or it can have objects that are not as rarely referenced as those in groups and but more rarely referenced than those in groups and . Many other variations exist. Further the characteristics may be different or they may be in a different order than portrayed here. Many possibilities exist without departing from the spirit of aspects of the invention.

Metadata includes pieces of data used to assist in navigating through the page groups as described with reference to . In this example the metadata is for heap section however the information is similar for other heap sections and each heap section has its own local metadata. In one example metadata includes a list of roots for the heap section the list including one or more roots for the heap section a reference update time RefUpdateTime indicating the last time the heap section was examined for relocation of objects a rare update count RareUpdateCount for each page group indicating a count of iterations for the set of objects of the page group for examination for e.g. relocation and certain object specific information for each object. In one example the object specific information includes for instance a reference count RefCount and a reference Ref indicator e.g. a bit for each selected object of a page group. The object is for instance a Java object stored in the heap section the reference count indicates for instance rare references and is incremented when it is determined that there has been no new references to the object during a last defined interval e.g. time interval and the reference indicator indicates whether the object has been referenced. In one example there is a reference count and reference indicator only for the larger objects on the heap that is objects of a predefined size or a predefined range of sizes and smaller objects that are on the heap do not include a reference count or reference indicator.

In one embodiment the metadata may be arranged to facilitate finding data in the metadata e.g. align objects on a predefined boundary size e.g. 100 bytes etc.

One embodiment of allocating objects in a particular page group of a selected heap section of a memory heap is described with reference to . This logic is performed by for instance the memory manager of a virtual machine e.g. JVM executing within a processor.

Referring to initially the memory manager allocates a memory object in a selected heap section and a selected page group of the heap section STEP . In this particular example it is shown that the memory object is allocated in heap section the first section of the heap which is considered the active heap section and page group since page group is in this example one of the groups for newly created objects. However this is only one example. Any page group and or heap section may be selected in other embodiments.

In allocating the object the address of the object may be added to the root list in the metadata if it is a parent object or its parent is not in the root list.

The memory manager then determines whether there is additional room in page group for a next object to be allocated INQUIRY . If there is still room then processing continues with allocating additional memory objects in this heap section and page group STEP . However if there is no more room in the selected page group e.g. in page group then another page group in for instance the same heap section is selected assuming there is such a page group if not then another section is selected STEP . In this example heap section page group is selected. Thus the next memory object is allocated in the newly selected heap section page group STEP . Similarly a determination is made as to whether page group is out of room INQUIRY . If not then objects continue to be allocated in that heap section and page group STEP . Otherwise another section and or page group is selected STEP . For instance if there are additional page groups in the heap section configured for new objects then another page group in heap section is selected. Otherwise if there are no more page groups in heap section configured for new objects then a new heap section is selected such as heap section . For instance page group of heap section is selected. Heap section becomes the new active heap section. When the object is added to heap section it is determined if the parent object is also in heap section . If not the address of the new object is added to the local root list for heap section . Additionally in one embodiment garbage collection is performed on heap section .

Although particular heaps and page groups are discussed in this embodiment these are only examples. Any heap section and or page group may be selected. However in this example certain page groups are designated as including newly referenced objects and thus are selected when allocating new objects.

To reclaim space in the heap sections garbage collection is performed by the memory manager. One embodiment of logic to determine whether garbage collection is to be performed is described with reference to . Initially the memory manager periodically checks each heap section to determine if there is enough room in one or more selected page groups of the heap section STEP . For instance each heap section is checked at predefined intervals such as every x seconds where x is e.g. 10. In other embodiments other intervals may be used such as other values for x or based on other criteria such as computing cycles etc.

A determination is made as to whether there is enough space in selected page groups of the heap section such as the most frequently referenced page groups of the heap section e.g. page groups and in this example INQUIRY . If there is enough space then processing continues with STEP . Otherwise garbage collection is started for page groups and which are the newest and most referenced objects in this example STEP .

Subsequently the memory manager determines whether garbage collection has recently been performed on the selected page groups e.g. groups and in all of the heap sections INQUIRY . If not then processing continues with STEP in which another heap section is examined. Otherwise the memory manager determines whether additional space is needed to accommodate more objects INQUIRY . This determination may be made any number of ways including but not limited to comparing the amount of free space to a defined value to determine whether more space is needed. If further space is not needed at this time then processing continues with STEP . Otherwise garbage collection is started in one or more other groups in each heap section until enough space is made available STEP .

In a further embodiment at each check that determines more space is needed garbage collection is performed for all of the page groups for all of the heap sections or for specifically chosen page groups and or heap sections .

Further details associated with garbage collection are described with reference to . Each heap section may be examined separately using one thread or in parallel using multiple threads. The logic described below is for each heap section to be garbage collected.

Referring to initially the memory manager executes a mark phase for the heap sections page groups to be collected STEP . In one example this includes using the roots of the heap sections stored in the metadata to complete the phase. The mark phase includes examining the objects in the selected page groups heap sections to determine the live objects and marking those live objects with an indicator. In one example the mark phase does not include a complete marking of the entire heap but instead uses a set of roots that are specific to the current heap section being marked. For example for heap section the local roots are stored in metadata . A local root exists for each object that was created in the heap section page group whose parent object is located in a different heap section page group. The mark phase begins with each of the local roots identifies and marks the root object and then identifies and marks any child objects that exists whose location on the heap falls within the same heap section page group.

The memory manager examines an object in a selected page group of a selected heap section to determine if that object is marked as reachable i.e. was it marked in the mark phase as being alive STEP . If the object is not marked as reachable INQUIRY then the object is not alive and the memory is returned to the free list of memory STEP . Further a determination is made as to whether the object being examined is the last object of the heap section to be examined INQUIRY . If so then garbage collection is complete for this heap section STEP . Otherwise processing continues to examine another object STEP .

Returning to INQUIRY if the object is marked as reachable then a further determination is made as to whether the object s reference indicator e.g. a bit is set INQUIRY . If the reference indicator is set then the object is alive and active and no action is taken except for resetting the reference indicator STEP . Processing continues to INQUIRY .

However returning to INQUIRY if the object s reference indicator is not set then the object is alive but not active. Thus in one embodiment compaction is performed in which the object is moved to a lower open address in this heap section such as in page group or STEP . Processing then continues to INQUIRY .

In a further embodiment a check is made prior to INQUIRY as to whether the object has a reference indicator. If so then processing continues to INQUIRY . Otherwise processing continues to INQUIRY .

In a further embodiment the heap sections are examined to find rarely referenced objects and possibly relocate those objects to other page groups i.e. compact the rarely referenced objects in particular page groups . One embodiment of this logic is described with reference to . In one example one or more independent threads are used to examine the heap sections to find the rarely referenced objects.

Referring to initially the memory manager selects a heap section to be examined STEP . In particular a reference update time RefUpdateTime stored in the metadata for the heap section is examined. A determination is made as to whether the current time e.g. provided by the processor s time of day TOD clock is greater than the reference update time plus a predefined threshold e.g. a programmable number of seconds e.g. 2 seconds or other time parameters INQUIRY . If the current time is not greater than the reference update time plus the threshold then processing continues with STEP . Otherwise an object in a frequently referenced area of the heap section e.g. page groups and is examined STEP .

A determination is made as to whether the object has an associated reference indicator e.g. of in the metadata for this object INQUIRY . If it does not have a reference indicator then processing continues with INQUIRY described below. However if the object has a reference indicator then a further determination is made as to whether that reference indicator is set e.g. set to one INQUIRY . If it is set then the object is left in the current location and the reference indicator is reset e.g. set to zero STEP . Otherwise the object is moved into for instance a rarely referenced area e.g. page group or of the heap section the reference count in the metadata e.g. of is set to one the reference indicator in the metadata is set to one and the metadata is adjusted including the roots to accommodate the new object in the group STEP .

Subsequent to STEP or processing continues with INQUIRY . At INQUIRY a determination is made as to whether it is the last object of the frequently referenced area to be examined. If it is not the last object then processing continues to STEP . Otherwise if it is the last object in the frequently referenced area to be examined then the RefUpdateTime is set equal to the time of day STEP . Further another area is selected to be examined such as the rarely referenced area e.g. page groups and STEP . One embodiment of this logic is described with reference to .

Referring to the memory manager examines the rare update count RareUpdateCount for a selected page group of the rarely referenced area e.g. group STEP . A determination is made as to whether it has been a predefined number of iterations e.g. 10 since the last check of this page group INQUIRY . If not then processing continues with STEP of to check a next heap section STEP . Otherwise a first object or other selected object of the selected page group in the metadata is examined STEP . A determination is made as to whether the reference indicator for the object is set INQUIRY . In a further embodiment a check is made prior to INQUIRY as whether the object has a reference indicator. If so then processing continues to INQUIRY . Otherwise processing continues to INQUIRY . If the reference indicator is set then the reference count in the metadata is decremented and the reference indicator is reset e.g. set to zero STEP . Processing then continues to INQUIRY .

At INQUIRY a determination is made as to whether it is the last object of that group. If it is then the RareUpdateCount is updated STEP and processing is complete STEP . Otherwise if it is not the last object INQUIRY then processing continues to STEP .

Returning to INQUIRY if the reference indicator is not set then the reference count in the metadata is incremented STEP . Further a determination is made as to whether the reference count is greater than a predetermined number such as for instance 5 INQUIRY . If it is not then processing continues with INQUIRY . Otherwise the object may be moved into for instance the deep very rarely referenced area such as page group or in this example since according to the counter it has not been referenced in quite a while. Further the reference count is left in the metadata STEP and processing continues to INQUIRY .

In yet a further embodiment periodic reordering of objects in page groups is performed an example of which is described with reference to . Initially the memory manager examines the metadata of all of the objects for each of the page groups in a selected heap section to determine a median object RefCount for the heap section STEP . Then the memory manager scans the RefCounts of the objects and compares them with the median. A determination is made as to whether a reorder will be beneficial i.e. are there RefCounts that differ from the median INQUIRY . If it is determined that reordering will not be beneficial then processing continues with STEP . However if reordering would be beneficial then the RefCount of a selected object of the metadata is examined STEP . A determination is made as to whether the RefCount of the selected object is above the median INQUIRY . If it is then the object may be swapped with an object in a lower number page group which has a RefCount below the median INQUIRY and processing continues with INQUIRY . However if the RefCount is not above the median then the object may be swapped with an object in a higher number page group which has a RefCount above the median STEP and processing continues with INQUIRY . In further embodiments the object may be swapped regardless of the RefCount of the object with which it is being swapped and or the swap may not occur if there is no object in the lower higher number page group with a RefCount below above the median depending on the circumstance.

At INQUIRY a determination is made as to whether this is the last object of the metadata to be examined. If it is the last object then reordering is complete STEP . Otherwise processing continues with STEP .

Another embodiment of garbage collection is described with reference to . In this embodiment a garbage collection trace and mark is executed STEP as described herein or in any other known manner. An object in a selected heap section is examined to determine if it is marked for collection STEP . A determination is made as to whether the object is marked as being reachable or live INQUIRY . If it is not marked then the object is not alive the RefCount is not adjusted and its memory is reclaimed STEP . However if it is marked then a further determination is made as to whether its reference indicator is set INQUIRY . If it is set then the reference indicator is reset e.g. set to zero and RefCount is set to zero STEP . However if the reference indicator is not set then RefCount is incremented STEP .

Next a determination is made as to whether the reference count RefCount is greater than a predefined threshold INQUIRY . If the reference count is greater than the threshold then the object may be moved to a page group of e.g. a lower number into an unused object area STEP . Otherwise it may be moved in the other direction to a page group with e.g. a higher page group number STEP .

In one embodiment subsequent to STEP or processing continues to STEP . Further in another embodiment prior to INQUIRY a determination is made as to whether the object has a reference indicator. If it does then processing continues with INQUIRY . Otherwise processing continues to STEP .

Described in detail herein is a memory management facility including garbage collection compaction and or reordering that is optimized for a high memory over commitment environment. In one or more aspects a garbage collection technique is provided in which a much larger number of heap sections is created as compared to existing generational garbage collection systems. Object reference indictors e.g. bits are added to objects to create marks that indicate how recently the objects were touched relative to other objects.

Further in one embodiment a compaction phase follows garbage collection that is focused on grouping objects by their relative reference rate. For instance least referenced objects are compacted e.g. to the left i.e. to lower number page groups and most referenced objects are compacted towards the right i.e. to higher number page groups . Free space is left in the middle and tracked with a set of pointers.

The garbage collection capability described herein does not resort to a global mark and sweep as often thus a much larger heap can be used in which frequently referenced objects are grouped together and left untouched over many partial garbage collections. One or more aspects allow JVMs to have very large virtual memory heaps without causing high virtual memory swapping rates at the hypervisor level.

One or more aspects provide a garbage collection technique and optimized JVM memory management settings. The garbage collection allows a hypervisor to achieve a much higher level of memory over commitment when supporting multiple Linux instances or any other operating systems . The garbage collection technique does not mark all of the objects in the Java heap during collection. It uses a technique of marking subsets of objects. As an example the Java memory heap is divided into subsections. These subsections are used during the marking phase of garbage collection such that these subsections of the heap are to be marked without referencing other areas of the heap as described herein.

In accordance with one or more further aspects a memory heap is divided into a large number of heap sections HS e.g. 32 for this example. Memory allocation for new objects begins for instance at the first heap section Active HS 0 . A local root list is provided for each heap section. In one embodiment when the active heap section becomes nearly full or in another embodiment when certain page groups of a page section become full garbage collection is run. The local root list for Heap Section is used to help mark all of the active objects in HS . After several rounds of garbage collection for HS there will eventually be a point when the number of active objects exceeds the space allocated in Heap Section . Then the active heap section is dynamically changed to the next section Active HS 1 .

When a new object is added to HS it is determined if the parent object is also in HS . If the parent is not in HS the address of the new object is added to the local root list for HS . New objects are added to HS and when HS becomes nearly full garbage collection is run on HS . The garbage collection mark phase provided by one or more aspects uses each entry of the local root list for HS to trace the linked list of objects that are in the active HS in this case HS 1. The mark phase does not reference objects in other heap sections. It is possible that the marking of objects in HS will indicate that an object is still alive when it has actually been cut off from the real roots somewhere in an object in HS . This inefficiency is accepted and the effect of this inefficiency is minimized by periodically performing a full garbage collection that uses the traditional technique of marking all live objects accurately in all sections of the heap at once.

The use of the other Heap Sections to continues in the same manner. When section becomes full the system wraps back to use Heap Section . By the time the wrap around occurs there will be many objects in HS that are not alive and have been cleared away by the periodic full garbage collection.

In one or more other embodiments objects can be moved between heap sections based on the average reference rate for that heap section compared to the reference rate of the object. Over time the least referenced objects end up together in e.g. the first heap section and the most often referenced objects end up in e.g. the last heap section. Objects that are suddenly referenced more than their peers in their heap section are moved to e.g. a higher heap section possibly jumping across several sections .

One or more further aspects of the invention may also provide a technique to sort and compact the live objects within a single heap section so that more frequently accessed objects are kept together on a small number of memory pages further reducing the memory working set of the Java system. Compaction is used which groups recently referenced objects together. Compaction is used only periodically and the system rarely performs a full traditional garbage collection where all live objects are marked a full sweep is done and the remaining objects are compacted within their subsections of the heap.

When a program method for any object is run a mark in the object s memory is made that indicates that it has been touched recently. These marks can be reset during the periodic full garbage collection done for the entire heap. The absence of these marks is used to indicate that an object is live but not frequently referenced. A compaction phase of the periodic full garbage collection is changed to group objects that are not frequently referenced together in specific memory pages within their heap section.

Rarely referenced objects are identified and packed close together. This allows whole virtual memory pages to become rarely referenced and then the normal virtual page management scheme will page those rarely listed pages out to disk for long periods of time. This reduces the virtual memory footprint of any Java program that runs in a system using one or more aspects of the invention.

As will be appreciated by one of average skill in the art aspects of embodiments may be embodied as a system method or computer program product. Accordingly aspects of embodiments may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as for example a circuit module or system. Furthermore aspects of embodiments may take the form of a computer program product embodied in one or more computer readable storage device s having computer readable program code embodied thereon.

One or more of the capabilities of embodiments can be implemented in software firmware hardware or some combination thereof. Further one or more of the capabilities can be emulated.

Referring to in one example a computer program product includes for instance one or more non transitory computer readable storage media to store computer readable program code means logic and or instructions thereon to provide and facilitate one or more embodiments.

The present invention may be a system a method and or a computer program product. The computer program product may include a computer readable storage medium or media having computer readable program instructions thereon for causing a processor to carry out aspects of the present invention.

The computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device. The computer readable storage medium may be for example but is not limited to an electronic storage device a magnetic storage device an optical storage device an electromagnetic storage device a semiconductor storage device or any suitable combination of the foregoing. A non exhaustive list of more specific examples of the computer readable storage medium includes the following a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory a static random access memory SRAM a portable compact disc read only memory CD ROM a digital versatile disk DVD a memory stick a floppy disk a mechanically encoded device such as punch cards or raised structures in a groove having instructions recorded thereon and any suitable combination of the foregoing. A computer readable storage medium as used herein is not to be construed as being transitory signals per se such as radio waves or other freely propagating electromagnetic waves electromagnetic waves propagating through a waveguide or other transmission media e.g. light pulses passing through a fiber optic cable or electrical signals transmitted through a wire.

Computer readable program instructions described herein can be downloaded to respective computing processing devices from a computer readable storage medium or to an external computer or external storage device via a network for example the Internet a local area network a wide area network and or a wireless network. The network may comprise copper transmission cables optical transmission fibers wireless transmission routers firewalls switches gateway computers and or edge servers. A network adapter card or network interface in each computing processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium within the respective computing processing device.

Computer readable program instructions for carrying out operations of the present invention may be assembler instructions instruction set architecture ISA instructions machine instructions machine dependent instructions microcode firmware instructions state setting data or either source code or object code written in any combination of one or more programming languages including an object oriented programming language such as Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The computer readable program instructions may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider . In some embodiments electronic circuitry including for example programmable logic circuitry field programmable gate arrays FPGA or programmable logic arrays PLA may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to personalize the electronic circuitry in order to perform aspects of the present invention.

Aspects of the present invention are described herein with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer readable program instructions.

These computer readable program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks. These computer readable program instructions may also be stored in a computer readable storage medium that can direct a computer a programmable data processing apparatus and or other devices to function in a particular manner such that the computer readable storage medium having instructions stored therein comprises an article of manufacture including instructions which implement aspects of the function act specified in the flowchart and or block diagram block or blocks.

The computer readable program instructions may also be loaded onto a computer other programmable data processing apparatus or other device to cause a series of operational steps to be performed on the computer other programmable apparatus or other device to produce a computer implemented process such that the instructions which execute on the computer other programmable apparatus or other device implement the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of instructions which comprises one or more executable instructions for implementing the specified logical function s . In some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.

In addition to the above one or more aspects may be provided offered deployed managed serviced etc. by a service provider who offers management of customer environments. For instance the service provider can create maintain support etc. computer code and or a computer infrastructure that performs one or more aspects for one or more customers. In return the service provider may receive payment from the customer under a subscription and or fee agreement as examples. Additionally or alternatively the service provider may receive payment from the sale of advertising content to one or more third parties.

In one aspect an application may be deployed for performing one or more embodiments. As one example the deploying of an application comprises providing computer infrastructure operable to perform one or more embodiments.

As a further aspect a computing infrastructure may be deployed comprising integrating computer readable code into a computing system in which the code in combination with the computing system is capable of performing one or more embodiments.

As yet a further aspect a process for integrating computing infrastructure comprising integrating computer readable code into a computer system may be provided. The computer system comprises a computer readable medium in which the computer medium comprises one or more embodiments. The code in combination with the computer system is capable of performing one or more embodiments.

Although various embodiments are described above these are only examples. For example computing environments of other architectures can be used to incorporate and use one or more embodiments. Further different thresholds markers and or indicators may be used. Many variations are possible.

Further other types of computing environments can benefit and be used. As an example a data processing system suitable for storing and or executing program code is usable that includes at least two processors coupled directly or indirectly to memory elements through a system bus. The memory elements include for instance local memory employed during actual execution of the program code bulk storage and cache memory which provide temporary storage of at least some program code in order to reduce the number of times code must be retrieved from bulk storage during execution.

Input Output or I O devices including but not limited to keyboards displays pointing devices DASD tape CDs DVDs thumb drives and other memory media etc. can be coupled to the system either directly or through intervening I O controllers. Network adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks. Modems cable modems and Ethernet cards are just a few of the available types of network adapters.

In a further embodiment one or more aspects relate to cloud computing. It is understood in advance that although this disclosure includes a detailed description on cloud computing implementation of the teachings recited herein are not limited to a cloud computing environment. Rather embodiments of the present invention are capable of being implemented in conjunction with any other type of computing environment now known or later developed.

Cloud computing is a model of service delivery for enabling convenient on demand network access to a shared pool of configurable computing resources e.g. networks network bandwidth servers processing memory storage applications virtual machines and services that can be rapidly provisioned and released with minimal management effort or interaction with a provider of the service. This cloud model may include at least five characteristics at least three service models and at least four deployment models.

On demand self service a cloud consumer can unilaterally provision computing capabilities such as server time and network storage as needed automatically without requiring human interaction with the service s provider.

Broad network access capabilities are available over a network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms e.g. mobile phones laptops and PDAs .

Resource pooling the provider s computing resources are pooled to serve multiple consumers using a multi tenant model with different physical and virtual resources dynamically assigned and reassigned according to demand. There is a sense of location independence in that the consumer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction e.g. country state or datacenter .

Rapid elasticity capabilities can be rapidly and elastically provisioned in some cases automatically to quickly scale out and rapidly released to quickly scale in. To the consumer the capabilities available for provisioning often appear to be unlimited and can be purchased in any quantity at any time.

Measured service cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service e.g. storage processing bandwidth and active user accounts . Resource usage can be monitored controlled and reported providing transparency for both the provider and consumer of the utilized service.

Software as a Service SaaS the capability provided to the consumer is to use the provider s applications running on a cloud infrastructure. The applications are accessible from various client devices through a thin client interface such as a web browser e.g. web based email . The consumer does not manage or control the underlying cloud infrastructure including network servers operating systems storage or even individual application capabilities with the possible exception of limited user specific application configuration settings.

Platform as a Service PaaS the capability provided to the consumer is to deploy onto the cloud infrastructure consumer created or acquired applications created using programming languages and tools supported by the provider. The consumer does not manage or control the underlying cloud infrastructure including networks servers operating systems or storage but has control over the deployed applications and possibly application hosting environment configurations.

Infrastructure as a Service IaaS the capability provided to the consumer is to provision processing storage networks and other fundamental computing resources where the consumer is able to deploy and run arbitrary software which can include operating systems and applications. The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems storage deployed applications and possibly limited control of select networking components e.g. host firewalls .

Private cloud the cloud infrastructure is operated solely for an organization. It may be managed by the organization or a third party and may exist on premises or off premises.

Community cloud the cloud infrastructure is shared by several organizations and supports a specific community that has shared concerns e.g. mission security requirements policy and compliance considerations . It may be managed by the organizations or a third party and may exist on premises or off premises.

Public cloud the cloud infrastructure is made available to the general public or a large industry group and is owned by an organization selling cloud services.

Hybrid cloud the cloud infrastructure is a composition of two or more clouds private community or public that remain unique entities but are bound together by standardized or proprietary technology that enables data and application portability e.g. cloud bursting for loadbalancing between clouds .

A cloud computing environment is service oriented with a focus on statelessness low coupling modularity and semantic interoperability. At the heart of cloud computing is an infrastructure comprising a network of interconnected nodes.

Referring now to a schematic of an example of a cloud computing node is shown. Cloud computing node is only one example of a suitable cloud computing node and is not intended to suggest any limitation as to the scope of use or functionality of embodiments of the invention described herein. Regardless cloud computing node is capable of being implemented and or performing any of the functionality set forth hereinabove.

In cloud computing node there is a computer system server which is operational with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with computer system server include but are not limited to personal computer systems server computer systems thin clients thick clients handheld or laptop devices multiprocessor systems microprocessor based systems set top boxes programmable consumer electronics network PCs minicomputer systems mainframe computer systems and distributed cloud computing environments that include any of the above systems or devices and the like.

Computer system server may be described in the general context of computer system executable instructions such as program modules being executed by a computer system. Generally program modules may include routines programs objects components logic data structures and so on that perform particular tasks or implement particular abstract data types. Computer system server may be practiced in distributed cloud computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed cloud computing environment program modules may be located in both local and remote computer system storage media including memory storage devices.

As shown in computer system server in cloud computing node is shown in the form of a general purpose computing device. The components of computer system server may include but are not limited to one or more processors or processing units a system memory and a bus that couples various system components including system memory to processor .

Bus represents one or more of any of several types of bus structures including a memory bus or memory controller a peripheral bus an accelerated graphics port and a processor or local bus using any of a variety of bus architectures. By way of example and not limitation such architectures include Industry Standard Architecture ISA bus Micro Channel Architecture MCA bus Enhanced ISA EISA bus Video Electronics Standards Association VESA local bus and Peripheral Component Interconnect PCI bus.

Computer system server typically includes a variety of computer system readable media. Such media may be any available media that is accessible by computer system server and it includes both volatile and non volatile media removable and non removable media.

System memory can include computer system readable media in the form of volatile memory such as random access memory RAM and or cache memory . Computer system server may further include other removable non removable volatile non volatile computer system storage media. By way of example only storage system can be provided for reading from and writing to a non removable non volatile magnetic media not shown and typically called a hard drive . Although not shown a magnetic disk drive for reading from and writing to a removable non volatile magnetic disk e.g. a floppy disk and an optical disk drive for reading from or writing to a removable non volatile optical disk such as a CD ROM DVD ROM or other optical media can be provided. In such instances each can be connected to bus by one or more data media interfaces. As will be further depicted and described below memory may include at least one program product having a set e.g. at least one of program modules that are configured to carry out the functions of embodiments of the invention.

Program utility having a set at least one of program modules may be stored in memory by way of example and not limitation as well as an operating system one or more application programs other program modules and program data. Each of the operating system one or more application programs other program modules and program data or some combination thereof may include an implementation of a networking environment. Program modules generally carry out the functions and or methodologies of embodiments of the invention as described herein.

Computer system server may also communicate with one or more external devices such as a keyboard a pointing device a display etc. one or more devices that enable a user to interact with computer system server and or any devices e.g. network card modem etc. that enable computer system server to communicate with one or more other computing devices. Such communication can occur via Input Output I O interfaces . Still yet computer system server can communicate with one or more networks such as a local area network LAN a general wide area network WAN and or a public network e.g. the Internet via network adapter . As depicted network adapter communicates with the other components of computer system server via bus . It should be understood that although not shown other hardware and or software components could be used in conjunction with computer system server . Examples include but are not limited to microcode device drivers redundant processing units external disk drive arrays RAID systems tape drives and data archival storage systems etc.

Referring now to illustrative cloud computing environment is depicted. As shown cloud computing environment comprises one or more cloud computing nodes with which local computing devices used by cloud consumers such as for example personal digital assistant PDA or cellular telephone A desktop computer B laptop computer C and or automobile computer system N may communicate. Nodes may communicate with one another. They may be grouped not shown physically or virtually in one or more networks such as Private Community Public or Hybrid clouds as described hereinabove or a combination thereof. This allows cloud computing environment to offer infrastructure platforms and or software as services for which a cloud consumer does not need to maintain resources on a local computing device. It is understood that the types of computing devices A N shown in are intended to be illustrative only and that computing nodes and cloud computing environment can communicate with any type of computerized device over any type of network and or network addressable connection e.g. using a web browser .

Referring now to a set of functional abstraction layers provided by cloud computing environment is shown. It should be understood in advance that the components layers and functions shown in are intended to be illustrative only and embodiments of the invention are not limited thereto. As depicted the following layers and corresponding functions are provided 

Hardware and software layer includes hardware and software components. Examples of hardware components include mainframes in one example IBM zSeries systems RISC Reduced Instruction Set Computer architecture based servers in one example IBM pSeries systems IBM xSeries systems IBM BladeCenter systems storage devices networks and networking components. Examples of software components include network application server software in one example IBM WebSphere application server software and database software in one example IBM DB2 database software. IBM zSeries pSeries xSeries BladeCenter WebSphere and DB2 are trademarks of International Business Machines Corporation registered in many jurisdictions worldwide .

Virtualization layer provides an abstraction layer from which the following examples of virtual entities may be provided virtual servers virtual storage virtual networks including virtual private networks virtual applications and operating systems and virtual clients.

In one example management layer may provide the functions described below. Resource provisioning provides dynamic procurement of computing resources and other resources that are utilized to perform tasks within the cloud computing environment. Metering and Pricing provide cost tracking as resources are utilized within the cloud computing environment and billing or invoicing for consumption of these resources. In one example these resources may comprise application software licenses. Security provides identity verification for cloud consumers and tasks as well as protection for data and other resources. User portal provides access to the cloud computing environment for consumers and system administrators. Service level management provides cloud computing resource allocation and management such that required service levels are met. Service Level Agreement SLA planning and fulfillment provide pre arrangement for and procurement of cloud computing resources for which a future requirement is anticipated in accordance with an SLA.

Workloads layer provides examples of functionality for which the cloud computing environment may be utilized. Examples of workloads and functions which may be provided from this layer include mapping and navigation software development and lifecycle management virtual classroom education delivery data analytics processing and transaction processing.

The terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting. As used herein the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will be further understood that the terms comprises and or comprising when used in this specification specify the presence of stated features integers steps operations elements and or components but do not preclude the presence or addition of one or more other features integers steps operations elements components and or groups thereof.

The corresponding structures materials acts and equivalents of all means or step plus function elements in the claims below if any are intended to include any structure material or act for performing the function in combination with other claimed elements as specifically claimed. The description of one or more embodiments has been presented for purposes of illustration and description but is not intended to be exhaustive or limited to in the form disclosed. Many modifications and variations will be apparent to those of ordinary skill in the art. The embodiment was chosen and described in order to best explain various aspects and the practical application and to enable others of ordinary skill in the art to understand various embodiments with various modifications as are suited to the particular use contemplated.

