---

title: Displaying estimated image data in a user interface
abstract: Methods and systems for robot functions and user interfaces are described. A server may receive a set of robot parameters, and may predict new parameters based on a robot command. In this manner, a user may receive parameters corresponding to the predicted values and mitigate network and processing latency. In other examples, a robot may provide a forward looking image and a robot speed. When a command to move forward is issued, the server may provide a predicted image and predicted speed. The server may be able to calculate a predicted image and a predicted speed (or other parameter) more quickly than the robot could provide the same information. The predicted information may be displayed on a user interface with a corresponding indication that the values are predicted. The robot may provide the server and the user interface with the actual data when it is available.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09399294&OS=09399294&RS=09399294
owner: Google Inc.
number: 09399294
owner_city: Mountain View
owner_country: unknown
publication_date: 20140305
---
The present application claims priority to U.S. patent application Ser. No. 13 440 656 filed on Apr. 5 2012 Provisional U.S. Patent Application Ser. No. 61 483 300 filed on May 6 2011 and Provisional U.S. Patent Application Ser. No. 61 595 847 filed on Feb. 7 2012 the entire contents of both are herein incorporated by reference.

Cloud computing refers to provision of computational resources via a computer network. In a traditional model of computing both data and software are fully contained on a user s computer. In cloud computing however the user s computer may contain relatively little software or data perhaps a minimal operating system and web browser for example and may serve as a display terminal for processes occurring on a network of computers. A common shorthand provided for a cloud computing service or even an aggregation of existing cloud services is the cloud .

Cloud computing has been referred to as client server computing however there may be distinctions between general cloud computing and client server computing. For example client server computing may include a distributed application structure that partitions tasks or workloads between providers of a resource or service e.g. servers and service requesters e.g. clients . Client server computing generally involves a one to one relationship between the server and the client whereas cloud computing includes generic services that can be accessed by generic clients e.g. a one to one relationship or connection may not be required . Thus cloud computing generally includes client server computing and additional services and functionality.

Cloud computing may free users from certain hardware and software installation and maintenance tasks through use of simpler hardware on the user s computer that accesses a vast network of computing resources e.g. processors hard drives etc. . Sharing of resources may reduce cost to individuals. Thus any computer connected to the cloud may be connected to the same pool of computing power applications and files. Users can store and access personal files such as music pictures videos and bookmarks or play games or use productivity applications on a remote server rather than physically carrying around a storage medium such as a DVD or thumb drive.

In one example a user may open a browser and connect to a host of web servers that run user interface software that collect commands from the user and interpret the commands into commands on the servers. The servers may handle the computing and can either store or retrieve information from database servers or file servers and display an updated page to the user. Through cloud computing data across multiple servers can be synchronized around the world allowing for collaborative work on one file or project from multiple users around the world for example.

Any of the methods described herein may be provided in a form of instructions stored on a non transitory computer readable medium that when executed by a computing device cause the computing device to perform functions of the method. Further examples may also include articles of manufacture including tangible computer readable media that have computer readable instructions encoded thereon and the instructions may comprise instructions to perform functions of the methods described herein.

The computer readable medium may include non transitory computer readable medium for example such as computer readable media that stores data for short periods of time like register memory processor cache and Random Access Memory RAM . The computer readable medium may also include non transitory media such as secondary or persistent long term storage like read only memory ROM optical or magnetic disks compact disc read only memory CD ROM for example. The computer readable media may also be any other volatile or non volatile storage systems. The computer readable medium may be considered a computer readable storage medium for example or a tangible storage medium.

In addition circuitry may be provided that is wired to perform logical functions in any processes or methods described herein.

In still further examples any type of devices may be used or configured to perform logical functions in any processes or methods described herein.

In yet further examples any type of devices may be used or configured as means for performing functions of any of the methods described herein or any portions of the methods described herein .

The foregoing summary is illustrative only and is not intended to be in any way limiting. In addition to the illustrative aspects embodiments and features described above further aspects embodiments and features will become apparent by reference to the figures and the following detailed description.

In the following detailed description reference is made to the accompanying figures which form a part hereof. In the figures similar symbols typically identify similar components unless context dictates otherwise. The illustrative embodiments described in the detailed description figures and claims are not meant to be limiting. Other embodiments may be utilized and other changes may be made without departing from the scope of the subject matter presented herein. It will be readily understood that the aspects of the present disclosure as generally described herein and illustrated in the figures can be arranged substituted combined separated and designed in a wide variety of different configurations all of which are explicitly contemplated herein.

This disclosure may disclose inter alia methods and systems for robot cloud computing. Within examples cloud based computing generally refers to networked computer architectures in which application execution and storage may be divided to some extent between client and server devices. A robot may be any device that has a computing ability and interacts with its surroundings with an actuation capability e.g. electromechanical capabilities . A client device may be configured as a robot including various sensors and devices in the forms of modules and different modules may be added or removed from robot depending on requirements. In some examples a robot may be configured to receive a second device such as mobile phone that may be configured to function as an accessory or a brain of the robot.

In examples described herein a robot may interact with the cloud to perform any number of actions such as to share information with other cloud computing devices. Within examples a server may receive a location of a robot and may determine a future location of the robot. The server may then determine a representation of image data from the robot corresponding to the future location and send the representation to a user. In this manner a user may receive image data corresponding to a view of the robot as currently seen by the robot so as to enable remote control of the robot over weakly connected networks. In other examples a robot may be moving forward and may capture image data of the forward view. The image data may be provided to a user and the cloud may also provide alternate views from the standpoint of the robot to the user. A robot user interface may be provided that is overlaid onto image data received from the robot.

In additional examples the robot may provide a variety of parameters e.g. speed position battery life orientation operation mode acceleration system status etc. to the cloud for display on a robot user interface. The cloud may predict values of the parameters before the robot has reported actual values. The predicted values of the parameters may be displayed on the robot user interface while the actual values are being transmitted to the cloud from the robot. The cloud may also transmit a confidence indicator to the user s device for display in the robot user interface. Thus the user would know if the shown parameters are calculated or actual values.

Referring now to the figures is an example system for cloud based computing. Cloud based computing generally refers to networked computer architectures in which application execution and storage may be divided to some extent between client and server devices. A cloud may refer to a service or group of services accessible over a network e.g. Internet by client and server devices for example.

In one example any computer connected to the cloud may be connected to the same pool of computing power applications and files. Thus cloud computing enables a shared pool of configurable computing resources e.g. networks servers storage applications and services that can be provisioned and released with minimal management effort or service provider interaction. Users can store and access personal files such as music pictures videos and bookmarks or play games or use productivity applications on a remote server rather than physically carrying around a storage medium.

As an example in contrast to a predominately client based or server based application a cloud based application may store copies of data and or executable program logic at remote server devices while allowing client devices to download at least some of this data and program logic as needed for execution at the client devices. In some examples downloaded data and program logic can be tailored to capabilities of specific client devices e.g. a personal computer tablet or mobile phone or robot accessing the cloud based application. In addition dividing application execution and storage between the client and server devices allows more processing to be performed by the server devices taking advantage of server devices processing power and capability for example.

Cloud based computing can also refer to distributed computing architectures in which data and program logic for a cloud based application are shared between one or more client devices and or server devices on a near real time basis. Parts of this data and program logic may be dynamically delivered as needed or otherwise to various clients accessing the cloud based application. Details of the architecture may be transparent to users of client devices. Thus a PC user or robot client device accessing a cloud based application may not be aware that the PC or robot downloads program logic and or data from the server devices or that the PC or robot offloads processing or storage functions to the server devices for example.

In a cloud includes a cloud service a cloud platform a cloud infrastructure and a database . The cloud may include more of fewer components and each of the cloud service the cloud platform the cloud infrastructure and the database may comprise multiple elements as well. Thus one or more of the described functions of the system may be divided up into additional functional or physical components or combined into fewer functional or physical components. In some further examples additional functional and or physical components may be added to the examples illustrated by . Delivery of cloud computing may involve multiple cloud components communicating with each other over application programming interfaces such as web services and three tier architectures for example.

The cloud may represent a networked computer architecture and in one example the cloud service represents a queue for handling requests from client devices. The cloud platform may include a frontend of the cloud and may be coupled to the cloud service to perform functions to interact with client devices. The cloud platform may include applications used to access the cloud via a user interface such as a web browser. The cloud infrastructure may include service application of billing components of the cloud and thus may interact with the cloud service . The database may represent storage capabilities by the cloud and thus may be accessed by any of the cloud service the cloud platform and or the infrastructure .

The system includes a number of client devices coupled to or configured to be capable of communicating with components of the cloud . For example a computer a mobile device a host and a robot client are shown coupled to the cloud . Of course more or fewer client devices may be coupled to the cloud . In addition different types of client devices may be coupled to the cloud . For example any of the client devices may generally comprise a display system memory and a processor.

The computer may be any type of computing device e.g. PC laptop computer etc. and the mobile device may be any type of mobile computing device e.g. laptop mobile telephone cellular telephone etc. .

The host may be any type of computing device or transmitter including a laptop computer a mobile telephone etc. that is configured to transmit data to the cloud .

The robot client may comprise any computing device that has connection abilities to the cloud and that has an actuation capability e.g. electromechanical capabilities . A robot may further be a combination of computing devices. In some examples the robot may collect data and upload the data to the cloud . The cloud may be configured to perform calculations or analysis on the data and return processed data to the robot client . In some examples as shown in the cloud may include a computer that is not co located with the robot client . In other examples the robot client may send data to a second client e.g. computer for processing.

Any of the client devices may include additional components. For example the robot client may include one or more sensors such as a gyroscope or an accelerometer to measure movement of the robot client . Other sensors may further include any of Global Positioning System GPS receivers infrared sensors optical sensors biosensors Radio Frequency identification RFID systems wireless sensors and or compasses among others for example.

In addition any of the client devices may include an integrated user interface UI that allows a user to interact with the device. For example the robot client may include various buttons and or a touchscreen interface that allow a user to provide input. As another example the robot client device may include a microphone configured to receive voice commands from a user. Furthermore the robot client may include one or more interfaces that allow various types of user interface devices to be connected to the robot client .

In communication links between client devices and the cloud may include wired connections such as a serial or parallel bus. Communication links may also be wireless links such as link which may include Bluetooth IEEE 802.11 IEEE 802.11 may refer to IEEE 802.11 2007 IEEE 802.11n 2009 or any other IEEE 802.11 revision or other wireless based communication links.

The communication links may change depending on the type of data being sent or network conditions. In some embodiments packets may be sent either based on the Transmission Control Protocol TCP or the User Datagram Protocol UDP . In some applications some data may be sent over a TCP link while additional data is sent over a UDP link. Each protocol has specific advantages and disadvantages. For example a TCP connection is more reliable with each packet being verified upon receipt. The TCP protocol also verifies the receipt of packet so if a packet it lost it can be transmitted again. Contrarily the UDP protocol does not have any packet verification. A UDP data stream is more like a data dump where the receiver may not receive every packet and some packets may be corrupt.

Despite UDP not having data verification in some applications the use of the UDP protocol may be desirable. UDP may be desirable for video streaming. If a packet is lost or corrupt the overall video stream may not suffer significantly. However when transmitting commands to a remote device TCP may be desirable and the reception and verification of each packet helps ensure a correct command is transmitted. In some embodiments the data protocol may be changed on device operating conditions. For example UDP may be used to stream video or position information until a threshold is reached then the connection could fall back to TCP to ensure the data is accurate. For example if a data connection is transmitting position information if the information indicated there may be an obstacle nearby a TCP connection may be desired to make sure the most accurate information is received.

In addition to protocol switching data compression may be changed on the fly as well. Data compression levels may change based on network conditions processing capabilities battery conditions or other factors. For example live in motion video from a robot may be sent to the cloud at a lower resolution than still images. In some embodiments the robot may record video at a full resolution but live stream a lower resolution video. The higher resolution video may be cached on the robot for later transmission to the cloud.

In other examples the system may include access points through which the client devices may communicate with the cloud . Access points may take various forms for example an access point may take the form of a wireless access point WAP or wireless router. As another example if a client device connects using a cellular air interface protocol such as a CDMA or GSM protocol an access point may be a base station in a cellular network that provides Internet connectivity via the cellular network.

As such the client devices may include a wired or wireless network interface through which the client devices can connect to the cloud or access points . As an example the client devices may be configured use one or more protocols such as 802.11 802.16 WiMAX LTE GSM GPRS CDMA EV DO and or HSPDA among others. Furthermore the client devices may be configured use multiple wired and or wireless protocols such as 3G or 4G data connectivity using a cellular communication protocol e.g. CDMA GSM or WiMAX as well as for WiFi connectivity using 802.11 . Additionally some client devices may include a means of telephonic commination. In some example embodiments a client device may not be able to make a traditional data connection. However data connectivity may also be made through a telephone call. Other examples are also possible.

In one example the storage may be used for compiling data from various sensors of the robot and storing program instructions. The processor may be coupled to the storage and may be configured to control the robot based on the program instructions. The processor may also be able to interpret data from the various sensors on the robot. Example sensors may include smoke sensors light sensors radio sensors infrared sensors microphones speakers gyroscope accelerometer a camera radar capacitive sensors and touch sensors etc.

The client device may also have components or devices that allow the client device to interact with its environment. For example the client device may have mechanical actuators such as motors wheels movable arms etc. that enable the client device to move or interact with the environment.

In some example various sensors and devices on the client device may be modules. Different modules may be added or removed from a client device depending on requirements. For example in a low power situation a robot may have fewer modules to reduce power usages. However additional sensors may be added as needed. To increase an amount of data a robot may be able to collect additional sensors may be added for example.

In some example the client device may be configured to receive a device such as device that includes the processor the storage and the sensors . For example the client device may be a robot that have a number of mechanical actuators e.g. a movable base and the robot may be configured to receive a mobile telephone to function as the brains or control components of the robot. The device may be considered a module of the robot. The device may be physically attached to the robot. For example a mobile phone may sit on a robot s chest and form an interactive display. The device may provide a robot with sensors a wireless link and processing capabilities for example. The device may allow a user to download new routines for his or her robot from the cloud. For example a laundry folding routine may be stored on the cloud and a user may be able to select this routine using a mobile phone to download the routine from the cloud and when the mobile phone is placed into or coupled to the robot the robot would be able to perform the downloaded action.

In some examples the client device may be coupled to a mobile or cellular telephone to provide additional sensing capabilities. The cellular phone may not be physically attached to the robot but may be coupled to the robot wirelessly. For example a low cost robot may omit a direct connection to the internet. This robot may be able to connect to a user s cellular phone via a wireless technology e.g. Bluetooth to be able to access the internet. The robot may be able to access various sensors and communication means of the cellular phone. The robot may not need as many sensors to be physically provided on the robot however the robot may be able to keep the same or similar functionality.

Thus the client device may include mechanical robot features and may be configured to receive the device e.g. a mobile phone which can provide additional peripheral components to the device such as any of an accelerometer gyroscope compass GPS camera WiFi connection a touch screen etc. that are included within the device .

In one example the robot may be a toy with only limited mechanical functionality and by connecting device to the robot the toy robot may now be capable of performing a number of functions with the aid of the device and or the cloud. In this manner the robot or components of a robot can be attached to a mobile phone to transform the mobile phone into a robot e.g. with legs arms that is connected to a server to cause operation functions of the robot.

The mountable device may further be configured to maximize runtime usage of the robot e.g. if the robot could learn what happens to cause the user to turn the toy off or set the toy down the device may be configured to perform functions to counteract such occurrences .

Any of the robots illustrated in may be configured to operate according to a robot operating system e.g. an operating system designed for specific functions of the robot . A robot operating system may provide libraries and tools e.g. hardware abstraction device drivers visualizers message passing package management etc. to enable robot applications. Examples of robot operating systems include open source software such as ROS robot operating system DROS or ARCOS advanced robotics control operating system proprietary software such as the robotic development platform ESRP from Evolution Robotics and MRDS Microsoft Robotics Developer Studio and other examples also include ROSJAVA. A robot operating system may include publish and subscribe functionality and may also include functionality to control components of the robot such as head tracking base movement e.g. velocity control navigation framework etc.

As shown any of the modules may be interconnected and or may communicate to receive data or instructions from each other so as to provide a specific output or functionality for the robot.

In one example the robot may send data to a cloud for data processing and in another example the robot may receive data from the cloud. The data received from the cloud may be in many different forms. The received data may be a processed form of data the robot sent to the cloud. The received data may also come from sources other than the robot. For example the cloud may have access to other sensors other robots and the internet.

The cloud may receive input from several robots. Data from each robot may be complied into a larger data set. For example the robot may take a picture of an object and upload the picture to the cloud . An object recognition program on the cloud may be configured to identify the object in the picture and provide data to all the robots connected to the cloud about the recognized object as well as possibly about other characteristics e.g. metadata of the recognized object such as a location size weight color etc. Thus every robot may be able to know attributes of an object in a photo uploaded by the robot .

The robots and may perform any number of actions with an area people other robots etc. In one example each robot and has WiFi or other network based connectivity and will upload publish data to the cloud that can then be shared with any other robot. In this manner each robot and shares experiences with each other to enable learned behaviors. For example the robot may traverse a pathway and encounter an obstacle and can inform the other robots and through the cloud of a location of the obstacle. Each robot and will have access to real time up to date data. In another example the robot can download data indicating images seen by the other robots and to help the robot identify an object using various views e.g. in instances in which the robots and have captured images of the objects from a different perspective .

In still another example the robot may build a map of an area and the robot can download the map to have knowledge of the area. Similarly the robot could update the map created by the robot with new information about the area e.g. the hallway now has boxes or other obstacles or with new information collected from sensors that the robot may not have had e.g. the robot may record and add temperature data to the map if the robot did not have a temperature sensor . Overall the robots and may be configured to share data that is collected to enable faster adaptation such that each robot and can build upon a learned experience of a previous robot.

Sharing and adaptation capabilities enable a variety of applications based on a variety of inputs data received from the robots and . In a specific example mapping of a physical location such as providing data regarding a history of where a robot has been can be provided. Another number or type of indicators may be recorded to facilitate mapping navigational functionality of the robots and e.g. a scuff mark on a wall can be one of many cues that a robot may record and then rely upon later to orient itself .

In one example the cloud may include store or provide access to a database of information related to objects and the database may be accessible by all the robots and . The database may include information identifying objects and details of the objects e.g. mass properties shape instructions for use etc. any detail that may be associated with the object that can be accessed by the robots and to perform object recognition. As an example information regarding use of an object can include e.g. such as for a phone how to pick up a handset how to answer the phone location of buttons how to dial etc.

In addition the database may include information about objects that can be used to distinguish objects. For example the database may include general information regarding an object e.g. such as a computer and additionally information regarding a specific computer e.g. a model number details or technical specifications of a specific model etc. . Each object may include information in the database including an object name object details object distinguishing characteristics etc. or a tuple space for objects that can be accessed. Each object may further include information in the database in an ordered list for example. In further examples the database may include a global unique identifier GUID for objects identified in the database e.g. to enable distinguishing between specific objects and the GUID may be associated with any characteristics or information describing the object. Thus a robot may be configured to access the database to receive information generally distinguishing objects e.g. a baseball vs. a computer and to receive information that may distinguish between specific objects e.g. two different computers .

The database may be accessible by all robots through the cloud or alternatively directly accessible by all robots without communication through the cloud . The database may thus be a shared knowledge base stored in the cloud .

Thus in some examples robots may share learned behaviors through the cloud . The cloud may have a server that stores robot learned activities or behaviors resulting in a shared knowledge base of behaviors and heuristics for object interactions e.g. a robot app store . Specifically a given robot may perform actions and builds a map of an area and then the robot can upload the data to the cloud to share this knowledge with all other robots. In this example a transportation of the given robot s consciousness can be made through the cloud from one robot to another e.g. robot Bob builds a map and the knowledge of Bob can be downloaded onto another robot to receive knowledge of the map .

Thus within examples the robots and may share information through the cloud and may access the database .

As mentioned robots or any client computing device may interact with the cloud to perform any number of functions. Functions may be delayed or modified based on latency of the cloud. For example the cloud may comprise a number of networks and in instances in which the robot is coupled to the cloud or communicates via the cloud messages to and from the robot may be delayed due to limitations of the networks.

In some examples a location of a robot may be determined based upon a GPS sensor on the robot. For instance the robot may provide its location to the cloud using the GPS sensor. The robot may use other location sensors or functions to determine a location such as cellular tower triangulation methods or WiFi localization techniques. However in other examples a robot may not be able to use GPS to determine its location such as when network conditions prevent the robot from either determining or transmitting its exact location. In such examples a location of the robot may be estimated based on a planned or known trajectory or path e.g. location speed direction etc. .

In some examples a user may control or operate a robot over the cloud e.g. send commands to the robot over the cloud and the cloud may comprise a number of networks. The robot may have a camera and a user may receive an output of the camera so as to see a view from the robot s point of view to enable control of the robot. In some examples a robot may be moving forward and collecting image data that is provided to a server. A user may view the image data in real time however the user will receive the image data at a time after the robot has collected the data. A user would like to have a representation of images seen at a current state by the robot rather than those seen one second ago for example to see an exact or substantially exact representation of image data as seen by the robot. The server may thus develop a representation of image data representing data expected to be collected by the robot and provide the representation to the user so that the user has a representation of images seen at a current state by the robot.

To overcome any latency issues with the cloud or delivery of the image data the cloud or components of the cloud may estimate a representation of image data expected to be collected by the robot based on the pathway that the robot is traveling. The cloud may have access to or include a database of maps navigation pathways and image data corresponding to points along the navigation pathways or points in the maps. The cloud can determine location data from the robot or estimate a location of the robot based on commands sent to the robot as described above e.g. known pathway speed and beginning location . Based on the location information of the robot the cloud can determine a future location of the robot and develop a representation of image data corresponding to the future location. The cloud may then provide the representation of image data corresponding to the future location to the user.

The cloud may develop the representation of image data corresponding to the future location by retrieving such image data from the database that corresponds to the future location. The cloud may retrieve still images and create a video feed for example to be provided to the user. The cloud may provide the estimated representation as well as real time data received from the robot to the user so that the user may have both data.

In addition for the method and other processes and methods disclosed herein the flowchart shows functionality and operation of one possible implementation of present embodiments. In this regard each block may represent a module a segment or a portion of program code which includes one or more instructions executable by a processor for implementing specific logical functions or steps in the process. The program code may be stored on any type of computer readable medium for example such as a storage device including a disk or hard drive. The computer readable medium may include non transitory computer readable medium for example such as computer readable media that stores data for short periods of time like register memory processor cache and Random Access Memory RAM . The computer readable medium may also include non transitory media such as secondary or persistent long term storage like read only memory ROM optical or magnetic disks compact disc read only memory CD ROM for example. The computer readable media may also be any other volatile or non volatile storage systems. The computer readable medium may be considered a computer readable storage medium for example or a tangible storage device.

In addition for the method and other processes and methods disclosed herein each block in may represent circuitry that is wired to perform the specific logical functions in the process.

At block the method includes receive location of a robot. For example as described above the robot may include a GPS and may provide a location to a server or the server may estimate the location of the robot based on a known beginning location a speed of movement of the robot and a navigation pathway traversed by the robot.

At block the method includes determine future location of the robot. The server may estimate a future location of the robot based on a known beginning location a speed of movement of the robot and a navigation pathway traversed by the robot. The future location of the robot may be a location of the robot at a time into the future e.g. a predetermined amount of time after a current time. The predetermined amount of time may be approximately equivalent to a latency of the cloud. As an example the server may determine a current location of the robot at time 4 00. In one example embodiment the latency of the cloud may be determine to be about 1 minute and thus the server may determine a future location of the robot or a location where the robot is expected to be at time 4 01. The predetermined amount of time may be set by a user the server or may vary based on latency of the cloud.

At block the method includes determine a representation of image data corresponding to the future location. Continuing with the example above the server may determine a representation of image data corresponding to the location where the robot is expected to be at time 4 01. The server may determine the representation of image data by accessing a database and retrieving image data corresponding to the future location.

At block the method includes send the representation to a user. For example the server may forward the representation to the user.

Using the example method in a user may receive image data corresponding to a view of the robot as approximately currently seen by the robot so as to enable remote control of the robot over weakly connected networks for example.

In some examples a robot may be moving forward and may capture image data of the forward view. The image data may be provided to a user such as for example using the method in . However a user may desire to move a camera on the robot to view a left right area of the robot or any area different from a default forward view of the robot . In instances in which the user does not have the ability to remotely move the camera on the robot to obtain a different view or should the user also still like to have a view of where the robot is going e.g. a forward view the cloud may provide a forward facing view as well as alternate views to the user.

Referring back to the robot may be moving forward toward point A and a camera on the robot may capture image data of the forward view toward point A. A user may desire to see a view to the left of the robot toward point B such as for example to determine whether to cause the robot to turn left. The user may query the cloud for an alternate view of the robot and the cloud may provide the alternate view.

In some examples in response to a query from a user the cloud may determine a location of the robot and a directional view desired by the user based on the location of the robot and develop a representation of the desired view. In some examples the representation of the desired view may be synthesized from data and not an actual representation of a view from an available camera. In other examples the representation of the desired view may be developed from actual camera views. The server may develop the representation of the desired view using any functions of the method in such as to access a database to retrieve image data corresponding to the desired view.

In some examples the cloud may provide image data to the user representing multiple views from a location of the robot. For example the cloud may provide image data representing a forward backward left and right view from a location of the robot.

As shown the robot user interface may be overlaid onto the image data such as overlaying the robot user interface onto real video e.g. a video feed . The robot user interface enables a user to control actions of the robot. Using the robot user interface the user sees the video feed from the robot and the interface overlays onto the view of the robot enabling the user to select items in the view etc. thereby making the video feed a part of the interface and allowing the user to manipulate items in the video feed. Similarly graphics of the user interface can be overlaid onto the video feed.

The robot user interface may include many user controls such as a slide bar zoom control in which a user may zoom in or out on an area of the image by sliding the bar up or down. The robot user interface may also include a navigation control including up down and left right arrows in which the user may control movement of the robot by pressing the arrows or sliding a finger around the circle on the navigation control to control a direction of movement.

In some examples the robot user interface may be provided or configured for use on a touchscreen display so that a user may provide inputs to the robot user interface by touching the controls.

The robot may be configured to detect objects in a pathway of the robot. In the image in the robot has detected object . The robot user interface may identify object by placing a box on the object to indicate to the user that the object is being identified. In addition in some examples the robot may estimate a distance to the object such as about 80 ft. in the example in . The robot user interface may provide a graphic to indicate to the user the distance so that the user may control movement of the robot accordingly.

The robot user interface may further provide graphics and overlaid onto the image. The user may select any of graphics and which may each be individually programmed to execute a function. For example a user may select graphic to cause the robot to travel to the location marked by the dot 10 . Similar functions may be executed by the robot by user selection of graphics and .

The robot user interface may enable the user to interact with or select items in the image as well. For example the image in is an aisle in a grocery store. The robot user interface may enable a user to select a bag of potato chips to the right to cause the robot to pick up or grab the bag of potato chips. In this manner the robot user interface may make each item in the image selectable.

To make items in the image selectable a server e.g. the cloud may receive the image data from the robot and may perform object recognition on the image data so as to provide an estimation of locations of objects in the image. The server may then provide the object recognition outputs to the robot user interface to enable the robot user interface to map recognized objects with selectable items in the image.

In another embodiment the user interface may include a robot speed indicator . The speed indicator may take various forms and is not limited to the embodiment shown in . In one embodiment the speed indicator has text on a colored background. The colored background may indicate an associated confidence level of the speed displayed on the speed indicator. For example if the background is red the speed may be low accuracy predicted speed. If the background is yellow the speed shown may be based on moderately accurate speed estimation. If the background is green the speed shown may be very accurate speed information provided from the robot. The colors and indication style are simply one example. Many other indication systems may be implemented. In another example embodiment the text may change color or size depending on the associated confidence level of the displayed information. In still a further embodiment the indicator may take the form of graphic next to data indictor. The graphic may change color size or shape depending on the desired configuration.

Thus the robot user interface enables sensor data to be overlaid onto a video feed and enables a user to interact with a robot in a three dimensional environment for example. Robot speed indicator is just one example parameter for which the user in robot user interface may display a predicted value. A user may interact with the robot and cause a variety of parameters to change e.g. speed position battery life orientation operation mode acceleration system status etc. . The methods and systems described herein are not limited to robot speed. Data from other various sensors may be used as well. Due to network latency and processing power in some examples it may be advantageous to use processing power associated with the cloud to calculate predictions for all robot parameters when a command is issued to the robot.

In some embodiments when a user issues a command to the robot the robot user interface may update with a predicted image from the new robot location. The prediction may be made by the device on which the robot user interface is displayed and or the cloud. The device on which the robot user interface is displayed may make a first estimate which the cloud may later refine with a more accurate estimate. In other embodiments the cloud may stream predicted images as soon as the cloud receives a robot instruction. As the cloud receives new image data from the robot it may supplement the predicted image data on the user interface with the actual image data from the robot. The user interface may indicate when the displayed information is predicted and when the display is the actual image from the robot.

In a further embodiment the cloud may allow a simulated action to be performed. For example if a user touches graphic indicating he or she wants the robot to move to this position the cloud may receive this command and initiate a simulation. The simulation may use map and sensor data to predict whether the robot could actually move to the position indicated by graphic . If the prediction says the robot cannot move to the indicated location e.g. the robot would run into an obstacle fall off a cliff etc. the user interface may be updated to indicate the movement restriction. For example the user interface may remove graphic from the display. In other embodiments graphic may turn change color to red to indicate it cannot be performed currently. Additionally the user interface may be updated to indicate the possible extent of movement available.

In some additionally embodiments the device on which the robot user interface is displayed and or the cloud may be able to predict actions that cannot be performed before a user tries to initiate said action. The user interface may indicate specific actions cannot be performed based on the prediction. The user interface or the cloud may prevent a user from giving an instruction that the robot will not be able to perform.

Although the blocks are shown in a linear fashion some may be performed in parallel while other blocks may be added or removed. At S the robot may initiate its status with a server. Initiating robot status may involve sending robot parameters from the robot to the server. In some embodiments S is performed after a robot is turned on reset or otherwise beginning functioning in an operation mode. The robot may initiate parameters involving its location operation mode orientation and speed. The server may be able to report the robot status and parameters to a control device at S. The control device may have a user interface for controlling the robot.

Once the control device receives a robot status the control device may allow a user to send commands to the robot. At S a command is sent from the control device to the server. The command may be an instruction for the robot to move interact with its environment or any other function that the robot is capable of performing. The server may responsively send the command to the robot at S. The robot may then responsively execute the command at S

While the robot is executing the robot command the server may calculate robot status parameters at S. The calculated status parameters may be based on the initial robot status provided at S and the robot command from S. For example if the robot command instructed the robot to move forward the calculated robot status parameters may predict the robot s parameters such as speed position orientation etc. The calculated status parameters may be reported to the control device at S. In some embodiments the control device may be able to calculate a robot status parameters on its own without the server or without communicating with the server. The control device can update a user interface UI with the calculated robot status parameters at S. The UI may show the calculated parameters along with a confidence indictor. The confidence indicator may signal the values are predicted.

While the robot is performing the command and or when the command has been completed the robot may send revised status parameters to the server at S. The server may receive the revised robot status parameters at Sand update the stored predicted values with the actual values provided by the robot. The server may relay the revised parameters comprising the actual values from the robot to the control device at S. The control device can update the UI with the revised parameters at S. The UI may indicate the parameters shown in the interface are the actual values reported by the robot.

In some examples a robot user interface may enable control of the robot based on movement of the device on which the robot user interface is displayed. illustrates example configurations for controlling movement of a robot based on movement of the display device. As shown a display device may display a robot user interface e.g. the robot user interface of . In one example to cause the robot to turn right a user may rotate the device such as shown between images and or from images A to B. A user may cause the robot to turn left by rotating the device in an opposite direction such as shown in image C. In some examples the user may cause the robot to move forward or backward by tilt the device forward or backward as shown in image D. In still further examples the user may cause the robot to turn and move at the same time by rotating and tilting the device as shown in image E.

The robot user interface also includes a video feed to show the user a point of view of the robot. Further the robot user interface may include a chat box in which the robot may provide messages to the user.

It should be understood that arrangements described herein are for purposes of example only. As such those skilled in the art will appreciate that other arrangements and other elements e.g. machines interfaces functions orders and groupings of functions etc. can be used instead and some elements may be omitted altogether according to the desired results. Further many of the elements that are described are functional entities that may be implemented as discrete or distributed components or in conjunction with other components in any suitable combination and location.

While various aspects and embodiments have been disclosed herein other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting with the true scope being indicated by the following claims along with the full scope of equivalents to which such claims are entitled. It is also to be understood that the terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting.

Since many modifications variations and changes in detail can be made to the described example it is intended that all matters in the preceding description and shown in the accompanying figures be interpreted as illustrative and not in a limiting sense. Further it is intended to be understood that the following clauses further describe aspects of the present description.

