---

title: Real-time video transformations in video conferences
abstract: Systems and methods are disclosed for real-time video transformations in video conferences. A method includes receiving, by a processing device, a request from a first participant of a video conference to modify a video stream. The method further includes identifying, by the processing device, a foreground and a background within the video stream. The method further includes generating, by the processing device, a modified video stream including a video or image inserted into the background.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09282287&OS=09282287&RS=09282287
owner: Google Inc.
number: 09282287
owner_city: Mountain View
owner_country: US
publication_date: 20140909
---
This disclosure relates to the field of video conferencing in particular to real time video transformations in video conferences.

Video collaborations over the Internet e.g. video conferences telemedicine etc. are becoming increasingly common as broadband access and applications that take advantage of broadband connectivity proliferate. Applications for supporting video collaborations may be browser based or may run independently of a browser.

The following presents a simplified summary of various aspects of this disclosure in order to provide a basic understanding of such aspects. This summary is not an extensive overview of the disclosure. It is intended to neither identify key or critical elements of the disclosure nor delineate any scope of the particular implementations of the disclosure or any scope of the claims. Its sole purpose is to present some concepts of the disclosure in a simplified form as a prelude to the more detailed description that is presented later.

In an aspect of the present disclosure a method includes receiving by a processing device a request from a first participant of a video conference to modify a video stream. The method further includes identifying by the processing device a foreground and a background within the video stream. The method further includes generating by the processing device a modified video stream including a video or image inserted into the background in which the video or image when displayed appears behind the foreground.

Computing devices for performing the operations of the above described method and the various implementations described herein are disclosed. Computer readable media that store instructions for performing operations associated with the above described method and the various implementations described herein are also disclosed.

Aspects and implementations of the present disclosure are directed to applying transformations in real time to video streams. The systems and methods disclosed can be applied to media collaborations e.g. audio and or video conferences audio and or video chat audio and or video conference rooms audio and or video chat rooms etc. in which content media streams e.g. live audio and or video content recorded audio and or video content etc. that are transmitted by devices of one or more participants users are combined into a composite content media stream. Existing video conference technologies enable participants to view the video streams provided by other participants in the video conference and such streams are often arranged e.g. within a single interface such that a single user e.g. the primary presenter or current speaker is allocated a relatively larger or more prominent portion of the interface.

Described herein in various implementations are technologies that allow one or more participants of a media collaboration to request to have video streams associated with the participants transformed in real time. For example as described herein during the course of a video conference a request to insert an image or video into a background of a video stream a video stream of the requester and or a video stream of a different participant is received. The inserted image or video may appear in the background e.g. behind a participant in the foreground e.g. next to or in front of the participant or both. A modified video stream may be generated e.g. by a content processing server a conference server and or locally on a client device participating in the video conference and transmitted to each participant of the video conference in order to produce an aesthetically appealing and or humorous effect during the video conference.

In one implementation the data store may be a memory e.g. random access memory a cache a drive e.g. a hard drive a flash drive a database system or another type of component or device capable of storing data. The data store may also include multiple storage components e.g. multiple drives or multiple databases that may also span multiple computing devices e.g. multiple server computers . In some implementations the data store may be cloud based. One or more of the devices of system architecture may utilize the data store to store public and private data and data store may be configured to provide secure storage for private data. The data store may be part of or distributed between any of the client devices A Z the conference server and the content processing server .

In one implementation the client devices A Z may include one or more computing devices such as personal computers PCs laptops mobile phones smart phones tablet computers netbook computers etc. Client devices A Z may also be referred to as user devices or mobile devices . An individual user may be associated with e.g. own and or use one or more client devices e.g. one or more of client devices A Z . Client devices A Z may each be owned and utilized by different users at different geographical locations. Users that participate in video collaborations e.g. video conferences may be referred to herein as conference participants .

The client devices A Z may each implement the user interfaces A Z respectively. Each of user interfaces A Z may allow a user of the respective client device A Z to send and receive information to one or more of the conference server and the content processing server . For example one or more of the user interfaces A Z may be a web browser interface that can access retrieve present and or navigate content e.g. web pages such as Hyper Text Markup Language HTML pages provided by the conference server . In one implementation one or more of the user interfaces A Z may be a standalone application e.g. a mobile app conferencing software etc. that allows a user of a respective client device A Z to send and receive information to the conference server and or the content processing server . In one implementation one or more of the user interfaces A Z may be conference interfaces that allow conference participants to engage in one or more of video conferencing audio conferencing chatting and or instant messaging. An example user interface e.g. a graphical user interface window is described in greater detail with respect to .

Each client device A Z further includes a media viewer A Z respectively. In one implementation the media viewers A Z may be applications that allow users to view content such as images videos web pages documents etc. For example the media viewer A may be a web browser that can access retrieve present and or navigate content e.g. web pages such as Hyper Text Markup Language HTML pages digital media items etc. served by a web server. The media viewer A may render display and or present the content to a user. The media viewer A may also display an embedded media player that is embedded in a web page e.g. a web page that may provide information about a product sold by an online merchant . In another example the media viewer A may be a standalone application e.g. a mobile app that allows users to view digital media items e.g. digital videos digital images electronic books etc. . In one implementation media viewers A Z may further allow for video to be received from one or more sources and displayed within the respective user interfaces A Z. For example client device A may receive video data from the conference server which may correspond to video streams generated by one or more additional client devices. The media viewer A may generate for display e.g. within the user interface A video corresponding to each of the video streams based on the received video data.

In one implementation the conference server may be one or more computing devices such as a rackmount server a router computer a server computer a personal computer a mainframe computer a laptop computer a tablet computer a desktop computer etc. data stores e.g. hard disks memories databases networks software components hardware components or combinations thereof that may be suitable for implementing the various features described herein. In some implementations the conference server can enable media collaboration services such as audio and or video conferences e.g. among users of client devices A Z using for example streaming video or voice over IP VoIP technologies and may be used for personal entertainment business educational or academically oriented interactions. The conference server may be dedicated to providing video conferencing services or may provide video conferencing services along with other services including for example news services social networking services and or content hosting services.

In one implementation the conference server includes a conference platform . The conference platform as illustrated in includes a hosting module an interface module and a content archive . More or less components may be included in the conference platform without loss of generality. For example two or more of the modules may be combined into a single module or one of the modules may be divided into two or more modules. In one implementation one or more of the modules may reside on different computing devices e.g. different server computers on a single client device distributed among multiple client devices etc. .

In one implementation the hosting module may be utilized by the conference platform to initiate and support media collaborations such as audio video conferences chat rooms video chats etc. For example the hosting module may receive requests from users to create media collaboration sessions may allow users to join pre existing media collaboration sessions upon receiving requests from the users may facilitate transmitting invitations to users that permit the users to join pre existing media collaboration sessions etc.

In one implementation the interface module may be utilized by the conference platform to receive multiple audio and or video streams from one or more of the client devices A Z of various participants and generate a composite stream that may include data associated with each of the received streams. The composite stream may then be provided to the one or more client devices A Z of the various participants in a media collaboration session e.g. a video conference . In some implementations the composite stream may include formatting data that can be used by the client devices A Z for extracting individual video streams and arranging the video streams for presentation by respective user interfaces A Z. Accordingly each user participant of a video conference can simultaneously view some or all of the content streams within a single interface screen as illustrated in .

In some implementations one or more participants in a media collaboration hosted by the conference platform may provide project audio content e.g. a spoken voice of a participant music etc. which upon being received perceived by a client device e.g. one of client devices A Z can be transmitted or otherwise provided by the client device as an audio stream that can be incorporated into the media collaboration. In some implementations such audio streams can be provided independent of a video stream e.g. a participant providing audio only input during a media collaboration while in other implementations such audio streams can be provided in conjunction with a video stream e.g. a combined stream incorporating synchronized video and audio of a participant speaking .

In one implementation the content archive may be utilized by the conference platform to store media collaboration data e.g. store video and or audio stream data chat data etc. which may be accessible by one or more participants via their respective client devices at a later time. In some implementations the content archive may be combined with the data store .

In one implementation the content processing server includes a content transformation component . The content transformation component as illustrated in includes a foreground identification module a target identification module and a content generation module . More or less components may be included in the content transformation component without loss of generality. For example two or more of the modules may be combined into a single module or one of the modules may be divided into two or more modules. In one implementation one or more of the modules may reside on different computing devices e.g. different server computers on a single client device distributed among multiple client devices etc. .

In one implementation the foreground identification module and the target identification module may be utilized by the content transformation component to identify relevant portions of one or more frames of a video stream. For example the foreground identification module may segment one or more frames of the video stream into a foreground and a background for example based on frame to frame comparison of the video images to determine object motion e.g. using a structure from motion algorithm . In some implementations the foreground identification module may utilize one or more digital signal processing DSP chips to perform real time image processing. The target identification module may automatically identify targets regions of interest e.g. faces of video conference participants within the foreground or background. Various algorithms techniques may be utilized for identifying foregrounds and regions of interest of images as would be appreciated by one of ordinary skill in the art.

In one implementation the content generation module may be utilized by the content transformation component to generate a modified video stream using data generated by the foreground identification module and or the target identification module . For example the video stream and an image or video to be inserted into the video stream may be parsed into separate images based on the identified background and foreground of the video stream and combined together to produce a modified video stream. In some implementations the content generation module may perform additional transformations e.g. anti aliasing to improve the quality of the modified video stream . In some implementations the image or video may correspond to one of video image items A Z which may be retrieved from the data store . Each of video image items A Z may include video image data A Z respectively and associated metadata A Z respectively.

In general functions described in one implementation as being performed by any of the conference server or the content processing server can also be performed by one or more of the client devices A Z in other implementations if appropriate. For example the client device A may implement a software application that performs the functions of the content transformation component . In addition the functionality attributed to a particular component can be performed by different or multiple components operating together. In some implementations the content processing server can be accessed as a service provided to other systems or devices through appropriate application programming interfaces.

The conference platform and the content transformation component were described as being implemented by the conference server and the content processing server respectively but may be implemented by any of the client devices A Z the conference server or the content processing server . As an example a client device e.g. client device A may be programmed to perform some or all of the functions of the conference platform and or the content transformation component . As another example the conference platform and content transformation component may be combined together in the conference server. In implementations in which the conference platform and or the content transformation component are implemented on a client device any functions described with respect to the conference platform and or the content transformation component that receive transmit retrieve identify determine etc. are understood to refer to functions performed by sub systems or sub modules within the client device rather than across a network e.g. the network as would be appreciated by one of ordinary skill in the art.

In some implementations each region can contain depict or otherwise present media content e.g. video content provided by a particular participant in a media collaboration. For example the main region may contain a video stream transmitted by a first participant e.g. a room of the first or primary participants in a videoconference video clips shared by the first participant etc. while each of the thumbnail regions A C may contain a miniaturized version of video streams transmitted by one or more additional participants static images e.g. an avatar etc. associated with the additional participants miniaturized versions of video streams associated with the additional participants or combinations thereof. It should be noted that although the regions of the GUI window are depicted as rectangular one or more of the regions may have some other shape e.g. a circle a trapezoid etc. . Moreover the shape size and or layout of the GUI window may depend on the device on which the GUI window is to be presented. For example as illustrated in the GUI window is formatted in a way that is suitable for a mobile device.

In one implementation each of the main region and the thumbnail regions A C may be associated with video streams generated by respective client devices of one or more participants in the video collaboration e.g. video conference participants . Moreover in certain implementations a particular region can change e.g. from a thumbnail region to a major region or switch the video streams displayed in the different regions depending on whether the participant associated with the region is speaking or not e.g. using the interface module . Such a change can be performed automatically e.g. without receiving any user request or detecting any user interaction . In some implementations the conference platform may receive the video streams and identify e.g. using the interface module which video stream corresponds to a current speaker or a focus of attention in general e.g. the video stream corresponds to a participant that is hosting the media collaboration a volume level of a speaker a host selection of a particular participant etc. . In some implementations a client device that implements the GUI window may receive a composite content stream e.g. that includes video audio stream data generated by one or more of the client devices A Z that was generated by the interface module of the conference platform . The client device may be configured to extract content e.g. one or more video audio streams from the composite content stream. In one implementation the composite content stream includes metadata that specifies geometric properties corresponding to regions of the GUI window such that video streams can be extracted from the composite content stream and mapped to the appropriate regions within the GUI window .

In one implementation one of the thumbnail regions A C may transform or transition into the main region e.g. in response to a participant selecting clicking on the thumbnail region or otherwise activating the thumbnail region and vice versa. In some implementations when a particular participant is speaking during a video conference a video stream of the participant may be displayed within the main region . For example if a video stream corresponding to a first participant is displayed in the main region and the first participant is not speaking a second participant s video stream may be promoted from one of the thumbnail regions A C to the main region while the first participant s video stream is demoted to one of the thumbnail regions A C.

In one implementation the composite content stream may include real time chat data. For example the chat data may be displayed within the chat region . The chat region may provide a user participant the opportunity input chat messages and transmit the chat messages e.g. to the conference server which routes the chat messages to client devices of other participants .

In one implementation the options region may provide selectable options to a user. For example the selectable options may allow the user to adjust settings of the media collaboration e.g. display features volume etc. invite additional users to participate apply transformations to a received generated video stream etc. Options related to content transformations are described in greater detail with respect to .

The operations of the method may be performed for a media collaboration according to various implementations of a system architecture e.g. the system architecture . In one implementation content streams such as video streams generated captured by client devices e.g. client devices A Z may be transmitted to a conference server e.g. the conference platform of the conference server and then transmitted to a content processing server e.g. the content transformation component of the content processing server . One or more of the content streams are transformed by the content processing server and transmitted e.g. as a composite content stream to the client devices. In another implementation the content streams are transmitted to the content processing server and one or more of the content streams are transformed transmitted to the conference server and then transmitted to the client devices e.g. as a composite content stream . In another implementation a content stream is generated captured by a first client device e.g. the client device A transformed at the client device e.g. by implementing the content transformation component locally on the client device A and transmitted to the conference server or directly to one or more additional client devices participating in the media collaboration. In another implementation an indication to transform a video stream may be transmitted from a first client device to a second client device in which the transformation of the video stream is performed by the second client device e.g. the second client device implements the content transformation component .

Referring to method begins at block when a selection of a video or image is received from a first participant of a video conference. For example the first participant may select the video or image via a user interface of a client device e.g. user interface A of the client device A . In one implementation the selection may be transmitted by the client device to a content processing server e.g. content processing server .

In one implementation the user interface or media collaboration interface may correspond to GUI window as illustrated in . The GUI window includes a main region that may display a video stream of the first participant. Thumbnails may include video streams of additional participants in the video conference e.g. a second participant associated with the thumbnail and a third participant associated with the thumbnail . In one implementation a thumbnail version of the video stream of the main region is displayed as a thumbnail e.g. as the thumbnail . In some implementations the GUI window may include a chat window e.g. chat region as illustrated in . The GUI window includes an options region that includes selectable options for performing a content transformation. For example the content transformation may include inserting a video or image into one or more video streams during a video conference to provide a comical effect referred to as a photobomb . The options region includes an image video list from which the first participant may select an image or video. For example the image video list may include one or more of a video or image of a celebrity a video or image of an animal a video or image of a cartoon character or other videos or images. As illustrated the first participant has selected martial artist from the list which may correspond to a video clip of a notable martial artist. The GUI window may also include a participant list that lists each of the participants in the video conference. In one implementation the first participant may select one or more participants including the first participant who corresponds to myself . As illustrated the first participant has selected checkbox which indicates that he she wishes to transform his her video stream to include the martial artist selected in the image video list . In some implementations less than all of the options may be present in the options region or additional options may be present in the options region .

Referring back to at block a request to modify a video stream is received from the first participant of the video conference. In one implementation the request is received at the client device and transmitted to a content transformation component e.g. the content transformation component of the content processing server. In one implementation the request may be received by the client device in the form of a selection of a selectable option by the first participant e.g. selection of photobomb button . In some implementations the first participant may select an image or video from the image video list and drag the selected image or video to a region of the GUI window displaying one of the video streams which may be interpreted by the content transformation component as a request to modify the video stream . For example the first participant may drag an indicator of the martial artist to his her video stream displayed in the main region . In other implementations different methods may be used for receiving the selection of the video or image and the request to modify the one or more video streams e.g. voice activation a topic extracted from spoken or textual conversation etc. .

At block a foreground and a background are identified within the video stream. In some implementations if the video stream is a live video stream block is performed for each frame of the live video stream. In some implementations block is performed by the foreground identification module . As illustrated in a foreground of the video stream is identified and may defined by a boundary that segments one or more frames of the video. As illustrated in a background may correspond to a remaining portion of the video stream that is outside of the boundary . In one implementation a target detection algorithm e.g. a facial recognition algorithm may be used by the target identification module to identify a target region within the foreground . For example the target region may correspond to a face e.g. a face of the first participant . A relative location of the foreground e.g. a target corresponding to the target region may be defined based on positions A and B of the target region within a video frame. In some implementations the target e.g. face may be tracked such that the positions A and B may vary from frame to frame of the video stream.

Referring back to at block a modified video stream that includes the video or image inserted into the background is generated such that the video or image when displayed appears behind the foreground. In one implementation a transformation is applied to the video stream by the content generation module to produce the modified video stream. As illustrated in a video frame corresponding to the selected martial artist is overlaid superimposed onto the background of to produce a modified background . As illustrated in the foreground of is then overlaid onto the modified background to produce a modified video frame . In some implementations each video frame of the video stream is transformed resulting in a modified video stream.

In some implementations the transformation may be applied for a time duration e.g. a pre determined time duration of 5 seconds 10 seconds 30 seconds etc. . In some implementations if the video stream is to be modified to include an image e.g. a static image in the background each frame of the video stream may be modified to include the static image for the time duration. In some implementations if a video stream is to be modified to include a video in the background each frame of the video stream may be modified to include an appropriate frame of the video e.g. frame N of the video stream is modified to include frame M of the video frame N 1 of the video stream is modified to include frame M 1 of the video etc. . respectively represent modified frames of the video stream associated with the first participant after applying the transformation which may be appear within respective GUI windows of one or more client devices of the additional participants when the modified video stream has been transmitted to the client devices in accordance with block . For example correspond to the video stream of the first participant of video conference that has been transformed to create the illusion of a martial artist entering the room of the first participant and delivering a powerful roundhouse kick to the back of the first participant s head. In applying the transformation the content transformation component may have accounted for a target region of the video stream e.g. target region in order to insert the video of the martial artist into the video stream at an appropriate location e.g. by translating the video frames of the martial artist such that a pre defined region of the video corresponding to the martial artist s boot is located directly behind the first participant s head.

In one implementation additional transformations may be applied to the video stream. For example as illustrated in a modified background is generated in a similar manner as described with respect to and a foreground of the video stream may be overlaid onto the modified background to produce a first modified video frame as described with respect to . Additionally the first modified video frame portion of the video e.g. corresponding to a hand may also be overlaid over the first modified video frame to produce a second modified video frame as illustrated in . Thus the transformation may include a portion of an image or video that appears behind the foreground of the video stream and a portion of the image or video that appears in front of the foreground. In some implementations a target region of the video stream may be taken into account in determining a position to insert the image or video e.g. to position the video of the martial artist so that his hand appears on the shoulder of the first participant .

For simplicity of explanation the various implementations of the methods of this disclosure are depicted and described as a series of acts. However acts in accordance with this disclosure can occur in various orders and or concurrently and with other acts not presented and described herein. Furthermore not all illustrated acts may be required to implement the methods in accordance with the disclosed subject matter. In addition those skilled in the art will understand and appreciate that the methods could alternatively be represented as a series of interrelated states via a state diagram or events. Additionally it should be appreciated that the implementations of the methods disclosed in this specification are capable of being stored on an article of manufacture to facilitate transporting and transferring such methods to computing devices. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device or storage media.

The exemplary computer system includes a processing device processor a main memory e.g. read only memory ROM flash memory dynamic random access memory DRAM such as synchronous DRAM SDRAM or Rambus DRAM RDRAM etc. a static memory e.g. flash memory static random access memory SRAM etc. and a data storage device which communicate with each other via a bus .

Processor represents one or more general purpose processing devices such as a microprocessor central processing unit or the like. More particularly the processor may be a complex instruction set computing CISC microprocessor reduced instruction set computing RISC microprocessor very long instruction word VLIW microprocessor or a processor implementing other instruction sets or processors implementing a combination of instruction sets. The processor may also be one or more special purpose processing devices such as an application specific integrated circuit ASIC a field programmable gate array FPGA a DSP network processor or the like. The processor is configured to execute instructions for performing the operations and steps discussed herein.

The computer system may further include a network interface device . The computer system also may include a video display unit e.g. a liquid crystal display LCD a cathode ray tube CRT or a touch screen an alphanumeric input device e.g. a keyboard a cursor control device e.g. a mouse and a signal generation device e.g. a speaker .

The data storage device may include a computer readable storage medium on which is stored one or more sets of instructions e.g. software embodying any one or more of the methodologies or functions described herein. The instructions may also reside completely or at least partially within the main memory and or within the processor during execution thereof by the computer system the main memory and the processor also constituting computer readable storage media. The instructions may further be transmitted or received over a network e.g. the network via the network interface device .

In one implementation the instructions include instructions for one or more content transformation components which may correspond to the identically named counterpart described with respect to . While the computer readable storage medium is shown in an exemplary implementation to be a single medium the terms computer readable storage medium or machine readable storage medium should be taken to include a single medium or multiple media e.g. a centralized or distributed database and or associated caches and servers that store the one or more sets of instructions. The terms computer readable storage medium or machine readable storage medium shall also be taken to include any transitory or non transitory medium that is capable of storing encoding or carrying a set of instructions for execution by the machine and that cause the machine to perform any one or more of the methodologies of the present disclosure. The term computer readable storage medium shall accordingly be taken to include but not be limited to solid state memories optical media and magnetic media.

In the foregoing description numerous details are set forth. It will be apparent however to one of ordinary skill in the art having the benefit of this disclosure that the present disclosure may be practiced without these specific details. In some instances well known structures and devices are shown in block diagram form rather than in detail in order to avoid obscuring the present disclosure.

Some portions of the detailed description may have been presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. These algorithmic descriptions and representations are the means used by those skilled in the data processing arts to most effectively convey the substance of their work to others skilled in the art. An algorithm is herein and generally conceived to be a self consistent sequence of steps leading to a desired result. The steps are those requiring physical manipulations of physical quantities. Usually though not necessarily these quantities take the form of electrical or magnetic signals capable of being stored transferred combined compared and otherwise manipulated. It has proven convenient at times principally for reasons of common usage to refer to these signals as bits values elements symbols characters terms numbers or the like.

It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the foregoing discussion it is appreciated that throughout the description discussions utilizing terms such as receiving transmitting generating adding subtracting inserting removing analyzing determining enabling identifying modifying or the like refer to the actions and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical e.g. electronic quantities within the computer system s registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

The disclosure also relates to an apparatus device or system for performing the operations herein. This apparatus device or system may be specially constructed for the required purposes or it may include a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a computer or machine readable storage medium such as but not limited to any type of disk including floppy disks optical disks compact disk read only memories CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing electronic instructions.

The words example or exemplary are used herein to mean serving as an example instance or illustration. Any aspect or design described herein as example or exemplary is not necessarily to be construed as preferred or advantageous over other aspects or designs. Rather use of the words example or exemplary is intended to present concepts in a concrete fashion. As used in this application the term or is intended to mean an inclusive or rather than an exclusive or . That is unless specified otherwise or clear from context X includes A or B is intended to mean any of the natural inclusive permutations. That is if X includes A X includes B or X includes both A and B then X includes A or B is satisfied under any of the foregoing instances. In addition the articles a and an as used in this application and the appended claims should generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form. Reference throughout this specification to an implementation or one implementation means that a particular feature structure or characteristic described in connection with the implementation is included in at least one implementation. Thus the appearances of the phrase an implementation or one implementation in various places throughout this specification are not necessarily all referring to the same implementation. Moreover it is noted that the A Z notation used in reference to certain elements of the drawings is not intended to be limiting to a particular number of elements. Thus A Z is to be construed as having one or more of the element present in a particular implementation.

It is to be understood that the above description is intended to be illustrative and not restrictive. Many other implementations will be apparent to those of skill in the art upon reading and understanding the above description. The scope of the disclosure should therefore be determined with reference to the appended claims along with the full scope of equivalents to which such claims are entitled.

