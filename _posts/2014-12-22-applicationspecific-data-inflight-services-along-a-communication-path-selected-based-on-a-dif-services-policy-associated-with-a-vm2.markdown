---

title: Application-specific data in-flight services along a communication path selected based on a DIF services policy associated with a VM
abstract: Embodiments provide data in-flight (DIF) services to software applications such as virtual machines (VMs) at an application level without requiring modification to established storage protocols. In exemplary embodiments, a software application is associated with a DIF services policy indicating one or more DIF services to apply to the software application. Data transmitted by the software application to a destination is tagged based on the DIF services policy associated with the software application and transmitted to the destination.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09547517&OS=09547517&RS=09547517
owner: VMware, Inc.
number: 09547517
owner_city: Palo Alto
owner_country: US
publication_date: 20141222
---
This application is a continuation of U.S. application Ser. No. 13 371 243 filed Feb. 10 2012 the entirety of which is hereby incorporated by reference herein.

Some computer networks support data in flight DIF services a set of attributes transformations or manipulations that apply to data being transferred between nodes of the network. For example DIF services may be used to provide data integrity data isolation data quality of service QoS and or data security e.g. encryption . In the context of a storage area network SAN data generated by software applications is transmitted through a fabric of network nodes to a consolidated data store. The nodes may include for example initiators e.g. host bus adapters HBAs network switches and or storage controllers in the SAN.

DIF services implementations generally include multiple network nodes working in tandem to accomplish desired results. For example to provide a QoS guarantee e.g. a minimum bandwidth and or a maximum latency a QoS policy may be enforced by all nodes between a source node and the datastore. Accordingly a number of DIF services standards have been developed for use by devices along the path of data transmission. However at least some of these standards do not support virtualization technology and may be unable to distinguish between software applications such as virtual machines VMs executed by a single host. DIF services may therefore be applied to a host based on the DIF services desired for any application executed by that host. For example if encryption is desired for a first application at a host and QoS is desired for a second application at the host an operator may apply both encryption and QoS to the host. As a result both services are applied to the first and second applications even though the operator has no desire to apply QoS to the first application or to apply encryption to the second application. Such over application of DIF services may increase operating overhead in the form of computing resource e.g. processor time memory and or network bandwidth utilization at the host and or elsewhere within the network while providing little or no benefit to the operator.

Conceivably computing resources may be more efficiently utilized by updating existing standards to apply DIF services to individual applications and modifying the nodes in a network to support the updated standards. However modifying multiple network nodes potentially provided by different vendors to support updated standards may be infeasible or impossible. For example modifying the network nodes may impose significant configuration and testing effort. Further some device vendors may be reluctant to invest the effort to support such updated standards.

One or more embodiments described herein provide software application e.g. virtual machine specific data in flight DIF services without requiring modification to established storage protocols. In exemplary embodiments each software application in a cluster may be associated with a DIF services policy indicating one or more DIF services to apply to the software application. The software application is executed by a host that satisfies the associated DIF services policy. For example the software application may be executed at a host that is capable of communicating with a datastore e.g. a storage array using a communication path that supports the services indicated in the DIF services policy. When the software application transmits data to a destination the host tags the data based on the DIF services policy associated with the software application and transmits the tagged data to the destination.

In some embodiments a host creates a plurality of communication paths between the host and a datastore with each communication path supporting a different DIF service or combination of DIF services. Data from each software application executed by the host may be transmitted using a communication path selected based on the DIF services policy if any associated with the software application. Accordingly computing resource utilization may be reduced while satisfying user specified DIF services policies.

This summary introduces a selection of concepts that are described in more detail below. This summary is not intended to identify essential features nor to limit in any way the scope of the claimed subject matter.

Embodiments described herein facilitate applying data in flight DIF services to individual software applications such as virtual machines VMs without requiring extensive changes to network nodes. Although VMs are specifically discussed below the techniques described herein are applicable to any software applications including web services databases media streaming software and or any other software that exchanges data over a network.

In exemplary embodiments a DIF service is communicated out of band OOB with respect to the communication channel s to which the DIF services policy applies. For example a VM may exchange data with a datastore using a storage specific protocol or communication channel such as iSCSI or Fibre Channel. A DIF services policy stipulating that such exchanges be encrypted may be communicated using a general purpose packet network that is considered out of band relative to the storage specific protocol or communication channel. Propagating DIF services policies out of band enables VM specific DIF services without requiring changes to the communication path between a VM and a network node e.g. storage controller with which the VM communicates. Further exemplary embodiments facilitate enforcing a DIF services policy associated with a VM regardless of which host executes the VM. For example a DIF services policy may be stored in association with a VM in a central depository e.g. a datastore included in a VM configuration file and or included in a virtual disk image associated with the VM.

As used herein DIF services refers to configurable attributes transformations or manipulations that may be applied to data transmitted between nodes in a network. For example DIF services may include data integrity data isolation data quality of service QoS and or data security.

Data integrity provides protection against corruption of transferred data. Because corruption can be introduced by any node along a communication path data integrity may be applied along the entire path. Data integrity typically calculates and adds checksums for transmitted data at the source node. Such checksums are validated by nodes along the communication path. This service enables a network operator to prevent corrupt data from being written to a datastore. Data integrity is often applied to data associated with enterprise applications such as databases. Examples of standard implementations of data integrity include data digest and data integrity field DIF data integrity extensions DIX .

Data isolation uses input output IO tags to provide isolation of data along a communication path that is shared by multiple users. Network nodes are configured to recognize these tags and prevent unauthorized users from reading the data. Exemplary implementations include VLAN which may be applied at Layer 2 of the Open Systems Interconnection OSI model and Internet Protocol IP address based access control lists which may be applied at Layer 3 of the OSI model.

Data QoS allocates network resources along a communication path to ensure that a user s or application s performance expectations e.g. minimum bandwidth and or maximum latency are met. An IO pattern e.g. a source node and or a destination node may be associated with a QoS policy at nodes along a communication path. These nodes enforce the QoS policy with respect to data transmissions matching the IO pattern. Exemplary QoS implementations include Data Center Bridging DCB and Fibre Channel over Ethernet FCoE .

Data security protects data against unauthorized data access and network attacks e.g. man in the middle attacks using authentication and or encryption services. For example before data is transferred between endpoint nodes both nodes may authenticate each other using cryptographic keys. In addition or alternatively the data may be encrypted at the transmitting node and decrypted at the receiving node. Exemplary data security implementations include Challenge Handshake Authentication Protocol CHAP and Internet Protocol Security IPsec .

In exemplary embodiments network nodes advertise or publish DIF services capabilities e.g. DIF services supported by the nodes to a server. A policy manager software application allows a user to select a DIF services policy specifying which DIF services to apply to a VM. This policy is stored as metadata associated with the VM. When the VM is executed powered on data transmitted by the VM is tagged by the host executing the VM based on the DIF services policy. The host also executes a path selection component that routes data to a path that supports the services specified by the DIF services policy associated with the VM. As the data is transmitted along the network nodes along the path each of the nodes in the path that advertised supported DIF services applies the DIF services policy.

Computing device also includes at least one presentation device for presenting information to a user . Presentation device is any component capable of conveying information to user . Presentation device may include without limitation a display device e.g. a liquid crystal display LCD organic light emitting diode OLED display or electronic ink display and or an audio output device e.g. a speaker or headphones . In some embodiments presentation device includes an output adapter such as a video adapter and or an audio adapter. An output adapter is operatively coupled to processor and configured to be operatively coupled to an output device such as a display device or an audio output device.

The computing device may include a user input device for receiving input from user . User input device may include for example a keyboard a pointing device a mouse a stylus a touch sensitive panel e.g. a touch pad or a touch screen a gyroscope an accelerometer a position detector and or an audio input device. A single component such as a touch screen may function as both an output device of presentation device and user input device .

Computing device also includes a network communication interface which enables computing device to communicate with a remote device e.g. another computing device via a communication medium such as a wired or wireless packet network. For example computing device may transmit and or receive data via network communication interface . User input device and or network communication interface may be referred to as an input interface and may be configured to receive information from a user.

Computing device further includes a storage interface that enables computing device to communicate with one or more datastores which store virtual disk images software applications data associated with software applications and or any other data suitable for use with the methods described herein. In exemplary embodiments storage interface couples computing device to a storage area network SAN e.g. a Fibre Channel network and or to a network attached storage NAS system e.g. via a packet network . The storage interface may be integrated with network communication interface .

In exemplary embodiments memory stores computer executable instructions for performing one or more of the operations described herein. Memory may include one or more computer readable storage media that have computer executable components embodied thereon. In the example of memory includes a

Embodiments are described herein with reference to virtual machines VMs . However it is contemplated that the methods described may be applied to any type of software application.

The virtualization software layer supports a virtual machine execution space within which multiple virtual machines VMs may be concurrently instantiated and executed. Hypervisor includes a device driver layer and maps physical resources of hardware platform e.g. processor memory network communication interface and or user input device to virtual resources of each of VMs such that each of VMs has its own virtual hardware platform e.g. a corresponding one of virtual hardware platforms each virtual hardware platform having its own emulated hardware such as a processor a memory a network communication interface a user input device and other emulated I O devices in VM .

In some embodiments memory in first virtual hardware platform includes a virtual disk that is associated with or mapped to one or more virtual disk images stored in memory e.g. a hard disk or solid state disk of computing device . The virtual disk image represents a file system e.g. a hierarchy of directories and files used by first virtual machine in a single file or in a plurality of files each of which includes a portion of the file system. In addition or alternatively virtual disk images may be stored in memory of one or more remote computing devices such as a datastore or a data storage container e.g. in a storage area network or SAN configuration .

Device driver layer includes for example a communication interface driver that interacts with network communication interface to receive and transmit data from for example a local area network LAN connected to computing device . Communication interface driver also includes a virtual bridge that simulates the broadcasting of data packets in a physical network received from one communication interface e.g. network communication interface to other communication interfaces e.g. the virtual communication interfaces of VMs . Each virtual communication interface for each VM such as network communication interface for first VM may be assigned a unique virtual Media Access Control MAC address that enables virtual bridge to simulate the forwarding of incoming data packets from network communication interface . In an embodiment network communication interface is an Ethernet adapter that is configured in promiscuous mode such that all Ethernet packets that it receives rather than just Ethernet packets addressed to its own physical MAC address are passed to virtual bridge which in turn is able to further forward the Ethernet packets to VMs . This configuration enables an Ethernet packet that has a virtual MAC address as its destination address to properly reach the VM in computing device with a virtual communication interface that corresponds to such virtual MAC address.

Virtual hardware platform may function as an equivalent of a standard x86 hardware architecture such that any x86 compatible desktop operating system e.g. Microsoft WINDOWS brand operating system LINUX brand operating system SOLARIS brand operating system NETWARE or FREEBSD may be installed as guest operating system OS in order to execute applications for an instantiated VM such as first VM . Virtual hardware platforms may be considered to be part of virtual machine monitors VMM which implement virtual system support to coordinate operations between hypervisor and corresponding VMs . Those with ordinary skill in the art will recognize that the various terms layers and categorizations used to describe the virtualization components in may be referred to differently without departing from their functionality or the spirit or scope of the disclosure. For example virtual hardware platforms may also be considered to be separate from VMMs and VMMs may be considered to be separate from hypervisor . One example of hypervisor that may be used in an embodiment of the disclosure is included as a component in VMware s ESX brand software which is commercially available from VMware Inc.

Hosts communicate with each other via a network . Cluster system also includes one or more management devices which are coupled in communication with hosts via network . In exemplary embodiments a management device monitors and controls hosts . For example management device may monitor performance metrics e.g. application performance metrics and or host performance metrics associated with hosts and may further coordinate the execution of VMs and or other software applications by hosts based on the performance metrics. One or more client devices are coupled in communication with network such that client devices may submit requests to hosts . For example hosts may execute instances of software applications that provide data in response to requests from client devices .

Although management device is shown outside fault domain the functions of management device may be incorporated into fault domain . For example management device may be included in fault domain . Alternatively the functions described with reference to management device may be performed by one or more hosts or VMs executed by one or more hosts in fault domain . Hosts management device and or client device may be computing devices .

Cluster system includes a first storage controller and a second storage controller that provide access to datastores in the form of logical storage containers . In exemplary embodiments storage controllers are instances of computing device shown in and storage containers are abstractions of are backed by storage devices e.g. hard disk drives and or solid state drives managed by storage controllers . For example first storage controller may provide a first storage container and a second storage container that are backed by portions of an array of storage devices e.g. in a redundant array of inexpensive disks or RAID configuration .

Hosts communicate with storage controllers via a storage network . For example storage network may include a storage area network SAN using a protocol such as Fibre Channel and or Internet Small Computer System Interface iSCSI . As another example storage network may include a network attached storage NAS . In exemplary embodiments VMs are associated with virtual disk images configuration files and or other data stored in file systems provided by storage containers . Further in some embodiments storage containers provide a VM specific file system that includes VM volumes each of which encapsulates data e.g. configuration and virtual disk images associated with a VM. Although storage network is illustrated as separate from network in some embodiments storage network may be combined with network .

In creating default communication path hypervisor and storage controller may negotiate session parameters governing the transmission of data through default communication path . Based on the negotiated session parameters hypervisor and storage controller create one or more other communication paths such as a second communication path with various attributes corresponding to DIF services supported by hypervisor and storage controller . For example second communication path may include a data integrity service.

Both hypervisor and storage controller transmit to management device an advertisement of DIF services supported by the corresponding component using an out of band communication path. For example referring also to first communication path and second communication path may be created using storage network and advertisements may be transmitted to management server using network . Management device receives the DIF services capability advertisements and associates supported DIF services with each storage controller and each hypervisor or corresponding host based on the advertisements. This information may be used to determine appropriate DIF services for an IO path and or to determine an appropriate host to execute a VM as described in more detail below.

Although illustrates a hypervisor and a storage controller it should be noted that management device may also receive DIF services capability advertisements from other components such as network switches e.g. OSI Layer 2 switches . For example management device may receive and store QoS capabilities associated with network switches in storage network .

In an exemplary scenario hypervisor communicates with storage controller using the iSCSI protocol. Hypervisor includes an iSCSI protocol stack and a storage controller driver configured to discover multiple channels of service between hypervisor and storage controller . For example hypervisor may apply data integrity Services for all IO transmitted via first communication path and no services for IO transmitted via second communication path . The DIF services associated with communication paths may be determined based on a configuration of hypervisor and or a configuration e.g. DIF services policy of VMs executed by hypervisor . Hypervisor may distinguish between communication paths by assigning a unique attribute such as a channel number to each communication path . As shown in first communication path is illustrated as a first channel Channel 0 and second communication path is illustrated as a second channel Channel 1 .

In exemplary embodiments a VM or a set of VMs is associated with a storage container . The application of DIF services to VMs may be implemented as a capability of storage containers potentially along with other capabilities such as an expected or guaranteed performance level e.g. IO operations per second . Further a storage container may provide a plurality of capabilities DIF services or otherwise. In some embodiments DIF services are grouped into tiers of service such as gold silver and bronze or high medium and low. For example gold service may include data integrity and a minimum level of IO operations per second silver service may include data integrity and bronze service may include no such capabilities.

In some embodiments management device creates a virtual disk image over a storage container using a protocol endpoint PE with the specified DIF services e.g. data integrity . A PE includes for example a device such as a disk that is addressable by a storage controller using a communication protocol e.g. SCSI or Fibre Channel supported by the storage controller . When the VM is powered on hypervisor transmits a bind request to the storage controller for the newly created VVOL in storage container both of which support the specified DIF services. In return hypervisor receives the association of the PE identifier VVOL identifier and storage container as part of the binding process . The PE is used by hypervisor to transmit data in accordance with the DIF services policy. In exemplary embodiments the DIF services policy is stored as metadata associated with the VM in the VVOL.

As described in more detail below hypervisor receives IO operations e.g. in data packets from a VM shown in executed by hypervisor tags the IO operations and transmits the tagged IO operations to storage controller . Storage controller determines whether the received operation satisfies the DIF services policy associated with the VM . When the DIF services policy is satisfied storage controller performs the received operation and transmits an IO response e.g. data read from storage container or confirmation that data was successfully written to storage container . When the DIF services policy is not satisfied storage controller rejects the received operation such as by transmitting an IO response indicating an error.

When a VM transmits data e.g. in a packet hypervisor receives the data and associates with the data one or more tags indicating the DIF services policy associated with the VM . A storage stack includes file system drivers and a path selection plugin PSP . The PSP selects based on the tag s a communication path registered by an underlying protocol driver . For example the PSP may select a communication path that supports the services indicated by the tag s . The tagged data is transmitted to the target storage controller using the selected communication path . When the transmitted data reaches the target storage controller storage controller performs any appropriate services as indicated by the tag s before storing the data in a logical storage container .

In one exemplary scenario host and storage controller communicate using the iSCSI protocol. Each transmission from a VM to storage controller is tagged with the DIF services that are associated with the VM . In the exemplary scenario VM is associated with a DIF services policy specifying data integrity. On a write transmission a checksum of the data to write may be calculated to facilitate validating the data during transmission in flight and or upon arrival at the target. Conversely on a read transmission received data may be validated by host by calculating a checksum of the data and comparing the calculated checksum to a checksum received with the data.

Indicated DIF services may be propagated using an asynchronous token AsyncToken scheme. The PSP selects a communication path satisfying the DIF services policy and the data is communicated using the selected communication path by a protocol driver . In some embodiments protocol driver calculates a checksum for the transmission. In other embodiments the checksum may be calculated e.g. by hypervisor or storage stack before protocol driver receives the data. Protocol driver offloads the IO operation to hardware resources e.g. firmware transmitting the data and the checksum along the selected communication path .

The target storage controller receives the IO at a protocol driver . Based on the VM being associated with a DIF services policy including data integrity storage controller ensures that the received IO satisfies the DIF services policy e.g. includes a checksum . Storage controller calculates a checksum and if the calculated checksum matches the received checksum stores the data in a logical storage container using a logical volume manager LVM . In some embodiments when data integrity is specified storage controller stores the received data in a format that allows checksum values to be stored with data corresponding to the checksum. For example if data may conventionally be stored in a 512 byte sector layout storage controller may store data associated with a VM having a DIF services policy including data integrity in a 520 byte sector layout with an 8 byte checksum field.

The above steps describe a write IO operation. A read IO operation is performed similarly but in reverse. For example when data integrity is enabled the target storage controller may read data requested by the VM and validate the checksum before transmitting the data to host .

Further although storage stack e.g. the PSP is responsible for accommodating the DIF services policy in the scenario above such accommodation may also or instead be performed by other components of host such as protocol driver . For example when QoS is indicated by a DIF services policy protocol driver may set or enable the QoS bit in an IO transmission and underlying network infrastructure along the selected communication path will apply the QoS policy.

Although the operations above are described with reference to particular devices it is contemplated that any portion of such operations may be performed by any computing device shown in . Further the application of DIF services policies to VMs is described above but the methods described may be practiced with respect to any software application executed by a host.

PEs storage containers and storage capabilities may be stored by storage array in a VM volume VVOL provider . A management application VC ESX which may be executed by management device and or a host both shown in queries the PEs storage containers and storage capabilities stored at VVOL provider . VC ESX creates DIF services policies that are available for selection by a storage policy based manager SPBM executed by management device . For example the DIF services policies may include individual DIF services policies and or service tiers each service tier including zero or more DIF services. A user may be prompted to select a DIF services policy to associate with a given VM and storage containers matching the selected DIF services policy may be displayed to the user for selection.

At step upon receiving a selection of a policy for a VM from SPBM VC ESX creates a VVOL within VVOL provider and selects a storage profile e.g. including a DIF services policy associated with the VM. VC ESX associates the storage profile with an identifier of the VM and stores this association in a central depository executed by management device . Central depository may in turn store the association in the VVOL associated with the VM in a virtual disk image associated with the VM and or in a configuration file associated with the VM. VC ESX binds the created VVOL to a PE at VVOL provider .

In the exemplary implementation VC ESX is capable of managing the DIF services policy associated with a VM. For example VC ESX may manage DIF services policies in response to user requests received by SPBM . To associate a DIF services policy with a new VM VC ESX executes an addDIFS function against central depository providing a VM identifier and a DIF services policy. To remove the DIF services policy from a VM VC ESX executes a deleteDIFS function against central depository providing a VM identifier. To modify the DIF services policy associated with a VM VC ESX executes an updateDIFS function against central depository providing a VM identifier and a new DIF services policy. To retrieve the DIF services policy currently associated with a VM VC ESX executes a getDIFS function against central depository providing a VM identifier.

First VM second VM and a storage stack similar to storage stack shown in are executed by a host . Storage stack creates a first communication path and a second communication path between host and a storage array . Data integrity in the form of a digest is enabled for first communication path . No data integrity is enabled for second communication path .

When VMs are powered on storage stack tags data transmitted by VMs based on the DIF services policies associated with VMs . Because data integrity is enabled in the DIF services policy associated with first VM IO from first VM is exchanged with storage array using first communication path . Because no data integrity is enabled in the DIF services policy associated with second VM IO from second VM is exchanged with storage array using second communication path . Accordingly the computing overhead of calculating and validating checksums is incurred only for first VM .

The methods described may be performed by computing devices shown in such as management device shown in . The computing devices communicate with each other through an exchange of messages and or stored data. A computing device may transmit a message as a broadcast message e.g. to an entire network and or data bus a multicast message e.g. addressed to a plurality of other computing devices and or as a plurality of unicast messages each of which is addressed to an individual computing device. Further in some embodiments messages are transmitted using a network protocol that does not guarantee delivery such as User Datagram Protocol UDP . Accordingly when transmitting a message a computing device may transmit multiple copies of the message enabling the computing device to reduce the risk of non delivery.

The operations described herein may be performed by a computer or computing device. A computer or computing device may include one or more processors or processing units system memory and some form of computer readable media. Exemplary computer readable media include flash memory drives digital versatile discs DVDs compact discs CDs floppy disks and tape cassettes. By way of example and not limitation computer readable media comprise computer readable storage media and communication media. Computer readable storage media are tangible and non transitory and store information such as computer readable instructions data structures program modules or other data. Communication media in contrast typically embody computer readable instructions data structures program modules or other data in a transitory modulated data signal such as a carrier wave or other transport mechanism and include any information delivery media. Combinations of any of the above are also included within the scope of computer readable media.

Although described in connection with an exemplary computing system environment embodiments of the disclosure are operative with numerous other general purpose or special purpose computing system environments or configurations. Examples of well known computing systems environments and or configurations that may be suitable for use with aspects of the disclosure include but are not limited to mobile computing devices personal computers server computers hand held or laptop devices multiprocessor systems gaming consoles microprocessor based systems set top boxes programmable consumer electronics mobile telephones network PCs minicomputers mainframe computers distributed computing environments that include any of the above systems or devices and the like.

Embodiments of the disclosure may be described in the general context of computer executable instructions such as program modules executed by one or more computers or other devices. The computer executable instructions may be organized into one or more computer executable components or modules. Generally program modules include but are not limited to routines programs objects components and data structures that perform particular tasks or implement particular abstract data types. Aspects of the disclosure may be implemented with any number and organization of such components or modules. For example aspects of the disclosure are not limited to the specific computer executable instructions or the specific components or modules illustrated in the figures and described herein. Other embodiments of the disclosure may include different computer executable instructions or components having more or less functionality than illustrated and described herein.

Aspects of the disclosure transform a general purpose computer into a special purpose computing device when programmed to execute the instructions described herein.

The operations illustrated and described herein may be implemented as software instructions encoded on a computer readable medium in hardware programmed or designed to perform the operations or both. For example aspects of the disclosure may be implemented as a system on a chip.

The order of execution or performance of the operations in embodiments of the disclosure illustrated and described herein is not essential unless otherwise specified. That is the operations may be performed in any order unless otherwise specified and embodiments of the disclosure may include additional or fewer operations than those disclosed herein. For example it is contemplated that executing or performing a particular operation before contemporaneously with or after another operation is within the scope of aspects of the disclosure.

When introducing elements of aspects of the disclosure or the embodiments thereof the articles a an the and said are intended to mean that there are one or more of the elements. The terms comprising including and having are intended to be inclusive and mean that there may be additional elements other than the listed elements.

Having described aspects of the disclosure in detail it will be apparent that modifications and variations are possible without departing from the scope of aspects of the disclosure as defined in the appended claims. As various changes could be made in the above constructions products and methods without departing from the scope of aspects of the disclosure it is intended that all matter contained in the above description and shown in the accompanying drawings shall be interpreted as illustrative and not in a limiting sense.

