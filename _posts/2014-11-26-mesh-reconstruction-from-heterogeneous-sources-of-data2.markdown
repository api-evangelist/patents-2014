---

title: Mesh reconstruction from heterogeneous sources of data
abstract: A system, apparatus, method, computer program product, and computer readable storage medium provide the ability to reconstruct a surface mesh. Photo image data is obtained from a set of overlapping photographic images. Scan data is obtained from a scanner. A point cloud is generated from a combination of the photo image data and the scan data. An initial rough mesh is estimated from the point cloud data. The initial rough mesh is iteratively refined into a refined mesh.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09659408&OS=09659408&RS=09659408
owner: Autodesk, Inc.
number: 09659408
owner_city: San Rafael
owner_country: US
publication_date: 20141126
---
This application claims the benefit under 35 U.S.C. Section 119 e of the following and commonly assigned U.S. provisional patent application s which is are incorporated by reference herein 

Provisional Application Ser. No. 61 909 847 filed on Nov. 27 2013 by Luc Franck Robert and Emmanuel Gallo entitled Mesh Reconstruction from Heterogeneous Sources of Data .

The present invention relates generally to reality capture data and in particular to a method apparatus and article of manufacture for reconstructing a three dimensional 3D mesh from reality capture data.

It may be desirable to accurately construct reconstruct a 3D mesh based on data from a variety of sources e.g. laser scans Kinect scans photos etc. . Prior art systems provide algorithms to produce a mesh out of single sources of data e.g. a point cloud e.g. products available from Geomagic Inc. . However today the only approach to mesh reconstruction from hybrid data i.e. from multiple sources would be to reconstruct point clouds for each modality independently e.g. photogrammetry and scan then run a surfacing algorithm on the resulting consolidated point cloud. In such an approach each modality proceeds independently from the others so there is no guarantee that one source modality will accurately integrate with another source modality e.g. that a photogrammetry reconstruction process will produce a point cloud that is close to the scan data . Further the resulting point clouds may be different enough that combining the point clouds into a single surface could be a challenge or even impossible. In embodiments of the invention all modalities co operate in the same minimization process and help each other in guiding the process towards the right solution.

Embodiments of the invention provide a new method to automatically reconstruct a highly accurate 3D mesh from reality capture data into a one step method that optimally combines information from any combination of modalities e.g. laser scans Kinect scans photos and any other representation that can be converted into a set of depth maps .

In the following description reference is made to the accompanying drawings which form a part hereof and which is shown by way of illustration several embodiments of the present invention. It is understood that other embodiments may be utilized and structural changes may be made without departing from the scope of the present invention.

Embodiments of the invention propose a new method to automatically reconstruct a highly accurate 3D mesh from reality capture data into a one step method that optimally combines information from any combination of laser scans Kinect scans photos and any other representation that can be converted into a set of depth maps.

The approach can be seen as a generalization of several existing approaches for 3D reconstruction such as photogrammetry e.g. Photofly or pure 3D based reconstruction Kinect Fusion or Poisson surface reconstruction . When only photos are available embodiments of the invention perform i.e. in terms of accuracy and speed at least as well as the photogrammetry engine available from Photofly When point cloud data is available embodiments of the invention perform at least as well as a standard surface reconstruction. When both types of data are present i.e. photos and point cloud data embodiments of the invention optimally fuse data from both sensors to obtain a high quality 3D mesh.

In one or more embodiments computer may be coupled to or may comprise a camera or photo capturing device e.g. a digital camera a cellular phone a personal digital assistant etc. . In yet another embodiment the computer may comprise a multi touch device mobile phone gaming system internet enabled television television set top box or other internet enabled device executing on various platforms and operating systems.

In one or more embodiments computer is communicatively coupled to or may comprise a laser scanner . Such a laser scanner may consist of a field measurement device capable of producing a 3D representation of present conditions through the collection of individually measured points. The set of all points collected and registered with another after the scanning process is referred to as a point cloud. Such a point cloud may be stored in data storage devices within the scanner in memory and or in any other device capable of storing such information. The laser scanner may utilize a variety of scanning methods including aerial static and mobile. Such laser scanning may scan millions of point in seconds without climbing on equipment and or conducting contact measurements.

In one embodiment the computer operates by the general purpose processor A performing instructions defined by the computer program under control of an operating system . The computer program and or the operating system may be stored in the memory and may interface with the user and or other devices to accept input and commands and based on such input and commands and the instructions defined by the computer program and operating system to provide output and results.

Output results may be presented on the display or provided to another device for presentation or further processing or action. In one embodiment the display comprises a liquid crystal display LCD having a plurality of separately addressable liquid crystals. Alternatively the display may comprise a light emitting diode LED display having clusters of red green and blue diodes driven together to form full color pixels. Each liquid crystal or pixel of the display changes to an opaque or translucent state to form a part of the image on the display in response to the data or information generated by the processor from the application of the instructions of the computer program and or operating system to the input and commands. The image may be provided through a graphical user interface GUI module . Although the GUI module is depicted as a separate module the instructions performing the GUI functions can be resident or distributed in the operating system the computer program or implemented with special purpose memory and processors.

In one or more embodiments the display is integrated with into the computer and comprises a multi touch device having a touch sensing surface e.g. track pod or touch screen with the ability to recognize the presence of two or more points of contact with the surface. Examples of multi touch devices include mobile devices e.g. iPhone Nexus S Droid devices etc. tablet computers e.g. iPad HP Touchpad portable handheld game music video player console devices e.g. iPod Touch MP3 players Nintendo 3DS PlayStation Portable etc. touch tables and walls e.g. where an image is projected through acrylic and or glass and the image is then backlit with LEDs . Such multi touch devices may also be integrated with or contain image capture capabilities such as a lens camera etc.

Some or all of the operations performed by the computer according to the computer program instructions may be implemented in a special purpose processor B. In this embodiment some or all of the computer program instructions may be implemented via firmware instructions stored in a read only memory ROM a programmable read only memory PROM or flash memory within the special purpose processor B or in memory . The special purpose processor B may also be hardwired through circuit design to perform some or all of the operations to implement the present invention. Further the special purpose processor B may be a hybrid processor which includes dedicated circuitry for performing a subset of functions and other circuits for performing more general functions such as responding to computer program instructions. In one embodiment the special purpose processor B is an application specific integrated circuit ASIC .

The computer may also implement a compiler that allows an application or computer program written in a programming language such as COBOL Pascal C FORTRAN or other language to be translated into processor readable code. Alternatively the compiler may be an interpreter that executes instructions source code directly translates source code into an intermediate representation that is executed or that executes stored precompiled code. Such source code may be written in a variety of programming languages such as Java Perl Basic etc. After completion the application or computer program accesses and manipulates data accepted from I O devices and stored in the memory of the computer using the relationships and logic that were generated using the compiler .

The computer also optionally comprises an external communication device such as a modem satellite link Ethernet card or other device for accepting input from and providing output to other computers .

In one embodiment instructions implementing the operating system the computer program and the compiler are tangibly embodied in a non transitory computer readable medium e.g. data storage device which could include one or more fixed or removable data storage devices such as a zip drive floppy disc drive hard drive CD ROM drive tape drive etc. Further the operating system and the computer program are comprised of computer program instructions which when accessed read and executed by the computer cause the computer to perform the steps necessary to implement and or use the present invention or to load the program of instructions into a memory thus creating a special purpose data structure causing the computer to operate as a specially programmed computer executing the method steps described herein. Computer program and or operating instructions may also be tangibly embodied in memory data storage device and or data communications devices thereby making a computer program product or article of manufacture according to the invention. As such the terms article of manufacture program storage device and computer program product as used herein are intended to encompass a computer program accessible from any computer readable device or media.

Of course those skilled in the art will recognize that any combination of the above components or any number of different components peripherals and other devices may be used with the computer .

A network such as the Internet connects clients to server computers . Network may utilize ethernet coaxial cable wireless communications radio frequency RF etc. to connect and provide the communication between clients and servers . Clients may execute a client application or web browser and communicate with server computers executing web servers . Such a web browser is typically a program such as MICROSOFT INTERNET EXPLORER MOZILLA FIREFOX OPERA APPLE SAFARI GOOGLE CHROME etc. Further the software executing on clients may be downloaded from server computer to client computers and installed as a plug in or ACTIVEX control of a web browser. Accordingly clients may utilize ACTIVEX components component object model COM or distributed COM DCOM components to provide a user interface on a display of client . The web server is typically a program such as MICROSOFT S INTERNET INFORMATION SERVER .

Web server may host an Active Server Page ASP or Internet Server Application Programming Interface ISAPI application which may be executing scripts. The scripts invoke objects that execute business logic referred to as business objects . The business objects then manipulate data in database through a database management system DBMS . Alternatively database may be part of or connected directly to client instead of communicating obtaining the information from database across network . When a developer encapsulates the business functionality into objects the system may be referred to as a component object model COM system. Accordingly the scripts executing on web server and or application invoke COM objects that implement the business logic. Further server may utilize MICROSOFT S Transaction Server MTS to access required data stored in database via an interface such as ADO Active Data Objects OLE DB Object Linking and Embedding DataBase or ODBC Open DataBase Connectivity .

Generally these components all comprise logic and or data that is embodied in or retrievable from device medium signal or carrier e.g. a data storage device a data communications device a remote computer or device coupled to the computer via a network or via another data communications device etc. Moreover this logic and or data when read executed and or interpreted results in the steps necessary to implement and or use the present invention being performed.

Although the terms user computer client computer and or server computer are referred to herein it is understood that such computers and may be interchangeable and may further include thin client devices with limited or full processing capabilities portable devices such as cell phones notebook computers pocket computers multi touch devices and or any other devices with suitable processing communication and input output capability.

Of course those skilled in the art will recognize that any combination of the above components or any number of different components peripherals and other devices may be used with computers and .

Embodiments of the invention may be implemented as a software application on a client or server computer . Further as described above the client or server computer may comprise a thin client device or a portable device that has a multi touch based display.

For the surface initialization at step source data is a hybrid from a variety of sources including point cloud data from a scanner or Kinect like sensor and overlapping photos. In this regard embodiments of the invention can apply to any combination of source data as long as each data can convert into a function that for a given set of rays in space and a point in 3D typically on a polygon of a surface evolving towards the solution can tell in what direction and potentially what distance the point should move along the ray to get closer to the surface. Examples of the source data and the associated function that can be used include 

The point cloud generation step may also be viewed as the extraction of a rough dense point cloud. All 3D scene details are captured during the generation extraction process. As described above point cloud data may be directly acquired based on scanner input e.g. a Kinect based scan or a laser scanner . However due to the size of directly acquired scanner input scan simplification may be performed to remove redundant data and keep important details. Scan simplification may include a clustering method keeping one representative by cluster an estimate of the surface variation covariance analysis the recursive splitting of clusters etc.

In addition part or all of the point cloud data may be obtained from photographs. To acquire the point cloud data from a photograph pair wise matching may be used via a plane sweep algorithm for the photographs. To extract points via the plane sweep algorithm a photo consistency score per pixel between pair wise images and or between the set of overlapping photographic images may be evaluated. The pair wise images are projected into a moving fronto parallel plane outliers may be removed by imposing a symmetry constraint and the matching scores are maximized locally over the depth. Such a process may be performed by a graphics processing unit GPU executing within a computer.

Further photo image data may be obtained from a set of overlapping photographic images. Such photo image data includes all of the information that is necessary to establish the relation between a pixel in the image and a ray in space. For example the photo image data may include the image data itself as well as associated pose information in space rotation translation and intrinsic parameters focal length non linear distortion principal point etc. .

When extracting generating the point cloud the point cloud data may be refined clustered filtered and outliers may be removed. To cluster the point cloud a top to bottom approach is used. One starts with one cluster and its surface variation is estimated. The surface variation quantifies how strong the surface deviates from the tangent plane. Then the cluster is recursively split until the surface variation is lower than a defined threshold or the size of the cluster is below a certain number of points. The split plane is defined by centroid and axis of greatest variation.

Once the dense point cloud is generated from the hybrid of sources at step an initial rough coarse mesh is estimated created at step . To create the coarse mesh a 3D Delaunay tessellation of the point clouds may be built. The 3D Delaunay triangulation is a triangulation such that the circumsphere of every tetrahedron does not contain any points. To extract the surface from the 3D Delaunay all tetrahadra are classified as inside or outside. For each 3D segment defined by a 3D point and the 3D location of the camera where the point comes from all tetrahedra intersected are penalized. Thereafter empty tetrahedral are rejected using a graph cut algorithm. Alternatively any other method may be used to estimate the rough mesh e.g. Poisson reconstruction . Further when creating the mesh visibility information may also be utilized e.g. information for each point that indicates from which viewpoint the point has been seen . Such visibility information may be utilized during mesh refinement to determine where the surface should be.

Accordingly an initial rough mesh is estimated that is close enough to converge to the global solution. To ensure the rough mesh is close enough to converge to the global solution the mesh may be projected onto one of the images that is used to refine the position of the mesh. If one examines the mesh from an image viewpoint a displacement may be visible. Such a displacement is measured in terms of pixels and the smaller the displacement the more likely the mesh will converge towards the global solution. Typical acceptable displacement values are of a few pixels e.g. up to 5 and depend strongly on the signal in the images.

The mesh is then refined at step . Such a mesh refinement step may also be referred to as a hybrid surface evolution. The mesh refinement is performed iteratively by optimizing a combination of two criteria 1 the photo consistency of images seeing the surface and 2 the signed surface distance to the point cloud for scan based data. In addition to these criteria an additional regularization term may impose some regularity continuity smoothness etc. properties on the mesh while it evolves. In other words the mesh refinement may utilize an error function that is based on a signed surface distance to the point cloud for the scan data. Further the refining process may combine the error function and a surface reprojection error for the photo image data where the surface reprojection error is based on a photo consistency score between the set of overlapping photographic images back projected onto the initial rough mesh . The mesh refinement may also be performed by a GPU.

At step the texture surface is generated from the refined mesh based on red green blue RGB data from the photo image data and or the scan data. Further the textured surface may be displayed processed output and or utilized by a user.

The scan based term measures the 3D distance represented by line between the mesh surface and the input point cloud . It contributes to surface evolution so as to minimize this 3D distance.

A global score is computed per surface element that combines both the correlation score and the 3D distance for instance with a linear combination. A weighting scheme can be used to specify the relative importance of the photo term vs the scan term. To compute the global score for each element of the refined surface mesh a displacement is computed combining all displacement contributions associated with the underlying data e.g. acquired from the correlation score or the 3D distance . The displacement is used to evolve the surface in order to minimize the global score.

Accordingly embodiments of the invention provide a new hybrid surface evolution process that both maximizes photo consistency for images and minimizes a signed distance function to the point cloud for depth data. In particular embodiments of the invention overcome problems with creating an accurate surface mesh based solely on photos that are homogeneous and lack certain information or based solely on scans that are unreliable with black dark surfaces and lack sharp edges. Instead embodiments of the invention combine input from both photos and scan based data to provide a reliable and accurate result in an efficient manner.

This concludes the description of the preferred embodiment of the invention. The following describes some alternative embodiments for accomplishing the present invention. For example any type of computer such as a mainframe minicomputer or personal computer or computer configuration such as a timesharing mainframe local area network or standalone personal computer could be used with the present invention.

In summary embodiments of the invention automatically e.g. without additional user input reconstruct a highly accurate 3D mesh from a variety of reality capture data e.g. laser scans Kinect scans photos etc. . Accordingly embodiments of the invention bring an elegant solution to several problems at once 

The foregoing description of the preferred embodiment of the invention has been presented for the purposes of illustration and description. It is not intended to be exhaustive or to limit the invention to the precise form disclosed. Many modifications and variations are possible in light of the above teaching. It is intended that the scope of the invention be limited not by this detailed description but rather by the claims appended hereto.

