---

title: System and method for detection of elephant flows
abstract: A system and method for detection of elephant flows includes a switching device. The switching device includes one or more ports, a memory, and a control unit coupled to the ports and the memory. The control unit is configured to detect storage locations information included in one or more first messages. The storage locations information identifies a storage node and is forwarded to a computing device. The control unit is further configured to detect opening of a connection between the computing device and the storage node based one or more second messages received for forwarding on one or more of the ports and determine identifying characteristics of an elephant flow based on information associated with the connection. In some embodiments, the control unit is further configured to forward network packets using an altered forwarding strategy when the network packets are associated with the elephant flow.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09461901&OS=09461901&RS=09461901
owner: DELL PRODUCTS L.P.
number: 09461901
owner_city: Round Rock
owner_country: US
publication_date: 20141009
---
The present disclosure relates generally to information handling systems and more particularly to detection of elephant flows in networks.

As the value and use of information continues to increase individuals and businesses seek additional ways to process and store information. One option is an information handling system IHS . An IHS generally processes compiles stores and or communicates information or data for business personal or other purposes. Because technology and information handling needs and requirements may vary between different applications IHSs may also vary regarding what information is handled how the information is handled how much information is processed stored or communicated and how quickly and efficiently the information may be processed stored or communicated. The variations in IHSs allow for IHSs to be general or configured for a specific user or specific use such as financial transaction processing airline reservations enterprise data storage or global communications. In addition IHSs may include a variety of hardware and software components that may be configured to process store and communicate information and may include one or more computer systems data storage systems and networking systems.

Additionally some embodiments of information handling systems include non transient tangible machine readable media that include executable code that when run by one or more processors may cause the one or more processors to perform the steps of methods described herein. Some common forms of machine readable media include for example floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge and or any other medium from which a processor or computer is adapted to read.

Computer networks form the interconnection fabric that enables reliable and rapid communications between computer systems and data processors that are in both close proximity to each other and at distant locations. These networks create a vast spider web of intranets and internets for handling all types of communication and information. Making all of this possible is a vast array of network switching products that make forwarding decisions in order to deliver packets of information from a source system or first network node to a destination system or second network node. Due to the size complexity and dynamic nature of these networks sophisticated network switching products are often required to continuously make forwarding decisions and to determine the best routes and or ways to forward network traffic in a network. As the nodes in the network place changing demands on the network switching products and the network by requesting the forwarding of different types of network of varying sizes it may be advantageous for the network switching products to adjust the ways that different packets of network traffic are handled. For example the network switching products may be tasked with forwarding a large quantity or bandwidth of related data between two nodes for an extended period of time. Data transfers with these characteristics are sometimes referred to as elephant flows. Because of the amount of data in the elephant flow and the amount of time it takes to forward the data it may be advantageous to adjust the forwarding strategy used by one or more of the network switching devices that are forwarding the network traffic associated with the elephant flow. However a precursor to adjusting the forwarding strategy to adapt to an elephant flow is the detection of the existence of the elephant flow.

Accordingly it would be desirable to provide improved systems and methods for detecting elephant flows.

According to one embodiment a switching device includes one or more ports a memory and a control unit coupled to the ports and the memory. The control unit is configured to detect storage locations information included in one or more first messages received for forwarding on one or more of the ports. The storage locations information identifies a storage node and is forwarded to a computing device. The control unit is further configured to detect opening of a connection between the computing device and the storage node based on one or more second messages received for forwarding on one or more of the ports and determine identifying characteristics of an elephant flow based on information associated with the connection.

According to another embodiment a method of managing a switching device includes detecting storage locations information included in one or more first messages received for forwarding at the switching device. The storage locations information identifies a storage node and is forwarded to a computing device. The method further includes detecting opening of a connection between the computing device and the storage node based on one or more second messages received for forwarding at the switching device determining identifying characteristics of an elephant flow based on information associated with the connection receiving one or more network packets at the switching device determining whether the network packets are associated with the elephant flow based on the identifying characteristics and forwarding the network packets using an altered forwarding strategy when the network packets are associated with the elephant flow. The first and second messages and the network packets are received on ports of the switching device.

According to another embodiment an information handling system includes a switching device. The switching device includes one or more ports a memory and a control unit coupled to the ports and the memory. The control unit is configured to detect storage locations information included in one or more first messages received for forwarding on one or more of the ports. The first messages are exchanged between a Hadoop client on a computing device and a name node of a Hadoop distributed file system HDFS or the Hadoop client and a first data node of the HDFS. The storage locations response identify a second data node of the HDFS. The control unit is further configured to detect opening of a connection between the Hadoop client or a storage module of the first data node and a storage module of the second data node based on one or more second messages received for forwarding on one or more of the ports determine identifying characteristics of an elephant flow based on information associated with the connection determine whether one or more network packets received for forwarding on one or more of the ports are associated with the elephant flow based on the identifying characteristics and forward the network packets using an altered forwarding strategy when the network packets are associated with the elephant flow.

In the following description specific details are set forth describing some embodiments consistent with the present disclosure. It will be apparent however to one skilled in the art that some embodiments may be practiced without some or all of these specific details. The specific embodiments disclosed herein are meant to be illustrative but not limiting. One skilled in the art may realize other elements that although not specifically described here are within the scope and the spirit of this disclosure. In addition to avoid unnecessary repetition one or more features shown and described in association with one embodiment may be incorporated into other embodiments unless specifically described otherwise or if the one or more features would make an embodiment non functional.

For purposes of this disclosure an IHS may include any instrumentality or aggregate of instrumentalities operable to compute classify process transmit receive retrieve originate switch store display manifest detect record reproduce handle or utilize any form of information intelligence or data for business scientific control entertainment or other purposes. For example an IHS may be a personal computer a PDA a consumer electronic device a display device or monitor a network server or storage device a switch router or other network communication device or any other suitable device and may vary in size shape performance functionality and price. The IHS may include memory one or more processing resources such as a central processing unit CPU or hardware or software control logic. Additional components of the IHS may include one or more storage devices one or more communications ports for communicating with external devices as well as various input and output I O devices such as a keyboard a mouse and a video display. The IHS may also include one or more buses operable to transmit communications between the various hardware components.

In some embodiments HDFS may further support processing of the data stored therein using the map reduce paradigm. The map reduce paradigm allows for processing of vast amounts of data in parallel on large clusters of commodity hardware in a reliable fault tolerant manner. HDFS typically stores multiple copies of data in large data blocks. In some examples the data blocks in HDFS may be 64 Megabytes MB in size and the replication factor for each block may be three meaning that three copies of each HDFS block are stored by HDFS . As shown in HDFS may include at least two types of components a name node and one or more data nodes .

As shown in name node and data nodes may form an HDFS cluster. In some embodiments one name node may be centralized and help supervise and or manage data nodes . Although a specific configuration of name node and data nodes is shown it is understood that the displayed arrangement of the name node and data nodes in is for exemplification purposes only and that HDFS or and HDFS cluster may include more than one name node and or any number of data nodes in any other reasonable topology.

In some embodiments the name node may be responsible for meta data management of the data stored in HDFS which may include information such as permissions file sizes block storage information and or the like. In some examples name node may be a server a computing device a cluster within a virtual machine and or the like. Name node may be coupled to a network using an edge switch . In some examples the name node may also be referred to as a master server for HDFS .

In some examples a storage application programming interface API may be used to access name node and support storage operations for HDFS . In some examples name node may delegate some or all of storage operations to data nodes . In some examples a client may make storage requests by exchanging one or more messages with name node . In some examples the one or more messages may be part of a message passing protocol such as API calls remote procedure call RPC web services and or the like. In some embodiments name node may distribute the storage and retrieval of data from HDFS to data nodes . In some examples the name node may receive storage requests. In some examples the storage requests may include requests for portions of the meta data stored by name node .

In some embodiments edge switches and or may facilitate communication between name node and data nodes . In some examples each of the edge switches and or may be a switch a hub a bridge a router and or the like. In some examples each of the edge switches and or may be top of rack switches blade switches and or the like. As shown in the examples of in some examples data nodes and are each be coupled to an edge switch and edge switch is coupled to data node . In some embodiments name node and data nodes may be coupled to network using any number of edge switches including some examples where one edge switch couples name node and edge switches to network . In some examples when one edge switch is used the messages between name node and data nodes may not be forwarded over the network . Although a specific configuration of edge switches and name node and data nodes is shown it is understood that the topology of the edge switches and name node and data nodes as shown in is for exemplification purposes only and that an HDFS or HDFS cluster may use other topologies.

In some embodiments data nodes may be responsible for storing the HDFS blocks in the native file system using in the respective data node . In some embodiments each of the data nodes may include one or more processors and memory configured to execute hardware and or software that implements a Hadoop storage module. In some embodiments each of the data nodes may further include one or more storage devices coupled to the one or more processors. Each of the one or more storage devices may include any kind of storage medium or machine readable media suitable for storage of HDFS blocks. Each of the storage devices may include one or more physical and or logical volumes may support a file system and or the like. In some examples the file system may be a local file system a distributed file system and or the like. Some common forms of machine readable media suitable for the storage devices may include floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium RAM PROM EPROM FLASH EPROM any other memory chip or cartridge and or any other medium from which a processor or computer is adapted to read and or the like. In some examples each of the data nodes may be further coupled to one or more storage devices using a network such as network . In some examples each of the storage devices may be any kind of network accessible storage including a storage area network SAN a network attached storage NAS a database server and or the like.

In some embodiments network may be any kind of network including a local area network LAN such as an Ethernet and or a wide area network WAN such as the internet and may vary in complexity from a single switching device operating in relative isolation to large networks of interconnected switching devices. In some examples each of the switching devices may be switches hubs bridges routers and or the like and need not all be the same type of device. The interconnected switching devices may be in close proximity to each other or separated by great distances both physically and as distance is measured in computer networking terms. The interconnected switching devices may also work together in a closely cooperative fashion or in a loose weakly coupled fashion. In some examples the network may also include a variety of hardware and software components that may be configured to process store and communicate information based on requests from of a client and various applications. In some embodiments network may include a network controller such as a software defined networking SDN controller for managing the configuration of the switching devices in network and or the supervision of one or more forwarding strategies used within network .

In some examples a client such as client may be a server or computer running software such as client software e.g. a Hadoop client that allows a computer mobile device tablet PDA Satellite phone video game console or other device to connect to a network and or use the storage services of HDFS . Although not shown in clients other than client may also be coupled to network and HDFS via one or more edge switches. In some examples client may make storage requests by exchanging one or more messages with name node and or data nodes . In some examples the one or more messages may be part of a message passing protocol such as API calls RPC web services and or the like.

Because of the large size of storage blocks in HDFS e.g. typically 64 MB the writing of blocks or the appending of data to existing blocks by clients such as client in HDFS often results in flows of network traffic between client and one of the data nodes that use a significant amount of bandwidth over an extended period of time. These flows of network traffic are sometimes referred to as elephant flows. As the data for a given block is being written by client to one of the data nodes it may be forwarded by client to edge switch where it is forwarded through network to the one of the edge switches coupling the one of the data nodes to network . As the data is forwarded by the edge switches and and the network switching devices in network this forwarding of data may consume a significant amount of resources in each of these edge switches and network switching devices. Thus it may be advantageous to detect the elephant flow associated with the writing of this data and make adjustments to the forwarding strategy used by the edge switches and or and or the network switching devices in network in order to improve the efficiency with which the data in the elephant flow is forwarded and or to reduce disruptions in other network traffic being forwarded by edge switches and or and or the network switching devices of network .

In some embodiments edge switches and or and or the network switching devices of network may make one or more adjustments to create the forwarding strategy for the elephant flow. In some examples the adjustments may include one or more of the following increasing the bandwidth allocated to network packets associated with the elephant flow finding one or more alternate paths for the network packets associated with the elephant flow and or network packets not associated with the elephant flow implementing and or activating one or more quality of service QoS mechanisms and or the like. In some examples the QoS mechanisms may include bandwidth reservation priority queuing and or the like. In some examples the QoS features may be configured using protocols such as the Resource Reservation Protocol RSVP Multiprotocol Label Switching MPLS Asynchronous Transfer Mode ATM and or the like.

In some examples the movement of data between client and the one of the data nodes may not be the only elephant flow associated with a storage operation initiated by client . Because HDFS typically stores blocks in multiple data nodes based on the replication factor one or more additional copies of the data are transferred to others of the data nodes resulting in further elephant flows through the edge switches and and network . Thus it would be advantageous to detect these elephant flows as well and adjust the forwarding strategy of at least those portions of the edge switches and and the switching devices of network that are forwarding the network packets of those elephant flows.

Consider as an example the case where client is writing data associated with an HDFS block to data storage devices associated with data node . Before the writing of the data begins client and data node may exchange one or more messages to create a connection between the Hadoop client in client and the HDFS storage module in data node . For example the Hadoop client and the HDFS storage module may create a Transport Control Protocol TCP connection between themselves based on the IP addresses of client and data node and the TCP ports associated with the Hadoop client and the HDFS storage module. As the data in the elephant flow is transferred between client and data node each of the network packets may include TCP and Internet Protocol IP headers with the two IP addresses and the two TCP ports. In addition the edge switches and as well as the switching devices in network may be able to detect the packets by inspecting the TCP and IP headers of packets being forwarded and apply the forwarding strategy for the elephant flow when a matching set of IP addresses and TCP ports is detected. A similar pattern of IP addresses and TCP ports may also be associated with the additional elephant flows that develop when the data in the block is being written is being replicated to others of the data nodes .

Before the edge switches and or and or the switching devices in network may implement the forwarding strategy for the elephant flow the identifying characteristics of the elephant flow should be known to the edge switches and or and or the switching devices of network . In the examples above this may include knowing the IP addresses and TCP ports associated with the elephant flow. There are several approaches to identifying elephant flows and determining the corresponding identifying elements.

A first approach may include enhancing the Hadoop client used by client and or the HDFS storage modules in name node and or data nodes to notify the edge switches and and or the switching devices of network before a Hadoop write operation is about to begin. This notification however is not very practical as it violates the abstraction principles of layering in a network as it would require the Hadoop client and the HDFS storage modules to become aware of the intervening network coupling them.

Another approach may be to include packet snooping by the edge switches and and or the switching devices of network to recognize a recurring pattern of network packets between the same two IP addresses and TCP ports. For example one or more heuristic rules may be used to detect one or more combinations of quantity interval periodicity and or the like among the network packets with the same IP addresses and TCP ports in the TCP and IP headers. The difficulty with using heuristic rules however is that they may be slow to detect an elephant flow because they may not be applied until after the elephant flow is in operation thus making the adjustments to the forwarding strategy applicable to a portion of the elephant flow. In addition the heuristic rules may result in failure to detect one or more elephant flows and or detecting as an elephant flow a flow that is not an elephant flow resulting in ineffective and or inappropriate adjustments to the forwarding strategy used by the edge switches and and or the switching devices of network .

Accordingly it would be advantageous to implement an elephant flow detection approach that may detect an elephant flow before network packets from the elephant flow are sent to the edge switches and and or the switching devices of network while also avoiding and or reducing the false positives and or false negatives of heuristic methods. One such approach may be determined for HDFS write operations by more closely examining the various exchanges and message passing that occur during HDFS write operations.

At a process a client makes a storage request to a name node. In some embodiments a client such as client may make or initiate a storage request with a file system such as HDFS through a storage controller for the file system. In the examples of name node may be the storage controller for HDFS . In some examples the storage request may be a request to create and write data to a new block and or to append data to a previously created block. In the examples of client may make the storage request to HDFS by exchanging one or more messages to name node . In some examples the one or more messages may be used to activate the Hadoop storage module API supported by name node execute one or more RPCs initiate a web service and or the like. In some examples the Hadoop client in client may decide to make the storage request after the Hadoop client has collected sufficient data from one or more sources and decides that the accumulated data is to be stored in a HDFS block. The messages may be transmitted over one or more network links and through one or more switching devices in a network. Referring again to the examples of the messages of process may pass through edge switch network and edge switch as they are forwarded between client and name node . In some examples when client and name node use the same edge switch e.g. when edge switch and edge switch are the same edge switch the messages may not be forwarded through network .

At a process the name node validates the storage request and replies. When name node receives the storage request made during process name node examines the storage request and validates that it is a storage request name node and HDFS may handle. In some examples this validation may include one or more operations such as determining whether client has sufficient permission s for the storage request HDFS has sufficient available storage to handle the request one or more parameters of the storage request are acceptable and or the like. Once name node determines the storage request may be handled name node responds to the storage request by sending one or more messages back to client through edge switch network and edge switch . The response from name node may notify client as to whether client may proceed with the storage request.

At a process the client requests storage locations information from the name node. After client receives the response from name node approving the storage request made during process client requests information identifying the storage locations to be used for the data to be written to the HDFS block. Because name node maintains general supervisory and management control over HDFS name node may be responsible for determining which of the data nodes is storing the first copy and the replicas of the HDFS block. Consequently client sends the request for the storage locations information to name node . Similar to the storage request of process client may request the storage locations information by exchanging one or more messages with name node . In some examples the one or more messages may be associated with one or more API calls RPCs web services and or the like. Also the one or more messages may be forwarded between client and name node through edge switches and as well as network .

At a process the name node responds with the storage locations information. In response to the request made by client during process name node may return storage locations information to client via one or more messages forwarded through edge switches and and network . In some examples the storage locations information may include at least in part an IP address of the data node selected by name node as that data node from among data nodes that is to store a first copy of the data from the storage request made during process . In some examples the storage locations information may also include IP addresses of the one or more data nodes selected by name node as the data nodes that are to store the corresponding replicas of the HDFS block. In some examples the storage locations information may further include one or more logical unit numbers volume numbers block identifiers and or the like.

At a process the client opens a connection with a first data node. Using the storage locations information provided by name node during process client opens a connection with a first one of the data nodes identified as storing the first copy of the HDFS block. In some examples the IP address of the first data node is used to identify the first data node. In some examples the connection is a TCP connection identified by the IP addresses of client and the first data node as well as a TCP port of the Hadoop client on client and a TCP port of the storage module on the first data node. In some examples client may open the connection with the first data node by exchanging one or more messages with the first data node through edge switch network and an edge switch coupling the first data node to network e.g. edge switch when the first data node is data node . In some examples when the first data node and client are both coupled to network using edge switch the one or more messages may be exchanged through edge switch without having to be forwarded through network . In some examples when the connection is a TCP connection the one or more messages may include one or more SYN SYN ACK and ACK messages.

At a process the client transfers data to the first data node. Once the connection is opened during process client may use the connection to transfer one or more network packets with data for storage by the first data node. Upon receiving the data the first data node may store the data as one or more blocks of its local file system that is maintained on one or more storage devices associated with the first data node. When the data being transferred between client and the first data node is a significant portion of an HDFS block the data transfer is an elephant flow and client may send the data using a large number of data packets to the first data node over an extended period of time. Because each of the network packets is forwarded from client to the first data node using the connection both the TCP and IP headers of each of the network packets may include the same IP addresses for client and the first data node as well as the same TCP ports for the Hadoop client in client and the storage module in the first data node. This allows each of the network packets that are part of the data transfer to be identified as part of the same elephant flow. As with the messages exchanged during process the network packets are forwarded from client to the first data node using edge switch the edge switch coupling the first data node to network and network except for the case where client and the first data node use the same edge switch so that the network packets may be forwarded though edge switch without being forwarded through network .

At a process the client closes the connection with the first data node. When client finishes transferring the data to be written to the first copy of the HDFS block during process the client may close the connection with the first data node to indicate that the transfer of data is complete. In some examples the connection may be closed by exchanging one or more messages between client and the first data node through edge switch network and the edge switch coupling the first data node to network e.g. edge switch when the first data node is data node . In some examples when the connection is a TCP connection the one or more messages may include one or more FIN messages. In some examples when the connection is closed this indicates the end of the elephant flow.

At a process the client transmits storage locations information to the first data node. After the connection is closed during process indicating that the client has no more data to write to a first copy of the HDFS block the process of replicating the HDFS block based on the replication factor for HDFS begins. In some embodiments client may be responsible for transmitting the storage locations information associated with a replica of the HDFS block to the first data node. In some examples the storage locations information may include at least in part an IP address of the data node selected by name node as that data node from among data nodes that is to store the replica of the HDFS block. In some examples the storage locations information may further include one or more logical unit numbers volume numbers block identifiers and or the like. In some embodiments the storage locations response from process may include the same storage locations request of process .

At a process the first data node opens a connection with a second data node. Using the storage locations information provided during process the first data node opens a connection with the second data node as identified by the storage locations information. In some examples the IP address of the second data node is used to identify the second data node. In some examples the connection may be a TCP connection identified by the IP addresses of the first and second data nodes as well as TCP ports of the storage modules in the first and second data nodes. In some examples the first data node may open the connection with the second data node by exchanging one or more messages with the second data node through the edge switch coupling the first data node to network network and an edge switch coupling the second data node to network e.g. edge switch when the second data node is data node . In some examples when the first and second data nodes are both coupled to network using the same edge switch e.g. edge switch the one or more messages may be exchanged through the same edge switch and may not be forwarded through network . In some examples when the connection is a TCP connection the one or more messages may include one or more SYN SYN ACK and ACK messages.

At a process the first data node transfers data to the second data node. Once the connection is opened during process the first data node may use the connection to transfer one or more network packets with data for storage by the second data node in the replica of the HDFS block. Upon receiving the data the second data node may store the data as one or more blocks of its local file system that is maintained on one or more storage devices associated with the second data node. When the data being transferred between the first data node and the second data node is a significant portion of an HDFS block the data transfer is an elephant flow and the first data node may send the data using a large number of data packets to the second data node over an extended period of time. Because each of the network packets is forwarded from the first data node to the second data node using the connection both the TCP and IP headers of each of the network packets may include the same IP addresses for the first and second data nodes as well as the same TCP ports for the storage modules in the first and second data nodes. These common header elements allow each of the network packets that are part of the data transfer to be identified as part of the same elephant flow. As with the messages exchanged during process the network packets are forwarded from the first data node to the second data node using the edge switch coupling the first data node to network the edge switch coupling the second data node to network and network except for the case where the edge switch coupling the first and second data nodes to network is a same edge switch e.g. edge switch so that the network packets may be forwarded though the same edge switch and may not be forwarded through network .

At a process the first data node closes the connection with the second data node. When the first data node finishes transferring the data to be written to the replica of the HDFS block during process the first data node may close the connection with the second data node to indicate that the transfer of data for the replica is complete. In some examples the connection may be closed by exchanging one or more messages between the first data node and the second data node through the edge switch coupling the first data node to network network and the edge switch coupling the second data node to network . In some examples when the connection is a TCP connection the one or more messages may include one or more FIN messages. In some examples when the connection is closed this indicates the end of the elephant flow associated with the replica.

In some embodiments processes may be repeated to copy the data for each of any additional replicas of the HDFS block as determined by the replication factor for HDFS . In some examples when the replication factor for HDFS is three processes would be repeated a second time to copy the data to a second replica i.e. to make a third copy of the HDFS block . In some examples processes may be repeated by the second data node as it sends data for a replica of the HDFS block on a third data node that is different from both the first and second data nodes.

Careful observation of the processes of method reveals that the edge switches in distributed computing system are able to detect each of the elephant flows created by method before data is transferred using the respective elephant flow during processes and as well as to detect the ending of the elephant flows during processes and . For example each of the elephant flows may be detected by observing transfer of storage locations information followed by the opening of a connection to transfer the data to the data node identified by the storage locations information. Consider the case of the first elephant flow between client and the first data node used to store the first copy of the data in an HDFS block. Each of the messages exchanged by client and name node during process used by client to determine the storage locations information are forwarded through edge switch whether or not client and name node are coupled to network using the same edge switch. Additionally each of the messages exchanged by client and the first data node to open the connection during process are forwarded through edge switch as well as each of the network packets sent in the first elephant flow. Further each of the messages exchanged by client and the first data node to close the connection during process are forwarded through edge switch . Thus edge switch is able to detect and observe each of the network messages and packets associated with formation use and ending of the first elephant flow. Similarly the edge switch coupling the first data node to network forwards each of the messages and data packets exchanged during processes associated with the second elephant flow used to make the replica of the HDFS block.

At a process storage locations information is detected. In some examples the storage locations information may correspond to the storage locations information transmitted during processes and or . The storage locations information may be forwarded by the edge switch coupling the client and or a data node to the network. In some embodiments the edge switch may determine that the messages the edge switch is forwarding are associated with the storage locations information using a deep packet inspection approach. In some examples the edge switch may perform deep packet inspection by looking at the headers and or bodies of the messages packets and or datagrams included in the messages being forwarded to look for specific types of header field types and or values as well as payload patterns indicative of the transfer of storage locations information. In some examples the deep packet inspection may include examining the headers and bodies of layer e.g. TCP and layer e.g. application packets and or datagrams. In some examples when the storage locations request is made through a RPC the deep packet inspection may detect the headers for a RPC as well as the request for the specific remote procedure associated with the transfer of the storage locations information. In some examples when the storage locations information is associated with a web service call the deep packet inspection may detect the headers for a web service call as well as the request for the specific web service. In some examples when the storage locations request is associated with a specific protocol the deep packet inspection may detect the headers for the specific protocol as well as the request name and or parameters associated with the storage locations information. In some examples the deep packet inspection may include parsing eXtensible Markup Language XML included in the messages being exchanged such as used by the Simple Object Access Protocol SOAP . In addition as part of the deep packet inspection the edge switch may parse one or more fields of forwarded messages to determine an identity of the data node designated by the name node in the storage locations information. In some examples the identity of the data node may be indicated by an IP address for the data node.

At a process opening of a connection is detected. Once the edge switch has detected the storage locations information during process the edge switch may begin looking for the opening of a corresponding connection to the data node identified in the storage locations information. In some examples the opening of the connection may correspond to the opening of the connection of processes and or . In some embodiments deep packet inspection may be used by the edge switch to detect the headers and bodies associated with the opening of the connection. In some examples when the connection is a TCP connection the deep packet inspection may detect the pattern of TCP messages between the IP address associated with the client and or a data node and the data node identified by the storage locations information. In some examples the TCP messages may include one or more SYN SYN ACK and or ACK messages. In some examples the deep packet inspection may also determine the TCP ports associated with the connection. Once the IP addresses and the TCP ports are known these may be used to identify later network packets associated with the connection and which are part of a corresponding elephant flow. In some examples the edge switch may also record the identifying characteristics of the elephant flow in one or more data structures databases flow tables and or the like.

At an optional process other devices are notified of the elephant flow. Because the edge switch detecting the elephant flow through processes and may only generally adjust its own forwarding strategy it may be useful for the edge switch to communicate its detection of the elephant flow with other devices in the network. In some examples the other devices may include one or more other edge switches such as the edge switch coupling the data node identified by the storage locations response. In some examples the other devices may be neighboring devices to the edge switch. In some examples when the network includes a network controller such as a SDN controller the edge switch may notify the network controller. In some examples the edge switch may notify the other devices using routing forwarding and or QoS protocols such as RSVP MPLS and or the like. In some embodiments process may not be used when the same edge switch couples the client and the data node identified by the storage locations response to the network because the edge switch is able to forward each of the network packets in the elephant flow without using other switching devices in the network.

At a process the edge switch is configured for the elephant flow. Once the edge switch has detected the elephant flow using processes and the edge switch may adjust its forwarding strategy to more effectively handle and or forward the network packets in the elephant flow and or to reduce disruptions to network packets associated with other flows. In some examples the adjustments may include one or more of the following increasing the bandwidth allocated to network packets associated with the elephant flow finding one or more alternate paths for the network packets associated with the elephant flow and or network packets not associated with the elephant flow implementing and or activating one or more QoS features and or the like. In some examples the QoS features may include bandwidth reservation priority queuing and or the like. In some embodiments the configuration to be used by the edge switch may be received from the network controller and or through the routing forwarding and or QoS protocols such as RSVP MPLS and or the like.

At a process data for the elephant flow is forwarded. As the client and or a data node and the data node identified by the storage locations response begin exchanging data using the connection detected during process the edge switch may forward the corresponding network packets using the forwarding strategy configured during process . In some examples the edge switch may detect the network packets that are part of the elephant flow by parsing the network packets using deep packet inspection to detect the pattern of headers and or the like that identify network packets from the elephant flow. In some examples when the connection is a TCP connection the deep packet inspection may identify packets with IP and TCP headers including the IP addresses and TCP ports associated with the elephant flow.

At a process closing of the connection is detected. Once the data is transferred using the elephant flow the client may close the connection detected during process . In some examples the closing of the connection may correspond to the closing of the connection of processes and or . In some examples the edge switch may detect the closing of the connection by again parsing the network packets it is forwarding by using deep packet inspection. In some examples when the connection is a TCP connection the deep packet inspection may identify the closing of the connection by observing one or more FIN messages with IP and TCP headers corresponding to the IP addresses and TCP ports associated with the elephant flow.

At a process the end of the elephant flow is noted. Once the edge switch detects the closing of the connection during process the edge switch may conclude that the elephant flow is ended and any altered forwarding policy configured during process may be rolled back and or removed. In some embodiments the other devices may also be notified of the end of the elephant flow using a process similar to process so that the other devices may be able to adjust their forwarding strategies as well.

In some embodiments processes may be repeated to detect and manage additional elephant flows being forwarded through the edge switch. In some examples processes may also be performed in parallel and or multi threaded fashion when multiple elephant flows are being concurrently detected and or managed by the edge switch.

Memory may be used to store one or more modules or applications and their corresponding data structures. In some embodiments the one or more applications may be implemented using software and or a combination of hardware and software. Memory may include one or more types of machine readable media. Some common forms of machine readable media may include floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge and or any other medium from which a processor or computer is adapted to read. In some examples the one or more applications may include a Hadoop client when computing device is used as part of client a storage module when computing device is used as part of name node and or data nodes routing and or forwarding modules when computing device is used as part of edge switches and or elephant flow detection and or management modules when computing device is used as part of edge switches and or and or the like. In some examples the applications may be used to perform and or facilitate the performance of the processes of methods and or .

In some embodiments computing device may further include one or more storage devices for storing one or more blocks of data . In some examples each of the storage devices may include one or more physical and or logical volumes may support a file system and or the like. In some examples the file system may be a local file system a distributed file system and or the like. Some common forms of storage devices may include for example floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium RAM EPROM FLASH EPROM or other memory chips or cartridges and or any other medium from which a processor or computer is adapted to read. In some examples each of the storage devices may be internally coupled to computing device as shown in and or may be externally coupled to computing device using cables drivers networks and or the like.

Computing device further includes one or more ports for coupling computing device to a network such as network and or other switching devices. Computing device may receive one or more messages from the network on ports and may transmit one or more messages over the network using ports . Depending upon the role of computing device in a computing system computing device may have as few as one port and as many as dozens or more ports. In some examples when the computing device is part of name node data nodes and or client the one or more ports may couple computing device to corresponding edge switches and or . In some examples when the computing device is part of edge switches and or the one or more ports may couple computing device to name node data nodes client and or other network switching devices in network .

Some embodiments of name node data nodes edge switches client and or edge switch may include non transient tangible machine readable media that include executable code that when run by one or more processors may cause the one or more processors to perform the processes of methods and or as described above. Some common forms of machine readable media that may include the processes of methods and or are for example floppy disk flexible disk hard disk magnetic tape any other magnetic medium CD ROM any other optical medium punch cards paper tape any other physical medium with patterns of holes RAM PROM EPROM FLASH EPROM any other memory chip or cartridge and or any other medium from which a processor or computer is adapted to read.

Although illustrative embodiments have been shown and described a wide range of modification change and substitution is contemplated in the foregoing disclosure and in some instances some features of the embodiments may be employed without a corresponding use of other features. One of ordinary skill in the art would recognize many variations alternatives and modifications. Thus the scope of the invention should be limited only by the following claims and it is appropriate that the claims be construed broadly and in a manner consistent with the scope of the embodiments disclosed herein.

