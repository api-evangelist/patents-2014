---

title: Method, device and storage medium for implementing augmented reality
abstract: The present disclosure relates to a method, a device and a storage medium for implementing augmented reality. The method includes: obtaining a real scene, and according to shooting position and shooting direction of the real scene, obtaining POIs within a preset area and POI information corresponding to the POIs, the POI information comprising position information of the corresponding POI; creating a virtual plane, and mapping position relationship between the POIs on the virtual plane, and inserting tags of POI information to the location of the corresponding POI on the virtual plane; superimposing the virtual plane having the tags of POI information onto the real scene to form an augmented reality view; and displaying the augmented reality view, and adjusting the virtual plane according to real-time information of the real scene, to make the virtual plane be visually parallel to the horizontal plane of the real scene.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09367961&OS=09367961&RS=09367961
owner: TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED
number: 09367961
owner_city: Shenzhen, Guangdong Province
owner_country: CN
publication_date: 20140310
---
This application is a U.S. continuation application under 35 U.S.C. 111 a claiming priority under 35 U.S.C. 120 and 365 c to International Application No. PCT CN2013 091048 filed Dec. 31 2013 which claims the priority benefit of Chinese Patent Application No. 201310129360.7 filed on Apr. 15 2013 the contents of which are incorporated by reference herein in their entirety for all intended purposes.

The present disclosure relates to computer technology particularly relates to a method a device and a storage medium for implementing augmented reality.

In recent years with the rapid development of intelligent terminals and mobile internet technology augmented reality technology abbreviated as AR is known to the public. A large number of AR applications based on image processing and terminal positioning technology have begun to emerge which caused a greater concern in the industry and becomes a technology research hotspot.

In researching and application of AR technology virtual AR information is applied to the real world. The traditional WEB page browsing query mode based on text input changes into a new mode based on camera shooting hotspots capturing and AR information viewing real time.

When users of AR terminals for example smart phones shoot surrounding scenery they can get AR experience at the same time. In a typical business scene when an AR application running on the user s mobile terminal captures AR targets deployed by AR service providers based on the user s current location the AR application can get the AR content corresponding with the AR target and according to the user s choice. The AR target for example includes the target point of interest to the user i.e. the point of interests POI . The AR content includes text images audio video and so on. The AR application displays virtual information captured by the imaging apparatus of the user s mobile terminal and AR content in a tag form on the terminal s screen and presents AR views to the users. The AR view is an observation view formed by AR content and real time recording with the imaging apparatus displayed and rendered on the mobile terminal s screen.

However in the existing AR technology the tags corresponding with POIs in the AR view often overlap each other so that the users cannot determine the location relationship between the POIs.

The present disclosure is to provide a method a device and a storage medium for implementing augmented reality electronic terminal to solve the problem mentioned above.

A method for implementing augmented reality electronic terminal includes obtaining a real scene and according to shooting position and shooting direction of the real scene obtaining POIs within a preset area and POI information corresponding to the POIs the POI information comprising position information of the corresponding POI creating a virtual plane and mapping position relationship between the POIs on the virtual plane and inserting tags of POI information to the location of the corresponding POI on the virtual plane superimposing the virtual plane having the tags of POI information onto the real scene to form an augmented reality view and displaying the augmented reality view and adjusting the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene electronic terminal.

A device for implementing augmented reality the device comprises at least a processor operating in conjunction with a memory and a plurality of modules the plurality of modules includes a real scene obtaining module configured to obtain a real scene a POI obtaining module configured to obtain POIs within a preset area and POI information corresponding to the POIs according to shooting position and shooting direction of the real scene the POI information comprising position information of the corresponding POI a virtual plane creating module configured to create a virtual plane and map position relationship between the POIs on the virtual plane and insert tags of POI information to the location of the corresponding POI on the virtual plane a superimposing module configured to superimpose the virtual plane having the tags of POI information onto the real scene to form an augmented reality view and a displaying and adjusting module configured to display the augmented reality view and adjust the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene.

A computer readable storage medium storing instructions for implementing augmented reality the instructions includes obtaining a real scene and according to shooting position and shooting direction of the real scene obtaining POIs within a preset area and POI information corresponding to the POIs the POI information comprising position information of the corresponding POI creating a virtual plane and mapping position relationship between the POIs on the virtual plane and inserting tags of POI information to the location of the corresponding POI on the virtual plane superimposing the virtual plane having the tags of POI information onto the real scene to form an augmented reality view and displaying the augmented reality view and adjusting the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene.

In accordance with the embodiments the electronic terminal creates a virtual plane maps position relationship between the POIs on the virtual plane inserts tags of POI information to the location of the corresponding POI on the virtual plane. Then the electronic terminal superimposes the virtual plane having the tags of POI information onto the real scene to form an augmented reality view displays the augmented reality view and adjusts the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene. Therefore the tags of POI information in the augmented reality view final presented to the users have more dimensional sense and more sense of hierarchy show the distance between the POIs and relative position relationship between the POI and uses intuitively and improves the efficiency of the application of augmented reality.

Other features and advantages of the present disclosure will immediately be recognized by persons of ordinary skill in the art with reference to the attached drawings and detailed description of exemplary embodiments as given below.

Various embodiments of the disclosure are discussed in detail below. While specific implementations are discussed it should be understood that this is done for illustration purposes only. A person skilled in the art will recognize that other components and configurations may be used without parting from the spirit and scope of the disclosure.

The method for implementing augmented reality may be applied in an electronic terminal. illustrates a runtime environment according to various embodiments of the present disclosure. The exemplary environment may include an electronic terminal a server and a communication network . The server and the client may be coupled through the communication network for information exchange such as sending receiving identification information sending receiving data files such as splash screen images etc. Although only one electronic terminal and one server are shown in the environment any number of electronic terminals or servers may be included and other devices may also be included.

The server as used herein may refer to one or more server computers configured to provide certain server functionalities such as database management and search engines. The server may include one or more processors to execute computer programs in parallel. In the present disclosure the sever may be a functional entity deployed by AR service providers for maintaining user preferences business relationships and orders and according to user requests or business settings to deliver captured augmented reality targets available for access to the electronic terminal such as POI as well as augmented reality content including text images audio video and other multimedia information to provide users with augmented reality services.

The communication network may include any appropriate type of communication network for providing network connections to the server and the electronic terminal or among multiple servers or clients. For example communication network may include the Internet or other types of computer networks or telecommunication networks either wired or wireless. In a certain embodiment the disclosed methods and apparatus may be implemented for example in a wireless network that includes at least one client.

The electronic terminals in the present disclosure such as desktop computers notebook computers smart phones personal digital assistants tablet PCs etc. may install run one or more smart operating system inside.

It can be understood by those skilled in the art that besides the processor all other components are belong to peripheral. The processor and the peripherals are coupled by many peripheral interfaces . Peripheral interfaces may be implemented based on the following standards Universal Asynchronous Receiver Transmitter UART General Purpose Input Output GPIO Serial Peripheral Interface SPI Inter Integrated Circuit I2C but not limited to the above standards. In some examples the peripheral interfaces may only include the bus while in other examples the peripheral interfaces may also include other components one or more controllers for example which may be a display controller for connecting a liquid crystal display panel or a storage controller for connecting storage. In addition these controllers may also be separated from the peripheral interface and integrated inside the processor or the corresponding peripheral.

The memory may be used to store software programs and modules such as the program instructions modules corresponding to the method and device of implementing augmented reality in the various embodiments of the present disclosure. The processor performs a variety of functions and data processing by running the software program and the module stored in the memory which implements the above method of processing virus in the electronic terminal in the various embodiments of the present disclosure. Memory may include high speed random access memory and nonvolatile memory such as one or more magnetic storage devices flash memory or other non volatile solid state memory. In some examples the memory may further include a remote configured memory compared to the processor which may be connected to the electronic terminal via the network. The network instances include but not limited to the Internet intranets local area network mobile communication network and their combinations.

The RF module is used for receiving and transmitting electromagnetic waves implementing the conversion between electromagnetic waves and electronic signals and communicating with the communication network or other devices. The RF module may include a variety of existing circuit elements which perform functions such as antennas RF transceivers digital signal processors encryption decryption chips the subscriber identity module SIM card memory etc. The RF module can communicate with a variety of networks such as the Internet intranets wireless network and communicate to other devices via wireless network. The above wireless network may include a cellular telephone network wireless local area network LAN or metropolitan area network MAN . The above wireless network can use a variety of communications standards protocols and technologies including but not limited to Global System for Mobile Communication GSM Enhanced Data GSM Environment EDGE wideband code division multiple access W CDMA Code division access CDMA time division multiple access TDMA Wireless Fidelity WiFi such as the American Institute of Electrical and Electronics Engineers Association standards IEEE 802.11a IEEE 802.11b IEEE802.11g and or IEEE 802.11n Voice over internet protocol VoIP Worldwide Interoperability for Microwave Access Wi Max other protocols used for mail instant messaging and short message as well as any other suitable communication protocol even including the protocols which are not yet been developed currently.

The Audio circuitry the speaker the audio jack the microphone together provide the audio interface between the user and the electronic device . Specifically the audio circuit receives audio data from the processor converts the audio data into an electrical signal and transmits the signal to the speaker . The speaker converts the electrical signals to sound waves which can be heard by human ears. The audio circuitry also receives electronic signals from the microphone converts electronic signals to audio data and transmits the audio data to the processor for further processing. The audio data may also be acquired from the memory or the RF module the transmission module . In addition the audio data may also be stored in the memory or transmitted by the RF module and the transmission module .

Examples of sensor include but not limited to an optical sensor an operating sensor and other sensors. Specifically the optical sensor may include an ambient light sensor and a proximity sensor. The ambient light sensor may sense ambient light and shade and then some modules executed by the processor may use the output of the ambient light sensor to automatically adjust the display output. The proximity sensor may turn off the display output when detect the electronic device near the ear. As a kind of motion sensor gravity sensor may detect the value of acceleration in each direction and the value and direction of gravity when the gravity sensor keeps still which can be used for applications to identify the phone posture such as horizontal and vertical screen switching related games magnetometer posture calibration and for vibration recognition related functions such as pedometer percussion etc. The electronic device may also include a gyroscope a barometer a hygrometer a thermometer and other sensors which is not shown for the purpose of brevity.

The input unit may be configured to receive the input character information and to generate input by keyboard mouse joystick optical or trackball signal related to user settings and function control. Specifically the input unit may include button and touch surface . The buttons for example may include character buttons for inputting characters and control buttons for triggering control function. The instances of the control buttons may include a back to the main screen button a power on off button an imaging apparatus button and so on. The touch surface may collect user operation on or near it for example a user uses a finger a stylus and any other suitable object or attachment to operate on or near the touch surface and drive the corresponding connecting device according to pre defined program. Optionally the touch surface may include a touch detection device and a touch controller. The touch detection device detects users touch position and a signal produced by the touch operation and passes the signal to the touch controller. The touch controller receives touch information from the touch detection device converts the touch information into contact coordinates sends the contact coordinates to the processor and receives and executes commands sent from the processor . In addition the touch surface may be implemented in resistive capacitive infrared surface acoustic wave and other forms. Besides the touch surface the input unit may also include other input devices. The preceding other input devices include but not limited to one or more physical keyboards trackballs mouse joysticks etc.

The display module is configured to display the information input by users the information provided to users and a variety of graphical user interfaces of the electronic device . The graphical user interfaces may consist of graphics text icons video and any combination of them. In one example the display module includes a display panel . The display panel may for example be a Liquid Crystal Display LCD panel an Organic Light Emitting Diode Display OLED panel an Electro Phoretic Display EPD panel and so on. Furthermore the touch surface may be on top of the display panel as a whole. In other embodiments the display module may also include other types of display devices such as a projection display device . Compared with the general display panel the projection display device needs to include a plurality of components for projection such as a lens group.

The power supply module is used to provide power for the processor and other components. Specifically the power supply module may include a power management system one or more power supplies such as a battery or AC a charging circuit a power failure detection circuit an inverter a power status indicator and any other components related to electricity generation management and distribution within the electronic device .

Referring to which is a flow chart of a method for implementing augmented reality provided by one embodiment of the present disclosure. The method includes the following steps.

In Step the electronic terminal obtains a real scene and according to shooting position and shooting direction of the real scene obtains POIs within a preset area and POI information corresponding to the POIs wherein the POI information comprises position information of the corresponding POI.

The real scene refers to a real time recording of the real physical world surrounding the user captured by the imaging apparatus of the electronic terminal e.g. smart phone . The real scene information may also be cached in the imaging apparatus.

The shooting position of the real scene may refer to the location information of the electronic terminal captured by a GPS module in the electronic terminal for example longitude 116 23 17 latitude 39 54 27 .

The shooting direction may refer to the viewing direction of the imaging apparatus captured by a direction sensor in the electronic terminal for example a partial north east 15 .

The preset area in the exemplary embodiments may be a square area I or a semicircular area II as shown in . The shooting position of the real scene is the center of one border AB of the square area I or the semicircular area II represented by the letter O in the . In OO represents the central axis of the square area I or the semicircular area II. The side of the square area I or the radius of the semicircular area II can be set according to actual needs for example 500 meters to 1000 meters or the like. Of course the predetermined area can also be a rectangle or a fan shaped area. The specific embodiments of the present disclosure are not limited thereto.

The electronic terminal may obtain POIs and POI information corresponding to the POIs from the server or directly obtain POIs and POI information corresponding to the POIs from application programming interface API the electronic map applications such as Baidu map soso map etc. The specific embodiments of the present disclosure are not limited thereto. Associated with updating the database the POI information may be updated in real time. The POI information may include name of the corresponding POI geographic information contact information and the relevant text images audio video and other multimedia information of the corresponding POI.

In Step the electronic terminal creates a virtual plane and maps position relationship between the POIs on the virtual plane and inserts tags of POI information to the location of the corresponding POI on the virtual plane.

In the step the electronic terminal creates a virtual plane. The virtual plane can be drawn using OpenGL. According to the location information of POIs position relationship between the POIs on the virtual plane can be obtained. Then the position relationship between the POIs is mapped on the virtual plane. Preferably the shape of the virtual plane can be obtained by reducing the preset area proportionally. Thus the position relationship mapped on the virtual plane can be closer to the actual position relationship between these POIs in the physical world.

The tags of POI information are computer identifiable marking. In this step tags of POI information to the location of the corresponding POI are inserted on the virtual plane. The specific form of the tags can be but not limited to a text prompt box or just a special shape graphic representation of computer identifiable marking. When users mouse moves over on the tags specific content of the tags will be displayed on the screen. The specific content of the tags may include POI information of the corresponding POI. In other words when users mouse moves over on the tags specific content of the tags will be displayed on the screen.

In Step the electronic terminal superimposes the virtual plane having the tags of POI information onto the real scene to form an augmented reality view.

According to the positional relationship between the POI and the shooting position and shooting direction of the real scene the electronic terminal superimposes the virtual plane having the tags of POI information onto the real scene to form an augmented reality view. Specifically the direction of the virtual plane when superimposed onto the real scene can be determined by distance between the actual geographic location of the POIs and the shooting position. For example one end having POIs relatively closing to the shooting position of the real scene can be set near the end of the augmented reality view closing to users and the other end having POIs relatively far away from the shooting position of the real scene can be set far from the end of the augmented reality view closing to users.

After being superimposing the virtual plane may be inclined at an angle so that the virtual plane is visually parallel to the horizontal plane of the real scene. That is from the users vision the virtual plane is coincident with or approximate parallel to the horizontal plane of the real scene. Therefore the tags of POI information in the augmented reality view may have more dimensional sense and more sense of hierarchy and may show the distance between the POIs and relative position relationship between the POI and uses intuitively.

In Step the electronic terminal displays the augmented reality view and adjusts the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene.

The electronic terminal displays the augmented reality view on the screen thereof to show it to users. In alternative embodiments the augmented reality view can be displayed on another screen besides the screen of the electronic terminal for example a screen of a car monitor.

When users constantly change angle of the electronic terminal the electronic terminal can obtain real time information of the real scene including the shooting position the shooting direction and the posture of the imaging apparatus in the electronic terminal to adjust the virtual plane so that the virtual plane can be always visually parallel to the horizontal plane of the real scene.

In accordance with the embodiment the electronic terminal creates a virtual plane maps position relationship between the POIs on the virtual plane inserts tags of POI information to the location of the corresponding POI on the virtual plane. Then the electronic terminal superimposes the virtual plane having the tags of POI information onto the real scene to form an augmented reality view displays the augmented reality view and adjusts the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene. Therefore the tags of POI information in the augmented reality view final presented to the users have more dimensional sense and more sense of hierarchy show the distance between the POIs and relative position relationship between the POI and uses intuitively and improves the efficiency of the application of augmented reality.

Referring to which is a flow chart of a method for implementing augmented reality provided by another embodiment of the present disclosure. The method includes the following steps 

In Step the electronic terminal obtains a real scene and according to shooting position and shooting direction of the real scene obtains POIs within a preset area and POI information corresponding to the POIs wherein the POI information includes position information of the corresponding POI.

In Step the electronic terminal creates the virtual plane and paints a grid on the virtual plane the grid having a plurality of evenly disposed points formed thereon.

Assuming that the virtual plane is in a square form the grid painted on the virtual plane can have a plurality of evenly disposed points. Preferably the plurality of points is arranged in an array for example the virtual plane may have a 50 50 grid pattern size in other words the virtual plane may have 50 50 points.

Furthermore properties of the grid can be set in advance. The property of grid can be set as displaying the grid when the augmented reality view is displayed which can enhance dimensional sense and sense of hierarchy of the virtual plane. The property of grid can also be set as hiding the grid when the augmented reality view is displayed.

In Step the electronic terminal maps the position relationship between the POIs on the corresponding points of the virtual plane by scaling transform.

According to the location information of POIs position relationship between the POIs on the virtual plane can be obtained. Then the position relationship between the POIs is mapped on the grid on the virtual plane. Thus the position relationship mapped on the virtual plane can be closer to the actual position relationship between these POIs in the physical world.

In Step the electronic terminal inserts the tag of POI information to the point corresponding to each POI.

In Step the electronic terminal superimposes the virtual plane having the tags of POI information onto the real scene to form an augmented reality view.

In Step the electronic terminal calculates the angle between the virtual plane and the horizontal plane of the reference image when the virtual plane is visually parallel to the horizontal plane of the reference image and setting the angle as a reference angle.

In Step the electronic terminal calculates a rotation matrix between the real scene and the reference image.

In Step the electronic terminal superimposes the virtual plane having the tags of POI information onto the real scene according to the rotation matrix and the reference angle.

Before creating the virtual plane the electronic terminal can create a Cartesian coordinate system firstly. For example in the Cartesian coordinate system the shooting position of real scene may be the origin point thereof the direction of North Pole of the earth may be the positive direction of Y axis thereof the East direction of the earth may be the positive direction of X axis thereof and Z axis thereof points to the sky. Assuming the selected reference image is an image of a real scene when user standing on the level ground i.e. XOY plane and taking the picture of the real scene in front of himself. The electronic terminal calculates the angle i.e. 15 between the virtual plane and the horizontal plane i.e. XOY plane of the reference image when the virtual plane is visually parallel to the horizontal plane of the reference image. The angle is set as a reference angle. That is from the users vision the feeling of watching the virtual reference is similar to 45 degree angle overlooking a horizontal plane.

Since during the process of obtaining the real scene the imaging apparatus s posture is continuously changing therefore the virtual plane can not be directly superimposed onto the real scene according to the above reference angle. A rotation matrix between the real scene and the reference image needs to be considered.

Generally the posture of the imaging apparatus includes translation pitch roll and yaw. Each imaging apparatus in three dimensional space has six degrees of freedom which includes three translation freedom degrees X Y Z. In the three dimensional space the imaging apparatus can also have three angles of rotation. The yaw refers to rotation of the imaging apparatus about the Y axis the pitch refers to rotation of the imaging apparatus about the X axis the roll refers to rotation of the imaging apparatus about the Z axis.

Different posture of the imaging apparatus lead to differences between the captured images. Using the direction sensor the electronic terminal can obtain the degree of roll yaw and pitch of the real scene captured by the imaging apparatus thereby calculating the rotation matrix between the real scene and the reference image. The rotation matrix presents space gesture relationship of the imaging apparatus at the time it captures reference image and at the time it captures each real scene. According to the rotation matrix and the reference angle the electronic terminal superimposes the virtual plane having the tags of POI information onto the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene.

In Step the electronic terminal calculates a rotation matrix between the real scene and the reference image according to real time information of the real scene and adjusts the virtual plane according to the rotation matrix between the real scene and the reference image to make the virtual plane be visually parallel to the horizontal plane of the real scene.

The electronic terminal displays the augmented reality view on the screen thereof to show it to users. Users are possible to constantly change angle of the electronic terminal. At this time the electronic terminal can calculate a rotation matrix between the real scene and the reference image according to real time information of the real scene and adjusts the virtual plane according to the rotation matrix between the real scene and the reference image to make the grid on the virtual plane look like a ground plane to users. The virtual plane displayed on the screen will change with the viewing direction of the imaging apparatus but always approximately parallel to the ground plane as shown in The tags of POI information corresponding to each POI within the preset area will emerge in the corresponding grid location so it is easy to distinguish the distance between the tags for users. When the user turns the electronic terminal the tags above the grid also rotate therewith. In addition when the some tags cover some other tags according to the user clicks on the screen the electronic terminal can show the tags in a pop up list form to the users to select a tag therefrom.

In accordance with the embodiment the electronic terminal creates a virtual plane maps position relationship between the POIs on the virtual plane inserts tags of POI information to the location of the corresponding POI on the virtual plane. Then the electronic terminal superimposes the virtual plane having the tags of POI information onto the real scene to form an augmented reality view displays the augmented reality view and adjusts the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene. Therefore the tags of POI information in the augmented reality view final presented to the users have more dimensional sense and more sense of hierarchy show the distance between the POIs and relative position relationship between the POI and uses intuitively and improves the efficiency of the application of augmented reality.

The real scene obtaining module is configured to obtain a real scene. The POI obtaining module is configured to obtain POIs within a preset area and POI information corresponding to the POIs according to shooting position and shooting direction of the real scene the POI information comprising position information of the corresponding POI. The virtual plane creating module is configured to create a virtual plane and map position relationship between the POIs on the virtual plane and insert tags of POI information to the location of the corresponding POI on the virtual plane. The superimposing module is configured to superimpose the virtual plane having the tags of POI information onto the real scene to form an augmented reality view. The displaying and adjusting module is configured to display the augmented reality view and adjust the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene.

In accordance with the embodiment the electronic terminal creates a virtual plane maps position relationship between the POIs on the virtual plane inserts tags of POI information to the location of the corresponding POI on the virtual plane. Then the electronic terminal superimposes the virtual plane having the tags of POI information onto the real scene to form an augmented reality view displays the augmented reality view and adjusts the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene. Therefore the tags of POI information in the augmented reality view final presented to the users have more dimensional sense and more sense of hierarchy show the distance between the POIs and relative position relationship between the POI and uses intuitively and improves the efficiency of the application of augmented reality.

The real scene obtaining module is configured to obtain a real scene. The POI obtaining module is configured to obtain POIs within a preset area and POI information corresponding to the POIs according to shooting position and shooting direction of the real scene the POI information comprising position information of the corresponding POI. The virtual plane creating module is configured to create a virtual plane and map position relationship between the POIs on the virtual plane and insert tags of POI information to the location of the corresponding POI on the virtual plane. The superimposing module is configured to superimpose the virtual plane having the tags of POI information onto the real scene to form an augmented reality view. The displaying and adjusting module is configured to display the augmented reality view and adjust the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene.

In this embodiment the virtual plane creating module may include a gridding unit configured to create the virtual plane and paint a grid on the virtual plane the grid having a plurality of evenly disposed points formed thereon a POI mapping unit configured to map the position relationship between the POIs on the corresponding points of the virtual plane by scaling transform and a tag inserting unit configured to insert the tag of POI information to the point corresponding to each POI.

The virtual plane creating module may further include a property setting unit configured to set properties of the grid the properties comprise displaying the grid when the augmented reality view is displayed and hiding the grid when the augmented reality view is displayed.

In this embodiment the superimposing module may includes a reference image selecting unit configured to select an image of the real scene as a reference image a reference angle calculating unit configured to calculate the angle between the virtual plane and the horizontal plane of the reference image when the virtual plane is visually parallel to the horizontal plane of the reference image and set the angle as a reference angle a rotation matrix calculating unit configured to calculate a rotation matrix between the real scene and the reference image and a superimposing unit configured to superimpose the virtual plane having the tags of POI information onto the real scene according to the rotation matrix and the reference angle.

In this embodiment the displaying and adjusting module may includes a display unit configured to calculate a rotation matrix between the real scene and the reference image according to real time information of the real scene and an adjusting unit configured to adjust the virtual plane according to the rotation matrix between the real scene and the reference image to make the virtual plane be visually parallel to the horizontal plane of the real scene.

In accordance with the embodiment the electronic terminal creates a virtual plane maps position relationship between the POIs on the virtual plane inserts tags of POI information to the location of the corresponding POI on the virtual plane. Then the electronic terminal superimposes the virtual plane having the tags of POI information onto the real scene to form an augmented reality view displays the augmented reality view and adjusts the virtual plane according to real time information of the real scene to make the virtual plane be visually parallel to the horizontal plane of the real scene. Therefore the tags of POI information in the augmented reality view final presented to the users have more dimensional sense and more sense of hierarchy show the distance between the POIs and relative position relationship between the POI and uses intuitively and improves the efficiency of the application of augmented reality.

What s more various devices provided by the embodiments of the disclosure discussed above is done for illustration purposes only and should not be taken as limitations of the general principles of the device for processing virus in electronic terminal provided by the embodiment of the disclosure. It will be understood that various combinations and changes in the form and details of the device illustrated may be made by those skilled in the art without departing from the disclosure.

Embodiments within the scope of the present disclosure may also include computer readable media for carrying or having computer executable instructions or data structures stored thereon. Such computer readable media can be any available media that can be accessed by a general purpose or special purpose computer. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices or any other medium which can be used to carry or store desired program code means in the form of computer executable instructions or data structures. When information is transferred or provided over a network or another communications connection either hardwired wireless or combination thereof to a computer the computer properly views the connection as a computer readable medium. A tangible computer readable medium expressly excludes software per se not stored on a tangible medium and a wireless air interface. Thus any such connection is properly termed a computer readable medium. Combinations of the above should also be included within the scope of the computer readable media.

Computer executable instructions include for example instructions and data which cause a general purpose computer special purpose computer or special purpose processing device to perform a certain function or group of functions. Computer executable instructions also include program modules that are executed by computers in stand alone or network environments. Generally program modules include routines programs objects components and data structures etc. that performs particular tasks or implement particular abstract data types. Computer executable instructions associated data structures and program modules represent examples of the program code means for executing steps of the methods disclosed herein. The particular sequence of such executable instructions or associated data structures represents examples of corresponding acts for implementing the functions described in such steps. Program modules may also comprise any tangible computer readable medium in connection with the various hardware computer components disclosed herein when operating to perform a particular function based on the instructions of the program contained in the medium.

The above descriptions are only preferred embodiments of the present disclosure and are not intended to limit the present disclosure. Any amendments replacement and modification made to the above embodiments under the spirit and principle of the present disclosure should be included in the scope of the present disclosure.

