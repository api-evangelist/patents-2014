---

title: Real-time dynamic tracking of bias
abstract: A bias value associated with a sensor, e.g., a time-varying, non-zero value which is output from a sensor when it is motionless, is estimated using at least two, different bias estimating techniques. A resultant combined or selected bias estimate may then be used to compensate the biased output of the sensor in, e.g., a 3D pointing device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09250716&OS=09250716&RS=09250716
owner: HILLCREST LABORATORIES, INC.
number: 09250716
owner_city: Rockville
owner_country: US
publication_date: 20140318
---
This application is a continuation of U.S. patent application Ser. No. 13 780 600 filed on Feb. 28 2013 now U.S. Pat. No. 8 683 850 which is a continuation of U.S. patent application Ser. No. 12 971 791 filed on Dec. 17 2010 now U.S. Pat. No. 8 407 022 which is a continuation of U.S. patent application Ser. No. 12 163 229 filed on Jun. 27 2008 now U.S. Pat. No. 7 860 676 which is related to and claims priority from expired U.S. Provisional Patent Application Ser. No. 60 937 596 filed on Jun. 28 2007 entitled Real Time Dynamic Tracking of Time Varying Bias in 3D Pointing Devices the disclosures of which are incorporated here by reference.

The present invention describes bias tracking techniques systems software and devices which can be used in 3D pointing devices as well as in other types of devices.

Technologies associated with the communication of information have evolved rapidly over the last several decades. Television cellular telephony the Internet and optical communication techniques to name just a few things combine to inundate consumers with available information and entertainment options. Taking television as an example the last three decades have seen the introduction of cable television service satellite television service pay per view movies and video on demand. Whereas television viewers of the 1960s could typically receive perhaps four or five over the air TV channels on their television sets today s TV watchers have the opportunity to select from hundreds thousands and potentially millions of channels of shows and information. Video on demand technology currently used primarily in hotels and the like provides the potential for in home entertainment selection from among thousands of movie titles.

The technological ability to provide so much information and content to end users provides both opportunities and challenges to system designers and service providers. One challenge is that while end users typically prefer having more choices rather than fewer this preference is counterweighted by their desire that the selection process be both fast and simple. Unfortunately the development of the systems and interfaces by which end users access media items has resulted in selection processes which are neither fast nor simple. Consider again the example of television programs. When television was in its infancy determining which program to watch was a relatively simple process primarily due to the small number of choices. One would consult a printed guide which was formatted for example as series of columns and rows which showed the correspondence between 1 nearby television channels 2 programs being transmitted on those channels and 3 date and time. The television was tuned to the desired channel by adjusting a tuner knob and the viewer watched the selected program. Later remote control devices were introduced that permitted viewers to tune the television from a distance. This addition to the user television interface created the phenomenon known as channel surfing whereby a viewer could rapidly view short segments being broadcast on a number of channels to quickly learn what programs were available at any given time.

Despite the fact that the number of channels and amount of viewable content has dramatically increased the generally available user interface control device options and frameworks for televisions has not changed much over the last 30 years. Printed guides are still the most prevalent mechanism for conveying programming information. The multiple button remote control with up and down arrows is still the most prevalent channel content selection mechanism. The reaction of those who design and implement the TV user interface to the increase in available media content has been a straightforward extension of the existing selection procedures and interface objects. Thus the number of rows in the printed guides has been increased to accommodate more channels. The number of buttons on the remote control devices has been increased to support additional functionality and content handling e.g. as shown in . However this approach has significantly increased both the time required for a viewer to review the available information and the complexity of actions required to implement a selection. Arguably the cumbersome nature of the existing interface has hampered commercial implementation of some services e.g. video on demand since consumers are resistant to new services that will add complexity to an interface that they view as already too slow and complex.

In addition to increases in bandwidth and content the user interface bottleneck problem is being exacerbated by the aggregation of technologies. Consumers are reacting positively to having the option of buying integrated systems rather than a number of segregable components. An example of this trend is the combination television VCR DVD in which three previously independent components are frequently sold today as an integrated unit. This trend is likely to continue potentially with an end result that most if not all of the communication devices currently found in the household will be packaged together as an integrated unit e.g. a television VCR DVD internet access radio stereo unit. Even those who continue to buy separate components will likely desire seamless control of and interworking between the separate components. With this increased aggregation comes the potential for more complexity in the user interface. For example when so called universal remote units were introduced e.g. to combine the functionality of TV remote units and VCR remote units the number of buttons on these universal remote units was typically more than the number of buttons on either the TV remote unit or VCR remote unit individually. This added number of buttons and functionality makes it very difficult to control anything but the simplest aspects of a TV or VCR without hunting for exactly the right button on the remote. Many times these universal remotes do not provide enough buttons to access many levels of control or features unique to certain TVs. In these cases the original device remote unit is still needed and the original hassle of handling multiple remotes remains due to user interface issues arising from the complexity of aggregation. Some remote units have addressed this problem by adding soft buttons that can be programmed with the expert commands. These soft buttons sometimes have accompanying LCD displays to indicate their action. These too have the flaw that they are difficult to use without looking away from the TV to the remote control. Yet another flaw in these remote units is the use of modes in an attempt to reduce the number of buttons. In these moded universal remote units a special button exists to select whether the remote should communicate with the TV DVD player cable set top box VCR etc. This causes many usability issues including sending commands to the wrong device forcing the user to look at the remote to make sure that it is in the right mode and it does not provide any simplification to the integration of multiple devices. The most advanced of these universal remote units provide some integration by allowing the user to program sequences of commands to multiple devices into the remote. This is such a difficult task that many users hire professional installers to program their universal remote units.

Some attempts have also been made to modernize the screen interface between end users and media systems. However these attempts typically suffer from among other drawbacks an inability to easily scale between large collections of media items and small collections of media items. For example interfaces which rely on lists of items may work well for small collections of media items but are tedious to browse for large collections of media items. Interfaces which rely on hierarchical navigation e.g. tree structures may be speedier to traverse than list interfaces for large collections of media items but are not readily adaptable to small collections of media items. Additionally users tend to lose interest in selection processes wherein the user has to move through three or more layers in a tree structure. For all of these cases current remote units make this selection processor even more tedious by forcing the user to repeatedly depress the up and down buttons to navigate the list or hierarchies. When selection skipping controls are available such as page up and page down the user usually has to look at the remote to find these special buttons or be trained to know that they even exist. Accordingly organizing frameworks techniques and systems which simplify the control and screen interface between users and media systems as well as accelerate the selection process while at the same time permitting service providers to take advantage of the increases in available bandwidth to end user equipment by facilitating the supply of a large number of media items and new services to the user have been proposed in U.S. patent application Ser. No. 10 768 432 filed on Jan. 30 2004 entitled A Control Framework with a Zoomable Graphical User Interface for Organizing Selecting and Launching Media Items now abandoned the disclosure of which is incorporated here by reference.

Of particular interest for this specification are the remote devices usable to interact with such frameworks as well as other applications and systems. As mentioned in the above incorporated application various different types of remote devices can be used with such frameworks including for example trackballs mouse type pointing devices light pens etc. However another category of remote devices which can be used with such frameworks and other applications is 3D pointing devices. The phrase 3D pointing is used in this specification to refer to the ability of an input device to move in three or more dimensions in the air in front of e.g. a display screen and the corresponding ability of the user interface to translate those motions directly into user interface commands e.g. movement of a cursor on the display screen. The transfer of data between the 3D pointing device may be performed wirelessly or via a wire connecting the 3D pointing device to another device. Thus 3D pointing differs from e.g. conventional computer mouse pointing techniques which use a surface e.g. a desk surface or mousepad as a proxy surface from which relative movement of the mouse is translated into cursor movement on the computer display screen. An example of a 3D pointing device can be found in U.S. Pat. No. 7 118 518 to Matthew G. Liberty hereafter referred to as the 518 patent the disclosure of which is incorporated here by reference.

The 518 patent describes 3D pointing devices which include for example one or two rotational sensors and an accelerometer. The rotational sensor s are used as described in more detail below to detect an angular rate at which the 3D pointing device is being rotated by a user. However the output of the rotational sensor s does not perfectly represent the angular rate at which the 3D pointing device is being rotated due to for example bias also sometimes referred to as offset in the sensor s outputs. For example when the 3D pointing device is motionless the rotational sensor s will typically have a non zero output due to their bias. If for example the 3D pointing device is used as an input to a user interface e.g. to move a cursor this will have the undesirable effect of cursor drifting across the screen when the user intends for the cursor to remain stationary. Thus in order to provide a 3D pointing device which accurately reflects the user s intended movement estimating and removing bias from sensor output is highly desirable. Moreover other devices in addition to 3D pointing devices may benefit from being able to estimate and compensate for the bias of inertial sensors. Making this process more challenging is the fact that the bias is different from sensor to sensor and even for individual sensors is time varying e.g. due to changes in temperature.

Accordingly there is still room for improvement in the area of bias estimation and handheld device design generally and 3D pointer design more specifically.

According to one exemplary embodiment a 3D pointing device includes at least one inertial sensor for detecting rotation of said 3D pointing device about at least one axis and generating a first output associated therewith an accelerometer for detecting acceleration of the 3D pointing device and generating a second output associated therewith and a processor for receiving the first and second outputs determining a bias value associated with the first output using at least a first bias estimation technique and a second bias estimation technique and compensating the first output using the bias value.

According to another exemplary embodiment a computer readable medium contains instructions which when executed on a processor perform the step of estimating a bias value associated with an inertial sensor using at least a first bias estimating technique to generate a first bias estimate and a second bias estimating technique to generate a second bias estimate.

According to another exemplary embodiment a method for estimating bias associated with an inertial sensor includes estimating the bias associated with the inertial sensor using at least a first bias estimating technique to generate a first bias estimate and a second bias estimating technique to generate a second bias estimate.

According to still another exemplary embodiment a processor includes a first function for estimating bias associated with an inertial sensor using a first bias estimation technique to generate first bias estimates and a second function for estimating the bias associated with the inertial sensor using a second bias estimation technique to generate second bias estimates.

According to yet another exemplary embodiment a pointing device includes at least one sensor for determining rotation of the pointing device about a first axis and generating a first output associated therewith and for determining rotation of the pointing device about a second axis and generating a second output associated therewith an accelerometer for determining an acceleration of the pointing device and outputting an acceleration output associated therewith a temperature sensor for detecting a temperature of the 3D pointing device and outputting a temperature output associated therewith and a processing unit for determining a bias estimate associated with the at least one rotational sensor using a a first bias estimate technique for generating first bias estimate data based upon determining whether the pointing device is stationary using the first second and third outputs b a second bias estimate technique for generating second bias estimate data based upon detection of a pitch of the pointing device using the first second and third outputs c a third bias estimate technique for generating third bias estimate data based upon slew rate filtering using the first and second outputs and d a fourth bias estimate technique for generating fourth bias estimate data based upon the temperature output and the first and second outputs.

The following detailed description of the invention refers to the accompanying drawings. The same reference numbers in different drawings identify the same or similar elements. Also the following detailed description does not limit the invention. Instead the scope of the invention is defined by the appended claims.

In order to provide some context for this discussion an exemplary aggregated media system in which the present invention can be implemented will first be described with respect to . Those skilled in the art will appreciate however that the present invention is not restricted to implementation in this type of media system and that more or fewer components can be included therein. Therein an input output I O bus connects the system components in the media system together. The I O bus represents any of a number of different of mechanisms and techniques for routing signals between the media system components. For example the I O bus may include an appropriate number of independent audio patch cables that route audio signals coaxial cables that route video signals two wire serial lines or infrared or radio frequency transceivers that route control signals optical fiber or any other routing mechanisms that route other types of signals.

In this exemplary embodiment the media system includes a television monitor a video cassette recorder VCR digital video disk DVD recorder playback device audio video tuner and compact disk player coupled to the I O bus . The VCR DVD and compact disk player may be single disk or single cassette devices or alternatively may be multiple disk or multiple cassette devices. They may be independent units or integrated together. In addition the media system includes a microphone speaker system video camera and a wireless I O control device . According to exemplary embodiments of the present invention the wireless I O control device is a 3D pointing device according to one of the exemplary embodiments described below. The wireless I O control device can communicate with the entertainment system using e.g. an IR or RF transmitter or transceiver. Alternatively the I O control device can be connected to the entertainment system via a wire.

The entertainment system also includes a system controller . According to one exemplary embodiment of the present invention the system controller operates to store and display entertainment system data available from a plurality of entertainment system data sources and to control a wide variety of features associated with each of the system components. As shown in system controller is coupled either directly or indirectly to each of the system components as necessary through I O bus . In one exemplary embodiment in addition to or in place of I O bus system controller is configured with a wireless communication transmitter or transceiver which is capable of communicating with the system components via IR signals or RF signals. Regardless of the control medium the system controller is configured to control the media components of the media system via a graphical user interface described below.

As further illustrated in media system may be configured to receive media items from various media sources and service providers. In this exemplary embodiment media system receives media input from and optionally sends information to any or all of the following sources cable broadcast satellite broadcast e.g. via a satellite dish very high frequency VHF or ultra high frequency UHF radio frequency communication of the broadcast television networks e.g. via an aerial antenna telephone network and cable modem or another source of Internet content . Those skilled in the art will appreciate that the media components and media sources illustrated and described with respect to are purely exemplary and that media system may include more or fewer of both. For example other types of inputs to the system include AM FM radio and satellite radio.

More details regarding this exemplary entertainment system and frameworks associated therewith can be found in the above incorporated by reference U.S. patent application A Control Framework with a Zoomable Graphical User Interface for Organizing Selecting and Launching Media Items . Alternatively remote devices in accordance with the present invention can be used in conjunction with other systems for example computer systems including e.g. a display a processor and a memory system or with various other systems and applications.

As mentioned in the Background section remote devices which operate as 3D pointers are of particular interest for the present specification. Such devices enable the translation of movement e.g. gestures into commands to a user interface. An exemplary 3D pointing device is depicted in . Therein user movement of the 3D pointing can be defined for example in terms of a combination of x axis attitude roll y axis elevation pitch and or z axis heading yaw motion of the 3D pointing device . In addition some exemplary embodiments of the present invention can also measure linear movement of the 3D pointing device along the x y and z axes to generate cursor movement or other user interface commands. In the exemplary embodiment of the 3D pointing device includes two buttons and as well as a scroll wheel although other exemplary embodiments will include other physical configurations. According to exemplary embodiments of the present invention it is anticipated that 3D pointing devices will be held by a user in front of a display and that motion of the 3D pointing device will be translated by the 3D pointing device into output which is usable to interact with the information displayed on display e.g. to move the cursor on the display . For example rotation of the 3D pointing device about the y axis can be sensed by the 3D pointing device and translated into an output usable by the system to move cursor along the yaxis of the display . Likewise rotation of the 3D pointing device about the z axis can be sensed by the 3D pointing device and translated into an output usable by the system to move cursor along the xaxis of the display . It will be appreciated that the output of 3D pointing device can be used to interact with the display in a number of ways other than or in addition to cursor movement for example it can control cursor fading volume or media transport play pause fast forward and rewind . Input commands may include operations in addition to cursor movement for example a zoom in or zoom out on a particular region of a display. A cursor may or may not be visible. Similarly rotation of the 3D pointing device sensed about the x axis of 3D pointing device can be used in addition to or as an alternative to y axis and or z axis rotation to provide input to a user interface.

According to one purely illustrative exemplary embodiment of the present invention two rotational sensors and and one accelerometer can be employed as sensors in 3D pointing device as shown in . Although this exemplary embodiment employs inertial sensors it will be appreciated that the present invention is not so limited and examples of other types of sensors which can be used in conjunction with other exemplary embodiments are provided below. The rotational sensors and can for example be implemented using ADXRS150 or ADXRS401 sensors made by Analog Devices. It will be appreciated by those skilled in the art that other types of rotational sensors can be employed as rotational sensors and and that the ADXRS150 and ADXRS401 are purely used as an illustrative example. Unlike traditional gyroscopes these rotational sensors use MEMS technology to provide a resonating mass which is attached to a frame so that it can resonate only along one direction. The resonating mass is displaced when the body to which the sensor is affixed is rotated around the sensor s sensing axis. This displacement can be measured using the Coriolis acceleration effect to determine an angular velocity associated with rotation along the sensing axis. If the rotational sensors and have a single sensing axis as for example the ADXRS150s then they can be mounted in the 3D pointing device such that their sensing axes are aligned with the rotations to be measured. For this exemplary embodiment of the present invention this means that rotational sensor is mounted such that its sensing axis is parallel to the y axis and that rotational sensor is mounted such that its sensing axis is parallel to the z axis as shown in . It will be appreciated that different sensor packages may be available which could lead to other exemplary implementations. For example the two 1 D rotational sensors and could be replaced by a single 2D rotational sensor package which provides outputs of rotational motion along e.g. the y and z axes. One exemplary 2 D rotational sensor is the Invensense IDG 300 although it will be appreciated that other sensors sensor packages may also be used. The rotational sensors can be 1 D 2 D or 3 D sensors. The accelerometer can for example be a 3 axis linear accelerometer although a 2 axis linear accelerometer could be used by assuming that the device is measuring gravity and mathematically computing the remaining 3value. Additionally the accelerometer s and rotational sensor s could be packaged together into a single sensor package. Other variations of sensors and sensor packages may also be used in conjunction with these exemplary embodiments.

The exemplary embodiments are not limited to the industrial design illustrated in but can instead be deployed in any industrial form factor another example of which is illustrated as . In the exemplary embodiment of the 3D pointing device includes a ring shaped housing two buttons and as well as a scroll wheel and grip although other exemplary embodiments may include other physical configurations. The region which includes the two buttons and and scroll wheel is referred to herein as the control area which is disposed on an outer portion of the ring shaped housing . More details regarding this exemplary embodiment can be found in U.S. patent application Ser. No. 11 480 662 entitled 3D Pointing Devices now abandoned filed on Jul. 3 2006 the disclosure of which is incorporated here by reference. Such devices have numerous applications including for example usage in the so called 10 foot interface between a sofa and a television in the typical living room as shown in . Therein as the 3D pointing device moves between different positions that movement is detected by one or more sensors within 3D pointing device and transmitted to the television or associated system component e.g. a set top box not shown . Movement of the 3D pointing device can for example be translated into movement of a cursor displayed on the television and which is used to interact with a user interface. Details of an exemplary user interface with which the user can interact via 3D pointing device can be found for example in the above incorporated U.S. patent application Ser. No. 10 768 432 now abandoned as well as U.S. patent application Ser. No. 11 437 215 entitled Global Navigation Objects in User Interfaces filed on May 19 2006 now abandoned the disclosure of which is incorporated here by reference.

One challenge faced in implementing exemplary 3D pointing devices in accordance with these exemplary embodiments is to employ components e.g. rotational sensors and which are not too costly while at the same time providing a high degree of correlation between movement of the 3D pointing device a user s expectation regarding how the user interface will react to that particular movement of the 3D pointing device and actual user interface performance in response to that movement. For example if the 3D pointing device is not moving the user will likely expect that the cursor ought not to be drifting across the screen. Likewise if the user rotates the 3D pointing device purely around the y axis she or he would likely not expect to see the resulting cursor movement on display contain any significant x axis component. To achieve these and other aspects of exemplary embodiments of the present invention various measurements and calculations are performed e.g. by the handheld device which are used to adjust the outputs of one or more of the sensors and and or as part of the input used by a processor to determine an appropriate output for the user interface based on the outputs of the sensors and . These measurements and calculations are used to compensate for factors which fall broadly into two categories 1 factors which are intrinsic to the 3D pointing device e.g. errors associated with the particular sensors and used in the device or the way in which the sensors are mounted in the device and 2 factors which are not intrinsic to the 3D pointing device but are instead associated with the manner in which a user is using the 3D pointing device e.g. linear acceleration tilt and tremor. Some exemplary techniques for handling these effects are described in the above incorporated by reference 518 patent. However the following exemplary embodiments provide additional techniques for handling the bias or offset error contributions to sensed motion which were described in the Background section above.

Referring now to the sensors and within the 3D pointing device provide a relatively noisy and distorted output that represents in this exemplary embodiment both angular rate and linear acceleration for the device. It will be appreciated that the present invention is not limited to sensor combinations including two rotational sensors and an accelerometer but can include other types of e.g. inertial sensors as described below. An overview of the time varying bias tracking and compensation scheme shown in will first be provided followed by a more detailed discussion of the functional blocks illustrated therein. The optional sensor interpretation block uses pre calculated bias values to improve the distorted sensor output while also converting the sensor output into standardized units. If sensor interpretation block is removed or instead disposed further downstream in the processing chain raw sensor outputs can alternatively be processed to estimate and remove bias.

The temperature sensor s information is processed by the temperature filter to remove noise from the temperature signal. In this exemplary embodiment four different techniques are used to estimate the bias associated with the output of the rotational sensors and the resulting bias estimates are combined or selected to form a composite value. More specifically as seen in the exemplary embodiment of the interpreted accelerometer and angular rate signals are processed by a stationary detection component an accelerometer assisted bias estimation AABE function a slew rate filter and a temperature assisted bias estimator TABE . The output from each of the four blocks is provided to an estimate combiner which produces a single estimate for the angular rate bias which estimate is updated as the 3D pointing device operates. Although this exemplary embodiment provides for a combination of four different bias estimates it will be appreciated that other exemplary implementations could combine any subset of the four bias estimates to generate a composite bias estimate. A table illustrating the various permutations is provided below. However in this exemplary implementation each of the four different techniques has certain strengths and weaknesses such that using all four in a blended approach provides a good estimate of the time varying bias of the sensors.

In the exemplary embodiment of the sensors and provide uncalibrated output data that corresponds to movement of the 3D pointing device i.e. linear acceleration and angular rate and temperature of the 3D pointing device. The output values may be corrupted by noise bias cross coupling and other errors. Accordingly the optional sensor interpretation block converts the uncalibrated data to standardized SI units e.g. m secfor the accelerometer data and rads sec for the rotational sensor s using pre calculated values. Furthermore the angular rate data output from the rotational sensor s is decoupled from the calibrated temperature data using pre calibrated values. A calibrated error residual will however remain since the sensor output values are environmentally dependent. More information regarding exemplary implementations of techniques which can be used in the sensor interpretation block can be found in the above incorporated by reference 518 patent.

The measured or detected temperature values which are output from the temperature sensor and which reflect a temperature at which the accelerometer and or rotational sensors are currently operating contain significant noise that would negatively affect downstream processing. To improve performance of bias estimation according to these exemplary embodiments a temperature filter is provided which improves the temperature estimate by removing noise with minimal latency. According to one purely illustrative exemplary embodiment the noise in the temperature estimates can be pre calculated statistically and then filtered or reduced by the temperature filter using single exponential smoothing SES or double exponential smoothing DES .

Stationary detection block determines when the 3D pointing device is not moving. According to this exemplary embodiment the stationary detection block analyzes the peak to peak values over a block of data from both the accelerometer and angular rate sensor s . When the peak to peak value is less than a predetermined threshold the device is determined to be stationary. The threshold allows the device to differentiate between the quasi stationary state where a user is holding the 3D pointing device in his or her hand but trying not to move it and the true stationary state when it is not being held by a user and is e.g. resting on a desk or table. When the device is held human tremor moves the 3D pointing device slightly and forces the detected peak to peak value above the threshold. An optional low pass filter can be provided upstream of the stationary detection function to minimize the 50 60 Hz electric power line interference while preserving the movement data associated with human tremor. More information relating to exemplary stationary detection techniques can be found in the incorporated by reference 518 patent. When the device is stationary any non zero outputs of the sensors are accurate estimates of the bias associated with the sensors. However this technique cannot be used when the device is moving.

Accordingly a second bias estimate is generated by an accelerometer assisted bias estimator AABE according to this exemplary embodiment. The AABE uses Earth s gravity to determine the angular rate bias in up to two of the three angular directions. An optional finite impulse response FIR low pass filter is provided upstream of AABE to eliminate sensor output data associated with hand tremor sensed by the sensors and . The same filter can be used on both the accelerometer data and angular rate data to keep the sensor data synchronized. In order to better understand the technique employed by the AABE to estimate bias error consider first that the 3D pointing device s body coordinate system can be defined as shown above in . However a user of the device s coordinate system xyz is defined in terms of the Earth s local tangent plane and north. That is from the user s perspective the positive x axis points north in the tangent plane the positive y axis points east and the positive z axis is directed geocentrically downward .

According to Euler s Theorem any two independent ortho normal coordinate frames can be related by a sequence of rotations not more than three about coordinate axes where no two successive rotations may be about the same axis. A rotation sequence can therefore be used to transform movement data from the body frame of reference in which the sensors inherently detect movement to the user s frame of reference. This provides among other things and purely as an example the capability to use the sensed movement data to more faithfully reproduce the user s intended movement of e.g. a cursor which is controlled based on movement of the 3D pointing device.

A conceptual illustration of an exemplary rotation sequence for performing this transformation is shown as . For this sequence the first rotation is about the z axis through an angle the second rotation is about the new y axis through an angle and the third rotation is taken about the newest x axis through an angle . More information relating to transforming data from a body frame of reference to a user s frame of reference may also be found in the 518 patent. However returning to the usage of this information to estimate bias by AABE the increment of the elevation angle measured from the angular rate sensor and accelerometer should be identical if their outputs were error free. Thus an estimate of the bias error introduced into the measurement data output from the sensors can be determined by calculating a difference between a change of elevation angle determined using the data output from the rotational sensors and a change of elevation angle determined using data output from the accelerometer .

Consider first that the existing biases in the measurements of the rotational sensor s can be represented as follows 

To determine its bias estimate the AABE calculates the change or increment amounts of the elevation angle in a duration varying time window from both filtered accelerometer data and filtered angular rate data. Then the AABE compares these values e.g. by taking a difference between them to establish its dynamic bias estimate. The relationship between the angular velocity vector in the body frame of reference and the rate of change of the Euler angles defined above dot over dot over dot over is determined by resolving the Euler rates into the body coordinate frame as shown below.

The total increment of elevation angle from the data generated by the accelerometer is calculated by evaluating the difference between the start elevation angle at the first sample of the given time window and the end elevation angle at the last sample of the given time window as expressed for example below.

The durations of the time windows used by the AABE can be determined based upon both 1 whether the measurement noise of the current accelerometer sample is below a predetermined threshold and 2 whether the averaged measurement noise of the current calculated pitch angular rate bias over the window is below the threshold. A minimum time duration can be enforced as the lower bound on window duration to ensure measurement validity quality. According to exemplary embodiments a new AABE window is not initialized until a sufficiently good accelerometer sample in the sense of noise and distortion arrives. The distortion and or noise are calculated using error propagation based on the sensor s noise level and modeling of human s tremor effect. The AABE time window can also be reset for example when one of the following conditions occurs a maximum pitch of the device is exceeded the filter has not yet initialized there is too much measurement noise there are too many missing samples too much change in the roll angle in the body frame of reference has occurred over the window or the time window has grown too large.

According to exemplary embodiments there are three different modes in which the AABE can provide bias estimates to the combiner . The first is to provide the bias estimates described above as individual data points which will converge over time. This first mode is referred to herein as 1 D Pitch mode . However under certain circumstances AABE can provide estimates in one of two other modes which may provide very quick and accurate bias estimates e.g. at power on of the device by using a line intersection technique to attempt to more rapidly converge on the best bias estimate. These two additional modes are referred to herein as 2D line intersection mode and 2D pseudo line intersection mode .

The 2D line intersection mode operates using two 1D Pitch mode AABE bias estimates together i.e. a first estimate at time t and a second estimate at time t 1 to obtain a better estimate. For example assume that a user rolls the device i.e. rotates it about the x axis between time t and time t 1. Then the first 1D Pitch mode bias estimate provides an estimate of the bias in one direction and the second 1D Pitch mode bias estimate provides an estimate of the bias in another direction. The intersection of these two lines provides an accurate and quick estimate of the set of

The 2D pseudo line intersection mode can according to this exemplary embodiment be considered as a special case of the 2D line intersection mode. In certain circumstances e.g. when the 3D pointing device is not moving or is moving very slowly AABE can map the averaged values of angular rate sensor s data over the current time window into the bias of the yaw angular rate defined in user frame. This mapping can be performed for example as follows 

The decision regarding in which of these three modes the AABE should operate at any given time can according to one exemplary embodiment be made as follows. This flow is also described below with respect to . If three exemplary criteria are met then AABE can operate in 2D pseudo line intersection mode. These three exemplary criteria are 1 if the measurement error variance corresponding to the current estimated bias of the pitch angular rate is smaller than a predetermined threshold 2 if the time window size BlockSize is short enough and 3 if the difference of the measured body frame roll angles 0 in the current time window and in the previous time window is small enough. If these three criteria are not all met then the AABE can operate in the 2D line intersection mode if condition 3 is not met and if another condition 4 is met. Condition 4 requires that the time gap between the last time window and current time window is shorter than a predetermined amount of time.

If neither of these sets of conditions is met then AABE operates in 1D Pitch mode. Additionally if either of the conditions 5 and 6 is met then AABE will also operate in 1D Pitch mode. Conditions 5 and 6 according to this exemplary embodiment are 5 if the difference between a newest estimate of bias using the 2D pseudo line intersection mode and the previous best estimate of estimate combiner is greater than k sqrt P where k is a pre defined constant factor P is the final bias estimate error covariance and 6 if the slope estimate in the TABE is available and used in estimate combiner when the AABE is not operating in 2D line intersection mode. All of the above conditions or criteria used to determine in which mode the AABE shall operate can be compared with pre calculated thresholds some of which may be constant and some of which may decay over time using e.g. a single exponential decay model or a double exponential decay model when the nature of the change rate of the bias is slowing down over time. It should be further appreciated that these algorithms can be run on each axis independently and potentially on each axis simultaneously e.g. assuming that any axis is the pitch axis instead of just the x axis as is described in some of these exemplary embodiments.

The AABE provides accurate and fast bias estimates for the pitch direction but does not directly measure the yaw bias as mentioned above. It should be further appreciated that AABE can be extended to also measure the roll bias and that AABE algorithm can be run on each axis roll or pitch independently and on both axes roll and pitch simultaneously. Accordingly the slew rate filter provides a third technique for estimating bias according to this exemplary embodiment. This technique which can be independent of the other bias estimation techniques described herein operates on the assumption that the rate of change of the amount of bias introduced by the rotational sensor will vary within a predetermined range which range is a function of the temperature of the device. That is the rate of change in the bias error is bounded by the rate of change in temperature of the device. The angular rate sensor data is first optionally processed by a low pass filter before flowing into the slew rate filter . The operation of the slew rate filter can be defined by the following equation where x is the input y is the output and B is the slew rate filter threshold. For this exemplary embodiment x is therefore the angular rate output from the low pass filter minus the current angular rate bias estimate fed back from the estimate combiner . The output y plus the current angular rate bias estimate is the next estimate for the angular rate bias to be output from the slew rate filter to the combiner .

The threshold value B used by the slew rate filter is periodically adaptively calculated based on the real time temperature change rate and the bias temperature slope estimate. The upper bound and the lower bound are enforced on such threshold. In this exemplary embodiment B is calculated as follows 

The fourth technique used to estimate bias according to this exemplary embodiment is performed by the temperature assisted bias estimation function TABE . This technique correlates the change in temperature of the device to the change of the bias introduced by the rotational sensor s . According to this exemplary embodiment the TABE uses the model Bias slope intercept where T in units of degrees Centigrade is the raw temperature measurement after decoupling both z and y channels of the angular rate data using the best current estimate of bias available but before temperature smoothing slope t is the change of bias per unit temperature as a function of time intercept t is the bias at a temperature of zero as a function of time and t is the time.

According to this exemplary embodiment a recursive least squared RLS method and algorithm is used to adaptively learn and track the slope t and intercept t an example of which RLS algorithm is illustrated in . The adaptive filtering part of this exemplary RLS algorithm is shown as adaptive filtering block . The reference input to the adaptive filtering are measurements from the temperature sensor also shown as temperature sensor in complemented with a unit constant of 1 the vector of T 1 shown as the input to adaptive filter block in . This vector represents a sensed temperature after interpretation e.g. in units of degrees Celsius as well as other factors e.g. pressure and humidity all of which are collectively identified as noise source related to temperature which may impact the bias and which are represented in this example by the unit constant of 1. The measured temperature Tof sensor is first interpreted in block also shown as part of sensor interpret block in and yields the estimate of the true temperature T. This true temperature is at least one cause of angular rate sensor s bias which is linearly transformed matrix multiplied and coupled into bias ZRO of angular rate sensor s using the above equation at block . The other possible root causes of angular rate sensor s bias such as pressure and humidity etc. are coupled into the ZRO in the forms of slope t and intercept t . The ZRO value is input to summer and added to the desired signal w source signal which is the angular rate data in units of rad s the summed value representing angular rate measurement from angular rate sensor s and also serving as the primary input to the RLS adaptive filtering block . The adaptive filtering block can for example operate as described below.

This exemplary implementation operates on the principle that minimizing the energy of the system output is equivalent to minimizing the difference between the ZRO and the output y of adaptive filter which can be shown as follows 

In this exemplary implementation the angular rate output from the sensor s may couple into the temperature signals from the temperature sensor which can cause difficulties for the RLS algorithm. This coupling mechanism can be minimized by providing a fading effect over the first several samples of the RLS algorithm. The fading effect can be calculated based on the magnitude of the rotation motion using the best knowledge about angular rate bias up to that point in time. The adaptive learned slope t is further evaluated by comparing its dynamic range peak to peak value in a time window of predefined length with a certain threshold if the adaptive learned slope is stable enough this estimated slope and its associated estimated error variance will be sent to the estimate combiner and the slew rate filter. The associated estimated error variance can be calculated using the standard deviation over the time window or using the peak to peak value over the time window itself. A lower bound on the error can be provided due to the nature of the hysteresis of the bias shift. It should be further appreciated that both slew rate filter and TABE algorithm can be run on each axis independently and or on both axes simultaneously.

The outputs of the four bias estimation functions as well as the filtered temperature data are provided to the estimate combiner which uses that information to generate a current bias estimate. The combiner can be implemented for example using a Kalman filter infrastructure which synthesizes all of the measurements available from the stationary detector slew rate filter the accelerometer assisted estimator and the temperature assisted estimator. The process model used in this exemplary embodiment is random walk with the worst dynamics assumption if the slope estimation is not available from TABE . The process model is changed to a linear temperature based model if the slope estimation is available from TABE . The state of the Kalman filter used as an estimate combiner according to this exemplary embodiment can be expressed as 

The process model of the Kalman filter used as estimate combiner according to this exemplary embodiment can be expressed as 

The process error covariance is calculated as slope slope where represents the matrix product Ris a 2 2 slope estimate error covariance matrix accounting for both y axis and z axis components which are also provided by TABE if such data is available T is the temperature change between a current filtered temperature estimate FiltT t and a last filtered temperature estimate FiltT t i.e. corresponding to the last time that the Kalman filter was executed Ris the estimate error variance of the estimate of T and k is a 2 2 correlation coefficients matrix. When the slope estimation is not available from the TABE the slope value used in this calculation is set to 0 0 and the Rvalue is set to be the worst dynamic range bounded by the value across all of the sensor set.

The predicted estimate error covariance associated with the Kalman filter according to this exemplary embodiment can be expressed as where Pis the predicted bias estimate error covariance at time tgiven the measurements up to time t and Pis the final bias estimate error covariance at time t.

The measurement model associated with the Kalman filter can be expressed as right arrow over right arrow over where right arrow over M t is the measurement set in terms of column vector at time step t right arrow over U is the measurement error at time twith mean of zero and covariance of R H t is the transfer matrix at time t.

Thus the updated final bias estimate output by the estimate combiner Kalman filter and its error covariance according to this exemplary embodiment are given as where Xis the final bias estimate at time tgiven the measurement up to time t Xis the predicted bias estimate at time tgiven the measurement up to time t and Pis the final bias estimate error covariance at time tgiven the measurement up to time t.

The individual bias estimate models described above which provide input to the Kalman filter can be serviced in priority order when available. For example when only one measurement set is available then the method reduces to a single constraint at a time. If on the other hand more than one measurement set is available at a particular time step according to one exemplary embodiment only one of the measurement sets will be executed by the Kalman filter based on for example the following priority order stationary detector AABE and slew rate filter . This aspect and other features of bias estimation according to these exemplary embodiments can also be seen in the process flow chart of .

Therein state initialization of the Kalman filter occurs at block . The rest of the flow illustrates the process of entering an update or prediction phase for the Kalman filter for a particular time step. Since the TABE is according to this exemplary embodiment the highest ranked of the bias estimators i.e. the process model is changed to a linear temperature based model if the slope estimation is available from TABE it is first determined at block whether slope estimate data is currently available from TABE . If so then the linear temperature based model is used and the slope and its associated error covariance are updated at block . If not the flow moves to block wherein it is determined whether a stationary detection indication is available. If so then the Kalman filter update process described above is called at block . The Kalman filter then updates its state based on the indication that the 3D pointing device is stationary and the output of the rotational sensor s are indicative of the current bias which they are introducing. The flow then proceeds to generate an output bias estimate at block .

Otherwise if the determination at block is No i.e. the device is not stationary then the flow proceeds to block . Therein it is determined whether data is available to generate an output from AABE as described above. If the answer is Yes then the flow proceeds to block wherein the process begins to determine which of the three afore described modes of operation should be used by the AABE to present bias estimation data to the Kalman filter. For example if conditions 1 3 described above are met then according to this exemplary embodiment the possibility exists to use the 2D pseudo line intersection mode to provide bias estimation data to the Kalman filter and the flow proceeds to block . Block determines whether any of the negative conditions 5 and 6 described above are present i.e. whether 5 the difference between a newest estimate of bias using the 2D pseudo line intersection mode and the previous best estimate of block is greater than k sqrt P where k is a pre defined constant factor and P is the final bias estimate error covariance or 6 the slope estimate in the TABE is available and used in the Kalman filter. If either of these negative conditions is present then the flow follows the Yes path and moves to block and the AABE provides bias estimation data using the 1D Pitch mode described above to be used in updating the state of the Kalman filter at block . Otherwise the flow follows the No path out of block to block where the bias estimation data is then calculated using the 2D pseudo line intersection mode and presented to the Kalman filter update block .

Returning to block if any of conditions 1 3 are not met then the flow follows the No path to block . At this block it is determined whether condition 3 described above is not met and whether condition 4 is met thereby permitting the AABE to provide bias estimation data to the Kalman filter update block using the 2D line intersection mode. This is shown by block . If these criteria are not met then the flow follows the No path to block and the processing using 1D Pitch mode continues as described above.

Returning to block if a measurement is not available from the AABE then the flow follows the No path to block . Therein it is determined whether a measurement is available from the slew rate filter . If so then bias estimation data from the slew rate filter is presented to the Kalman filter update call to update the state of the Kalman filter based on that data via the Yes path. Otherwise if none of the four bias estimation techniques described above have measurements available during a particular timestep iteration then the flow proceeds to block wherein a prediction phase is performed for the Kalman filter rather than an update . The prediction phase uses the state estimate from the previous timestep to produce an estimate of the state at the current timestep i.e. but without measurement data as in the update call . This estimated state is then used to drive the bias estimate output at block i.e. either after the prediction phase or the update phase of the Kalman filter. The updated state and associated error covariance are then used in the next timestep as indicated by block . According to exemplary embodiments the output from block can be used in several ways. For example as shown in the output can be fed back with e.g. one sample delay at blocks and to the TABE and sensor interpretation block slew rate filter respectively to improve their estimates during the next timestep.

Moreover the estimated bias of the rotational sensor s as well as its associated temperature and the estimated slopes if they are available from the TABE can be stored in flash memory described below with respect to on the embedded hardware as dynamic calibration data for preparation of a next time system power cycle use. For example the next time the 3D pointer system is powered on and if such information is available from flash memory this information will be fed back to the estimate combiner as the initial estimate of the bias to the temperature filter for better angular rate decoupling and to the slew rate filter as the initial current bias estimate. This information can also help to reduce the dynamic range the system needs to handle by better refining Q in the Kalman filter.

Having provided a description of bias estimation in exemplary 3D pointing devices according to the afore described exemplary embodiments illustrates an exemplary hardware architecture associated with such 3D pointing devices. Therein a processor communicates with other elements of the 3D pointing device including a flash memory scroll wheel JTAG LEDs switch matrix IR photodetector rotational sensor s accelerometer and transceiver . The flash memory device can be used by processor to store various programs and or data for use in operating the 3D pointing device e.g. bias estimates as described above. The scroll wheel is an optional input component which enables a user to provide input to the interface by rotating the scroll wheel clockwise or counterclockwise. JTAG provides the programming and debugging interface to the processor. LEDs provide visual feedback to a user for example when a button is pressed. Switch matrix receives inputs e.g. indications that a button on the 3D pointing device has been depressed or released that are then passed on to processor . The optional IR photodetector can be provided to enable the exemplary free space pointing device to learn IR codes from other remote controls. Rotational sensors provide readings to processor regarding e.g. the y axis and z axis rotation angular rate of the 3D pointing device as described above. Accelerometer provides readings to processor regarding the linear acceleration of the 3D pointing device which can be used e.g. to perform tilt compensation and to compensate for errors which linear acceleration introduces into the rotational readings generated by rotational sensor s . Transceiver is used to communicate information to and from 3D pointing device e.g. to the system controller or to a processor associated with a computer. The transceiver can be a wireless transceiver e.g. operating in accordance with the Bluetooth standards for short range wireless communication or an infrared transceiver. Alternatively 3D pointing device according to these exemplary embodiments can communicate with systems via a wireline connection.

The individual bias estimators described above can be used and applied independently of one another or in different combinations. As mentioned above although the afore described exemplary embodiments combine all four of the outputs to yield an improved estimate for a particular yet exemplary implementation those skilled in the art will recognize that each produces an independent estimate and can be used with or without the others. More specifically and for completeness exemplary embodiments contemplate each combination of rate estimators listed in the table below. This list is not however intended to be exhaustive.

Additionally although the foregoing exemplary embodiments describe a specific yet purely exemplary Kalman filter operating as an estimate combiner it will be appreciated that other mechanisms can be used to combine or select the bias estimates output from the plurality of bias estimators in any given exemplary embodiment if more than one bias estimator is employed . Moreover the exemplary processing described herein may be performed in whole or in part either within the 3D pointing device itself or outside of the 3D pointing device. For example raw sensor data can be transmitted to a system processor e.g. within a set top box or a computer wherein it can then be processed to output a bias estimate and use that bias estimate as part of the larger processing scheme to determine motion of the 3D pointing device and use such information e.g. to update cursor position associated with a cursor displayed on a user interface screen. The bias estimate described herein can for example be subtracted from an initial measurement of angular rate by the rotational sensor s e.g. after a static calibration as a function of temperature has been performed.

Systems and methods for processing data according to exemplary embodiments of the present invention can be performed by one or more processors executing sequences of instructions contained in a memory device. Such instructions may be read into the memory device from other computer readable mediums such as secondary data storage device s . Execution of the sequences of instructions contained in the memory device causes the processor to operate for example as described above. In alternative embodiments hard wire circuitry may be used in place of or in combination with software instructions to implement the present invention. Such software may run on a processor which is housed within the device e.g. a 3D pointing device or other device which contains the sensors or the software may run on a processor or computer housed within another device e.g. a system controller a game console a personal computer etc. which is in communication with the device containing the sensors. In such a case data may be transferred via wireline or wirelessly between the device containing the sensors and the device containing the processor which runs the software which performs the bias estimation and compensation as described above. According to other exemplary embodiments some of the processing described above with respect to bias estimation may be performed in the device containing the sensors while the remainder of the processing is performed in a second device after receipt of the partially processed data from the device containing the sensors.

Although the foregoing exemplary embodiments relate to sensing packages including one or more rotational sensors and an accelerometer bias estimation techniques according to these exemplary embodiments are not limited to only these types of sensors. Instead bias estimation techniques as described herein can be applied to devices which include for example only accelerometer s optical and inertial sensors e.g. a rotational sensor a gyroscope or an accelerometer a magnetometer and an inertial sensor e.g. a rotational sensor a gyroscope or an accelerometer a magnetometer and an optical sensor or other sensor combinations. Additionally although exemplary embodiments described herein relate to bias estimation in the context of 3D pointing devices and applications such techniques are not so limited and may be employed in methods and devices associated with other applications e.g. medical applications gaming cameras military applications etc.

The above described exemplary embodiments are intended to be illustrative in all respects rather than restrictive of the present invention. Thus the present invention is capable of many variations in detailed implementation that can be derived from the description contained herein by a person skilled in the art. For example although the foregoing exemplary embodiments describe among other things the use of inertial sensors to detect movement of a device other types of sensors e.g. ultrasound magnetic or optical can be used instead of or in addition to inertial sensors in conjunction with the afore described signal processing. All such variations and modifications are considered to be within the scope and spirit of the present invention as defined by the following claims. No element act or instruction used in the description of the present application should be construed as critical or essential to the invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items.

