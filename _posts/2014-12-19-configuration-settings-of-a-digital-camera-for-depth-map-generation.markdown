---

title: Configuration settings of a digital camera for depth map generation
abstract: Systems and methods are disclosed for identifying image capture instructions for capturing images that may be used to generate quality depth maps. In some examples, the image capture instructions are generated by predictively determining in a scene-independent manner configuration settings to be used by a camera to capture a minimal quantity of images for generating the quality depth map. The image capture instructions may thus indicate a quantity of images to be captured and the aperture and focus settings to be used when capturing the images. The image capture instructions may be determined based in part on a distance estimate, camera calibration information and a predetermined range of optimal blur radii. The range of optimal blur radii ensures that there will be sufficient depth information for generating a depth map of a particular quality from the yet-to-be-captured images.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09307222&OS=09307222&RS=09307222
owner: Adobe Systems Incorporated
number: 09307222
owner_city: San Jose
owner_country: US
publication_date: 20141219
---
This application is related to co pending U.S. application Ser. No. 14 552 332 filed on Nov. 24 2014 and U.S. application Ser. No. 14 576 936 filed on Dec. 19 2014 the contents of each is hereby incorporated in their entirety by reference.

This disclosure relates generally to methods and systems for predictively determining configuration settings for a digital camera and a quantity of images to be captured by the digital camera using those setting for the purpose of estimating depth of a scene represented by the quantity of images.

A portion of the disclosure of this patent document contains material that is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyright rights whatsoever.

Digital cameras including digital single lens reflex DSLR cameras and digital cameras integrated into mobile devices often have sophisticated hardware and software that enables a user to capture digital images using a combination of different user defined and camera defined configuration settings. A digital image provides a digital representation of a particular scene. A digital image may subsequently be processed by itself or in combination with other images to derive additional information from the image. For example one or more images may be processed to estimate the depths of the objects depicted within the scene i.e. the distance of each object from a location from which the picture was taken. The depth estimates for each object in a scene or possibly each pixel within an image are included in a file referred to as a depth map. Among other things depth maps may be used to improve existing image editing techniques e.g. cutting hole filling copy to layers of an image etc. 

Depth from defocus is a conventional technique used to estimate depth of a scene using out of focus blur i.e. to generate depth maps . Depth estimation using such techniques is possible because imaged scene locations will have different amounts of out of focus blur i.e. depth information based on the configuration settings of the camera e.g. aperture setting and focus setting used to take the images. Estimating depth therefore involves estimating the amount of depth information at the different scene locations whether the depth information is derived from one image or from multiple images. Conventionally the accuracy of such estimates depends on the number of images used and the amount of depth information. This is because the greater the number of images that are inputted the greater the amount of depth information that can be compared for any one position e.g. pixel in the scene.

A conventional depth from defocus technique compares blurry patches in a single image with certain assumptions about the scene derived from prior image models. While these assumptions may hold true for certain scenes they fail when the underlying image does not have sufficient depth information to fit the assumptions. Another conventional technique estimates depth by processing multiple images captured as a focal stack i.e. same aperture different focus and fitting those images to an image model. The number of images typically corresponds to the number of available focus settings for the digital camera. This can lead to inefficiencies because often more images are taken than may otherwise be required to provide sufficient depth information. In addition this technique requires that the images be fitted to an image model which can lead to imprecise depth estimates. Yet another conventional technique estimates depth by processing multiple images captured as an aperture stack i.e. same focus different aperture . Similar to the focal stack technique this conventional technique requires that many images be taken which can be inefficient when fewer images would provide sufficient depth information. And even though this aperture stack technique often captures more images than may otherwise be required because the camera configuration settings are not predetermined to preserve optimal depth information the resulting images often have areas where the depth information is insufficient. Thus the depth maps outputted from processing images captured using this aperture stack technique are often very coarse. Finally a last conventional technique processes a dense set of images i.e. hundreds of images with varying aperture and focus settings and compares each pixel in the dense set of images to estimate depth. This conventional technique outputs a precise depth map but still requires the dense set of images that can be inefficient to capture and process.

Thus conventional depth from defocus techniques rely on assumptions about the scene require the user to capture a large number of input images require the user to capture images using patterns of camera settings that are not predetermined to preserve sufficient depth information and or are capable of outputting only a low quality depth map. Accordingly it is desirable to provide improved solutions for predictively determining a minimum number of images to be captured and the camera configuration settings used for capturing them such that the images collectively provide sufficient depth information from which a quality depth map can be generated.

Systems and methods are provided for predictively determining image capture instructions for use in capturing images that can be processed to generate a quality depth map. In particular the image capture instructions once determined indicate a minimum number of images to be taken and with which aperture and focus settings they should be taken such that the images will provide sufficient depth information from which can be generated a depth map having a certain degree of depth quality. In some examples depth quality is represented by unambiguous depth estimates e.g. depth estimates that avoid multiple peaks when evaluated using a depth likelihood function . The image capture instructions are determined by evaluating a scene independent portion of a depth discrimination function using calibration data for the digital camera that is used to capture the images. In some examples a sufficient amount of depth information means that for each depth of interest within a depth range the corresponding blur radius within at least two images of the minimum number of images is about 1 to about 2 pixels.

The image capture instructions are determined based on 1 an input identifying an estimate of the closest distance from the camera of an object in a scene to be imaged and 2 calibration data for the camera. The calibration data defines for a given aperture setting the rates at which blur in an image increases as positions in the image move away from a focal plane i.e. a plane in the scene that is entirely in focus . For example for a larger aperture the calibration data defines that the blur increases at a greater rate as a position in the image is moved away from the focal plane as compared to smaller apertures. In some examples to determine the image capture instructions an image characteristic engine evaluates one or more aperture settings with different combinations of focus settings over a set of depth values within a depth range to determine how many images can be captured using those configuration settings such that a range of optimal blur radii in each image is about 1 to about 2 pixels. The minimum depth of the depth range is set as the distance estimate that was inputted for the scene. The maximum depth of the depth range may be any depth greater than the minimum depth but for convenience may be assumed to be infinity. Thus if the inputted distance estimate for the scene is two meters the depth range may be set as two meters to infinity.

To ensure that there is sufficient depth information throughout the depth range the image characteristic engine accesses the calibration data for the camera and uses the data to determine configuration settings for images to be captured within the depth range. In one example which can be used for any camera lens the image characteristic engine holds the aperture setting constant and selects a depth value set to the minimum depth of the depth range in the first iteration to determine a focus setting greater than the depth value with which an image can be captured having sufficient depth information e.g. the range of optimal blur radii is about 1 to about 2 pixels at the depth value . A next depth value greater than the prior focus setting is then determined at which the captured image will still have sufficient depth information e.g. the range of optimal blur radii will still be about 1 to about 2 pixels and a next focus setting greater than the next depth value is determined at which the captured image will continue to have sufficient depth information. This process is repeated over the entire depth range each time outputting a focus setting. The resulting set of focus settings corresponds to the number of images that should be captured of the scene to ensure that sufficient depth information is available for generating a quality depth map. In another example which can also be used for any camera lens the image characteristic engine determines the set of optimal focus settings using a simplified mathematical function that approximates blur radius based on the thick lens constant. With either example the image capture instructions are determined using the aperture setting and the determined set of focus settings.

The evaluation performed by the image characteristic engine ensures that the quantity of images and corresponding focus settings are determined in a manner such that the depths of field corresponding to the images do not substantially overlap do not have substantial gaps and are laid out equally within the depth range. A depth of field is an interval within the depth range e.g. two meters to infinity having a focal plane e.g. a focus setting at the center of the interval. In particular the depth of field intervals are laid out in a manner that ensures a range of optimal blur radii of about 1 to about 2 pixels for any pixel within the depth range e.g. at two meters at five meters at a hundred meters etc. including the pixels within the depth of field intervals and at the edges of the depth of field intervals. Thus a depth range will have more than one depth of field interval depending on the number of images identified by the image capture instructions. In some examples the depth range optimally has at least two depth of field intervals. The range of optimal blur radii includes the extent of blur that any pixel should experience within the entire depth range. Pixels in the range of optimal blur radii may have blur radii of about 1 to about 2 pixels. This measure of the blur radii may be used as a constraint when evaluating a set of depth values over the depth range.

These illustrative examples are mentioned not to limit or define the disclosure but to provide examples to aid understanding thereof. Additional examples are discussed in the Detailed Description and further description is provided there.

Computer implemented systems and methods are disclosed for determining image capture instructions for use in depth map generation. As introduced above a depth map may be generated by for example comparing differences in defocus blur associated with two or more input images.

Techniques described herein overcome the deficiencies identified above by predictively determining image capture instructions in a manner that is scene independent preserves sufficient depth information minimizes the number of images to be taken and ensures that a quality depth map can be generated from the images. In some examples depth quality is represented by unambiguous depth estimates e.g. depth estimates that avoid multiple peaks when evaluated using a depth likelihood function . The image capture instructions include the number of images to be taken and the aperture settings and the focus settings for each image.

The image capture instructions are determined without relying on data gathered from the scene to be captured an all in focus image or an image model. Instead the image capture instructions are determined using results of an evaluation of a depth discriminability function to maximize a scene independent portion thereof. The scene independent portion of the depth discriminability function is specific to a particular digital camera and lens. By maximizing the scene independent portion a range of optimal blur radii is determined. As used herein blur radius refers to the extent of a blur experienced by a pixel in an image and measured in terms of pixel s . The blur radius depends on the focus setting and aperture setting used to capture the image. The range of optimal blur radii is used in determining the image capture instructions. Thus the techniques described herein are characterized as being scene independent because they are implemented without regard to the makeup of the scene to be imaged and are therefore applicable to any scene having adequate texture.

The range of optimal blur radii indicates that for areas of high frequency content e.g. areas in the to be captured scene that have texture i.e. not a flat white wall sufficient depth information will be available in the captured images such that a quality depth map can be generated from the images. Thus by accounting for the range of optimal blur radii the image capture instructions are determined in a manner that ensures sufficient depth information will be available. This also enables the image capture instructions to be generated in a manner that minimizes the number of images to be taken. The number of images to be taken is determined by determining the position of one or more focal planes within a depth range at which a captured image focused thereon will provide sufficient depth information i.e. defocus blur . The positions of the determined focal planes thus correspond to the focus settings of the camera and the number of determined focal planes corresponds to the number of images to be taken of the scene. The focal plan determination is based on a fixed aperture setting. The position of a particular focal plane varies depending on the aperture setting of the camera. This is because aperture affects the rate at which blur increases as distance increases away from the focal plane. Thus for a particular aperture setting of a particular camera the image capture instructions may indicate that two images are needed for a given depth range in order to preserve sufficient depth information. However for the same camera having a different aperture setting the image capture instructions may indicate that three images are needed for the given depth range in order to preserve sufficient depth information.

After generation the image capture instructions are provided to the user of the digital camera or to the user s digital camera so that the digital camera can be operated or controlled to capture the number of images suggested by the image capture instructions using the settings also suggested.

In some examples to determine image capture instructions a user inputs a distance estimate e.g. two meters characterizing the object nearest to the user in a scene to be captured. In some examples a digital camera determines the distance estimate or the distance estimate is received using some other technique other than the user input. This distance estimate is used to determine a depth range for the scene with the minimum depth being the distance estimate and the maximum depth being some depth greater than the minimum depth. In some examples the maximum depth is assumed to be infinity. In some examples the user inputs or the camera generates a minimum depth a maximum depth or both. The depth range is then divided up into depths of field with the number of depths of field corresponding to the number of images and the location of focal planes within the depths of field corresponding to focus settings. In some examples a set of depth values and corresponding configuration settings are evaluated over the depth range and the configuration settings that maintain about 1 to about 2 pixels of blur for the depth values are selected and outputted as the image capture instructions.

The number of images and corresponding configuration settings are determined in a manner that ensures that depths of field corresponding to the images do not substantially overlap and do not have substantial gaps. Within each depth of field interval a maximum blur radius of about 1 to about 2 pixels is maintained for any pixel within the depth of field interval. The determination that the range of optimal blur radii should be about 1 to about 2 pixels is determined by maximizing a scene independent portion of the depth discriminability function. In doing so it is determined that for the particular digital camera and lens combination it is optimal i.e. ensures sufficient depth information to have a range of optimal blur radii of about 1 to about 2 pixels. Maximizing the scene independent term of the depth discrimination function is performed prior to determining the image capture instructions. In some examples however maximizing the scene independent term of the depth discrimination function may be performed during calibration of the particular digital camera and lens combination. In any event the range of optimal blur radii of about 1 to about 2 pixels is used as a constraint when evaluating a depth range based on a depth estimate to determine the image capture instructions. Having a range of optimal blur radii of about 1 to about 2 pixels ensures that for areas of high frequency content e.g. areas in the to be captured scene that have texture i.e. not a flat white wall sufficient depth information will be available such that a quality depth map can be generated from the images captured in accordance with the image capture instructions.

In one example to determine the image capture instructions i.e. focus settings aperture settings and number of images the techniques described herein hold the aperture setting constant and iterate through the depth range by computing focus settings for different depth estimates such that the blur experienced by pixels within the depth range is about 1 to about 2 pixels. To begin an initial depth estimate D is set equal to a minimum depth of the depth range Dmin and a focus setting E i.e. a focal plane placed at a distance E is computed. The focus setting E is computed when E is greater than D and in a manner such that the blur experienced by pixels at the initial depth estimate D is within the range of optimal blur radii of about 1 to about 2 pixels for the focus setting E. In this manner the depth of field is centered at E and the lower depth value extends to Dmin i.e. D because Dmin D . The determined focus setting E can then be used to evaluate the upper range of the depth of field e.g. extending above E . This process is iteratively continued until D is greater than or equal to the maximum depth of the depth range Dmax or when some other condition is met e.g. a pre determined number of iterations have been performed or a target quantity of images has been reached . The number of focus settings e.g. E E etc. needed to file the entire depth range corresponds to the number of images and the focus settings of the image capture instructions. In this example the total number of images and corresponding focus settings are not known until the entire iteration is complete. In some examples the focus settings are manipulated converted transformed or otherwise adjusted to conform to the focus functionality available on the digital camera.

In another example the depth range and the depth of field intervals are converted to 1 depth prior to determining the number of images and focus settings for each image. Generating the image capture instructions using 1 depth ensures that lengths of the depth of field intervals for each depth of field are the same. The depth of field intervals are then equally spaced within the depth range in a manner that ensures that there are no gaps and no overlaps of the depth of field intervals. Similar as above in this example the range of optimal blur radii that is used is about 1 to about 2 pixels. In this example it is assumed that the rate of change of blur radius as a function of inverse depth is approximately constant over the depth range. This assumption should be valid for most lenses although the rate of change may be different for different lenses. Thus for each lens there is a lens constant that represents a conversion factor between inverse depth and radius of blur. The process in this example begins by taking the total length of the depth range in inverse depth and dividing it by the maximum length of a depth of field interval within the depth range. The maximum length of the depth of field interval is determined by dividing the range of optimal blur radii by the conversion factor . This gives the total number of depth of field intervals within the depth range. The total length of the depth range in inverse depth is then divided by the total number of depth of field intervals to get an optimal length of each depth of field interval that will fill the entire depth range without gaps and without overlapping onto others. For each depth of field interval having the optimal length a focus setting is determined. The number of focus settings corresponds to the number of images to be captured. Because the process in this example considers the range of optimal blur radii of about 1 to about 2 pixels when evaluating the maximum length of each depth of field interval sufficient depth information will be available such that a quality depth map can be generated from the images captured in accordance with the image capture instructions. A quality depth map has an unambiguous depth likelihood e.g. a likelihood that if a depth map were generated using the particular configuration settings and from the number of images the depth estimates would very likely be the actual real world depths or only one depth is likely for any given set of pixels . In addition the process in this example first determines the number of images which corresponds to the number of depth of field intervals and then determines the focus settings for each depth of field interval.

In accordance with techniques described herein image capture instructions may indicate a quantity of images to be captured and corresponding configuration settings e.g. aperture settings and focus settings of a digital camera for capturing images for depth map generation. Images may be captured according those instructions and a depth map may then be generated using those images. A depth map generated using image capture instructions described herein includes depth information representing the distance of objects in a scene from the digital camera i.e. a location in the real world from where the pictures were taken . Distance values for pixels of the depth map may correspond to RGB pixels of the images. Depth maps may be used for example to improve existing image editing techniques. For example depth information for an image may be used to distinguish more accurately between foreground objects and background objects in a scene. Such a distinction may be relevant to selecting objects whether in the foreground or background within the image. By way of illustration an image of a scene may depict a child e.g. a foreground element standing in front of a tree e.g. a background element . A user desiring to clip the child from the scene may indicate as such by selecting a portion of the child using an image editing application. The image editing application may use depth information associated with the image in addition to selection cues such as color and texture to generate an outline of the child to be clipped.

Turning now to the figures illustrates block diagram showing functional components and their inputs and outputs for implementing techniques for predictively determining image capture instructions and capturing images according to those instructions for use in depth map generation as described herein. A first component is an image characteristic engine . As used herein engine refers to a set of instructions embodied in software that when executed on a processor cause the processor to perform one or more functions. The image characteristic engine is configured to receive depth range information and camera calibration information . The depth range information may include a user input or automatic input constituting an estimated distance of a scene an estimated distance of an object within the scene an estimated distance of a nearest object within the scene an average distance of the objects in the scene a measured distance of at least one object in the scene a measured distance of the nearest object of the scene and or any other information capable of conveying the distance of one or more objects in the scene. An image of the scene to which the depth range information pertains is captured using an image capture device . The image capture device may be for example a camera portion of a digital single lens reflex camera a point and shoot camera an integrated camera of a mobile device an integrated camera of a tablet device an integrated camera of a video camera an integrated camera of a laptop or any other suitable device for capturing an image or content from which an image may be extracted. In some examples the image characteristic engine receives the depth range information via an input on a user device that executes or is in communication with the image characteristic engine . In some examples the depth range information is programmatically determined based in part on a selection of one or more shooting modes of the image capture device . For example the image characteristic engine may be implemented in an image capture device comprising a digital camera and the depth range information may correspond to selection of one of a variety of shooting modes e.g. landscape portrait macro indoors outdoors sports etc. of the digital camera. Each of these modes may imply a minimum distance of the scene. In some examples a different shooting mode may be selected that implies minimum optical characteristics of the digital camera to be used by the image characteristic engine to determine the image capture instructions . For example a particular lens and camera combination may have two possible apertures and a minimum focus distance of 1 meter. By selecting the different shooting mode the image characteristic engine considers the two possible aperture settings and the minimum focus distance in determining the image capture instructions .

Once the depth range information is received the image characteristic engine performs one or operations with respect to the depth range information in order to determine image capture instructions . Examples of such operations are described with respect to for example. Ultimately a purpose of generating the image capture instructions or at least a portion thereof may be to generate a depth map from images N captured by the image capture device according to the image capture instructions . A depth map comprises estimates of distances of objects within the scene from the viewpoint where the images N were captured. Thus in some examples the image characteristic engine determines the image capture instructions such that a yet to be generated depth map may meet certain requirements once generated. For example such a requirement is a certain degree of likelihood that the depths indicated by the depth map are correct e.g. for an pixel having an actual distance of 4.5 meters a depth map indicating that the pixel has an estimated distance between 4 5 meters may be suitable . To this end the image characteristic engine predictively determines a quantity of images and configuration settings needed to achieve such a depth map.

In particular the quantity of images indicates the number of images N that should be taken using the image capture device and the configuration settings indicate the settings of the image capture device for capturing the images N such that sufficient depth information will be present in order to generate a quality depth map from the images N . In some embodiments the configuration settings indicate aperture settings and focus settings that should be used when capturing the recommended number of images identified by the quantity of images . The aperture settings relate to the amount of light let into the camera when an image is captured. The aperture of a camera is adjusted using a mechanism of blades that adjusts the amount of light. The focus setting relates to a distance of a focal plane from the image capture device e.g. a digital camera and is adjusted accordingly. In other embodiments the configuration settings additionally or alternatively include any camera setting that can affect the level of blur in an image at different depths.

In some embodiments when generating the image capture instructions the image characteristic engine associates configuration settings with each image of the quantity of images . For example assume that the image characteristic engine determines that the quantity of images that should be captured is four. The image characteristic engine may also associate with each of the four images a particular aperture setting and a particular focus setting . In some examples the aperture settings and the focus settings for each of the four images are different. In some examples however at least some of the aperture settings and or at least some of the focus settings are the same.

The image capture instructions are then provided to the image capture device . The image capture device is configured according to the image capture instructions in order to capture the images N . Because the images N are captured with the image capture device according to the image capture instructions the images N include or are associated with configuration information N . For example an image file may store not only data representing the image but also data or metadata representing the configuration information N . In other examples the configuration information N is stored in separate files associated with the applicable image files. The configuration information is associated with the image the configuration information is associated with the image and so forth. The configuration information N for each of the images N includes at least the aperture setting and the focus setting used by the image capture device to capture the images N .

The communication service is configured to manage communications between the other services of the image characteristic engine and other devices or components e.g. hardware and or software components that communicate with the image characteristic engine . For example depth range information is received by the communication service . In some examples depth range information is provided to another service of the image characteristic engine such as the shooting mode service and or the image capture instruction service . The communication service also receives image capture instructions from the image capture instruction service and provides image capture instructions to other services of the image characteristic engine to an operator of a digital camera e.g. via a display screen to a digital camera e.g. to component s of the digital camera that programmatically set configuration settings to an output device e.g. a printer to a storage structure associated with the image characteristic engine and to other similar entities. When the image characteristic engine is implemented on the same user device configured to capture images and executes a depth generation engine the communication service processes requests to perform operations received from other components of that user device including the depth generation engine and or a depth refinement engine. When the image characteristic engine is implemented as part of an online image editing service the communication service manages communications with one or more user devices.

The shooting mode service is configured to determine the depth range information based at least in part on a shooting mode of a digital camera. A shooting mode may include for example a landscape mode a portrait mode a macro mode an indoors mode an outdoors mode a sports mode and other similar modes of the digital camera. For example when shooting in the landscape mode a scene is likely further away than when shooting in the macro mode. Thus the depth range information may correspond to the selection of one of a user selected mode or an auto selected mode and the depth range information may include any suitable division of distance. For example suitable divisions of distance may include one meter to infinity two meters to infinity five meters to infinity ten meters to infinity and any other suitable division. In some examples the shooting mode service determines a lower value of the depth range information and it is assumed that the larger value is infinity.

The image capture instruction service is configured to predictively determine the image capture instructions . In some examples this includes identifying a quantity of images to be captured based on the depth range information and identify appropriate configuration settings for capturing the images in a manner to enable generation of a quality depth map. In some examples the image capture instruction service determines image capture instructions that can be used to capture the images from which a depth map may be generated in which depth ambiguity for textured patches of constant depth within a hypothetical scene is eliminated or minimized. This includes for example evaluating a likelihood function in a manner that minimizes double peaks i.e. where more than one depth is likely . As is known in the art a likelihood function in a statistics context is defined as a function of the parameters of a statistical model. The likelihood function of a set of parameter values given outcomes x is equal to the probability of those observed outcomes given those parameter values.

In the example illustrated in the amount of frequency content at a given frequency of the hypothetical blurry patch indicates where the hypothetical blurry patch is plotted as an X coordinate in x y coordinates. The amount of frequency content at a given frequency of the hypothetical blurry patch indicates where the hypothetical blurry patch is plotted as a Y coordinate in x y coordinates. Thus the amount of frequency content corresponding to the hypothetical blurry patch and the amount of frequency content corresponding to the hypothetical blurry patch together comprise an x y coordinates for each of the depths illustrated. For example at a coordinate the frequency contents for both of the hypothetical blurry patches are low close to origin . Conversely at a coordinate the frequency content for the hypothetical blurry patch is high compared to the frequency content for the hypothetical blurry patch large X value small Y value . In some examples the set of hypothetical blurry patches are evaluated at each discrete distance within a depth range identified from the depth range information . Each discrete distance may comprise a depth value. And using different depth values it is determined what the set of hypothetical blurry patches may look like with particular configuration settings. In the hypothetical diagram when the depth value is depth 5 i.e. the coordinate the frequency content for the hypothetical blurry patch is greater than the frequency content for the hypothetical blurry patch . When the depth value is depth 10 i.e. the coordinate the frequency content for the hypothetical blurry patch may about the same as the frequency content for the hypothetical blurry patch . Depth discriminability is determined based on the angular variation between the depths of the depth estimates. As used herein depth discriminability refers to the ability to discriminate between more than one depth for a particular pixel or patch. Thus the depth discriminability between the depth estimate of depth 10 and the depth estimate of depth 5 is high because there is a distinguishable angular variation between the two depth estimates. The same may be said for the other depth estimates there is a distinguishable angular variation between the depth estimates. In some examples the greater amount of frequency content at higher frequencies may make for more robust depth estimates with less uncertainty.

An evaluation of the plot in the diagram for the two hypothetical blurry patches may verify that in order to have images for generating a depth map of the desired quality at least two images should be captured of the scene using a particular aperture setting and two different focus settings where the images will have a defocus blur of about one to two pixels. Thus the diagram may be used to verify that the different possible depths can be discriminated. In some examples the defocus blur should be less than or equal to about a pixel and a half. This is because some defocus blur is desirable in order to preserve frequency content.

In some examples the operator estimates the distance estimate . For example this may include the operator estimating the distance estimate without any assistance of the digital camera . In some examples the operator estimates the distance estimate with the assistance of the digital camera or some other device e.g. a rangefinder a tape measure etc. . In some examples the digital camera determines the distance estimate in response to an input command provided by the operator . For example the digital camera may include functionality e.g. an integrated rangefinder to estimate distances of objects or the functionality may be associated with a mode of the digital camera . In some examples the distance estimate is estimated and provided as depth range information to another user device or the image editing service executing the image characteristic engine . In this example the other user device or image editing service receives the depth range information and in accordance with techniques described herein determines image capture instructions e.g. a quantity of images aperture settings and focus settings which may then be provided to the operator or the digital camera . In some examples image capture instructions are stored in a look up table which is accessible by the operator and or the digital camera . For example a hardcopy of a portion of the look up table may be provided to the operator and the operator may manually adjust the configuration settings of the digital camera to capture one or more images in accordance with the image capture instructions . In some examples the image capture instructions for a plurality of distance ranges are determined and stored in a memory of the digital camera or other user device . In some examples the image capture instructions are particular to the digital camera a type of digital camera a lens of the digital camera a combination of a lens and the digital camera . In some examples the digital camera comprises a camera body and a lens and the image capture instructions are tailored to combinations of camera bodies and lenses based on calibration data for the digital camera .

In some examples the configuration settings are stored in association with the images N as configuration information N . In some examples the operator inputs a distance estimate into the digital camera . The digital camera may execute an image characteristic engine which receives the distance estimate as input of the depth range information . The image characteristic engine then outputs for the operator e.g. via a display screen image capture instructions including a quantity of images to be captured an aperture setting for each image and a focus setting for each image. To capture the images the operator first adjusts the digital camera according to a first aperture setting selected out of for example f 1.2 f 2 f 4 f 5.6 f 8 f 16 f 22 or other suitable aperture settings corresponding to a first recommended image as identified by the image capture instructions . The operator then focuses the digital camera according to a first focus setting corresponding to the first recommended image as identified by the image capture instructions and captures the scene using the digital camera . The image is a result of the scene being captured. The operator then adjusts the digital camera according to a second aperture setting selected out of for example f 1.2 f 2 f 4 f 5.6 f 8 f 16 f 22 or other suitable aperture settings corresponding to a second recommended image as identified by the image capture instructions . The operator then focuses the digital camera according to a second focus setting corresponding to the second recommended image as identified by the image capture instructions and captures the next image of the scene using the digital camera . In some examples the operator captures more images with the same or different aperture settings and focus settings . The images N are then be used by a depth generation engine e.g. the depth generation engine A or B to output one or more depth maps.

By using the techniques relating to image capture instructions described herein it may be determined that when a larger depth range is present in a scene a greater number of images are needed to be captured in order to adequately preserve frequency content. For example for a depth range of two meters to infinity two images may not be adequate to preserve frequency content. For such a depth range it may be desirable to divide up the depth range and treat each division as its own individual depth range which may involve capturing more than two images in total. Thus in some examples image capture instructions may indicate that a frequency preserving set of images should be captured. In some examples the image capture instructions may indicate that for a depth range of two meters to infinity four pictures should be taken with different aperture settings . In some examples the image capture instructions may also indicate that for three meters to infinity three pictures should be taken with different aperture settings . For distances beginning with five meters and above in some examples the image capture instructions may indicate that two images should be taken.

In some examples the image characteristic engine determines the image capture instructions in accordance with the following examples. The following examples also illustrate in more detail how to evaluate a depth likelihood function how to use frequency content to determine image capture instructions and the like. In some cases the following examples are intended to supplement the discussion above regarding generation of the image capture instructions for creation of quality depth maps. In some examples a quality depth map is a depth map that avoids significant double peaks in a likelihood function. Thus in some examples the image capture instructions indicate a quantity of images to be taken and the configuration settings that should be used to capture them such that for an image patch the energy function d i at its ground truth depth circumflex over d is much smaller than the energy function at any other hypothetical depth d d circumflex over d .

Given a specific set of focus settings and aperture settings the input images i may depend on not only these configuration settings but also on image noise. Accordingly a likelihood function can be decomposed into a determinant and a stochastic part 

Here circumflex over and may correspond to ground truth and hypothetical defocus OTF Fourier transform of defocus blur kernel which may be decided by not only the depths d or circumflex over d but also the focus settings f and aperture settings a . The variables H and N denote Fourier transform of the all in focus image and may denotes noise respectively.

Although due to the stochastic term there may be challenges completely eliminating ambiguity however the likelihood function can be defined to be weakly unimodal when the deterministic term contrasts the likelihood of a wrong depth hypothesis significantly from that of the ground truth depth 

In some examples the depth information provided by the scene and configuration setting tuple h f a over a set of depth hypothesis D as may be defined as 

In some examples the first phase may include optimizing f and a regardless of texture of the scene. After a few images have been captured and additional knowledge about the all in focus image scene texture h f and a may be optimized conditioned on knowledge about h.

In some examples a sequence of depth hypothesis D is considered and minimal energy discriminative power is computed over all pairs of circumflex over d and d in D 

In some examples certain theorems discussed herein may allow correct depth estimation for many possible patches when configuration settings are chosen by maximizing and

In some examples the defocus invariant texture may be significantly different from periodic and therefore may not be directly applied to theorems discussed herein. In some examples the images may be prefiltered with Laplacians to make the scene texture more periodic. In this case H may no longer be a measurement of intensity variance in the sharp texture but may instead measure the significance of depth variant component in the scene texture.

In some examples theorems discussed herein may imply certain things about selecting configuration settings. For example to learn what may be implied it may be desirable to first express in terms of the blur kernel radius 

In selecting configuration settings for a pair of images an optimal pair of configuration setting for depth acquisition may be considered. The relationship of defocus kernel radius in two images sharing the same depth may satisfy 

Empirically it may be observed that for the same aperture velocity of defocus kernel radius change w.r.t. inverse depth for focus setting is approximately the same

and the distance between reference depth plane and aperture image on the object side may not change much i.e. B B and thus

In practice it may be desirable to obtaining depth information from high frequencies e.g. 2 so that high spatial resolution may be guaranteed. Thus as mentioned above it may be desirable to have a difference in defocus level between the two images to be 1 2 pixels.

Note that even in such situations and significantly decreases when either or go out of the range of . This may correspond to limiting the defocus blur radius of both images within 1 2 pixels.

In some examples for a very wide depth range of interest it may be impossible to achieve the above condition even with the smallest aperture. Thus is some examples the image capture instructions may indicate that multiple images be captured having the same focus settings . In some examples a straight forward choice may be to capture a frequency preserving focal stack of the scene. In some examples the image capture instructions may indicate that a focal stack should be captured. In some examples this may mean that images should be captured with the same aperture setting and have focus settings uniformly distributed within the focal range of interest. In some examples for each depth of interest a corresponding defocus blur may be less than 1.5 pixels in at least two images.

In some examples the image capture instructions for acquiring the images for depth maps may be the same as for acquiring an all in focus image. Therefore in some examples by capturing the images in accordance with the image capture instructions a depth map and an estimation of the all in focus image may be generated. Unlike conventional methods the image capture instructions may not indicate that a dense focal stack of images should be taken. Instead to reduce computational cost it may be desirable that smaller apertures settings are used in order to reduce the number of images . In some examples from a user specified depth range of interest identified from the depth range information optimal configuration settings regardless of the scene texture may be identified with the least number of images to be captured. The following data corresponds to the number of images and their corresponding aperture for various depth ranges using calibration data of a Canon EF50 mm 1.2L lens according to one example.

In some examples the images identified above may be captured using relatively small apertures. For example for many outdoor scenes an aperture smaller than f 8 may provide for suitable results. Even for very far scenes the largest aperture chosen may still be smaller than f 2.2 which may be one of the largest possible apertures on cellphones.

The following discussion describes example acts and or procedures that may be performed using techniques described herein in accordance with at least one example. depicts process including example functions relating to determining image capture instructions for use in depth map generation as described herein. Some or all of the process or any other processes described herein or variations and or combinations thereof may be performed under the control of one or more computer systems configured with executable instructions and may be implemented as code e.g. executable instructions one or more computer programs or one or more applications executing collectively on one or more processors by hardware or combinations thereof. The code may be stored on a computer readable storage medium for example in the form of a computer program comprising a plurality of instructions executable by one or more processors. The computer readable storage medium may be non transitory. The image characteristic engine whether implemented in one of the user devices N or within the image editing service may perform the process of . In some examples the process is suitable a camera having any lens following any suitable lens model. For example the process may be suitable for lens following a thick lens model or a thin lens model.

The process begins at by receiving depth range information. The depth range information may comprise a distance estimate. Receiving the distance estimate may include receiving the distance estimate comprising an estimate of the nearest object within a scene. In some examples the distance estimate may indicate an average distance of the scene. In some examples the distance estimate may comprise a distance of a portion of the scene from a viewpoint. In some examples the depth range information may be used to identify a depth range. For example the depth range information may indicate a minimum depth e.g. two meters and a maximum depth may be estimated. In some examples the depth range information indicate both the minimum depth and the maximum depth. One or both of these depths may be inputted by a user or gathered using devices or automatic methods. In some examples the depth range is divided into a set of discrete depth values. At least a portion of the set of depth values are evaluated by the process to determine focus settings aperture settings and a minimal quantity of images. In some examples the depth range information comprises an input of a target quantity of images. The target quantity of images may indicate the number of images the user is willing to take or the number of images that can possible be taken by the camera within a certain time threshold e.g. five seconds . In some examples the process considers the target quantity of images while determining the image capture instructions and adjusts the output accordingly. In some examples this may result in depth information exceeding or falling short of the range of optimal blur radii. In some examples when the target quantity of images exceeds the minimal quantity of images there may overlaps in the depths of field and or excess depth information. In some examples when the target quantity of images is fewer than the minimal quantity of images there may be gaps in the depths of field and or a deficiency of depth information.

At the process sets a first depth value equal to a minimum depth value based on the depth range information. For example if the depth range information indicates a depth range e.g. two meters to fifty meters the first depth value is two meters. In this manner the process begins with the smallest depth and iterates through all the depth values until a depth value that is greater than a maximum depth e.g. fifty meters is reached.

At the process identifies a range of optimal blur radii for images to be captured. In some examples the range of optimal blur radii is determined prior to the execution of the process . For example the range of optimal blur radii may be pre computed and provided to a computer executing the process . In some examples the range of optimal blur radii is determined in part by evaluating a scene independent portion of a depth discrimination function including a scene dependent portion and the scene independent portion. The scene independent portion is independent of the scene because it relies on calibration data for a digital camera used to capture the images and not the underlying scene. In some examples the depth discrimination function comprises equation 3 as described herein. The depth discriminability function is evaluated in a manner that maximizes the scene independent portion of the depth discriminability function. In some examples the range of optimal blur radii is factored into the determination of the image capture instructions in order to ensure that there will be sufficient depth information such that a quality depth map can be generated from the captured images. In this manner the image capture instructions are determined in a way that maximizes the amount of depth information but also minimizes the number of images to be captured. In some examples the range of optimal blur radii is about 1 to about 2 pixels.

At the process identifies an aperture setting. In some examples the same aperture setting may be used for at least two of the images to be captured. In some examples the aperture setting is one of the smallest allowable aperture settings based on the available aperture settings of the camera. In some examples the aperture setting is optimally chosen as part of evaluating the scene independent portion of the depth discriminability function. The aperture setting may be greater than the smallest allowable aperture in some examples. In some examples the process is evaluated using different aperture settings at . In this manner the focus settings may be determined for different aperture settings.

At the process determines a first focus setting such that the first focus setting is greater than the minimum depth value and such that blur experienced by pixels at the minimum depth value is within the range of optimal blur radii in an image captured using the aperture setting and the first focus setting. In some examples this may include computing the first focus setting in a manner that considers the amount of depth information that will be available at other positions within the image.

At the process outputs the first focus setting. In some examples this includes storing the first focus setting. In some examples the first focus setting is outputted to table of focus settings. This may include capturing an image using the first focus setting and the aperture setting. In some examples outputting the first focus setting may include generating an image capture instruction including the first focus setting.

At the process determines a next depth value such that the next depth value is greater than the previous focus setting and such that blur experienced by pixels at the next depth value is within the range of optimal blur radii in an image captured using the aperture setting and a focus setting corresponding to the next depth value. For example if the previous focus setting e.g. the first focus setting was at three meters the next depth value that is selected is greater than three meters.

At it is determined whether the next depth value is greater than or equal to the maximum depth value. In some examples the maximum depth value corresponds to the depth range determined from the depth range information. If yes the process ends at . If no the process continues to where the process determines an additional focus setting such that the additional focus setting is greater than the next depth value and such that blur experienced by pixels at the next depth value is within the range of optimal blur radii in an image captured using the aperture setting and the additional focus setting.

At the process outputs the additional focus setting. In some examples this includes storing the additional focus setting. In some examples the additional focus setting is outputted to table of focus settings. This may include capturing an image using the first focus setting and the aperture setting. In some examples outputting the additional focus setting may include generating an image capture instruction including the additional focus setting. After outputting the additional focus setting at the process returns to and determines a next depth value such that the next depth value is greater than the previous focus setting and such that blur experienced by pixels at the next depth value is within the range of optimal blur radii in an image captured using the aperture setting and a focus setting corresponding to the next depth value.

The following discussion describes example acts and or procedures that may be performed using techniques described herein in accordance with at least one example. depicts process including example functions relating to determining image capture instructions for use in depth map generation as described herein. The image characteristic engine whether implemented in one of the user devices N or within the image editing service may perform the process of . In some examples all or part of the process may be computed using inverse depth i.e. depth measurements. In some examples the process is simpler than the process because the process determines the minimal quantity of images upfront and spaces the depths of field evenly over the depth range.

The process begins at by receiving depth range information. The depth range information may comprise a distance estimate. Receiving the distance estimate may include receiving the distance estimate comprising an estimate of the nearest object within a scene. In some examples the distance estimate may indicate an average distance of the scene. In some examples the distance estimate may comprise a distance of a portion of the scene from a viewpoint. In some examples the depth range information may be used to identify a depth range. For example the depth range information may indicate a minimum depth e.g. two meters and a maximum depth may be estimated. In some examples the depth range information indicates both the minimum depth and the maximum depth. One or both of these depths may be inputted by a user or gathered using devices or automatic methods. In some examples the depth range information comprises an input of a target quantity of images. The target quantity of images may indicate the number of images the user is willing to take or the number of images that can possible be taken by the camera within a certain time threshold e.g. five seconds . In some examples the process considers the target quantity of images while determining the image capture instructions and adjusts the output accordingly. In some examples this may result in depth information exceeding or falling short of the range of optimal blur radii. In some examples when the target quantity of images exceeds the minimal quantity of images there may overlaps in the depths of field and or excess depth information. In some examples when the target quantity of images is fewer than the minimal quantity of images there may be gaps in the depths of field and or a deficiency of depth information.

At the process identifies a range of optimal blur radii for images to be captured. In some examples the range of optimal blur radii is determined prior to the execution of the process . For example the range of optimal blur radii may be pre computed and provided to a computer executing the process . In some examples the range of optimal blur radii is determined in part by evaluating a scene independent portion of a depth discrimination function including a scene dependent portion and the scene independent portion. The scene independent portion is independent of the scene because it relies on calibration data for a digital camera used to capture the images and not the underlying scene. In some examples the depth discrimination function comprises equation 3 as described herein. The depth discriminability function is evaluated in a manner that maximizes the scene independent portion of the depth discriminability function. In some examples the range of optimal blur radii is factored into the determination of the image capture instructions in order to ensure that there will be sufficient depth information such that a quality depth map can be generated from the captured images. In this manner the image capture instructions are determined in a way that maximizes the amount of depth information but also minimizes the number of images to be captured. In some examples the range of optimal blur radii is about 1 to about 2 pixels.

At the process identifies an aperture setting. In some examples the same aperture setting may be used for at least two of the images to be captured. In some examples the aperture setting is one of the smallest allowable aperture settings based on the available aperture settings of the camera. In some examples the aperture setting is optimally chosen as part of evaluating the scene independent portion of the depth discriminability function. The aperture setting may be greater than the smallest allowable aperture in some examples. In some examples the process is evaluated using different aperture settings at . In this manner the focus settings may be determined for different aperture settings.

At the process determines a maximum K value based on calibration data for the camera. The K value indicates the maximum length of an interval in a depth range. In some examples the depth range is determined based on the depth range information. In some examples the camera calibration data includes the range of optimal blur radii and a lens constant a. In particular the maximum K value may be determined by dividing the length of the depth range by the range of optimal blur radii divided by the lens constant . The lens constant represents a conversion factor between inverse depth and radius of blur e.g. blur kernels . The blur kernels are identified from a mapping of calibration settings e.g. aperture and focus and depth to blur kernels. The mapping is derived from a calibration of the camera. In this example lens constant is based on the assumption that the rate of change of blur radius as a function of inverse depth is approximately constant over the depth range. In the thick lens model example in equation 12 the lens constant represents the approximately constant product C f D f over the depth range for the thick lens parameters C f and D f.

At the process determines based on the maximum K value a quantity of intervals within the depth range The quantity of intervals corresponds to a minimal quantity of images suggested. In some examples each interval corresponds to a depth of field interval. Thus the quantity of intervals is the number of depths of field that will completely pack the depth range without any gaps and without overlapping depths of field. In some examples the depths of fields are equally spaced throughout the depth range. In some examples the quantity of intervals corresponds to the minimal quantity of images because an image is designated for each interval in the depth range. Thus the correspondence may be one to one. In some examples there are more intervals than images and vise versa.

At the process determines based on the quantity of intervals an optimal interval length. In some examples the optimal interval length is based on the quantity of the set of intervals. In this manner the optimal interval length of each interval is the total length of the depth range e.g. minimum depth minus maximum depth divided by the quantity of intervals.

At the process determines based on the optimal length of the each interval a focus setting for each image of the minimal quantity of images. In some examples the focus setting for each image corresponds to a focal plane placed at the midpoint of each interval of the set. In some examples the determined focus settings are converted or otherwise adjusted to conform with the focus settings available on the camera. In some examples the focus settings are output in the form of an array that includes a focus setting for each of the minimal images. In some examples each image of the minimal quantity of images corresponds to the aperture setting. In some examples the aperture setting is the same aperture setting for a portion of the minimal quantity of images. In some examples the focus setting and the aperture setting for each image of the minimal quantity of images are used by the camera to capture the minimal quantity of images.

The user device comprises any suitable device capable of capturing an image and or performing one or more operations on images. In some examples the user device is any suitable computing device such as but not limited to digital camera a mobile phone a smart phone a personal digital assistant PDA a laptop computer a personal computer a desktop computer a set top box a thin client device or other computing device. The user device is utilized by one or more users not shown for interacting with the image editing service .

The user device therefore includes a processor that is communicatively coupled to a memory and that executes computer executable program code and or accesses information stored in the memory . In some examples the memory stores a web service application and one or more engines e.g. the image characteristic engine a depth generation engine A a depth refinement engine A an image editing engine A . The processor comprises a microprocessor an application specific integrated circuit ASIC a state machine or other processing device. The processor may also include any of a number of processing devices including one. Such a processor can include or may be in communication with a computer readable medium storing instructions that when executed by the processor cause the processor to perform the operations described herein. The web service application may enable the user to interact with the image editing service over the network . The user device also comprises an image capture device A . The image capture device A is configured to capture one or more images. In some examples the image capture device A comprises a conventional digital camera including a lens aperture setting focus setting an infrared projector and or a structured light device. Any uses of digital camera throughout this specification are for illustrative purposes only and a person of ordinary skill in the art would understand that such term may generally be used to refer to any image capture device executed by or integrated with any one of the user devices N or any similar device. Therefore the terms digital camera and user device may sometimes be used generically and interchangeably herein. In some examples the user device is a digital camera and may be configured with the image capture device A in order to capture images but may not include any or some of the engines. In this example the user device or an operator of the user device is provided with image capture instructions to use while capturing the images using the image capture device A .

The image editing service includes a processor that is communicatively coupled to a memory and that executes computer executable program code and or accesses information stored in the memory . In some examples the memory stores an operating system and one or more engines e.g. the image characteristic engine the depth generation engine B the depth refinement engine B and the image editing engine B . The operating system comprises any suitable operating system configured for interacting with the image editing service . The processor comprises a microprocessor an ASIC a state machine or other processing device. The processor also comprises any of a number of processing devices including one. Such a processor can include or may be in communication with a computer readable medium storing instructions that when executed by the processor cause the processor to perform the operations described herein.

The memory comprises any suitable computer readable medium. The computer readable medium may include any electronic optical magnetic or other storage device capable of providing a processor with computer readable instructions or other program code. A computer readable medium may include for example a magnetic disk memory chip ROM RAM an ASIC a configured processor optical storage magnetic tape or other magnetic storage or any other medium from which a computer processor can read instructions. The instructions may include processor specific instructions determined by a compiler and or an interpreter from code written in any suitable computer programming language including for example C C C Visual Basic Java Python Perl JavaScript and ActionScript.

The image editing service also includes a number of external or internal devices such as input or output devices. For example the image editing service includes input output I O device s and or ports such as for enabling connection with a keyboard a mouse a pen a voice input device a touch input device a display speakers a printer or other I O device. The image editing service also includes additional storage which may include removable storage and or non removable storage. The additional storage may include but is not limited to magnetic storage optical disks and or tape storage. The disk drives and their associated computer readable media may provide non volatile storage of computer readable instructions data structures program modules and other data. The image editing service also includes a user interface . The user interface is utilized by an operator or other authorized user to access portions of the image editing service . In some examples the user interface includes a graphical user interface web based applications programmatic interfaces such as application programming interfaces APIs or other user interface configurations. The image editing service also includes data store . The data store comprises data structures for storing information related to the implementation of the techniques described herein. Such information is stored in image database . Within the image database is stored input images depth maps and other similar images and maps together with their associated information.

The depth generation engines A B are configured to generate depth maps based on a plurality of the images captured by the image capture device or captured by another image capture device and provided to one of the user devices N or the image editing service . In some examples the depth generation engines A B perform one or more operations to generate depth maps in accordance with techniques described in U.S. application Ser. No. 14 552 332 filed on Nov. 24 2014 the entirety of which is hereby incorporated by reference. For example as discussed in more detail in U.S. application Ser. No. 14 552 332 the depth generation engines A B may generate depth maps all in focus images and measures of uncertainty.

The depth refinement engines A B are configured to refine previously generated depth maps. In some examples the depth refinement engines A B perform one or more refinement operations with respect to a depth map generated by one of the depth generation engines A B . Such refinement operations function to improve the depth map. In some examples improving the depth map includes increasing a likelihood that depths within the depth map are indeed the correct the depths. In some examples improving the depth map may include identifying by one of the depth refinement engines A B a quantity of additional images to capture and configuration settings to use when capturing the quantity of additional images. In some examples the depth refinement engines A B perform one or more operations to refine depth maps in accordance with techniques described in U.S. application Ser. No. 14 576 936 filed on Dec. 19 2014 the entirety of which is hereby incorporated by reference. For example as discussed in more detail in U.S. application Ser. No. 14 576 936 the depth refinement engines A B estimate how many more images to take and what aperture settings and focus settings should be used in order to have sufficient depth information to refine a particular depth map. For example the depth refinement engines A B may take as input an initial depth map an all in focus image and a measure of uncertainty. Based on these it is recommended how many additional images should be captured and what aperture settings and focus setting should be used such that the initial depth map may be improved by some improvement criterion.

The image editing engines A B are configured to perform one or more operations relating to image editing. For example after the images have been captured in accordance with the image capture instructions and a depth map has been generated and optionally refined one of the image editing engines A B are utilized to edit an image corresponding to the depth map. As noted previously the depth map may be stored as a separate file associated with the image or may be included as data or metadata within the image file.

Numerous specific details are set forth herein to provide a thorough understanding of the claimed subject matter. However those skilled in the art will understand that the claimed subject matter may be practiced without these specific details. In other instances methods apparatuses or systems that would be known by one of ordinary skill have not been described in detail so as not to obscure the claimed subject matter.

Unless specifically stated otherwise it is appreciated that throughout this specification discussions utilizing terms such as processing computing calculating determining and identifying or the like refer to actions or processes of a computing device such as one or more computers or a similar electronic computing device or devices that manipulate or transform data represented as physical electronic or magnetic quantities within memories registers or other information storage devices transmission devices or display devices of the computing platform.

The system or systems discussed herein are not limited to any particular hardware architecture or configuration. A computing device can include any suitable arrangement of components that provide a result conditioned on one or more inputs. Suitable computing devices include multipurpose microprocessor based computer systems accessing stored software that programs or configures the computing system from a general purpose computing apparatus to a specialized computing apparatus implementing one or more embodiments of the present subject matter. Any suitable programming scripting or other type of language or combinations of languages may be used to implement the teachings contained herein in software to be used in programming or configuring a computing device.

Embodiments of the methods disclosed herein may be performed in the operation of such computing devices. The order of the blocks presented in the examples above can be varied for example blocks can be re ordered combined and or broken into sub blocks. Certain blocks or processes can be performed in parallel.

The use of adapted to or configured to herein is meant as open and inclusive language that does not foreclose devices adapted to or configured to perform additional tasks or steps. Additionally the use of based on is meant to be open and inclusive in that a process step calculation or other action based on one or more recited conditions or values may in practice be based on additional conditions or values beyond those recited. Headings lists and numbering included herein are for ease of explanation only and are not meant to be limiting.

While the present subject matter has been described in detail with respect to specific embodiments thereof it will be appreciated that those skilled in the art upon attaining an understanding of the foregoing may readily produce alterations to variations of and equivalents to such embodiments. Accordingly it should be understood that the present disclosure has been presented for purposes of example rather than limitation and does not preclude inclusion of such modifications variations and or additions to the present subject matter as would be readily apparent to one of ordinary skill in the art.

