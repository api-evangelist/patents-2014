---

title: System and method for optical cold storage wherein plurality of first and second chunks are encoded and placed on different optical disks
abstract: Various embodiments (“systems”) are described for transferring data from a primary storage (e.g., magnetic disk drives, solid state drives, etc.) to an optical cold storage rack. The optical cold storage rack may include many physical optical storage disks, but a much smaller number of burners and readers (e.g., optical disk drives). When data is to be transferred to the optical cold storage rack, the system may generate a plan for performing the transfer. “Migration worker” components may then implement the plan and may be exclusively dedicated to implementing such plans. In various embodiments, the plan may specify how large data file “aggregates” (collections of portions of one or more data files) are to be distributed across optical disks (“disks”) to improve throughput during subsequent reading operations from the optical cold storage rack. The plan may also anticipate the relation between the limited number of burners/readers and the overall optical cold storage rack disk capacity.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09483200&OS=09483200&RS=09483200
owner: FACEBOOK, INC.
number: 09483200
owner_city: Menlo Park
owner_country: US
publication_date: 20141103
---
Disparate technical and business objectives can make it difficult for businesses and other entities institutions to store and safeguard large volumes of data. For example the software and hardware applications servicing an institution s primary storage system may need to provide redundancy across different hardware platforms determine appropriate timings for the storage and retrieval of data and allocate data in a structured manner. These technical considerations can also be complicated by business objectives. For example where the organization deals in sensitive personal information it may be necessary for definitive measures for erasing data in storage to be readily available.

Optical data storage systems provide some benefits that may address various of these technical and business needs. For example an optical disk may not require any power until it is placed into an optical disk drive drive so that data can be read or written. However successful integration of optical storage into an operational database system demands that the nuances of the optical storage and the existing storage systems be fully considered.

For example success regularly depends upon the harmonious integration of factors such as data retention policies privacy policies storage operations encoding protocols etc. Rather than joining disparate collections of tools at different levels of abstraction an optical storage system would ideally synthesize these elements for a common purpose. Typical optical storage systems fail to provide this integrated functionality or to achieve the consequent efficiency gains.

While the flow and sequence diagrams presented herein show an organization designed to make them more comprehensible by a human reader those skilled in the art will appreciate that actual data structures used to store this information may differ from what is shown in that they for example may be organized in a different manner may contain more or less information than shown may be compressed and or encrypted etc.

The headings provided herein are for convenience only and do not necessarily affect the scope or meaning of the claimed embodiments. Further the drawings have not necessarily been drawn to scale. For example the dimensions of some of the elements in the figures may be expanded or reduced to help improve the understanding of the embodiments. Similarly some components and or operations may be separated into different blocks or combined into a single block for the purposes of discussion of some of the embodiments. Moreover while the various embodiments are amenable to various modifications and alternative forms specific embodiments have been shown by way of example in the drawings and are described in detail below. The intention however is not to limit the particular embodiments described. On the contrary the embodiments are intended to cover all modifications equivalents and alternatives falling within the scope of the disclosed embodiments as defined by the appended claims.

Various embodiments systems are described for transferring data from a primary storage e.g. magnetic disk drives solid state drives etc. to an optical cold storage rack. The optical cold storage rack may include many physical optical storage disks but a much smaller number of burners and readers e.g. optical disk drives . When data is to be transferred to the optical cold storage rack the system may generate a plan for performing the transfer. Migration worker components may then implement the plan and may be exclusively dedicated to implementing such plans. In various embodiments the plan may specify how large data file aggregates collections of portions of one or more data files are to be distributed across optical disks disks to improve throughput during subsequent reading operations from the optical cold storage rack. The plan may also anticipate the relation between the limited number of burners readers and the overall optical cold storage rack disk capacity. Header and footer metadata may be appended to each file portion stored in the optical cold storage rack disks to facilitate recovery. The metadata may indicate the location and relationship of other file portions related to this file portion. Methods for efficiently deleting data from the optical cold storage rack so as to comply with various data retention and or privacy policies are also provided in various embodiments.

Various examples of the disclosed techniques will now be described in further detail. The following description provides specific details for a thorough understanding and enabling description of these examples. One skilled in the relevant art will understand however that the techniques discussed herein may be practiced without many of these details. Likewise one skilled in the relevant art will also understand that the techniques can include many other obvious features not described in detail herein. Additionally some well known structures or functions may not be shown or described in detail below so as to avoid unnecessarily obscuring the relevant description.

The terminology used below is to be interpreted in its broadest reasonable manner even though it is being used in conjunction with a detailed description of certain specific examples of the embodiments. Indeed certain terms may even be emphasized below however any terminology intended to be interpreted in any restricted manner will be overtly and specifically defined as such in this section.

Turning now to the figures is a block diagram illustrating elements in a primary and optical storage topology as may occur in some embodiments. A primary storage system may include a file system entity in communication with a plurality of processing systems . Though referred to herein as a primary storage system the system may simply reflect the storage devices upon which the enterprise would depend absent the existence of the optical storage. Accordingly the primary storage system may simply be a collection of local hard drives employed by the enterprise during normal operations. However the primary storage system may also reflect a hard disk drive based cold storage system and may or may not be networked with other computer devices.

The data in the primary storage system may originally be stored in a hard disk drive hard drive storage for ready access. The processing systems may determine e.g. periodically or based on a specified schedule that data from the primary storage system is to be stored in or retrieved from the optical storage racks. When such a determination is made the processing systems may provide instructions to one or more migration workers . Either the processing systems or migration workers may create a plan depicting the operations necessary to fulfill the instruction. The plan may then be implemented by one or more migration workers

A migration worker may be one or more dedicated process on a machine connected to a network e.g. a computing machine such as a router or switch or it may be one or more processes operating on one or more separate machines. Each migration worker may determine a series of actions necessary to perform a portion of the plan. Migration workers may distribute the portions of the plan amongst themselves or be assigned portions directly by the processing systems . The migration worker may read and write data from hard drives in the primary storage system. In some embodiments the migration worker may apply Reed Solomon RS encoding to data transmitted to the optical storage system. RS encoding may facilitate the recovery of data even if one or more of the optical disks fail.

The migration workers may consult a database as part of the plan execution. Each migration worker may then selectively direct the read and write operations at one or more optical disk burners and readers across one or more optical storage racks . For example in the event that a database e.g. file allocation table becomes corrupt or otherwise unavailable it can be rebuilt using the data stored in the headers and footers.

Each optical storage rack may include a finite number of burners and or readers having limited processing ability. For example there may be twelve burners each able to operate at 20 MB per second. Each of the burners and readers may be able to operate on one or more disks . An example disk may include data stored in a plurality of header footer and data partitions. The header and footer partitions may indicate where related chunks of data e.g. portions of the file aggregates found in the data partitions may be found in the optical storage system.

The optical storage system may include Write Once Read Many WORM technology and may operate on a low cost and high density optical media. The optical system may consist of a robotic arm fitted into a server rack stacked with optical media storage and one or more optical media drives. The optical cold storage system may employ optical disk drives or optical disks that are not rewritable to further reduce the total cost of operations TCO .

A repair system may work with the migration workers to verify integrity of the disks throughout operations. An Anti Entropy scanner may also communicate with the database and the optical storage to detect errors.

Various of the disclosed configurations may increase write read speeds and increase availability some racks burners can be down . The configurations may also increase durability e.g. lowering the risk of losing data . The time to load media may be reduced to 30 s. In some embodiments loadings may also be amortized for reading writing big data sets full disks . The input output speed may also be improved. Some embodiments may parallelize reads writes to multiple drives.

In some implementations the optical rack may have twelve burners or 1.2 TB of active storage. An HDD rack may have 32 active HDDs or 128 TB of active storage. The write read strategy may include clustering of the data across time and spread across multiple racks.

In some embodiments there may be high HDD aggregation via the configuration. A space re balancer may be employed to dynamically adjust the data distribution. The re balancer may be non real time and may run when needed. The re balancer may move volumes to new hardware to even out real time load.

The customer system may indicate a desired action to a system in the FrontEnd plane . The migration workers may calculate the size and determine a portion of the plan to execute. RS encoding may be used to encode data stored in the optical storage to mitigate errors. The customer system may provide and request data from the system. These requests for data to be returned and for data to be written may be received at a FrontEnd Plane the FrontEnd plane may include a web tier interface such as may be presented to an external computer . The FrontEnd Plane may communicate with a Durability Plane via front end racks and via a Control Plane via metadata calls. Data may flow to the FrontEnd Plane and Durability Plane via a core router and rack switch . The rack switch may control data flow from one or more racks located in the data plane .

Each storage node may include a head node having multiple processors or cores e.g. cores 146 GB RAM and or 10 Gbps Ethernet. One will recognize that various other computing device specifications may be equally suitable. In some embodiments there may be one HDD active per tray.

One or more migration workers may then acquire the plan . Referencing the plan the migration workers may then consult various hard drive storages to acquire the desired chunks of data. The migration workers may then make calls e.g. by invoking various data storage calls e.g. via an application programming interface to the optical storage to write the chunks in accordance with the plan.

The migration worker may associate the file chunks with blocks which are themselves associated with logical volumes . In this example file chunk A is associated with blocks B B and B. File chunk B is associated with blocks B and B. Each of Blocks B B are associated with Volume in this example. Logical volumes may be associated with physical volumes on the optical disks. In this example each of the physical volumes P P is associated with the same logical volume V. The physical volumes may be associated with disks. Here physical volume P is found on disk D physical volume P on disk D and physical volume P on disk D. The disks may be found on different racks in the optical storage. For example here disk D appears on rack Rack disk D on rack Rack and disk D on rack Rack.

Thus primary storage system requests a file from an optical storage the system can cause a migration worker to implement a plan to identify the appropriate disks and racks based upon the chunks in the file. Linear programming and other optimizations may be used to identify the best timing and order in which to request that each disk be read from the respective rack.

In the illustrated example a file A in primary storage includes three chunks A A and A. A file B in primary storage includes the chunks B B. When directed to write the files A and B to optical storage the system may generate a plan to intersperse the disk writes such that the chunks are readily accessible. For example the first disk D may receive the chunk A and then the chunk B. A second disk D may receive the chunk B and then the chunk A. Finally a disk D may receive the chunk A. By separating the chunks in the depicted manner the read time for many files may be improved. If all the chunks associated with a single file were stored on the same disk not only would this reduce the efficacy of the RS encoding but it would require that individual disks be separately handled for each file request.

A header and a footer may be appended to each chunk as it appears in the respective disks D D. For example the header of the chunk A as it appears in D may indicate the length of the data in A found in D. The header may also indicate the disks where each of the chunks A and A are located and the respective offsets at which they may be found. RS encoding may be used across all the disks to facilitate recovery should any one disk be lost or destroyed. RS encoding may be applied to each chunk in isolation as well.

At block the migration worker may construct a plan though in some embodiments the plan be separately generated and provided to the migration worker . The plan may anticipate both the character of the instructions and the character of the existing optical storage context. For example the burners and readers in the optical storage may have a finite capacity and may already be allocated to other requests. The migration worker may identify portions of files residing on disks which will be retrieved according the existing operations. Rather than specify separate requests the migration worker can then wait for these disks to be retrieved and then request a supplemental operation. For example the robotics control unit may retain a queue of operations to be performed. The migration worker may direct the node computer to insert operations in fulfillment of the determined plan alongside existing operations in the queue.

At block the migration workers may implement the transfer while encoding and or organizing data to facilitate recovery and or management. For example if the instructions request that a new file be created or that new data be written to a file the migration worker may RS encode chunks in the file affected by the modification to facilitate error detection and correction.

At block the system may consider the next unexecuted portion of a plan. If the portion is able to be executed on the optical storage at block e.g. if the necessary readers and disks are not available then the system may wait for a more suitable time. Similarly if at block the migration worker determines that a required portion of the network database is unavailable the migration worker may proceed to the next portion. For example just as the optical network is not always available the hard drives on the primary storage may not always be available as well. Though not depicted in this example the operations at the primary storage and at the optical storage need not proceed together. The migration worker may e.g. retrieve data from the optical storage regardless of the primary storage s availability and store the data. Once the primary storage becomes available the data may be transferred. For example the primary storage may be accessible over a network or have a finite number of input out interfaces.

When it is possible to perform the requested operation the migration worker may break the file into chunks at block although in some embodiments the primary storage may have performed this operation in advance . At block the migration worker may then encode the chunks of data e.g. using RS encoding. At block the migration worker may direct the optical storage e.g. via the robotics control unit to distribute the file chunks across the various storage disks. If portions of the plan remain unexecuted at block the system may consider the next unexecuted portion.

While a greedy approach is presented in more forward looking embodiments are also considered wherein the migration worker anticipates future portions of the plan to economize upon the requirements of preceding portions. For example where a subsequent portion of the plan requires a disk access if the same disk is to be accessed previously the necessary modifications for both portions may be performed upon the first access.

Upon a request from the primary storage to delete a dataset the optical storage may overwrite the data in each rack e.g. writing l s at each bit . An encryption key may be stored in the database and used to encrypt data as it is written to the optical storage. When a deletion is requested the key may simply be destroyed.

The memory and storage devices are computer readable storage media that may store instructions that implement at least portions of the various embodiments. In addition the data structures and message structures may be stored or transmitted via a data transmission medium e.g. a signal on a communications link. Various communications links may be used e.g. the Internet a local area network a wide area network or a point to point dial up connection. Thus computer readable media can include computer readable storage media e.g. non transitory media and computer readable transmission media.

The instructions stored in memory can be implemented as software and or firmware to program the processor s to carry out actions described above. In some embodiments such software or firmware may be initially provided to the processing system by downloading it from a remote system through the computing system e.g. via network adapter .

The various embodiments introduced herein can be implemented by for example programmable circuitry e.g. one or more microprocessors programmed with software and or firmware or entirely in special purpose hardwired non programmable circuitry or in a combination of such forms. Special purpose hardwired circuitry may be in the form of for example one or more ASICs PLDs FPGAs etc.

The above description and drawings are illustrative and are not to be construed as limiting. Numerous specific details are described to provide a thorough understanding of the disclosure. However in certain instances well known details are not described in order to avoid obscuring the description. Further various modifications may be made without deviating from the scope of the embodiments. Accordingly the embodiments are not limited except as by the appended claims.

Reference in this specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment of the disclosure. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment nor are separate or alternative embodiments mutually exclusive of other embodiments. Moreover various features are described which may be exhibited by some embodiments and not by others. Similarly various requirements are described which may be requirements for some embodiments but not for other embodiments.

The terms used in this specification generally have their ordinary meanings in the art within the context of the disclosure and in the specific context where each term is used. Certain terms that are used to describe the disclosure are discussed below or elsewhere in the specification to provide additional guidance to the practitioner regarding the description of the disclosure. For convenience certain terms may be highlighted for example using italics and or quotation marks. The use of highlighting has no influence on the scope and meaning of a term the scope and meaning of a term is the same in the same context whether or not it is highlighted. It will be appreciated that the same thing can be said in more than one way. One will recognize that memory is one form of a storage and that the terms may on occasion be used interchangeably.

Consequently alternative language and synonyms may be used for any one or more of the terms discussed herein nor is any special significance to be placed upon whether or not a term is elaborated or discussed herein. Synonyms for certain terms are provided. A recital of one or more synonyms does not exclude the use of other synonyms. The use of examples anywhere in this specification including examples of any term discussed herein is illustrative only and is not intended to further limit the scope and meaning of the disclosure or of any exemplified term. Likewise the disclosure is not limited to various embodiments given in this specification.

Without intent to further limit the scope of the disclosure examples of instruments apparatus methods and their related results according to the embodiments of the present disclosure are given above. Note that titles or subtitles may be used in the examples for convenience of a reader which in no way should limit the scope of the disclosure. Unless otherwise defined all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this disclosure pertains. In the case of conflict the present document including definitions will control.

