---

title: Image processing device, image processing method, and program
abstract: There is provided an image processing device including a moving image generation unit configured to generate a parallelly animated moving image in which a plurality of object images are each parallelly animated, the plurality of the object images having been selected from a series of object images that have been generated by extracting a moving object from frame images of a source moving image, and an image output unit configured to output the parallelly animated moving image.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09600160&OS=09600160&RS=09600160
owner: Sony Corporation
number: 09600160
owner_city: Tokyo
owner_country: JP
publication_date: 20141029
---
This application claims the benefit of Japanese Priority Patent Application JP 2013 254031 filed Dec. 9 2013 the entire contents of which are incorporated herein by reference.

The present disclosure relates to an image processing device an image processing method and a program.

Many technologies have been proposed to improve expressiveness of moving images. For example JP 2012 4739A corresponding U.S. publication US 2011 0305438 A1 describes a technology of improving usability for a user with respect to a playback operation such as playback pause frame by frame playback and pause release that are performed on moving image data. Such technologies improves the expressiveness of the moving images in terms of a playback capability by which the user can slowly play back a desired section of the moving image.

However for example in a case where a user wants to watch an identical section repeatedly it is necessary for the technology described in JP2012 4739 A to rewind the playback or to set the section to be repeatedly played back in response to a user operation. Even after the repeat playback is set re setting is necessary in a case of watching another section of the identical moving image repeatedly. Accordingly there is a room for improvement with respect to usability.

Accordingly in a nod to the above described situation the present disclosure proposes a novel and improved image processing device image processing method and program capable of enhancing expressiveness of moving images.

According to an embodiment of the present disclosure there is provided an image processing device including a moving image generation unit configured to generate a parallelly animated moving image in which a plurality of object images are each parallelly animated the plurality of the object images having been selected from a series of object images that have been generated by extracting a moving object from frame images of a source moving image and an image output unit configured to output the parallelly animated moving image.

According to another embodiment of the present disclosure there is provided an image processing method including generating a parallelly animated moving image in which a plurality of object images are each parallelly animated the plurality of the object images having been selected from a series of object images that have been generated by extracting a moving object from frame images of a source moving image and outputting the parallelly animated moving image.

According to another embodiment of the present disclosure there is provided a program for causing a computer to achieve a function of generating a parallelly animated moving image in which a plurality of object images are each parallelly animated the plurality of the object images having been selected from a series of object images that have been generated by extracting a moving object from frame images of a source moving image and a function of outputting the parallelly animated moving image.

By parallelly animating each of the plurality of object images a movement of an object in a certain section is expressed in a repeating manner at shorter intervals than a case of playing back the entire moving image repeatedly. According to the above described configuration expressiveness of moving images is enhanced by enabling such expression.

As described above according to one or more of the embodiments of the present disclosure it is possible to enhance expressiveness of moving images.

Hereinafter preferred embodiments of the present disclosure will be described in detail with reference to the appended drawings. Note that in this specification and the appended drawings structural elements that have substantially the same function and structure are denoted with the same reference numerals and repeated explanation of these structural elements is omitted.

First with reference to a schematic configuration according to an embodiment of the present disclosure is explained. In the present embodiment a terminal device used by a user is used as an image processing device. The terminal device may be a device having a camera function such as a digital camera a mobile phone including smart phone a tablet terminal or a portable game machine. In this case the terminal device can use a moving image captured by the camera function as a source of image processing described below. Alternatively the terminal device may be a device that does not have the camera function such as variety of PCs or media players. In this case the terminal device can use a moving image acquired from another device via a network as a source of the image processing. Note that in the case where the terminal device has the camera function this terminal device can also use a moving image acquired from another device via a network as a source of the image processing.

Note that such as a terminal device described below a hardware configuration of an information processing device according to the present embodiment is described below. The following software configuration and functional configuration may be achieved by a processor such as a central processing unit CPU of the information processing device unless otherwise specified.

In the present embodiment the image processing engine reads as a source a moving image captured by an imaging device included in the terminal device a moving image acquired by the terminal device from another device in a network or the like. Hereinafter such moving images are also referred to as source moving images. The image processing engine extracts a series of object images from a source moving image by executing image processing as described below. The series of object images are generated by extracting a moving object from a source moving image.

The application includes a graphical user interface GUI an engine controller an editor and an upload manager . For example the GUI causes a display of the terminal device to display an operation screen as described below and acquires a user operation performed on the operation screen the user operation using a touchscreen a mouse or the like. The engine controller inputs to the image processing engine an instruction to select a source or to execute processing on the basis of the user operation via the GUI . The editor edits a series of object images output from the image processing engine on the basis of a user operation via the GUI . For example the editor generates a parallelly animated moving image in which respective object images are parallelly animated the object images having been selected from a series of object images and the editor causes the display of the terminal device to display the generated moving image via the GUI as a preview. Alternatively the editor may generate a singly animated moving image in which a single object image is animated the single object image having been selected from the series of object images and the editor may display the generated moving image as a preview in similar way. For example by using an application programming interface API prepared as the SDK the upload manager enables an image generated by the application using functions such as the engine controller and the editor to be uploaded onto a server in a network or to be transmitted to another terminal device.

The SDK is a set of prepared software tools by which the application uses functions provided by an operating system OS for example. The SDK allows the application to use functions such as input output a file operation and communication in the terminal device for example.

The image analysis unit corresponds to the above described image processing engine for example. The image analysis unit generates a series of object images by extracting a moving object from frame images of a source moving image. The series of object image may be obtained by separating an image of a region in which a motion vector exceeds a threshold from a background image in the frame images. Note that variety of known technologies can be used for generating the series of object images and kinds of the known technologies are not particularly limited. In addition the region separated as the object image may substantially match with an outer shape of the moving object or may include the object and a background part adjacent to the object for example.

Moreover the image analysis unit may generate a background image in addition to the series of the object images. For example the background image is generated by extracting a region other than the object from one or plurality of frame images and by performing image composition as necessary. The background image may be displayed as a background of a moving image generated by the moving image generation unit for example.

In a case where the terminal device includes the imaging device in the present embodiment the image analysis unit may use a moving image captured by the imaging device as a source moving image. Alternatively the image analysis unit may use a moving image received from another device via the communication device as a source moving image. Alternatively the image analysis unit may use a recorded moving image delivered via the broadcasting wave or the like as a source moving image.

The image acquisition unit corresponds to the above described engine controller of the application for example. The image acquisition unit acquires a series of object images output from the image analysis unit . As described above the series of object images are generated by extracting a moving object from frame images of a source moving image. The image acquisition unit may further acquire a background image output from the image analysis unit . Note that in the present embodiment the image acquisition unit acquires a series of object images and a background image from the image analysis unit . However in another embodiment it is also possible for the image acquisition unit to acquire a series of object images and a background image via the communication unit from another device having functions similar to the image analysis unit . Alternatively the image acquisition unit may acquire a series of object images and a background image that have already been stored in a storage included in the terminal device .

The moving image generation unit corresponds to the above described editor of the application for example. The moving image generation unit selects a plurality of object images from a series of object images acquired by the image acquisition unit and generates a parallelly animated moving image in which each of the selected object images are parallelly animated. Alternatively the moving image generation unit selectively generates any one of the parallelly animated moving image and a singly animated moving image in which a single object image is animated the single object image having been selected from the series of object images acquired by the image acquisition unit . Here the one or plurality of object images that are animated in the parallelly animated moving image and or the singly animated moving image may be displayed in a manner that the one or plurality of object images are overlaid on a common background image acquired by the image acquisition unit .

The image output unit corresponds to the above described editor of the application for example. The image output unit outputs a moving image generated by the moving image generation unit . For example the image output unit outputs a parallelly animated moving image in a case where the moving image generation unit generates only the parallelly animated moving image. Alternatively the image output unit outputs any one of a parallelly animated moving image and a singly animated moving image in a case where the moving image generation unit selectively generates any one of the parallelly animated moving image and the singly animated moving image.

The display control unit corresponds to the above described the GUI of the application for example. The display control unit causes the display unit that is a display included in the terminal device for example to display a moving image output from the image output unit . At this time the display control unit may cause the display unit to display an operation element such as a button or a slider for editing as described below in addition to the moving image. A user operation performed on such operation elements may be acquired by the operation unit including the touchscreen the mouse and the like of the terminal device for example. On the basis of this operation the moving image generation unit may regenerate a moving image. That is the display control unit causes the display unit to display a moving image as a preview image which can be further edited. Note that a detail of edit processing using the preview image is described later.

The communication unit corresponds to the above described upload manager of the SDK for example. Via the communication device of the terminal device the communication unit uploads a moving image output by the image output unit onto the server in the network or transmits the moving image to another terminal device. Here it is decided whether the generated moving image is further edited or is transmitted via the communication unit on the basis of a user operation performed on an operation element on the display unit the user operation having been acquired by the operation unit . Note that according to another embodiment the moving image output from the image output unit may be stored in the storage instead of being transmitted via the communication unit and then may be viewed or transmitted later.

For example in the terminal device the image acquisition step S is executed by capturing of the moving image performed by the imaging device reception of the moving image performed by the communication device or recording of the moving image delivered via the broadcasting wave. Alternatively the moving image may be read from a local storage such as an HDD of the terminal device . Frame images D of the moving image source moving image acquired in this step are stored in the storage.

Next the analysis step S is executed by the image analysis unit of the terminal device . As explained above in this step a series of object images D are generated by extracting a moving object from frame images D of a source moving image. In addition in this analysis step S a background image D may be generated by extracting a region other than the object image from any one of the frame images or by compositing the regions other than the object images extracted from the frame images.

Next the moving image generation step S is executed by the moving image generation unit of the terminal device . In this step the moving image is generated by using the series of object images background image D . As already explained about the moving image generation unit the moving image may be a parallelly animated moving image in which a plurality of object images are parallelly animated the plurality of object images having been selected from the series of object images D or may be a singly animated moving image in which a single object image is animated the single object image having been selected from the series of object images D . The generated moving image is output by the image output unit .

Next the preview step S is executed by the display control unit and the display unit of the terminal device . In this step the moving image generated in the moving image generation step S is presented to the user as the preview image. The user who has referred to the preview image decides whether to further make a change to the moving image or to perform upload of the moving image onto the server transmission of the moving image to another terminal device or storing of the moving image in the storage and then the user performs an operation input for doing that on the operation unit .

In a case where the user operation input acquired by the operation unit has instructed to further make the change to the moving image in the above described preview step S the moving image generation step S is executed again under a condition designated by the user operation input. Data to be referred to at this time is the already extracted object images background image D . As described later the change to be further made in the preview step S in the present embodiment is change in the single or plurality of object images selected for the moving image generation performed by the moving image generation unit or change in a playback speed for example. Accordingly in the case where the moving image generation step S is executed again it is possible to reuse the already extracted object images background image D and the analysis step S does not have to be executed gain.

In this way according to the present embodiment it is possible to reduce a computational cost for executing the moving image generation step S and the preview step S so as to save a system resource and it is also possible to quickly display the regenerated image. As a result according to the present embodiment it is possible to easily execute edit and preview of the moving image any number of times and it is possible to make the moving image with which the user is satisfied.

In a case where the user operation input acquired by the operation unit has instructed to perform upload transmission or storage of the generated moving image in the above described preview step S the storage transmission step S is executed. In this step the generated moving image is transmitted or stored as moving image data D to be transmitted including to be uploaded or to be stored.

Note that a format of the moving image data S is not particularly limited. As the format it is possible to use not only a general format of moving image but also variety of formats such as the graphics interchange format GIF and Flash registered trademark . As described later the moving image may be continuous shooting images in a case where its frame rate is low. Accordingly a format of the date to be output is also not limited to formats of moving image.

Next with reference to an example of generation of a moving image parallelly animated moving image in which a plurality of object images are parallelly animated according to an embodiment of the present disclosure is explained.

The source moving image includes frame images . Note that in a case where a frame rate is low the frame images may be read as continuous shooting images. In the diagrams the frame images marked with number to number are shown.

The analyzed image includes object images . The object images are extracted from respective frame images of the source moving image for example. More specifically the object images may be images obtained by separating a region in which a motion vector exceeds a threshold from a background image other than the region the motion vector having been calculated from each of the frame images . In the diagram the object images marked with FG to FG are shown. Note that the object images are also referred to as foreground FG images since the object images are foreground that is in front of the background BG image .

The analyzed image further includes the background image BG . As described above the background image may be a region other than an object extracted from any one of the frame images or may be an image generated by compositing regions other than the object images extracted from the plurality of frame images for example.

Hereinafter the example of generation of a moving image is explained using the object images and the background image that have been extracted from the source moving image in the example in . Needless to say the number of frame images may be far more than 16 frame images shown in the diagram. Accordingly the object images may also be generated far more than 16 object images. However the object images do not have to respectively correspond with the frame images . For example an object image may be extracted from a plurality of frame images .

Moreover only one background image is not necessarily generated. For example in a case where the playback time of the source moving image is long and the background in the frame images greatly changes it may be possible to generate a plurality of background images and to use the background images in order according to change in the backgrounds in the frame images corresponding to respective object images .

The illustrated parallelly animated moving image includes a frame image to a frame image . Such frame images are temporally continuous frame images and such frame images configure the parallelly animated moving image by being continuously played back at a predetermined frame rate. Note that in a case where a frame rate is low the moving image may be recognized as continuous shooting images. Here the frame image is set as an initial frame image in the parallelly animated moving image . The parallelly animated moving image may include additional frame image following after the illustrated four frame images.

In the frame image object images FG FG FG FG FG and FG that have been overlaid on the background image BG are shown. Such object images have been selected from the series of object images object images FG to FG shown in . In addition in the example shown in the diagram every third object image is selected from the series of object images.

In the next frame image object images FG FG FG FG and FG that have been overlaid on the identical background image BG are shown. Such object images are object images each of which proceeds by one frame in the source moving image from the respective object images shown in the frame image . In a similar way in the frame image object images FG FG FG FG and FG that have been overlaid on the background image BG are shown. In addition in the frame image object images FG FG FG FG FG and FG that have been overlaid on the background image BG are shown.

When the frame image to the frame image are continuously played back the object image FG displayed in the frame image is displayed in a manner that FG sequentially changes into FG FG and FG in the frame image to the frame image . This change is identical to change in images that is observed when a series of object images is played back while the object image is set as a starting point. That is in the parallelly animated moving image the object image is animated. In the present specification sequential playback of a plurality of images is referred to as being animated the plurality of images having been captured in chronological order. In a case where the entire frame image is animated a moving image or continuous shooting images is played back. In a case where an object image overlaid on the common background image is animated an image of a region this region differs from one object image to another of an object to be a foreground of the background image is sequentially played back in chronological order.

In a way similar to the object image the object images and FG FG FG and FG that have been displayed in the frame image are sequentially changed and displayed in the frame image to frame image . Accordingly in the illustrated example it can be said that each of the object images to is parallelly animated in the parallelly animated moving image the object images to having been selected from the series of object images.

Note that such object images have been selected from the series of common object images. Accordingly for example when the playback of the parallelly animated moving image progresses an object image displayed after the object image FG reaches the image FG displayed as the object image in the frame image . Accordingly it can be said that the display of the object images in each frame image is parallelly animated display of the series of object images performed by setting the object images as starting points.

For example as known from the example shown in where FG of the object images is displayed again in the frame image the object images displayed in the parallelly animated moving image do not flow off but may be repeatedly displayed without end. Accordingly for example after the object image displayed in starts to move display of a new object image image identical with the object image may be stared at a time when the object image matches with the object image that is at the start of display.

In the above explained parallelly animated moving image according to the embodiment of the present disclosure a plurality of object images selected from a series of object images are parallelly animated. Accordingly for example it becomes easy to observe a particular part of movement of the object represented by the series of object images. In a case of a moving image in which a single object image is animated a particular part of movement of the object is not played back again until the playback is repeated automatically or in response to a user operation after the particular part is once played back. On the other hand in a case of the parallelly animated moving image it is repeated that a certain object image plays back a particular part of movement of its object and then another object image plays back the corresponding part. Such moving image may be useful when checking a sports form or a dance form for example. More specifically for example in the example in every third object images to displayed in the frame image each proceed by four frames. As a result in the frame image an object image sequentially displayed after the object image reaches FG that has been displayed as the object image in the frame image and an object image sequentially displayed after the object image reaches FG that has been displayed as the object image in the frame image . In addition a second last object image FG from FG is newly displayed similar ways can be applied to the object images to . As a result the frame image is the image identical with the frame image . With regard to subsequent frame images patterns identical with the frame image to frame image are repeated. In this way movement of an object can be played back in a time corresponding to three frames in the parallelly animated moving image of the example shown in although the movement of the object is played back in a time corresponding to 16 frames in a source moving image. Accordingly for example it becomes easy for a user to repeatedly observe a particular part of movement of an object. In addition a file size of the moving image can be reduced. More specifically the parallelly animated moving image of the example in can reuse the frame image to frame image after the frame image . Accordingly the parallelly animated moving image includes data for only three frames although a moving image in which a single object image is animated includes data for 16 frames.

Moreover for example in a case where the object image represents a person in the parallelly animated moving image a comical scene can be represented since it appears that a plurality of people repeats an identical movement. For example more comical moving image can be generated if the moving image generation unit plays back a moving image at high speed or plays back the moving image in reverse in response to a user operation acquired by the operation unit .

Note that in the above example the moving image generation unit selects the plurality of object images from the series of object images at fixed intervals every third object image . However the embodiment of the present disclosure is not limited to such example.

For example the moving image generation unit may set intervals for example time or the number of frames for selecting a plurality of object images in accordance with a movement speed of an object in a source moving image. More specifically for example in a case where the movement speed of the object is high that is in a case where spatial intervals between original object images are large the object images may be selected at shorter intervals. Alternatively for example in a case where the movement speed of the object is low that is in a case where spatial intervals between the original object images are small the object images may be selected at longer time intervals. Accordingly distance between object images displayed in the parallelly animated moving image can be maintained to be an appropriate distance for example distance in which the object images are not overlaid with each other too much and there is not too much space between the object images regardless of the moving speed of the object.

A playback speed frame rate of the generated moving image may also be variable. For example as described above playback in high speed or reverse playback that are based on a user operation can be possible. In addition the moving image generation unit may set a playback speed of the parallelly animated moving image in accordance with length of the source moving image. In this case for example the playback speed becomes fast when the source moving image is long and the playback speed becomes slow when the source moving image is short.

As a result for example any parallelly animated moving image can be played back in a subequal time regardless of length of the source moving images.

Next with reference to an example of generation of a moving image singly animated moving image in which a single object image is animated according to an embodiment of the present disclosure is explained. Note that a series of object images to be used for generating a moving image is similar to the example of the parallelly animated moving image. Accordingly repeated explanation is omitted.

The illustrated singly animated moving image includes a frame image to a frame image . Such frame images are temporally continuous frame images. The singly animated moving image is generated by continuously playing back the frame images at a predetermined frame rate. Note that in a case where a frame rate is low the moving image may be recognized as continuous shooting images. Here the frame image is set as an initial frame image in the singly animated moving image . The singly animated moving image may include additional frame image following after the illustrated eight frame images.

In the frame image an object image FG overlaid on a background image BG are shown. Here the single object image has been selected from the series of object images object images FG to FG shown in .

In the next frame image an object image FG overlaid on the identical background image BG is shown. This object image is an object image which proceeds by one frame in the source moving image from the object image shown in the frame image . In addition the object image of FG may remain displayed as an effect of an afterimage. In a similar way in the frame image object images FG and FG that are overlaid on the background image BG are shown. In the frame image object images FG and FG that are overlaid on the background image BG are shown.

When the frame image to the frame image are continuously played back the object image FG displayed in the frame image is displayed in a manner that FG sequentially changes into FG FG and FG in the frame image to the frame image . This change is identical to change in images that is observed when a series of object images are played back while the object image is set as a starting point. That is with regard to this moving image it can be said that the object image is animated.

In contrast to the above described parallelly animated moving image only a single object image is animated in the singly animated moving image shown in the example in . For example in the frame images to the object image FG and the object images FG to FG are displayed together. However the object image FG is being displayed as the effect of the afterimage and remains stationary. After the frame image the object image FG is additionally displayed as an afterimage. After the frame image the object image FG is additionally displayed as an afterimage. Accordingly four object images are displayed together after the frame image . However only an object image FG in a case of frame image displayed subsequent to the object image remains animated.

In the above explained singly animated moving image according to the embodiment of the present disclosure only a single object image selected from a series of object images is animated. Accordingly it takes time to express entire movement of an object in the generated moving image. On the other hand the displayed object images are not overlaid on each other except the case an object image is displayed as an effect of afterimage such as the above described example in the singly animated moving image. Accordingly the singly animated moving image is suitable for a case where a single object moves without changing its place widely for example. Accordingly the moving image generation unit and the image output unit may switch a moving image to be generated and output in response to a user operation or in accordance with a movement amount of an object for example.

For example the moving image generation unit may generate a parallelly animated moving image if a movement amount of an object in a source moving mage exceeds a threshold and the moving image generation unit may generate a singly animated moving image if not. Here the movement amount is a movement amount of an object in images from start to end of a series of object images which may be corresponding to time period from start to end of a source moving image for example. For a case where the movement amount of the object is large the parallelly animated moving image is suitable the parallelly animated moving image being able to express entire movement of an object in a short time by simultaneously displaying and animating a plurality of object images. On the other hand in a case where the movement amount of the object is small it may be difficult to view the plurality of object images since the object images are simultaneously animated and overlaid on each other. Accordingly for this case the singly animated moving image in which the object images are displayed basically without being overlaid on each other is suitable 

Moreover for example the moving image generation unit may generate a parallelly animated moving image if there are a plurality of objects in a source moving image and the moving image generation unit may generate a singly animated moving image if not. In a case where there are a plurality of objects for example afterimages of object images are displayed as effects like the example of the singly animated moving image shown in . Accordingly a temporally posterior object image is displayed in foreground and a temporally anterior object image is hidden. On the other hand displayed object images are each animated in the parallelly animated moving image. Accordingly some images do not remain hidden and both temporally posterior object image and temporally anterior object image can be viewed.

Next with reference to an example of a GUI according to an embodiment of the present disclosure is explained. is a diagram illustrating the example of the GUI according to the embodiment of the present disclosure.

With reference to the display control unit in the terminal device causes the display unit to display a GUI screen including a slider a switch button a seek bar a playback speed display an effect list display button a reshooting button and a store share button . An operation input performed on the GUI screen by a user is acquired by a touchscreen included in the operation unit for example.

The slider is shared for setting of the playback speed of a moving image and setting of intervals for selecting a plurality of object images from a series of object images the settings being for generation of the parallelly animated moving image. For example in the shown example the slider is illustrated as a slider between and . In a case where the slider is used for setting the playback speed the playback speed becomes high when the slider approaches a side and the playback speed becomes low when the slider approaches a side. Here by operating the slider to approach the side it may be possible to decrease the playback speed from a forward playback region to a reverse playback region that is less than 0.

In a case where the slider is used for setting predetermined intervals the intervals become small object images are displayed more close with each other when the slider approaches the side and the intervals become large the object images are displayed more far from each other when the slider approaches the side. Alternatively in contrast to the above example it may be possible that the intervals become large when the slider approaches the side and the intervals become small when the slider approaches the side when the predetermined intervals are set.

The switch button is an example of operation elements for switching functions of the slider between setting of the playback speed and setting of the predetermined intervals. In the shown example a switch button represents a state where the setting of the playback speed is selected and a switch button represents a state where the setting of the predetermined intervals is selected.

As another example the switch button may be replaced with a switch tab as shown in . In the shown example a switch tab represents a state where the setting of the predetermined intervals is selected and a switch tab represents a state where the setting of the playback speed is selected.

The seek bar represents a playback position of a moving image during preview. The playback speed display represents a playback speed of the moving image during preview. Accordingly when operating the slider after selecting a setting function for a playback speed by using the switch button the playback speed of a moving image during preview is changed and the playback speed display is changed. Note that as an additional configuration it may be possible to change the playback speed of the moving image by using a direction display displayed at opposite sides of the playback speed display in the shown example the direction display represents a direction along the seek bar .

The effect list display button is a button for displaying a list used for selecting various effects to be applied to the moving image. For example the effects may include switch between the parallelly animated moving image in which a plurality of object images are parallelly animated and the singly animated moving image in which a single object is animated performed by a user operation existence or non existence of an afterimage in the singly animated moving image a fade effect applied to an object image to be displayed and a setting of a time range in which an object image is animated.

The reshooting button is a button for storing or abandoning a moving image during preview and shooting a new source moving image. The reshooting button may be displayed in a case where the terminal device has a shooting function for example.

The store share button is a button for storing or sharing a moving image during preview. When the store share button is operated the moving image is stored in a storage in the terminal device or a storage in a network or the moving image is uploaded onto a server for sharing moving images via the communication unit for example.

By using the above explained GUI the user can set intervals between object images to be parallelly animated in a moving image and can set a playback speed of the moving image via a few operation parts for example. As a result for example the operation parts displayed in the GUI screen is simplified and an area in which a moving image is displayed to be previewed can be widened.

Next with reference to a hardware configuration of an information processing device according to an embodiment of the present disclosure is explained. is a block diagram showing a hardware configuration example of an information processing device according to the embodiment of the present disclosure. A shown information processing device may achieve the terminal device according to the embodiments of the present disclosure for example.

The information processing device includes a central processing unit CPU read only memory ROM and random access memory RAM . In addition the information processing device may include a host bus a bridge an external bus an interface an input device an output device a storage device a drive a connection port and a communication device . Moreover the information processing device may include an imaging device and a sensor as necessary. The information processing apparatus may include a processing circuit such as a digital signal processor DSP or an application specific integrated circuit ASIC alternatively or in addition to the CPU .

The CPU functions as an operation processor and a controller and controls all or some operations in the information processing apparatus in accordance with various programs recorded in the ROM the RAM the storage device or a removable recording medium . The ROM stores programs and operation parameters which are used by the CPU . The RAM temporarily stores program which are used in the execution of the CPU and parameters which are appropriately modified in the execution. The CPU ROM and RAM are connected to each other by the host bus including an internal bus such as a CPU bus. In addition the host bus is connected to the external bus such as a peripheral component interconnect interface PCI bus via the bridge .

The input device is a device which is operated by a user such as a mouse a keyboard a touchscreen buttons switches and a lever. The input device may be for example a remote control unit using infrared light or other radio waves or may be an external connection device such as a portable phone operable in response to the operation of the information processing apparatus . Furthermore the input device includes an input control circuit which generates an input signal on the basis of the information which is input by a user and outputs the input signal to the CPU . By operating the input device a user can input various types of data to the information processing apparatus or issue instructions for causing the information processing apparatus to perform a processing operation.

The output device includes a device capable of visually or audibly notifying the user of acquired information. The output device may be a display device such as a liquid crystal display LCD a plasma display panel PDP and an organic electro luminescence EL displays an audio output device such as a speaker or a headphone or a printer for example. The output device may output the results obtained from the process of the information processing apparatus in a form of a video such as text or an image and an audio such as voice or sound.

The storage device is a device for data storage which is configured as an example of a storage unit of the information processing apparatus . The storage device includes for example a magnetic storage device such as a hard disk drive HDD a semiconductor storage device an optical storage device or a magneto optical storage device. The storage device stores programs to be executed by the CPU various data and data obtained from the outside.

The drive is a reader writer for the removable recording medium such as a magnetic disk an optical disk a magneto optical disk or a semiconductor memory and is embedded in the information processing apparatus or attached externally thereto. The drive reads information recorded in the removable recording medium attached thereto and outputs the read information to the RAM . Further the drive writes in the removable recording medium attached thereto.

The connection port is a port used to directly connect devices to the information processing apparatus . The connection port may be a universal serial bus USB port an IEEE1394 port and a small computer system interface SCSI port for example. The connection port may also be an RS 232C port an optical audio terminal a high definition multimedia interface HDMI port and so on. The connection of the external connection device to the connection port makes it possible to exchange various data between the information processing apparatus and the external connection device .

The communication device is for example a communication interface including a communication device or the like for connection to a communication network . The communication device may be for example a communication card for a wired or wireless local area network LAN Bluetooth registered trademark wireless USB WUSB or the like. In addition the communication device may be a router for optical communication a router for Asymmetric Digital Subscriber Line ADSL a modem for various kinds of communications or the like. The communication device can transmit and receive signals to and from for example the Internet or other communication devices based on a predetermined protocol such as TCP IP. In addition the communication network connected to the communication device may be a network or the like connected in a wired or wireless manner and may be for example the Internet a home LAN infrared communication radio wave communication satellite communication or the like.

The imaging device is a device that generates an image by imaging a real space using an image sensor such as a charge coupled device CCD or a complementary metal oxide semiconductor CMOS sensor as well as various members such as one or more lenses for controlling the image formation of a subject image on the image sensor for example. The imaging device may be a device that takes still images and may also be a device that takes moving images.

The sensor is any of various sensors such as an acceleration sensor a gyro sensor a geomagnetic sensor an optical sensor or a sound sensor for example. The sensor acquires information regarding the state of the information processing apparatus such as the orientation of the case of the information processing apparatus as well as information regarding the environment surrounding the information processing apparatus such as the brightness or noise surrounding the information processing apparatus for example. The sensor may also include a Global Positioning System GPS sensor that receives GPS signals and measures the latitude longitude and altitude of the apparatus.

In the embodiments of the present disclosure the information processing device does not have to include the sensor . However in a case where the information processing device includes the sensor location information on an original moving image can be attached to a file of an output image when the location information has been recorded using a GPS at a time when the moving image has been shot so as to upload or store the output image to or in the storage for example. In addition for example it is possible to detect an attribute of a case of the information processing device by using the acceleration sensor and to decide a display direction of an image to be displayed as a GUI or layout of an operator. In addition when a tilt effect is applied to the display object image as shown in a tilt of a case of the information processing device may be reflected in an effect the tilt having been detected by the acceleration sensor or the gyro sensor.

The example of the hardware configuration of the information processing apparatus has been explained. Each of the above components may be realized using general purpose members but may also be realized in hardware specialized in the function of each component. Such a configuration may also be modified as appropriate according to the technological level at the time of the implementation.

In the above described embodiments the example that the terminal device functions as the image processing device including the image acquisition unit the moving image generation unit the image output unit and the like has been explained. However the embodiment of the present disclosure is not limited to such example. For example the functions of the image processing device may be achieved by a server including one or plurality of information processing devices in a network. In this case for example the server may perform image analysis on a source moving image received from the terminal device extract a series of object images select a plurality of object images from the series of object images generate a moving image in which the plurality of display object images are parallelly animated and transmit the moving image as a preview image to the terminal device. It is also possible for the server to reselect a plurality of object images to be animated in response to an operation input received from the terminal device or to change a playback speed and then to transmit a new preview image to the terminal device for example. In addition the server stores or transmits the generated moving image in response to an operation input received from the terminal device.

The embodiments of the present disclosure can include for example the image processing apparatus the system the image processing method executed in the image processing device or the system which are described above a program for causing the image processing device to function and a non transitory tangible medium having a program stored therein.

Although the preferred embodiments of the present disclosure have been described in detail with reference to the appended drawings the present disclosure is not limited thereto. It should be understood by those skilled in the art that various modifications combinations sub combinations and alterations may occur depending on design requirements and other factors insofar as they are within the scope of the appended claims or the equivalents thereof.

a moving image generation unit configured to generate a parallelly animated moving image in which a plurality of object images are each parallelly animated the plurality of the object images having been selected from a series of object images that have been generated by extracting a moving object from frame images of a source moving image and

wherein the moving image generation unit selectively generates any one of the parallelly animated moving image and a singly animated moving image in which a single object image is animated the single object image having been selected from the series of object images.

wherein the moving image generation unit generates the parallelly animated moving image in a case where a movement amount of the object exceeds a threshold.

wherein the moving image generation unit generates the parallelly animated moving image in a case where the plurality of objects exist.

wherein the moving image generation unit selects the plurality of object images from the series of object images at predetermined intervals.

wherein the moving image generation unit sets the predetermined intervals in accordance with a movement speed of the object.

wherein the moving image generation unit sets the predetermined intervals in accordance with a user operation.

wherein the moving image generation unit sets a playback speed of the parallelly animated moving image in accordance with a user operation.

wherein the moving image generation unit sets the playback speed within a range including a reverse playback region.

a display control unit configured to cause a display unit to display a graphical user interface GUI that receives the user operation for setting the playback speed.

wherein the moving image generation unit selects the plurality of object images from the series of object images at predetermined intervals set in accordance with a user operation.

wherein the GUI includes a slider shared for setting of the playback speed and setting of the predetermined intervals and an operation element for switching functions of the slider.

wherein the moving image generation unit sets a playback speed of the parallelly animated moving image in accordance with length of the source moving image.

generating a parallelly animated moving image in which a plurality of object images are each parallelly animated the plurality of the object images having been selected from a series of object images that have been generated by extracting a moving object from frame images of a source moving image and

selectively generating any one of the parallelly animated moving image and a singly animated moving image in which a single object image is animated the single object image having been selected from the series of object images.

generating the parallelly animated moving image in a case where a movement amount of the object exceeds a threshold.

a function of generating a parallelly animated moving image in which a plurality of object images are each parallelly animated the plurality of the object images having been selected from a series of object images that have been generated by extracting a moving object from frame images of a source moving image and

a function of selectively generating any one of the parallelly animated moving image and a singly animated moving image in which a single object image is animated the single object image having been selected from the series of object images.

a function of generating the parallelly animated moving image in a case where a movement amount of the object exceeds a threshold.

