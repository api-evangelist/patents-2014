---

title: Graphical user interfaces including touchpad driving interfaces for telemedicine devices
abstract: The present disclosure describes various aspects of remote presence interfaces (RPIs) for use on portable electronic devices (PEDs) to interface with remote telepresence devices. An RPI may allow a user to interact with a telepresence device, view a live video feed, provide navigational instructions, and/or otherwise interact with the telepresence device. The RPI may allow a user to manually, semi-autonomously, or autonomously control the movement of the telepresence device. One or more panels associated with a video feed, patient data, calendars, date, time, telemetry data, PED data, telepresence device data, healthcare facility information, healthcare practitioner information, menu tabs, settings controls, and/or other features may be utilized via the RPI.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09361021&OS=09361021&RS=09361021
owner: INTOUCH TECHNOLOGIES, INC.
number: 09361021
owner_city: Goleta
owner_country: US
publication_date: 20141121
---
This U.S. patent application is a continuation of PCT Application No. PCT US2013 031743 the PCT application which application is hereby incorporated by reference it is entirety. This U.S. patent application and the PCT application also claim priority under 35 U.S.C. 119 e to U.S. Provisional Application No. 61 650 205 filed May 22 2012 titled Remote Presence Interface and Patient Data Integration U.S. Provisional Application No. 61 674 794 filed Jul. 23 2012 titled Graphical User Interfaces Including Touchpad Driving Interfaces for Telemedicine Devices U.S. Provisional Application No. 61 674 796 filed Jul. 23 2012 titled Clinical Workflows Utilizing Autonomous and Semi Autonomous Telemedicine Devices U.S. Provisional Application No. 61 674 782 filed Jul. 23 2012 titled Behavioral Rules For a Telemedicine Robot To Comply With Social Protocols U.S. Provisional Application No. 61 766 623 filed Feb. 19 2013 titled Graphical User Interfaces Including Touchpad Driving Interfaces for Telemedicine Devices which applications are all hereby incorporated by reference in their entireties.

This disclosure relates to interactive and display interfaces for telepresence devices in healthcare networks. More specifically this disclosure provides various graphical user interfaces and interactive interfaces for remote presence devices.

The described features structures and or characteristics of the systems and methods described herein may be combined in any suitable manner in one or more alternative embodiments and may differ from the illustrated embodiments.

Healthcare facilities may include telemedicine technologies such as telepresence devices in a telepresence network that allow remote healthcare practitioners to provide services to patients and or other healthcare practitioners in remote locations. For example a remote healthcare practitioner may be a neurologist practicing in a relatively large hospital who may via a telepresence device provide services and consultations to patients and or other medical professionals in a relatively small hospital that may otherwise not have a neurologist on staff.

The present disclosure provides various interfaces for visualizing controlling and driving telepresence devices. In a remote presence RP system a telepresence device such as an autonomous or semi autonomous robot may communicate with an interfacing device via a communications network. In various embodiments a portable electronic device PED may be used to run a remote presence interface RPI adapted to provide various telepresence functions.

In various embodiments an RPI application may be executed on a device configured as a stand alone PED configured to solely run the RPI application. Alternatively the RPI application may be executed by any of a wide variety of PEDs configured as multi purpose PEDs such as the Apple iPad . In various embodiments a user may launch an RPI application and login using login credentials. The login process may utilize any of a wide variety of encryption algorithms and data protection systems. In various embodiments the login process may meet or exceed standards specified for Health Insurance Portability and Accountability Act HIPAA compliance.

A user may select one or more endpoint telepresence devices via the RPI. Once a secure connection is established the RPI may display a video feed from the telepresence device on the PED. In addition the RPI may include any number of navigational panels setting controls telemetry data displays map views and or patient information displays.

In some embodiments the RPI may allow a user to manually semi autonomously or autonomously control the movement of the telepresence device. The RPI may allow a user to specify movement i.e. a location within a healthcare facility or a physical movement such as a head turn of the telepresence device using a destination selection panel an arrow a physical or virtual joystick a touch pad click to destination vector based driving mouse based vector driving and or other navigational control.

For example a user may provide a navigation input by selecting a location within a live video feed e.g. via a click or a touch . The navigation input may be used to transmit navigation instructions to a remote telepresence device. For instance in a click drive mode the selection of a location within the live video feed may be used to navigate the telepresence device to the selected location. The selection of a location on a floor or hallway may result in navigation instructions that cause the telepresence robot to autonomously or semi autonomously navigate to the selected location.

In some embodiments an operator may input a navigation input in the form a navigation vector provided e.g. drawn traced mapped with respect to the live video feed. The navigation vector may include a length on the display and or other input device e.g. touchpad and an angle with respect to plane of the display and or other input device. As an example a plane of the display and or other input device may be described with a Cartesian coordinate system as having an x axis and a y axis. The navigation vector may be provided with respect to the display plane and described as having an x axis component horizontal direction and a y axis component vertical direction .

According to various embodiments a navigation input provided as a navigation vector may be decomposed into a horizontal x axis component and a vertical y axis component. The length and sign i.e. positive or negative value of the horizontal component of the navigation vector may be used to determine a magnitude and direction of a rotational velocity and or an angular displacement of a telepresence device. The length of the vertical component of the navigation vector may be used to determine the magnitude of a forward velocity and or a forward displacement of a telepresence device.

The length of the horizontal component may be used to determine the magnitude of the rotational velocity and or angular displacement using a scaling function. The scaling function may be constant linear and or non linear. Thus using a non linear scaling function a first horizontal component twice as long as a second horizontal component may not result in a first rotational velocity double that of the second rotational velocity. Similarly the length of the vertical component may be used to determine the magnitude of the forward velocity and or forward displacement using a scaling function. Again the scaling function may be constant linear and or non linear. The scaling function used to translate the horizontal component may be different than the scaling function used to translate the vertical component.

Alternatively selectively and or in a different navigation mode the selection of a location within the live video feed may be used to generate a navigation vector where the length of the vector corresponds to the velocity at which the telepresence device should navigate and or the distance the telepresence device should navigate and the angle of the vector corresponds to the direction the telepresence device should navigate. For instance a navigation input may be in the form of a vector drawn as either a final endpoint selection or as a vector including a beginning point and an end point. The end point of the vector may represent the location to which the telepresence device should navigate i.e. a desired navigation point . Navigation instructions may be generated based on the current location of the telepresence device and the endpoint of the vector within the live video feed. According to some embodiments the vector s image pixel endpoint may be mapped via a lookup table to one or more translate and rotate commands to cause the telepresence device to navigate to the selected location. In some embodiments the length of the vector may correspond to the desired distance to move the telepresence device a desired acceleration of the telepresence device and or a desired velocity of the telepresence device.

As an example a navigation input may be received that directs a telepresence device to navigate forward with respect to the live video feed 3 meters and to the right 2 meters. Any of a wide variety of navigation instructions may be possible to correctly navigate the telepresence device. For instance the navigation instructions may direct the telepresence device to navigate approximately 3.6 meters at a 34 degree angle relative to the video feed. Alternatively the navigation instructions may direct the telepresence device to navigate 3 meters forward and then 2 meters to the right. As will be appreciated any number of navigations routes and corresponding navigation instructions may be possible. The navigation input may be translated into navigation instructions as a plurality of drive forward commands coupled with rotate commands.

In various embodiments the navigation instructions are derived from a navigation input indicating a desired direction and or location and the current location of the telepresence device. In some embodiments the live video feed may be delayed slightly due to network and or processing limitations. For example a live video feed may be delayed by a few tenths of a second or even by a few seconds. This video latency may result in inaccurate navigation instructions. Accordingly the navigation input may be adjusted based on the known video latency and the velocity and direction of the robot.

Returning to the example above if the telepresence device were traveling at 1.25 meters per second in a forward direction relative to the live video feed and the video latency was 0.8 seconds then the telepresence device will have already traveled 1 of the desired 3 meters when the selection is made. Accordingly the selection of a location 3 meters ahead and 2 meters to the right may be translated or mapped to navigation instructions that cause the telepresence device to travel 2 meters forward and 2 meters to the right or 2.8 meters at a 45 degree angle to compensate the movement of the telepresence device. Thus the navigation instructions may be adjusted based on the latency of the video feed.

In various embodiments a navigation input in the form of a vector such as a vector provided in a mouse based vector input mode may be translated into navigation instructions through the use of a lookup table. In some embodiments the lookup table may include values that compensate for latency. That is the navigation instructions returned by the lookup table may be based on the navigation input and the current or recent average video latency.

Various alternative navigation systems methods and processing steps may be used in conjunction with the presently described remote presence interface including those described in U.S. Pat. No. 6 845 297 titled Method and System for Remote Control of Mobile Robot filed on Jan. 9 2003 and European Patent No. 1279081 titled Method and System for Remote Control of Mobile Robot filed on May 1 2001 which applications are hereby incorporated by reference in their entireties.

The RPI may provide various notifications associated with the network connection the PED a patient a healthcare facility a healthcare practitioner a telepresence device and or the like. The RPI may include a media management module configured to allow a user to record and or store audio and or visual data for subsequent use. A settings panel may allow settings on the PED and or the telepresence device to be adjusted. In some views multiple windows may provide quick access to various panels of information. For example one or more panels associated with a video feed patient data calendars date time telemetry data PED data telepresence device data healthcare facility information healthcare practitioner information menu tabs settings controls and or other features may be displayed simultaneously and or individually in a full screen mode.

The RPI may utilize a camera of the PED to capture an image of the user of the PED and project the image on a screen on the telepresence device. In some embodiments the image on the screen of the telepresence device may be modified and or enhanced. In one embodiment an avatar representing the user of the PED is displayed on the PED. In some embodiments the RPI may encourage or induce a user to utilize the PED with a front facing camera at or above eye level. Similarly the RPI may encourage or induce a user to utilize the PED with a front facing camera approximately centered on a user s face. For instance on an Apple iPad the RPI may encourage a user to utilize the iPad in a portrait mode for many tasks in order to maintain a more natural perspective of the user for projection via the screen on the telepresence device.

In various embodiments the RPI may facilitate conference sessions with more than two people interacting via a combination of PEDs and or telepresence devices. For example multiple healthcare practitioners may participate in a remote consultation. In such an example each healthcare practitioner may utilize an RPI on a PED to access a telepresence device at a bedside of a patient. The remote presence system via the network servers RPIs and or telepresence devices may facilitate the multi user experience.

The RPI may incorporate sub applications and or provide access to related applications such as a StrokeRESPOND application configured to provide one or more functions and or workflow processes described in U.S. patent application Ser. No. 12 362 454 titled DOCUMENTATION THROUGH A REMOTE PRESENCE ROBOT filed on Jan. 29 2009 which application is hereby incorporated by reference in its entirety.

As described herein and illustrated in various embodiments the display of a PED may be utilized by the RPI to display any combination of video feed panels informational panels data panels setting control panels navigation panels and or panels providing access to any of various functions made accessible via the RPI. The RPI may be configured to maintain a stateful connection at the application layer such that a session and or variables may be continued and or maintained in the event that the connection is lost or dropped. The RPI application may attempt to re establish a disconnected session using saved or logged variables in the event a connection is lost or dropped. The PED and or RPI application may have settings that enable a user to maximize frame rate or image quality at the expense of the battery life of the device or vice versa.

The RPI may include an information bar status bar that displays various status information related to the PED including battery life wireless connection strength wireless connection name or SSID or the current time. The RPI may include one or more toolbars. A toolbar may be disposed along the top edge of the upper pane of the RPI. The toolbar may be manually hidden by touching or selecting an icon or a specified area of the display or the toolbar may auto hide after a period of time. Once hidden the user may un hide the toolbar by touching selecting or otherwise moving an input device on or around an icon or specified area of the display.

The RPI may include a Picture in Picture region or window that displays local video or image data currently being captured by the camera of the PED. The local video feed may be captured from a camera either incorporated within or otherwise in communication with the PED. The user may resize the local video window reposition it within the display and or remove it. The local video window may be displayed in a lower pane of the GUI while the remote video is displayed in the upper pane or vice versa.

The RPI may include an in video interface that enables the user to control the endpoint device by interacting with the live video feed. For example when the user touches taps clicks or otherwise selects a point in the live video feed the endpoint may change a mechanical pan or tilt or digital pan or tilt or both such that the point selected by the user is centered in the live video feed. The user may also adjust an optical or digital zoom or both of the live video feed. For example a user may adjust an optical and or digital zoom by pinching together or spreading apart two or more fingers on the surface of a touch sensitive display of the PED. As another example the user may control all or some of a mechanical or digital pan tilt or zoom of the live video feed by pressing and dragging a finger on the surface of the display to specify a diagonal or other dimension of a zoom region. After a period of time or upon releasing his or her finger the endpoint may mechanically or digitally pan tilt or zoom to match a dimension of the zoom region to a dimension of the live video feed and or to match a center of the zoom region to a center of the live video feed. In one embodiment a user may zoom out to a default zoom which may be fully zoomed out by performing a double tap in the live video feed or by double clicking or right clicking a mouse cursor within the live video feed.

In one embodiment the user may direct movement of a telemedicine device or other telepresence device to a particular location within the live video feed by performing a touch hold tap where the user touches a location on the screen holds his or her finger on that location for a brief interval until a cursor appears on the screen under the user s finger positions the cursor which now follows the user s finger at a point in the remote video window representing the desired destination and subsequently taps his or her finger once again to confirm the location as the desired destination. The telepresence device may then proceed to a position in the live video feed corresponding to the location selected by the user.

Additional functionalities available via the RPI through a touch screen interface may include a two finger swipe to display video from one or more auxiliary video sources such as a video camera still camera endoscope ultrasound device radiological imaging device magnetic resonance imaging device or other medical imaging device.

A toolbar may be shrunken and or expanded vertically or horizontally or both or hidden and unhidden by touching or tapping an icon disposed at the top of the screen. For example an icon may have the appearance of an arrow or triangle that points up when the toolbar is fully expanded or unhidden and may point down when the toolbar is shrunken or hidden. The icon itself may shrink or expand with the toolbar. Alternatively the toolbar may be unhidden by the user pulling down or making a downward swipe from the top or other edge of the screen. The toolbar may again be hidden by pushing up or making a swipe toward the top or other edge of the screen.

Additional functions or applications may be accessed from the toolbar. Each function or application may have a distinctive icon in the toolbar indicative of the underlying functionality. If there are more functions icons available than can be displayed on the toolbar the toolbar may be configured to scroll icons onto and off of the toolbar with a swipe of the user s finger in the toolbar. The icons may scroll continuously in a carousel fashion or the scrolling may be disabled in a particular direction when there are no further icons to be displayed thus informing the user of this fact. Alternatively the toolbar may not scroll available icons but instead show only a specified set of icons. In this case additional functions or applications would be exposed to the user via additional menu levels windows or pop overs accessible via one or more icons contained in the toolbar or elsewhere in the RPI.

The toolbar may provide access to various functions of the RPI such as activating or deactivating a headset or handset which may be coupled to the telepresence device in either a wired or wireless fashion when additional privacy is desired in communicating with the remote user i.e. the user at the control station PED activating or deactivating a stethoscope for monitoring a patient creating a still image or snapshot from a camera still or video on or otherwise coupled to the telepresence device or any auxiliary input starting or stopping recording video from a camera on or coupled to the telepresence device or any auxiliary input navigation features opening or bringing up a map or list of destinations e.g. people s names associated with a device or location reversing local camera view toggle local video to come from front of the PED or back of the PED activating or deactivating remote pointer cursor on remote display follows or mirrors cursor position on local display which is positioned by the user tapping or touching the desired location on the display activating or deactivating a laser pointer on the remote device a laser pointer may be positioned on the telepresence device so as to correspond to a position of tap or touch within the live video feed muting or un muting a microphone of the PED opening the settings panel disconnecting and or other features options and or settings.

From the lower pane of the RPI the user may initiate a vector drive mode for controlling a telepresence device. For example a mouse click touch drag motion or other action may be used to draw or otherwise input a vector for controlling the motion of a telepresence device. For example a user may touch two fingers in the lower pane and drag them a desired distance and direction on the screen to send a drive command with a respective velocity and heading to the mobile telepresence device.

The interface may further include a mechanism for deactivating an obstacle detection obstacle avoidance ODOA system such that the user may operate in a nudge mode and continue to slowly move the telepresence device despite the telepresence being in contact with or close proximity to another object. This mechanism may automatically time out such that the ODOA system is re engaged after a period of inactivity. Placing the telepresence device in nudge mode may cause a camera of the telepresence device to be automatically positioned to look down around the body of the telepresence device and either in the direction of drive command issued by the user or in the direction of an object closest to or in contact with the telepresence device so that the user may see what obstacle he or she is commanding the telepresence device to nudge . Alternatively the ODOA system may be entirely deactivated. In one embodiment the ODOA system may be deactivated so long as the telepresence device is driven or moved below a specified velocity.

The RPI may be configured for deployment on any of a wide variety of PEDs including the Apple iPad iPod and iPhone . The RPI may be configured for deployment on any of a wide variety of PEDs such as mobile phones computers laptops tablets and or any other mobile or stationary computing device. In some embodiments the RPI may be presented via a plug in or in browser application within a standard web browser.

In some embodiments the RPI may allow for varying feature sets depending on the type of PED utilized. For example on a larger tablet sized PED the RPI may include any combination of the numerous features described herein. While on a smaller PED such as an Apple iPhone the available features may be limited to suit a particular context or use case. In one embodiment the RPI may allow a user such as nurse or hospital staffer to control the movement of a telepresence device without establishing a telepresence audio video session. In other embodiments for example a remote family member of a patient may conduct a two way voice and video telepresence with his or her iPhone but may not have permission to drive or otherwise control the movement of the telepresence device. Any number of features or combination of features may be included and or excluded for a particular PED.

As an example scenario a nurse may utilize an RPI on a PED with limited functionality such as an Apple iPhone to request a cardiac consult for a patient. A telepresence system in contact with the RPI submits the request to a telepresence device. The telepresence device may begin navigating to the patient while simultaneously initiating a connection with a cardiac doctor. For example the telepresence device may call an appropriate cardiac doctor e.g. the cardiologist on call the nearest cardiologist the patient s specific cardiologist etc. on one or more PEDs belonging to the doctor. Given that the nurse is using a PED with limited functionality the nurse may be allowed to control the telepresence device and or participate in an audio only telepresence session but may be provided a limited feature set. Accordingly the nurse may be able to communicate with the doctor as the telepresence device navigates to the patient.

In some embodiments a nurse or a patient may request a doctor or a specific type of doctor via an RPI or via a display interface directly on a telepresence device. The RPI the telepresence device and or a corresponding telepresence system may intelligently call a specific doctor as described herein. Alternatively the RPI the telepresence device and or a corresponding telepresence system may call a plurality of doctors. In such a scenario the first doctor to attend may be connected via an RPI to a telepresence device to service the request of the nurse or patient. The call routing and telepresence session may be managed in a network cloud a telepresence network and or via some other suitable computing device.

Throughout the specification various functions features processing and or other computing actions are described as being performed by at least one of an RPI a PED a telepresence system and or other computing device. It will be appreciated that in many instances the actual processing calling function implementation recording and or other computer performed actions may be executed on a local device a remote device and or via networked or cloud device.

Reference throughout this specification to one embodiment or an embodiment means that a particular feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. Thus the appearances of the phrases in one embodiment and in an embodiment in various places throughout this specification are not necessarily all referring to the same embodiment. In particular an embodiment may be a system an article of manufacture such as a computer readable storage medium a method and or a product of a process.

The phrases connected to and in communication with refer to any form of interaction between two or more entities including mechanical electrical magnetic and electromagnetic interaction. Two components may be connected to each other even though they are not in direct contact with each other and even though there may be intermediary devices between the two components.

Types of telepresence devices include but are not limited to remote telepresence devices mobile telepresence units and or control stations. For example a remote telepresence device may include a telepresence robot configured to move within a medical facility and provide a means for a remote practitioner to perform remote consultations. Additionally telepresence devices may comprise any of a wide variety of endpoint devices such as those described in U.S. patent application Ser. No. 13 360 579 filed on Jan. 27 2012 titled INTERFACING WITH A MOBILE TELEPRESENCE ROBOT which application is hereby incorporated by reference in its entirety. Telepresence devices may also comprise any of the endpoint devices described in U.S. patent application Ser. No. 13 360 590 filed on Jan. 27 2012 titled INTERFACING WITH A MOBILE TELEPRESENCE ROBOT which application is hereby incorporated by reference in its entirety.

A portable electronic device PED as used throughout the specification may include any of a wide variety of electronic devices. Specifically contemplated and illustrated are tablet style electronic devices including but not limited to electronic readers tablet computers tablet PCs cellular phones interactive displays video displays touch screens touch computers and the like. Examples of PEDs include the Apple iPad iPod and iPhone the Hewlett Packard Slate the Blackberry Playbook the Acer Iconia Tab the Samsung Galaxy the LG Optimus G Slate the Motorola Xoom the HP touchpad Topaz the Dell Streak and the like.

Throughout this description a tablet style touch screen PED is used as an exemplary PED however any of a wide variety of PEDs and or other electronic devices may be used instead. For instance tablet computing devices cellular phones computers laptops etc. could be used in place of the illustrated and described touch screen tablet devices. It will be appreciated by one of skill in the art that operations and functions performed on or by a PED may also be performed on a stationary portable electronic device such as a desktop computer or server.

The embodiments of the disclosure may be understood by reference to the drawings wherein like elements are designated by like numerals throughout. In the following description numerous specific details are provided for a thorough understanding of the embodiments described herein. However those of skill in the art will recognize that one or more of the specific details may be omitted or other methods components or materials may be used. In some cases operations and or components are not shown or described in detail.

Furthermore the described features operations or characteristics may be combined in any suitable manner in one or more embodiments. The order of the steps or actions of the methods described in connection with the embodiments disclosed may be varied. Thus any order in the drawings or Detailed Description is for illustrative purposes only and is not meant to imply a required order unless otherwise specified.

Embodiments may include various features which may be embodied in machine executable instructions executed by a general purpose or special purpose computer or other electronic device . Alternatively the features may be performed by hardware components that include specific logic for performing the steps or by a combination of hardware software and or firmware. Accordingly the various components modules systems and or features described herein may be embodied as modules within a system. Such a system may be implemented in software firmware hardware and or physical infrastructure.

Embodiments may also be provided as a computer program product including a non transitory machine readable medium having stored thereon instructions that may be used to program or be executed on a computer or other electronic device such as a PED to perform processes described herein. The machine readable medium may include but is not limited to hard drives floppy diskettes optical disks CD ROMs DVD ROMs ROMs RAMs EPROMs EEPROMs magnetic or optical cards solid state memory devices or other types of media machine readable media suitable for storing electronic instructions.

According to various embodiments the RPI may automatically adjust the field of view FOV of the camera . In some embodiments the healthcare practitioner or other user may manually adjust the field of view of the camera . Additionally any number of compositional and exposure variables of the camera may be automatically or manually adjusted adjustable. The RPI or the healthcare practitioner may automatically or manually select which camera to use in the event a PED has multiple cameras. A user may in some embodiments select which camera is used during a session.

Factors involved in determining the optimal endpoint device could be distance or estimated travel time to the selected patient or remaining battery life of respective telepresence devices. Additionally the RPI may dispatch the endpoint device that can reach the selected patient while minimizing travel through areas with poor wireless connectivity confined spaces areas high traffic areas sensitive and or secure areas dangerous areas and or otherwise undesirable zones.

The endpoint list may also include doctors nurses staff or any other persons that may currently or for a scheduled period of time be associated with a particular location and or patient to which the endpoint can navigate. The endpoint list may be searchable and or filterable. In some embodiments the endpoint list may be implemented with a text box in a window or in separate tabs. As the user enters alphanumeric characters into the text box the list may be instantaneously filtered to exclude endpoints whose names do not match the character string currently contained in the text box.

Other filtering parameters may be specified such as endpoint type manufacturer status facility building floor room customer and or any other grouping. Logical arbitrary or otherwise customized groupings of endpoints may be created by a user or administrator and these groupings may additionally be used to filter or otherwise search the list of endpoints. In some embodiments each endpoint in the list may have an associated status indicator which informs the user whether a device is ready busy offline in a private session and or in a multi presence session which the user may join to receive session audio video images or potentially control the some or all functions of the endpoint .

Once a destination patient or other person is selected the RPI may communicate the desired destination to the telepresence device via navigation instructions. The navigation instructions may allow for the telepresence device to be manually navigated semi autonomously navigated or autonomously navigated to the desired destination. Systems and methods for manual semi autonomous and autonomous navigation are described in U.S. patent application Ser. No. 13 360 579 previously incorporated by reference.

The RPI may be designed to provide a user with notifications regarding various states of a device e.g. the PED or the telepresence device a connection or a session. For instance the RPI may display indications of whether video or audio recording is active and or enabled or if a laser pointer or remote pointer is active a battery level or remaining time available based on the current battery level related to network performance and or a wireless signal strength.

In one embodiment the RPI may provide a message to the user who may be moving around if the PED loses or detects a decrease in strength of a communication signal e.g. a WiFi or 4G signal as the result of the user s movement and or as a result of the telepresence device leaving a good WiFi zone or some loss outage or failure elsewhere in the link. The message provided to the user may distinguish whether the loss outage or drop in strength has occurred locally remotely or elsewhere in the link.

In some embodiments the RPI may be configured to provide notifications or alerts using various display modifications annotations or overlays. For example the screen may pulsate with a partially translucent overlay to indicate that a battery of the telepresence device is dying and or that connectivity is below a predetermined level. For example the screen may pulsate with a red glow possible with a vignette such that it is increasingly translucent toward the center of the display to indicate that a battery is dying.

In one embodiment a notification may include one or more pop up dialogue boxes to bring critical information to the attention of the user of the RPI. For example if the connectivity falls below a level considered clinically viable the RPI may request that a user of the RPI acknowledge the current limitation in order to continue the telepresence session. As another example the RPI may request that a user acknowledge anomalous conditions associated with the RPI the patient and or the telepresence device. The RPI may request that a user acknowledge that they are aware of or have noticed patient conditions considered outside of predetermined ranges. For example the telepresence device and or the RPI may recognize that a patient s heart rate is below a threshold level and request that a remote user of the RPI acknowledge awareness of the condition.

For example when a user taps the video or movie projector icon in a toolbar the RPI may display the native video controls of the PED overlaid above the live video feed along a toolbar across the upper panel or a lower panel or elsewhere on the screen. Additionally a library of network accessible or locally stored video clips or movies may be made accessible in the lower panel. The user may navigate the video clip library by swiping left or right which may cause successive clips to be visually cycled from completely obscured to partially obscured to fully visible and selectable playable to partially obscured again and so on. Once the user locates a desired video the user may drag and drop the video from the media manager module to the upper panel to cause the video to be displayed on a screen on the telepresence device.

The RPI may enable playback to be controlled from the PED and or the telepresence device. Once a video is selected the RPI may enable the user to navigate or skip through an index of key frames contained in the video. The RPI may additionally enable the user to delete a video using a flicking gesture. For security and privacy videos may be stored in an encrypted format. In another example when the user taps the camera icon in a toolbar the interface may display a cover flow image library in the lower pane. Images may be searched browsed displayed on the PED or displayed at the remote endpoint in the same manner as described above with respect to video files in the media manager.

A lower bar may also include one or more management tools. As illustrated a picture in picture selection may allow a user to selectively disable the picture in picture window . An auto brightness feature may be enabled via a checkbox. The control settings may further include a microphone level meter to indicate a volume or sound pressure level relative to a maximum specified input or clipping level. Additionally the settings control may include a microphone gain slider to allow adjustment of a microphone gain to a desired level. Similarly a speaker level meter may graphically illustrate the current volume or sound pressure level relative to a maximum specified output or slipping level. The remote controls may include a picture in picture checkbox to enable the user to toggle a picture in picture display of the remote video view at the remote endpoint.

The PED may allow data to be entered via the touch screen using keyboard . As illustrated the RPI may display a single data panel in a full screen mode by removing the upper panel typically used to display the live video feed from the telepresence device. Various tabs may toggle the screen between various data input and or visualization modes. In some embodiments the remote video view may continue to be displayed in a small window or panel.

The display and or the interface may comprise a touch screen or other interface to receive inputs. In some embodiments if a telepresence device is an autonomous mobile telepresence device the display and or the interface may provide a list of destinations healthcare practitioners and or patients to which as described herein the telepresence device can be sent or connected. The display and or the interface may also enable a person to stop the telepresence device when it is autonomously navigating and likewise enable the telepresence device to resume autonomous navigation to its destination. The display and or the interface may additionally have a button or menu option that instructs the telepresence device to autonomously navigate to an out of the way location e.g. a wall corner etc. a dock a storage location and or a charging station. The display and or the interface may include buttons or menu options for various settings or to page or notify support personnel of a problem with or question regarding the operation of the telepresence device.

The input intended to direct the telepresence device to a new location may be considered a navigation input. For example the selection of a room patient healthcare practitioner location within a video feed and or other selection or input intended to cause the telepresence robot to navigate may be considered a navigation input. The navigation input may then be translated into one or more navigation instructions to guide the telepresence robot autonomously or semi autonomously to the selected location.

The RPI may enable complete integration of patient data monitoring with the remote telepresence session thereby adding a dimension of data driven functionality uniquely valuable in telepresence applications. The user may select an icon from a toolbar or other panel to activate a patient bedside data monitoring app such as those offered by any of a variety of real time patient data monitoring application providers. Upon selecting the appropriate icon a patient data monitoring window may appear in the RPI. The user may expand this pane to a full screen view reposition the pane and or resize the pane as described above. The RPI may show any number of real time or archived patient biometrics or waveforms such as temperature heart rate pulse blood pressure oxygen saturation etc.

Using the touch screen interface the user may pause and resume real time time delayed or archived patient data. The user may move back and forth through time based patient data using dragging or swiping gestures or the user may zoom or scale the waveform or metric along an amplitude axis and or time axis. The application may further allow the user to set markers along a waveform to measure variations in amplitude or time associated with various features of the patient data such as peaks valleys maxima or minima global or local global averages running averages threshold crossings or the like.

The data may be collected from bedside monitors or other monitoring devices in real time and archived for a period of time or indefinitely in a server or database. The monitoring app may be a separate application and or integrated within the RPI. The monitoring app may retrieve the relevant data and provide it to the RPI through an application programming interface API and or the RPI may independently retrieve the data from a database.

The data may also be collected by the telepresence device by for example directing a camera of the telepresence device to the display of a monitoring device and either recording video of the monitor display or performing image analysis on the video image to extract the patient data. The user and or telepresence device may annotate the data and store the annotations with the data either locally or in a remote server for later retrieval. The monitoring app may enable alarms alerts notifications or other actions or scripted activities set to take place in response to certain events in the data.

Further the interface may integrate available ADT with patient bedside or biometric data. For example if a patient s vitals or other biometrics trigger an alert or alarm condition the telepresence device may be configured to autonomously navigate to the bed or room number of that patient and send a notification or invitation to a doctor caregiver or specialist to begin a telepresence session with the patient. Additionally when a healthcare practitioner initiates a session with a telepresence device and selects either a location destination or patient to visit with the autonomous telepresence device the bedside or biometric data for a patient associated with the selected location destination or patient may be automatically retrieved and used to populate a dashboard of patient data that the healthcare practitioner can then review annotate or otherwise interact with as discussed above and depicted in .

Moreover an autonomous mobile telepresence device may be used to conduct patient rounds in a healthcare facility. As the telepresence device moves from one location to the next the location of the telepresence device may be used to retrieve the name and or other data of a patient s associated with that location. For example the telepresence device may retrieve patient biometrics bedside data electronic medical records and or other patient data to populate a patient dashboard on a display of the PED. In one embodiment this information may be retrieved from a health level 7 HL7 compliant server associated with the facility healthcare practitioner and or patient.

In addition an autonomous mobile telepresence device may be scripted or scheduled to make scheduled stops at various beds rooms locations or patients. The RPI may retrieve the names or contact info of people such as doctors nurses students family members etc. associated with a scheduled or upcoming stop at a particular patient or location and send a notification via SMS email etc. to the associated people inviting them to join the telepresence session by receiving audio and or video from the session on a PED via the RPI.

To accommodate a time interval that may be necessary or convenient to allow others to join the session the telepresence device may send invitations notifications and or reminders to join the session a predetermined amount of time prior to the time the session is scheduled to begin. Repeated or reminder notifications may be sent to each party at regular or decreasing intervals to remind them of an upcoming session. The notifications may contain a hyperlink to follow to join the session a link to the RPI an app notification or badge for display on the PED or the address or phone number of another device address to connect to. The notification may further include a username password pin and or other credential s that the invitees may provide to join the session. The length of the session may be at least partially based on the number of users connected and or their priority levels.

In the illustrated embodiment a user of the RPI may select a navigation mode via a selection panel . Inputs for selecting the navigation mode and or inputs to direct the actual navigation may be performed using any of a wide variety of inputs including but not limited to a voice input a keyboard a mouse a touch input a stylus and or via another peripheral input device. In each of the navigation modes a user may provide a navigation input in one or more manners. The navigation input may then be translated processed lookup table etc to generate and transmit navigation instructions to the telepresence robot to guide the telepresence robot autonomously or semi autonomously to a desired location.

According to various embodiments the destinations may include various locations within a healthcare facility specific patient names and or the names of various healthcare practitioners. In some embodiments the locations of healthcare practitioners may be determined using cameras within the healthcare facility global positioning systems local positioning systems radio frequency identification RFID tags and or the like.

The arrow provided as a navigation input may be used to generate navigation instructions that are transmitted to a remote telepresence device. As illustrated the navigation input may be in the form of a vector arrow drawn as either a final endpoint selection or as a vector including a beginning point and an end point. The end point of the vector may represent the location to which the telepresence device should navigate. Accordingly navigation instructions may be generated based on the current location of the telepresence device and the endpoint of the vector within the live video feed. In some embodiments the vector s image pixel endpoint may be mapped via a lookup table to one or more translate and rotate commands to cause the telepresence device to navigate to the selected location. In some embodiments the length of the vector may correspond to the desired distance to move the telepresence device a desired acceleration of the telepresence device and or a desired velocity of the telepresence device.

As previously described a navigation input may direct a telepresence device to navigate forward with respect to the live video feed 3 meters and to the right 2 meters. Any of a wide variety of navigation instructions may be possible to correctly navigate the telepresence device. For instance the navigation instructions may direct the telepresence device to navigate approximately 3.6 meters at a 34 degree angle relative to the video feed. Alternatively the navigation instructions may direct the telepresence device to navigate 3 meters forward and then 2 meters to the right. As will be appreciated any number of navigations routes and corresponding navigation instructions may be possible. The navigation input may be translated into navigation instructions as a plurality of drive forward commands coupled with rotate commands.

In some embodiments the live video feed may be delayed slightly due to network and or processing limitations. This video latency may result in inaccurate navigation instructions. Accordingly the navigation input may be adjusted based on the known video latency and the current or past velocity and direction of the robot. For example the selection of a location within the video feed may be translated into navigation instructions that compensate for the latency of the video feed. For instance if an end point endpoint pixel of a vector drawn on the video feed maps to a position 1 meter forward and 0.5 meters to the right relative to the current location of the telepresence device and the telepresence device has moved 0.2 meters forward since the video frame on which the vector was drawn was captured or since the associated command was issued a lookup table entry for 0.8 meters forward and 0.5 meters to the right may be used to determine and or adjust the navigation instructions. Video latency calculation and command compensation may be performed at the telepresence device at a remote interface device and or at any networked computing device. In some embodiments the navigation instructions may be generated to compensate for the video latency. In other embodiments the telepresence device and or other computing device may adjust the navigation instructions to compensate for the video latency.

In some embodiments the live video feed and the four way controller may be displayed in a full screen or expanded mode. In other embodiments and or modes various additional panels icons tabs and or other objects and simultaneously with the mouse based driving interface. For example a remote controls panel may allow a user to control various settings of the remote telepresence device such as the audio and video settings. A media control panel may allow a user to open play record and or otherwise manipulate the current live video or audio feed network accessible audiovisual material remotely at the telepresence device stored audiovisual material and or locally stored audiovisual material.

An advanced controls panel may allow a user or select users based on account privileges to modify various aspects of the connection or session settings access external or peripheral applications e.g. StrokeRESPOND and or control other aspects of the remote telepresence session. A local controls panel may allow a user to control various settings of the RPI the PED and or other local peripheral devices such as the audio and video settings associated with the telepresence session. A battery life indicator may provide information regarding the current battery life and or expected battery life based on current or past consumption rates. Various additional icons and tabs and may provide additional controls and or options within the RPI and or associated with the remote telepresence device.

In various embodiments a navigation input in the form of a vector provided in a mouse based vector input mode may be translated into navigation instructions through the use of a lookup table. In some embodiments the lookup table may include values that compensate for latency. That is the navigation instructions returned by the lookup table may be based on the navigation input and the current or recent average video latency as described herein.

Placing the telepresence device in nudge mode may cause a camera of the telepresence device to be automatically positioned to look down around the body of the telepresence device and either in the direction of drive command issued by the user or in the direction of an object closest to or in contact with the telepresence device so that the user may see what obstacle he or she is commanding the telepresence device to nudge . Alternatively the ODOA system may be entirely deactivated. In one embodiment the ODOA system may be deactivated so long as the telepresence device is driven or moved below a specified velocity.

In various embodiments of the mouse based driving interface the controls and vectors may be drawn as overlays on the live video feed e.g. via a click and hold of a mouse button or a tap and hold via a stylus or finger . In other embodiments a panel or peripheral device may be used to draw the vectors to control the velocity and or direction of travel. In some embodiments the velocity selected by the length of the vector may be overridden based on other factors such as obstacle detection congestion human presence etc. .

According to various embodiments a head portion and or the camera of the telepresence device may be re centered via an icon within the mouse based driving interface or via a keyboard or other peripheral device selection. In some embodiments the selection of any of the arrows within the four way controller may orient or re orient the head portion of the telepresence device.

In some embodiments while an application is open in the lower panel the user may switch to viewing the application in full screen mode by grabbing the upper part of the application window and dragging upward toward the upper panel . The user may return to the two pane view by dragging downward from the top of the upper panel . The full screen application view may include a picture in picture of the live video feed from the telepresence device so that the user may continue to monitor the remote environment. Some applications and or the RPI may continue to run in the background even when not displayed.

According to various embodiments the toolbar may provide access to a handset a stethoscope a camera a video a live cursor a laser pointer microphone settings a map navigational options a disconnect button and or other features options or settings. The toolbar may provide access to various other functions or applications such as StrokeRESPOND SureNotes a media manager patient data lab results image data and or team communication.

In the illustrated embodiment the left joystick may be configured to control movement of the base or body of the telepresence device. The right joystick may be configured to control movement of a head or upper portion of the telepresence device. The portion of the telepresence device controlled by each joystick and may be user selectable and or reversed.

From the login page potentially after successfully logging in a navigation button may display a navigation page . The navigation page may allow a user to select between various navigation modes such as a map button to result in a map page or a location button to display a list of locations . Again once a destination is selected the in transit page may be displayed as the telepresence device navigates to the selected location.

A settings page may be displayed allowing a user to select from any number of settings. For example a WiFi selection may result in a WiFi page being displayed. A robot selection may result in a robot page being displayed. The state diagram illustrated in is a simplified state diagram and intentionally omits numerous possible states and connections between states for clarity. Each and every panel icon setting application option tab selection input and the like described herein may be represented as a separate state entry action transition condition transition exit action and or other component of a complex state diagram. As will be appreciated by one of skill in the art each of the various aspects functions operations control panels icons objects buttons display panels display windows etc. described herein may be described and or implemented in terms of software hardware and or firmware and could potentially be described as a complex state machine.

The instructional panel may provide instructions for finger swipes to move the telepresence device forward and reverse slide the telepresence device side to side rotate the telepresence device to the right and rotate the telepresence device to the left . Separate control of a head portion of the telepresence device may be available using multiple fingers using a toggle button software or hardware or by tapping within the live video feed . A lower toolbar may provide access to various other functions features and or settings of the RPI such as those described herein and especially in conjunction with . In some embodiments the RPI may include instructional or demonstrational videos for any of the various embodiments or functions described herein.

During training initial use or after indicating help is needed the live video feed and or the window may be dimmed and or otherwise less obtrusive. A help screen overlay may provide instructions and or guidance with how to toolbars and or other interface options. As illustrated in the overlay may comprise text descriptions of the toolbar icons connected by lines to each icon. In some embodiments instructions and or guidance for camera controls and or driving controls for the telepresence device may be illustrated as an overlay as well. For example instructions on how to use the joysticks and in may be provided in a help screen overlay. Similarly the gestures and in may be provided in an instructional or help screen overlay. In some embodiments the instructional overlay may be in the form of moving or video instructions overlaid on an existing display. For example the overlay may demonstrate the gestures and in .

According to various embodiments an RPI may be configured with all or some of the features and embodiments described herein. For example an RPI may include any number of the features and embodiments described herein as selectively displayed and or selectively functional options. An explicit enumeration of all possible permutations of the various embodiments is not included herein however it will be apparent to one of skill in the art that any of the variously described embodiments may be selectively utilized if not at the same time in a single RPI.

This disclosure has been made with reference to various exemplary embodiments including the best mode. However those skilled in the art will recognize that changes and modifications may be made to the exemplary embodiments without departing from the scope of the present disclosure. While the principles of this disclosure have been shown in various embodiments many modifications may be made to adapt the RPI for a specific environment and or to satisfy particular operating requirements without departing from the principles and scope of this disclosure. These and other changes or modifications are intended to be included within the scope of the present disclosure. This disclosure includes all possible permutations of the independent claims and their dependent claims.

