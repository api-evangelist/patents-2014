---

title: Voice application architecture
abstract: A voice-based system may comprise a local speech interface device and a remote control service. A user may interact with the system using speech to obtain services and perform functions. The system may allow a user to install applications to provide enhanced or customized functionality. Such applications may be installed on either the speech interface device or the control service. The control service receives user speech and determines user intent based on the speech. If an application installed on the control service can respond to the intent, that application is called. Otherwise, the intent is provided to the speech interface device which responds by invoking one of its applications to respond to the intent.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09548066&OS=09548066&RS=09548066
owner: Amazon Technologies, Inc.
number: 09548066
owner_city: Seattle
owner_country: US
publication_date: 20140811
---
Homes and other user premises are increasingly equipped with always on Internet or cloud connectivity. In many cases even mobile users have constant or nearly constant data connectivity. The common availability of network communications in combination with increasing capabilities of computing devices has created a number of new possibilities for services and other functionality that use the variety of connected devices accessible to users. Language based and speech based systems are examples of technologies that may be used to provide conveniences to users as they interact with automated systems.

This disclosure describes devices systems and services that perform natural language and or speech based interactions with users. In described embodiments a system listens to or interacts with a user to determine a user intent based on natural language understanding of the user s speech. For example a user may utter an expression that is understood as an intent to play a song or to order movie tickets. In certain embodiments the system may conduct natural language dialogs with the user to determine or clarify user intents. Upon determining the intent of the user the system acts upon the intent by performing an action or providing a service in fulfillment of the intent such as by playing the song or interacting further with the user to order movie tickets.

The system may include a speech interface device located in the home of a user and a supporting cloud based control service. The speech interface device is configured to capture user utterances and provide them to the control service. The control service performs speech recognition and natural language understanding on the utterances to determine intents expressed by the utterances. In response to an identified intent the control service causes a corresponding action to be performed. An action may be performed at the control service or by instructing the speech interface to perform a function.

Built in capabilities of the system may be extended by aftermarket applications that are selected or purchased by a user. Such applications may be designed for installation and execution on either the control service or the speech interface device. Upon determining a user intent based on received user speech the control service identifies one of the applications that is suitable for responding to the intent. If such an application has been installed and enabled on the control service the control service invokes that application. Otherwise if there is a suitable application installed on the speech interface device the control service passes an indication of the user intent to the speech interface device. Upon receiving an indication of an intent the speech interface device invokes a corresponding application to respond to the user intent.

The speech interface device may operate in conjunction with and or under the control of a remote network based or network accessible control service also referred to as a speech service or speech based service that is configured to receive audio from the speech interface device to recognize speech in the received audio and to perform or initiate functions or services in response to the recognized speech. Such functions or services may be implemented by the control service independently of the speech interface device and or may be implemented by providing a command to the speech interface device for local execution by the speech interface device . For example the control service may instruct the speech interface device to play music speech or other audio content specified by the control service . Additionally functions or services may be implemented by applications that are enabled and or installed by the user for execution on the speech interface device or the control service .

The speech interface device may have one or more microphones and one or more audio speakers or transducers to facilitate speech interactions with the user . The speech interface device may have a network communications interface for communications over a communications network with the control service . The communications network may comprise a public wide area network such as the Internet or may comprise any of various other types of public and private networks that extend beyond the local premises of the user . Additionally the communications interface may communicate locally over a local area network within the user premises.

The speech interface device may include operational or control logic which may comprise a processor and memory . The processor may include multiple processors and or a processor having multiple cores. The processor may also comprise or include a digital signal processor for processing audio signals.

The control logic may include applications programs and other software stored in the memory . The software may comprise computer executable instructions that are executed by the processor to perform acts or actions that implement desired functionality of the speech interface device including the functionality described herein. The memory may be a type of non transitory computer readable storage media and may include volatile and nonvolatile memory. Thus the memory may include but is not limited to RAM ROM EEPROM flash memory magnetic media optical media or other memory technology. The memory may also include media commonly used for transferring or distributing software such as CD ROMs DVDs flash drives memory sticks etc.

The software may include system or operating software that is preinstalled on and integrated with the speech interface device . The operating software may comprise an operating system that provides basic functionality of the speech interface device including drivers audio processing functions interfaces to the control service and so forth. The operating software may include preinstalled programs or applications for performing various built in functions and actions. The operating software may also include action handlers or interfaces that perform actions in response to instructions received from the control service .

The memory may may also contain user installed applications also referred to herein as device applications which may comprise applications that have been installed by the user in the memory and activated for execution by the processor subsequent to purchase and installation of the device . Various aftermarket applications may be available to the user for local installation and execution. In some embodiments the control service may provide functionality for allowing the user to identify and install applications that have been made available by various developers and vendors for execution on the speech interface device . For example the user may state Find an application for calling a taxi. The control service may respond by offering to provide such an application for installation on the speech interface device . The user may accept the offer whereupon the application may be provided to and installed on the speech interface device .

The control service may in some instances be part of a network accessible computing platform that is maintained and accessible via the network . Network accessible computing platforms such as this may be referred to using terms such as on demand computing software as a service SaaS platform computing network accessible platform cloud services data centers and so forth. The control service may be configured to provide services to large numbers of speech interface devices in the homes or premises of different users.

The speech interface device and or the control service may communicatively couple to the network via wired technologies e.g. wires universal serial bus USB fiber optic cable etc. wireless technologies e.g. radio frequencies RF cellular mobile telephone networks satellite Bluetooth etc. or other connection technologies. The network is representative of any type of communication network including data and or voice networks and may be implemented using wired infrastructure e.g. coaxial cable fiber optic cable etc. a wireless infrastructure e.g. RF cellular microwave satellite Bluetooth etc. and or other connection technologies.

The control service is configured to receive an audio stream from the speech interface device to recognize speech in the audio stream and to determine user intent from the recognized speech. Depending on the nature of the recognized intent the control service may respond by performing an action or invoking an application to perform an action.

In some cases the control service may determine the intent and return a description of the intent to the speech interface device so that the speech interface device can perform an action in response to the intent. Upon receiving a recognized intent from the control service the speech interface device may invoke one of the user installed applications to perform an action in fulfillment of the intent.

In other cases the control service may return an instruction or command to the speech interface device and a command handler of the speech interface device may execute the instruction or command to perform an action within the environment .

The control service includes operational or control logic which may comprise one or more servers computers and or processors . The control logic includes memory containing applications programs and or other software in the form of instructions that are executed by the processor to perform acts or actions that implement desired functionality of the control service including the functionality described herein. The memory may be a type of non transitory computer readable storage media and may include volatile and nonvolatile memory. Thus the memory may include but is not limited to RAM ROM EEPROM flash memory magnetic media optical media or other memory technology. The memory may also include media commonly used for transferring or distributing software such as CD ROMs DVDs flash drives memory sticks etc.

Among other logical and physical components not specifically shown software of the control service may include a speech processing component also referred to as speech services . The speech services may include automatic speech recognition ASR functionality that recognizes human speech in an audio signal provided by the speech interface device from the microphone . The speech services may also include natural language understanding NLU functionality that determines user intent based on user speech that is recognized by the speech recognition components. The speech services may also include speech generation functionality that synthesizes or otherwise produces speech audio. For example the speech generation functionality may comprise a text to speech component that produces speech to be played on the speaker of the speech interface device .

The control service may also provide a dialog management component configured to coordinate speech dialogs or interactions with the user in conjunction with the speech services . Speech dialogs may be used to determine or clarify user intents by asking the user for information using speech prompts.

The control service may also comprise a command interpreter and action dispatcher referred to below simply as a command interpreter that determines functions or commands corresponding to intents expressed by user speech. In some cases commands may correspond to functions that are to be performed at least in part by the speech interface device and the command interpreter may in those cases provide device commands or instructions to the speech interface device for implementing such functions. The command interpreter implements basic built in capabilities that are used in conjunction with the speech interface device . Such basic capabilities may be implemented and enabled by default for users of all speech interface devices . Examples of basic capabilities may comprise setting alarms or notifications increasing decreasing the volume of the speaker generating audible speech through the speaker initiating certain types of communications with users of similar devices and so forth.

The control service may also have or be configured to use one or more user installed applications which may also be described as aftermarket applications third party applications optional applications enabled applications server applications and so forth. Applications such as this may be optional and may be obtained by the user from a library or other collection of available installable applications. In some cases a user may purchase applications for use in conjunction with the system . Generally server applications may be selected obtained and installed by a user in the same manner as the device applications .

The user installed applications provide supplemental and or additional functionality and capabilities in addition to the basic functionality provided by the command interpreter . Enabled or authorized user installed application applications may be automatically invoked in response to recognized user intents that the applications are capable of servicing.

In certain situations the user installed server applications may be provided and hosted by the control service . Alternatively certain of the server applications may be provided and or hosted by third parties or third party services and may communicate with the control service using network based interfaces.

The control service may also have an application selection component also referred to herein as an intent router that selects and invokes applications based on recognized intents expressed by user speech. For example each of the server applications may be associated with one or more intents to which the application is capable of responding. In response to a recognized user intent that is not serviceable by the command interpreter the application selector may select and invoke one of the server applications of the control service . In some cases the application selector may also select from the installed device applications of the speech interface device.

The control service may also perform functions in response to speech recognized from received audio that involve entities or devices that are not shown in . For example the control service may interact with other network based services to obtain information or services on behalf of the user .

Certain of the available applications may be hosted by and executed from network servers or services and may be accessed through appropriate network applications programming interfaces APIs . Others of the available applications may be designed for execution on servers or processors of the control service . The installed server applications may include those that are executed by the control service as well as those that are hosted by third party services under the supervision of the control service . Yet others of the available applications may be designed for installation on and execution by the speech interface device . The installed device applications include applications such as this.

As mentioned above with reference to the control service may have an automatic speech recognition ASR component and a natural language understanding NLU component . The dialog management component is configured to coordinate dialogs or interactions with the user based on speech as recognized by the speech recognition component and or understood by the natural language understanding component . The control service may also have a text to speech component that is responsive to the dialog management component to generate speech for playback to the user on the speech interface device .

The components described above may function based on different types of models or rules. For example the ASR component may base its functionality on ASR models which may include acoustic models created by means of various training techniques. Similarly the NLU component may utilize NLU models that specify grammar lexicons phrases responses and so forth and which also may be created by training. The dialog management component may utilize dialog models that specify logic for conducting dialogs with users. A dialog comprises an alternating sequence of natural language statements or utterances by the user and system generated speech or textual responses. The dialog models embody logic for creating responses based on received user statements in order to prompt the user for more detailed information regarding intents or to obtain other information from the user .

The application selection component or intent router identifies selects and or invokes installed device applications and or installed server applications in response to user intents identified by the NLU component . In response to a determined user intent the intent router attempts to identify one of the installed applications and that is capable of servicing the user intent. If such an application is found it is called or invoked to either satisfy the user intent or to conduct further dialog with the user to further refine the user intent.

Each of the installed applications and may have or provide an intent specification that defines the intent that is serviceable by the application. The intent indicated by the intent specification may be referred to herein as an application intent or as the serviceable intent of the application. The intent specification of an installed application defines a general intent or intent type that can be serviced by the application. The control service uses the intent specifications of the installed applications to detect user utterances expressions or intents that correspond to the applications and .

An application intent specification may include NLU models for use by the natural language understanding component in conjunction with the NLU models . In some cases the NLU models may include or incorporate the NLU models specified by the installed applications and .

The installed applications and may also have or specify dialog models that create and coordinate speech interactions with the user . The dialog models may be used by the dialog management component in conjunction with the dialog models to create and coordinate dialogs with the user and to determine user intent either before or during operation of the installed applications and . In some cases the dialog models may include or incorporate the dialog models specified by the installed applications and .

The control service may have or expose an application programming interface and certain of the applications and may be registered through the API with the control service . The registration of a particular application may indicate or provide a corresponding intent specification for use by the control service . Application developers may provide registrations of their applications through the API so that the applications and may be used in conjunction with the control service .

The NLU component and the dialog management component may in some embodiments be configured to use the intent specifications of the applications and to conduct dialogs to identify expressed intents of users and to identify installed applications that correspond to or are capable of servicing intents expressed by users.

The intent specification of an application may be utilized either before or during operation of the application. In some cases for example the dialog management component may utilize the intent specification when determining a general user intent prior to initiating or invoking an application. More specifically the NLU component and dialog management component may use the intent specification of an application in conjunction with the NLU models and dialog models to determine when a user has expressed an intent that can be serviced by the application. Subsequently the NLU component and dialog management component may use the intent specification to conduct further dialogs with the user in order to further refine the user intent. Alternatively the application itself may conduct further dialogs with the user utilizing capabilities of the control service to refine user intent in order to provide associated functionality.

As an example in response to a user utterance the control service may refer to the intent specifications of multiple applications including both device applications and server applications to identify a purchase tickets intent that has been registered as a serviceable intent by one of the applications. The service may then invoke the corresponding application. Upon being invoked the application may receive an indication of the determined intent and may conduct or coordinate further dialogs with the user in order to elicit further intent details. Upon determining sufficient details regarding the user intent the application may perform its designed functionality in fulfillment of the intent.

When conducting dialogs with the user the installed applications may utilize speech related capabilities of the control service such as those of the ASR component the NLU component the dialog management component and the text to speech component .

As another example a user may state an intent that is not serviceable by any applications that are currently available to the user. For example the user may state I want to a call a taxi. Although none of the applications that the user has currently installed or activated are capable of servicing such an intent the control service may search a listing or marketplace of available applications to identify one that has specified a matching or corresponding serviceable intent. In some cases the control service may then automatically install or enable the identified application. In other cases the control service may prompt the user to purchase or activate the application and subsequently launch or invoke the application. When installing one of the applications the application may be installed on the speech interface device or on the control service .

When an application has been invoked or initiated further speech interactions with the user may be performed under the control of the initiated application which may interpret user statements in accordance with the activity domain of the application using NLU models that are particular to the application and its domain. For example the application may conduct dialogs with the user in accordance with the functions that the application is designed to perform. Upon detecting a user statement or intent that is not consistent with the activity domain of the application the application may terminate itself and control may return to the control service . In some cases the control service may continue to monitor user statements during execution of installed applications and may preempt an application upon detecting an expression or intent by the user that is not consistent with the activity domain of the application.

The speech interface device has an audio capture function or component that captures audio from the environment using the microphone . The audio capture component generates an audio signal and provides the audio signal to the control service . The audio signal potentially contains user utterances including speech of the user .

The ASR component receives the audio signal and performs speech recognition to produce a text string containing the natural language spoken by the user . The text string is provided to the NLU component which uses natural language understanding techniques to determine an intent expressed by the words of the text string .

The control service may have multiple installed server applications as described above which have been selected and enabled by a user for execution on one or more server computers of the control service . The speech interface device may also have multiple installed device applications which have been selected and enabled by a user for execution on the speech interface device . The installed applications and may perform different functions or provide different services relating to different activity or content domains. For example one application might relate to the music domain and might have functionality for finding and playing music. Another application might correspond to a notification domain and might have functionality for setting and issuing alerts or alarms. The applications may be speech enabled meaning that they are configured to interact with users through speech to provide desired functionality. Each of the applications may correspond to one or more serviceable intents that the application is capable of satisfying or servicing.

The control service may be configured to keep track of which server applications have been installed or enabled for each of multiple speech interface devices . The control service may also be configured to keep track of which device applications have been installed and enabled on each of multiple speech interface devices . In addition the control service may be configured to keep track of the intents that each installed or enabled application is capable of responding to or otherwise handling.

Upon recognizing an intent the application selector or intent router identifies and selects one of the device applications or one of the server applications . The intent router provides an indication or description of the recognized intent to the selected application and invokes the selected application or causes invocation of the selected application. Invocation of the selected application may made programmatically and or by appropriate API calls to the application or to the speech interface device .

When one of the applications or is selected the selected application responds to the provided intent by performing a corresponding action. When one of the server applications is selected the action may be performed entirely by the application or the application may send a command to an action handler of the speech interface device to cause the speech interface device to perform the action or part of the action. For example the application may send a command for the speech interface device to play a tone to increase speaker volume to play speech or to perform some other action.

When one of the device applications is selected the intent router may send a command to the speech interface device specifying the application that is to be invoked and the intent to which the application is to respond. The application may in some cases be specified by an application identifier App ID . In response the operating software of the speech interface device may programmatically invoke the specified device application . The selected device application may respond to the specified intent by using integrated capabilities of the speech interface device and or capabilities provided by the control service . For example a selected and invoked device application may utilize speech services of the control services including ASR and NLU services in order to conduct interactions and dialogs with the user . The selected device application may also use or act in conjunction with other online services such as music services news services online merchants various types of service providers and so forth.

In this example the intent router of the control service may first attempt to identify and invoke one of the server applications that is suitable for responding to the determined intent . If such an application cannot be found the intent is passed to the intent router of the speech interface device which attempts to identify and invoke one of the device applications that is capable of servicing the recognized intent. In some embodiments the intent router of the control service may be configured to keep track of which device applications are installed on the speech interface and may pass the intent to the speech interface device only when one of the device applications is able to respond to the intent.

Note that although certain techniques have been described in a speech based context user input and dialogs may be provided or conducted in ways other than speech such as textually. For example a user may specify intents by typing natural language statements using a keyboard and a service may respond by displaying responsive text. Dialogs may be conducted using such two way textual exchanges. In addition an architecture other than described herein may be used other environments or configurations. For example functions illustrated as being performed by the speech interface device may be performed by a computing device such as a personal computer a smartphone a tablet computer or any other type of device.

A particular executable application may be designed for installation and execution on either the speech interface device or the control service . Executing an application on the speech interface device may be desirable in certain situations where the device may be able to provide more resources and or lower latencies. In addition applications installed on the speech interface device may be able to continue to provide certain functions such as local control functions during periods of network unavailability. Home automation is an example environment in which it may be desirable for applications to be installed on the speech interface device .

Executing an application on the control service may be desirable in situations where the speech interface device has limited capacities for applications making heavy use of speech services for functions primarily utilizing network resources and or in other situations.

In some situations an application may be designed to execute on either one of the speech interface device and the control service or may be implemented as two similarly functioning versions suitable for execution on the respective entities. In these situations a user may be asked to specify whether the application should be installed on the speech interface device or the control service . Alternatively the system may evaluate other factors and may determine where to install the application. In some cases an application may be installed on both the speech interface device and the control service and may execute from one location or the other depending on circumstances. Furthermore in some situations there may be a different application installed on each of the speech interface device and the control service for handling the same intent and the system may determine which of the applications to invoke based on context or other factors.

An action comprises receiving user speech and or a user utterance that indicates or expresses a corresponding user intent. The action may comprise receiving audio from the speech interface device which may contain the user speech. The speech interface device may provide a continuous audio stream to the control service or may provide audio segments containing individual user utterances.

An action comprises performing speech processing on the received user speech to determine the intent expressed by the user speech. The action may include performing automatic speech recognition ASR and natural language understanding NLU on the received user speech to determine the intent expressed by the user speech or utterance. The action may also include performing a two way speech dialog with the user to prompt the user for additional information and to thereby clarify elements or roles of the user intent.

An action comprises identifying and or selecting one of the server applications or one or the device applications corresponding to the intent expressed by the user utterance. The application may be selected by determining which of the applications has an associated serviceable intent that matches the expressed intent of the user.

Further actions depend on whether the identified and or selected application is one of the device applications or one of the server applications as indicated by the decision block of . If the identified application is one of the device applications the control service performs an action of providing an indication of the intent to the speech interface device . The speech interface device is responsive to the received indication of the intent to invoke one of the device applications that performs an action corresponding to the intent. In some cases the control service may also perform an action of explicitly specifying which of the device applications is to be used to respond to the user intent such as by specifically an application identifier. The speech interface device responds to this specification by invoking the specified application which in turn responds by performing an action corresponding to the user intent. In some cases the invoked device application may also respond by confirming to the control service or the intent router that the device application has acted in response to the provided intent or that it is able to respond to the provided intent.

If the identified application is one of the server applications an action is performed of initiating or invoking the identified server application and an action is performed of providing an indication of the determined user intent to the invoked server application . The invoked application may respond by performing an action corresponding to the user intent. In some cases the invoked server application may also respond by confirming to the control service or the intent router that the server application has acted in response to the provided intent or that it is able to respond to the provided intent.

Note that in some embodiments the intent router may be configured to invoke both a device application and a server application in response to a particular intent and to provide an indication of the intent to both of the two applications. Either one or both of the two invoked applications may provide a response indicating that they have or will perform an action in response to the first intent. When the intent router receives a response from one of the applications the other application may be terminated or canceled or instructed to cancel any further processing. For example the device may provide a response that one of its applications will perform an action in response to the intent and the intent router may in response cancel a server application that has previously been invoked to handle the intent. Alternatively the server application may provide a response indicating that it will perform an action in response to the intent and the intent router may in response instruct the device to cancel the device application. This technique may be used to reduce response latencies in some situations.

The method may be performed iteratively to process successive user utterances and intents. For example the control service may receive successive first and second user utterances corresponding to first and second user intents. In response to the first user intent the control service may identify select and cause a server application to be invoked and may also provide an indication of the first user intent to the server application. In response to a second user intent the control service may identify select and cause to be invoked a device application and may provide an indication of the second user intent to the device and or to the device application. Alternatively in response to the second user intent the control service may simply pass an indication of the second user intent to the speech interface device and the speech interface device may itself select and invoke an application from its user installed device applications to respond to the second user intent.

In some implementations the control service may first attempt to determine whether one of the server applications is capable of responding to a particular user intent. If so that server application is invoked to respond to the user intent. Otherwise an indication of the user intent is provided to the speech interface device and the speech interface device identifies selects and invokes one of its device applications to respond to the user intent.

An action comprises capturing audio and providing the audio to the control service . The audio may contain user speech or utterances. An utterance contained by the audio may express or correspond to a user intent that can be serviced by an application that has previously been selected and enabled for execution by the speech interface device or the control service .

An action comprises in response to providing user speech to the control service receiving an indication of the intent that is expressed by the user speech. In some cases the action also comprises receiving a specification of a device application that is to be invoked in response to the user intent. The device application may be specified in terms of an application identifier ID .

An action comprises identifying an application corresponding to the user intent indicated by the action . In cases where the control service has explicitly specified an application or an application ID this may comprise simply identifying the application specified by the control service . In other cases where the control service has not specified a particular device application the action may comprise comparing the received intent with intents to which currently installed device applications are capable of responding and selecting one of the device applications that is capable of responding to the intent indicated by the control service .

An action comprises initiating or invoking the selected application. An action may comprise providing the intent received from the control service to the invoked application. An action performed by the invoked application comprises performing an act corresponding to the intent expressed by the user speech. In some cases the application may conduct further dialogs with the user and may receive further speech in order to determine the act or acts that should be performed.

Although the subject matter has been described in language specific to structural features it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features described. Rather the specific features are disclosed as illustrative forms of implementing the claims.

