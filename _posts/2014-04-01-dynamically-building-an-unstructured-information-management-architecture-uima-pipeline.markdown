---

title: Dynamically building an unstructured information management architecture (UIMA) pipeline
abstract: A pipeline development environment includes a toolset that includes a visual design editor. The editor comprises a display interface having a palette of known Annotators that may be selected by a developer. The pipeline development environment also includes or has associated therewith a data repository. The data repository stores datasets. A particular dataset is associated with an Annotator and comprises dependency data generated from execution of a pipeline (or some portion thereof). The repository typically stores datasets from many pipeline runs, including runs of other pipelines, multiple runs of a given pipeline with different inputs, etc. Using the editor, a developer creates a visual representation of the pipeline. As Annotators are added into the pipeline, system tooling dynamically generates the descriptor files and other configuration parameters (for the new pipeline), preferably based on the dependency data associated with the individual Annotators and retrieved from the repository.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09280340&OS=09280340&RS=09280340
owner: International Business Machines Corporation
number: 09280340
owner_city: Armonk
owner_country: US
publication_date: 20140401
---
This disclosure relates generally to development and testing of computer software components for Natural Language Processing NLP based information systems.

The Unstructured Information Management Architecture UIMA is a specification that standardizes a software system framework for performing complex content analytics on unstructured data. The main idea of UIMA is that a document is submitted to a pipeline that is comprised of an ordered set of Annotators and Controllers. Each Annotator is invoked sequentially or in parallel providing annotations on the content and recording them along the way in the document. Optionally an Annotator can use the results of other Annotators that have been executed before it in the pipeline and adds its own output if any to the collective data set for further operations. UIMA pipelines vary in size and complexity and it is not uncommon to have pipeline of substantial size that requires a large amount of time to initialize and run. For example the Natural Language Processing NLP based Question Answering system IBM Watson may contain up to 300 Annotators and takes several minutes or more to initialize and run. Such computational requirement causes productivity problems for Annotator developers who must restart the pipeline every time they make a change no matter how small to a particular Annotator. As a result a developer typically works on one or more parts of the pipeline spending time to create and configure an environment suitable for testing his or her particular change. Beside the time needed to maintain these partial pipelines developers have had mixed results in the efficiency of these test environments. Moreover developers still must complete their testing with a full pipeline to be confident of the final results. Current development and testing systems do not adequately satisfy these needs.

A pipeline development environment includes a toolset that includes a visual design editor. The editor comprises a display interface having a palette of known Annotators that may be selected by a developer. The pipeline development environment also includes or has associated therewith a data repository. The data repository stores datasets. A particular dataset is associated with an Annotator and comprises dependency data generated from execution of a pipeline or some portion thereof . The repository typically stores datasets from many pipeline runs including runs of other pipelines multiple runs of a given pipeline with different inputs etc.

A developer uses the editor to generate a pipeline. In particular the developer selects an Annotator and drags it or a representation thereof into a workspace area. Upon dropping the Annotator or taking some other such control action the tool automatically accesses the dependency data from the data repository and generates all appropriate descriptors for the Annotator along with the required TypeSystem declarations configuration parameters and the like necessary to implement the Annotator in the pipeline. The descriptors for the Annotator may include aggregate parent analysis engine descriptors. Thus preferably the developer s act of selecting the Annotator and placing it in the working area automatically generates the underlying descriptor tooling needed to place this Annotator into the pipeline being generated. The developer then selects a second Annotator from the palette and drags it into a visual or other association with the first Annotator. Upon connecting the second Annotator to the first Annotator the tool automatically updates the pipeline descriptors now taking into consideration the dependency data associated with the second Annotator once again preferably obtained from the repository as well as any potential cross dependencies based on a comparison of the dependency data from each of the two Annotators that are now connected to one another . The process continues by building the underlying pipeline descriptors TypeSystem declarations configuration parameters etc. for the pipeline as each new Annotator is added into the visualization on the editor. During the design process the system may verify the integrity of the pipeline being generated and as necessary provide information about missing or potentially superfluous dependencies. Upon completion the developer can run the pipeline.

The foregoing has outlined some of the more pertinent features of the disclosed subject matter. These features should be construed to be merely illustrative. Many other beneficial results can be attained by applying the disclosed subject matter in a different manner or by modifying the subject matter as will be described.

With reference now to the drawings and in particular with reference to exemplary diagrams of data processing environments are provided in which illustrative embodiments of the disclosure may be implemented. It should be appreciated that are only exemplary and are not intended to assert or imply any limitation with regard to the environments in which aspects or embodiments of the disclosed subject matter may be implemented. Many modifications to the depicted environments may be made without departing from the spirit and scope of the present invention.

With reference now to the drawings depicts a pictorial representation of an exemplary distributed data processing system in which aspects of the illustrative embodiments may be implemented. Distributed data processing system may include a network of computers in which aspects of the illustrative embodiments may be implemented. The distributed data processing system contains at least one network which is the medium used to provide communication links between various devices and computers connected together within distributed data processing system . The network may include connections such as wire wireless communication links or fiber optic cables.

In the depicted example server and server are connected to network along with storage unit . In addition clients and are also connected to network . These clients and may be for example personal computers network computers or the like. In the depicted example server provides data such as boot files operating system images and applications to the clients and . Clients and are clients to server in the depicted example. Distributed data processing system may include additional servers clients and other devices not shown.

In the depicted example distributed data processing system is the Internet with network representing a worldwide collection of networks and gateways that use the Transmission Control Protocol Internet Protocol TCP IP suite of protocols to communicate with one another. At the heart of the Internet is a backbone of high speed data communication lines between major nodes or host computers consisting of thousands of commercial governmental educational and other computer systems that route data and messages. Of course the distributed data processing system may also be implemented to include a number of different types of networks such as for example an intranet a local area network LAN a wide area network WAN or the like. As stated above is intended as an example not as an architectural limitation for different embodiments of the disclosed subject matter and therefore the particular elements shown in should not be considered limiting with regard to the environments in which the illustrative embodiments of the present invention may be implemented.

With reference now to a block diagram of an exemplary data processing system is shown in which aspects of the illustrative embodiments may be implemented. Data processing system is an example of a computer such as client in in which computer usable code or instructions implementing the processes for illustrative embodiments of the disclosure may be located.

With reference now to a block diagram of a data processing system is shown in which illustrative embodiments may be implemented. Data processing system is an example of a computer such as server or client in in which computer usable program code or instructions implementing the processes may be located for the illustrative embodiments. In this illustrative example data processing system includes communications fabric which provides communications between processor unit memory persistent storage communications unit input output I O unit and display .

Processor unit serves to execute instructions for software that may be loaded into memory . Processor unit may be a set of one or more processors or may be a multi processor core depending on the particular implementation. Further processor unit may be implemented using one or more heterogeneous processor systems in which a main processor is present with secondary processors on a single chip. As another illustrative example processor unit may be a symmetric multi processor SMP system containing multiple processors of the same type.

Memory and persistent storage are examples of storage devices. A storage device is any piece of hardware that is capable of storing information either on a temporary basis and or a permanent basis. Memory in these examples may be for example a random access memory or any other suitable volatile or non volatile storage device. Persistent storage may take various forms depending on the particular implementation. For example persistent storage may contain one or more components or devices. For example persistent storage may be a hard drive a flash memory a rewritable optical disk a rewritable magnetic tape or some combination of the above. The media used by persistent storage also may be removable. For example a removable hard drive may be used for persistent storage .

Communications unit in these examples provides for communications with other data processing systems or devices. In these examples communications unit is a network interface card. Communications unit may provide communications through the use of either or both physical and wireless communications links.

Input output unit allows for input and output of data with other devices that may be connected to data processing system . For example input output unit may provide a connection for user input through a keyboard and mouse. Further input output unit may send output to a printer. Display provides a mechanism to display information to a user.

Instructions for the operating system and applications or programs are located on persistent storage . These instructions may be loaded into memory for execution by processor unit . The processes of the different embodiments may be performed by processor unit using computer implemented instructions which may be located in a memory such as memory . These instructions are referred to as program code computer usable program code or computer readable program code that may be read and executed by a processor in processor unit . The program code in the different embodiments may be embodied on different physical or tangible computer readable media such as memory or persistent storage .

Program code is located in a functional form on computer readable media that is selectively removable and may be loaded onto or transferred to data processing system for execution by processor unit . Program code and computer readable media form computer program product in these examples. In one example computer readable media may be in a tangible form such as for example an optical or magnetic disc that is inserted or placed into a drive or other device that is part of persistent storage for transfer onto a storage device such as a hard drive that is part of persistent storage . In a tangible form computer readable media also may take the form of a persistent storage such as a hard drive a thumb drive or a flash memory that is connected to data processing system . The tangible form of computer readable media is also referred to as computer recordable storage media. In some instances computer recordable media may not be removable.

Alternatively program code may be transferred to data processing system from computer readable media through a communications link to communications unit and or through a connection to input output unit . The communications link and or the connection may be physical or wireless in the illustrative examples. The computer readable media also may take the form of non tangible media such as communications links or wireless transmissions containing the program code. The different components illustrated for data processing system are not meant to provide architectural limitations to the manner in which different embodiments may be implemented. The different illustrative embodiments may be implemented in a data processing system including components in addition to or in place of those illustrated for data processing system . Other components shown in can be varied from the illustrative examples shown. As one example a storage device in data processing system is any hardware apparatus that may store data. Memory persistent storage and computer readable media are examples of storage devices in a tangible form.

In another example a bus system may be used to implement communications fabric and may be comprised of one or more buses such as a system bus or an input output bus. Of course the bus system may be implemented using any suitable type of architecture that provides for a transfer of data between different components or devices attached to the bus system. Additionally a communications unit may include one or more devices used to transmit and receive data such as a modem or a network adapter. Further a memory may be for example memory or a cache such as found in an interface and memory controller hub that may be present in communications fabric .

Computer program code for carrying out operations of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C C Objective C or the like and conventional procedural programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Those of ordinary skill in the art will appreciate that the hardware in may vary depending on the implementation. Other internal hardware or peripheral devices such as flash memory equivalent non volatile memory or optical disk drives and the like may be used in addition to or in place of the hardware depicted in . Also the processes of the illustrative embodiments may be applied to a multiprocessor data processing system other than the SMP system mentioned previously without departing from the spirit and scope of the disclosed subject matter.

As will be seen the techniques described herein may operate in conjunction within the standard client server paradigm such as illustrated in in which client machines communicate with an Internet accessible Web based portal executing on a set of one or more machines. End users operate Internet connectable devices e.g. desktop computers notebook computers Internet enabled mobile devices or the like that are capable of accessing and interacting with the portal. Typically each client or server machine is a data processing system such as illustrated in comprising hardware and software and these entities communicate with one another over a network such as the Internet an intranet an extranet a private network or any other communications medium or link. A data processing system typically includes one or more processors an operating system one or more applications and one or more utilities. The applications on the data processing system provide native support for Web services including without limitation support for HTTP SOAP XML WSDL UDDI and WSFL among others. Information regarding SOAP WSDL UDDI and WSFL is available from the World Wide Web Consortium W3C which is responsible for developing and maintaining these standards further information regarding HTTP and XML is available from Internet Engineering Task Force IETF . Familiarity with these standards is presumed.

As will be described the UIMA techniques described below may be used to facilitate the development and testing of methods and system for analyzing unstructured content. One known technique for such analysis involves natural language processing.

By way of additional background question answering or question and answering or Q A is a type of information retrieval. Given a collection of documents such as the World Wide Web or a local collection a Q A system should be able to retrieve answers to questions posed in natural language. Q A is regarded as requiring more complex natural language processing NLP techniques than other types of information retrieval such as document retrieval and it is sometimes regarded as the next step beyond search engines. Closed domain question answering deals with questions under a specific domain for example medicine or automotive maintenance and it can be seen as an easier task because NLP systems can exploit domain specific knowledge frequently formalized in ontologies. Open domain question answering deals with questions about nearly everything and they can only rely on general ontologies and world knowledge. These systems usually have much more data available from which to extract the answer. Systems of this type are implemented as a computer program executed on a machine. Typically user interaction with such a computer program either is via a single user computer exchange or a multiple turn dialog between the user and the computer system. Such dialog can involve one or multiple modalities text voice tactile gesture or the like . Examples of such interaction include a situation where a cell phone user is asking a question using voice and is receiving an answer in a combination of voice text and image e.g. a map with a textual overlay and spoken computer generated explanation. Another example would be a user interacting with a video game and dismissing or accepting an answer using machine recognizable gestures or the computer generating tactile output to direct the user. The challenge in building such a system is to understand the query to find appropriate documents that might contain the answer and to extract the correct answer to be delivered to the user.

In the past understanding the query was an open problem because computers do not have human ability to understand natural language nor do they have common sense to choose from many possible interpretations that elementary natural language understanding systems can produce. A solution that addresses this problem is IBM Watson which may be described as among other things as an open domain Q A system that is an NLP artificial intelligence AI based learning machine. A machine of this type may combine natural language processing machine learning and hypothesis generation and evaluation it receives queries and provides direct confidence based responses to those queries. A Q A solution such as IBM Watson may be cloud based with the Q A function delivered as a service SaaS that receives NLP based queries and returns appropriate answers.

A representative Q A system such as described in U.S. Pat. No. 8 275 803 provides answers to questions based on any corpus of data. The method facilitates generating a number of candidate passages from the corpus that answer an input query and finds the correct resulting answer by collecting supporting evidence from the multiple passages. By analyzing all retrieved passages and that passage s metadata in parallel there is generated an output plurality of data structures including candidate answers based upon the analyzing step. Then by each of a plurality of parallel operating modules supporting passage retrieval operations are performed upon the set of candidate answers for each candidate answer the data corpus is traversed to find those passages having candidate answer in addition to query terms. All candidate answers are automatically scored causing the supporting passages by a plurality of scoring modules each producing a module score. The modules scores are processed to determine one or more query answers and a query response is generated for delivery to a user based on the one or more query answers.

In an alternative embodiment the Q A system may be implemented using IBM LanguageWare a natural language processing technology that allows applications to process natural language text. LanguageWare comprises a set of Java libraries that provide various NLP functions such as language identification text segmentation and tokenization normalization entity and relationship extraction and semantic analysis.

As noted above UIMA stands for Unstructured Information Management Architecture. It is a component architecture and software framework implementation for the analysis of unstructured content such as text video audio and the like. The framework originally developed by IBM and now an open source Apache project provides a common platform for unstructured analytics enables reuse of analysis components and reduce duplication of analysis development. It is pluggable architecture that allows developers to plug analysis components and to combine them together with other such components. The framework enables an analysis task which may not be monolithic to be carried out by a multi stage process where different modules build on each other to provide a more powerful analysis chain or pipeline. In some cases analysis components from different specialized vendors may need to work together to produce the results needed. Machines operating such components may be located remote from one another. Often the UIMA application interested in such analysis results does not need to know the details of how individual analysis components work together to create the results. The UIMA framework takes care of the integration and orchestration of multiple components.

UIMA provides a standards based architecture and software framework for creating discovering composing and deploying a broad range of multi modal analysis capabilities and integrating them with search technologies. Apache UIMA Framework is an available open source Java reference implementation that can be used to develop describe compose and deploy UIMA components and applications. The framework also provides a developer with an Eclipse based development environment that includes a set of tools and utilities for using UIMA.

UIMA specifies component interfaces in an analytics pipeline. In UIMA an Analysis Engine AE is a program that analyzes artifacts and infers information from them. An artifact is an unstructured item being analyzed by an annotator. It could be an HTML web page an image a video stream a recorded audio conversation an MPEG 4 stream a document or some portion thereof or the like. Analysis Engines are constructed from building blocks called Annotators. An Annotator which is a set of computer instructions that contains analysis logic analyzes an artifact and creates additional data about that artifact. An Analysis Engine AE may contain one or many Annotators. An Annotator produces its analysis result in the form of a Feature Structure which is a data structure that has a type and a set of attribute value pairs. An Annotation is a type of Feature Structure that is attached to a region of the artifact being analyzed such as a span of text in a document. All Feature Structures including Annotations are represented in a UIMA Common Analysis Structure CAS which is the primary data structure through which all UIMA components communicate. The CAS may be described as a common data structure share by UIMA framework components and that encapsulates analysis results shared across the various UIMA components. Typically the CAS is an in memory representation of the artifact being analyzed and as noted above includes content and metadata information in the form of Annotations with the CAS being supplied generated by a sequence of Annotators that each add metadata based on their own specific analysis logic and wherein subsequent Annotators build on the results from prior Annotators in the flow. The Apache UIMA framework provides a native Java interface to the CAS and that interface represents each Feature Structure as a Java object.

Generally a developer can develop and test a UIMA Annotator by defining the CAS types that the Annotator will use generate the Java classes for these types write the actual annotator Java code create an Analysis Engine descriptor and test the Annotator.

A UIMA pipeline is based on a UIMA pipeline configuration. A UIMA pipeline configuration file is a placeholder for resources used to annotate documents. It contains different stages e.g. language lexical analysis parsing rules and clean up . The stages are run consecutively and interact together to generate annotations. The UIMA pipeline configuration is often referred to a UIMA pipeline.

A UIMA pipeline configuration is created and configured using a tool such as IBM LanguageWare Resource Workbench. Using an Explorer tool the user navigates to Project Configuration Annotators directory and then selects New UIMA Pipeline Configuration. Using the display interface the user names the UIMA Pipeline configuration and can select whether to include a parsing rules stage in the pipeline. When finished the tool creates an .annoconfig file.

The UIMA Pipeliness configuration has four 4 main stages Document Language Lexical Analysis Parsing Rules and Clean up stage . The pipeline will not run unless the proper resources have been added. Using a first panel in the display interface a user first makes a Document Language selection and in particular i whether the document language configuration is automatically determined using a selected Acceptable Language ii determined using a specified dictionary or iii specified manually e.g. English . Then using a second panel in the display interface a user then makes a Lexical Analysis selection specifying the dictionary resources that will be used in the pipeline. The system may include built in dictionaries for different languages and that cover Lexical Analysis. To add custom dictionaries the user can open a workspace browser to obtain and add the relevant resources to the pipeline. Dictionaries from an Explorer function may be inserted into the pipeline configuration as well. Using another panel in the display interface the user continues to configure the Parsing rules. To add a parsing rules database the user can select to open the workspace browser to obtain and add the relevant resources. The user can also identify and drag a .jar file into the Parsing rules field. Using another panel in the display interface the user enters the Clean up stage. In this stage the user can select the Types concepts that are to be shown or hidden when annotating documents. This is useful when there are intermediate Types that the user does not want to see annotated in the final output of the document analysis. After all the resources have been added to the UIMA pipeline configuration the configuration is saved.

When a LanguageWare engine is in use for example in a Q A system the above described stages typically are contained within one of the stages shown in such as the Question Analysis.

The techniques herein assume the existence of a UIMA pipeline that is assembled from building blocks Annotators and those building blocks may themselves be created or sourced from multiple entities. Annotators may execute on different machines.

The subject matter herein substantially enhances productivity of Annotator developers by providing techniques and tools that obviate running a full pipeline every time a developer makes a change to a particular Annotator. In general this is achieved by automatically recording various states from a running UIMA pipeline and enabling replay of a particular Annotator e.g. by recreating conditions of the Annotator running in a full pipeline. As will be seen the approach provides the further advantage of enabling other pipeline modifications e.g. adding or removing Annotators without modifying existing descriptors that are not otherwise possible without pipeline re start as well as conditional stop execution on an Annotator based on CAS events such as specific feature read write and delete.

As described above it is assumed that an analytics pipeline has been configured and includes a set of Annotators. A representative pipeline is as shown in . An Annotator executes in one or more machines and there may be multiple machines operating in a distributed manner whether co located or remote from one another . According to this disclosure and as illustrated in an Annotator and potentially each Annotator in the pipeline is instrumented at its standard UIMA interface in a manner so as to capture additional information generated during the processing of the analysis logic therein. The Annotator is instrumented by a software agent that wraps the Annotator preferably using Aspect Oriented Programming AOP techniques. The software agent captures low level UIMA events that occur as the Annotator processes its analysis logic against the input received by the Annotator. In computing aspect oriented programming AOP involves breaking down program logic into distinct parts or so called concerns which cohesive areas of functionality. AOP implementations provide crosscutting expressions that encapsulate each concern in one place which is called an aspect. An aspect may modify the behavior of other code the non aspect part of a program by applying advice additional behavior at various join points points in a program specified in a quantification or query called a point cut. In AOP whenever program execution reaches one of the join points described in the point cut a piece of code the advice associated with the point cut is executed. AOP techniques are used herein to create point cuts and advices in tactically chosen low level UIMA application programming interfaces APIs . As a result event data is thrown off by the software agent which calls back to a monitoring host system . The monitoring host system receives similar callbacks from one or more other Annotators that are provisioned in a similar manner to capture event data using AOP point cuts and advices .

While instrumenting an Annotator using an AOP based software agent is a preferred technique to capture event data other event data capture techniques may be used. Thus for example an Annotator may be provided with built in native event capture code.

In this manner each of set of Annotators in the pipeline generates event data which data is then captured at the monitoring host system . As will be described below the monitoring host system may comprise one or more machines applications processes and associated databases. One of these applications is a pipeline inspector as illustrated in which operates to receive the events e.g. Run Start AE Start AE Finish Feature Read Feature Write Feature Remove Annotation Read Annotation Write and Run Finish illustrated. Of course the type of events associated with the AOP callbacks will depend on the Annotator logic the position within the pipeline the particular API provisioned and the like. The event data in the aggregate is sometimes referred to herein as an information map that describes a state of the pipeline or some portion thereof . In addition and according to a further aspect of this disclosure any intermediary CAS generated as a result of execution of a particular Annotator also is captured by the pipeline inspector. Further configuration parameters Type System configuration data and the like static information also is collected. In general the pipeline inspector then performs static analysis of the UIMA descriptors associated with the intermediary CAS together with a run time analysis of the pipeline events themselves.

Preferably a full run of the pipeline is carried out end to end to create the largest possible information map based on the dynamically generated events . Preferably the end to end run of the pipeline is performed multiple time perhaps with different input data sets to exercise as many code paths as possible. As the full pipeline is exercised in this manner more and more code paths are tested and further code dependencies are then expressed in the information map. The information map which describes these code dependencies may then be used to generate a reusable data model that can be replayed to facilitate Annotator development and testing as will be described in more detail below.

Although end to end execution of the pipeline even multiple times with different input datasets is preferred this is not required as the techniques herein may be applied to sub pipelines or more generally any portions of the pipeline that are capable of being run autonomously in a sand boxed manner .

The pipeline inspector is implemented in software executing in a computing entity or entities. It is the main component responsible for instrumenting and launching the pipeline Java Virtual Machine JVM to fire special events designed to provide run time analysis data the event data to collect and analyze these events and to generate an in memory pipeline run analysis the reusable data model that can then be serialized by a host application to perform the additional development activities. The host application may perform Annotator debugging testing and the like. Preferably a new pipeline inspector is instantiated and disposed for each pipeline run but this is not a requirement as a particular data model may receive event information and intermediary CASes and other configuration data from multiple or even partial pipeline runs.

Thus in a typical use case intermediary CASes and configuration parameters are captured during particular Annotation operation s and stored in a repository for later use. These later uses are sometimes referred to herein as replays and they may be quite varied. The following provides several example use cases. A replay preferably is carried out via a user interface that provides a mechanism by which a developer configures one or more replay scenarios each of which can leverage the reusable data model that represents the state of the pipeline execution. The particular user interface may be web based or provided by a native application executing in a graphical user interface and typically includes display panels menus navigation templates workspaces and the like.

In one example scenario when a user wants to run a particular Annotator standalone the system automatically uses the appropriate intermediary CASes available in the data model as input to this Annotator.

In another example scenario the user can also select an Annotator for soft deletion while re exercising the pipeline. In this case no existing descriptor is modified rather the software agent associated with the selected Annotator simply bypasses the Annotator at run time thereby essentially replacing its execution by a no operation no op . This has the same effect as if the Annotator was not present. With this approach developers can very quickly try out new pipeline configurations without editing existing descriptors which can be time consuming and error prone.

As another example scenario a user can select an Annotator to be inserted in the pipeline choosing the order of execution. Similar to the previous case the associated agent s then injects code in the Annotator that comes before and it uses an after advice to chain a call to the inserted Annotator.

The system also allows for debugging the pipeline using for example the Eclipse IDE JDT tooling such as shown in . While the user can still use traditional debug breakpoints the system can also conditionally stop Annotators at dynamically computed points in time. For example the user can choose to stop an Annotator if a particular feature is present not present or even if a particular feature structure has a field with a specific value etc. There are many other types of debugging possibilities that may be implemented in a similar manner and that will help the developer increase its productivity and resolve issues faster.

Without limitation the techniques herein may be implemented in a pipeline development environment such as IBM Watson WPDE. WPDE provides a toolset that includes an Annotator analysis tool to run and analyze any part of a pipeline. From Eclipse developers can use the WPDE tools to select component descriptors generate static models and perform performance and error analysis on a pipeline or any component in a pipeline when Annotators are instrumented according to the techniques herein the pipeline development environment may then also be used to generate the models containing run time analysis data as has been described. In particular the WPDE annotator tool provides pipeline run time analysis capabilities for the following tasks visually representing Annotator flow during a run collecting elapsed time for each Annotator showing the feature structures input output for each Annotator computing the Annotator dependencies based on features and annotations opening the UIMA descriptor or source class for a particular Annotator showing aggregation of data from multiple runs such as average timing and union of all the features and dependencies saving all CASes or saving intermediary CASes for selected Annotators supporting dynamically loaded Annotators and Annotators that are run multiple times and opening the CAS in an Annotation Viewer. The Annotation Viewer is a known UIMA editor and debugging tool.

A pipeline development environment such as described includes machines applications processes databases and interfaces to support the described functionality.

The subject disclosure provides significant advantages. The system enables automatic recording of a large amount of variables e.g. intermediary CASes configuration parameters etc. from a running pipeline. It enables developers to run a particular Annotator in a standalone manner thereby re creating the same conditions as if the Annotator were running within the full pipeline. Using this approach developers can experiment with the pipeline e.g. by preventing select Annotators from running soft delete without modifying the pipeline descriptors. The developer can then see the effect of an Annotator not being present in the pipeline. The approach further enables the developer to experiment with the pipeline by adding select Annotators soft addition without modifying the pipeline descriptors. In addition the developer can experiment with the pipeline by combining soft addition and soft deletion to perform a soft replacement of a particular Annotator. This can include replacing the Annotator class or other configuration parameters in the descriptor.

In this manner the developer is provided optimal manipulation granularity which provides significant advantages in terms of times saving and rapid turnaround. The disclosed subject matter preferably operates at the Annotator level which is a larger level of granularity that is inherent to UIMA systems. The Annotators that are chained together by descriptor sets can contain numerous classes and in fact they can be comprised of nested sets of additional Annotators. The Annotators can optionally invoke inter process services on the same machine or on remote machines. The subject technique supports addition removal and replacement at these Annotator levels. With this approach a developer can perform many different types of experiments e.g. he or she may replace an original Annotator e.g. comprised of dozens of classes with another using a different set of classes or he or she may replace one Annotator e.g. which runs locally to the main pipeline with another that calls out to a different machine to off load work.

As mentioned above UIMA pipelines can be substantial in size. In addition the UIMA platform typically runs an initialization process that instantiates and initializes all of the Annotators in the pipeline prior to inserting the first object of work at the input. Taking the example above e.g. a pipeline of 300 annotators taking 30 minutes for a run imagine a developer working on an Annotator that is used at the 200th position of that pipeline. During a run of a single input item all 300 Annotators are first created and initialized and then 199 other Annotators perform their work before the Annotator of interest is called. This is inefficient in terms of development time testing time processing and storage. Prior to the techniques disclosed herein the developer would need to restart the entire pipeline and repeat these steps it might be 25 of the 30 minutes are repeated on any restart. With the subject disclosure however the 30 minute run is performed once and extensive recording of the system states captures the essence of the run. The developer working on Annotator can swap in a new version of his or her work and then replay the system run by having the described technique pick up again with the state and data sets that had been presented to that Annotator and captured this eliminates the need to run initialization on all of the system and in this example scenario it also eliminates the processing of those first 199 predecessor units. The 25 minutes are reduced to seconds freeing the developer to debug or to test and compare alternatives with very rapid turnaround times.

Once the reusable data model is generated it may be used to facilitate the development of new UIMA pipelines using existing Annotators and Analysis Engines composed of such elements e.g. in a pipeline development environment that includes a visual editor. The visual editor may be web based e.g. configured as a set of web pages or a standalone visual editor executed in a graphical user interface or other display environment. There is no requirement to implement the visual editor with any particular platform or operating environment. A representative tool or more generally a visual design environment that may be used for this purpose includes Eclipse GEF Visual Designer. This is a software based tool that includes display palettes rendering tools drop and drag interfaces and the like. As shown in and using Eclipse Visual Designer a user can select an inspector wizard tool to review UIMA component descriptors invoke a static parsing tool to generate a static model of the pipeline as shown in GUI invoke other inspector functions and display the resulting model such as shown in display . In this example the GEF Editor responds to the inspector to overlay the run time analysis data obtained from the reusable data model on top of the static model shown in display thereby showing the Annotator elapsed time as well as a dependency graph of the Annotators.

The concept of dependency data is further explained by the example pipeline shown in . In particular is a sample pipeline showing annotators A C1 their run order 1 26 and arrows depicting dependencies between or among annotators. Using the approach described above the pipeline is executed end to end and the reusable data model is generated. As noted the model contains all of the information captured from instrumenting the pipeline namely run order dependencies features in and out for each Annotator intermediary CASes for a run TypeSystem definitions for each Annotator in the pipeline the Types used by each Annotator etc. Now assume a developer is working on annotator S. From the information map it can be seen that to run S it is first required to run Q and then C. That said however the map further reflects that to run Q it is first required to run M which in turn cannot be run until F is run and so on. Given this dependency graph it is possible to build a composite pipeline that only runs what is required by S and then stops after S is run. This is pipeline .

According to this disclosure a pipeline development environment includes a toolset that includes a visual design environment having an editor such as shown in . The editor comprises a display interface having a palette of known Annotators that may be selected by a developer. An Annotator may be selected from a set of icons a drop down list or in any other convenient manner. The pipeline development environment also includes or has associated therewith a data repository. The data repository stores datasets. A particular dataset is associated with an Annotator and comprises dependency data generated from execution of a pipeline or some portion thereof as described above. Thus and in the example scenario shown in pipeline is executed the reusable data model is generated and a dataset of dependency data associated with Annotator S is stored in the repository. The dependency data comprises one or more parent aggregate analysis engine descriptor s along with the required TypeSystem declarations configuration parameters and the like to implement the Annotator at least with respect to the pipeline in which that Annotator ran previously . An Annotator may have multiple dataset s associated therewith e.g. as a result of the Annotator being executed in distinct pipelines although typically there will be just one set of dependency data per Annotator. In like manner other dependency data for other Annotators such as those shown in is also stored in the repository. The repository typically stores datasets from many pipeline runs including runs of other pipelines multiple runs of a given pipeline with different inputs etc. In this manner the repository includes dependency data generated for Annotators based on the use of such Annotators in many pipelines. The repository may be local or remote centralized or distributed private or public or any combination of such characteristics.

Generalizing a pipeline development environment of this disclosure thus is associated with a repository that stores dependency data with respect to a set of Annotators that may be used as building blocks for pipelines. The dependency data for a particular Annotator preferably is derived from one or more information maps using the instrumenting techniques described above although this data may be collected or generated from other sources.

With the above as background it is now assumed that a developer desires to generate a new pipeline. As used herein a new pipeline may be a variant of an existing pipeline or a completely new pipeline generated from scratch or some combination thereof. Using the visual editor the developer selects an Annotator such as Annotator S and drags it or a representation thereof into a workspace a build area of the editor. Upon dropping the Annotator or taking some other such control action the tool automatically accesses the dependency data from the repository and generates all appropriate descriptors for the Annotator along with the required TypeSystem declarations configuration parameters and the like necessary to implement the Annotator. The descriptors for the Annotator may include aggregate parent analysis engine descriptors such as shown in wherein Annotator S included the above described set of parent Annotators and their run order and associated dependencies . Thus the developer s act of selecting the Annotator and placing it in the build area automatically generates the underlying descriptor tooling needed to place this Annotator into the pipeline being generated. The descriptor and other configuration data is imported from the repository and as noted above preferably the repository is populated with this dependency data as a result of generating the reusuable data models in the manner described herein.

The developer then selects a second Annotator from the palette and drags it into a visual or other association with the first Annotator S. In other words the developer drags the second Annotator and takes some action indicating that the second Annotator is connected to the first Annotator in the pipeline. As this connection action completes or under some other control the tool automatically updates the pipeline descriptors now taking into consideration the dependency data associated with the second Annotator once again preferably obtained from the repository as well as any potential cross dependencies based on a comparison of the dependency data from each of the two Annotators that are now connected to one another. The process continues by building the underlying pipeline descriptors TypeSystem declarations configuration parameters etc. for the pipeline as each new Annotator is added into the visualization on the editor. Once the pipeline descriptors have been created on the local file system a user may use other visual tools in the design environment to modify the design verify the integrity of the pipeline test the pipeline or portions thereof and then run the pipeline.

Thus in accordance with this disclosure the system automatically detects UIMA pipeline dependencies stores them in reusable data models and then applies this knowledge in the creation of a new UIMA pipeline that reuses the Annotators from the previously generated information maps. Using the design environment the developer can generate pipeline descriptor files dynamically to create a functioning pipeline.

The technique of dynamically building a UIMA pipeline based on previously generated information maps or more generally Annotator dependency data as described herein may be implemented using any visual tool editor that has been supplemented to include the underlying tooling necessary to maintain fetch and stitch together the descriptor and other dependency data derived from the data models. As has been described a preferred embodiment is a pipeline development environment PDE that provides a toolset that includes an Annotator analysis tool to run and analyze any part of a pipeline.

Thus according to this disclosure a development tool for building a pipeline comprises an editor with an associated palette of known Annotators e.g. generated from reusable data models . The palette may be constructed from a repository containing an aggregation of any number of information maps resulting e.g. from multiple pipeline analysis. To create a new pipeline or sub pipeline a user simply drags an Annotator into an editor workspace. The editor then generates a parent Aggregate Analysis Engine descriptor along with the required TypeSystem declarations configuration parameters etc. Using a drop and drag tool a user then drags subsequent annotators into the editor workspace and connects them at any point to have the generated pipeline updated. Once the pipeline descriptors have created on a file system a user uses existing tools to tweak the design as necessary and then runs the pipeline. In an alternative embodiment the pipeline may be run from within the tool using a dynamically generated run configuration.

According to this disclosure a pipeline development environment is provided and used to generate a functioning UIMA pipeline based on the data model and without requiring that a developer be aware of Annotator interdependencies. To this end dependencies that are generated within the data model are analyzed in an automated manner such that when an Annotator is added to a new pipeline its dependent Analysis Engines are added dynamically in the a correct sequence and with correct configuration parameters TypeSystem etc. required to produce a functioning pipeline. In addition during the process of generating the new pipeline the system may verify the integrity of the pipeline being generated and as necessary provide information about missing or potentially superfluous dependencies.

The technique herein provides several advantages. A pipeline developer who is developing a new version of an existing pipeline or a new pipeline can do so easily and quickly yet safe in the knowledge that any required Analysis Engines are added in the correct sequence. The technique enables developers to create a sub pipeline containing all of the Annotators that need to run before a particular Annotator under development this facilitates test of just that Annotator or set of Annotators through an appropriate run of the pipeline or portion thereof . This enables the developer to test and develop in a real pipeline environment while only running the absolute subset of Annotators needed. In addition developers can easily and quickly verify the integrity of an existing pipeline thus increasing their productivity as well as the overall pipeline performance.

Each of the agent instrumentation pipeline inspector Annotator replay and pipeline generator functions described above may be implemented as a standalone approach e.g. a software based function executed by a processor or it may be available as a managed service including as a web service via a SOAP XML interface in whole or in part. The particular hardware and software implementation details described herein are merely for illustrative purposes are not meant to limit the scope of the described subject matter. Any aspect of this functionality may be implemented in a cloud based manner.

More generally computing devices within the context of the disclosed subject matter are each a data processing system such as shown in or comprising hardware and software and these entities communicate with one another over a network such as the Internet an intranet an extranet a private network or any other communications medium or link. The applications on the data processing system provide native support for Web and other known services and protocols including without limitation support for HTTP FTP SMTP SOAP XML WSDL UDDI and WSFL among others. Information regarding SOAP WSDL UDDI and WSFL is available from the World Wide Web Consortium W3C which is responsible for developing and maintaining these standards further information regarding HTTP FTP SMTP and XML is available from Internet Engineering Task Force IETF . Familiarity with these known standards and protocols is presumed.

The scheme described herein may be implemented in or in conjunction with various server side architectures including simple n tier architectures web portals federated systems and the like. As noted the techniques herein may be practiced in a loosely coupled server including a cloud based environment.

Still more generally the subject matter described herein can take the form of an entirely hardware embodiment an entirely software embodiment or an embodiment containing both hardware and software elements. In a preferred embodiment the functionality 1 is implemented in software which includes but is not limited to firmware resident software microcode and the like. Furthermore the device specific functionality on either side of the channel can take the form of a computer program product accessible from a computer usable or computer readable medium providing program code for use by or in connection with a computer or any instruction execution system. For the purposes of this description a computer usable or computer readable medium can be any apparatus that can contain or store the program for use by or in connection with the instruction execution system apparatus or device. The medium can be an electronic magnetic optical electromagnetic infrared or a semiconductor system or apparatus or device . Examples of a computer readable medium include a semiconductor or solid state memory magnetic tape a removable computer diskette a random access memory RAM a read only memory ROM a rigid magnetic disk and an optical disk. Current examples of optical disks include compact disk read only memory CD ROM compact disk read write CD R W and DVD. A computer readable storage medium is a tangible non transitory item.

The computer program product may be a product having program instructions or program code to implement one or more of the described functions. Those instructions or code may be stored in a computer readable storage medium in a data processing system after being downloaded over a network from a remote data processing system. Or those instructions or code may be stored in a computer readable storage medium in a server data processing system and adapted to be downloaded over a network to a remote data processing system for use in a computer readable storage medium within the remote system.

In a representative embodiment the software agent pipeline inspector and replay and pipeline generator components are implemented in a special purpose computing platform preferably in software executed by one or more processors. The software is maintained in one or more data stores or memories associated with the one or more processors and the software may be implemented as one or more computer programs. Collectively this special purpose hardware and software comprises the functionality described above.

While the above describes a particular order of operations performed by certain embodiments of the invention it should be understood that such order is exemplary as alternative embodiments may perform the operations in a different order combine certain operations overlap certain operations or the like. References in the specification to a given embodiment indicate that the embodiment described may include a particular feature structure or characteristic but every embodiment may not necessarily include the particular feature structure or characteristic.

Finally while given components of the system have been described separately one of ordinary skill will appreciate that some of the functions may be combined or shared in given instructions program sequences code portions and the like.

The techniques herein are not limited to any particular software architecture and may be generalized for use in any framework in which individual software components are adapted to be chained or otherwise combined into larger functional engines or systems but wherein the individual components are capable of being developed executed and tested in an autonomous sand boxed manner. The software elements are loosely coupled building blocks. Thus the techniques are not limited to UIMA pipelines but may be implemented with other pipeline based software architectures exhibiting such characteristics. In any such embodiment the pipeline software system comprises a set of software elements components that are adapted to be chained together.

An element of a pipeline software system as defined herein typically is an Annotator but this is not a limitation. An element may also be a set of Annotators an Analysis Engine AE or some other component thereof.

The references to LanguageWare and other products are not intended to be limiting. While the techniques herein can be applied to UIMA stages created from LanguageWare tools LanguageWare stages are not required to be present. As noted above the particular source of an Annotator may be quite varied and the techniques herein work with Annotators irrespective of where they originate.

