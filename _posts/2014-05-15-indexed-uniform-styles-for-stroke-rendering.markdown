---

title: Indexed uniform styles for stroke rendering
abstract: Style parameters, which specify respective visual parameters for rendering a map feature at multiple zoom levels, are stored as an indexed data structure in one or more uniform variables that are (i) accessible in multiple stages of a rendering pipeline, (ii) unchanged during execution of the multiple stages of the rendering pipeline. A selection of a zoom level at which the map feature is to be displayed is received via a user interface. One or more indices (exactly one in a typical case) are paired with every stylized vertex drawn. The vertex shader is configured to retrieve corresponding style parameters from the indexed data structure using the one or more indices and render the map feature at the selected zoom level using the retrieved style parameters.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09495767&OS=09495767&RS=09495767
owner: GOOGLE INC.
number: 09495767
owner_city: Mountain View
owner_country: US
publication_date: 20140515
---
The present disclosure relates to interactive digital maps and more particularly to rendering representations of paths on digital maps at varying camera distances or zoom levels.

The background description provided herein is for the purpose of generally presenting the context of the disclosure. Work of the presently named inventors to the extent it is described in this background section as well as aspects of the description that may not otherwise qualify as prior art at the time of filing are neither expressly nor impliedly admitted as prior art against the present disclosure.

For information clarity roads bicycle paths transit lines and similar features are represented on digital maps in a stylized rather than a realistic form. For example the style in which a road segment is represented on a digital map can include a set of visual parameters such as the number of strokes e.g. one for the outline and one for the fill color per stroke attributes such as stroke width stroke color etc. Thus drawings stylized paths in near real time e.g. using Graphics Processing Unit or GPU hardware is essential for providing quality mapping applications. Without a high performance solution to drawings stokes a mapping application loses fluidity and without appropriately stylized stokes a mapping application loses aesthetics and or clarity.

Some mapping applications are implemented in a client server architecture where a computer or mobile device such as a smartphone runs a local client that is served map data from a centralized server. A map of the earth with sufficient detail for navigation requires a huge amount of data. To make this data manageable by client devices with limited resources memory disk space CPU processing cycles data is often buffered by the server and parceled out to the client as needed.

Client devices typically render scenes from a top down vantage point or at some angle from this vantage point up to ninety degrees. As the altitude of this vantage point changes the level of detail of the map view must change accordingly. For example the user may wish to view continents or city blocks. To manage this wide gamut of levels of detail servers often serve map data at discrete levels zoom levels corresponding to altitudes of views above the map.

As one example a server can provide definitions of styles for rendering roads and other map features at several discrete zoom levels. In some cases the server does not provide style definitions for every discrete zoom level in the valid range. Thus the server may provide style definitions for roads only at discrete zoom levels N and N 2 even if a client device at some point may display a digital map at zoom level N 1. Moreover on some devices such as smartphones and tablet computers capable of receiving gesture input the positioning of a virtual camera in a digital mapping application may be updated in a continuous manner or at least in a manner with much finer granularity than the discrete zoom levels at which data is served. It is therefore possible for a client device to display a digital map at zoom level 7.5 or 8.45 for example. However it is impractical for the server to attempt to provide style data to client devices for hundreds or thousands of fractional zoom levels.

To enable a rendering pipeline to efficiently interpolate style information defined for map features at several zoom levels a computing device encodes interpolatable visual parameters for various styles as an indexed data structure in uniform parameters which are accessible in multiple stages of a rendering pipeline and remain unchanged during execution of the various stages of the rendering pipeline. In this manner a mapping application can encode a single index into the indexed data structure representing the style information that can be decoded during vertex shading. Moreover to fluidly and continuously transition between zoom levels the vertex shader can interpolate style parameters to render map features at intermediate zoom levels for which style information is not available. As one example a certain stroke may have a style change across successive zoom levels. More specifically a road that may not be visible at five thousand meters above the ground but be visible a one thousand meters from the ground. When a client device receives only discrete zoom level data from a map data server the client device makes the transition appear natural and smooth by increasing the transparency of the road as the altitude increases until the road disappears.

According to one implementation of these techniques a method for providing map features on interactive digital maps includes storing style parameters which specify respective visual parameters for rendering a map feature at a plurality of zoom levels as an indexed data structure in one or more uniform variables that are i accessible in multiple stages of a rendering pipeline ii unchanged during execution of the multiple stages of the rendering pipeline. The method also includes receiving via a user interface a selection of a zoom level at which the map feature is to be displayed. Further the method includes providing one or more indices into the indexed data structure to a vertex shader based on the selected zoom level and causing the vertex shader to retrieve corresponding style parameters from the indexed data structure using the one or more indices and render the map feature at the selected zoom level using the retrieved style parameters.

According to another implementation a memory module e.g. a hard disk a flash drive or random access memory RAM stores instructions where the instructions are executable on one or more general purpose processors of a computing device such as a central processing unit CPU . The instructions cause the computing device to store style parameters which specify respective visual parameters for rendering a map feature at a plurality of zoom levels as an array of uniform variables that are i accessible in multiple stages of a rendering pipeline implemented in one or more graphics processors ii unchanged during execution of the multiple stages of the rendering pipeline wherein the array is indexed by style identifiers. The instructions further cause the computing device to receive via a user interface of the computing device a selection of a zoom level at which the map feature is to be displayed determine a style identifier that identifies a style using which the map feature is rendered at the selected zoom level provide the style identifier to a vertex shader executable on the one or more graphics processors and cause the vertex shader to retrieve corresponding style parameters from the array of uniform variables using the style identifier and render the map feature at the selected zoom level using the retrieved style parameters.

According to yet another implementation a computing device includes one or more general purpose processors a graphics pipeline implemented in one or more graphics processors a uniform buffer to store uniform parameters accessible in multiple stages of a rendering pipeline where the uniform parameters are unchanged during execution of the multiple stages of the rendering pipeline a user interface and a non transitory computer readable memory storing instructions. When executed by the one or more general purpose processors the instructions cause the computing device to store as an indexed data structure in the uniform buffer style parameters specifying respective visual parameters for rendering a map feature at a plurality of zoom levels. The instructions further cause the computing device to receive via a user interface a selection of a zoom level at which the map feature is to be displayed provide one or more indices into the indexed data structure to a vertex shader executable as part of the graphics pipeline in accordance with the selected zoom level and cause the vertex shader to retrieve corresponding style parameters from the indexed data structure using the one or more indices and render the map feature at the selected zoom level using the retrieved style parameters.

A mapping application operating in a computing device implements a graphics pipeline that includes vertex shaders and fragment shaders. The mapping application receives style parameters such as widths and colors of strokes and the number of strokes for rendering roads and or similar map features at certain zoom levels. To render these map features the mapping application augments a set of conventional vertex attributes which contain at least spatial information and in some cases other vertex attributes such as texture coordinates with indices into an indexed set of uniforms storing the style parameters. The uniforms are commonly accessible by all vertex shaders and fragment shaders and persistently store the style parameters through multiple executions of shaders. The mapping application provides the vertex attributes augmented with the indices to a vertex shader which retrieves via the indices and in some cases interpolates style parameters to generate interpolated style parameters for an intermediate zoom levels.

For clarity a brief overview of a typical graphics pipeline is provided below and an example computing system in which some or all of the techniques outlined above can be implemented is then discussed with reference to .

To render stylized roads and other features as discussed above a client device can utilize a hardware graphics renderer in a GPU that implements two pipeline shading stages. The first stage corresponds to vertex shaders that operate on vertices which describe polygons drawn in a framebuffer see below . The second stage corresponds to fragment shaders that operate on fragments visible in a frame or sets of pixels that make up a frame. For example the client device can create a collection of triangles made up of points defined in two or three dimensions and pass the collection of triangles to the GPU. For each triangle Tin the collection the GPU then can run a vertex shader on each vertex of triangle T and a fragment shader on each pixel enclosed by triangle T.

Modern hardware 3D graphics renderers such as an OpenGL ES renderer perform optimally when rendering state changes are minimal with respect to the amount of data being drawn. The basic I O model of these hardware renderers can be described as follows the renderers receive vertices and texture pixel data and produce fragments. Generally speaking to render a frame of information on a hardware graphics renderer the following steps are taken 1 the region in memory for storing bitmaps known as a framebuffer is cleared and 2 for each logical object in the rendered frame 2a vertex and texture data are prepared for rendering 2b the state of the graphics pipeline is set and 2c a draw function to draw the data is executed.

Step 2c above describes a common programming loop. Accordingly the fewer iterations there are of step 2c the better the software application will perform. This principle of maximizing rendering performance can be referred to as batching. To comply with the principle software applications must batch together as many like elements of graphics state and draw these like elements atomically.

Another important principle for maximizing performance is to minimize shading logic. Vertex shaders are executed once per vertex for objects visible in a frame being rendered whereas fragment shaders are executed at least once per output pixel fragment of the frame. In some cases fragment shading may occur many times for a single output fragment such as in multi pass or blended rasterization. A typical modern display may contain millions of pixels in an output frame and tens of thousands of vertices. To perform better software applications must reduce the complexity of these shaders that must be run so frequently.

Map data stored in the map database also can include descriptions of geometry for various other map features such as buildings parks and bodies of water text labels textures various forms of metadata etc. Some of these map features can be defined in a vector graphics format or another suitable scaleable format. In some cases map data also can include raster images in a bitmap format for example.

The map data server may organize and serve map data to client devices using any suitable scheme such as map tiling for example. Map tiles generally correspond to a two dimensional organization of geospatial data into a quadtree. Each tile at a given zoom level is divided into four tiles at the next level up to the highest level of magnification. Similarly three dimensional organization of geospatial data can be implemented using octrees. To map the surface of the Earth onto a plane Mercator or another suitable projection can be used.

The map database also stores style parameters for rendering roads at certain zoom levels. For example style parameters A A A . . . describe style parameters for various styles at zoom level 15 and style parameters B B B . . . describe style parameters for various styles at zoom level 17. Each set of style parameters can describe a respective color and width for each of several strokes. When providing road data to client devices the map data server can assign a style identifier to each road segment in a given map tile. For example the map data server can indicate that the segment of an interstate highway present in the map tile should be rendered using style a local road should be rendered using style a bicycle path should be rendered using style etc.

According to some implementations when the client device requests map data for a certain geographic area to be displayed at zoom level Z the map data server provides e.g. to the client device via the network style parameters and possibly other map data for the requested zoom level as well for the next zoom level Z 1. Further the map data server alternatively or additionally can provide some of the map data for the zoom level Z 1. Depending on the implementation the map data server can provide style parameters e.g. stroke 1 width 0x05 stroke 1 color 0xFFFF000 stroke 2 width 0x04 stroke 2 color 0x8000FF00 for several styles and at several zoom levels at the same time as the map data or during a separate session for retrieving style parameters.

For example the client device may request map data for rendering a digital map of a geographic region R at zoom level 15 and the map data server can provide the map data for zoom level 15 along with style information for zoom levels 15 and 17 for each road visible at zoom level 15 or alternatively zoom levels 15 and 17 . Using these style parameters the client device can scale representations of roads in the region R between zoom levels 15 and 17. More particularly the client device can use the techniques discussed in more detail below to interpolate style parameters and display a certain road segment at zoom level 16 16.3 15.55 etc.

With continued reference to the map data server can be implemented as a single device or as a group of devices. One or more of these devices can include one or more processors a network interface and a non transitory computer readable memory that stores instructions executable on the one or more processors . For example a request processor can process requests from a client device identify and retrieve relevant polylines and style parameters from the map database along with other relevant map data and transmit this data to the requesting client device.

Similarly the map database can be implemented in a single storage device or multiple storage devices. The communication network can include any suitable number of Internet links local area links long range wireless link short range wireless links etc.

In the example of the client device is a portable device such as a smartphone or tablet computer for example. In general however the techniques for interpolating style parameters and rendering patterns of graphics can be utilized both in portable and non portable computing devices. In this example a rendering module of the client device implements an interpolation technique that includes passing indices into an indexed set of uniforms to a vertex shader in the form of augmented vertex attributes.

The client device includes the rendering module a network interface configured to communicate with other devices via the network and a touchscreen configured to receive gesture based input and to display rendered images generated by the rendering module . The rendering module includes one or more general purpose processors a non transitory computer readable memory and a graphics card e.g. including one or more graphics processing units or GPUs that has buffer s . In other implementations the client device may include additional components or conversely not include some of the components illustrated in .

The memory of the client device stores a mapping application that generates interactive digital maps. Depending on the implementation the mapping application can operate as a standalone application or as a component of another application such as a web browser for example. The mapping application includes a style parameter encoder . In operation the style parameter encoder augments vertex attributes e.g. provided to the vertex shader with style indices or just indices for rendering map features where each of the indices refer to a corresponding style parameter stored in uniform storage of the graphics card referred to herein as simply uniforms . The graphics card may execute the interpolating vertex shader to retrieve style parameters from the uniforms via indices into the uniforms . The vertex shader and a fragment shader then render map features according to the retrieved style parameters. When a map feature is to be displayed at an intermediate zoom level e.g. a zoom level between two discrete zoom levels the vertex shader and the fragment shader may interpolate style parameters and render roads or other map features at specified zoom levels as discussed in more detail with reference to .

The uniforms of the graphics card may include any number of values attributes numbers symbols etc. utilized by a graphics pipeline to render graphics such as digital map tiles. The data or parameters in the uniforms is shared among all vertex shaders and fragment shaders of a graphics pipeline such as the the vertex shader and the fragment shader . In an implementation utilizing the OpenGL Shading Language GLSL the uniforms may be declared with a uniform storage qualifier and may be passed as parameters to any shader program. The uniforms remain unchanged i.e. they persist from the execution of one shader program to the execution of another shader program within a particular rendering process. In some implementations the uniforms may include constant values such as positions styles etc. across one or more vertices but in general the uniforms may include any parameters constant or non constant across one or more vertices and passible as parameters to all shaders of a graphics pipeline.

In some cases programs or modules such as application programming interfaces APIs of the graphics card may constrain the amount of storage for the uniforms . The buffers on the graphics card may store the uniforms e.g. as a read only register array . However the rendering module may also store the uniforms in larger off chip buffers to increase the amount of storage for the uniforms .

In some implementations the uniforms may store an indexed set of style parameters for all map tiles utilized by the mapping application . For example the uniforms may store color width or other style parameters for every map tile at every zoom level of a two dimensional organization of geospatial data e.g. of the globe . Such a storage of style parameters in the uniforms allows rendering without a need for frequent updates of the style parameters in the uniforms . However in some other implementations the uniforms may only store some of the style parameters utilized by the mapping application and may be updated over time to include more or different style parameters.

Referring to a graphics pipeline can be implemented in a rendering module graphics card or more generally hardware configured to render graphics. The pipeline includes a vertex shader and a fragment shader which can operate on a framebuffer . The vertex shader receives vertex attributes that include both conventional spatial parameters such as coordinates of vertices that make up a road centerline and texture coordinates and spatial parameters such as width color the number of strokes etc. During operation the vertex shader outputs values such as color that are passed to fragment shader in the form of so called varyings . The number of times Y the fragment shader executes can exceed the number of times X the vertex shader executes by a factor of 100 for example.

The graphics pipeline can be implemented in the graphics card in the client device for example. More specifically the style parameter encoder or other module operating in the mapping application can generate the vertex attributes . The shaders and can be implemented as the shaders and respectively.

As illustrated in before rendering individual frames of information data including vertex data and associated visual parameters is prepared or initialized stage . Style parameters may be stored in a uniform storage as an indexed set of uniforms for example as further discussed with reference to . Also indices or style indices into the indexed set of uniforms are encoded into style vertex attributes at stage which can be executed on a general purpose processors such as the processors of . As a more specific example the style parameter encoder can execute block as part preparing the graphics pipeline at stage . Vertex and texture data are readied for rendering at stage .

To render a frame of information in the graphics pipeline the framebuffer is cleared first at stage . At stage a logical object for drawing is selected. For example all road segments for a certain tile can be put into a Vertex Buffer Object VBO so as to be drawn with a one call to a draw function. In some cases if the amount of data does not fit into a single VBO the data is split into multiple VBOs. A corresponding style index can be encoded into each vertex to enable the vertex shader to look up style parameters for the vertex in a set of uniforms as this vertex is being drawn. As discussed below the style parameters can include color and width definitions for various strokes associated with the style.

The graphics pipeline state is set at stage and a draw function is called at stage to execute the vertex shader and the fragment shaders. The graphics pipeline then performs the stages and for the next logical object until every logical object in the frame has been drawn.

The vertex shader retrieves the style parameters from the uniforms based on the encoded style indices stage and strokes or otherwise renders logical objects such as roads according the retrieved style parameters . In some cases the vertex shader interpolates the style parameters for a certain zoom level stage as discussed in more detail with reference to .

Now referring to at least some of the blocks of an example method for generating parameters for the graphics pipeline of can be implemented in the style parameter encoder for example as a set of software instructions that execute on the processor s . Likewise at least some of the blocks of an example method for generating parameters for the graphics pipeline of can be implemented in the graphics card for example. Generally any combination of components of the rendering module may implement blocks of the example method .

The method begins at block where indices corresponding to style parameters are encoded into vertex attributes. These indices augment fixed vertex attributes that contain spatial position information related to an object such as Cartesian coordinates of the object. The indices may refer to or point to style parameters in a set of uniforms. The style parameters referred to by the indices may indicate widths and colors for several strokes number of strokes etc. as illustrated in the uniforms of . Referring back to one index may reference style parameters A for road style S at zoom level 15 another index may reference style parameters A for road style S at zoom level 15 and another index may reference style parameters B for road style S at zoom level 17.

In some implementations indices may be grouped into containers such as vertex buffer objects VBOs that are separate but which can be combined interchangeably with conventional vertex attributes describing position. Further the grouping of indices can be further delineated based on zoom levels. For example indices partitioned into a VBO may be aggregated into a vertex array object VAO for each zoom level. Again referring back to an index referring to style parameters A e.g. stored in the uniforms and an index corresponding to style parameters B both of which describe road style S at different zoom levels can form a zoom style group G which a vertex shader may use to interpolate style parameters at least in the range between zoom level 15 and zoom level 17.

At block indices representing styles along with the corresponding conventional vertex attributes may be bound e.g. by executing appropriate function s supported by the graphics pipeline and the programming language to the vertex shader when a frame of a scene is rendered for the current zoom level of the virtual camera. Thus indices pointing to uniform style parameters can be understood as logical variable groups of vertex attribute data that can be interchangeably combined with canonical fixed vertex attribute data in accordance with the current zoom level.

For example the mapping application of can process user input such as an instance of a pinch to zoom gesture applied to the touchscreen and determine that the current zoom level for the camera should be 15.7. The mapping application can obtain a polyline for a road segment visible in the viewport at zoom level 15.7 identify style S in which the road segment must be rendered and indicate to the style parameter encoder that the zoom level should be 15.7. The style parameter encoder in turn can select from among the available set of resources style parameters A and B for style S corresponding to zoom levels 15 and 17 respectively. The style parameter encoder then may execute blocks and to prepare vertex attributes including indices to the style parameters A and B for use by a vertex shader.

It is noted that if style parameters are available e.g. stored in the uniforms for zoom levels more proximate to the selected zoom level the mapping module A can use these parameters instead. Thus if style parameters for zoom levels 15 and 16 are available the mapping application may encode indices to these style parameters rather than indices to style parameters for zoom levels 15 and 17 for rendering a road at zoom level 15.7. Further if a current zoom level corresponds to a discrete zoom level the mapping application may only encode an index corresponding to style parameters of that discrete zoom level.

When the frame of the scene is rendered successive style parameters which correspond to successive zoom levels are retrieved from uniforms based on corresponding indices. The style parameters are in some cases interpolated in a vertex shader in accordance with the current zoom level of the virtual camera block . The fragments of the map feature are then drawn at block .

The position of a camera in a mapping application e.g. defining the visible area of a digital map may change near continuously e.g. when paired with a pinch gesture . However in some implementations rendering state updates required for drawing may only occur at the frequency of discrete zoom level changes. That is a rendering module may draw frames at an intermediate zoom level without the need to continuously update a GPU state containing style information.

Referring generally to it is noted that these techniques do not require a storage of style parameters for each vertex. Rather indices into a common set of indexed style parameters stored as uniforms prevent unnecessary replication of style parameters that are likely the same for many vertices.

The following additional considerations apply to the foregoing discussion. Throughout this specification plural instances may implement components operations or structures described as a single instance. Although individual operations of one or more methods are illustrated and described as separate operations one or more of the individual operations may be performed concurrently and nothing requires that the operations be performed in the order illustrated. Structures and functionality presented as separate components in example configurations may be implemented as a combined structure or component. Similarly structures and functionality presented as a single component may be implemented as separate components. These and other variations modifications additions and improvements fall within the scope of the subject matter of the present disclosure.

Hardware and software modules can provide information to and receive information from other hardware and or software modules. Accordingly the described hardware modules may be regarded as being communicatively coupled. Where multiple of such hardware or software modules exist contemporaneously communications may be achieved through signal transmission e.g. over appropriate circuits and buses that connect the hardware or software modules. In embodiments in which multiple hardware modules or software are configured or instantiated at different times communications between such hardware or software modules may be achieved for example through the storage and retrieval of information in memory structures to which the multiple hardware or software modules have access. For example one hardware or software module may perform an operation and store the output of that operation in a memory device to which it is communicatively coupled. A further hardware or software module may then at a later time access the memory device to retrieve and process the stored output. Hardware and software modules may also initiate communications with input or output devices and can operate on a resource e.g. a collection of information .

Some of the methods or routines discussed above may be performed by one or processors or processor implemented hardware modules. The performance of certain of the operations may be distributed among the one or more processors not only residing within a single machine but deployed across a number of machines. In some example embodiments the processor or processors may be located in a single location e.g. within a home environment an office environment or as a server farm while in other embodiments the processors may be distributed across a number of locations.

Some portions of this specification are presented in terms of algorithms or flow diagrams representing operations on data stored as bits or binary digital signals within a machine memory e.g. a computer memory . These algorithms or flow diagrams are examples of techniques used by those of ordinary skill in the data processing arts to convey the substance of their work to others skilled in the art. In this context methods represented by flow diagrams involve physical manipulation of physical quantities. Typically but not necessarily such quantities may take the form of electrical magnetic or optical signals capable of being stored accessed transferred combined compared or otherwise manipulated by a machine. It is convenient at times principally for reasons of common usage to refer to such signals using words such as data content bits values elements symbols characters terms numbers numerals or the like. These words however are merely convenient labels and are to be associated with appropriate physical quantities.

Unless specifically stated otherwise discussions herein using words such as processing computing calculating determining presenting displaying or the like may refer to actions or processes of a machine e.g. a computer that manipulates or transforms data represented as physical e.g. electronic magnetic or optical quantities within one or more memories e.g. volatile memory non volatile memory or a combination thereof registers or other machine components that receive store transmit or display information.

As used herein any reference to one embodiment or an embodiment means that a particular element feature structure or characteristic described in connection with the embodiment is included in at least one embodiment. The appearances of the phrase in one embodiment in various places in the specification are not necessarily all referring to the same embodiment.

Some embodiments may be described using the expression coupled and connected along with their derivatives. For example some embodiments may be described using the term coupled to indicate that two or more elements are in direct physical or electrical contact. The term coupled however may also mean that two or more elements are not in direct contact with each other but yet still co operate or interact with each other. The embodiments are not limited in this context.

As used herein the terms comprises comprising includes including has having or any other variation thereof are intended to cover a non exclusive inclusion. For example a process method article or apparatus that comprises a list of elements is not necessarily limited to only those elements but may include other elements not expressly listed or inherent to such process method article or apparatus. Further unless expressly stated to the contrary or refers to an inclusive or and not to an exclusive or. For example a condition A or B is satisfied by any one of the following A is true or present and B is false or not present A is false or not present and B is true or present and both A and B are true or present .

In addition use of the a or an are employed to describe elements and components of the embodiments herein. This is done merely for convenience and to give a general sense of the description. This description should be read to include one or at least one and the singular also includes the plural unless it is obvious that it is meant otherwise.

Upon reading this disclosure those of skill in the art will appreciate still additional alternative structural and functional designs for rendering digital maps through the disclosed principles herein. Thus while particular embodiments and applications have been illustrated and described it is to be understood that the disclosed embodiments are not limited to the precise construction and components disclosed herein. Various modifications changes and variations which will be apparent to those skilled in the art may be made in the arrangement operation and details of the method and apparatus disclosed herein without departing from the spirit and scope defined in the appended claims.

