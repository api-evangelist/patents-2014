---

title: Hierarchical bitmasks for indicating the presence or absence of serialized data fields
abstract: Disclosed are systems and methods for communicating with a sender machine and a receiver machine, and analyzing a bitmask associated with a message to be sent from the sender machine to the receiver machine, such that the bitmask comprises one or more presence bits and one or more absence bits, such that the presence bits indicate that an associated field of the message are included in the message and the absence bits indicate that an associated field of the message are omitted in the message. The systems and methods also dynamically determine compression instructions to compress the bitmask, and provide the compression instructions to the sender machine, wherein the compression instructions reduce size of the bitmask associated with the message to be sent to the receiver machine.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09137337&OS=09137337&RS=09137337
owner: TIBCO Software Inc.
number: 09137337
owner_city: Palo Alto
owner_country: US
publication_date: 20140609
---
This application is a continuation of and claims priority to U.S. patent application Ser. No. 13 298 236 entitled Hierarchical bitmasks for indicating the presence or absence of serialized data fields filed on Nov. 16 2011 that is a non provisional of and claims priority to U.S. Provisional Patent Application No. 61 414 342 entitled Hierarchical bitmasks for indicating the presence or absence of serialized data fields filed on Nov. 16 2010 both of which are hereby incorporated by reference in their entirety.

The disclosed embodiments relate generally to data compression and more specifically relate to a hierarchical approach for compressing and decompressing bitmasks.

Typical servers and communication systems do not provide efficient implementations to limit or decrease the size of transmissions which may cause the network to become congested. Typically all of the information of a transmission is necessarily passed through the network. Without data compression expensive resources are continuously consumed with every message including storage space and transmission bandwidth. Bitmasks or other methods may be used to decrease the size of messages sent in transmissions but bitmasks have overhead that increases the size of each compressed message. The additional size of bitmasks appended to each message may consume expensive resources and negatively affect communication speed. The need has arisen to provide a method and system for compressing the bitmasks associated with messages to address the issues of consuming expensive resources communication speed and network congestion.

According to an aspect of this disclosure systems are described for compressing and decompressing bitmasks. The systems may also include a sender machine and a receiver machine for compressing sending receiving and decompressing the bitmask across a network or data pipeline.

According to another aspect of this disclosure methods are described for compressing bitmasks and decompressing bitmasks. The methods may include building a representative tree and traversing the representative tree using a bitmask of n bits. The methods may further include creating nodes at a first level for a number of bits in the bitmask and aligning the nodes in a certain level of the representative tree while retaining the original left to right ordering of the bits in the bitmask. The methods may further include creating a parent level based on the first level or creating a new parent level based on the parent level etc.

The methods may further include creating an empty buffer and traversing the tree. For each non zero node in the tree the value of the node is appended to the buffer. The methods may further include optimizing a compressed bitmask by minimizing the number of bits used to represent strings of zeroes inverting a bitmask to convert a dense bitmask to a sparse intermediate bitmask and or inverting the compression and decompression algorithms to compress and decompress strings of ones rather than zeroes. Methods may further include ordering fields of the bitmask to group zero fields together.

According to another aspect of this disclosure methods are disclosed for decompressing a bitmask. The methods may include traversing compressed bitmask copying leaf nodes and reconstructing interleaving runs of zeroes by deducing zero sub trees.

Methods and systems are described below for a system that allows for the transmission of bitmasks in compressed form and for decompression of the bitmasks upon receipt of affected messages. In an embodiment this is exemplified in the realm of message based middleware. These embodiments save message buffer space rendering sender receiver message systems more efficient.

When parties in a network distributed computing system cloud computing system or any other sender receiver message system e.g. a sender machine and receiver machine in a message oriented middleware system agree on an ordered field based message format and a method for encoding such a message into a linear buffer buffer space may be saved by omitting fields for which no value is specified or for which the value is unchanged from the previous message in the sequence.

When omitting fields out of a pre arranged field set the sender machine may include a bitmask to indicate which fields are present or to indicate which fields are unchanged from the previous message in the sequence. For example a bitmask for a message with 64 fields can be represented by a sequence of 64 bits with each bit indicating the presence e.g. bit 1 or absence e.g. bit 0 of the sequentially ordered fields. Thus the bitmask may be encoded in 8 bytes and sent by a sender machine across a data pipeline or network to a receiving machine. A receiver machine can combine the bitmask message field definitions and the message buffer to reconstruct the original message.

The bitmask may be used to indicate presence or absence of information depending on whether the message has few fields or many i.e. in some modes a 1 bit may indicate the presence of information while the 0 bit may indicate the absence of information in other modes the opposite is true. A bitmask can indicate which mode is being used by signaling an extra bit or out of band. As discussed below a sparser bitmap with large runs or contiguous extents of 0 bits typically results in a better bitmask compression.

While bitmasks save buffer space by allowing absent or unchanged data fields to be omitted the bitmasks themselves also take space. A system and process for compacting bitmasks via a hierarchical representation are disclosed and this compression and decompression scheme produces especially good results for bitmasks that are relatively sparse few ones many zeroes and concentrated ones in contiguous positions .

Manager server is a server configured to analyze data flow in the system and may determine bottlenecks or opportunities for improved efficiencies in the system for example by re ordering data fields for enhanced bitmask compression or by introducing bitmask compression for a set of data messages . Manager server may include a manager engine for processing or executing the manager server analysis calculations re ordering etc. Thus Sender machine and receiver machine may not communicate with the manager server for every bitmask compression and decompression task. In an embodiment sender machine and receiver machine communicate with the manager server when determining a re ordering of data fields for enhanced bitmask compression and or for determining good data message set candidates for bitmask compression and decompression.

Format server and a format engine are configured to establish an agreement on message formats between sender machine and receiver machine . This agreement may be established outside of the context of bitmask compression and thus in an embodiment sender machine and receiver machine may not communicate with the format server for bitmask compression and decompression tasks. In an embodiment sender machine and receiver machine may communicate with format server when sender machine and receiver machine wish to encode decode format information in a message or set of messages.

Although format server and manager server are illustrated as separate servers in format server and manager server may be a single server a set of multiple servers acting as a single servers etc. Although not illustrated in some embodiments a message based middleware may be in communication with the sender machine and the receiver machine to facilitate the transmission of messages. In an embodiment an administrator machine may be in communication with the manager server allowing an administrator to alter settings of the manager server and in an embodiment the settings of the bitmask compression engine in the applications .

Sender machine and receiver machine allow for transmission of bitmasks in compressed form by processing and executing bitmask compression and decompression algorithms at application processing elements for system . This functionality provides performance dividends when a high number of messages where bitmask compression is significant relative to the size of present fields are communicated.

While illustrated as a single sender machine in system may comprise more than one sender machine . Although described as sender machine in sender machine may receive messages in some embodiments. While illustrated as a single receiver machine in system may comprise more than one receiver machine . Although described as receiver machine in receiver machine may generate and send messages in some embodiments. In some embodiments sender machine and receiver machine may be the same machine such that it can receive and send messages.

In some embodiments prearranged compression formats are optionally established at the format server . The message may be created and compressed at sender machine in which the compressed message is sent to the receiver machine via network and the message may be decompressed at the receiver machine . In some embodiments manager server analyzes data flow to determine optimal ordering of data fields. In some embodiments format server and manager server may monitor one or more messages communicated between one or more sender machines and receiver machines and dynamically determine a compression format to compress messages prior to being sent by the one or more sender machines .

Sender machine may use API calls to construct the compressed message which may then be sent to the receiver machine via network . The compressed message may consist of two parts 1 the compressed bitmask and 2 the fields themselves. Receiver machine may receive the compressed message and use 1 the prearranged format 2 the compressed bitmask and 3 the compressed fields in order to reconstruct the bitmask and interpret the data portion of a buffer. In an embodiment multiple servers and may be used to establish an agreed format between sender machine and receiver machine and for analyzing data flows and ordering of data fields.

Network may represent any form of communication network supporting circuit switched packet based and or any other suitable type of communications between sender machine receiver machine format server manager server and any other elements in . Network may additionally include any other nodes of system capable of transmitting and or receiving information over a communication network. Although shown in as a single element network may represent one or more separate networks including all or parts of various different networks that are separated and serve different respective elements illustrated in . Network may include routers hubs switches firewalls content switches gateways call controllers and or any other suitable components in any suitable form or arrangement. Network may include in whole or in part one or more secured and or encrypted Virtual Private Networks VPNs operable to couple one or more network elements together by operating or communicating over elements of a public or external communication network. In general network may comprise any combination of public or private communication equipment such as elements of the public switched telephone network PSTN a global computer network such as the Internet a local area network LAN a wide area network WAN or other appropriate communication equipment. In some embodiments network may not be used if all of the components are located on the same machine. In an embodiment sender machine and receiver machine may communicate through peer to peer P2P communications over network .

System may comprise sender machine receiver machine format server and manager server each of which may be any suitable computing device comprising a processor and a memory to perform the described functionality. Sender machine receiver machine format server and manager server may comprise one or more machines workstations laptops blade servers server farms and or stand alone servers. Sender machine receiver machine format server and manager server may include any hardware and or controlling logic used to communicate information to and from one or more elements illustrated in . For example sender machine receiver machine format server and manager server may be operable to receive and process data of different types that may be transmitted via different protocols or formats. Other elements in may also comprise hardware and or controlling logic to communicate information to and from one or more elements illustrated in . Memory may store any suitable information. Memory may comprise any collection and arrangement of volatile and or non volatile components suitable for storing data. For example memory may comprise random access memory RAM devices read only memory ROM devices magnetic storage devices optical storage devices and or any other suitable data storage devices. In particular embodiments memory may represent in part computer readable storage media on which computer instructions and or logic are encoded. Memory may represent any number of memory components within local to and or accessible by processor. Processor may represent and or include any form of processing component including general purpose computers dedicated microprocessors or other processing devices capable of processing electronic information. Examples of processor include digital signal processors DSPs application specific integrated circuits ASICs field programmable gate arrays FPGAs and any other suitable specific or general purpose processors.

At decision block whether the current level for the first iteration the first level has more than one node is determined. If the current level has more than one node then a new level is created and nodes are created at the new level for each k consecutive nodes in the current level at action . In an embodiment if the number of nodes at the current level is not a power of k then the nodes at the current level may be padded with nodes whose values are k zeroes. In another embodiment the original bitmask of n bits is padded with zeroes until its length is a power of k.

The new level nodes are assigned a value calculated as a concatenation of bits at action . In other words each bit in each new level node is calculated by determining the logical OR of one current level node s bits. Certain actions in the process are repeated except that the new level is considered the current level at the next iteration until the current level has one node at decision block . When the current level only has one node the process ends at block .

For example consider an n 27 k 3 bitmask 27 bit bitmask with a block size of 3 having the following bits 101001000000000000000011011. Following the process discussed in nodes are created for each successive block of k bits in the n bit bitmask at action . The example above contains nine successive blocks of k bits so nine nodes are created. The nodes are arranged in a first level of the representative tree in the original left to right ordering of the bits. This first level makes up the leaves of the representative tree.

Referring back to at decision block it is determined that the current level which for the first iteration is the first level has nine nodes. Thus the current level has more than one node and a new level is created with nodes for each k consecutive nodes in the current level at action . In this example the number of nodes at the current level is a power of n and the new level is not padded with nodes containing zeroes. The current level has nine nodes or three k consecutive nodes so three nodes are created in the new level.

Referring back to the new level nodes are assigned a value calculated as a concatenation of bits at action . As discussed above each bit in each new level node is calculated by determining the logical OR of one current level node s bits.

Referring back to in the present example the bits in the nodes of new level are determined by determining the logical OR of each of the current level nodes bits. For the left most node in the new level the left most bit is determined by the logical of the left most node in the current level . The logical OR of the left most node in the current level is 1 so the left most bit in the left most node in the new level is set to 1. The logical OR is determined for each node in the current level allowing for each bit in the nodes in the new level to be similarly determined.

Referring back to as discussed above certain actions in the process may be repeated except that the new level is considered the current level at the next iteration until the current level has one node at decision block . When the current level only has one node the process ends at block .

Referring back to and the present example the new level is now considered the current level at the next iteration. Thus for the next iteration the current level is level and the new level is level .

Referring to both and at decision block it is determined that the current level has three nodes. Thus the current level has more than one node and a new level is created with nodes for each k consecutive nodes in the current level at action . The current level has three nodes or one k consecutive node so one node is created in the new level . The action for determining the bit values in the node in new level are performed and the new level is considered the current level in the next iteration. Because the current level has one node the process ends during this iteration at block .

As discussed above in relation to to encode the tree as a representative compressed bitmask the representative tree is traversed. In an embodiment the tree is traversed in preorder but other orders may also be used.

Referring to and an empty buffer is generated at action . Starting at the root node the tree is traversed at action and the non zero content is recorded in the buffer for the compressed bitmask at action . Thus for present example the non zero root node is recorded followed by the non zero parent node and non zero child nodes from left to right and in the left most sub tree. Moving from left to right the next sub tree is the all zero parent node sub tree. Thus as discussed above in relation to the remainder of that node s sub tree is not traversed this entire sub tree containing nodes and is skipped with no values recorded. Moving from left to right the next sub tree is based on non zero parent node . Thus the non zero parent node and non zero child nodes from left to right in the right most sub tree are recorded. The buffer now contains the compressed bitmask 101 110 101 001 011 011 011. The compressed bitmask includes 21 bits instead of the original 27 bits. Compressing a single bitmask from 27 down to 21 when the bitmask is sent numerous times over a network achieves unexpected improvements in system efficiency. It follows that compressing small amounts of data e.g. around 1000 bytes or less sent numerous times over a networks using the processes disclosed herein results in unexpected efficiency improvements over known data compression techniques.

As discussed above the processes for compressing a bitmask minimize the number of bits needed to represent strings of zeroes. This is accomplished by skipping sub trees composed entirely of zeroes. This works well when the original bitmask is sparse with many zeroes and few ones. When the bitmask is dense many ones and few zeroes the original bitmask may be inverted with a bitwise ones complement to convert the dense bitmask to a sparse intermediate bitmask. E.g. 11101101111 becomes 00010010000.

A second method of implementing this optimization would be to invert the compression algorithm itself such that it compresses strings of ones rather than strings of zeroes. This would produce the substantially the same level of compression and would use an indicator bit to signal the receiver that the decompression semantics should be likewise inverted.

As noted the bitmask compression and decompression processes and systems discussed herein minimize the number of bits used to represent sub trees composed entirely of zeroes. When these bits represent data such as fields in a message that can be reordered the compression performance may be improved by grouping together data most likely to be present that is represented by 1 bits in the bitmask . In the case of message formats pre arranged ordered collection of fields for example fields that are commonly present in a message may be sorted to the front leaving long compressible strings of zeroes on the tail of the bitmask.

In a managed messaging system the ordering of the fields may be manually specified by the format s creator or an administrator in communication with a manager server. The field ordering may also be automatically managed via dynamic analysis of traffic by the manager server. This latter approach would allow a system to tune its bitmask compression to follow changes in message traffic.

While various embodiments have been described above it should be understood that they have been presented by way of example only and not limitation. Thus the breadth and scope of a preferred embodiment should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the claims and their equivalents for any patent that issues claiming priority from the present provisional patent application.

For example as referred to herein a machine or engine may be a virtual machine computer node instance host or machine in a networked computing environment. Also as referred to herein a networked computing environment is a collection of machines connected by communication channels that facilitate communications between machines and allow for machines to share resources. Also as referred to herein a server is a machine deployed to execute a program and may include software instances.

Resources may encompass any types of resources for running instances including hardware such as servers clients mainframe computers networks network storage data sources memory central processing unit time scientific instruments and other computing devices as well as software software licenses available network services and other non hardware resources or a combination thereof.

A networked computing environment may include but is not limited to computing grid systems distributed computing environments cloud computing environment etc. Such networked computing environments include hardware and software infrastructures configured to form a virtual organization comprised of multiple resources which may be in geographically disperse locations.

Services and applications are described in this application using those alternative terms. Services can be java services or other instances of operating code. A service application is a program running on a machine or a cluster of machines in a networked computing environment. Services may be transportable and may be run on multiple machines and or migrated from one machine to another.

Various terms used herein have special meanings within the present technical field. Whether a particular term should be construed as such a term of art depends on the context in which that term is used. Connected to in communication with or other similar terms should generally be construed broadly to include situations both where communications and connections are direct between referenced elements or through one or more intermediaries between the referenced elements including through the Internet or some other communicating network. Network system environment and other similar terms generally refer to networked computing systems that embody one or more aspects of the present disclosure. These and other terms are to be construed in light of the context in which they are used in the present disclosure and as those terms would be understood by one of ordinary skill in the art would understand those terms in the disclosed context. The above definitions are not exclusive of other meanings that might be imparted to those terms based on the disclosed context.

Words of comparison measurement and timing such as at the time equivalent during complete and the like should be understood to mean substantially at the time substantially equivalent substantially during substantially complete etc. where substantially means that such comparisons measurements and timings are practicable to accomplish the implicitly or expressly stated desired result.

Additionally the section headings herein are provided for consistency with the suggestions under 37 CFR 1.77 or otherwise to provide organizational cues. These headings shall not limit or characterize the invention s set out in any claims that may issue from this disclosure. Specifically and by way of example although the headings refer to a Technical Field such claims should not be limited by the language chosen under this heading to describe the so called technical field. Further a description of a technology in the Background is not to be construed as an admission that technology is prior art to any invention s in this disclosure. Neither is the Brief Summary to be considered as a characterization of the invention s set forth in issued claims. Furthermore any reference in this disclosure to invention in the singular should not be used to argue that there is only a single point of novelty in this disclosure. Multiple inventions may be set forth according to the limitations of the multiple claims issuing from this disclosure and such claims accordingly define the invention s and their equivalents that are protected thereby. In all instances the scope of such claims shall be considered on their own merits in light of this disclosure but should not be constrained by the headings set forth herein.

