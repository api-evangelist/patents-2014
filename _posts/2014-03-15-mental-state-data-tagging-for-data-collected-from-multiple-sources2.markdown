---

title: Mental state data tagging for data collected from multiple sources
abstract: Mental state data useful for determining mental state information on an individual, such as video of an individual's face, is captured. Additional data that is helpful in determining the mental state information, such as contextual information, is also determined. The data and additional data allows interpretation of individual mental state information. The additional data is tagged to the mental state data and at least some of the mental state data, along with the tagged data, can be sent to a web service where it is used to produce further mental state information.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09646046&OS=09646046&RS=09646046
owner: Affectiva, Inc.
number: 09646046
owner_city: Boston
owner_country: US
publication_date: 20140315
---
This application claims the benefit of U.S. provisional patent applications Mental State Data Tagging for Data Collected from Multiple Sources Ser. No. 61 790 461 filed Mar. 15 2013 Mental State Analysis Using Heart Rate Collection Based on Video Imagery Ser. No. 61 793 761 filed Mar. 15 2013 Mental State Analysis Using Blink Rate Ser. No. 61 789 038 filed Mar. 15 2013 Mental State Well Being Monitoring Ser. No. 61 798 731 filed Mar. 15 2013 Personal Emotional Profile Generation Ser. No. 61 844 478 filed Jul. 10 2013 Heart Rate Variability Evaluation for Mental State Analysis Ser. No. 61 916 190 filed Dec. 14 2013 Mental State Analysis Using an Application Programming Interface Ser. No. 61 924 252 filed Jan. 7 2014 and Mental State Analysis for Norm Generation Ser. No. 61 927 481 filed Jan. 15 2014. This application is also a continuation in part of U.S. patent application Collection of Affect Data from Multiple Mobile Devices Ser. No. 14 144 413 filed Dec. 30 2013 which claims the benefit of U.S. provisional patent applications Optimizing Media Based on Mental State Analysis Ser. No. 61 747 651 filed Dec. 31 2012 Collection of Affect Data from Multiple Mobile Devices Ser. No. 61 747 810 filed Dec. 31 2012 Mental State Analysis Using Heart Rate Collection Based on Video Imagery Ser. No. 61 793 761 filed Mar. 15 2013 Mental State Data Tagging for Data Collected from Multiple Sources Ser. No. 61 790 461 filed Mar. 15 2013 Mental State Analysis Using Blink Rate Ser. No. 61 789 038 filed Mar. 15 2013 Mental State Well Being Monitoring Ser. No. 61 798 731 filed Mar. 15 2013 and Personal Emotional Profile Generation Ser. No. 61 844 478 filed Jul. 10 2013 which is also a continuation in part of U.S. patent application Mental State Analysis Using Web Services Ser. No. 13 153 745 filed Jun. 6 2011 which claims the benefit of U.S. provisional patent applications Mental State Analysis Through Web Based Indexing Ser. No. 61 352 166 filed Jun. 7 2010 Measuring Affective Data for Web Enabled Applications Ser. No. 61 388 002 filed Sep. 30 2010 Sharing Affect Data Across a Social Network Ser. No. 61 414 451 filed Nov. 17 2010 Using Affect Within a Gaming Context Ser. No. 61 439 913 filed Feb. 6 2011 Recommendation and Visualization of Affect Responses to Videos Ser. No. 61 447 089 filed Feb. 27 2011 Video Ranking Based on Affect Ser. No. 61 447 464 filed Feb. 28 2011 and Baseline Face Analysis Ser. No. 61 467 209 filed Mar. 24 2011 and is also a continuation in part of U.S. patent application Sporadic Collection of Mobile Affect Data Ser. No. 14 064 136 filed Oct. 26 2012 which claims the benefit of U.S. provisional patent applications Sporadic Collection of Affect Data Ser. No. 61 719 383 filed Oct. 27 2012 Optimizing Media Based on Mental State Analysis Ser. No. 61 747 651 filed Dec. 31 2012 Collection of Affect Data from Multiple Mobile Devices Ser. No. 61 747 810 filed Dec. 31 2012 Mental State Analysis Using Heart Rate Collection Based on Video Imagery Ser. No. 61 793 761 filed Mar. 15 2013 Mental State Data Tagging for Data Collected from Multiple Sources Ser. No. 61 790 461 filed Mar. 15 2013 Mental State Analysis Using Blink Rate Ser. No. 61 789 038 filed Mar. 15 2013 Mental State Well Being Monitoring Ser. No. 61 798 731 filed Mar. 15 2013 and Personal Emotional Profile Generation Ser. No. 61 844 478 filed Jul. 10 2013 which is also a continuation in part of U.S. patent application Mental State Analysis Using Web Services Ser. No. 13 153 745 filed Jun. 6 2011 which claims the benefit of U.S. provisional patent applications Mental State Analysis Through Web Based Indexing Ser. No. 61 352 166 filed Jun. 7 2010 Measuring Affective Data for Web Enabled Applications Ser. No. 61 388 002 filed Sep. 30 2010 Sharing Affect Data Across a Social Network Ser. No. 61 414 451 filed Nov. 17 2010 Using Affect Within a Gaming Context Ser. No. 61 439 913 filed Feb. 6 2011 Recommendation and Visualization of Affect Responses to Videos Ser. No. 61 447 089 filed Feb. 27 2011 Video Ranking Based on Affect Ser. No. 61 447 464 filed Feb. 28 2011 and Baseline Face Analysis Ser. No. 61 467 209 filed Mar. 24 2011. The foregoing applications are each hereby incorporated by reference in their entirety.

This application relates generally to analysis of mental states and more particularly to tagging of mental state data collected from multiple sources.

People spend an ever increasing amount of time interacting with computers and consume a vast amount of computer delivered media. This interaction can be for many different reasons such as a desire to find educational or entertaining content to interact with others using social media to create documents and to play games to name a few examples.

In some cases the human computer interaction can take the form of a person performing a task using a software based tool running on a computer. Examples include creating a document editing a video and or doing one or more of the numerous other activities a modern computer can perform. The person might find the execution of certain activities interesting or even exciting and might be surprised at how easy it is to perform the activity. The person can become excited happy or content as he or she performs an interesting or exciting activity. On the other hand the person might find some activities difficult to perform and might become frustrated or even angry with the computer or software tool. In some cases for example users are surveyed in an attempt to determine whether or not a computer or computer program functioned well and to identify where the computer program might need improvement. However such survey results are often unreliable because the surveys are often completed well after the activity was performed. In addition survey participation rates can be low and people may not provide accurate and honest answers to the survey.

In other cases of human computer interaction a person might not be using a software tool to accomplish a task but instead might be consuming computer accessed content or media such as news pictures music or video. Currently people consuming computer driven content can tediously self rate the media if they wish to communicate personal preferences. In some cases viewers enter a specific number of stars corresponding to a level of like or dislike while in other cases users are asked to answer a list of questions. While a system for collecting users evaluations of media and other products or services can be a helpful metric current evaluation schemes are often tedious and challenging. Recommendations based on such a system of star rating and or other means of self reporting are imprecise subjective unreliable and are further limited by sample size as only a small number of viewers prove to actually rate the media they consume. Thus in many cases such subjective evaluation is neither a reliable nor practical way to evaluate personal responses to media.

A third party observer can also be used to evaluate the human computer interaction. A trained observer can often infer the user s mental state simply by observing the individual their actions and their context e.g. their environment. The third party might also interact with the user and ask them questions about how they are feeling or details about what they are doing. While such a methodology can provide interesting results the need for a trained observer to view and analyze the user means that using third party observers is not scalable to large numbers of people performing many tasks in many locations. It also might be possible that the mere presence of the observer impacts the user s mental state generating questionable results.

Mental state data such as video of an individual s face is captured on the individual and is useful for determining mental state information on that individual. Additional data is also determined that is helpful in determining the mental state information helps to interpret the mental state information or otherwise provides information about mental states. The additional data is tagged to the mental state data and at least some of the mental state data is sent to a web service where it may be used to produce mental state information. A computer implemented method for mental state analysis is disclosed comprising receiving two or more portions of mental state data tagged with additional information selecting one or more portions of the received two or more portions of mental state data based on the additional information that was tagged and analyzing the one or more selected portions of mental state data to generate mental state information wherein a result from the analyzing is used to render an output on mental states. The one or more portions of mental state data may be selected based at least in part on tags identifying a particular individual. The one or more portions of mental state data may be selected based at least in part on tags identifying a particular context.

In embodiments a computer implemented method for mental state analysis comprises capturing mental state data on an individual from a first source determining additional data about the mental state data wherein the additional data provides information about mental states tagging the additional data to the mental state data and sending at least a portion of the mental state data tagged with the additional data to a web service. The context may comprise an identity of another person in proximity of the individual.

In some embodiments a computer implemented method for mental state analysis comprises receiving an analysis based on both mental state data and additional data tagged to the mental state data and rendering an output based on the analysis. In some embodiments a computer implemented method for mental state analysis comprises obtaining mental state data which is collected on an individual from multiple sources determining a portion of the mental state data that is to be sent to a web service determining additional data about the mental state data tagging the additional data to the portion that is to be sent to the web service analyzing the mental state data from multiple sources using the additional data that was tagged and rendering an output about mental states based on the mental state data on the individual from multiple sources along with the additional data that was tagged. In embodiments a computer program product embodied in a non transitory computer readable medium for mental state analysis comprises code for capturing mental state data on an individual from a first source code for determining additional data about the mental state data wherein the additional data provides information about mental states code for tagging the additional data to the mental state data and code for sending at least a portion of the mental state data tagged with the additional data to a web service. In some embodiments a computer system for mental state analysis comprises a memory which stores instructions one or more processors attached to the memory wherein the one or more processors when executing the instructions which are stored are configured to capture mental state data on an individual from a first source determine additional data about the mental state data wherein the additional data provides information about mental states tag the additional data to the mental state data and send at least a portion of the mental state data tagged with the additional data to a web service.

Various features aspects and advantages of various embodiments will become more apparent from the following further description.

As a user interacts with a computing device the user s mental state can provide valuable insight into the nature of the human computer interaction. The mental state of the user can include such emotions as frustration confusion disappointment hesitation cognitive overload fear exhaustion focus engagement attention boredom exploration confidence trust delight satisfaction excitement happiness contentment or many other human emotions. Understanding a user s mental state as he or she interacts with the computing device can prove valuable for a variety of reasons including determining which aspects of a computer program are working well and which aspects need improvement determining aspects of a computer game that are too difficult for some users or too easy for some users measuring the effectiveness of advertisements determining which parts of a video most please a specific user or determining a user s preferences in order to better suggest what other media games or applications the specific user finds appealing among other potential reasons.

While consuming media the user can exhibit physical manifestations of his or her mental state such as facial expressions physiological reactions and movements. Sensors coupled to a computer depending on the embodiment either the same computer with which the user is interacting or one or more other computers can detect capture and or measure one or more external manifestations of the user s mental state. In embodiments for example a still camera can capture images of the user s face a video camera can capture images of the user s movements a heart rate monitor can measure the user s heart rate a skin conductance sensor can detect changes in the user s electrodermal activity response and an accelerometer can measure such movements as gestures foot tapping or head tilts. Many other sensors and capabilities are possible. Some embodiments include multiple sensors to capture the user s mental state data.

Other data related to the mental state data can be determined the identity of the individual being monitored for example. Additionally the task that the individual is performing or the media that the user is consuming can be identified among other data points. A time date and or location can be logged and surrounding environmental data such as temperature humidity lighting levels noise levels and the like can be determined. Any number of other factors can be determined and tagged to the mental state data in order to associate the additional data with the mental state data. Tagging the additional data to the mental state data can be performed by including the additional data in the file that holds the mental state data. Any format can be used for the additional data depending on file format used for the mental state data. Some examples of formats that can be used for the additional data include but are not limited to ID3 exchangeable image file format EXIF extensible metadata platform XMP or other metadata standards. By tagging the mental state data with the additional data the additional data is persistently associated with the mental state data.

Once the mental state data has been collected and tagged with the additional data at least some of the tagged mental state data is sent to a web service. The web service can comprise a computer that is communicated with over a network or through a network of networks such as the internet. The web service receives the tagged mental state data and selects some of the tagged mental state data based on the additional data included in the tags. The web service then analyzes the selected tagged mental state data to create mental state information about the individual. The mental state information is then used either by the web service or by another computer that receives the mental state information from the web service to render an output. In some embodiments the rendering is performed on the computer hosting the web service while in other embodiments the rendering is either executed on the computer that originally collected the mental state data or on a different computer.

The rendered output can include text icons pictures graphs binary data or any other form or output that depending on the embodiment can be interpreted by a person or another computer. In at least one embodiment the rendered output includes a graph showing the prevalence of a particular mental state over time. In some embodiments the rendered output includes an icon that changes based on the user s mental state. In some embodiments the rendered output includes a file containing numerical data based on the obtained analysis. The result of the mental state analysis can also be included in a calendar where it can be displayed or compared with the ongoing activities already included in the calendar.

The flow also includes determining additional data about the mental state data. The additional data can be information about the identity of the individual information about the source of the mental state data contextual information or other metadata. In other words the additional data can include information on a source that collected the mental state data and or the context in which the mental state data was collected. In some embodiments the context comprises a time while in other embodiments the context comprises a location . The location can be determined by any mechanism including but not limited to internet protocol IP address mapping manual entering of location data by an operator or the individual being monitored or by receiving radio broadcasts. In at least one embodiment the location is determined using GPS. The location can be identified using any type of identification including but not limited to an address latitude and longitude coordinates a building identifier or a room identifier. Practically the location information could identify a building a room or another type of address or position. Additionally in some embodiments the context comprises environmental information .

In many embodiments the context comprises an activity performed by the individual. The activity includes at least one of talking on a phone playing a videogame working at a computer or watching a media presentation depending on the embodiment. The context can further include information further identifying the context such as the name or number of the other party on the phone the name of the videogame a descriptor of the activity being performed within the videogame the type of activity being worked on with the computer the name of the media presentation being watched or other information. In other embodiments the context comprises an identity for another person or other people within a given proximity of the individual. The additional data can include human coded information on the individual. The additional data can be annotated information using the human coded information. The human coded information can include analysis of mental states seen by the human coder in the face of the individual. The human coded information can include a summary of the mental state analysis.

The additional data can include information about an identity of the individual . The information about the individual can be in any form but in some embodiments the information about the identity of the individual includes a name of the individual and or an identity value for the individual. The identity of the individual can be determined by any method including but not limited to manual entry by the individual or an operator a computer system account login or an identity card scan. In at least one embodiment the information about the identity of the individual is determined using face recognition.

The various data and additional data from multiple sources can be synchronized. In some embodiments the data and additional data can include timestamps for synchronizing. In other cases some repetitive pulse can be used to align information as needed which can in some cases be an audio or light pulse or group of pulses. These pulses can be used for later alignment of the data and additional data during analysis.

The flow includes tagging the additional data to the mental state data . Through such tagging additional data can be associated with the mental state data. The tagging can be done by any method for associating data in a computer system. By tagging the mental state data with the additional data the additional data is associated with the mental state data in a persistent manner. In some embodiments the additional data can be included in the file that holds the mental state data. Depending on file format used for the mental state data any format can be used for the additional data. Some examples of formats that can be used for the additional data include ID3 exchangeable image file format EXIF extensible metadata platform XMP or any other metadata standard. In other embodiments the additional data is stored in a separate file linked to the file that holds the mental state data. In yet other embodiments a separate file contains links to both the additional data file and the mental state data file.

The flow includes sending at least a portion of the mental state data tagged with the additional data to a web service . The web service can be contacted over a network or a network of networks such as the Internet and the web service can be hosted on a different computer than the computer used to capture the mental state data. The mental state data can be partitioned based on the additional data. The portion of the mental state data to be sent to the web service can be determined based on the additional data. In one embodiment the tagged mental state data is examined and the portions which are tagged with the identity of a particular individual are sent. In other embodiments the portions that are tagged with a particular activity are sent. Other embodiments utilize different tags to determine the portions of the mental state date to be sent. In at least one embodiment the portion of the mental state data to be sent to the web service is determined based on facial recognition performed on the mental state data when the mental state data is comprised of facial images. The mental state data can be combined with data from other sources such as social media information to augment the mental state analysis. In some cases a user can obtain feedback based on the mental state data in order to enhance an experience for the user.

The flow can further comprise analyzing the mental state data to produce mental state information. In some embodiments the analyzing is performed based on facial movement. Other embodiments analyze biosensor data to produce mental state information. Various mental states can be inferred such as frustration confusion disappointment hesitation cognitive overload fear exhaustion focus engagement attention boredom exploration confidence trust delight satisfaction excitement happiness sadness stress anger contentment or many other human emotions. In some embodiments the additional data is used in conjunction with the mental state data to produce the mental state information. In some embodiments the additional data is used to limit the mental state data that is analyzed. In other embodiments the additional data directly contributes to the determining of the mental state such as by analyzing the contents of an email being read. Various steps in the flow may be changed in order repeated omitted or the like without departing from the disclosed concepts. Various embodiments of the flow may be included in a computer program product embodied in a non transitory computer readable medium that includes code executable by one or more processors.

As the user is monitored the user can move due to the nature of the task boredom distractions or for another reason. As the user moves the user s face can be visible from one or more of the multiple sources. In some embodiments for example if the user is looking in a first direction the line of sight from the webcam can observe the individual s face but if the user is looking in a second direction the line of sight from the room camera can observe the individual s face. Further if the user is looking in a third direction the line of sight from the phone camera can observe the individual s face. If the user is looking in a fourth direction the line of sight from the tablet cam can observe the individual s face. If the user is looking in a fifth direction the line of sight from the wearable camera can observe the individual s face. The wearable device such as the glasses can be worn by another user or an observer. In other embodiments the wearable device is a device other than glasses such as an earpiece with a camera a helmet or hat with a camera a clip on camera attached to clothing or any other type of wearable device with a camera or other sensor for collecting mental state data. The individual can also wear a wearable device including a camera which can be used for gathering contextual information and or collecting mental state data on other users. Because the individual can move his or her head the facial data can be collected intermittently when the individual is looking in a direction of a camera. In some cases multiple people are included in the view from one or more cameras and some embodiments include filtering out faces of one or more other people to determine whether the individual is looking toward a camera.

A second track can include continuously collected mental state data such as electrodermal activity data . A third track can include facial data which can be collected on an intermittent or continuous basis by a first camera such as the room camera of . Thus the mental state data from the first source can include facial information. The facial data can be collected intermittently when the individual is looking toward a camera. The facial data can include one or more still photographs videos or abstracted facial expressions which can be collected when the user looks in the direction of the camera. A fourth track can include facial data collected on an intermittent or continuous basis by a second camera such as the mobile phone cam of . The fourth track can include three instances of collected facial data and . The three collected instances of facial data and can include one or more still photographs videos or abstracted facial expressions which can be collected when the user looks in the direction of a camera.

A fifth track can include contextual data collected simultaneously with the mental state data. In one example the fifth track includes location data environmental information and time data although other contextual data can be collected in other embodiments. In the embodiment shown the fifth track of contextual data can be associated with the fourth track of mental state data. Some embodiments determine multiple tracks of additional data that can be associated with one or more tracks of mental state data. For example another track can include identity information of the individual being monitored by the camera capturing the third track of mental state data.

Additional tracks in the timeline shown through the nth track of mental state data or additional data of any type can be collected. The additional tracks can be collected on a continuous or on an intermittent basis. The intermittent basis can be either occasional or periodic. Analysis can further comprise interpolating mental state data when the collected mental state data is intermittent and or imputing additional mental state data where the mental state data is missing. One or more interpolated tracks can be included and can be associated with mental state data that is collected on an intermittent basis such as the facial data of the fourth track . The two instances of interpolated data interpolated data and interpolated data can contain interpolations of the facial data of the fourth track for the time periods where no facial data was collected in that track. Other embodiments interpolate data for periods where no track includes facial data. In other embodiments analysis includes interpolating mental state analysis when the collected mental state data is intermittent.

The mental state data such as the continuous mental state data and or any of the collected facial data can be tagged. In the example timeline shown facial data and are tagged. The tags can include metadata related to the mental state data including but not limited to the device that collected the mental state data the individual from whom the mental state data was collected the task being performed by the individual the media being viewed by the individual and the location the environmental conditions the time the date or any other contextual information useful for mental state analysis. The tags can be used to locate pertinent mental state data for example the tags can be used to identify useful mental state data for retrieval from a database. The tags can be included with the mental state data that is sent over the internet to cloud or web based storage and or services and can be used remotely but the tags can also be used locally on the machine where the mental state data was collected.

In embodiments additional data which provides information about the mental state data is determined. Such additional data can be tagged to the mental state data as mental state metadata . The mental state metadata can provide information about the mental states useful in the analysis of the mental state data . The mental state metadata or additional data is data that is not tagged to the mental state data by the source of the mental state data and not always known to the source of the mental state data . Thus the mental state metadata is tagged to the mental state data by an entity that is not the original source of the mental state data.

In one embodiment a video camera is used to capture the mental state data . The video camera can include standard metadata such as time and date and model number of the camera along with the video image which in this case comprises video image mental state data in a MPEG 4 data stream that is sent from the video camera to a mental state collection machine. The standard metadata can be included using standard metadata formats defined by the MPEG 4 specification. The mental state collection machine can determine an identity of the individual being monitored such as a login ID and an activity of that individual such as watching a particular media presentation. The mental state collection machine can then tag the video image with the login ID and the name of the particular media presentation as mental state metadata . In at least one embodiment the mental state collection machine formats the mental state metadata as XMP metadata and includes it in the MPEG 4 file. Other embodiments determine different additional information to be used as mental state metadata and use different formats to tag the mental state data with the mental state metadata .

Once the data collection machine has captured mental state data at least a portion of the mental state data tagged with the additional data is sent to a web service. The portion of the mental state data sent to the web service can be based on the additional data or can be based on mental state metadata . At the web service portions of mental state data can be selected for analysis based at least in part on tags identifying one or more contexts. In at least one embodiment the selected portions are based at least in part on identifying a particular individual. In some embodiments the selected portions include tags identifying at least two different timestamps so that samples can be distributed over a period of time. In at some embodiments the selected portions are based at least in part on tags identifying a particular context. Once the portions are selected they can be analyzed by the web service and used to create mental state information.

The flow continues by analyzing the one or more selected portions of mental state data to generate mental state information wherein a result from the analyzing is used to render an output on mental states . Analysis and rendering based on tagged data can aid a human user in being able to focus on areas of particular interests without wading through enormous sums of irrelevant data. A rendering can include a summary of mental states a graphical display showing a media presentation and associated mental states a social media pages with mental state information and the like. The rendering can also include excerpts of a media presentation such as in some embodiments a highlight reel style presentation based on mental states and associated tagged data. In some cases portions of a media presentation can be excluded based on mental states and tagged data. In some embodiments the same computer that was used to analyze the mental state data is also used to render the output but in other embodiments the output used for rendering being sent to another computer where the other computer provides the rendering. The rendering can be any type of rendering including textual rendering graphical rendering pictorial rendering or a combination thereof. In some embodiments another computer can provide information to another user. This other user can perform various analyses including A B type testing and comparisons. Various steps in the flow may be changed in order repeated omitted or the like without departing from the disclosed concepts. Various embodiments of the flow may be included in a computer program product embodied in a non transitory computer readable medium that includes code executable by one or more processors.

Mental states can be inferred based on physiological data such as the physiological data from the sensor . Mental states can also be inferred based on facial expressions and head gestures observed by a webcam or by using a combination of data from the webcam and data from the sensor . The mental states can be analyzed based on arousal and valence. Arousal can range from being highly activated such as when someone is agitated to being entirely passive such as when someone is bored. Valence can range from being very positive such as when someone is happy to being very negative such as when someone is angry. Physiological data can include one or more of electrodermal activity EDA heart rate heart rate variability skin temperature respiration accelerometer readings and other types of analysis of a human being. It should be understood that both here and elsewhere in this document physiological information can be obtained either by biosensor or by facial observation via an image capturing device. Facial data can include facial actions and head gestures used to infer mental states. Further the data can include information on hand gestures body language and body movements such as visible fidgets. In some embodiments these movements are captured by cameras while in other embodiments these movements are captured by sensors. Facial data can include tilting of the head to the side leaning forward smiling frowning and many other gestures or expressions.

In some embodiments electrodermal activity is collected either continuously every second four times per second eight times per second 32 times per second or on some other periodic basis. Alternatively electrodermal activity can be collected on an intermittent basis. The electrodermal activity can be recorded and stored onto a disk a tape flash memory or a computer system or can be streamed to a server. The electrodermal activity can be analyzed to indicate arousal excitement boredom or other mental states based on observed changes in skin conductance. Skin temperature can be collected and or recorded on a periodic basis. In turn the skin temperature can be analyzed . Changes in skin temperature can indicate arousal excitement boredom or other mental states. Heart rate information can also be collected recorded and analyzed . A high heart rate can indicate excitement arousal or other mental states. Accelerometer data can be collected and used to track one two or three dimensions of motion. The accelerometer data can be recorded. The accelerometer data can be used to create an actigraph showing an individual s activity level over time. The accelerometer data can be analyzed and can indicate a sleep pattern a state of high activity a state of lethargy or other states. The various data collected by the biosensor can be used along with the facial data captured by the webcam in the analysis of mental state. Contextual information can be based on one or more of skin temperature and accelerometer data. The mental state data can include one or more of a group including physiological data facial data and accelerometer data.

The individual can interact with the mental state collection machine interact with another computer view a media presentation on another electronic display and or perform numerous other activities. The system can include a computer program product embodied in a non transitory computer readable medium including code for capturing mental state data on an individual from a first source code for determining additional data about the mental state data wherein the additional data provides information about mental states code for tagging the additional data to the mental state data and code for sending at least a portion of the mental state data tagged with the additional data to a web service. With such a program stored in memory the one or more processors can be configured to capture mental state data on an individual from a first source determine additional data about the mental state data wherein the additional data provides information about mental states tag the additional data to the mental state data and send to a web service at least a portion of the mental state data tagged with the additional data. In some embodiments the second camera device can be used as a second source of mental state data which is tagged with the additional data and sent to the web service.

Some embodiments can include an analysis server . In embodiments the analysis server can be configured as a web service. The analysis server includes one or more processors coupled to a memory to store instructions. Some embodiments of the analysis server include a display . The one or more processors can be configured to receive tagged mental state data from the mental state collection machine the first camera device and or any other computers configured to collect mental state data. The one or more processors can then select one or more portions of the received mental state data based on the additional data from the tags and can then analyze the received mental state data . The analysis can produce mental state information inferred mental states emotigraphs actigraphs other textual graphical representations or any other type of analysis. The analysis server can display at least some of the analysis on the display and or can provide the analysis of the mental state data to a client machine such as the mental state data collection machine or another client machine so that the analysis can be displayed to a user. The analysis server can enable a method that includes receiving two or more portions of mental state data tagged with additional information selecting one or more portions of the received two or more portions of mental state data based on the additional data from the tags and analyzing the one or more selected portions of mental state data to generate mental state information wherein a result from the analyzing is used to render an output on mental states.

Some embodiments include another client machine . The client machine includes one or more processors coupled to memory to store instructions and a display . The client machine can receive the analysis of the mental state data from the analysis server and can render an output to the display . The system can enable a computer implemented method for mental state analysis that includes receiving an analysis based on both mental state data and additional data tagged to the mental state data and rendering an output based on the analysis. In at least one embodiment the mental state data collection machine the analysis server and or the client machine functions are accomplished by one computer.

Thus the system can enable a method including obtaining mental state data which is collected on an individual from multiple sources determining a portion of the mental state data that is to be sent to a web service determining additional data about the mental state data tagging the additional data to the portion that is to be sent to the web service analyzing the mental state data from multiple sources using the additional data that was tagged and rendering an output about mental states based on the mental state data on the individual from multiple sources along with the additional data that was tagged.

Each of the above methods may be executed on one or more processors on one or more computer systems. Embodiments may include various forms of distributed computing client server computing and cloud based computing. Further it will be understood that the depicted steps or boxes contained in this disclosure s flow charts are solely illustrative and explanatory. The steps may be modified omitted repeated or re ordered without departing from the scope of this disclosure. Further each step may contain one or more sub steps. While the foregoing drawings and description set forth functional aspects of the disclosed systems no particular implementation or arrangement of software and or hardware should be inferred from these descriptions unless explicitly stated or otherwise clear from the context. All such arrangements of software and or hardware are intended to fall within the scope of this disclosure.

The block diagrams and flowchart illustrations depict methods apparatus systems and computer program products. The elements and combinations of elements in the block diagrams and flow diagrams show functions steps or groups of steps of the methods apparatus systems computer program products and or computer implemented methods. Any and all such functions generally referred to herein as a circuit module or system may be implemented by computer program instructions by special purpose hardware based computer systems by combinations of special purpose hardware and computer instructions by combinations of general purpose hardware and computer instructions and so on.

A programmable apparatus which executes any of the above mentioned computer program products or computer implemented methods may include one or more microprocessors microcontrollers embedded microcontrollers programmable digital signal processors programmable devices programmable gate arrays programmable array logic memory devices application specific integrated circuits or the like. Each may be suitably employed or configured to process computer program instructions execute computer logic store computer data and so on.

It will be understood that a computer may include a computer program product from a computer readable storage medium and that this medium may be internal or external removable and replaceable or fixed. In addition a computer may include a Basic Input Output System BIOS firmware an operating system a database or the like that may include interface with or support the software and hardware described herein.

Embodiments of the present invention are neither limited to conventional computer applications nor the programmable apparatus that run them. To illustrate the embodiments of the presently claimed invention could include an optical computer quantum computer analog computer or the like. A computer program may be loaded onto a computer to produce a particular machine that may perform any and all of the depicted functions. This particular machine provides a means for carrying out any and all of the depicted functions.

Any combination of one or more computer readable media may be utilized including but not limited to a non transitory computer readable medium for storage an electronic magnetic optical electromagnetic infrared or semiconductor computer readable storage medium or any suitable combination of the foregoing a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM Flash MRAM FeRAM or phase change memory an optical fiber a portable compact disc an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

It will be appreciated that computer program instructions may include computer executable code. A variety of languages for expressing computer program instructions may include without limitation C C Java JavaScript ActionScript assembly language Lisp Perl Tcl Python Ruby hardware description languages database programming languages functional programming languages imperative programming languages and so on. In embodiments computer program instructions may be stored compiled or interpreted to run on a computer a programmable data processing apparatus a heterogeneous combination of processors or processor architectures and so on. Without limitation embodiments of the present invention may take the form of web based computer software which includes client server software software as a service peer to peer software or the like.

In embodiments a computer may enable execution of computer program instructions including multiple programs or threads. The multiple programs or threads may be processed approximately simultaneously to enhance utilization of the processor and to facilitate substantially simultaneous functions. By way of implementation any and all methods program codes program instructions and the like described herein may be implemented in one or more threads which may in turn spawn other threads which may themselves have priorities associated with them. In some embodiments a computer may process these threads based on priority or other order.

Unless explicitly stated or otherwise clear from the context the verbs execute and process may be used interchangeably to indicate execute process interpret compile assemble link load or a combination of the foregoing. Therefore embodiments that execute or process computer program instructions computer executable code or the like may act upon the instructions or code in any and all of the ways described. Further the method steps shown are intended to include any suitable method of causing one or more parties or entities to perform the steps. The parties performing a step or portion of a step need not be located within a particular geographic location or country boundary. For instance if an entity located within the United States causes a method step or portion thereof to be performed outside of the United States then the method is considered to be performed in the United States by virtue of the causal entity.

While the invention has been disclosed in connection with preferred embodiments shown and described in detail various modifications and improvements thereon will become apparent to those skilled in the art. Accordingly the forgoing examples should not limit the spirit and scope of the present invention rather it should be understood in the broadest sense allowable by law.

