---

title: Efficient bandwidth estimation
abstract: Techniques for efficient bandwidth estimation are described herein. In some cases, the bandwidth estimation techniques disclosed herein may, for example, calculate bandwidth based on multiple packet groups transmitted at different times. Additionally, in some cases, the bandwidth estimation techniques disclosed herein may, for example, capture cross traffic and its effects on bandwidth. Furthermore, in some cases, the bandwidth estimation techniques disclosed herein may, for example, employ dynamic self-correcting techniques for more reliable estimates.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09608934&OS=09608934&RS=09608934
owner: Amazon Technologies, Inc.
number: 09608934
owner_city: Reno
owner_country: US
publication_date: 20140627
---
This application claims the benefit of U.S. Provisional Application No. 61 902 740 filed Nov. 11 2013 entitled EFFICIENT BANDWIDTH ESTIMATION the entirety of which is incorporated herein by reference.

This application is related to the following applications each of which is hereby incorporated by reference in its entirety U.S. patent application Ser. No. 14 076 718 filed Nov. 11 2013 entitled VIDEO ENCODING BASED ON AREAS OF INTEREST U.S. patent application Ser. No. 14 076 821 filed Nov. 11 2013 entitled ADAPTIVE SCENE COMPLEXITY BASED ON SERVICE QUALITY U.S. patent application Ser. No. 14 077 127 filed Nov. 11 2013 entitled SERVICE FOR GENERATING GRAPHICS OBJECT DATA U.S. patent application Ser. No. 14 077 136 filed Nov. 11 2013 entitled IMAGE COMPOSITION BASED ON REMOTE OBJECT DATA U.S. patent application Ser. No. 14 077 165 filed Nov. 11 2013 entitled MULTIPLE PARALLEL GRAPHICS PROCESSING UNITS U.S. patent application Ser. No. 14 077 084 filed Nov. 11 2013 entitled ADAPTIVE CONTENT TRANSMISSION U.S. patent application Ser. No. 14 077 180 filed Nov. 11 2013 entitled VIEW GENERATION BASED ON SHARED STATE U.S. patent application Ser. No. 14 077 186 filed Nov. 11 2013 entitled MULTIPLE STREAM CONTENT PRESENTATION U.S. patent application Ser. No. 14 077 149 filed Nov. 11 2013 entitled DATA COLLECTION FOR MULTIPLE VIEW GENERATION U.S. patent application Ser. No. 14 077 142 filed Nov. 11 2013 entitled STREAMING GAME SERVER VIDEO RECORDER U.S. patent application Ser. No. 14 076 815 filed Nov. 11 2013 entitled LOCATION OF ACTOR RESOURCES U.S. patent application Ser. No. 14 077 146 filed Nov. 11 2013 entitled SESSION IDLE OPTIMIZATION FOR STREAMING SERVER U.S. patent application Ser. No. 14 077 023 filed Nov. 11 2013 entitled APPLICATION STREAMING SERVICE .

Recent technological advances have improved the ability to transmit and deliver information in a fast and efficient manner. In accordance with such advances it is becoming increasingly popular to acquire and store data at a central provider location and to deliver the data to end users quickly upon request. This model may employ technological concepts such as streaming in which content may be constantly received by and presented to an end user while being delivered by a provider. One rapidly expanding area is the use of streaming technology to deliver content such as video games. When streaming content a provider may access the requested content render the content from scenes into images and then encode and transmit the images to a client over a network such as the Internet.

While streaming and other content delivery technology provides many benefits any model that relies on transmission of data across a network may necessarily be subject to at least some of the drawbacks associated with network communications. Such drawbacks may include for example reductions in network throughput reductions in available network bandwidth increases in a loss rate such as a packet loss rate increases in network latency and others. In particular the term throughput as used herein refers to a proportion of transmitted data that is successfully received. Some techniques have been developed for transmitting data in such a manner as to increase the throughput and or reduce a loss rate of the transmitted data. In particular a technique known as forward error correction may involve coding of transmitted data using an error correcting code to include both source bits and additional redundant bits that may be used for example to detect and correct errors occurring during the transmission process.

In general this disclosure describes techniques for adaptive content transmission. In accordance with the disclosed techniques a content item such as a video game may be transmitted from a content provider to a client device using an electronic network such as the Internet. During the transmission of the content item the content provider may monitor the network connection to the client to collect data corresponding to one or more network conditions associated with the transmission of the content item. Such network conditions may include for example network throughput available network bandwidth a loss rate such as a packet loss rate network latency and others. The content provider may then use the collected data to dynamically adjust a proportion of forward error correction applied in connection with the transmitted content item. The applied proportion of forward error correction may be determined for adjustment at any desired transmission interval. For example in some cases the applied proportion of forward error correction may be determined for adjustment on a frame by frame basis or in intervals of a plurality of frames.

In some cases as an alternative or in addition to network conditions the applied proportion of forward error correction may be adjusted based at least in part on one or more transmission attributes. For example in some cases the applied proportion of forward error correction may be adjusted based on transmission attributes such as an encoding bitrate of the transmitted data a resolution of the transmitted data frame rate of the transmitted data and others. In some cases one or more transmission attributes such as those listed above may also be dynamically adjusted by the content provider. This dynamic adjustment of transmission attributes may result in a balancing process in which a desired amount of forward error correction is raised or lowered based on one or more other dynamically adjusted transmission attributes. For example in some cases when it is determined that the encoding bitrate will be dynamically increased then the proportion of forward error correction may be dynamically decreased in order to make more bits available for application of the higher encoding bitrate.

A number of other example factors may also be considered in association with the dynamic adjustment of the applied proportion of forward error correction. For example in some cases the applied proportion of forward error correction may be adjusted based on one or more transmission protocols employed for transmission of a content item. As another example the applied proportion of forward error correction may be adjusted based on the identity of the transmitted content item itself or the identity and or capabilities of the client to which the content item is being transmitted. As yet another example the applied proportion of forward error correction may be adjusted based on historical transmission information. Such historical transmission information may include for example historical associations between applied proportions of forward error correction encoding bitrates and other transmission attributes and resulting observed throughput loss rates and other network conditions. Such historical transmission information may also include for example historical associations between client satisfaction and applied proportions of forward error correction and other transmission attributes.

In addition to adaptive content transmission some techniques for efficient estimation of bandwidth are also disclosed herein. As set forth above one or more transmission attributes such as an applied proportion of forward error correction and an encoding bitrate may in some cases be determined at least in part based on conditions such as bandwidth. In some cases the bandwidth estimation techniques disclosed herein may for example calculate bandwidth based on multiple packet groups transmitted at different times. Additionally in some cases the bandwidth estimation techniques disclosed herein may for example capture cross traffic and its effects on bandwidth. Furthermore in some cases the bandwidth estimation techniques disclosed herein may for example employ dynamic self correcting techniques for more reliable estimates.

As set forth above in some cases a content provider may render and transmit content to clients over an electronic network such as the Internet. Content may in some cases be provided upon request to clients using for example streaming content delivery techniques. An example computing environment that enables rendering and transmission of content to clients will now be described in detail. In particular illustrates an example computing environment in which the embodiments described herein may be implemented. is a diagram schematically illustrating an example of a data center that can provide computing resources to users and which may be referred herein singularly as user or in the plural as users via user computers and which may be referred herein singularly as computer or in the plural as computers via a communications network . Data center may be configured to provide computing resources for executing applications on a permanent or an as needed basis. The computing resources provided by data center may include various types of resources such as gateway resources load balancing resources routing resources networking resources computing resources volatile and non volatile memory resources content delivery resources data processing resources data storage resources data communication resources and the like. Each type of computing resource may be general purpose or may be available in a number of specific configurations. For example data processing resources may be available as virtual machine instances that may be configured to provide various web services. In addition combinations of resources may be made available via a network and may be configured as one or more web services. The instances may be configured to execute applications including web services such as application services media services database services processing services gateway services storage services routing services security services encryption services load balancing services application services and the like. These services may be configurable with set or custom applications and may be configurable in size execution cost latency type duration accessibility and in any other dimension. These web services may be configured as available infrastructure for one or more clients and can include one or more applications configured as a platform or as software for one or more clients. These web services may be made available via one or more communications protocols. These communications protocols may include for example hypertext transfer protocol HTTP or non HTTP protocols. These communications protocols may also include for example more reliable transport layer protocols such as transmission control protocol TCP and less reliable transport layer protocols such as user datagram protocol UDP . Data storage resources may include file storage devices block storage devices and the like.

Each type or configuration of computing resource may be available in different sizes such as large resources consisting of many processors large amounts of memory and or large storage capacity and small resources consisting of fewer processors smaller amounts of memory and or smaller storage capacity. Customers may choose to allocate a number of small processing resources as web servers and or one large processing resource as a database server for example.

Data center may include servers which may be referred herein singularly as server or in the plural as servers that provide computing resources. Referring to communications network may for example be a publicly accessible network of linked networks and possibly operated by various distinct parties such as the Internet. In other embodiments communications network may be a private network such as a corporate or university network that is wholly or partially inaccessible to non privileged users. In still other embodiments communications network may include one or more private networks with access to and or from the Internet.

Communication network may provide access to computers . User computers may be computers utilized by users or other customers of data center . For instance user computer or may be a server a desktop or laptop personal computer a tablet computer a wireless telephone a personal digital assistant PDA an e book reader a game console a set top box or any other computing device capable of accessing data center . User computer or may connect directly to the Internet e.g. via a cable modem or a Digital Subscriber Line DSL . Although only two user computers and are depicted it should be appreciated that there may be multiple user computers.

User computers may also be utilized to configure aspects of the computing resources provided by data center . In this regard data center might provide a gateway or web interface through which aspects of its operation may be configured through the use of a web browser application program executing on user computer . Alternately a stand alone application program executing on user computer might access an application programming interface API exposed by data center for performing the configuration operations. Other mechanisms for configuring the operation of various web services available at data center might also be utilized.

Servers shown in may be standard servers configured appropriately for providing the computing resources described above and may provide computing resources for executing one or more web services and or applications. In the example data center shown in a router may be utilized to interconnect the servers and . Router may also be connected to gateway which is connected to communications network . Router may be connected to one or more load balancers and alone or in combination may manage communications within networks in data center for example by forwarding packets or other data communications as appropriate based on characteristics of such communications e.g. header information including source and or destination addresses protocol identifiers size processing requirements etc. and or the characteristics of the private network e.g. routes based on network topology etc. . It will be appreciated that for the sake of simplicity various aspects of the computing systems and other devices of this example are illustrated without showing certain conventional details. Additional computing systems and other devices may be interconnected in other embodiments and may be interconnected in different ways.

In the example data center shown in a server manager is also employed to at least in part direct various communications to from and or between servers and . While depicts router positioned between gateway and server manager this is merely an exemplary configuration. In some cases for example server manager may be positioned between gateway and router . Server manager may in some cases examine portions of incoming communications from user computers to determine one or more appropriate servers to receive and or process the incoming communications. Server manager may determine appropriate servers to receive and or process the incoming communications based on factors such as an identity location or other attributes associated with user computers a nature of a task with which the communications are associated a priority of a task with which the communications are associated a duration of a task with which the communications are associated a size and or estimated resource usage of a task with which the communications are associated and many other factors. Server manager may for example collect or otherwise have access to state information and other information associated with various tasks in order to for example assist in managing communications and other operations associated with such tasks.

It should be appreciated that the network topology illustrated in has been greatly simplified and that many more networks and networking devices may be utilized to interconnect the various computing systems disclosed herein. These network topologies and devices should be apparent to those skilled in the art.

It should also be appreciated that data center described in is merely illustrative and that other implementations might be utilized. Additionally it should be appreciated that the functionality disclosed herein might be implemented in software hardware or a combination of software and hardware. Other implementations should be apparent to those skilled in the art. It should also be appreciated that a server gateway or other computing device may comprise any combination of hardware or software that can interact and perform the described types of functionality including without limitation desktop or other computers database servers network storage devices and other network devices PDAs tablets cellphones wireless phones pagers electronic organizers Internet appliances television based systems e.g. using set top boxes and or personal digital video recorders and various other consumer products that include appropriate communication capabilities. In addition the functionality provided by the illustrated modules may in some embodiments be combined in fewer modules or distributed in additional modules. Similarly in some embodiments the functionality of some of the illustrated modules may not be provided and or other additional functionality may be available.

In at least some embodiments a server that implements a portion or all of one or more of the technologies described herein may include a general purpose computer system that includes or is configured to access one or more computer accessible media. depicts a general purpose computer system that includes or is configured to access one or more computer accessible media. In the illustrated embodiment computing device includes one or more processors and or which may be referred herein singularly as a processor or in the plural as the processors coupled to a system memory via an input output I O interface . Computing device further includes a network interface coupled to I O interface .

In various embodiments computing device may be a uniprocessor system including one processor or a multiprocessor system including several processors e.g. two four eight or another suitable number . Processors may be any suitable processors capable of executing instructions. For example in various embodiments processors may be general purpose or embedded processors implementing any of a variety of instruction set architectures ISAs such as the x86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA.

System memory may be configured to store instructions and data accessible by processor s . In various embodiments system memory may be implemented using any suitable memory technology such as static random access memory SRAM synchronous dynamic RAM SDRAM nonvolatile Flash type memory or any other type of memory. In the illustrated embodiment program instructions and data implementing one or more desired functions such as those methods techniques and data described above are shown stored within system memory as code and data .

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripherals in the device including network interface or other peripheral interfaces. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor .

Network interface may be configured to allow data to be exchanged between computing device and other device or devices attached to a network or networks such as other computer systems or devices for example. In various embodiments network interface may support communication via any suitable wired or wireless general data networks such as types of Ethernet networks for example. Additionally network interface may support communication via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs storage area networks or via any other suitable type of network and or protocol.

In some embodiments system memory may be one embodiment of a computer accessible medium configured to store program instructions and data as described above for implementing embodiments of the corresponding methods and apparatus. However in other embodiments program instructions and or data may be received sent or stored upon different types of computer accessible media. Generally speaking a computer accessible medium may include non transitory storage media or memory media such as magnetic or optical media e.g. disk or DVD CD coupled to computing device via I O interface . A non transitory computer accessible storage medium may also include any volatile or non volatile media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM read only memory etc. that may be included in some embodiments of computing device as system memory or another type of memory. Further a computer accessible medium may include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as a network and or a wireless link such as those that may be implemented via network interface . Portions or all of multiple computing devices such as those illustrated in may be used to implement the described functionality in various embodiments for example software components running on a variety of different devices and servers may collaborate to provide the functionality. In some embodiments portions of the described functionality may be implemented using storage devices network devices or special purpose computer systems in addition to or instead of being implemented using general purpose computer systems. The term computing device as used herein refers to at least all these types of devices and is not limited to these types of devices.

A compute node which may be referred to also as a computing node may be implemented on a wide variety of computing environments such as commodity hardware computers virtual machines web services computing clusters and computing appliances. Any of these computing devices or environments may for convenience be described as compute nodes.

A network set up by an entity such as a company or a public sector organization to provide one or more web services such as various types of cloud based computing or storage accessible via the Internet and or other networks to a distributed set of clients may be termed a provider network. Such a provider network may include numerous data centers hosting various resource pools such as collections of physical and or virtualized computer servers storage devices networking equipment and the like needed to implement and distribute the infrastructure and web services offered by the provider network. The resources may in some embodiments be offered to clients in various units related to the web service such as an amount of storage for storage processing capability for processing as instances as sets of related services and the like. A virtual computing instance may for example comprise one or more servers with a specified computational capacity which may be specified by indicating the type and number of CPUs the main memory size and so on and a specified software stack e.g. a particular version of an operating system which may in turn run on top of a hypervisor .

A number of different types of computing devices may be used singly or in combination to implement the resources of the provider network in different embodiments including general purpose or special purpose computer servers storage devices network devices and the like. In some embodiments a client or user may be provided direct access to a resource instance e.g. by giving a user an administrator login and password. In other embodiments the provider network operator may allow clients to specify execution requirements for specified client applications and schedule execution of the applications on behalf of the client on execution platforms such as application server instances Java virtual machines JVMs general purpose or special purpose operating systems platforms that support various interpreted or compiled programming languages such as Ruby Perl Python C C and the like or high performance computing platforms suitable for the applications without for example requiring the client to access an instance or an execution platform directly. A given execution platform may utilize one or more resource instances in some implementations in other implementations multiple execution platforms may be mapped to a single resource instance.

In many environments operators of provider networks that implement different types of virtualized computing storage and or other network accessible functionality may allow customers to reserve or purchase access to resources in various resource acquisition modes. The computing resource provider may provide facilities for customers to select and launch the desired computing resources deploy application components to the computing resources and maintain an application executing in the environment. In addition the computing resource provider may provide further facilities for the customer to quickly and easily scale up or scale down the numbers and types of resources allocated to the application either manually or through automatic scaling as demand for or capacity requirements of the application change. The computing resources provided by the computing resource provider may be made available in discrete units which may be referred to as instances. An instance may represent a physical server hardware platform a virtual machine instance executing on a server or some combination of the two. Various types and configurations of instances may be made available including different sizes of resources executing different operating systems OS and or hypervisors and with various installed software applications runtimes and the like. Instances may further be available in specific availability zones representing a logical region a fault tolerant region a data center or other geographic location of the underlying computing hardware for example. Instances may be copied within an availability zone or across availability zones to improve the redundancy of the instance and instances may be migrated within a particular availability zone or across availability zones. As one example the latency for client communications with a particular server in an availability zone may be less than the latency for client communications with a different server. As such an instance may be migrated from the higher latency server to the lower latency server to improve the overall client experience.

In some embodiments the provider network may be organized into a plurality of geographical regions and each region may include one or more availability zones. An availability zone which may also be referred to as an availability container in turn may comprise one or more distinct locations or data centers configured in such a way that the resources in a given availability zone may be isolated or insulated from failures in other availability zones. That is a failure in one availability zone may not be expected to result in a failure in any other availability zone. Thus the availability profile of a resource instance is intended to be independent of the availability profile of a resource instance in a different availability zone. Clients may be able to protect their applications from failures at a single location by launching multiple application instances in respective availability zones. At the same time in some implementations inexpensive and low latency network connectivity may be provided between resource instances that reside within the same geographical region and network transmissions between resources of the same availability zone may be even faster .

As set forth above a content item may be transmitted for example from a content provider to a client. is a diagram illustrating an example content transmission system in accordance with the present disclosure. As shown in content provider and client communicate via network which may in some cases be an electronic network such as for example the Internet or another type of wide area network WAN or local area network LAN . As set forth above content may be provided to client by employing for example streaming content delivery in which content may be constantly received by and presented by a destination such as client . Content provider may for example provide one or more content providing services for providing content to clients such as client . The content providing services may reside on one or more servers. The content providing services may be scalable to meet the demands of one or more customers and may increase or decrease in capability based on the number and type of incoming client requests. Portions of content providing services may also be migrated to be placed in positions of reduced latency with requesting clients. For example content provider may determine an edge of a system or network associated with content providing services that is physically and or logically closest to client . The content provider may then for example spin up migrate resources or otherwise employ components associated with the determined edge for interacting with the client . Such an edge determination process may in some cases provide an efficient technique for identifying and employing components that are well suited to interact with a particular client and may in some embodiments reduce the latency for communications between a content provider and one or more clients.

As shown in content item such as a video game may be delivered from content provider to client . The term content as used herein refers to any presentable information and the term content item as used herein refers to any collection of any such presentable information. For example content item may include graphics content such as a video game. In some cases content item may include two dimensional content which as used herein refers to content that may be represented in accordance with two dimensional scenes. Also in some cases content item may include three dimensional content which as used herein refers to content that may be represented in accordance with three dimensional scenes. The two dimensional or three dimensional scenes may be considered logical representations in the sense that they may for example not physically occupy the areas that they are intended to logically model or represent. The term scene as used herein refers to a representation that may be used in association with generation of an image. A scene may for example include or otherwise be associated with information or data that describes the scene.

Information from content item may be provided to a rendering component which may use the information to generate resulting two dimensional images for transmission to client . For example information regarding content item scenes associated with content item may be provided to rendering component . Rendering component may for example generate resulting images based on the scene information associated with content item . Rendering component may perform well known operations such as lighting shading clipping transformation scan conversion rasterization texturing and fragment shading. Rendering component may include for example one or more graphics processing units. Essentially the output of rendering component may be a two dimensional image that may be provided to encoding and compression components . An image may include for example information associated with a displayable output such as information associated with various pixel values and or attributes.

Encoding and compression components may encode and compress content images prior to their transmission to client . Encoding and compression components may for example include an encoder a compressor a codec and the like. Encoding and compression components may generally use any appropriate technique to encode and or compress content images for transmission to client .

Encoding and compression components may for example apply a particular encoding bitrate for encoding of images. As will be described in greater detail below in some cases the encoding bitrate applied to transmitted images may be adjusted dynamically based on information from dynamic adjustment component .

Forward error correction component may apply forward error correction techniques to image frames transmitted from content provider to client . As set forth above forward error correction may involve coding of transmitted data using an error correcting code to include both source bits and additional redundant bits that may be used for example to detect and correct errors occurring during the transmission process. Forward error correction may for example include channel coding techniques. Forward error correction may employ codes such as the Reed Solomon codes Raptor codes Golay codes Multidimensional parity codes and Hamming codes. In some cases forward error correction component may apply a particular proportion of forward error correction which may correspond to a ratio of a number of redundant bits in comparison to a number of source bits. Source bits may include for example bits generated by the content item or based on information within the content item . As will be described in greater detail below in some cases the proportion of forward error correction applied to transmitted image frames may be adjusted dynamically based on information from dynamic adjustment component .

After any necessary application of encoding compression and or forward error correction image frames may be transmitted to client by transmission component . In some cases transmission component may include a dedicated respective streaming server associated with client . In some cases such a dedicated respective streaming server may include all or portions of other components such as the encoding and compression components and forward error correction component . The use of a dedicated respective streaming server may be advantageous for example because it may in some cases enable improved ability to adjust various transmission attributes to individual clients based on conditions such as throughput bandwidth a loss rate latency and others with a network connection to each client. It is noted however that the disclosed techniques are not limited to the use of dedicated servers for transmission to each client. It is also noted that a dedicated server is not necessarily required to adjust any or all transmission attributes mentioned in the present disclosure. Any number of servers each for transmission to any number of different clients may be employed in association with the techniques disclosed herein. Additionally the disclosed techniques are not limited to the use of streaming technology and may employ other content delivery methods.

Content may be transmitted from content provider to client using any combination of various different protocols. For example content may be transmitted using either hypertext transfer protocol HTTP or non HTTP protocols. Content may be transmitted using protocols that are considered reliable and protocols that are considered non reliable. In some cases content may be transmitted using different transport layer protocols such as transmission control protocol TCP user datagram protocol UDP and others.

In some cases a particular transfer layer protocol that is generally considered to be more reliable such as TCP protocol may be employed. However the use of a protocol that is considered to be more reliable may in some cases cause data to be transmitted more slowly than when a less reliable protocol is employed. In some cases a particular transfer layer protocol that is generally considered to be less reliable such as UDP protocol may be employed. However the use of a protocol that is considered to be less reliable may in some cases cause more errors and more lost or missing data to occur during data transmission.

Dynamic adjustment component makes various determinations regarding dynamic adjustment of various transmission attributes including for example a proportion of forward error correction applied to the transmitted data an encoding bitrate of the transmitted data a resolution of the transmitted data a frame rate of the transmitted data and various other transmission attributes. As will be described in detail below in order to assist in performing various determinations dynamic adjustment component may for example directly and or indirectly monitor communicate with or otherwise interact with various components and devices such as client network transmission component forward error correction component encoding and compression components rendering component content item and various other components and devices.

As set forth above dynamic adjustment component may for example obtain information corresponding to network conditions associated with a connection from content provider to client . The obtained information may correspond to network conditions such as network throughput available network bandwidth a loss rate such as packet loss rate network latency error rate distortion rate packet jitter and various other conditions. In some cases client may send feedback information to dynamic adjustment component regarding lost packets and the inter arrival rate of packets. Information regarding lost packets may for example include or be used to compute a block error rate. The inter arrival rates of packets sent in a burst from content provider to the client may for example be used to assist in providing an estimate of the available bandwidth. Also in some cases dynamic adjustment component may estimate bandwidth based on the rate at which content provider is able to push data into particular sockets. Any combination of these example techniques or other available techniques may be employed to gather information corresponding to network conditions.

Dynamic adjustment component may also for example obtain information associated with various transmission attributes. For example dynamic adjustment component may obtain information associated with transmission attributes such as a proportion of forward error correction applied to the transmitted data an encoding bitrate of the transmitted data a resolution of the transmitted data a frame rate of the transmitted data an amount or complexity of source data being encoded in one or more frames an amount of change in the contents of source data between frames and others. Dynamic adjustment component may monitor any or all components and or obtain any or all information at any appropriate intervals including for example a frame by frame interval or in intervals of a plurality of frames. As should be appreciated different information may be obtained at different intervals with respect to one another.

In addition to monitoring and obtaining information dynamic adjustment component may also calculate determine and send instructions for dynamically adjusting values of various transmission attributes including for example an applied proportion of forward error correction an encoding bitrate of the transmitted data a resolution of the transmitted data a frame rate of the transmitted data and others. In many cases all or some of the dynamically adjusted transmission attributes may be at least partially dependent upon one another. As set forth above this dynamic adjustment of transmission attributes may result in a balancing process in which for example a desired amount of forward error correction is raised or lowered based on one or more other dynamically adjusted transmission attributes. For example in some cases when it is determined that the encoding bitrate will be dynamically increased then the proportion of forward error correction may be dynamically decreased in order to make more bits available for application of the higher encoding bitrate. By contrast in some cases when it is determined that the encoding bitrate will be dynamically decreased then the proportion of forward error correction may be dynamically increased due to more bits being available for application of forward error correction.

In general dynamically applying a higher proportion of forward error correction may for example cause more redundancy. Thus applying a greater proportion of forward error correction may in some cases allow or result in changes such as reductions in encoding bitrate reductions in resolution and frame rate and others. By contrast dynamically applying a lower proportion of forward error correction may for example cause less redundancy. Thus applying a lower proportion of forward error correction may in some cases allow or result in changes such as increases in encoding bitrate increases in resolution and frame rate and others. While increasing an applied proportion of forward error correction may sometimes result in an increase in throughput and or a reduction in a loss rate the amount of an increase in applied forward error correction may in some cases not necessarily be exactly proportional to a resulting increased level of throughput and or decreased loss rate. For example a fifty percent increase in the applied proportion of forward error correction may in some cases not necessarily result in a fifty percent increase in throughput and or a fifty percent reduction in a loss rate.

Near real time transmission information may include certain portions of information collected by dynamic adjustment component from for example monitoring and communicating with content item components and network client and various other components or entities. Near real time transmission information may also include other information associated with transmission of content. In some cases certain portions of near real time transmission information may be updated on a periodic basis such as frame by frame or another period. However near real time transmission information need not necessarily be limited or restricted to any particular timeframe or period relative to a current time.

In some cases dynamic adjustment component may also collect store maintain and access historical transmission information . Historical transmission information may include for example information regarding how prior settings and adjustments to applied proportions of forward error correction encoding bitrates and other transmission attributes have affected resulting rates of throughput loss rates and other network conditions for prior transmissions of various content items and clients in various regions. Historical transmission information may for example be stored such that it may be aggregated based on various factors such as content items clients timeframes geographic regions and others.

Historical transmission information may also include for example client satisfaction information. Client satisfaction information may include for example information regarding a duration that a client plays a particular content item. For example client satisfaction information may indicate that for one or more prior transmissions of a first content item clients historically tend to play a first content item for a longer duration when the encoding bitrate is higher and the applied proportion of forward error correction is lower. Thus on subsequent transmissions of the first content item dynamic adjustment component may send commands to transmit the first content item using a higher encoding bitrate and a lower applied proportion of forward error correction. By contrast client satisfaction information may also indicate that for one or more prior transmissions of a second content item clients historically tend to play a second content item for a longer duration when the encoding bitrate is lower and the applied proportion of forward error correction is higher. Thus on subsequent transmissions of the second content item dynamic adjustment component may send commands to transmit the second content using a lower encoding bitrate and a higher applied proportion of forward error correction.

In some cases dynamic adjustment component may employ various transmission attribute determination logic for dynamically adjusting various transmission attributes. The transmission attribute determination logic may for example be stored by or otherwise provided to dynamic adjustment component . The transmission attribute determination logic may for example specify various priorities for balancing various transmission attributes. For example in some cases the transmission attribute determination logic may indicate that some transmission attributes may have a higher priority than others. For example the transmission attribute determination logic may indicate that higher proportions of forward error correction are considered to be more important than higher encoding bitrates. By contrast in some cases the transmission attribute determination logic may indicate that higher encoding bitrates are considered to be more important than higher proportions of forward error correction. In some cases various weights may be provided to indicate a relative importance of some transmission attributes in comparison to other transmission attributes.

Also in some cases different specified values ranges of values and maximum and minimum values may be provided for one or more transmission attributes. For example in some cases an acceptable maximum or minimum proportion of forward error correction may be specified. As another example a particular encoding bitrate or an acceptable range of encoding bitrates may be specified. Also in some cases different weights or ratios may be specified for one or more attributes in comparison to one another and to other information associated with the data being transmitted.

In some cases transmission attribute prioritization logic may vary depending upon factors such as for example available bandwidth and latency. For example when available bandwidth is lower higher encoding bitrates may in some cases be considered more important than higher proportions of forward error correction. By contrast in some cases when available bandwidth is higher higher proportions of forward error correction may in some cases be considered more important than higher encoding bitrates. As another example when latency is higher higher encoding bitrates may in some cases be considered more important than higher proportions of forward error correction. By contrast in some cases when latency is lower higher proportions of forward error correction may in some cases be considered more important than higher encoding bitrates.

In some cases transmission attribute prioritization logic may also vary depending on one or more protocols being employed for transmission of the data. For example transmission attribute prioritization logic may specify that when UDP protocol is employed higher proportions of forward error correction may in some cases be preferred in comparison to higher encoding bitrates. As another example when non UDP protocols are employed higher encoding bitrates may in some cases be preferred in comparison to higher proportions of forward error correction.

Transmission attribute prioritization logic employed by dynamic adjustment component may be aggregated at any desired level. For example different transmission attribute prioritization logic may be associated with different clients and or different content items. Different transmission attribute prioritization logic may be applied for example at different times of day or different days of the year. Different transmission attribute prioritization logic may be applied for example based on various capabilities and geographic locations of the client and or of various different components of the content provider that are employed in association with transmission of a particular content item to a particular client. The capabilities of the client may include for example processing capabilities storage capabilities communications capabilities display and presentation capabilities and others.

As also shown in example input includes example network conditions example transmission attributes other example information and example historical transmission attributes . In particular example network conditions include throughput bandwidth a loss rate and latency. The example network conditions may for example be associated with the transmission of one or more prior frames. Example transmission attributes include an encoding bitrate applied to one or more prior frames a resolution applied to one or more current and or prior frames a frame rate an amount of source data in the current frame an amount of change in content of source data from the prior frame and a proportion of forward error correction applied to one or more prior frames. Other example information includes one or more transmission protocols employed to transit the content item an identity of the content item an identity and geographic location and capabilities of the client and time and date. As set forth above the capabilities of the client may include for example processing capabilities storage capabilities communications capabilities display and presentation capabilities and others. Example historical transmission attributes include historical throughput information historical loss rates historical proportions of forward error correction historical encoding bitrates and historical client satisfaction information. It is noted that the contents of example input are merely examples and that any portion of information included in example input is not necessarily required by dynamic information component . Any combination of additional or alternative input information may also be employed in accordance with the disclosed techniques.

As shown in dynamic adjustment component may use example input in combination with transmission attribute prioritization logic to determine example output which in the example of includes a proportion of forward error correction and an encoding bitrate to apply to a current frame of the transmitted data. Thus in the example of dynamic adjustment component may employ some level of balancing between the applied proportion of forward error correction and the encoding bitrate. Some example techniques for balancing these and other transmission attributes are described in detail above. Transmission attribute prioritization logic may include any of the example transmission attribute prioritization logic described above or any other additional or alternative logic. As set forth above transmission attribute prioritization logic may be for example stored in dynamic adjustment component or otherwise accessible to or provided to dynamic adjustment component . As also set forth above dynamic adjustment component determinations such as depicted in may be made at any desired transmission interval. For example in some cases the applied proportion of forward error correction may be determined for adjustment on a frame by frame basis or in intervals of a plurality of frames. It is noted that example output of is merely an example and is non limiting. In some cases the proportion of forward error correction and or the encoding bitrate may remain constant and may not be adjusted by dynamic adjustment component . Also in some cases any combination of additional or alternative transmission attributes and other items may be adjusted by dynamic adjustment component in accordance with the disclosed techniques.

Diagrams of some example forward error correction adjustments are illustrated in . In particular provides an example in which adjustment is performed based on four example input conditions which are identified in as throughput loss rate latency and bandwidth. As shown in a content item generates a prior frame and a subsequent frame . Prior frame is transmitted from the content provider to the client prior to subsequent frame . In some cases subsequent frame may be the next frame transmitted immediately following prior frame . However subsequent frame is not required to immediately follow prior frame .

As described in detail above the content provider may monitor the client to which a content item is transmitted and or the network connection to the client in order to identify information associated with network conditions such as throughput loss rate latency and bandwidth. For example before during and after the transmission of prior frame the content provider may obtain information associated with throughput loss rate latency and bandwidth corresponding to the transmission of prior frame . As shown in example input includes information associated with throughput loss rate latency and bandwidth corresponding to the transmission of prior frame as indicated by the words prior frame in parentheses in box . Additionally as shown in the box corresponding to prior frame a lower proportion of forward error correction was applied to transmit prior frame to the client.

As illustrated in the information included in example input box is used to determine an adjusted proportion of forward error correction to apply to subsequent frame . Based on the factors indicated in example input it is determined in the example of that the applied proportion of forward error correction should be adjusted to a higher level for subsequent frame . In particular example input indicates that a lower throughput and a higher loss rate were observed in association with the transmission of prior frame . Thus a higher level of forward error correction may be employed in order to assist in improving the level of throughput and or reducing the loss rate. Additionally it is observed that latency is lower and bandwidth is higher. The lower latency and higher bandwidth both suggest a higher likelihood that the proportion of forward error correction may be increased without for example significant negative impact to other transmission attributes such as encoding bitrate.

It is noted that the determination to increase the applied proportion of forward error correction illustrated in subsequent frame of is merely an example and that such a determination is not necessarily required based on example input in accordance with the disclosed techniques. For example the particular transmission attribute logic employed by any given system as described above may in some cases result in a different determination to not adjust or to differently adjust the applied proportion of forward error correction. Similarly the other determinations illustrated in subsequent frames and of respectively are examples and are not necessarily required based on the example inputs and shown in respectively.

Referring now to another example forward error correction adjustment is shown. In particular illustrates a scenario in which a higher proportion of forward error correction was applied to prior frame . Additionally in different network conditions are observed in comparison to those shown in . Specifically indicates that a higher throughput and a lower loss rate were observed in association with the transmission of prior frame . Thus because the observed throughput was higher and the observed loss rate was lower it may be possible to reduce the applied proportion of forward error correction without significant negative impact to throughput and or loss rate. Additionally it is observed that latency is higher and bandwidth is lower. The higher latency and lower bandwidth both suggest a higher likelihood that redundant forward error correction bits from prior frame could be used more efficiently by for example increasing the encoding bitrate to provide a better image quality. Accordingly based on the factors indicated in example input it is determined in the example of that the applied proportion of forward error correction should be adjusted to a lower level for subsequent frame .

Referring now to another example forward error correction adjustment is shown. In particular illustrates a scenario in which a lower proportion of forward error correction and a higher encoding bitrate were applied to prior frame . Additionally in different network conditions are observed in comparison to those shown in . Specifically example input box of indicates that a lower throughput was observed in combination with a higher loss rate higher latency and a lower bandwidth in association with the transmission of prior frame . Thus because observed throughput for prior frame is lower and the observed loss rate is higher it may be desirable to apply more forward error correction for subsequent frame . However because observed latency is higher and the bandwidth is lower the amount of bits available for additional forward error correction may be limited. Thus it may be desirable to balance forward error correction against other transmission attributes such as the encoding bitrate. In particular example input also indicates that for subsequent image the encoding bitrate is determined to be less important than forward error correction. This determination may be made for example based on transmission attribute prioritization logic that is stored by or otherwise made available to dynamic adjustment component .

Thus in the example of because the encoding bitrate is less important than forward error correction it may be determined that additional bits may be allocated to forward error correction as opposed to the encoding bitrate. Accordingly in the example of it is determined that the applied proportion of forward error correction should be adjusted to a higher level for subsequent frame . Additionally because the encoding bitrate of the subsequent frame is less important than forward error correction also indicates that the encoding bitrate of subsequent frame is determined to be lower. It is once again noted that the examples of merely illustrate some possible example manners in which some dynamic determinations may be made and that the determinations included in are not necessarily required based on the example input and logic associated with .

In some other example cases dynamic determinations may be made based on additional network conditions such as error rate distortion rate and packet jitter. In some cases increases in rates or occurrences of these additional network conditions may not be desirable and may be limited using techniques such as forward error correction. Accordingly increases in these additional network conditions may in some cases cause higher proportions of forward error correction to be applied to subsequent frames while decreases in these additional network conditions may in some cases cause lower proportions of forward error correction to be applied to subsequent frames.

At operation a frame count is iterated such that a current frame is set to be a next frame. For example upon a first performance of operation a first transmitted frame of the content item may become the current frame. As another example upon a second performance of operation a second transmitted frame of the content item may become the current frame. It is noted that operation is included for purposes of simplicity to clarify to the reader that operations in the process of may be repeated for one or more transmitted frames. Operation need not necessarily require any processing or computation by the content provider.

At operation network condition information is received by for example dynamic adjustment component of . As set forth above the received network condition information may be associated with a connection from the content provider to the client. The received information may correspond to network conditions such as network throughput a loss rate such as a packet loss rate available network bandwidth network latency error rate distortion rate packet jitter and various other conditions. It is noted that the received network condition information may in some cases be associated with the transmission of one or more frames transmitted prior to the current frame. Thus in some cases network condition information may not be available or may be minimal upon the first performance of operation . However an increased amount of network condition information may become available upon subsequent performances of operation . Various techniques for obtaining network condition information are set forth in detail above and are not repeated here.

At operation transmission attribute information is received by for example dynamic adjustment component of . As set forth above the received transmission attribute information may be associated with transmission attributes such as a proportion of forward error correction applied to current and or prior frames an encoding bitrate of current and or prior frames a resolution of current and or prior frames a frame rate information associated with an amount or complexity of source data being encoded in current and or prior frames an amount of change in the content of source data between one or more frames and other associated information.

At operation other information is received including for example information identifying the client information identifying one or more capabilities of the client information identifying the content item information identifying a geographic location of the client a current or near current time and date information identifying one or more transmission protocols employed for transmission of the content item and others.

At operation historical transmission information is received by for example dynamic adjustment component of . As set forth above the received historical transmission information may include for example historical associations between applied proportions of forward error correction encoding bitrates and other transmission attributes and resulting observed throughput loss rates and other network conditions. The received historical transmission information may also include for example historical associations between client satisfaction and applied proportions of forward error correction encoding bitrates and other transmission attributes.

It is once again noted that all or any portion of the information associated with operations and may be received at any appropriate intervals including for example a frame by frame interval or in intervals of a plurality of frames. As should be appreciated different information may be obtained at different intervals with respect to one another. Thus even one or more transmission attributes are adjusted for each transmitted frame it is not necessarily required that all or any portion of operations and be repeated for each transmitted frame.

At operation transmission attribute determination logic is identified by for example dynamic adjustment component of . As set forth above transmission attribute determination logic may for example describe priorities for determination of various transmission attributes with respect to the information received at operations and . Such priorities may include for example instructions for balancing various transmission attributes with respect to one another. A number of examples of transmission attribute determination logic are described in detail above and are not repeated here. It is further noted that operation need not necessarily be repeated for each frame being transmitted and in some cases may only be performed once.

At operation values of one or more transmission attributes are determined for the current frame. For example at operation the values of one or more transmission attributes may be dynamically adjusted such that their value changes for the current frame relative to their values for one or more prior frames. Operation may also include for example a determination to leave the values of one or more transmission attributes unchanged for the current frame relative to their values for one or more prior frames. The one or more determined transmission attribute values may include for example an applied proportion of forward error correction for the current frame an encoding bitrate for the current frame a resolution for the current frame a frame rate and others. As set forth above the transmission attribute values may for example be determined based at least in part on the attribute determination logic identified at operation in combination with any or all of the information received at operations and and possibly additional or alternative information. For example at operation the values of one or more transmission attributes for the current frame may be determined and or adjusted based on network conditions transmission attributes and information associated with the transmission of one or more current and or prior frames. Operation may include for example a balancing of one or more transmission attributes relative to one another. For example in some cases increasing an applied proportion of forward error correction may result in decreasing of an encoding bitrate a resolution and or a frame rate. As another example in some cases decreasing an applied proportion of forward error correction may result in increasing of an encoding bitrate a resolution and or a frame rate. A number of other examples of techniques for determining the applied proportion of forward error correction and other transmission attribute values are described in detail above and are not repeated here.

It is once again noted that transmission attribute values may be determined at any appropriate interval including for example a frame by frame interval or in intervals of a plurality of frames. Thus it is not necessarily required operation be repeated for each transmitted frame. It is also noted that in some cases one or more transmission attributes may not be dynamically adjusted and may not be part of the determination performed at operation . For example in some cases the encoding bitrate may remain constant and therefore its value need not be determined at operation . As another example in some cases the applied proportion of forward error correction may remain constant and therefore its value need not be determined at operation .

Operation may include determining one or more transmission attributes associated with transmission of video data and or audio data. In particular forward error correction and various other transmission attributes may be applied to and dynamically adjusted for video data and or audio data using any or all of the techniques disclosed herein. The transmission attributes may be adjusted for video data and or audio data on a frame by frame basis or at any other desired interval or rate. The terms content and content item as used herein may include both video data and or audio data.

At operation operations are performed in accordance with the transmission attributes values determined at operation . For example at operation the current frame may be encoded using a determined encoding bitrate and a determined proportion of forward error correction may be applied to the current frame. At operation the current frame is transmitted to the client which may display the transmitted frame.

At operation it is determined whether there are any more frames remaining for transmission in association with the content item. If so then the process returns to operation . If not then the content item transmission is terminated at operation .

It is noted that while some examples of the disclosed techniques described above may refer to streaming of content the disclosed techniques are not limited to use with streaming technology. For example the disclosed techniques may also be employed for downloading of files or other information over a network. Additionally any of the disclosed techniques for adaptive content transmission may be employed in combination with such a download procedure. For example forward error correction for a file download may be adjusted dynamically based upon any combination of network conditions transmission attributes historical information transmission attribute prioritization logic and other information as set forth above. In some cases file downloads may be performed using transmission protocols that may be considered less reliable such as UDP protocol. As set forth above the use of a less reliable protocol may be desirable in some cases because it may for example reduce latency reduce costs and or increase bandwidth efficiency in comparison to more reliable protocols. However file downloads may also be employed using more reliable protocols. Additionally it is once again noted that the disclosed techniques are not limited to use with any particular communication protocols and may be employed with respect to both more reliable and less reliable protocols.

In some cases one or more additional packet streams may be used for transmission of data in combination with various forward error correction techniques in order to for example assist in reduction of latency. To illustrate this concept a first example will now be described in which ten packets may be transmitted over a network using ten streams with no forward error correction employed in association with the transmission. By contrast in a second example a twenty percent proportion of forward error correction may be applied to the ten packets to result in ten source packets and two redundant packets. The ten source packets and two redundant packets result in twelve total packets which in the second example may be transmitted using twelve streams. In the second example the receiving device may use only the first ten of the twelve packets to be received. The final two packets to be received may be discarded since they may not be required to satisfactorily replicate the transmitted data at the receiving device. Thus by using additional streams the second example may in some cases allow forward error correction to be applied with no or minimal additional latency experienced by the receiving device. These additional packet stream techniques may in some cases be particularly advantageous when used with more reliable protocols such as TCP. However these additional packet stream techniques are not limited to use with any particular communication protocols and may be employed with respect to both more reliable and less reliable protocols.

In some cases certain additional techniques may be applied to assist in reliable transmissions within a particular timeframe and or sequence. In particular certain transmitted data may sometimes be considered unnecessary or unimportant if not received within a particular timeframe and or sequence relative to its transmission. For example client input data such as state data transmitted from a client to a content provider may sometimes have minimal value if it is not received shortly after its transmission. In some cases the client input data may be associated with a generation of one or more subsequent content item frames. In such cases if the subsequent content item frames are generated and transmitted before the client input data is successfully received by the content provider then the client input data may have little or no value to the content provider.

To assist in reliable transmission of data such as client input data the transmitted data may in some cases include or otherwise be associated with an identifier such as a timestamp a sequence identifier and the like. Such an identifier may indicate a fixed or relative time and or sequence associated with the transmission of the data. If the data is not received within a certain time or position in a sequence then the transmitted data may be ignored. Additionally in some cases certain portions of the transmitted data may be successfully received while other portions of the transmitted data may not be successfully received due to for example packet losses or other conditions. In such cases if the successfully received portions of the data are received within a certain time or position in a sequence then the receiving entity may send a request for the transmitting entity to re transmit the data. By contrast if the successfully received portions of the data are not received within a certain time or position in a sequence then the receiving entity may simply ignore the received data and or not send a re transmission request.

As set forth above one or more transmission attributes such as an applied proportion of forward error correction and an encoding bitrate may in some cases be determined at least in part based on conditions such as bandwidth. Some example techniques for estimating of bandwidth will now be described in detail.

In some cases at each video frame interval the server may send a group of packets which are referred to herein as packet groups. In some cases each packet group may include video and FEC repair packets. illustrates an example diagram of multiple packet groups. Packet group includes packets . Packet group includes packets . Packet group includes packets . Within each packet group the packets may for example be sent back to back. On the client side by observing how and what packets in a packet group arrive the network conditions such as available bandwidth and if network congestion has occurred may be derived. Adaptive streaming decisions may then be made.

When packets from a packet group travel through a network such as the Internet they may get slowed down by a bottleneck link or by other packets from cross traffic. illustrates an example of a bottleneck link. As shown in packet group includes packets . Packets are transmitted from server to client via network . Packets are depicted in as being wider after being received by client than they were prior to transmission by server . The widened depiction of packets after being received by client is intended to represent that packets have been slowed down by a bottleneck link.

In some cases irrespective of the cause of slow down or speed up which may happen for example when the cross traffic goes away the end to end available bandwidth between the server and the client can be measured by computing the rate that packets arrive on the client. The available bandwidth may be computed as shown in where BW is bandwidth PG is a first packet group PG is a second packet group Dis the total number of bits sent in the first packet group excluding the first transmitted packet in the first packet group Dis the total number of bits sent in the second packet group excluding the first transmitted packet in the second packet group Tis the server side timestamp difference between the first and second packet group Tand Tare the received timestamp of the first and the last packet in the first packet group and Tand Tare the received timestamp of the first and the last packet in the second packet group.

In some cases when packets travel through a network such as the Internet they may encounter network congestion. Network congestion may result in a burst or a large number of packet losses within a packet group. illustrates an example of network congestion. As shown in packets are transmitted from server to client via network . However packets are lost during the transmission process and are not received by client . Network congestion can be detected by looking at the loss stats. In some cases three thresholds may be defined for overall loss ratio consecutive loss count and minimum loss count. If for example all three thresholds are met for a packet group then in some cases it may be determined that network congestion has occurred.

In some cases for each packet group received the client may compute the available bandwidth. Also in some cases the available bandwidth for each packet group may be provided to a component that determines EWMA Exponentially Weighted Moving Average . Also in some cases for each packet group received network congestion may be detected based on loss stats. In some cases if network congestion has occurred then the available bandwidth may be promptly reported as the current average bandwidth 1 the overall packet loss ratio . By contrast if no network congestion has occurred then the current average bandwidth may be reported at an appropriate report time.

In some cases a bandwidth estimation algorithm may be a part of an adaptation algorithm and may be employed for example to calculate available bandwidth for a streaming service.

A bandwidth estimation algorithm may for example be a dynamic self correcting algorithm such that as new information is received the algorithm may for example correct its estimate of the bandwidth and other estimates. In practice observations may come with a lot of noise. A bandwidth estimation algorithm may in some cases implement noise filtering in most of its steps. Some example criteria for noise filtering are regularity of the estimate as defined below consistency of the estimate in its forecast time skew between server side and client side timestamps and how credible a line of estimates has been.

Multiple estimates may be extracted from a single packet group. For example in a packet group of n packets n 1 estimates may be extracted. This may allow more estimates to be read out of data and also allow a fair comparison to be made between estimates. The set of multiple estimates may then be combined to form a single estimate. Noise filtering and the dynamic self correction algorithm may occur in the process of merging estimates.

Some heuristics associated with the dynamic self correction algorithm may include assigning a larger weight to an estimate with more credibility and discounting an estimate that is far from a current view.

The dynamic self correction algorithm may in some cases be memory less the state may evolve over time with no memory of its state in the past.

Cross traffic may be estimated using an example general bandwidth estimation formula as defined below.

In some cases single packet group information may indicate a maximum available bandwidth and multiple packet group information may indicate an effective cross traffic which may for example assist in determining a level at which a service will stream in order to share network resources in a fair and friendly manner.

An example bandwidth estimation algorithm will now be described in detail. The example bandwidth estimation algorithm may for example estimate available bandwidth at any given time during a session based on the inter arrival times of packets.

1 It is assumed that a received timestamp is provided with each packet. An absolute value of the timestamp need not be accurate but the relative differences between timestamps are accurate.

2 It is assumed that a packet group consists of video and repair packets. The total number of packets in a packet group is known denoted by n . The size of each packet may vary but the algorithm may work better when sizes are about the same. It is assumed that among n packets m packets are received.

3 A cut off timestamp representing when enough packets in a given packet group may be received in order for successful decoding is denoted by T. Any packet delivered after Tis ignored and considered to be a lost packet.

4 The minimum number of packets needed for decoding is denoted as m where the subscript r represents the word required .

5 The set of received packets is denoted by P P . . . P indexed in the order they re received. Let tbe the timestamp of Pwhere j 1 . . . m. Hence we have t . . . t.

4 Bandwidth relative delivery time and regularity index can be grouped into vector notation . . . 1.2 . . . 1.3 0 . . . 1.4 

5 Given two pairs of bandwidth relative delivery time and regularity index b e r and b e r we will combine them using combine factor such that 1 by 1.5 1.6 

The discussion above is based on the assumption that packets are sent back to back by the server. In the general case the following setup may be employed 

2 Denote by Dthe total number of bits sent in the packet group Gfor k 1 . . . n excluding the first transmitted packet in each packet group. Thus the bits included in the first transmitted packet within each packet group are not included in the value of D.

3 Denote by Tand Tthe received timestamp of the first and the last packet in the packet group G respectively. Also denote by Tthe server side timestamp difference between packet group Gand Gfor k 1 . . . n 1.

Under this setting the available bandwidth estimate of the combined packet groups G . . . Gis given by the following formula 

Some aspects of the above formula will now be described. In the simplest case where n 2 the above formula reduces to 

The above formulas 1.8 and 1.9 may capture any cross traffic and its effect on our available bandwidth as it will affect the effective time span contribution in the denominator. The effect may be more dominant in between packet groups. Even within a single packet group cross traffic packets can be inter leaved with our packets in the group and it may be reflected as longer time span of the group. The same idea applies to a single packet group case if packets in the packet group are sent with some time delay in between. The correction term may apply to any sequence of packets with arbitrary time

In some cases a dynamic state evolution algorithm may be employed. One example scenario in which a dynamic state evolution algorithm may be employed is in the middle of a streaming session with known current indicator states such as bandwidth estimates regularity indices and expected relative delivery times. A dynamic state evolution algorithm may for example be employed using the following example procedures. In particular when a new packet group is received its own indicators may be calculated as described above. These calculations may then be combined with the current state if the new estimates are in reasonable distance from the current state. Otherwise the calculations may be rejected. If too many rejections are encountered in a short period of time then this may be a strong signal that new estimates are the new reality. Therefore after a certain threshold the example algorithm may start to accept outliers. This process may be performed per each line of estimates i.e. for each k th packets in the packet group . The state of the algorithm may keep track of how many updates each line of estimates has gone through in a recent time period. This information may be used when calculating the overall bandwidth estimates at any given time.

Some example bandwidth estimation techniques will now be described in detail with respect to . In particular is a flowchart depicting an example bandwidth estimation procedure for multiple packet groups in accordance with the present disclosure. As set forth above a server may transmit multiple packet groups to a client. corresponds to an example in which two packet groups are used to calculate an estimated bandwidth. Specifically the two packet groups include a first packet group and a second packet group. Both the first packet group and the second packet group include multiple packets. They need not necessarily include the same amount of packets. The first transmitted packet in the first packet group is referred to herein as a first start packet. The last transmitted packet in the first packet group is referred to herein as a first end packet. As should be appreciated depending upon the number of packets in the first packet group any number of packets may be transmitted between the first start packet and the first end packet. The first transmitted packet in the second packet group is referred to herein as a second start packet. The last transmitted packet in the second packet group is referred to herein as a second end packet. As should be appreciated depending upon the number of packets in the second packet group any number of packets may be transmitted between the second start packet and the second end packet.

Referring now to at operation the server determines a first transmit time indicator that indicates a time associated with transmission of the first packet group. In some cases the first transmit time indicator may be a timestamp value that is added to the first packet group and transmitted to the client along with the first packet group. In some cases there may be some delay between the determination of the first transmit time indicator and the actual transmission of the first packet group.

At operation the server transmits the first packet group to the client. At operation the client receives the first packet group from the server. As set forth above the server may transmit packets back to back within a packet group. Thus packets within a packet group may be transmitted very closely in time with respect to one another. However various network conditions such as a bottleneck link cross traffic and others may cause there to be measurable time gaps between the times that each packet within a packet group is received by the client.

At operation the client determines a first start packet receive time indicator that indicates a time associated with receiving of the first start packet by the client. As set forth above the first start packet is the first packet transmitted in the first packet group. At operation the client determines a first end packet receive time indicator that indicates a time associated with receiving of the first end packet by the client. As set forth above the first end packet is the last packet transmitted in the first packet group. As should be appreciated any number of other receive time indicators associated with receiving of any number of other packets in the first packet group may also be determined by the client.

At operation the server determines a second transmit time indicator that indicates a time associated with transmission of the second packet group. In some cases the second transmit time indicator may be a timestamp value that is added to the second packet group and transmitted to the client along with the second packet group. In some cases there may be some delay between the determination of the second transmit time indicator and the actual transmission of the second packet group.

At operation the server transmits the second packet group to the client. At operation the client receives the second packet group from the server. At operation the client determines a second end packet receive time indicator that indicates a time associated with receiving of the second end packet by the client. As set forth above the second end packet is the last packet transmitted in the second packet group. As should be appreciated any number of other receive time indicators that indicate times associated with receiving of any number of other packets in the second packet group may also be determined by the client.

At operation the bandwidth between the server and the client is estimated. The bandwidth may be estimated by for example one or more processing components that may execute at the client at the server compute nodes and or on other devices. Any information necessary for bandwidth estimation may be communicated between the client server and or other nodes or devices as appropriate. A formula for an example bandwidth estimation based on two packet groups is set forth in equation 1.9 and above. Specifically the bandwidth may be estimated for example by determining a ratio between a first value and a second value. In the example of the first value may represent the numerator of equation 1.9 while the second value may represent the denominator of equation 1.9. The first value may be determined based at least in part on a number of bits included in the first packet group excluding the first start packet and a number of bits in the second packet group excluding the second start packet. This value may for example be determined by the server and or by the clients based on amount of data transmitted and or received. Any combination of well known techniques for determining an amount of received and or transmitted data may be employed in order to determine the number of bits for the first value. The second value may be determined based at least in part on the first and the second transmit time indicators the first start packet receive time indicator and the first and the second end packet receive time indicators.

In greater detail the second value may be calculated based on a difference between a first group term and a second group term. The first group term may be calculated based on a difference between the second end packet receive time indicator and the first start packet receive time indicator. The second group term may be calculated based on a difference between a first amount and a second amount. The first amount may be calculated based on a difference between the second transmit time indicator and the first transmit time indicator. The second amount may be calculated based on a difference between the first end packet receive time indicator and the first start packet receive time indicator.

As set forth above estimating the bandwidth using multiple packet groups may in some cases capture effects of cross traffic on the estimated bandwidth. Accordingly estimating the bandwidth in this manner may in some cases be more accurate than an estimation based on samples obtained from only a single packet group.

At operation additional data is transmitted from the server to the client in accordance with one or more transmission attributes that are determined based at least in part on the bandwidth estimated at . The transmission attributes that are determined based at least in part on the estimated bandwidth may include for example an applied proportion of forward error correction and an encoding bitrate and any of the other transmission attributes mentioned above or other transmission attributes. A number of example techniques for determining transmission attributes based at least in part on bandwidth are described in detail above such as with reference to and are not repeated here. It is noted that if the estimation of the bandwidth i.e. operation is performed at the server then the server may have the bandwidth estimation information locally available for use in determining transmission attributes. By contrast if the estimation of the bandwidth is performed at the client or another node or device other than the server then an indication of the bandwidth estimation may for example be transmitted from the client or other node or device back to the server for use by the server at operation .

As an example in some cases a packet receive time indicator may be determined for each received packet in a packet group. Also in some cases the packet receive time indicators may be used to determine a time delay between packet receive times for each pair of subsequently and previously received packets in the packet group e.g. delay between packet 1 and packet 2 delay between packet 2 and packet 3 etc. . Thus in some cases for a packet group with n packets n 1 time delays between packet receive time pairs may be calculated. In some cases a regularity of estimates for an individual packet group may be based on a deviation between calculated time delays between packet receive time pairs for the group. For example a packet group for which the receive time pairs for all packets are approximately equally spaced apart may in some cases be determined to be highly regular. By contrast a packet group with greater deviations between receive time pairs may in some cases be determined to be more irregular. In some cases packet groups with higher regularity may be considered to have more credible data and may be given a higher weight when merged with data from other packet groups for bandwidth estimation purposes see operation below . By contrast in some cases packet groups with lower regularity may be considered to have less credible data and may be given a lower weight when merged with data from other packet groups for bandwidth estimation purposes see operation below .

Also a bandwidth for an individual packet group may be estimated. In some cases the bandwidth for the individual packet group may be estimated by dividing an amount of bits in the packet group by a difference between the end packet receive time indicator i.e. the time indicator for the last transmitted packet and the start packet receive time indicator i.e. the time indicator for the first transmitted packet for the packet group.

It is noted here that for a first packet group received as part of the process of i.e. for the first iteration of operations and the following operation may be skipped since there will not be any other prior received packet groups with which to combine the data from the first received packet group.

For packet groups subsequent to the first received packet group at operation a combined total bandwidth estimate for multiple packet groups is calculated or re calculated using data from the current individual packet group. Some example techniques for calculating a combined total bandwidth estimate for multiple packet groups are described in detail above with respect to equation 1.8 and are not repeated here. Additionally for the particular case in which the bandwidth is estimated based on two packet groups some more simplified example bandwidth estimation techniques are described in detail above with respect to equation 1.9 and and are not repeated here.

In some cases the combined total bandwidth estimate may be calculated or recalculated using a selected number of most recently received packet groups. For example in some cases the combined total bandwidth estimate may be calculated using the two most recently received packet groups. For example a client may receive a first and a second packet group from the server. A combined total bandwidth estimate may then be calculated based on the first and the second packet groups. Subsequently the client may receive a third packet group from the server. The combined total bandwidth estimate may then be recalculated based on the second and the third packet groups. Subsequently the client may receive a fourth packet group from the server. The combined total bandwidth estimate may then be recalculated based on the third and the fourth packet groups.

As another example in some cases the combined total bandwidth estimate may be calculated or recalculated using all received packet groups. For example a client may receive a first and a second packet group from the server. A combined total bandwidth estimate may then be calculated based on the first and the second packet groups. Subsequently the client may receive a third packet group from the server. The combined total bandwidth estimate may then be recalculated based on the first second and third packet groups. Subsequently the client may receive a fourth packet group from the server. The combined total bandwidth estimate may then be recalculated based on the first second third and fourth packet groups.

In some cases as part of the combined total bandwidth estimate for multiple packet groups performed at operation data for one or more of the multiple packet groups may be weighted differently than data for one or more other of the multiple packet groups. This different packet group weighting may be applied for example when data for different packet groups have different determined levels of credibility with respect to one another. As set forth above in some cases a level of credibility for data associated with a packet group may be based on factors such as regularity of receive times for packets within the group and other factors. Thus in some cases data for packet groups with higher credibility and or regularity may be given a higher relative weight while data for packet groups with lower credibility and or regularity may be given a lower relative weight. For example consider a scenario in which a particular packet group is determined to have a relatively high bandwidth. In cases where the particular packet group is assigned a higher relative weight the particular packet group s higher individual bandwidth may have a greater effect on the combined total bandwidth than in cases where the packet group is assigned a lower relative weight. Thus the combined total bandwidth estimate may be higher in cases when the particular packet group is assigned a higher relative weight while the combined total bandwidth estimate may be less high in cases when the particular packet group is assigned a lower relative weight. Any appropriate techniques for assigning higher or lower weights to one or more packet groups as part of the bandwidth estimation process may be employed.

Additionally in some cases some combined bandwidth estimates may also be assigned different weights with respect to one another. In some cases the different weights may be based on a similarity of a combined bandwidth estimate with respect to previously calculated combined bandwidth estimates. Estimates with lower weights may sometimes be given less importance when being used to determine transmission attributes such as encoding bitrate and proportion of forward error correction. By contrast estimates with higher weights may sometimes be given more importance when being used to determine transmission attributes. For example consider the scenario in which a bandwidth estimate based on second and third packet groups is considerably higher than a prior bandwidth estimate based on first and second packet groups. In some cases this may indicate that the bandwidth estimate based on the second and third estimate may be unreliable due to its considerable variation from the prior estimate. In some cases the bandwidth estimate based on the second and third packet groups may at least temporarily be assigned a lower weight in comparison to the prior estimate. Now suppose that a fourth packet group is received and a new bandwidth estimation is calculated based on the third and the fourth packet groups. If the new bandwidth calculation for the third and fourth packet groups results in a higher bandwidth consistent with the calculation for the second and third packet groups than this may be a signal that the higher bandwidth condition has become the new reality. Thus the new bandwidth estimate may in some cases be assigned a higher weight based on an assumption that the higher bandwidth estimates represent the new reality.

At operation it is determined whether there are any remaining packet groups transmitted by the server. If so then the process returns back to operation at which a next packet group is received by the client and the process is repeated. If there are no remaining packet groups then the process is completed at operation .

Some example performance results will now be described. The results shown are for streaming a looped segment of an example content item over a router that simulates packets loss delays and bandwidth limitations. The results shown are for a session that encounters no cross traffic. At the outset bandwidth is not constrained and is in excess of 50 Mbps. One way delay is set to 30 ms. At around 40 seconds the bandwidth is set to 3.2 Mbps. After around 15 seconds later the bandwidth is set to 2 Mbps. After around another 15 seconds later then bandwidth is again set to 1 Mbps. The bandwidth is subsequently set to 5 Mbps and the independent loss rate is set to 5 then 10 . The results are taken from the real time metrics available at an example server. illustrates example bandwidth estimation results using the bandwidth estimation algorithm shown in equation 1.8 above. The example bandwidth estimation results match very closely with the bandwidth limitations applied via the router. The bandwidth estimates shown are using median noise filtering as opposed to dynamic state evolution.

The video throughput measured at a client and fed back to the server as a metric is shown in . The measured throughput of the video compared to FEC and audio is shown in . The video target bitrate as plotted in yielded encoded Y PSNRs as shown in . The server side estimate of the percent of frames distorted due to packet loss is shown in . The metric shows bumps in the incidence of distorted frames coinciding with abrupt reductions in available bandwidth. The distortion rates at the end may be an error in the server side estimation. In the period starting around 115 seconds the bandwidth was 5 Mbps and the loss rate 5 . There were actually very noticeable distorted frames in this period. shows packet loss rates that were taken from RTCP receiver reports fed back to the server.

Each of the processes methods and algorithms described in the preceding sections may be embodied in and fully or partially automated by code modules executed by one or more computers or computer processors. The code modules may be stored on any type of non transitory computer readable medium or computer storage device such as hard drives solid state memory optical disc and or the like. The processes and algorithms may be implemented partially or wholly in application specific circuitry. The results of the disclosed processes and process steps may be stored persistently or otherwise in any type of non transitory computer storage such as e.g. volatile or non volatile storage.

The various features and processes described above may be used independently of one another or may be combined in various ways. All possible combinations and subcombinations are intended to fall within the scope of this disclosure. In addition certain methods or process blocks may be omitted in some implementations. The methods and processes described herein are also not limited to any particular sequence and the blocks or states relating thereto can be performed in other sequences that are appropriate. For example described blocks or states may be performed in an order other than that specifically disclosed or multiple blocks or states may be combined in a single block or state. The example blocks or states may be performed in serial in parallel or in some other manner. Blocks or states may be added to or removed from the disclosed example embodiments. The example systems and components described herein may be configured differently than described. For example elements may be added to removed from or rearranged compared to the disclosed example embodiments.

It will also be appreciated that various items are illustrated as being stored in memory or on storage while being used and that these items or portions thereof may be transferred between memory and other storage devices for purposes of memory management and data integrity. Alternatively in other embodiments some or all of the software modules and or systems may execute in memory on another device and communicate with the illustrated computing systems via inter computer communication. Furthermore in some embodiments some or all of the systems and or modules may be implemented or provided in other ways such as at least partially in firmware and or hardware including but not limited to one or more application specific integrated circuits ASICs standard integrated circuits controllers e.g. by executing appropriate instructions and including microcontrollers and or embedded controllers field programmable gate arrays FPGAs complex programmable logic devices CPLDs etc. Some or all of the modules systems and data structures may also be stored e.g. as software instructions or structured data on a computer readable medium such as a hard disk a memory a network or a portable media article to be read by an appropriate drive or via an appropriate connection. The systems modules and data structures may also be transmitted as generated data signals e.g. as part of a carrier wave or other analog or digital propagated signal on a variety of computer readable transmission media including wireless based and wired cable based media and may take a variety of forms e.g. as part of a single or multiplexed analog signal or as multiple discrete digital packets or frames . Such computer program products may also take other forms in other embodiments. Accordingly the present invention may be practiced with other computer system configurations.

Conditional language used herein such as among others can could might may e.g. and the like unless specifically stated otherwise or otherwise understood within the context as used is generally intended to convey that certain embodiments include while other embodiments do not include certain features elements and or steps. Thus such conditional language is not generally intended to imply that features elements and or steps are in any way required for one or more embodiments or that one or more embodiments necessarily include logic for deciding with or without author input or prompting whether these features elements and or steps are included or are to be performed in any particular embodiment. The terms comprising including having and the like are synonymous and are used inclusively in an open ended fashion and do not exclude additional elements features acts operations and so forth. Also the term or is used in its inclusive sense and not in its exclusive sense so that when used for example to connect a list of elements the term or means one some or all of the elements in the list.

While certain example embodiments have been described these embodiments have been presented by way of example only and are not intended to limit the scope of the inventions disclosed herein. Thus nothing in the foregoing description is intended to imply that any particular feature characteristic step module or block is necessary or indispensable. Indeed the novel methods and systems described herein may be embodied in a variety of other forms furthermore various omissions substitutions and changes in the form of the methods and systems described herein may be made without departing from the spirit of the inventions disclosed herein. The accompanying claims and their equivalents are intended to cover such forms or modifications as would fall within the scope and spirit of certain of the inventions disclosed herein.

