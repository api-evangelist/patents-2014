---

title: Data center analytics and dashboard
abstract: A method and system to evaluate data efficacy across an enterprise is disclosed. The method includes the step of indexing a set of data sources that include at least one of structured and unstructured data artifacts. The method further includes accessing the indexing on the one or more data sources with a computer. The method further includes the step of generating a plurality of analytics about the data sources based on the indexing, wherein the analytics include a plurality of: a document originality analytic, a corpus storage volume analytic, a data source ingest analytic, a document type analytic, and an analysis analytic. The method further includes displaying, on a display device, an interactive visualization of results based on the analytics, wherein the visualization comprises at least one of: a histogram, a graph, a timeline, a panel, a list, a chart, a popup, and a table.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09613322&OS=09613322&RS=09613322
owner: Orbis Technologies, Inc.
number: 09613322
owner_city: Annapolis
owner_country: US
publication_date: 20140402
---
The present application claims priority benefit under 35 U.S.C. 119 e of U.S. Provisional Patent Application No. 61 807 534 entitled Data Center Analytics and Dashboard filed Apr. 2 2013 the contents of which are incorporated herein by reference in their entirety.

The present invention relates to systems and methods to generate and display analytics for enterprise data spread across one or more data sources.

Organizations often have multiple systems that store and process the same or similar data. However this is expensive for organizations in terms of maintaining the disparate systems and there may be data synchronization issues such as using an outdated customer address in one system even though the current address is persisted in a different system. Additionally an organization may be forced to spend money on hardware that is not required due to the proliferation of duplicate data.

In most organizations users desktop and mobile computing environments often contain multiple files containing the same or similar data with different names. Having this data duplication is sometimes intentional to preserve data lineage such as in compliance situations but is also accidental in some cases. Using resources to store unneeded data often results in incurring costs to replace or augment a user s computing environment before the serviceable life of the computing environment is met.

Many organizations provide enterprise storage systems for their users to manage documents that have enterprise value. Some examples of these enterprise systems include shared file systems document management systems content management systems mobile drop box access and others. Multiple users often contribute the same or similar documents to be persisted on their behalf in these enterprise systems. This results in increased storage requirements for storing the same or similar data.

Also large organizations often lack the ability to discover collaborative opportunities that exist outside defined processes.

To overcome the problems described above a data center analytics and dashboard is disclosed that significantly increases the ease and efficiency of making business decisions based on semantic analysis of the enterprise content spread across one or more data sources. Such an approach provides a view of several high level key indicators and summary analytics associated with the data storage originality source key relationships date and time of origin etc. . The analytics are presented in an immediately intuitive and visual way on a dashboard. The dashboard user interface UI enables rapid high level assessment of quality and quantity analytics of unstructured semi structured and structured data sources. The approach provides the user with the ability to discover more detailed analysis of specific performance parameters.

In one embodiment a graphical representation of the relative value of data in an enterprise storage solution is provided. Such a representation may enable an enterprise to determine in which systems to prioritize maintenance resources. The relative value can be determined through a variety of analytics designed to explicitly illustrate artifact or document originality derivation of content correlations across data sources use of data sources the impact of text analytics and semantic markup on enterprise storage and processing and similar analytics. Such a solution can provide a quick and easy way to assess the value of the data and subsequently the most efficient and cost effective enterprise data storage solution.

In another embodiment a graphical representation of the relative value of files within a user s computing environment can enable the user of a computing environment and the group responsible for managing the computing environment to more efficiently store the needed data without using resources for extraneous data.

In yet another embodiment a graphical representation of the relative value of documents within an enterprise storage system can enable the managers of the system to more efficiently manage storage requirements and alert users of similar content.

In one embodiment a graphical representation of the relative value of data across an enterprise which includes the use of data by multiple users across different defined processes in an organization can be used to enable an organization to discover opportunities for collaboration to possibly innovate an organization s products or services or to become more operationally efficient in providing the products or services. For example if multiple users are maintaining the same information about manufacturing data possibly one from a regulatory affairs perspective and another from quality assurance perspective a graphical user interface depicting the relative value of this data as determined by a set of analytics can provide the organization s management needed data to establish a collaborative process between these two groups of users. The discovered collaboration opportunity could lead to decreased costs as well as discovering ways to innovate manufacturing or delivery of the product.

In exemplary embodiments a data quality analytics DQA system according to the present invention provides a dashboard and analytics system to evaluate data efficacy across disparate data sources using multiple analytics including but not limited to document originality corpus storage volume data source ingest timeline document type and analysis.

In some embodiments a DQA system according to the present invention enables more efficient storage management requirements and alerts user of similar content. For example if multiple users are maintaining the same information about a particular target a graphical user interface depicting the relative value of this data as determined by a set of analytics would provide the organization s management needed data to establish a collaborative process between these two groups of users which could lead to decreased costs as well as discovered ways to innovate manufacturing or delivery of the product.

In some embodiments a DQA system according to the present invention leverages semantic text analytics incorporating Natural Language Processing NLP algorithms machine learning and evidential reasoning for example in a Hadoop cloud processing environment. For example the analytics component may analyze the content of the data source to determine the level of similarity between one set of data and data.

Analytics are used in a DQA system according to the present invention to evaluate the efficacy of data across an enterprise and is based on common data governance ideals such as data lineage pedigree and provenance.

In some embodiments a document originality analytic evaluates the originality of data within a corpus of documents. The analysis is based on two concepts exact text match wherein the same or similar text is used and similar facts wherein different text describes the same facts. Original data may be considered as higher value as this analytic may represent uniqueness of data across the enterprise. This analytic also captures document originality by document type using document metadata originality by document age using metadata depicting the date a document was created and originality by document size which evaluates the number of sentences as compared to the number of original sentences.

In other embodiments the data source ingest timeline analytic identifies the volatility of data. High volatility data such as stock price data holds little value over time but is of high value at the current time. Volatile data may also hold high value for trend analysis. The data source ingest timeline analytic may identify growth in ingest and or update rates that may identify a systemic problem such as quality decrease in initial document versions or an infrastructure concern such as change in storage system utilization estimates.

In some embodiments the document type analytic uses document metadata to analyze the types of documents in a corpus and provide metrics depicting the number of documents of each type in the corpus. This can be used to identify the value of data based on the type of document as some document types may be of higher value to users than other types of documents.

In other embodiments the corpus storage volume analytic provides metrics on the relative value of data based on facts extracted from documents versus facts inferred from documents using models logic or rules. This analytic captures the value of data that is inferred from cross document correlation based on models and logic. This analytic also computes the total disk storage required for facts extracted from the document as well as inferred using models logic or rules. The analytic also computes the number of sentences in each document. This enables the capability to view the amount of storage required by document size i.e. number of sentences which is useful in determining storage requirements by document size.

In some embodiments the analysis analytic identifies the top entity to entity relationships across a set of data sources. This may be useful in determining the value of data that is extracted from a corpus of documents or inferred from across enterprise data sources using models logic and rules. The analysis analytic also may identify the top entities and top sentences across unstructured text sources as well as the top documents based on derived content analysis. In this analysis each document may be compared for similarity and derived content is determined by comparing document create and or modified dates. Content is considered derived when a document age is newer than an older document with similar content.

A client may interact with the DQA system using client components including analytics widgets and dashboard . On the backend the DQA system may consist of one or more servers computers and network devices to operate the DQA indexing and analytics component the DQA API and the DQA Dashboard . Examples of such servers and or computers configured to implement DQA are depicted in described below.

At the data source level the DQA indexes perform the analysis to generate analytics on data source components which may include unstructured text data sources structured data sources and other data sources such as for example Hadoop cloud based data sources. There may be additional analytics derived from data sources using analytics that already exist in an enterprise such as predictive analytics text analytics and others. Such analytics such as predictive analytics and text analytics may be used in conjunction with the analytics generated through the DQA indexes The DQA Indexes do not have to be installed on the same server as the data sources but must have accessibility to the data such as via a communications network through a network interface.

The DQA API allows the DQA dashboard to access the results or analytics from the DQA indexes and other analytics over the data sources . The dashboard is configurable to access existing analytics clients within an enterprise e.g. predictive text etc. to supplement the analytics from the DQA indexes and optionally provide drill down details. The drill down within the dashboard can also access the data directly from the data source components . To support this direct access the dashboard must have access to existing analytics clients existing analytics APIs and Datasource APIs e.g. JDBC for an RDBMS a document repository API such as WebDAV etc. .

In one embodiment a DQA system according to the present invention may be used to for cloud analytics. In such embodiments the application layer with dashboard and analytics widgets may use Ozone Widget Framework OWF based UIs. The interface layer with analytics API datasource API and DQA API may use the Unstructured Information Management Architecture UIMA framework and the APIs required for the metadata generated from the cloud analytics and data services. Additionally the data sources may include Amazon Web Services Army cloud Red Disk infrastructure and enterprise cloud infrastructure deployed in an Amazon Web Services environment.

In some embodiments the dashboard may be configurable by a user based on the analytics deployed and user preference. For example if a data originality analytic was deemed as most important to a user the dashboard could be configured such that the pie chart or other visualization depicting a data originality analytic in data originality panel as depicted in could be placed at the top of the dashboard to represent its importance.

The dashboard also may display hover text in the GUI to provide additional information about each analytic result as well as drill down capabilities. The Tools button in the upper right of the main dashboard window gives the user the capability to using an input device display all hover text for each panel and take a snapshot of all analytics results with or without the hover text. The Panel Expansion button allows the user to see details of the results of each analytic supporting the visualization in that panel . Visualizations for most analytics can be configured by the user. For example for data age analytics results the user could choose a timeline to see the amount of data that existed at a certain time or a histogram to show the average amount of data for some time group such as a 3 month span or a pie chart to show the percentage of data age for a collection of data such as a corpus of documents or a bar to show the percentage of a specific group of data with the same age range in context to all data s age ranges. Panels may be displayed for any number of analytics including one or more of a document originality analytic panel a document age analytic panel a corpus storage volume analytic panel an analysis analytic panel and a document type analytic panel

In some embodiments one or more data or document originality analytics may be derived from multiple algorithms running in for example MapReduce to calculate the originality of the data artifacts or documents within the data source corpus. The data originality calculation may be based on two algorithms 1 an exact match of the text wherein the same or similar text is used and 2 the identification of similar facts wherein different text describes the same facts entities and relations . In the calculation of originality original data may be considered as higher value as this content represents uniqueness of this data across the enterprise. The data originality analytic also may take into account document originality by document type using document metadata. For example document originality can take into account the document age using metadata representing the date a document was created. Additional metadata can further be generated showing the document size and the number duplicate sentence as compared to the number of original sentences.

In some embodiments the analysis dashboard element depicted in may be generated from a DQA system running multiple NLP algorithms that extract entities relationships and other text metadata to assist in the computations to determine similarity. Such semantic text analytics may support corpus analysis. For example the DQA system and specifically the indexes may leverage semantic text analytics to identify top entity to entity relationships across a corpus. This may be useful in determining the value of data that is extracted from a corpus or inferred from cross document correlation using models logic and rules that may be stored in DQA indexes . Semantic text analytics may also be leveraged to identify top entities and top sentences across all documents in a corpus as well as the top documents based on derived content analysis. In this analysis each document may be compared for similarity and derived content is determined by comparing document create and or modified dates. Content is considered derived when a document age is newer than an older document with similar content.

Duplication of data across data sources may result in computationally intensive algorithms running unnecessary computations across the duplicate data. Inefficient data management results in higher sustainment costs. For example unneeded analytics processing for duplicate data in a cloud data source may result in a higher replacement rate of hard drives due to excessive disk writes. As a result one calculation of a data source storage analytic may be the computation of the total disk storage required for facts extracted from the data source as well as inferred using models logic or rules. In some embodiments where the data sources are cloud data sources the corpus storage volume analytic may be critical where the cloud data sources contain artifacts that are both structured and unstructured. Typical intelligence data types signals data imagery etc. may contain files that are significantly larger than average documents. For example in a multi INT environment it is possible for less than 5 of the data to consume a majority of storage space.

In some embodiments the document type analytic may establish the value of a data source that is being migrated to a cloud environment. The document type panel and popup may be viewed and used by program managers to assess the value of the contribution of a data source that is contributed by an organization to a cloud. Having multiple metrics by data source and by data type may create a more informed decision making process on the migration of legacy databases to a cloud storage infrastructure.

Computer also includes network interface for receiving messages e.g. messages transmitted from a client and transmitting messages over network and a data storage system which may include one or more computer readable media . Computer readable media may include any number of persistent storage devices e.g. magnetic disk drives solid state storage etc. and or transient memory devices e.g. Random Access Memory .

Computer also includes a display device . The display device may be for example a monitor touch screen LCD screen or any physical or virtual interface to display content. In some embodiments the DQA dashboard may be displayed on display device where the invention is implemented on computer . The data processing system of computer may be connected to the display device such as for example through a wireless or physical connection and be configured to display the DQA dashboard and the illustrative workspace windows described above. In some embodiments display device is coupled to an input device such as where computer is connected to an LCD screen display device configured to receive input from a user.

The data processing system of computer may also be connected to an input device which may be for example a keyboard touchscreen mouse or voice capture device for voice recognition. In some embodiments input device may be connected to computer via a network and a network interface and in other embodiments the input device may be directly connected to the processing system of computer such as via a wire cable or wireless connection.

In embodiments where data processing system includes a microprocessor a DQA computer program product may be provided. Such a computer program product may include computer readable program code which implements a computer program stored on a computer readable medium . Computer readable medium may include magnetic media e.g. a hard disk optical media e.g. a DVD memory devices e.g. random access memory etc. In some embodiments computer readable program code is configured such that when executed by data processing system code causes the processing system to perform steps described above.

In other embodiments computer may be configured to perform the functions described above without the need for code . For example data processing system may consist merely of specialized hardware such as one or more application specific integrated circuits ASICs . Hence the features of the present invention described above may be implemented in hardware and or software. For example in some embodiments the functional tiers described above may be implemented by data processing system executing computer instructions by data processing system operating independent of any computer instructions or by any suitable combination of hardware and or software.

DQA systems and methods according to the present invention may be implemented in various platforms. The following examples of DQA implementation are for example only and are not intended to further limit the invention. A person of skill in the art can appreciate that the invention may be implemented in a variety of platforms.

For example in a preferred embodiment a DQA system may be implemented as computer readable program code on a computer readable medium across one or more computers . The DQA system running on one or more computers may access one or more data sources located for example locally in the one or more computers data storage systems or externally through network . One motivation to run the data center analytics and dashboard system locally on a computer may be to achieve lower latency and a faster run time.

In other embodiments the DQA system may be run on the Internet accessed by a computer via a connection such as buses and cables to network . One motivation for an Internet embodiment may be to allow data center analytics and dashboard system to access various Internet based data sources such as cloud based data sources.

While various embodiments and implementations of the present invention have been described above and claimed it should be understood that they have been presented by way of example only and not limitation. For example the DQA may generate and or display one or some or all of the analytics described herein. Thus the breadth and scope of the present invention should not be limited by any of the above described exemplary embodiments.

