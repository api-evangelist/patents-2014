---

title: Static routes for logical routers
abstract: Some embodiments provide a method for a network controller. The method receives configuration data, for a logical router managed by the network controller, that specifies at least one logical port for the logical router. The method automatically generates connected routes for the logical router based on network address ranges specified for the logical ports of the logical router. The method receives a manually input static route for the logical router. The method generates data tuples, for distribution to several managed network elements, based on the connected and static routes for the logical router in order for the several managed network elements to implement the logical router.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09419855&OS=09419855&RS=09419855
owner: NICIRA, INC.
number: 09419855
owner_city: Palo Alto
owner_country: US
publication_date: 20140314
---
In traditional physical networking routes come in three types connected static and dynamic. Connected routes are those determined automatically based on local interface information. When an interface has an address configured in a subnet then the router has a directly connected route to that subnet. Static routes are those manually configured at the router and dynamic routes are learned from other routers via routing protocols e.g. BGP OSPF IGP etc. . As this may result in a router being presented with multiple routes for the same IP address routers perform various processing techniques in order to choose between these routes.

Virtual networks may also have routers referred to as logical routers. Previous implementations of logical routers have only used connected routes however generated based on the IP prefix configured on the port of the logical router. Adding different types of routes to logical routers would pose the problem of requiring additional processing techniques for the logical routers which may not be easily performed by the software forwarding elements often used to implement such logical routers.

Some embodiments provide a network control system that enables static route support for logical routers. In some embodiments the logical router is managed by a network controller which receives the input for a static route e.g. through an API and incorporates the static route into its stored state for the logical router. In order for the logical router to be implemented in a physical network managed by the network controller of some embodiments the controller generates a routing table for the logical router and distributes the routing table to various elements in the network that implement the logical router. In some embodiments the network controller distributes this routing table including the static route information as i flow entries distributed to managed forwarding elements and ii data tuples defining a routing table for a virtualized container e.g. a namespace that operates as a L gateway for communicating with external networks.

In some embodiments the network controller that manages the logical router receives a definition of a static route through its API e.g. as input by an administrator through a cloud management application . In addition the controller generates routes for the logical router based on the configuration also received through the API of a logical network of which the logical router is a part. The logical network of some embodiments may contain logical switches that attach to the logical router and subnets are defined for these logical switches and thus for the logical ports of the logical router to which the logical switches attach . Based on the subnets defined for these logical ports the network controller of some embodiments generates routes that send network addresses in the subnets to the respective interfaces. When static routes are received the controller automatically calculates an input routing table and from this generates an output routing table. The routes in the output routing table are then distributed to the managed forwarding elements and L gateways in order to implement the logical router.

The network controller of some embodiments uses a table mapping engine to perform most of its state calculations e.g. generating flow entries to implement logical networks generating data tuples for logical services and routing tables for L gateways etc. . However in some embodiments in order to convert an input set of routes into an output set of routes the table mapping engine uses a separate route processing engine. Whereas the table mapping engine of some embodiments is implemented in a first programming language useful for performing join operations between sets of tables e.g. datalog nLog etc. the route processing engine of some embodiments is implemented in a second programming language useful for performing recursive processes and error checking e.g. C C etc. .

This route processing engine of some embodiments receives a set of routes from the table mapping engine e.g. routes automatically generated by the table mapping engine based on the subnets to which the logical ports of the logical router connect static routes input through the network controller API and performs a recursive traversal process on the routes in order to identify a final logical destination for each network address range routed by the logical router. When multiple input routes provide contradictory information for a particular network address or range of addresses the route processing engine of some embodiments determines which route has a higher priority. Some input routes may provide a next hop address rather than output port for a route. In these cases the route processing engine recursively traverses the set of input routes until reaching a route specifying either a destination output port or a drop packet action. The route processing engine returns the set of output routes with final actions e.g. drop packet send to particular output port specified for each route.

Upon receiving the output set of routes from the route processing engine the table mapping engine of some embodiments generates the information to distribute to the network elements e.g. managed forwarding elements managed gateways in order for the network elements to implement the logical router. These may include flow entries sent to the managed forwarding elements specifying e.g. to forward packets with certain network addresses to certain logical ports as well as routing table information for the gateways e.g. data tuples defining a routing table for an IP stack operating in a namespace . In addition to flow entries that implement the logical routing table specifying to forward packets to a particular logical port the table mapping engine of some embodiments also generates flow entries that map the logical port to physical interfaces so that packets can be sent across the physical managed network between managed forwarding elements.

The preceding Summary is intended to serve as a brief introduction to some embodiments of the invention. It is not meant to be an introduction or overview of all inventive subject matter disclosed in this document. The Detailed Description that follows and the Drawings that are referred to in the Detailed Description will further describe the embodiments described in the Summary as well as other embodiments. Accordingly to understand all the embodiments described by this document a full review of the Summary Detailed Description and the Drawings is needed. Moreover the claimed subject matters are not to be limited by the illustrative details in the Summary Detailed Description and the Drawing but rather are to be defined by the appended claims because the claimed subject matters can be embodied in other specific forms without departing from the spirit of the subject matters.

In the following detailed description of the invention numerous details examples and embodiments of the invention are set forth and described. However it will be clear and apparent to one skilled in the art that the invention is not limited to the embodiments set forth and that the invention may be practiced without some of the specific details and examples discussed.

Some embodiments provide a network control system that enables static route support for logical routers. In some embodiments the logical router is managed by a network controller which receives the input for a static route e.g. through an API and incorporates the static route into its stored state for the logical router. In order for the logical router to be implemented in a physical network managed by the network controller of some embodiments the controller generates a routing table for the logical router and distributes the routing table to various elements in the network that implement the logical router. In some embodiments the network controller distributes this routing table including the static route information as i flow entries distributed to managed forwarding elements and ii data tuples defining a routing table for a virtualized container e.g. a namespace that operates as a L gateway for communicating with external networks.

The network controller of some embodiments uses a table mapping engine to perform most of its state calculations e.g. generating flow entries to implement logical networks generating data tuples for logical services and routing tables for L gateways etc. . However in some embodiments in order to generate the routing table for distribution based on a set of input routes the table mapping engine uses a separate route processing engine. Whereas the table mapping engine of some embodiments is implemented in a first programming language useful for performing join operations between sets of tables e.g. datalog nLog etc. the route processing engine of some embodiments is implemented in a second programming language useful for performing recursive processes and error checking e.g. C C etc. .

In some embodiments the network controller is one of several controllers that manages numerous managed forwarding elements that implement multiple logical networks across numerous host machines. For example a logical network might include several logical switches that attach to a logical router with numerous virtual machines VMs attached to the logical switches. The VMs reside on numerous host machines possibly alongside VMs of other logical networks. A managed forwarding element MFE operates on each host machine e.g. as a software forwarding element residing in the virtualization software of the host machine in order to process packets sent to and received from the VMs on that host machine. In some embodiments the MFE on a particular host machine stores information in order to implement the logical forwarding elements for the various different logical networks that have VMs residing on the host machine.

The network controller may manage a particular one or several of these logical networks and therefore stores information in the state storage about the logical forwarding elements. In some embodiments the network controller receives configuration information defining the logical network that it manages and computes additional information for distribution to the MFEs in order to implement the logical network. The state storage stores both configuration state and computed state information for all of the logical forwarding elements of the logical networks managed by the controller . In addition in some embodiments other controllers share configuration state information with the network controller for other logical networks that are not managed by the controller . However in some such embodiments the controllers do not share computed state information and each controller only computes state for the logical networks that it manages.

The input interface is an application programming interface API in some embodiments through which the network controller receives configuration information. The configuration information may be input by an administrator logging into the network controller directly or through a management application that translates administrator entered information into API commands to send to the controller. In addition the network controller may receive as configuration information a definition of a static route through the input interface . Upon receiving this information the input interface stores the configuration data into the state storage . In some embodiments each logical forwarding element e.g. the logical router is stored as an object and the routes are stored as objects which are owned by the logical router object. To define a configured route in the state storage some embodiments store the type of route e.g. connected static the network address or range of addresses governed by the route a destination e.g. a next hop address a logical port a drop action for packets having a network address in the range governed by the route and a priority for the route.

The table mapping engine performs state calculations for logical networks managed by the controller in some embodiments. These state calculations may include generating flow entries to implement the logical networks generating data tuples for logical services and routing tables for L gateways etc. In some embodiments the table mapping engine is implemented in a table mapping language that performs join operations between sets of tables such as nLog or datalog. When the table mapping engine of some embodiments receives a set of routes for a logical router that includes one or more static routes i.e. that includes routes other than those defined automatically based on the logical ports of the logical router the table mapping engine utilizes the route processing engine to translate the input set of routes into an output set of routes.

The route processing engine of some embodiments receives a set of routes from the table mapping engine e.g. routes automatically generated by the table mapping engine or network controller API based on the subnets to which the logical ports of the logical router connect static routes input through the network controller API and performs a recursive traversal process on the routes in order to identify a final logical destination for each network address range routed by the logical router. When multiple input routes provide contradictory information for a particular network address or range of addresses the route processing engine of some embodiments determines which route has a higher priority. Some input routes may provide a next hop address rather than output port for a route. In these cases the route processing engine recursively traverses the set of input routes until reaching a route specifying either a destination output port or a drop packet action. The route processing engine returns the set of output routes with final actions e.g. drop packet send to particular output port specified for each route. In some embodiments the route processing engine is implemented in a language different from the table mapping engine i.e. not a table mapping language . Specifically some embodiments implement the route processing engine in a language that is optimal for error checking and recursive traversal processes e.g. C C etc. .

Upon receiving the output set of routes from the route processing engine the table mapping engine of some embodiments generates the information to distribute to the network elements e.g. managed forwarding elements and managed gateways residing on the host machines in order for the network elements to implement the logical router. This data may include flow entries sent to the managed forwarding elements specifying e.g. to forward packets with certain network addresses to certain logical ports as well as routing table information for the gateways e.g. data tuples defining a routing table for an IP stack operating in a namespace . In addition to flow entries that implement the logical routing table specifying to forward packets to a particular logical port the table mapping engine of some embodiments also generates flow entries that map the logical port to physical interfaces so that packets can be sent across the physical managed network between managed forwarding elements.

The controller distributes the data for the logical router and other data for e.g. other logical forwarding elements such as the logical switches of the logical network generated by the table mapping engine to the host machines via the state distribution interface . In some embodiments the controller distributes the data through a hierarchy of other network controllers. For instance in some embodiments each logical network or each logical forwarding element is managed by a particular controller which may also manage other logical networks and each host machine is managed by a particular controller which may also manage other host machines . The controller computes the state e.g. flow entries for logical networks that it manages and distributes this data to the various controllers that manage the host machines implementing those logical networks. In other embodiments the state distribution interface interfaces directly with the host machines to distribute the data.

An example operation of the network controller will now be described. In some embodiments a user inputs a configuration for a logical network which may include several logical switches connected to a logical router. Each logical switch connects to a logical port of the logical router and each logical port is assigned a subnet i.e. a range of network addresses . In addition the user inputs at least one static route. The network controller receives the configuration data including the configuration of the static route through the input interface .

Based on the received configuration data the input interface stores configuration state in the state storage . With respect to the logical router the input interface stores 1 a connected route for each logical port for routing packets with network addresses in the range specified for the logical port to that logical port and 2 static routes as defined by the configuration data. In some embodiments the input interface also automatically defines a low priority default route for handling packets sent to network addresses for which routes are not otherwise defined e.g. to a logical gateway port . In other embodiments such a default route is only defined if input by a user.

Upon detecting the change in the configuration state stored in the state storage the table mapping engine begins generating new data tuples for distribution to the host machines in order to implement the logical network. However because static routes are defined the table mapping engine offloads the route traversal to the route processing engine . Specifically the table mapping engine sends to the route processing engine an input set of routes i.e. those defined by the configuration state 

The route processing engine generates an output set of routes from the received set of input routes. Specifically the route processing engine identifies routes that are not in use e.g. lower priority routes that are superseded by higher priority routes for the same set of network addresses and recursively traverses the set of routes to identify a final action for each set of network addresses e.g. a drop packet action a final output port to which to send packets . The route processing engine returns the final route information to the table mapping engine .

The table mapping engine uses the final route information to generate flow entries and or data tuples defining the implementation of the logical router for the host machines . The table mapping engine provides these generated data tuples to the state distribution interface for distribution to the host machines e.g. directly to the host machines through a hierarchical network control system etc. .

The above description introduces the network controller of some embodiments for managing logical routers with static routing. Several more detailed embodiments are described below. First Section I introduces the implementation and configuration of logical networks via a network control system of some embodiments. Section II then describes the configuration of static routes for a logical router and Section III describes the operation of the route processing engine in a controller according to some embodiments. Finally Section IV describes an electronic system with which some embodiments of the invention are implemented.

In some embodiments the network controllers e.g. the controller described above by reference to are part of a network control system used to manage numerous logical networks implemented in a physical managed network e.g. a private datacenter such as an enterprise site a public datacenter etc. . In such a managed network different tenants configure different logical networks which the network control system implements in a virtualized fashion over the same physical network while maintaining isolation between the logical networks.

In some embodiments the logical network is an abstract conception of a network generated by an administrator and the logical network is implemented in a virtualized distributed manner in a managed physical infrastructure e.g. in a multi tenant datacenter . That is the virtual machines that connect to the logical switches may reside on various different host machines within the infrastructure and physical managed forwarding elements e.g. software virtual switches operating on these host machines implement some or all of the logical forwarding elements logical switches logical routers etc. .

A logical router as in this example connects a set of logical switches to which virtual machines logically attach. Each logical switch or each logical port of the logical router to which a logical switch attaches represents a particular set of IP addresses i.e. a subnet and is implemented in the managed network across a set of managed forwarding elements MFEs to which the virtual machines physically connect e.g. through virtual interfaces . In some embodiments the logical routers are implemented in a centralized manner e.g. in one or more redundant gateways rather than distributed across the MFEs with the logical switches. In other embodiments the logical routers are implemented in a distributed fashion as well by the MFEs that connect to the virtual machines. However when the logical router also connects to the external network via one or more ports these connections to the external network are implemented through the use of one or more gateways. The gateways in some embodiments are responsible for both sending data traffic from the managed network to the external unmanaged physical network and processing traffic sent from the external network into the managed network.

As shown the physical infrastructure of the managed network includes three host machines for hosting virtual machines and a gateway host machine . The VMs of the logical network reside on the hosts implemented on top of virtualization software e.g. a hypervisor virtual machine monitor etc. that operates in the host. Additional virtual machines that connect to other logical networks may also reside on some or all of these hosts in the physical infrastructure of the managed network as well as on other hosts not shown in this figure .

In addition to the virtual machines each of the hosts operates a managed forwarding element MFE . In some embodiments this MFE is a software virtual switch that operates within the virtualization software of the host e.g. Open vSwitch or another software forwarding element . In the implementation illustrated in the managed forwarding elements in the hosts implement the logical switches and . As shown because only VM resides on the first host only the logical switch to which this VM connects is implemented by the MFE though other logical switches for other logical networks may also be implemented by the MFE . Similarly the MFE only implements the second logical switch while the MFE implements both logical switches and . In other embodiments each of these MFEs implements both logical switches.

In this centralized implementation of the logical network none of the MFEs that run in the VM hosts implement the logical router . Instead the entire routing table of the logical router resides in the gateway host . As shown a namespace or other virtualized container operates on the gateway host in order to implement the logical router . When one of the MFEs determines that a packet sent by one of the VMs of the logical network requires logical router processing the MFE sends the packet to the logical router implemented by the namespace . Some embodiments utilize tunnels between the MFEs and the MFE located in the gateway host . In some embodiments the MFEs are provisioned such that when a packet is logically forwarded to a logical router the MFE encapsulates the packet in a tunnel to the MFE operating on the gateway host . As mentioned some embodiments implement the logical router in several gateway hosts with one host active. In this case the MFEs send packets to the active host unless that tunnel is down in which case the MFEs send the packets to one of the standby hosts.

In other embodiments the managed forwarding elements in the VM host machines implement the logical router in a distributed manner with the logical routers implemented in the gateways only functioning to process packets sent from machines in the managed network to destinations outside the managed network and to process packets sent from sources outside the managed network to machines in the managed network. conceptually illustrates such a distributed implementation in a managed network . In this case a namespace operating in a gateway host machine only implements the routing table for packets entering or egressing the managed network rather than the entire routing table for the logical router .

As in the previous figure the portion of the physical infrastructure of the managed network that implements the logical network includes three host machines for hosting virtual machines and a gateway host machine that hosts a L gateway in a namespace . In this case the managed forwarding elements that operate on the hosts e.g. within the virtualization software of these hosts not only implement the logical switches and but also the logical router . This enables first hop logical processing in some embodiments in which all or most of the logical processing for a packet is performed at the first MFE that receives the packet. Thus a packet sent from VM to VM would be processed at the MFE through logical switch to logical router and then to logical switch . The MFE would identify the logical egress port of logical switch for the packet as the port to which VM attaches and map this egress port to a tunnel to the MFE at host .

However for traffic sent to an external destination i.e. not connected to either logical switch the MFE identifies a logical egress port of the logical router as the port that connects to the external network. The MFE then sends this traffic to the gateway host on which the L gateway is implemented i.e. the north south routing portion of the routing table for packet sent into and out of the managed network . As in the centralized embodiments in some embodiments the L gateway is implemented with one active gateway and one or more standby gateways.

As described above these MFEs and gateways are provisioned in some embodiments by a network control system. One or more network controllers in the network control system receive the network configuration input by a user administrator and convert this information into flow entries and or data tuples that can be used by the MFEs and gateway host machines and distributes the data tuples to the host machines.

In some embodiments each of the controllers in a network control system is a computer e.g. with an x86 based processor with the capability to function as an input translation controller logical controller and or physical controller. Alternatively in some embodiments a given controller may only have the functionality to operate as a particular one of the types of controller e.g. as a physical controller . In addition different combinations of controllers may run in the same physical machine. For instance the input translation controller and the logical controller may run in the same computing device with which a data center management application interacts or with which an administrator interacts directly .

The input translation controller of some embodiments includes an input translation application that translates network configuration information received from a user. While shown as receiving the information directly from the user in in some embodiments a user interacts with a data center management application which in turn passes the network configuration information to the input translation controller.

For example a user may specify a network topology such as that shown in . For each of the logical switches the user specifies the machines that connect to the logical switch i.e. to which logical ports of the logical switch the VMs are assigned . The user may also specify which logical switches attach to any logical routers a logical port of the logical router for connection to external networks and any configuration details for the logical router. The input translation controller translates the received network topology into logical control plane data that describes the network topology as a set of data tuples in some embodiments. For example an entry might state that a particular MAC address A is located at a first logical port X of a particular logical switch that a logical router Q is located at a second logical port Y of the particular logical switch or that a logical port G of the logical router Q is a gateway port to an external network.

In some embodiments each logical network is governed by a particular logical controller e.g. logical controller . The logical controller of some embodiments translates the logical control plane data that defines the logical network and the logical forwarding elements e.g. logical routers logical switches that make up the logical network into logical forwarding plane data and the logical forwarding plane data into physical control plane data. The logical forwarding plane data in some embodiments consists of flow entries described at a logical level. For the MAC address A at logical port X logical forwarding plane data might include a flow entry specifying that if the destination of a packet matches MAC A to forward the packet to port X. The port of the logical router Q will also have a MAC address and similar flow entries are created for forwarding packets with this MAC address to port Y of the logical switch. Similarly for a logical router with a port K to which a logical switch having a range of IP addresses C C the logical forwarding plane data might include a flow entry specifying that if the destination of a packet matches IP C C to forward the packet to port K.

In some embodiments the logical controller translates the logical forwarding plane data into universal physical control plane data. The universal physical control plane data enables the network control system of some embodiments to scale even when the network includes a large number of managed forwarding elements e.g. hundreds thousands to implement a logical forwarding element and when the network implements a large number of logical networks. The universal physical control plane abstracts common characteristics of different MFEs in order to express physical control plane data without considering differences in the MFEs and or location specifics of the MFEs.

As stated the logical controller of some embodiments translates logical control plane data into logical forwarding plane data e.g. logical flow entries that include a match over logical network parameters such as logical addresses logical ingress ports etc. then translates the logical forwarding plane data into universal physical control plane data. In some embodiments the logical controller application stack includes a control application for performing the first translation and a virtualization application for performing the second translation. Both of these applications in some embodiments use a rules engine for mapping a first set of tables into a second set of tables. That is the different data planes are represented as tables e.g. nLog tables and the controller applications use a table mapping engine e.g. an nLog engine to translate between the planes e.g. by applying join operations on the tables . The input and output tables in some embodiments store sets of data tuples that define the different planes of data.

In some embodiments the logical router processing entails recursive route traversal processes and various types of error checking that are not optimally performed by the table mapping engine. Specifically the configuration data for a logical router includes a set of input routes analogous to the routing information base of a physical router that must be narrowed to a set of output routes used to implement the routing table of the logical router analogous to the forwarding information base of a physical router . In some embodiments this set of output routes is part of the logical control plane data. In order to generate this logical control plane data for the logical router the table mapping engine of some embodiments offloads the route processing to a separate module in the logical controller implemented in a language better suited to such recursive and error checking generation actions. The route processing engine returns a set of output routes that the table mapping engine incorporates into its generation of logical forwarding plane entries.

Each of the physical controllers and is a master of one or more managed forwarding elements e.g. located within host machines . In this example each of the two physical controllers is a master of two managed forwarding elements located at the VM host machines . Furthermore the physical controller is a master of two gateway hosts and which host MFEs as well as the active and standby logical routers for a particular logical network. In some embodiments the active and standby hosts for a logical router are managed by the same physical controller as in this figure while in other embodiments separate physical controllers manage the different gateway hosts of a logical network.

In some embodiments a physical controller receives the universal physical control plane data for a logical network and translates this data into customized physical control plane data for the particular MFEs that the physical controller manages and which require data for the particular logical network. In other embodiments the physical controller passes the appropriate universal physical control plane data to the MFEs which have the ability e.g. in the form of a chassis controller running on the host machine to perform this conversion themselves.

The universal physical control plane to customized physical control plane translation involves a customization of various data in the flow entries. For the first example noted above the universal physical control plane would involve several flow entries i.e. several data tuples . The first entry states that if a packet matches the particular logical data path set e.g. based on the packet being received at a particular physical ingress port and the destination address matches MAC A then forward the packet to logical port X. This entry will be the same in the universal and customized physical control planes in some embodiments. Additional entries are generated to match a physical ingress port e.g. a virtual interface of the host machine to the logical ingress port X for packets received from the VM having MAC A as well as to match a destination logical port X to the physical egress port of the physical MFE e.g. again the virtual interface of the host machine . However these physical ingress and egress ports are specific to the host machine on which the MFE operates. As such the universal physical control plane entries include abstract physical ports while the customized physical control plane entries include the actual physical interfaces which in many cases are virtual interfaces of the specific MFEs.

In some embodiments as shown the logical router hosts also operate managed forwarding elements e.g. using the same packet processing virtual switching software as the VM hosts . These MFEs also receive physical control plane data from the physical controller that enables the MFEs to implement the logical forwarding elements. In addition some embodiments distribute the routing table data to the namespaces operating in the gateway hosts through the hierarchical network control system. The logical controller that manages the logical network selects the gateway host for the logical router in some embodiments e.g. using a load balancing algorithm that spreads the logical routers for various logical networks across a set of hosts .

The logical controller identifies the physical controller that manages the selected gateway host and distributes the routing table as well as any other information used for layer 3 processing such as firewall information NAT etc. to the identified physical controller. In some embodiments the routing table is distributed as a set of data tuples. The physical controller then distribute these data tuples to the gateway host . The gateway hosts convert these data tuples into a routing table for use by a container e.g. a VM a namespace that operates on the gateway host as a logical router or L gateway.

The above describes the hierarchical network control system of some embodiments although the network control system of other embodiments includes only a single controller or a controller cluster with one active and one or more standby controllers . conceptually illustrates the propagation of data through the hierarchical network control system of some embodiments. The left side of this figure shows the data flow to the managed forwarding elements to implement the logical forwarding elements either the logical switches or the logical switches and logical routers of the logical network while the right side of the figure shows the propagation of routing table data to the gateway hosts in order to provision the logical routers either the entire logical router or only the gateway logical router functionality .

On the left side the input translation controller receives a network configuration through an API which is converted into logical control plane data. This network configuration data includes a logical topology such as that shown in . In some embodiments the network configuration may also include the specification of one or more static routes for a logical router. The network configuration specifies attachments of logical switches to logical routers in some embodiments with MAC addresses assigned to each logical router port that connects to a logical switch and each logical switch having an associated IP subnet.

As shown the logical control plane data is converted by the logical controller specifically by a control application of the logical controller to logical forwarding plane data and then subsequently by a virtualization application of the logical controller to universal physical control plane data. In some embodiments these conversions generate a flow entry at the logical forwarding plane or a data tuple that defines a flow entry then add a match over the logical data path set e.g. the logical switch or router at the universal physical control plane. The universal physical control plane also includes additional flow entries or data tuples for mapping generic physical ingress ports i.e. a generic abstraction of a port not specific to any particular MFE to logical ingress ports as well as for mapping logical egress ports to generic physical egress ports. For instance for forwarding a packet to a logical router the flow entries at the universal physical control plane for a logical switch would include a forwarding decision to send a packet to the logical port to which the logical router connects when the destination MAC address matches that of the logical router port.

In addition for the centralized logical router the universal physical control plane entries would include a mapping of the logical port to a generic physical port of a host machine that connects to the gateway host on which the logical router resides and generic tunneling entries for encapsulating the packet in a tunnel to the gateway host. On the other hand for the distributed logical router the universal physical control plane entries would not send all packets destined for the logical router to the gateway but instead include the logical router processing. Similar to the examples in the previous paragraph for the logical switch the logical router flow entries identify a logical egress port based on a match over i the logical router pipeline i.e. that the packet has been forwarded to the logical router and ii the IP address. The mapping of IP address to logical port in some embodiments is based on the routing table generated by the route processing engine at the logical controller. For packets forwarded to a logical router port that faces the external network the universal physical control plane additionally includes entries for mapping the logical egress port to a destination gateway and encapsulating the packet in a tunnel to the gateway.

The physical controller one of the several physical controllers in the hierarchical network control system as shown translates the universal physical control plane data into customized physical control plane data for the particular MFEs that it manages at hosts and . This conversion involves substituting specific data e.g. specific physical ports for the generic abstractions in the universal physical control plane data. For instance in the example of the above paragraph the port integration entries are configured to specify the physical layer port appropriate for the particular logical router or L gateway connection e.g. an actual physical port and tunnel encapsulation information for the particular host machine on which the MFE operates .

The MFE at host one of several MFEs managed by the physical controller performs a translation of the customized physical control plane data into physical forwarding plane data in some embodiments. The physical forwarding plane data in some embodiments are the flow entries stored within a MFE e.g. within a software virtual switch such as Open vSwitch against which the MFE actually matches received packets. In addition the MFE at the gateway host performs such a translation in order to forward packets between the namespace and the other network entities e.g. VMs .

The right side of illustrates data propagated to the gateway hosts e.g. host to implement a logical router either a centralized logical router or a L gateway for a distributed logical router rather than to the MFEs. As shown the logical controller receives an input set of routes generates an output set of routes and then translates the output set of routes into routing data tuples from these routes.

In some embodiments the input set of routes is generated by either the logical controller or the input translation controller from the network configuration input by the user e.g. the administrator . When a user designs the logical network such as network each logical switch has an associated IP subnet. From this the logical controller automatically generates routes to each of these logical router ports that attach to the logical switches e.g. if IP 10.0.0.0 24 send to Port J . In addition when the logical router includes a gateway port to external networks the logical controller of some embodiments generates a low priority default route to send packets that do not match any other routes to the external network. The logical controller may have data in some embodiments that identifies a physical router in the external network so that the default route sends packets to the identified router. Furthermore users may input static routes as part of the logical network configuration. In some embodiments the static routes specify either a logical router port or a next hop network address to which to send packets with network addresses that fall in a given range e.g. 12.0.0.0 28 .

Before calculating the flow entries or the routing data tuples for the logical router the logical controller of some embodiments generates an output set of routes based on the input set of routes. In some embodiments a route processor in the logical controller recursively traverses the set of input routes to identify final output actions for each set of network addresses. For instance if the input set includes multiple routes for the same network address or set of network addresses the route processor identifies those with the highest priority as in use and removes for the purpose of creating a routing table for implementation in the network the lower priority routes. In addition if a route specifies to send packets to an output port that is not in use then the route processor removes that route. For static routes that specify a next hop network address rather than an output port the route processor traverses the set of routes i.e. identifying the route for the specified next hop network address until a route with either an output port or a drop action specifying for the router to drop packets sent to the network address is reached then outputs the final action for the network address to the set of output routes.

In the centralized logical router implementation of some embodiments all of the routes in the output set are converted into routing data tuples at the logical controller. This may be performed by the table mapping engine in some embodiments. In the distributed implementation much of the output set of routes is specified as part of the logical control plane data and converted into physical control plane data as shown on the left side of . In this case the routing data tuples for distribution to the L gateways will still include the routes to the external physical router s as well as routes for processing incoming packets received via the connection with these external routers.

In addition to the routes themselves the logical controller also generates a set of data tuples that defines the logical routers. For instance when a logical router is created the logical controller of some embodiments selects at least one gateway host then creates a new data tuple i.e. a record that specifies the new namespace or other container on the host for the logical router. In addition some embodiments specify in the data tuple that routing is enabled for the namespace as opposed to or in addition to other services such as DHCP .

Once the logical controller creates the data tuples and identifies the gateway host or hosts that will receive the data tuples the logical controller then identifies the physical controller that manages the gateway host. As mentioned like the VM hosts each of the gateway hosts has an assigned master physical controller. In the example of the gateway host is managed by the physical controller so the other physical controller does not receive the logical router data tuples. In order to supply the logical router configuration data to the gateway hosts the logical controller of some embodiments pushes the data to the physical controller . In other embodiments the physical controllers request the configuration data e.g. in response to a signal that the configuration data is available from the logical controller.

The physical controller passes the data to the gateway host much as it passes the physical control plane data. In some embodiments the routing data tuples are sent to a database running on the host that is part of the software associated with the MFE and used to configure certain aspects of the MFE e.g. its port information and other non flow entry configuration data . Some embodiments use a first protocol e.g. OpenFlow to pass the flow entries for the MFE to the hosts while using a second protocol e.g. OVSDB to pass the configuration and routing table data to the hosts. The namespace or other container implementing the logical router retrieves the appropriate information from the database on its host or has the appropriate information passed to it. In some embodiments a process on the gateway host translates the data tuples stored in the database into a routing table and other network stack data e.g. a standard Linux network stack including a routing table for the namespace.

The above description describes the conversion by the network control system of the network configuration into a set of physical forwarding plane flow entries that the physical controller passes to the host e.g. via a protocol such as OpenFlow . In other embodiments however the data for defining flow entries is passed in other forms such as more abstract data tuples and the MFEs or processes running on the hosts with the MFEs convert these data tuples into flow entries for use in processing data traffic.

As indicated above the network control system e.g. the network controllers of some embodiments enable administrators to configure static routes for logical routers in logical networks maintained by the administrators. These static routes are incorporated into the data structures that store state for the logical router along with automatically generated routes for the logical router. As such the network control system of some embodiments generates from the static routes and other logical router data flow entries and data tuples used to implement the logical router by the network elements managed by the network control system.

The API of some embodiments provides an interface through which the controller receives configuration state data for one or more logical networks. In some embodiments the API represents a set of methods that may be used to create modify delete query etc. logical network data in the state storage . In some embodiments a network administrator may access the controller through a direct connection e.g. by manually inputting the API calls or through a cloud management application. In the case of a cloud management application in some embodiments the administrator configures a logical network through a graphical interface or other intuitive interface of the application which translates the data received from the user into the appropriate API calls to the controller .

Some such API methods for the API include methods to create a logical router create logical router ports create a logical switch attach a logical switch to a logical router attach a logical port to an external network create a static route modify a static route remove a static route query a logical router for its routes etc. These various methods in some embodiments enable the administrator to access or modify configuration state data stored in the state storage .

In some embodiments the state storage stores a set of objects that define logical networks managed by the controller . Based on commands received by the API the controller creates objects in the state storage . The state storage of some embodiments is a network information base NIB described in detail in U.S. Patent Publication No. 2013 0058356 which is incorporated herein by reference although other embodiments use different storages for storing state information at the network controllers. In addition to storing the configuration state received through the API the state storage of some embodiments also stores computed state calculated by the state computation module .

Furthermore the network controller may receive state information from i other network controllers and ii network elements e.g. MFEs through interfaces with these entities not shown . In some embodiments other logical controllers receive configuration state for other logical networks and share the configuration state information with the controller e.g. through an RPC channel . In some such embodiments the network controllers only share configuration state and do not share computed state. This enables an administrator to input configuration data for a particular logical network into any of the network controllers as the configuration data will be shared with the network controller that manages the particular logical network and only that network controller will compute state for the logical network based on the input configuration state. The managed forwarding elements and namespaces hosting L gateways may also provide state information e.g. regarding links that are down the amount of traffic processed for particular logical networks etc. to their managing physical controller e.g. through one of the channels used to provision the MFE or namespace . When a physical controller receives this information in some embodiments the controller identifies the appropriate logical controller to which to provide the data which is then stored in the state storage of the controller e.g. storage .

The state computation module or set of modules of some embodiments allows the controller to compute additional state information based on i the configuration state received through the API ii previously computed state e.g. in a series of computations and iii state propagated upwards to the network controller from the physical managed forwarding elements. In some embodiments the state computation module is a table mapping engine e.g. the table mapping engine described above by reference to . The state computation module may also include a route processing engine for recursively traversing configuration state routes to generate computed state routes. The table mapping engine of some embodiments is implemented in a first table mapping programming language e.g. nLog that is optimal for performing join operations between tables while the route processing engine of some embodiments is implemented in a second programming language e.g. C that is optimal for error checking and recursive operations. In some such embodiments the table mapping engine receives the configuration state data from the state storage extracts the input set of routes from the configuration state and passes those input routes to the route processing engine. The route processing engine generates an output set of routes and returns the output data to the table mapping engine which stores the computed state in the state storage and uses the computed state to generate information for distribution to the managed forwarding elements and gateways. For purposes of this section however the state computation module is treated as a single entity. The details of the table mapping engine and route processing engine are described in greater detail below in Section III.

The operation of the controller to receive configuration state including static router information and process that configuration state will now be described by reference to . conceptually illustrates the receipt of a logical network configuration by the controller . As shown the API receives a configuration for a logical network through one or more API calls. The logical network as illustrated includes two logical switches that attach to a logical router which also connects to an external network e.g. through a L gateway port . The logical switches include several ports to which VMs attach. In addition the logical network configuration indicates that one of the logical router ports connecting to a switch is assigned the subnet 11.0.0.0 24 and the other logical router port connecting to a logical switch is assigned the subnet 10.0.0.0 24 while the third logical router port connecting to an external network is assigned the subnet 18.0.0.0 24.

Though shown as a single set of data in some embodiments the API receives separate commands to create each of the logical forwarding elements logical switch A logical switch B and the logical router . In addition in some embodiments the attachment of each logical switch to the logical router is a separate command as is the attachment of each VM to the logical switch.

The figure also illustrates a portion of the external physical network 18.0.0.0 24 to which the logical router gateway port connects. Specifically the external physical network includes two physical routers with interfaces 18.0.0.1 and 18.0.0.2 respectively connecting the logical routers to the physical network 18.0.0.0 24. While shown in the drawing along with the logical network configuration in order to provide clarity one of ordinary skill in the art will recognize that the administrator inputting the logical network configuration does not actually input the structure of the physical network. Rather the administrator simply configures the logical router gateway port with the subnet 18.0.0.0 24.

As illustrated the logical router object of some embodiments includes its list of ports two of which attach to the logical switches A and B and a third of which attaches to the external network as an L gateway port. The logical router object may specify whether the logical router is implemented in distributed or centralized fashion in some embodiments. In addition the API creates a set of routes as part of the logical router object. In some embodiments each of the routes is also an object owned by the logical router object stored in the state storage . As shown the set of routes includes routes automatically generated by the API based on the logical network configuration . Specifically for each of the logical ports connecting to a logical switch L gateway etc. the API generates a connected high priority route for the network address range e.g. IP addresses associated with that port.

In this case one of the routes is for the port to which logical switch A attaches. This route routes network addresses that fall in the range given in Classless Inter Domain Routing CIDR format 11.0.0.0 24 to the logical output port X. In addition the route object of some embodiments specifies the type of route e.g. connected because the route is based on a specific logical port the action to take for packets with destination IP addresses in the prefix range accept in this case though other routes may specify to drop packets and the priority of the route. In some embodiments connected routes are given the highest priority . In addition to the route the set of routes also includes a similarly structured route to send IP addresses in the range 10.0.0.0 24 to logical output port Y. In some embodiments the API also includes a low priority default route to send packets to a particular one of the external physical routers e.g. 18.0.0.2 if the IP address is not otherwise recognized. Such a route might specify to send packets in the range 0.0.0.0 0 to 18.0.0.2 but with a priority of or whatever number is used for the lowest priority . Other embodiments do not specify a priority for the route 0.0.0.0 0 because by longest prefix matching principles all routes will always be more specific and therefore have higher priorities. Such a route would be overruled by any more specific route but would serve to send packets for unknown destinations to the external network by default.

Though not shown in this figure the state computation module of some embodiments identifies that the configuration state has changed and subsequently retrieves this data in order to compute state information for distribution to the managed forwarding elements. The state computation module generates flow entries and or data tuples to distribute to the managed forwarding elements and namespaces and distributes this computed information e.g. via a set of physical controllers . The state computation module also stores the computed state in the state storage .

The API of some embodiments generates error messages to return to the user or application providing the API calls if a static route is not input properly. For instance if the static route specifies both a next hop IP and an output port or one of these destinations and a drop packet action or neither of these destinations with an accept action then the API returns an error message and does not create the route. Furthermore the API may send error messages if the specified logical router does not exist if the user attempts to manually create a connected route if any of the network addresses are malformed or if a route for the same prefix having the same priority already exists for the logical router.

Because the input route is correctly specified the API stores an object for the static route in the set of routes for the logical router as the static route configuration data identifies this as the logical router to which the route belongs. As shown the data stored for the object includes the information input for the route as configuration data the routed prefix 20.0.0.0 24 the next hop IP address 18.0.0.1 the accept action and the priority with being the highest priority . In this case the route specifies a next hop IP address of one of the physical routers on the external network to which the L gateway port Z is attached. The router 18.0.0.1 might have another interface that connects to the subnet 20.0.0.0 24 and therefore the administrator setting up the logical network would indicate via a static route that packets with those destination addresses should be sent to the particular router with the interface 18.0.0.1 i.e. as opposed to the other router with an interface 18.0.0.2 .

As shown in this figure the state computation module retrieves a set of input routes from the state storage and returns a set of output routes to the state storage. In some embodiments the controller stores a separate set of objects for the output routes as compared to the objects stored for the input routes. In other embodiments the controller stores additional information e.g. a final action whether the route is in use for each route in the existing object for the route. In still other embodiments the controller stores a set of objects with the additional information that are linked to the input routes e.g. a first set of route objects and a second set of route status objects with each route status object owned by a different route object .

In this example the output set of routes is stored with the logical router by the state computation module . The operation of the state computation module to generate the output set of routes will be described in greater detail below in Section III. As shown the logical router object now includes output routes including an output route for the input route . The output route specifies for network addresses in the range 20.0.0.0 24 that packets should be sent to output Port Z with a final next hop IP address of 18.0.0.1. This is based on the static route sending packets in the specified range to the IP address 18.0.0.1 which is in the range of addresses that the router sends to Port Z via a connected route generated based on the logical network configuration .

In addition to storing this computed state in the storage the state computation module also generates updated data to provision the MFEs and gateways based on the updated routes. That is the state computation generates additional data tuples and or flow entries that incorporate the added static route indicating to forward packets with destination addresses in the range 20.0.0.0 24 to the logical output port for the L gateway to the next hop IP address 18.0.0.1.

One example for which a user might configure static routes occurs when a logical router has multiple output ports connecting to an external network which are implemented on different gateways which might connect to different physical routers in the external network . The user might want packets for a specific external destination sent out either via a specific gateway or via a specific external router and this information could be incorporated into a static route i.e. specifying for packets to the destination s network address the next hop IP address of the specific router or the output port associated with the specific gateway . Similarly as in the case shown in a single logical router output port might connect to a physical network with multiple physical routers and the user might want packets for different destinations sent to the different routers e.g. if the different physical routers have interfaces to different networks .

As shown the process begins by receiving at a command to create a new static route for a logical router. In some embodiments the controller receives this through an API call to create a new route which includes various parameters to define the route. These parameters may include the logical router for which the route is defined the IP prefix range of packets that will be routed according to the route a destination for the route and a priority for the route as well as other parameters in some cases .

Upon receiving the route the process determines at whether the particular logical router for which the route is specified exists. In some embodiments the parameters specify a logical router for the route by a unique identifier. The logical router however must actually be a logical router for which data is stored at the controller. In some embodiments this does not require that the controller be the master of the logical router i.e. that the controller compute state for the logical router as the configuration state for the logical router may be shared between the controllers. Thus the process could be performed to receive static route information for a logical router at a controller that is not the master controller of the logical router as the receiving controller would share the data with the master controller which could then compute additional state information for the logical router based on the received data.

When the logical router specified in the logical route parameters does not exist the process proceeds to which is described below. Otherwise the process identifies at the prefix to be routed by the static route. This is the range of destination network addresses e.g. IP addresses to which the route will be applied i.e. the route will be applied to packets having a destination network address in the range specified by the prefix.

The process then determines at whether the identified prefix is valid. In some embodiments a valid prefix is one formatted in proper CIDR format i.e. four 8 bit numbers with a number of leading bits of the prefix . Thus a prefix range of X.Y.Z.0 24 specifies any network address from X.Y.Z.0 X.Y.Z.255. Similarly a prefix range of X.Y.Z.0 28 specifies any network address from X.Y.Z.0 X.Y.Z.127. A prefix is invalid if any of the specified numbers is greater than 8 bits e.g. if the user attempts to specify 257.0.0.0 if more than four numbers are given etc.

When the prefix specified for the route is invalid the process proceeds to described below. Otherwise the process identifies at a destination for the route. The process then determines at whether the destination is exactly one of a next hop network address an output port or a silent drop. Some embodiments actually specify these destinations as part of different parameters. For instance in some embodiments the static route definition allows for separate output port next hop IP and action parameters. The output port is used if the packets with destination addresses matching the specified prefix should be sent to a particular port of the logical router. The next hop IP address is used if the packets with destination addresses matching the specified prefix should be sent to e.g. a particular different router e.g. a physical router on an external network . Some embodiments require that an action be specified for the route with possible options of accept and blackhole i.e. silently drop without sending an error message to the sender .

Some embodiments do not allow the configuration for a static route to specify both an output port and a next hop network address. Furthermore when the specified action is to accept packets with destination addresses in the prefix range exactly one of the output port and the next hop address must be specified. On the other hand when the action specifies to drop packets then both of the output port and the next hop address must be empty.

When one of these conditions is violated e.g. more than one of silent drop a next hop address and an output port are specified or none of these are specified the process returns at an error. As indicated above an error may be returned for invalid prefixes or nonexistent logical routers as well. Some embodiments return an error message to the source of the command e.g. a management application an administrator computer etc. that attempted to create the new route.

When the route is a valid static route the process stores the route as an input route for the specified logical router. In some embodiments the process creates a new route object for the static route which is owned by a previously created logical router object. Storing the new route in some embodiments automatically causes the controller to perform a route traversal process for the logical router or at least for the new route of the logical router in order to identify whether to use the route and other output information for the route. Furthermore in some embodiments the controller automatically shares the configured route i.e. the input route with other controllers in case those controllers need to use the route to compute state information.

As indicated above the network controller of some embodiments performs route processing operations to generate an output set of routes from an input set of routes for a logical router. Specifically when new routes are configured for a logical router e.g. new static routes input manually through commands to the controller new connected routes generated based on the attachment of logical switches to ports of the logical router etc. some embodiments use a route processing engine in the controller to calculate the set of output routes. The route processing engine identifies final actions e.g. a final output port a drop action for each routed prefix identifies routes that should be taken out of use based on superseding higher priority routes and performs other actions. In some embodiments a table mapping engine in the controller uses the data from the route processing engine to generate data tuples for distribution to network elements e.g. managed forwarding elements namespaces that implement L gateways .

The API of some embodiments provides an interface through which the controller receives configuration state data for one or more logical networks. As described above by reference to in some embodiments the API represents a set of methods that may be used to create modify delete query etc. logical network data in the state storage . In some embodiments a network administrator may access the controller through a direct connection e.g. by manually inputting the API calls or through a cloud management application. Some such API methods for the API include methods to create a logical router create logical router ports create a logical switch attach a logical switch to a logical router attach a logical port to an external network create a static route modify a static route remove a static route query a logical router for its routes etc. These various methods in some embodiments enable the administrator to access or modify configuration state data for logical routers stored in the state storage .

In some embodiments the state storage stores a set of objects that define logical networks managed by the controller as well as configuration state for logical networks managed by other network controllers. Based on commands received by the API the controller creates modifies and deletes objects in the state storage . In addition to storing the configuration state received through the API the state storage of some embodiments also stores computed state calculated by the state computation module . Furthermore the network controller may receive state information from other network controllers and network elements e.g. MFEs gateways operating in namespaces as described above by reference to .

The table mapping engine performs state calculations for logical networks managed by the controller . As shown the table mapping engine includes a flow generation module and a configuration data generation module both of which generate data for distribution to the managed forwarding elements and L gateways. In some embodiments both of these modules use similar input data tuples to generate output data tuples but generate different data for distribution to the various network elements.

The flow generation module generates data for the managed forwarding elements to use in processing packets. Specifically in some embodiments the flow generation module generates flow entries that take a match action format. That is each flow entry specifies a condition or set of conditions for a packet to match and an action or set of actions for a managed forwarding element to apply to the packet when the packet matches all of the conditions. For instance one of many flow entries used to implement a logical router might specify that if a packet i has been assigned to the logical router and ii has a destination IP address in a particular range e.g. 10.0.0.0 24 then take the actions of i writing a particular logical egress port into a register for the packet and ii resubmit the packet to the managed forwarding element for further processing. In some embodiments the flow generation module generates the flow entries by performing table mapping operations e.g. join operations on the data stored in the state storage as well as information received from the route processing engine . In some embodiments the flow generation module of the table mapping engine outputs data for distribution via the OpenFlow protocol.

The configuration data generator generates data for both the managed forwarding elements as well as the namespaces in which logical routers and L gateways operate in some embodiments. For the managed forwarding elements the configuration data may include port and or tunnel configuration among other data. Whereas the MFEs receive packet processing data as flow entries however the namespaces that implement centralized logical routers and L gateways for distributed logical routers receive packet processing instructions in the format of data tuples distributed in the same manner as configuration data. For instance for a namespace the gateway host machine on which the namespace resides receives the definition of the namespace as a data tuple generated by the configuration data generator and receives its routing table and other network stack configuration in this format as well in some embodiments. As with the flow generation module the configuration data generator of some embodiments generates configuration data by performing table mapping operations e.g. join operations on the data stored in the state storage as well as information received from the route processing engine . In some embodiments the configuration data generator outputs data for distribution via the OVSDB protocol.

The route processing engine of some embodiments receives a set of routes from the table mapping engine e.g. routes automatically generated based on the subnets to which the logical ports of the logical router connect static routes received through the API and performs a recursive traversal process on the routes in order to identify a final logical destination for each network address range routed by the logical router. When multiple input routes provide contradictory information for a particular network address or range of addresses the route processing engine of some embodiments determines which route has a higher priority. Some input routes may provide a next hop address rather than output port for a route. In these cases the route processing engine recursively traverses the set of input routes until reaching a route specifying either a destination output port or a drop packet action. The route processing engine returns the set of output routes with final actions e.g. drop packet send to particular output port specified for each route. In some embodiments the route processing engine is implemented in a language different from the table mapping engine i.e. not a table mapping language . Specifically some embodiments implement the route processing engine in a language that is optimal for error checking and recursive traversal processes e.g. C C etc. .

The controller distributes the flow entries and configuration data for the logical router and other data for e.g. other logical forwarding elements such as the logical switches of the logical network generated by the table mapping engine to host machines via the state distribution interface . The host machines shown in the figure include a first machine for hosting VMs and a second machine for hosting namespaces to implement logical routers and gateways. Both of the host machines and include managed forwarding elements for processing packets e.g. OVS while the gateway host also includes the logical routers and gateways to act as routers in order to process packets.

In some embodiments the controller distributes the data through a hierarchy of other network controllers as shown above in . In such embodiments the state distribution interface is an interface with other controllers that act as intermediaries for the distribution of data to the host machines and possibly perform additional translation of the data tuples . In some embodiments the controller uses a Remote Procedure Call RPC channel to communicate with other controllers.

In other embodiments the controller interfaces directly with the host machines and as well as numerous other host machines to distribute the data. In some such embodiments the controller uses two channels for communication with each host machine a first channel e.g. OpenFlow for distributing the flow entries generated by the flow entry generation module for use by the managed forwarding elements and a second channel e.g. OVSDB for distributing the configuration data generated by the configuration data generator .

The data flow through the network controller during its operation to process logical router information will now be described. includes several encircled numbers which indicate the flow of different data into through and out of the network controller . One of ordinary skill in the art will recognize that the controllers of some embodiments will process data other that that which is shown and that the data flow in this figure is meant to represent the operations performed and data transferred specifically relating to a logical router managed by the network controller.

As shown by the encircled the API receives a command to create or modify the configuration of a logical router. Specifically the command modifies the routes stored for the logical router. The command could be the creation of a new static route the attachment of a logical switch to a port of the logical router the creation of a new port for the logical router the modification of an existing static route etc.

As a result shown by the encircled the API modifies the data structure stored for the logical router e.g. an object such as a C object in the state storage . The figure illustratively shows the logical router data structure as storing a RIB set of input routes and FIB set of output routes . While some embodiments use such a structure other embodiments store data structures e.g. objects for each input route owned by the logical router. After processing in some such embodiments the logical router also stores a status data structure e.g. object for each route. Other such embodiments modify the route data structure after processing to include the status data. This processing will be described in further detail below.

In this example the configuration state of the logical router is modified based on data received through the API of the controller . However in some embodiments this configuration data could instead be received by another controller in the network control system. In this case the other controller receives the data and updates its copy of the logical router data structure. However because the other controller does not manage the particular logical router the controller does not compute additional state based on the input state. The other controller does though propagate the modified configuration state to other controllers including the controller . In this situation when the controller receives the update to the logical router data structure the controller proceeds as shown by the remainder of the figure.

When the configuration state of the logical router data structure is modified the table mapping engine retrieves the state of the logical router as shown by the encircled in the figure. For changes to other data structures and for some changes to the logical router the table mapping engine begins computing additional state at this point. However because the update to the logical router modifies the configuration state routes of the data structure the table mapping engine passes the route data to the route processing engine as shown by the encircled .

The route processing engine performs a route selection and traversal operation in order to identify the output routing table for the logical router. The operation of the route processing engine according to some embodiments is shown by . In some embodiments the route processing engine takes as input each new or modified route for the logical router and outputs status data for each route. For instance for a new static route that specifies a next hop IP address the route processing engine determines whether to use the new route and if in use a final output port for the route or a final action of blackhole i.e. drop packets for the route. The route processing engine returns the output set of routes to the table mapping engine as shown by the encircled .

At this point the table mapping engine performs several actions. The output routing data computed by the route processing engine is stored in the logical router data structure as shown by the encircled . This figure conceptually illustrates this data as being stored in the FIB. The conceptual RIB for input configuration data and FIB for output data represent analogies to the RIB to FIB conversion performed by physical routers in traditional networks.

The table mapping engine also generates both flow entries and configuration data using the output routing data provided by the route processing engine . For distributed logical routers much of the routing for packets sent by VMs of the logical networks is performed by the first hop MFEs using the flow entries. As such these flow entries use the routing data to encode the routes in a match action format. Thus a route specifying that a particular network address range is routed to a particular logical port will be encoded as a match on the destination address over the network address range and an action to send the packet to the logical port. Similarly a route specifying that a particular network address range is to be blackholed will be encoded as a match on the destination address over the network address range and an action to drop the packet. In some cases the logical router also specifies other data e.g. routing policies etc. which the table mapping engine encodes in flow entries as well. Because the MFEs operate on both the VM hosts and the gateway hosts the table mapping engine distributes the flow entries to both the host and the host through the state distribution interface as shown by the encircled s though at least some of the flow entries distributed will be different between the two hosts .

In addition the table mapping engine uses the output routing data from the route processing engine to generate configuration data for the namespace operating as a L gateway on the host . This configuration data in some embodiments i defines the existence of the namespace and ii provides configuration information for the network stack in the namespace including the routing table. Thus the output routing data from the route processing engine is used to generate a set of data tuples defining a routing table for the namespace that implements a L gateway for the logical router. This data is distributed to the gateway host through the state distribution interface as shown by the encircled . As described above both the flow entry data tuples and the configuration data tuples may be distributed through a hierarchy of network controllers rather than directly from the controller to the host machines and e.g. through two different network controllers that manage the two different host machines and .

The above described the data flow through a controller for logical router processing according to some embodiments. As mentioned one of the operations performed on the data involves the route processing engine which receives a set of input routes and outputs a set of output routes or output routing table data about the input routes . conceptually illustrate a process performed by the route processing engine of some embodiments to generate a set of output route information for a set of input routes of a logical router. The process will be described by reference to which conceptually illustrate various example input and output sets of route information.

As shown the process begins by receiving at a set of input routes from the table mapping engine. As mentioned the route processor that performs the process is in some embodiments a separate set of code from the table mapping engine that performs the bulk of the state computation for the network controller. The table mapping engine accesses the stored state data for a logical router e.g. the set of route objects determines when the route processing engine should process the state data and passes the data to the route processing engine. In some embodiments each route in the set of routes is an object that stores a set of parameters including the type e.g. connected or static a prefix i.e. a range of network addresses an output port i.e. the logical router port to which packets matching the prefix will be sent a next hop address i.e. the IP address of the next hop router or gateway to which packets matching the prefix will be sent an action e.g. accept allow packets matching the prefix or blackhole drop packets matching the prefix and a priority used to select between routes for the same network address .

To perform route processing the process of some embodiments first identifies routes that are superseded by higher priority routes. Different embodiments may perform different sets of operations to identify low priority routes that should not be used and only one possible set of operations is shown in this figure. In the example shown the process selects one route at a time then identifies all of the routes that should be removed from use based on having a lower priority than the selected route. Other embodiments might select one route at a time and then determine whether any other routes eliminate the selected route from use based on having a higher priority.

In this case the process selects at a route. Some embodiments start with the highest priority routes or the lowest priority routes use a random or pseudo random order start with the earliest or latest created routes etc. For the selected route the process determines at whether any of the other input routes have the same network address range specified by their prefix as the currently selected route. In some embodiments only routes that have the same network address range are identified at operation . That is routes with overlapping prefixes of different specificity are not identified. That is a first route for the prefix 12.0.0.1 28 has its entire network address range encompassed by a second route for the prefix 12.0.0.0 24. However even if the 12.0.0.0 24 route has a higher priority the first route will not be removed. This is because the logical routers of some embodiments use longest prefix matching principles. Thus a more specific route e.g. a 28 route has an inherently higher priority than a less specific route e.g. a 24 route . Packets matching two routes of different specificities will be routed by the more specific route irrespective of the listed priorities of the routes.

If any routes exist in the input routes with the same prefix as the selected route the process marks at all of the routes for the prefix except the highest priority route as not in use. This indicates that the network controller will not use the route when generating data tuples to implement the logical router. In this way the route processing engine decreases the number of routes actually implemented in the network when the routes will not have any bearing on the processing of packets.

After marking any low priority routes that are superseded by the selected route as not in use the process determines at whether the set of input routes contains any additional routes to check for superseded lower priority routes. When a route is marked as not in use some embodiments remove the route from the set of input routes to analyze with operations . When more routes remain for analysis by these operations the process returns to to select another route.

Once all of the routes have been processed to remove low priority routes the route processing engine then removes routes that send packets to ports that are not in use. For this the process selects at a route that is in use i.e. that has not been marked as not in use and specifies an output port. As with operation different embodiments may select the routes in an order based on priority time of creation etc. In this case though only routes that specify a destination output port i.e. a port of the logical router are selected. As described above routes may either specify a destination output port a destination next hop IP address or a drop action but not more than one of these. For this operation the route processing engine is only interested in the routes that specify destination output ports.

For the selected route the process determines at whether the port exists and is currently up. In some cases the route may specify as its destination a logical port that does not exist. For instance a user might create a logical router with six ports and then create a static route pointing to the fifth port. If the user then modifies the logical router to remove the fifth and sixth ports the static route will point to a non existent port. Furthermore a port might not be in use. If in the previous example the user does not attach the fifth port to any destinations e.g. an external network a logical switch etc. then the port will not be in use.

If the selected route specifies as a destination an output logical port that either does not exist or is down not in use then the process marks at the selected route as not in use. This indicates that the network controller will not use the route when generating data tuples to implement the logical router. This prevents the implementation of the logical router from sending packets to logical ports that do not map to a physical destination.

After evaluating each route specifying an output port the process determines at whether the set of input routes in use includes any additional routes that specify output port destinations. When more such routes exist the process returns to to select the next such route. After checking all of the routes that specify output ports the process then begins the recursive route traversal operations. These operations for each route identify either a destination output port or a drop action based on following the paths specified by the set of routes.

As shown the process selects at a route that is in use i.e. not superseded by a higher priority route and specifies a next hop destination IP address rather than a drop packet action or an output port destination . Similar to operations and different embodiments select the routes in a different order.

For the selected route the process looks up at a route for the specified destination next hop IP address. So long as a default route for the prefix 0.0.0.0 0 is included in the input set of routes then all IP addresses will match at least one route. If the IP address maps to the prefixes of multiple routes then operation uses the route with the longest prefix match in some embodiments. For instance if the selected route specifies a next hop IP of 20.1.1.1 and routes exist for the prefixes 20.0.0.0 8 and 20.1.1.0 24 the route processor uses the route for the more specific prefix 20.1.1.0 24.

The process then determines at whether the route identified for the next hop IP is in use. In general the routes are in use by default unless marked as not in use for either low priority or a port related issue the port being down or nonexistent . In this case lower priority routes will not be identified for a next hop IP because the higher priority route will always be an option. When the highest priority and most specific route identified for the next hop is not in use then the process marks at the selected route as not in use and proceeds to operation to determine whether additional routes require the route traversal process.

Otherwise if the route for the next hop IP is still in use the process determines at whether the route for the next hop IP address is set to drop packets. As mentioned some routes may specify a drop packet action rather than an accept packet action with a destination. If the identified route for the next hop is set to drop packets the process sets at the currently selected route selected at operation to also drop packets and clears at the previously specified next hop IP for the selected route then proceeds to operation . Because some embodiments do not allow a route to specify a destination e.g. a next hop IP address and specify to drop packets when the route processor sets the drop packet action for a route the route processor also removes the next hop IP for the route in order to satisfy these criteria. In some embodiments the route processor does not modify the route object but rather a route status object that specifies the output settings for the route to be used by the table mapping engine to generate data tuples for implementation of the logical router. In some such embodiments the route processor sets a final action parameter for the route status to drop packets and clears a final next hop IP parameter but does not change the configured route data.

If the identified route for the next hop IP does not specify a drop packet action the process then determines at whether the route identified for the next hop IP address specifies an output port destination. At this point the route identified at operation either specifies i another next hop IP address or ii an output port as its destination as it does not specify a drop packet action.

When the identified route does not specify an output port destination i.e. specifies another next hop IP address the process returns to operation to look up a route for the next hop IP address specified by the route identified at the previous iteration of operation . Thus if a first route for the prefix 13.0.0.0 24 specifies a next hop gateway IP of 14.0.0.1 and a second route for the prefix 14.0.0.0 24 specifies a next hop gateway IP of 15.0.0.1 then the route processor looks up a third route for 15.0.0.1 and attempts to use the specified action or destination for this route to resolve the first route. The process continues recursively attempting to resolve the routes until it reaches a route that i not in use ii specifies a drop action or iii specifies an output port.

When the most recently identified route specifies an output port as its destination the process sets at the final output port of the selected route as the output port specified by the most recently identified route. In addition the process sets the current next hop IP i.e. the next hop IP for which the most recently identified route was identified as the final next hop IP for the selected route i.e. the route selected at operation .

As the first two routes specify output ports as their destinations these routes are simply marked as in use in the output set of routes and no traversal is required. In some embodiments though not shown in this figure for simplicity the route processor copies the output ports into a final output port route status field for each of these routes and similarly copies the action of accept into a final action status field for the routes. For the route the route traversal process first looks up a route for the next hop IP address of 12.0.0.1 and identifies the route . Because this route specifies a next hop IP destination of 11.0.0.1 the route traversal process next looks up a route for this IP address and identifies the route . At this point the newly identified route specifies an output port so this output port X and the final next hop IP address 11.0.0.1 are copied into the final status data for the output route . For the route the route traversal process involves fewer recursive lookups as the first route identified is the route which specifies the output port X. As such the output route includes the final output port X. In some embodiments the route processor also copies the next hop IP 11.0.0.1 into a final next hop IP field for the output. The default route specifies a next hop IP 10.0.0.1 which resolves to Port Y after the recursive route traversal.

Returning to the process after a selected route has been resolved and any needed output data generated for the route the process determines at whether any additional routes remain that require the route traversal process i.e. are not marked as not in use and specify a next hop IP address . When additional routes remain the process returns to to select another route for traversal. Once all of the routes have been analyzed and the output data generated for the routes the process returns at the output set of routes to the table mapping engine so that the table mapping engine can use the output status data to generate the data tuples used by the MFEs and gateways to implement the logical router.

Many of the above described features and applications are implemented as software processes that are specified as a set of instructions recorded on a computer readable storage medium also referred to as computer readable medium . When these instructions are executed by one or more processing unit s e.g. one or more processors cores of processors or other processing units they cause the processing unit s to perform the actions indicated in the instructions. Examples of computer readable media include but are not limited to CD ROMs flash drives RAM chips hard drives EPROMs etc. The computer readable media does not include carrier waves and electronic signals passing wirelessly or over wired connections.

In this specification the term software is meant to include firmware residing in read only memory or applications stored in magnetic storage which can be read into memory for processing by a processor. Also in some embodiments multiple software inventions can be implemented as sub parts of a larger program while remaining distinct software inventions. In some embodiments multiple software inventions can also be implemented as separate programs. Finally any combination of separate programs that together implement a software invention described here is within the scope of the invention. In some embodiments the software programs when installed to operate on one or more electronic systems define one or more specific machine implementations that execute and perform the operations of the software programs.

The bus collectively represents all system peripheral and chipset buses that communicatively connect the numerous internal devices of the electronic system . For instance the bus communicatively connects the processing unit s with the read only memory the system memory and the permanent storage device .

From these various memory units the processing unit s retrieve instructions to execute and data to process in order to execute the processes of the invention. The processing unit s may be a single processor or a multi core processor in different embodiments.

The read only memory ROM stores static data and instructions that are needed by the processing unit s and other modules of the electronic system. The permanent storage device on the other hand is a read and write memory device. This device is a non volatile memory unit that stores instructions and data even when the electronic system is off. Some embodiments of the invention use a mass storage device such as a magnetic or optical disk and its corresponding disk drive as the permanent storage device .

Other embodiments use a removable storage device such as a floppy disk flash drive etc. as the permanent storage device. Like the permanent storage device the system memory is a read and write memory device. However unlike storage device the system memory is a volatile read and write memory such a random access memory. The system memory stores some of the instructions and data that the processor needs at runtime. In some embodiments the invention s processes are stored in the system memory the permanent storage device and or the read only memory . From these various memory units the processing unit s retrieve instructions to execute and data to process in order to execute the processes of some embodiments.

The bus also connects to the input and output devices and . The input devices enable the user to communicate information and select commands to the electronic system. The input devices include alphanumeric keyboards and pointing devices also called cursor control devices . The output devices display images generated by the electronic system. The output devices include printers and display devices such as cathode ray tubes CRT or liquid crystal displays LCD . Some embodiments include devices such as a touchscreen that function as both input and output devices.

Finally as shown in bus also couples electronic system to a network through a network adapter not shown . In this manner the computer can be a part of a network of computers such as a local area network LAN a wide area network WAN or an Intranet or a network of networks such as the Internet. Any or all components of electronic system may be used in conjunction with the invention.

Some embodiments include electronic components such as microprocessors storage and memory that store computer program instructions in a machine readable or computer readable medium alternatively referred to as computer readable storage media machine readable media or machine readable storage media . Some examples of such computer readable media include RAM ROM read only compact discs CD ROM recordable compact discs CD R rewritable compact discs CD RW read only digital versatile discs e.g. DVD ROM dual layer DVD ROM a variety of recordable rewritable DVDs e.g. DVD RAM DVD RW DVD RW etc. flash memory e.g. SD cards mini SD cards micro SD cards etc. magnetic and or solid state hard drives read only and recordable Blu Ray discs ultra density optical discs any other optical or magnetic media and floppy disks. The computer readable media may store a computer program that is executable by at least one processing unit and includes sets of instructions for performing various operations. Examples of computer programs or computer code include machine code such as is produced by a compiler and files including higher level code that are executed by a computer an electronic component or a microprocessor using an interpreter.

While the above discussion primarily refers to microprocessor or multi core processors that execute software some embodiments are performed by one or more integrated circuits such as application specific integrated circuits ASICs or field programmable gate arrays FPGAs . In some embodiments such integrated circuits execute instructions that are stored on the circuit itself

As used in this specification the terms computer server processor and memory all refer to electronic or other technological devices. These terms exclude people or groups of people. For the purposes of the specification the terms display or displaying means displaying on an electronic device. As used in this specification the terms computer readable medium computer readable media and machine readable medium are entirely restricted to tangible physical objects that store information in a form that is readable by a computer. These terms exclude any wireless signals wired download signals and any other ephemeral signals.

While the invention has been described with reference to numerous specific details one of ordinary skill in the art will recognize that the invention can be embodied in other specific forms without departing from the spirit of the invention. In addition a number of the figures including conceptually illustrate processes. The specific operations of these processes may not be performed in the exact order shown and described. The specific operations may not be performed in one continuous series of operations and different specific operations may be performed in different embodiments. Furthermore the process could be implemented using several sub processes or as part of a larger macro process. Thus one of ordinary skill in the art would understand that the invention is not to be limited by the foregoing illustrative details but rather is to be defined by the appended claims.

