---

title: Automated software installation using a click area prediction model
abstract: A device may receive an instruction to automatically install a program using a click area prediction model. The click area prediction model may be associated with predicting a click area of a user interface that, when selected, causes a program installation procedure to proceed. The device may identify an installation user interface associated with installing the program. The device may determine a group of regions included in the installation user interface. The device may identify sets of features associated with the group of regions. The device may determine, based on the sets of features and the click area prediction model, a group of scores associated with the group of regions. The device may identify a particular region as a predicted click area based on the group of scores. The device may select the predicted click area to attempt to cause the program installation procedure to proceed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09477457&OS=09477457&RS=09477457
owner: Juniper Networks, Inc.
number: 09477457
owner_city: Sunnyvale
owner_country: US
publication_date: 20140331
---
A computer program e.g. software may be installed on a device to allow the program to be executed by the device. Some programs are supplied in a form unsuitable for immediate execution and require an installation procedure. The program may be repeatedly executed after installation e.g. without the need to reinstall the program before each execution .

According to some possible implementations a device may include one or more processors to receive an instruction to automatically install a program using a click area prediction model where the click area prediction model may be associated with predicting a click area of a user interface and where the click area may include an area of a user interface that when selected causes a program installation procedure associated with installing the program to proceed identify an installation user interface associated with installing the program determine a group of regions included in the installation user interface identify sets of features associated with the group of regions where each set of features of the sets of features may correspond to a region of the group of regions determine based on the sets of features and the click area prediction model a group of scores associated with the group of regions where each score of the group of scores may correspond to a region of the group of regions identify a particular region of the group of regions as a predicted click area based on the group of scores and select the predicted click area where the predicted click area may be selected to attempt to cause the program installation procedure to proceed.

According to some possible implementations a computer readable medium may store one or more instructions that when executed by one or more processors cause the one or more processors to receive an indication to install a program without user intervention using a click area prediction model associated with predicting a click area of a user interface where the click area may include an area of a user interface that when selected causes a program installation process associated with installing the program to continue determine an installation user interface associated with installing the program identify a group of regions included in the installation user interface determine sets of features associated with the group of regions where each set of features of the sets of features may be associated with a corresponding region of the group of regions determine based on the sets of features and the click area prediction model a group of scores associated with the group of regions where each score of the group of scores may be associated with a corresponding region of the group of regions and where each score of the group of scores may reflect a prediction that the corresponding region is associated with a click area of the installation user interface identify a particular region of the group of regions as a predicted click area based on the group of scores and select the predicted click area where the predicted click area may be selected to attempt to cause the program installation process to continue.

According to some possible implementations a method may include receiving by a device an indication to automatically install software using a click area prediction model where the click area prediction model may be associated with predicting a click area of a user interface and where the click area including an area of a user interface that when selected causes a software installation procedure associated with installing the software to advance identifying by the device an installation user interface associated with installing the program determining by the device a group of regions include in the installation user interface identifying by the device sets of features associated with the group of regions where each set of features of the sets of features may correspond to a region of the group of regions determining by the device a group of scores associated with the group of regions where the group of scores may be determined based on inputting the sets of features into the click area prediction model and where each score of the group of scores may correspond to a region of the group of regions identifying by the device a predicted click area based on the group of scores and selecting by the device the predicted click area based on identifying the predicted click area where the predicted click area may be selected to attempt to cause the software installation procedure to advance.

The following detailed description of example implementations refers to the accompanying drawings. The same reference numbers in different drawings may identify the same or similar elements.

A user may wish to install software e.g. a computer program an application etc. on a user device e.g. a laptop computer a desktop computer a tablet etc. . In some cases the user may want the user device to install the software automatically e.g. without user intervention by automatically navigating a series of user interfaces e.g. dialog boxes associated with installing the software. However this type of automated software installation may require the user device to be capable of intelligently interacting with the dialog boxes. In some cases the use of standard dialog boxes in a software installation procedure may allow the software installation to be scripted e.g. using an operating system specific application programming interface but this approach fails when a software installation procedure uses non standard dialog boxes. Implementations described herein may allow a device to automatically e.g. without user intervention install software by training a click area prediction model to detect and intelligently select click areas of user interfaces e.g. dialog boxes associated with installing the software. In this way software may be automatically installed despite the use of non standard user interfaces in the software installation procedure.

As shown in the user device may receive the instruction to automatically install the software and may initiate a software installation procedure associated with installing the software. As shown the software installation procedure may begin by causing the user device to display a software installation dialog box.

As shown in the user device may identify a dialog box associated with the software installation e.g. after the user device initiates the software installation procedure . As further shown the user device may determine a group of regions associated with the dialog box by dividing e.g. using a grid system the dialog box into regions.

As further shown in the user device may identify a set of features associated with a first region e.g. region A such as color features of the region geometric features of the region image fragment features of the region fill features of the region neighbor features of the region and or text features of the region. As shown the user device may input the set of features associated with the first region into the click area prediction model e.g. stored and or accessible by the user device and the click area prediction model may output a score associated with the first region. The score e.g. a numerical value may indicate the likelihood that the first region is within a desired click area of the dialog box. As shown the user device may continue to identify sets of features associated with each region and input the sets of features into the click area prediction model to generate a score for each region of the dialog box.

As shown in the user device may determine the scores and may identify the region that corresponds to the highest score as a predicted click area. For the purposes of example implementation assume that the predicted click area is a region that falls within the Next button included in the dialog box. As shown the user device may select the predicted click area to attempt to proceed with the software installation without user intervention. The user device may continue in this manner by predicting a click area for another dialog box associated with installing the software e.g. a dialog box that appears after selecting the Next button in the first dialog box . In this way a user device may automatically e.g. without user intervention install software using a click area prediction model to detect and intelligently click on user interfaces e.g. dialog boxes associated with installing the software.

User device may include one or more devices capable of automatically installing software based on an output of a click area prediction model. For example user device may include a computing device such as a laptop computer a tablet computer a handheld computer a desktop computer a mobile phone e.g. a smart phone a radiotelephone etc. a personal digital assistant a gaming device or a similar device. In some implementations user device may be capable of identifying a user interface e.g. a dialog box associated with a software installation determining a group of regions associated with the user interface and identifying e.g. using computer vision by analyzing the user interface etc. a set of features associated with each region of the group of regions. Additionally or alternatively user device may be capable of inputting the set of features associated with the region into a click area prediction model and receiving an output e.g. a score provided by the click area prediction model.

Network may include one or more wired and or wireless networks. For example network may include a wireless local area network WLAN a local area network LAN a wide area network WAN a metropolitan area network MAN a telephone network e.g. the Public Switched Telephone Network PSTN a cellular network a public land mobile network PLMN an ad hoc network an intranet the Internet a fiber optic based network or a combination of these or other types of networks. In some implementations network may allow communication between devices such as user device and modeling device .

Modeling device may include one or more devices capable of receiving providing generating storing and or processing information associated with a click area prediction model. For example modeling device may include a computing device such as a server. In some implementations modeling device may be capable of storing and or providing information associated with the click area prediction model. Additionally or alternatively modeling device may be capable of analyzing a training user interface and updating and or training the click area prediction model based on a result of analyzing the training user interface.

The number of devices and networks shown in is provided for explanatory purposes. In practice there may be additional devices and or networks fewer devices and or networks different devices and or networks or differently arranged devices and or networks than those shown in . For example user device and modeling device may be implemented within a single device. Furthermore two or more of the devices shown in may be implemented within a single device or a single device shown in may be implemented as multiple distributed devices. Additionally one or more of the devices of environment may perform one or more functions described as being performed by another one or more of the devices of environment . Devices of environment may interconnect via wired connections wireless connections or a combination of wired and wireless connections.

Bus may include a path that permits communication among the components of device . Processor may include a processor a microprocessor and or any processing component e.g. a field programmable gate array FPGA an application specific integrated circuit ASIC etc. that interprets and or executes instructions. In some implementations processor may include one or more processor cores. Memory may include a random access memory RAM a read only memory ROM and or any type of dynamic or static storage device e.g. a flash memory a magnetic memory an optical memory etc. that stores information and or instructions for use by processor .

Input component may include any component that permits a user to input information to device e.g. a keyboard a keypad a mouse a button a switch etc. . Output component may include any component that outputs information from device e.g. a display a speaker one or more light emitting diodes LEDs etc. .

Communication interface may include any transceiver like component such as a transceiver and or a separate receiver and transmitter that enables device to communicate with other devices and or systems such as via a wired connection a wireless connection or a combination of wired and wireless connections. For example communication interface may include a component for communicating with another device and or system via a network. Additionally or alternatively communication interface may include a logical component with input and output ports input and output systems and or other input and output components that facilitate the transmission of data to and or from another device such as an Ethernet interface an optical interface a coaxial interface an infrared interface a radio frequency RF interface a universal serial bus USB interface or the like.

Device may perform various operations described herein. Device may perform these operations in response to processor executing software instructions included in a computer readable medium such as memory . A computer readable medium is defined as a non transitory memory device. A memory device includes memory space within a single physical storage device or memory space spread across multiple physical storage devices.

Software instructions may be read into memory from another computer readable medium or from another device via communication interface . When executed software instructions stored in memory may cause processor to perform one or more processes that are described herein. Additionally or alternatively hardwired circuitry may be used in place of or in combination with software instructions to perform one or more processes described herein. Thus implementations described herein are not limited to any specific combination of hardware circuitry and software.

The number of components shown in is provided for explanatory purposes. In practice device may include additional components fewer components different components or differently arranged components than those shown in .

As shown in process may include receiving a training user interface including a known click area associated with a click area prediction model used for automating software installation block . For example modeling device may receive a training dialog box including a known click area associated with a click area prediction model used for automating software installation. In some implementations modeling device may receive the training user interface from another device e.g. a device associated with generating the training user interface . In some implementations modeling device may receive the training user interface based on user input e.g. when a user of modeling device creates the training user interface .

A training user interface may include a user interface that includes a known click area. A known click area may include an area of a training user interface known to modeling device that when selected e.g. by clicking would cause a software installation to proceed e.g. if the training user interface were a part of an actual software installation . For example a training user interface may include an area e.g. a rectangle a square etc. corresponding to a Next button and Install button an OK button or the like that is identified as a click area. In this example modeling device may receive information that identifies the known click area when modeling device receives the training user interface.

A click area prediction model may include a model designed to predict a click area of a user interface associated with an automated software installation e.g. when the click area of the user interface is unknown . In some implementations the click area prediction model may include a machine learning model such as a support vector machine. Additionally or alternatively the click area prediction model may include another type of model. In some implementations modeling device may store information associated with the click area prediction model. Additionally or alternatively modeling device may provide information associated with the click area prediction model to another device e.g. user device such that the click area prediction model may be used to predict a click area of an unknown user interface.

In some implementations modeling device may create train and or update the click area prediction model based on features associated with a training user interface as discussed below.

As further shown in process may include determining regions included in the training user interface block . For example modeling device may determine regions included in the training user interface. In some implementations modeling device may determine the regions when modeling device receives the training user interface e.g. after modeling device receives the training user interface .

Regions of a user interface e.g. a training user interface may include two or more portions of a user interface that when combined comprise the entire user interface. For example modeling device may determine the regions of the training user interface by dividing the training user interface into a group of regions e.g. using a grid system . As another example user device may determine the regions of a user interface associated with installing software by dividing the user interface into a group of regions as discussed below with regard to step . In some implementations the regions may be of equal size e.g. each region includes one pixel each region includes one hundred pixels etc. . Alternatively the regions may be of unequal size.

In some implementations the regions may be determined based on elements of the user interface. For example modeling device may detect an area of the user interface that may be indicative of an edge of a rectangle and modeling device may determine the regions based on detecting the edge of the rectangle e.g. such that the edge of the rectangle corresponds to an edge of one or more regions . In some implementations the size shape and or manner in which the regions are to be determined may be based on input provided to modeling device by a user of modeling device .

As further shown in process may include identifying a set of features associated with a region block . For example modeling device may identify a set of features associated with a region. In some implementations modeling device may identify the set of features associated with a region when modeling device determines the regions included in the training user interface e.g. after modeling device determines the regions .

In some implementations modeling device may identify the features associated with the region based on analyzing the region. For example modeling device may analyze the region e.g. using computer vision using an optical character recognition OCR tool etc. and may identify the features based on a result associated with analyzing the region.

Features associated with a region of a user interface e.g. a training user interface a user interface associated with installing software etc. may include characteristics of the region that may be indicative of whether the region is located in a click area. For example the features associated with the region may include color features geometric features image fragment features fill features text features neighbor features and or one or more other types of features.

A color feature may include a feature associated with one or more colors included in a region of a user interface. For example the color feature may include a color name an average color by component e.g. a red component a green component a blue component a color brightness a color luminance a quantity of different colors in the region etc. of one or more colors included in the region. As another example the color feature may include information indicating a difference between the color of the region and a background color of the user interface information indicating a difference between the color of the region and an average color of the user interface etc.

A geometric feature may include a feature associated with a position of the region. For example the geometric feature of a region may include information indicating a position of the region e.g. within the user interface a shape and a size of the region as compared to a shape and a size of the user interface etc. As another example the geometric feature may include information indicating a proximity of the region to a geometric object e.g. a rectangle an edge etc. included in the user interface.

An image fragment feature may include a feature indicating whether the region matches another region associated with a click area known to modeling device . For example modeling device may store information e.g. an image fragment that includes a region that has been identified as being included in a click area and modeling device may determine whether the region matches the image fragment. In this example the image fragment feature may indicate that the region matches the image fragment that has been identified as being included in the click area.

A fill feature may include a feature associated with a distance between lines and or transitions included in the region. For example modeling device may identify the fill feature by analyzing the region from left to right e.g. horizontally to determine a distance between abrupt color changes included in the region e.g. an abrupt color change may be indicative of a line an edge a geometric shape etc. being included in the region .

A text feature may include a feature associated with text included in the region. For example modeling device may analyze the region using an OCR tool to determine whether the region includes text. In some implementations modeling device may analyze the region using the OCR tool may detect text and may determine a text feature based on the text included in the region. For example modeling device may identify a text feature including information indicating that the region includes a particular word e.g. OK Cancel Next Install etc. a particular letter a particular symbol etc.

Neighbor features may include one or more features of regions adjacent to the region. For example the neighbor features of a first region may include color features of a second region color features of a third region etc. e.g. when the second region is located immediately above the first region when the third region is located immediately below the first region etc. . In some implementations the neighbor features may include color features geometric features image fragment features fill features text features and or another feature of one or more neighboring regions.

In some implementations modeling device may identify another type of feature e.g. the listed features are not exhaustive of all possible features .

As further shown in process may include determining a score associated with the region of the training user interface based on the known click area block . For example modeling device may determine a score associated with the region based on the known click area. In some implementations modeling device may determine the score associated with the region after modeling device identifies the set of features associated with the region. Additionally or alternatively modeling device may determine the score after modeling device determines the regions included in the training user interface.

A score associated with a region of a user interface e.g. a training user interface a user interface associated with installing software etc. may include information e.g. a numerical value indicative of whether the region is located in a click area. In some implementations the score may include a numerical value within a range e.g. a range from 0 to 1 a range from 0 to 100 etc. .

In some implementations the score may be determined based on information that identifies a known click area included in the training user interface. For example modeling device may receive the training user interface including the known click area and may determine the regions included in the training user interface. In this example modeling device may determine a score associated with each region of the training user interface based on the known click area e.g. a region at the center of the known click area may be associated with a score of 1.0 a region at the edge of the known click area may be associated with a score of 0.1 a region outside the known click area may be associated with a score of 0.0 etc. . In some implementations user device may determine that a region located at the center of the known click area is to receive a maximum score e.g. 1.0 that a region located at the edge of the known click area is to receive a score between a minimum score and the maximum score e.g. between 0.0 and 1.0 and that a region outside the known click area is to receive the minimum score e.g. 0.0 .

As further shown in process may include determining whether a set of features and a score have been determined for each region of the training user interface block . For example modeling device may determine whether a set of features and a score have been determined for each region of the training user interface.

In some implementations modeling device may determine whether a set of features and a score have been determined for each region based on tracking information associated with modeling device . For example modeling device may determine the regions included in the training user interface and modeling device may maintain tracking information that identifies regions for which modeling device has determined a set of features and a score and modeling device may determine whether a set of features and a score have been determined for each region based on the tracking information stored by modeling device .

As further shown in if a set of features and a score have not been determined for each region of the training user interface block NO then process may return to block . For example modeling device may determine that a set of features and a score have not been determined for each region and modeling device may proceed with determining a set of features and a score for another region.

As further shown in if a set of features and a score have been determined for each region of the training user interface block YES then process may include updating the click area prediction model based on the set of features and the score associated with each region block . For example modeling device may determine a set of features and a score for each region of the training user interface and modeling device may update the click area prediction model based on the set of features and the score for each region of the training user interface.

In some implementations modeling device may update the click area prediction model based on information associated with the regions of the training user interface. For example modeling device may determine a first set of features associated with a first region of the training user interface that corresponds to a first score e.g. 1.0 and may determine a second set of features associated with a second region that corresponds to a second score e.g. 0.0 . In this example modeling device may update the click area prediction model based on the first set of features e.g. such that the click area prediction model is more likely to identify a click area when another region associated with an unknown user interface includes a region that includes a set of features similar to the first set of features . Similarly modeling device may update the click area prediction model based on the second set of features e.g. such that the click area prediction model is less likely to identify a click area when another region associated with an unknown user interface includes a region that includes a set of features similar to the second set of features .

Additionally or alternatively modeling device may update the click area prediction model based on information provided by user device . For example user device may successfully install software using the click area prediction model and may provide to modeling device information associated with the successful software installation e.g. sets of features associated with regions of a user interface scores determined by the click area prediction model associated with the regions of the user interface etc. and modeling device may update the click area prediction model based on the information associated with the successful software installation provided by user device .

In this way modeling device may receive a training user interface including a known click area may determine regions associated with the training user interface and may determine a set of features and a score associated with each region of the training user interface. Modeling device may modify update train etc. a click area prediction model e.g. a model designed to predict a click area of an unknown user interface based on the sets of features and the scores associated with each region of the training user interface. Modeling device may receive any number of training user interfaces in order to improve performance and or accuracy of the click area prediction model.

Although shows example blocks of process in some implementations process may include additional blocks different blocks fewer blocks or differently arranged blocks than those depicted in . Additionally or alternatively one or more of the blocks of process may be performed in parallel.

As shown in MD1 may receive the training dialog box and the information that identifies the known click area e.g. an area corresponding to a Next button included in the training dialog box . As further shown MD1 may determine regions included in the training dialog box by dividing the training dialog box into regions using a grid system e.g. including rows A through I and including columns through .

As shown in MD1 may identify a set of features associated with a first region A1. As shown the set of features associated with the A1 region may include color features e.g. Color Light Green 90 Black 10 geometric features e.g. Location Upper Left text features e.g. Text Yes Black fill features e.g. Abrupt Color Change No neighbor features e.g. Neighbor A2 Light Green Black B1 Abrupt Color Change and other features associated with the A1 region not shown . As further shown MD1 may also determine a score e.g. Score 0.0 associated with the A1 region e.g. assume that MD1 is configured to determine a score of zero for any region not included in the known click area .

As further shown MD1 may continue to determine a set of features and a score for each region of the training dialog box including a set of features associated with region H4. As shown the set of features associated with the H4 region may include color features e.g. Color Grey 45 Blue 10 Silver 45 geometric features e.g. Location Lower Left text features e.g. Text No fill features e.g. Abrupt Color Change Yes Edge of Rectangle and neighbor features e.g. Neighbor H5 Silver 100 and other features associated with the H4 region not shown . As further shown MD1 may also determine a score e.g. Score 0.2 associated with the H4 region e.g. assume that MD1 is configured to determine a score of 0.2 for any region on the edge the known click area .

As further shown MD1 may continue to determine a set of features and a score for each region of the training dialog box including a set of features associated with region H7. As shown the set of features associated with the H7 region may include color features e.g. Color Silver 50 Black 50 geometric features e.g. Location Lower Left Center text features e.g. Text Yes Black fill features e.g. Abrupt Color Change No Center of Rectangle and neighbor features e.g. Neighbor H8 Silver 50 Black 50 G7 Grey 80 Blue 20 Edge of Rectangle and other features associated with the H7 region not shown . As further shown MD1 may also determine a score e.g. Score 1.0 associated with the H7 region e.g. assume that MD1 is configured to determine a score of 1.0 for any region in the middle of the known click area .

As further shown in MD1 may provide information associated with the sets of features and the corresponding scores to the click area prediction model e.g. stored by MD1 . The click area prediction model may be modified trained and or updated based on the information associated with the sets of features and the corresponding scores.

As indicated above are provided merely as an example. Other examples are possible and may differ from what was described with regard to .

As shown in process may include receiving an instruction to automatically install software based on a click area prediction model block . For example user device may receive an instruction to automatically install software based on a click area prediction model.

In some implementations user device may receive the instruction to automatically install the software based on a configuration of user device . For example user device may be configured to automatically install software using a click area prediction model each time user device receives information indicating that user device is to install software. Additionally or alternatively a user of user device may provide input instructing user device to automatically install the software based on the click area prediction model e.g. when the user initiates a software installation and then initiates an automated software installer that implements the click area prediction model . In some implementations user device may initiate a software installation procedure associated with installing the software when user device receives the instruction e.g. such that a first user interface associated with the software installation is displayed by user device .

As further shown in process may include identifying a user interface associated with installing the software based on a screenshot image block . For example user device may identify a user interface associated with installing the software based on a screenshot image. In some implementations user device may identify the user interface when user device receives the instruction to automatically install the software e.g. after user device receives the instruction and initiates the software installation procedure .

In some implementations user device may identify the user interface based on a screenshot image associated with user device . For example user device may capture a screenshot image reflecting information that is currently being displayed by a display screen of user device . In this example user device may capture the screenshot image after initiating the software installation procedure e.g. after a first dialog box associated with installing the software has appeared and may compare the screenshot image to a base screenshot image stored by user device that includes a standard background e.g. a screenshot image captured while no user interfaces were being displayed by user device . User device may then identify the user interface based on comparing the screenshot image and the base screenshot image.

In some implementations user device may identify the user interface using another method. For example a graphics subsystem e.g. associated with an operating system of user device may be configured to capture the user interfaces e.g. an image of the user interface when the user interface is displayed by user device .

As further shown in process may include determining regions included in the user interface block . For example user device may determine regions included in the user interface identified by user device . In some implementations user device may determine the regions when user device identifies the user interface e.g. after user device identifies the user interface associated with installing the software .

In some implementations user device may determine regions included in the user interface in a manner to similar to that described above with regard to block . For example user device may determine the regions of the user interface based on a grid system based on elements included in the user interface or in another manner.

As further shown in process may include identifying a set of features associated with a region included in the user interface block . For example user device may identify a set of features associated with a region included in the user interface. In some implementations user device may determine the set of features associated with the region after user device determines the regions included in the user interface. Additionally or alternatively user device may identify a set of features associated with a region after user device identifies another set of features associated with another region and computes a score associated with the other region as discussed below with regard to block .

In some implementations user device may identify the features associated with the region based on analyzing the region in a manner similar to that described above with regard to block . In some implementations the features associated with the region of the user interface may include characteristics of the region that may be indicative of whether the region is located in a click area such as color features geometric features image fragment features fill features text features neighbor features and or one or more other types of features.

As further shown in process may include determining a score associated with the region based on the set of features and the click area prediction model block . For example user device may determine a score associated with the region based on the set of features and the click area prediction model. In some implementations user device may determine the score when user device identifies the set of features associated with the region e.g. after user device identifies the set of features .

A score associated with a region of a user interface may include information indicative of whether the region is located in a click area as discussed above with regard to block . In some implementations user device may determine the score associated with the user interface based on inputting the set of features into the click area prediction model. For example user device may identify the set of features associated with the region may provide information associated with the set of features as input to the click area prediction model e.g. via modeling device and the click area prediction model may provide as output a score associated with the region determined based on the set of features associated with the region.

As further shown in process may include determining whether a score has been determined for each of the regions block . For example user device may determine whether a score has been determined for each region of the user interface associated with installing the software.

In some implementations user device may determine whether a score has been determined for each region based on tracking information associated with user device . For example user device may determine the regions included in the user interface associated with installing the software and user device may maintain tracking information that identifies regions for which user device has determined a score and user device may determine whether a score has been determined for each region based on the tracking information stored by user device .

As further shown in if a score has not been determined for each of the regions block NO then process may return to block . For example user device may determine that a score has not been determined for each region of the user interface associated with installing the software and user device may proceed with identifying a set of features e.g. and subsequently determining a score for another region included in the user interface.

As further shown in if a score has been determined for each region of the user interface associated with installing the software block YES then process may include identifying a predicted click area based on the scores associated with the regions block . For example user device may determine that a score has been determined for each region of the user interface and user device may identify a predicted click area based on the scores associated with the regions.

A predicted click area may include an area corresponding to one or more regions included in a user interface associated with installing software that a click area prediction model identifies as area of a user interface that when selected causes the a software installation procedure to proceed. In some implementations user device may identify the predicted click area based on the scores associated with the regions of the user interface. For example user device may identify a region associated with the highest score determined by user device e.g. when the region receives a score of 1.0 and user device may identify the predicted click area as the area corresponding to the region. In some implementations the predicted click area may include an area of the user interface that corresponds to a single region. Alternatively the predicted click area may include an area of the user interface that corresponds to a group of regions e.g. a group of adjacent regions .

In some implementations user device may identify a group of predicted click regions based on the scores. For example user device may identify a first predicted click area e.g. an area of the user interface that corresponds to a region with a score of 1.0 may identify a second predicted click area e.g. an area of the user interface that corresponds to a region with a score of 0.9 etc. In this example user device may store information associated with the group of predicted click areas such that user device may select the group of predicted click areas based on their respective scores.

Additionally or alternatively user device may identify the predicted click area based on one or more heuristic techniques. For example user device may apply a heuristic technique associated with matching the user interface e.g. dialog box to a known user interface matching a series of user interfaces to a known series of user interfaces detecting and selecting a particular element e.g. a check box a radio button etc. included in the user interface etc.

In some implementations user device may identify the predicted click area and user device may select e.g. by automatically clicking the predicted click area to attempt to advance the software installation procedure. For example user device may identify the predicted click area and may select the predicted click area. In this example user device may wait for a period of time e.g. 2 seconds 5 seconds etc. after selecting the predicted click area and may capture an additional screenshot image. User device may then determine whether the software installation procedure has advanced based on the additional screenshot image. For example if the additional screenshot image includes the user interface e.g. when selecting the predicted click area did not result in any change to the user interface then user device may identify and select another predicted click area e.g. an area corresponding to a region with the second highest score and may select the other predicted click area. In this way user device may select one or more predicted click areas associated with the user interface in an attempt to advance the software installation procedure.

In some implementations user device may select the predicted click area may wait for a period of time and may capture an additional screenshot image that includes a different user interface. User device may then return to block and determine regions included in the user interface and may proceed as described above. In this way user device may continue to identify and select predicted click areas for a series of user interfaces associated with the software installation procedure e.g. until the software installation is completed .

In some implementations user device may store information associated with one or more user interfaces associated with the software installation procedure. For example user device may select a predicted click area included in a first user interface may store information that identifies the location of the predicted click area of the first user interface may select a predicted click area included in a subsequent second user interface may store information that identifies the location of the predicted click area of the second user interface etc. In this example if user device determines that the software installation procedure has returned to the first user interface user device may select a different predicted click area e.g. based on the information stored by user device such that user device does not select the same sequence of predicted click areas in the series of user interfaces. In other words user device may store information that allows user device to traverse multiple pathways through the software installation procedure.

Although shows example blocks of process in some implementations process may include additional blocks different blocks fewer blocks or differently arranged blocks than those depicted in . Additionally or alternatively one or more of the blocks of process may be performed in parallel.

Assume that UD1 receives the instruction to automatically install the Media Player software and initiates a software installation procedure associated with installing the Media Play software e.g. by displaying a first dialog box . As shown in UD1 may identify the dialog box by capturing a screenshot image and comparing the screenshot image to a base screenshot image e.g. a screenshot image stored by UD1 that does not include any user interfaces . As shown in UD1 may determine regions included in the dialog box by dividing the dialog box into regions using a grid system e.g. including rows A through Q and columns through .

As shown in UD1 may then identify a set of features associated with a first region included in the user interface A1. As shown the set of features associated with the A1 region may include color features e.g. Color Light Green 80 Black 20 geometric features e.g. Location Upper Left text features e.g. Text Yes Black fill features e.g. Abrupt Color Change No and neighbor features e.g. Neighbor A2 Light Green Black B1 Abrupt Color Change and other features associated with the A1 region not shown . As further shown UD1 may determine a score associated with the A1 region by providing information associated with the set of features as input to a click area prediction model e.g. via MD1 . As shown the click area prediction may receive the information associated with the set of features and may output a score e.g. 0.00 for the A1 region.

As further shown UD1 may continue to determine a set of features and a score for each region of the dialog box including a set of features associated with region P8. As shown the set of features associated with the P8 region may include color features e.g. Color Silver 80 Black 20 geometric features e.g. Location Lower Left Center text features e.g. Text Yes Black fill features e.g. Abrupt Color Change No and neighbor features e.g. Neighbor 08 Grey 80 Blue 20 Edge of Rectangle Q8 Silver 20 Blue 20 Grey 60 Edge of Rectangle Edge of Dialog Box and other features associated with the P8 region not shown . As further shown UD1 may determine a score associated with the P8 region by providing information associated with the set of features as input to the click area prediction model. As shown the click area prediction may receive the information associated with the set of features and may output a score e.g. 0.99 for the P8 region.

As further shown UD1 may continue to determine a set of features and a score for each region of the dialog box including a set of features associated with region Q10. As shown the set of features associated with the Q10 region may include color features e.g. Color Silver 20 Blue 20 Grey 60 geometric features e.g. Location Lower Center text features e.g. Text No fill features e.g. Abrupt Color Change Yes Edge of Rectangle and neighbor features e.g. Neighbor P10 Silver 100 and other features associated with the Q10 region not shown . As further shown UD1 may determine a score associated with the Q10 region by providing information associated with the set of features as input to the click area prediction model. As shown the click area prediction may receive the information associated with the set of features and may output a score e.g. 0.15 for the Q10 region.

As shown in after UD1 has determined a score for each region included in the dialog box UD1 may identify a predicted click area associated with the dialog box. For the purposes of example implementation assume that UD1 is configured to identify the region with the highest score as a predicted click area. As shown assume that the P8 region has the highest score e.g. 0.99 as determined by the click area prediction model. As shown UD1 may then select e.g. by automatically clicking the predicted click area.

As shown in another dialog box may be displayed based on UD1 selecting the first predicted click area included in the dialog box. As shown UD1 may wait five seconds after selecting the predicted click area may capture a screenshot image including the other dialog box may determine that the other dialog box is different than the dialog box e.g. that the software installation procedure has advanced and may repeat one or more of the operations described above to proceed with installing the software.

As indicated above are provided merely as an example. Other examples are possible and may differ from what was described with regard to .

Implementations described herein may allow a device to automatically e.g. without user intervention install software by training a click area prediction model to detect and intelligently select click areas of user interfaces associated with installing the software. In this way software may be automatically installed despite the use of non standard user interfaces in the software installation procedure.

The foregoing disclosure provides illustration and description but is not intended to be exhaustive or to limit the implementations to the precise form disclosed. Modifications and variations are possible in light of the above disclosure or may be acquired from practice of the implementations.

As used herein the term component is intended to be broadly construed as hardware firmware or a combination of hardware and software.

Certain user interfaces have been described herein. In some implementations the user interfaces may be customizable by a device or a user. Additionally or alternatively the user interfaces may be pre configured to a standard configuration a specific configuration based on a type of device on which the user interfaces are displayed or a set of configurations based on capabilities and or specifications associated with a device on which the user interfaces are displayed.

It will be apparent that systems and or methods as described herein may be implemented in many different forms of software firmware and hardware in the implementations shown in the figures. The actual software code or specialized control hardware used to implement these systems and or methods is not limiting of the implementations. Thus the operation and behavior of the systems and or methods were described without reference to the specific software code it being understood that software and control hardware can be designed to implement the systems and or methods based on the description herein.

Even though particular combinations of features are recited in the claims and or disclosed in the specification these combinations are not intended to limit the disclosure of possible implementations. In fact many of these features may be combined in ways not specifically recited in the claims and or disclosed in the specification. Although each dependent claim listed below may directly depend on only one claim the disclosure of possible implementations includes each dependent claim in combination with every other claim in the claim set.

No element act or instruction used herein should be construed as critical or essential unless explicitly described as such. Also as used herein the articles a and an are intended to include one or more items and may be used interchangeably with one or more. Furthermore as used herein the term set is intended to include one or more items and may be used interchangeably with one or more. Where only one item is intended the term one or similar language is used. Also as used herein the terms has have having or the like are intended to be open ended terms. Further the phrase based on is intended to mean based at least in part on unless explicitly stated otherwise.

