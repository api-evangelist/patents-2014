---

title: Custom web services data link layer
abstract: A data interface efficiently transports, manages, and provides data transfer. The data transfer may happen between a data storage layer and a presentation layer, as examples. The presentation layers may be graphical user interfaces that display or report complex data sets, with the data storage layer providing the source data for the presentation layers. The data interface implements a data link layer that efficiently caches, stores, and locates query results, while simultaneously handling security. The data link layer may include load balancing, efficient cache refresh, and other features.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09378252&OS=09378252&RS=09378252
owner: Accenture Global Services Limited
number: 09378252
owner_city: 
owner_country: IE
publication_date: 20140102
---
This application is a continuation application of U.S. patent application Ser. No. 13 016 795 which claims the priority benefit of European Patent Office application serial number 10425351.3 filed Nov. 12 2010 titled Custom Web Services Data Link Layer the entirety of which are herein incorporated by reference.

This disclosure relates to providing data to presentation layers from a data storage layer. In particular this disclosure relates to a data link layer that efficiently handles dataflow between a data storage layer and potentially many data presentation layers.

Data analysis systems continue to evolve in terms of their capability and complexity. For example U.S. Patent Pub. No. 2009 0307054 which is incorporated herein by reference in its entirety describes a consumer and shopper analysis system that collects normalizes processes and presents complex data and data analysis results as part of a sophisticated analysis system for analyzing customer behavior. The analysis system adeptly manages significant information flow from both internal and external sources that drives the analyses. In doing so the analysis system manages data obtained from multiple different systems integrates the data to provide a single data source of high integrity and delivers precise information in a timely and accessible manner to business executives at all levels of the enterprise. The analysis system executes sophisticated analyses of the data to provide valuable insights into company performance to allow the company executives to make effective decisions.

In the analysis system described in the patent application noted above a presentation layer displays the analyses results. The data that drives the analyses results resides in a data storage layer. Because of the immense amount of data that may reside in the data storage layer and because many instances of the presentation layer may be making simultaneous access demands to the data storage layer for significant amounts of data a need exists to efficiently transport manage and provide the data between the data storage layer and the presentation layer and to handle the simultaneous access demands. Significant technical challenges reside in providing the required data from the data storage layer to the presentation layer in a time processing and storage efficient manner.

A data link layer interfaces a data storage layer to potentially many presentation layers. The data link layer may be implemented in a machine in which a presentation layer interface is operative to receive a data query for a primary data store from a requesting presentation layer. In the machine the presentation layer interface may be part of the data link layer.

The data link layer includes a query handler operable to identify a query filter parameter for the data query identify a security specifier for the data query and identify a query statement for the data query. The query handler also forms a search key comprising the query filter specifier the security specifier and the query statement.

A data cache in communication with the data link layer stores cached query results obtained from the primary data store. In one implementation a cached query result includes a query result key and a query result data entity linked to the query result key. In the data link layer a search handler searches the data cache to match the search key to the query result key. The search handler thereby determines that the query result data entity already exists for the data query in the data cache. The search handler may then return the query result data entity to the requesting presentation layer through the presentation layer interface.

Other systems methods features and advantages will be or will become apparent to one with skill in the art upon examination of the following figures and detailed description. It is intended that all such additional systems methods features and advantages be included within this description be within the scope of the invention and be protected by the following claims.

The data storage layer includes a primary data store . The primary data store may be a database a flat file or any other mechanism or data structure that stores data whether in semiconductor memory on hard disk or in other types of memory. In one implementation a data model organizes the data in the primary data store according to any desired set of tables relationships keys or other characteristics. A database management system may implement either or both of the primary data store and data model for example.

With respect to customer value management for instance the data model may store and organize data for analyzing any aspect of customer behavior as described in U.S. Patent Pub. No. 2009 0307054. Specifically the data model may segment the data into modules or other units tables sets of tables or segments such as a Market Insight module a Customer module a Sales module a Promotion module a Sales Force module a Supply Chain module and a Logistics module. However the primary data store may store any information for any purpose according to any desired organizational structure.

The data link layers cache data obtained from the primary data store for faster more efficient access by the presentation layers . While there are many different possible implementations of the architecture in one implementation the data link layers include a master data link layer and non master data link layers . Exemplary distinctions in processing are noted below. The data link layers access a data cache in an effort to obtain data responsive to data queries for the primary data store received from requesting presentation layers. The data link layers may receive such data queries through a presentation layer interface and may return query result data entities to the requesting presentation layers. The presentation layer interface may be as examples a message passing interface e.g. a web services interface a remote procedure call interface a shared memory interface or other interface.

The data cache may be implemented with a database a flat file or any other mechanism or data structure that stores data. The data cache may be stored in semiconductor memory on hard disk or in other types of memory. A database management system may implement the data cache .

The data cache may store data from the primary data store in any desired manner. As one example the data cache stores one or more query result keys e.g. the query result key QRK paired or associated with query result data entities e.g. the query result data entity QRDE . The query result key may or may not uniquely identify a query result data entity. The query result key may be formed from one or more pieces of information aggregated together e.g. concatenated . The pieces of information may include in one implementation one or more query filter parameters from a data query a security specifier and a query statement from the data query. When a new data query arrives the data link layer that processes the data query may form a search key in the same way as the query result key then search for matches for the search key against the query result keys in the data cache .

The query filter parameters may be values for variables specified in pre defined queries. For example a pre defined query may include department and salary filter fields and the data query may specify values of those variables effectively filtering the results to those values . The security specifier may be a list of groups for the entity associated with e.g. causing the data query e.g. Supervisors and Engineering . In other words the security specifier may be a group membership list for the requesting entity causing the data query. The query statement may be the text of the search statement in the data query or the text of a pre defined data query specified in the data query as examples.

Accordingly the query result key captures both the filter parameters the specific search and the security information for the entity performing the search. Therefore the data link layers as a natural part of trying to locate query result data entities cooperate with the data cache to enforce security in addition to finding and returning the requested results. Efficient secured control over the data in the primary data store results as part of the natural operation of the data cache .

The query result data entity may be any form type or structure of data. For example the query result data entity may be a string numeric or other data type. In one implementation the query result data entity is a binary large object BLOB that includes any one or more types of data as a single data chunk. The query result data entity may be the entire result of a query performed against the primary data store and optionally compressed and then stored in the data cache for later retrieval and delivery to the presentation layers without having to re execute the data query against the primary data store .

In some implementations the data storage layer may communicate cache refresh instructions to the data link layers e.g. to the master data link layer including a full or partial query result key or other cache entry identifier to match against one or more entries in the data cache . The data storage layer may also provide current data to the data link layers . In response for example the master data link layer may update any of the query result data entities with current data from the primary data store . One technical benefit is that the cached results of queries are kept up to date in the data cache without the need to re execute the associated search in the primary data store every time that query result data changes in the primary data store . In particular the data storage layer may keep the results of regular expected frequent or any other specified queries consistently up to date in the data cache .

The presentation layers obtain data from the data link layers or the data storage layer . The presentation layers process the data and generate user interfaces of any type and content desired. For example the presentation layers may graphically illustrate any aspect of customer value management as described in U.S. Patent Pub. No. 2009 0307054.

As noted above the data cache stores cached query results obtained from the primary data store . Each cached query result may include a query result key and a query result data entity linked or associated with the query result key . The data cache may be a database flat file or other mechanism for storing data. There may be a single data cache in the architecture which all of the data link layers search for existing query result data entities or there may be multiple instances of the data cache .

The search handler includes logic operative to search the data cache . For example the search handler may match the search key against the query result keys to determine that the query result data entity already exists for the data query. If the query result data entity already exists the search handler may return the query result data entity to the requesting presentation layer through the presentation layer interface . In one implementation the data link layer instance that has searched the data cache also retrieves the query result data entity . In other implementations the search handler searches the data cache and if a matching query result key is found the search handler requests the query result data entity from a master data link layer receives the query result data entity from the master data link layer and then returns the query result data entity to the requesting presentation layer. In other words the master data link layer may be responsible for retrieving query result data entities from the data cache for the various instances of the data link layers.

In some cases a data query may be a bundled data query that includes multiple individual data queries aggregated together e.g. as a batch of queries from a given presentation layer instance . As one example the bundle may be formed on the presentation layer side by a bundling process that waits for a certain time after for additional data queries after receiving a data query from the presentation layer. The bundling process may then pass the multiple individual data queries to the data link layer .

The load balancer may distribute any received data query or any of the individual data queries from a bundled data query to any of the data link layer instances including the master data link layer . Thus in one implementation the presentation layer instances send their data queries to the load balancer which distributes them to data link layer instances according to any desired load balancing technique e.g. round robin . In other implementations there is no load balancer in the master data link layer but presentation layers communicate data requests through a separate load balancer e.g. a hardware load balancer which in turn distributes the data queries to the various data link layer instances according to the selected load balancing technique.

The cache handler facilitates updates to the data in the data cache . In particular the cache handler may include logic operative to receive a cache refresh instruction and responsively update one or more query result data entities with current data from the primary data store . To that end the cache handler may search the data cache for entries matching the entries specified in the cache refresh instruction e.g. by search key or partial key and replace the data in the data cache with current data received from the data layer .

The security information may be provided by a single sign on handler for example or by another source of security information. More specifically the data link layer may leverage the integration of the presentation layer with the data layer to obtain e.g. username and group information. For example a Microsoft Internet Information Service Server may generate a session identifier a form of security token when a web user is authenticated e.g. via username password . A database server e.g. Microsoft SQL server that handles the data cache or primary data store may employ the security token to authorize access to the data cache and data store without requiring the requesting entity to provide repeatedly a username and password.

Logic in the data link layers may obtain the current username using in a vendor specific mechanism e.g. an Application Programming Interface API call . The logic may then fetch the groups for the user from a database using a specific query by calling an API function or in another manner. Each particular implementation depending on the vendor products selected or custom built solutions may provide a different method of single sign on or other security mechanism across one or more parts of the architecture including the data link layers data storage layers and presentation layers . Because the security information forms part of the query result key the data cache implements a security layer independent cache with built in security checking regardless of the type or construction of security information the architecture provides.

Some data queries may specify a pre defined query e.g. by number or other identifier established in the query library . In support of such data queries the query library includes any number of pre defined queries which may include any number of filter parameters that the data query may specify. In other words a data query may specify a pre defined query and the parameters for the query. However the data queries may instead fully specify a particular search to perform without reference to any particular pre defined query in the query library . Regardless functional block determines the query requirements e.g. the required filter parameters and obtains the query requirements e.g. by obtaining filter parameters or the specified query from the data query .

Functional block prepares the query and executes a search of the data cache . In one implementation the functional block creates a search key for matching against the query result keys in the data cache . As discussed above the search key may by a combination of the query filter parameters the security specifier and the query statement for the data query formed in the same manner as the query result keys.

If a matching query result key is present in the data cache then functional block obtains the corresponding query result data entity. In one implementation the functional block requests that a master data link layer obtain the corresponding query result data entity. The master data link layer retrieves the corresponding query result data entity and returns the corresponding query result data entity to the requesting data link layer. However any data link layer may itself retrieve in other implementations the corresponding query result data entity from the data cache . The data link layer returns the search result set e.g. the query result data entity to the requesting presentation layer.

When a matching query result key cannot be located in the data cache functional block executes the specified data query by communicating the data query to the data layer . Functional block adds the search result to the data cache . In that regard the search result optionally compressed may form a new query result data entity that is stored in the data cache . The associated query result key may be set as the search key formed in functional block e.g. as the combination of query filter parameters security specifier and query statement used to build the search key .

The query result data entities stored in the data cache may be a partial or a complete result set from the primary data store for the data query. In some instances the result sets may include significant amounts of data. Nevertheless the data cache may hold the complete result sets as individual query result data entities and may provide the complete result sets to the requesting presentation layer so that the data layer need not repeatedly perform the search retrieve the significant amounts of data and pass the large result set back to the presentation layer. Accordingly the data cache makes even large result sets quickly and efficiently available to requesting presentation layers.

Functional block receives cache refresh instructions and responsively updates the query result data entities with current data from the primary data store. Accordingly the architecture keeps the query result data entities current with respect to data changes in the primary data store . This proactive approach to keeping data current in the data cache helps to avoid inefficient submission of regular frequent or selected data queries back to the data layer .

The functionality discussed with respect to may be implemented in hardware software or other logic. The functionality may be organized as desired between or across logical modules programs or processors as desired. For example the query handler may be responsible for receiving the data queries retrieving the security information and retrieving the query requirements .

In memory in the machine may be a database management system DBMS . The DBMS may implement and manage read write access to the primary data store and the data cache as examples. In addition any number of non master data link layer instances may be running in the memory . As described above with reference to the non master data link layer instances may include search handler logic and query handler logic . Furthermore a master data link layer instance may be running in the memory . As noted above with respect to the master data link layer instance may include search handler logic query handler logic cache handler logic data request handler logic and load balancer logic .

Any number of presentation layer instances may be present in the memory . The presentation layer instances generate data queries for the data link layer instances to handle. Furthermore the DBMS or other cache updating logic may generate a cache refresh instruction with current data . The master data link layer instance responds to the cache refresh instruction by updating the corresponding data in the data cache as explained above.

The logic in the specific data link layer identifies a query filter parameter a security specifier and a query statement for the data query. The logic then forms a search key from the query filter parameter security specifier and query statement . The logic performs a search of the data cache for example by attempting to match the search key to the query result keys in the data cache .

When the data cache does not hold a matching query result data entity then the logic issues the data query to the data storage layer . A master or non master data link layer instance may submit the data query to the data storage layer . The data storage layer provides a result set which the logic may compress for storage in the data cache . Furthermore the logic forms a query result key and stores the compressed result set as a query result data entity along with the result key in the data cache . When the data cache holds a matching query result data entity then the logic requests the matching query result data entity e.g. from the master data link layer instance .

In either case the logic retrieves the query result data entity from the data cache . The query result data entity is returned to the requesting data link layer instance . In response the requesting data link layer instance returns the query result data entity either compressed or uncompressed as desired or requested by e.g. the presentation layer to the presentation layer instance that made the data query .

In the description above various implementations of the data link layer were described. For example a machine may include a presentation layer interface operative to receive a data query for a primary data store from a requesting presentation layer and a data link layer in communication with the presentation layer interface. The data link layer may include a query handler operable to identify a query filter parameter for the data query identify a security specifier for the data query identify a query statement for the data query and form a search key comprising the query filter specifier the security specifier and the query statement.

In addition the machine may include a data cache comprising cached query results obtained from the primary data store. Each cached query result may include a query result key and a query result data entity linked to the query result key. The machine may further include a search handler operative to search the data cache to match the search key to the query result key to determine that the query result data entity already exists for the data query in the data cache and return the query result data entity to the requesting presentation layer through the presentation layer interface.

The security specifier may comprise a group membership list for a requesting entity causing the data query. The query result data entity may comprise a complete result set from the primary data store for the data query. The complete result set may comprise a compressed complete result set.

In the machine the search handler may be further operative to request the query result data entity from a master data link layer instance and receive the query result data entity from the master data link layer instance. Also the data query may comprise a bundled data query comprising multiple individual data queries and the machine may further include a load balancer operative to distribute the multiple individual data queries to individual instances of the data link layer.

The machine may further comprise a cache handler in communication with the data cache the cache handler operative to receive a cache refresh instruction and responsively update the query result data with current data from the primary data store. The data cache may be a database a flat file or both a database and a flat file.

In terms of the processing performed to accomplish the technical solutions described above the processing may include receiving a data query against a primary data store from a requesting presentation layer through a presentation layer interface and forming a search key comprising a query filter parameter for the data query a security specifier for the data query and a query statement for the data query. The processing may further include caching query results in a data cache each query result comprising a query result key and a query result data entity linked to the query result key. Also the processing may include matching the search key to the query result key to determine that the query result data entity already exists for the data query in the data cache and returning the query result data entity to the requesting presentation layer through the presentation layer interface.

In other implementations the data link layer functionality may be provided in a product comprising a machine readable medium and logic stored on the machine readable medium. The logic when executed by a processor causes the processor to receive a data query against a primary data store from a requesting presentation layer through a presentation layer interface form a search key comprising a query filter parameter for the data query a security specifier for the data query and a query statement for the data query. The logic also causes the processor to cache query results in a data cache each query result comprising a query result key and a query result data entity linked to the query result key. The logic also causes the processor to match the search key to the query result key to determine that the query result data entity already exists for the data query in the data cache and to return the query result data entity to the requesting presentation layer through the presentation layer interface.

In general the logic handlers e.g. the search handler query handler cache handler and data request handler load balancer and processing described above may be encoded or stored in a machine readable or computer readable medium such as a compact disc read only memory CDROM magnetic or optical disk flash memory random access memory RAM or read only memory ROM erasable programmable read only memory EPROM or other machine readable medium as for examples instructions for execution by a processor controller or other processing device. The medium may be implemented as any device or tangible component that contains stores communicates propagates or transports executable instructions for use by or in connection with an instruction executable system apparatus or device. Alternatively or additionally the logic may be implemented as analog or digital logic using hardware such as one or more integrated circuits or one or more processors executing instructions that perform the processing described above or in software in an application programming interface API or in a Dynamic Link Library DLL functions available in a shared memory or defined as local or remote procedure calls or as a combination of hardware and software. The logic may be functionally partitioned to meet to goals of any specific implementation.

The systems may include additional or different logic and may be implemented in many different ways. A processor may be implemented as a controller microprocessor digital signal processor microcontroller application specific integrated circuit ASIC discrete logic or a combination of other types of circuits or logic. Similarly memories may be Dynamic Random Access Memory DRAM Static Random Access Memory SRAM Flash or other types of memory. Parameters e.g. conditions and thresholds and other data structures may be separately stored and managed may be incorporated into a single memory or database or may be logically and physically organized in many different ways. Programs and instructions may be parts of a single program separate programs implemented in libraries such as Dynamic Link Libraries DLLs or distributed across several memories processors cards and systems.

While various embodiments of the invention have been described it will be apparent to those of ordinary skill in the art that many more embodiments and implementations are possible within the scope of the invention. Accordingly the invention is not to be restricted except in light of the attached claims and their equivalents.

