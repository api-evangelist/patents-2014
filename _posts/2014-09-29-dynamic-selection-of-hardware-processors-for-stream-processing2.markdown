---

title: Dynamic selection of hardware processors for stream processing
abstract: A computing platform supports stream processing pipelines, each of which comprises a sequence of stream processing tools. Upon specification of a stream processing pipeline, multiple available hardware processors are evaluated to determine which of the processor is capable of executing each tool of the pipeline while satisfying specified performance goals. Among these processors, a hardware processor is selected for each pipeline tool that will minimize power consumption.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09569221&OS=09569221&RS=09569221
owner: Amazon Technologies, Inc.
number: 09569221
owner_city: Seattle
owner_country: US
publication_date: 20140929
---
The use of complex software algorithms to improve the experiences of device users places increasing demands on the computing capabilities of such devices. Complex algorithms may be used for computer vision three dimensional displays programmable cameras high definition video and audio and so forth. Main CPUs even in multiple core configurations are hard pressed to meet the demands of these algorithms because of thermal and power limitations.

One increasingly popular response to this problem is to provide distributed auxiliary computing resources that can provide special purpose capabilities that demonstrate higher performance and lower power consumption. Such auxiliary resources may include graphics processing units GPUs digital signal processors DSPs single instruction multiple data SIMD extensions and other helper cores such as special purpose accelerators.

Mobile battery operated devices are increasingly called upon to perform highly complex and computationally intensive tasks relating to image graphics and audio processing. Tasks such as these typically involve processing continuous and or intermittent streams of data such as audio video and other related data.

In addition to increasingly faster processor clock speeds the use of which has reached a point of diminishing returns many system on chip SoC architectures utilize different types of hardware processors addition to a main central processing unit CPU . For example SoCs may utilize multiple general purpose central processing units CPUs CPU cores core extensions such as single instruction multiple data SIMD extensions graphic processing units GPUs and digital signal processors DSPs as well as other on chip or off chip vector and stream processors. Systems and system architectures such as these which use a variety of different types of hardware processors may be referred to as heterogeneous parallel computing systems.

In certain embodiments described herein an SoC has multiple hardware processors and associated low level software drivers or kernels that support the hardware processors. The SoC may also have one or more libraries of low level software functions that may be called upon to perform specialized functions relating to graphics processing graphic and video rendering audio processing and so forth.

At a yet higher level of abstraction the SoC may provide stream processing tools for performing high level algorithms with respect to data streams. In a vision processing environment for example stream processing tools may be provided for such things as color conversion blurring corner detection image segmentation edge detection object detection recognition and tracking stereoscopic image analysis three dimensional shape analysis and so forth.

In order to perform complex tasks that require sequences of analytical and processing operations stream processing tools may be logically arranged in sequences referred to as processing pipelines or tool chains. A processing pipeline accepts a data stream such as a video stream analyzes the data stream using a sequence of individual tools and returns a result. More specifically the first tool of the pipeline may receive an input image of a video stream and may process the input image to produce an output image. The output image is provided as an input image to a subsequent tool in the pipeline. Images or other data are passed in this manner through multiple processing tools to produce a desired pipeline output data stream.

The SoC may provide libraries of stream processing tools for use by applications. The SoC may also provide software interfaces that applications can use to specify and create pipelines. The created pipelines may use the stream processing tools of the SoC libraries or may use stream processing tools provided by the application.

The SoC may also provide a library of preconfigured pipelines which use the provided stream processing tools to implement various types of tasks. The application may provide software interfaces that applications can use to set up and initiate preconfigured pipelines and or pipelines constructed by the application itself.

An application that is to be executed by the SoC may be written and provided in high level or intermediate level programming languages without hardware dependencies and without dependencies on the lower level software components of the SoC. Instead the application may specify a processing pipeline comprising multiple stream processing tools that are provided by the SoC. At runtime the SoC may evaluate the current operating environment and conditions and select one of multiple available hardware processors to execute each of the stream processing tools. The selection of a particular hardware processor to execute a particular stream processing tool may be based on a variety of information including information provided by the application itself. For example the application may indicate maximum desired or allowable latencies for a pipeline and or for individual tools of the pipeline and the SoC may select a hardware processor that can provide latencies at or lower than the indicated maximum latencies. When selecting a hardware processor the SoC may also consider power consumption and may select one of the hardware processors that minimizes power consumption while still maintaining within the expected latencies of the pipeline.

The SoC may also assign processing tools to different hardware processors based on characteristics of the hardware processors and current operating conditions. For example the SoC may be configured with information regarding power vs. performance characteristics of the individual hardware processors and may select processors to achieve desired power usage and performance goals. The SoC may also look at current loads of the processors and may select a processor having available capacities that are sufficient to achieve desired performance goals for a pipeline or a processing tool.

The SoC provides a set of high level hardware agnostic components that may be called by an application using application interfaces to perform various high level computing tasks. The interfaces may be referred to herein as application programming interfaces APIs or simply as interfaces or high level software interfaces.

The components may comprise a library of functions stream processing tools and stream processing pipelines that may be invoked by the application . The components may provide functionality relating to various types of data processing such as graphics processing image processing vision processing audio processing graphics rendering audio rendering mathematical and logical operations etc. Examples relating to vision processing may include such things as image conversion resizing filtering and segmentation edge detection object detection and identification object tracking and so forth.

The application may be written in a high level language and may contain calls to the high level software interfaces . The application may perform specific tasks by calling the high level interfaces to invoke the functional components . Of particular relevance to the discussion herein the application may define and or select processing pipelines that are subsequently executed by the SoC to perform operations or tasks with respect to streams of data. A processing pipeline comprises multiple stream processing tools also referred to as software tools each of which comprises an operation function algorithm or other executable unit of software. Each tool typically has one or more logical inputs that accept data streams such as video image streams. Each tool also has one or more logical outputs that provide processed data streams or other data. The tools of a pipeline are logically configured in a sequence so that a data stream is passed through the sequence and operated on by each of the tools.

In the specific example of the stream processing tool receives a data stream . As an example the data stream may be a video stream provided by a video camera. The stream processing tool processes the data stream and provides an output data stream which is in turn provided to both the stream processing tool and the stream processing tool . The stream processing tools and perform additional processing on the data stream to produce respective output data streams and which are provided as inputs to the stream processing tool . The stream processing tool analyzes the data streams and to produce an output data stream .

The output data stream may comprise various types of data depending on the purpose of the pipeline . For example a pipeline may be designed to detect and track the face of a person in a video stream and the output data stream of the pipeline may comprise coordinates of the face. As another example the pipeline may be designed to perform audio beamforming with respect to an audio data stream where the pipeline has inputs from multiple microphones and produces a directional audio signal as output.

Individual stream processing tools may implement algorithms for accomplishing any desired tasks with regard to audio data streams video data streams and other types of data streams. The stream processing tools may also be used to produce audio and video signals for output such as by rendering audio and video based on various types of input streams.

The SoC may have a number of precompiled processing pipelines for performing common tasks. Such precompiled pipelines may be augmented by additional functionality defined by the application . As examples precompiled pipelines may be provided for object recognition and tracking based on video data for audio processing of audio signals for rendering audio graphics and video and for various other types of tasks.

Returning to the SoC also has a resource management framework also referred to herein as a resource manager that performs resource management scheduling and load balancing for processing pipelines. Generally the application is configured to configure and or select a processing pipeline for execution. The resource management framework is responsive to the specification of a processing pipeline to select appropriate processing components to execute the selected or designated processing pipeline.

The resource management framework may select from multiple available hardware processors for execution of a processing pipeline or of individual tools of the processing pipeline. The selection may be made dynamically depending on conditions at runtime. For example existing processing loads of the hardware processors may be evaluated prior to selecting a particular hardware processor to execute a specific pipeline tool. Selection from among available processing components may also be based on characteristics and requirements of the processing pipeline such as whether the pipeline is to run continuously or intermittently latency expectations of the pipeline power requirements of the pipeline computational requirements of the pipeline existing conditions such as current processing loads of the processing components etc. In some cases the application may provide information that indicates or implies the performance or computational goals of the application the pipeline or the tools of the pipeline such as allowable latencies desired computational accuracy etc.

In some cases the selection of a hardware processor may be influenced by the computational requirements of the processing pipeline and or the tools such as whether they relate to image processing rendering general computation analysis signal processing etc. For example an audio analysis processing graph may be assigned to and executed by a DSP. As another example an image processing graph may be assigned to and executed by a GPU.

The hardware processors may include one or more CPUs and or CPU cores one or more GPUs one or more DSPs one or more co processors and any of various other types of processors such as vector processors extensions accelerators etc. The co processors may be on chip or may in some cases reside off chip. The hardware processors may also include network resources such as servers or other processors that are accessible through a local area network or a wide area network such as the Internet. The hardware processors may also include other components with which the SoC can communicate including both on device and off device components.

The SoC also comprises multiple hardware drivers and or kernels that are accessed to utilize the hardware processors and other hardware components of the SoC and the device upon which it resides. The hardware kernels manage access to hardware resources by software components of the SoC .

The SoC further comprises multiple function libraries each of which may include kernels methods routines etc. for performing operations with respect to common types of data objects or streams. As examples the function libraries may implement vision processing functions video processing functions graphics and or graphics rendering functions audio processing functions and so forth. The function libraries may also implement co processor functions for accessing and utilizing the capabilities of any co processors of the SoC .

The function libraries may also include a compiler that may be used to compile certain functions or tools as will be described in more detail below.

The SoC may include a parallel processing framework having a resource management component . Generally the parallel processing framework supervises execution of pipelines and pipeline tools by the hardware processors . As will be described in more detail below the resource management component selects which of the multiple hardware processors will be used to execute individual tasks. The resource management component selects from among the hardware processors in order to satisfy performance goals while also minimizing power consumption.

The SoC may further comprise multiple stream processing tools that are be used within processing pipelines to implement corresponding processes functions or algorithms with respect to a data stream. The stream processing tools also referred to herein as software tools may include components such as graphics tools vision tools rendering tools audio tools and various other types of tools. Each stream processing tool is configured to receive one or more input data streams to process or analyze the one or more input data streams and to produce one or more output data streams based on the processing or analysis.

The SoC may also include multiple preconfigured stream processing pipelines each of which comprises a sequence or arrangement of the stream processing tools . As a specific example the preconfigured stream processing pipelines may include a face tracking pipeline that uses the vision tools to perform face tracking. The face tracking pipeline may accept a raw video data stream and output a data stream indicating coordinates of a detected face in the raw video data stream.

As other examples the preconfigured stream processing pipelines may include audio pipelines for performing various audio tasks such as filtering sound source localization beamforming text to speech conversion speech synthesis etc. The preconfigured pipelines may include video pipelines for performing various types of video analysis tasks such as object detection object identification object tracking video rendering shape analysis and so forth. The preconfigured pipelines may include graphics pipelines for analyzing and or rendering graphics streams. The preconfigured stream processing pipelines may include any other types of processing pipelines or tool chains that receive and process data streams.

The SoC has software interfaces that are accessible by applications to configure and execute the processing pipelines . The applications comprise programs that utilize the various resources provided by the SoC to perform high level functionality. Examples of applications include calendar applications email applications games word processors media players and so forth. In some cases the applications may be installed by an end user of the device upon which the SoC is implemented. Applications may also be pre installed upon certain devices for execution by the resources of the SoC . Generally an application uses resources of the SoC to perform higher levels of functionality than are natively provided by the SoC .

The software interfaces are configured to be called by the applications to configure instantiate and execute processing pipelines such the preconfigured pipelines . In addition the software interfaces provide functionality for an application to assemble configure instantiate and execute custom processing pipelines that use the stream processing tools provided by the SoC . Furthermore in some cases the software interfaces may include functionality for creating custom stream processing tools that can be used within custom processing pipelines.

Upon execution an application specifies a processing pipeline which may comprise one of the preconfigured pipelines or a custom pipeline by providing appropriate instructions through the software interfaces to the parallel processing framework . The resource management component responds to the instructions by selecting resources of the SoC to execute the tools of the specified pipeline. In particular the resource management component selects one of the hardware processors to execute each of the stream processing tools of the pipeline. After selecting a hardware processor to execute each tool of the specified pipeline the parallel processor oversees execution of the tool.

In some cases particularly in cases where the application provides a custom tool for execution within a custom pipeline the compiler may be called upon to compile a stream processing tool from a high level or intermediate level programming language to executable code or an executable instruction sequence that is particular to the hardware processor that is selected to execute the stream processing tool. The compilation may be performed at runtime after selecting the hardware processor that is to be used for executing the stream processing tool.

The SoC may also include memory which may comprise one or more non transitory computer readable media storing computer executable instructions that when executed by one or more of the hardware processors of the SoC cause the one or more hardware processors to perform the acts described herein. In particular the software and firmware elements of the SoC including the application may be stored by the memory . The memory may comprise non volatile and non removable system memory and may also comprise removable or portable memory such as may be used to transfer and distribute software and other data.

The stream processing tools may include stream processing tools that are provided by the system as well as other stream processing tools that are provided by an application . Tools may be provided at runtime by the application through tool interfaces which may comprise software interfaces such as are often referred to as application programming interfaces or APIs.

The pipelines may include pipelines that are provided and preconfigured by the system and that utilize the tools that are also provided as part of the system . In addition the pipelines may include pipelines that are specified or defined by the application and that use tools that are defined by the application . Pipelines may be created and or selected by the application through pipeline interfaces which may comprise software interfaces such as are often referred to as APIs.

In operation the application uses the tool interfaces and the pipeline interfaces to create and or select a specified pipeline which comprises a plurality of stream processing tools specified from the available or provided tools . In response to specification of the pipeline a parallel processing framework or resource management component selects one of multiple hardware processors to execute each of the pipeline tools .

Each of the tools is provided as executable code to the correspondingly selected hardware processor . In some cases the parallel processing framework may compile one of more of the tools at runtime to convert from a high level or intermediate level language provided by the application to the low level code that is executable by the particular hardware processors that have been selected to execute the tools . In some cases the compiling may be to an intermediate language or code used by low level drivers associated with the hardware processors . In some cases the compilation may be to an intermediate level language that calls functions routines and kernels associated with a selected hardware processor.

The parallel processing framework may select the hardware processor to execute a particular stream processing tool based on various information including but not limited to 

In some implementations the parallel processing framework may be configured to receive information from the application regarding the needs or expectations of the application regarding execution latency accuracy and or other factors. Specifically the application may indicate one or more performance goals to the parallel processing framework and the parallel processing framework may consider the performance goals when selecting the hardware processors for execution of the various tools of the specified pipeline . The performance goals may indicate allowable latencies of the pipeline or of individual tools of the pipeline . The performance goals may also indicate types of processing involved by each of the tools .

An action comprises receiving instructions from an application regarding a processing pipeline such as instructions to execute a specified processing pipeline. The instructions may identify or specify one of multiple processing pipelines that are preconfigured and provided by the computing platform. Alternatively the instructions may specify or provide a configuration of a custom processing pipeline.

The specified processing pipeline comprises a sequence of multiple stream processing tools. Each stream processing tool may be a tool that is provide by the computing platform or a tool that is provided as a software module by the application.

The instructions provided by the application may include one or more commands that identify individual stream processing tools of the processing pipeline and that further identify a sequential configuration of the tools of the processing pipeline. The commands may provide further configuration information such as information regarding data providers and data consumers.

Each stream processing tool may comprise a software component that implements a function method or algorithm. For example each stream processing tool may be provided as a program or routine written in a hardware agnostic programming language. Each stream processing tool may invoke kernel functions of the computing platform including low level device and processor drivers as well as function libraries that may be provided by the computing platform. In some cases one or more stream processing tools may be provided as part of the computing platform. In addition one or more stream processing tools may be specified and or provided by the application.

Each stream processing tool is configured to be executed by each of multiple available hardware processors of the computing system. For example a stream processing tool may be written or provided in a high level or intermediate level language that calls functions supported by the computing platform but that is not dependent on hardware features of the computing system. At runtime prior to execution the stream processing tool may be compiled for a specific hardware processor. Alternatively the computing platform may be configured to have multiple pre compiled versions of each stream processing tool wherein each version is suitable for execution by a different available hardware processor.

An action may comprise constructing and or providing a processing pipeline in response to the instructions or commands received from the application. For example the application may identify multiple software tools provided by a library of software tools and may specify an order in which the software tools are to be sequenced. The application may specify parameters or arguments for the tools and may specify data sources and data sinks. The computing platform may respond by instantiating the identified tools for operation in the specified sequence on a data stream received from the specified data source.

An action may comprise receiving one or more performance goals that are to be associated with the pipeline or individual stream processing tools of the pipeline. The one or more performance goals may indicate an allowable execution latency of each processing tool of the processing pipeline. The one or more performance goals may in some cases also indicate whether the pipeline is to execute continuously and or a priority at which the pipeline or its stream processing tools are to execute. In some cases the performance goals may indicate a minimum computational accuracy to be achieved by the stream processing tools of the pipeline.

An action comprises determining available capabilities and or capacities of the multiple hardware processors. In some cases this may comprise determining existing processor loads and or power consumption of each of the multiple hardware processors.

Remaining actions of are performed with respect to each of the individual stream processing tools of the processing pipeline. An action comprises estimating power consumed by each hardware processor to execute the individual stream processing tool. The action may also comprise estimating the latency required or introduced by each hardware processor when it is called upon to execute the individual stream processing tool. In some cases these actions may be based on observations during previous executions of the individual stream processing tool by different hardware processors. The action may comprise determining whether or not a particular hardware processor is currently capable of executing the individual stream processing tool within no more than the allowable latency that has been indicated by the performance goals for the individual stream processing tool.

An action comprises selecting one of the hardware processors to execute the individual stream processing tool wherein the selected one of the hardware processors has available capacities or capabilities that satisfy the performance needs or goals of the individual stream processing tool. In some cases the action is based at least in part on characteristics of the hardware processors such as speeds power consumption and power versus latency estimations. In some cases the action may be based at least in part on current processing loads of the processors. In some cases the selection of the hardware processor may be based on the estimated or projected performance of the hardware processor in comparison to the estimated or projected power usage of the hardware processor when executing the individual stream processing tool. In some cases selecting the hardware processor to execute the individual stream processing component may comprise determining that the hardware processor has available capacity or capabilities that will provide the computing needs indicated by the application with respect to the pipeline. The hardware processor may also be selected based on a desired priority of the pipeline as indicated by the application and or on the type of processing required of by the individual processing tool.

As a specific example the action may comprise determining which of the multiple available hardware processors are capable of executing the individual stream processing tool with no more than the allowable latency. The action may further comprise determining which of these hardware processors uses the least power when executing the individual stream processing tool. The action may comprise selecting the hardware processor that is capable of executing the individual stream processing tool while using the least comparative amount of power.

An action comprises compiling the individual stream processing tool to create an instruction sequence for execution by the selected hardware processor. In some cases stream processing tools may be pre compiled for different hardware processors. In other cases the individual stream processing tool may be compiled after or in response to selecting the hardware processor so that the individual stream processing tool may be compiled for the specific processor upon which it will be executed. Runtime compiling such as this may be particularly useful for stream processing tools that are provided by the application at runtime.

An action comprises selecting a processor speed or clock speed of the selected hardware processor such that the hardware processor is able to satisfy the performance needs of the individual stream processing tool for which the hardware processor has been selected to execute. Note that in some cases the clock speed may be selected to accommodate multiple processes that are being executed concurrently by the hardware processor.

An action comprises executing the individual stream processing tool on the selected hardware processor using the selected clock speed.

The example method allows an application to utilize the various hardware resources of a computing platform without being dependent upon the particular hardware resources that are provided by the computing platform. Rather the application may be written with reference to standard libraries of functions tools and pipelines.

Furthermore the resource management features utilized by the described techniques allow the computing platform to reduce its power consumption while still providing adequate levels of performance.

Although the subject matter has been described in language specific to structural features it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features described. Rather the specific features are disclosed as illustrative forms of implementing the claims.

