---

title: Trace buffer based replay for context switching
abstract: A command processor may process a command stream for execution by at least one processor, including storing data associated with a first set of one or more operations in the command stream in a trace buffer, wherein the first set of one or more operations accesses one or more memory locations in memory, and wherein the data include an indication of contents of the one or more memory locations associated with the first set of one or more operations. The command processor may interrupt the processing of the command stream. The command processor may, in response to resuming processing of the command stream subsequent to the interrupting of the processing of the command stream, replay at least a portion of the command stream, including processing a second set of one or more operations of the command stream based at least in part on the data stored in the trace buffer.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09626313&OS=09626313&RS=09626313
owner: QUALCOMM Incorporated
number: 09626313
owner_city: San Diego
owner_country: US
publication_date: 20141218
---
As the performance of specialized processors such as graphics processing units GPUs that includes multiple processing cores continues to increase at a rapid rate computer programs are increasingly being written to take advantage of such specialized processors in a heterogeneous computing system. For example a host processor such as a central processing unit CPU may be able to offload processing of one or more portions of computer applications onto a secondary processor such as a GPU by sending one or more command streams including operations that the GPU may execute. In this way a computing system including both a CPU and a GPU may be able to more efficiently execute computer applications.

In general aspects of the disclosure are directed to context switching of a processing unit and a trace buffer based replay of a command stream that is executed by a processing unit such as a GPU. The trace buffer may ensure the consistency of operations in the command stream during replay of the command stream by storing data associated with memory locations upon which the operations in the command stream depend.

In one aspect the disclosure is directed to a method for replaying a command stream comprising processing by a command processor a command stream for execution by at least one processor including storing by the command processor data associated with a first set of one or more operations in the command stream in a trace buffer wherein the first set of one or more operations in the command stream accesses one or more memory locations in memory and wherein the data associated with the first set of one or more operations include an indication of contents of the one or more memory locations associated with the first set of one or more operations interrupting by the command processor the processing of the command stream and in response to resuming by the command processor processing of the command stream subsequent to the interrupting of the processing of the command stream replaying by the command processor at least a portion of the command stream including processing by the command processor a second set of one or more operations of the command stream based at least in part on the data stored in the trace buffer that is associated with the first set of one or more operations.

In another aspect the disclosure is directed to a device configured for of graphics or compute processing comprising at least one processor a memory and a command processor configured to process a command stream for execution by the at least one processor including storing data associated with a first set of one or more operations in the command stream in a trace buffer wherein the first set of one or more operations in the command stream accesses one or more memory locations in the memory and wherein the data associated with the first set of one or more operations include an indication of contents of the one or more memory locations associated with the first set of one or more operations interrupt the processing of the command stream and in response to resuming processing of the command stream subsequent to the interrupting of the processing of the command stream replay at least a portion of the command stream including processing a second set of one or more operations of the command stream based at least in part on the data stored in the trace buffer that is associated with the first set of one or more operations.

In another aspect the disclosure is directed to a computer readable storage medium having instructions stored thereon that when executed cause one or more processors to perform operations comprising processing a command stream for execution by at least one processor including storing by the command processor data associated with a first set of one or more operations in the command stream in a trace buffer wherein the first set of one or more operations in the command stream accesses one or more memory locations in memory and wherein the data associated with the first set of one or more operations include an indication of contents of the one or more memory locations associated with the first set of one or more operations interrupting the processing of the command stream and in response to resuming processing of the command stream subsequent to the interrupting of the processing of the command stream replaying at least a portion of the command stream including processing a second set of one or more operations of the command stream based at least in part on the data stored in the trace buffer that is associated with the first set of one or more operations.

In another aspect the disclosure is directed to a device comprising means for processing a command stream for execution by at least one processor including storing by the command processor data associated with a first set of one or more operations in the command stream in a trace buffer wherein the first set of one or more operations in the command stream accesses one or more memory locations in memory and wherein the data associated with the first set of one or more operations include an indication of contents of the one or more memory locations associated with the first set of one or more operations means for interrupting the processing of the command stream and in response to resuming processing of the command stream subsequent to the interrupting of the processing of the command stream means for replaying at least a portion of the command stream including means for processing a second set of one or more operations of the command stream based at least in part on the data stored in the trace buffer that is associated with the first set of one or more operations.

The details of one or more aspects of the disclosure are set forth in the accompanying drawings and the description below. Other features objects and advantages of the disclosure will be apparent from the description and drawings and from the claims.

In general aspects of the disclosure are directed to techniques for context switching of a processing unit and a trace buffer based replay of a command stream that is executed by a processing unit such as a graphics processing unit GPU . On a mobile system on a chip SoC integrated circuit spatial partitioning for various workloads such as dividing processing cores so that individual cores may process different workloads may not be practical due to constraints of the silicon area. The GPU may be better utilized by temporally partitioning of the GPU resources to allow various processes to make forward progress. The temporal partitioning process can be achieved via context switching so that the GPU may switch between processing multiple command streams. In context switching the GPU may be interrupted during the processing of a command stream and switched to process another command stream. The GPU may subsequently switch back to processing the interrupted command stream. Context switching on the GPU may potentially encounter different challenges compared with context switching on the CPU. For example due to deeper pipeline than CPU and various programmable and fixed function hardware blocks context switching may require an enormous amount of state tracking

A GPU driver executing on a host processor may send to the GPU workload state information as a stream of commands i.e. a command stream that is decoded by a command stream processor such as a command processor of the GPU or any other suitable stream processor. A command stream may include one or more checkpoints in the command stream that can be used as a restart point. The checkpoint may allow for fast switching between streams. This scheme is called replay because the command stream upon being restarted may encounter operations of the command stream it has already previously encountered prior to the context switch.

While the GPU driver streams one or more command stream to the GPU any external memory contents that the command stream relies upon may be short lived and thus unavailable when the GPU switches back to processing the interrupted command stream because the contents of those memory contents may have changed while the command stream was interrupted. Thus any external memory dependency of the command stream may not be guaranteed for an arbitrary amount of time considering the uncertainty in context switching. As such the command stream during replay may not be exactly the same as before the context was switched thereby execution of the command stream may result in errors.

To ensure the consistency of operations in the command stream during replay of the command stream a trace buffer may store data associated with memory locations upon which the operations in the command stream depend. In the context of debugging tracing is the process of logging relevant information as the execution of code progresses. At the end of a run important events during the execution are captured in traces that are valuable in debugging. The concept of tracing can be applied to the present invention via use of the trace buffer. The GPU may record into the trace buffer important events and or data generated used during execution. The information recorded into the trace buffer can be later consumed as is for re executing the command stream.

The trace buffer may track external memory read writes as well as the contents of the external memory to ensure that the command stream during replay is the same as before the context was switched. For example the trace buffer can store the history of a memory location processed packets and or commands snapshots of required memory reads predicates for control flow flags for completed external memory syncs and any other packets that depend upon external memory.

In accordance with aspects of the present disclosure the command processor may process a command stream for execution by at least one processor including storing by the command processor data associated with a first set of one or more operations in the command stream in a trace buffer wherein the first set of one or more operations in the command stream accesses one or more memory locations in memory and wherein the data associated with the first set of one or more operations include an indication of contents of the one or more memory locations associated with the one or more operations. The command processor may interrupt the processing of the command stream. The command processor may in response to resuming processing of the command stream subsequent to the interrupting of the processing of the command stream replay at least a portion of the command stream based at least in part on the data stored in the trace buffer including processing by the command processor a second set of one or more operations of the command stream based at least in part on the data stored in the trace buffer.

Computing device may include additional modules or units not shown in for purposes of clarity. For example computing device may include a speaker and a microphone neither of which are shown in to effectuate telephonic communications in examples where computing device is a mobile wireless telephone or a speaker where computing device is a media player. Computing device may also include a video camera. Furthermore the various modules and units shown in computing device may not be necessary in every example of computing device . For example user interface and display may be external to computing device in examples where computing device is a desktop computer or other device that is equipped to interface with an external user interface or display.

Examples of user interface include but are not limited to a trackball a mouse a keyboard and other types of input devices. User interface may also be a touch screen and may be incorporated as a part of display . Transceiver module may include circuitry to allow wireless or wired communication between computing device and another device or a network. Transceiver module may include modulators demodulators amplifiers and other such circuitry for wired or wireless communication.

Processor may be a microprocessor such as a central processing unit CPU configured to process instructions of a computer program for execution. Processor may comprise a general purpose or a special purpose processor that controls operation of computing device . A user may provide input to computing device to cause processor to execute one or more software applications. The software applications that execute on processor may include for example an operating system a word processor application an email application a spreadsheet application a media player application a video game application a graphical user interface application or another program. Additionally processor may execute GPU driver for controlling the operation of GPU . The user may provide input to computing device via one or more input devices not shown such as a keyboard a mouse a microphone a touch pad or another input device that is coupled to computing device via user interface .

The software applications that execute on processor may include one or more graphics rendering instructions that instruct processor to cause the rendering of graphics data to display . In some examples the software instructions may conform to a graphics application programming interface API such as e.g. an Open Graphics Library OpenGL API an Open Graphics Library Embedded Systems OpenGL ES API a Direct3D API an X3D API a RenderMan API a WebGL API an Open Computing Language OpenCL or any other public or proprietary standard GPU compute API. In order to process the graphics rendering instructions processor may issue one or more graphics rendering commands to GPU e.g. through GPU driver to cause GPU to perform some or all of the rendering of the graphics data. In some examples the graphics data to be rendered may include a list of graphics primitives e.g. points lines triangles quadrilaterals triangle strips etc.

GPU may be configured to perform graphics operations to render one or more graphics primitives to display . Thus when one of the software applications executing on processor requires graphics processing processor may provide graphics commands and graphics data to GPU for rendering to display . The graphics data may include e.g. drawing commands state information primitive information texture information etc. GPU may in some instances be built with a highly parallel structure that provides more efficient processing of complex graphic related operations than processor . For example GPU may include a plurality of processing elements such as shader units that are configured to operate on multiple vertices or pixels in a parallel manner. The highly parallel nature of GPU may in some instances allow GPU to draw graphics images e.g. GUIs and two dimensional 2D and or three dimensional 3D graphics scenes onto display more quickly than drawing the scenes directly to display using processor .

GPU may in some instances be integrated into a motherboard of computing device . In other instances GPU may be present on a graphics card that is installed in a port in the motherboard of computing device or may be otherwise incorporated within a peripheral device configured to interoperate with computing device . In some examples GPU may be on chip with processor such as in a system on chip SOC GPU may include one or more processors such as one or more microprocessors application specific integrated circuits ASICs field programmable gate arrays FPGAs digital signal processors DSPs or other equivalent integrated or discrete logic circuitry. GPU may also include one or more processor cores so that GPU may be referred to as a multi core processor.

In some examples graphics memory may be part of GPU . Thus GPU may read data from and write data to graphics memory without using a bus. In other words GPU may process data locally using a local storage instead of off chip memory. Such graphics memory may be referred to as on chip memory. This allows GPU to operate in a more efficient manner by eliminating the need of GPU to read and write data via a bus which may experience heavy bus traffic and associated contention for bandwidth. In some instances however GPU may not include a separate memory but instead utilize system memory via a bus. Graphics memory may include one or more volatile or non volatile memories or storage devices such as e.g. random access memory RAM static RAM SRAM dynamic RAM DRAM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM Flash memory a magnetic data media or an optical storage media.

In some examples GPU may store a fully formed image in system memory . Display processor may retrieve the image from system memory and output values that cause the pixels of display to illuminate to display the image. Display may be the display of computing device that displays the image content generated by GPU . Display may be a liquid crystal display LCD an organic light emitting diode display OLED a cathode ray tube CRT display a plasma display or another type of display device.

Memory available to processor and GPU may include system memory and output buffer . Output buffer may be a part of system memory or may be separate from system memory . Output buffer may store rendered image data such as pixel data as well as any other data.

Software application may be any application that utilizes the functionality of GPU . For example software application may be a GUI application an operating system a portable mapping application a computer aided design program for engineering or artistic applications a video game application or another type of software application that uses 2D or 3D graphics.

Software application may include one or more drawing instructions that instruct GPU to render a graphical user interface GUI and or a graphics scene. For example the drawing instructions may include instructions that define a set of one or more graphics primitives to be rendered by GPU . In some examples the drawing instructions may collectively define all or part of a plurality of windowing surfaces used in a GUI. In additional examples the drawing instructions may collectively define all or part of a graphics scene that includes one or more graphics objects within a model space or world space defined by the application.

Software application may invoke GPU driver to issue one or more commands to GPU for rendering one or more graphics primitives into displayable graphics images. For example software application may invoke GPU driver to provide primitive definitions to GPU . In some instances the primitive definitions may be provided to GPU in the form of a list of drawing primitives e.g. triangles rectangles triangle fans triangle strips etc. The primitive definitions may include vertex specifications that specify one or more vertices associated with the primitives to be rendered. The vertex specifications may include positional coordinates for each vertex and in some instances other attributes associated with the vertex such as e.g. color coordinates normal vectors and texture coordinates. The primitive definitions may also include primitive type information e.g. triangle rectangle triangle fan triangle strip etc. scaling information rotation information and the like.

Based on the instructions issued by software application to GPU driver GPU driver may formulate one or more commands that specify one or more operations for GPU to perform in order to render the primitive. When GPU receives a command from CPU a graphics processing pipeline may execute on shader processors to decode the command and to configure a graphics processing pipeline to perform the operation specified in the command. For example an input assembler in the graphics processing pipeline may read primitive data and assemble the data into primitives for use by the other graphics pipeline stages in a graphics processing pipeline. After performing the specified operations the graphics processing pipeline outputs the rendered data to output buffer associated with a display device. In some examples the graphics processing pipeline may include fixed function logic and or be executed on programmable shader cores.

Output buffer stores destination pixels for GPU . Each destination pixel may be associated with a unique screen pixel location. In some examples output buffer may store color components and a destination alpha value for each destination pixel. For example output buffer may store Red Green Blue Alpha RGBA components for each pixel where the RGB components correspond to color values and the A component corresponds to a destination alpha value. Although output buffer and system memory are illustrated as being separate memory units in other examples output buffer may be part of system memory . Further as discussed above output buffer may also be able to store any suitable data other than pixels.

In some examples a graphics processing pipeline may include one or more of a vertex shader stage a hull shader stage a domain shader stage a geometry shader stage and a pixel shader stage. These stages of the graphics processing pipeline may be considered shader stages. These shader stages may be implemented as one or more shader programs that execute on shader units in GPU . Shader units may be configured as a programmable pipeline of processing components. In some examples shader unit may be referred to as shader processors or unified shaders and may perform geometry vertex pixel or other shading operations to render graphics. Shader units may include one or more shader processors each of which may include one or more components for fetching and decoding operations one or more ALUs for carrying out arithmetic calculations one or more memories caches and registers.

GPU may designate shader units to perform a variety of shading operations such as vertex shading hull shading domain shading geometry shading pixel shading and the like by sending commands to shader units to execute one or more of a vertex shader stage a hull shader stage a domain shader stage a geometry shader stage and a pixel shader stage in a graphics processing pipeline. In some examples GPU driver may cause a compiler executing on CPU to compile one or more shader programs and to download the compiled shader programs onto one or more programmable shader units contained within GPU . The shader programs may be written in a high level shading language such as e.g. an OpenGL Shading Language GLSL a High Level Shading Language HLSL a C for Graphics Cg shading language an OpenCL C kernel etc. The compiled shader programs may include one or more instructions that control the operation of shader units within GPU . For example the shader programs may include vertex shader programs that may be executed by shader units to perform the functions of a vertex shader stage hull shader programs that may be executed by shader units to perform the functions of a hull shader stage domain shader programs that may be executed by shader unit to perform the functions of a domain shader stage geometry shader programs that may be executed by shader unit to perform the functions of a geometry shader stage and or pixel shader programs that may be executed by shader units to perform the functions of a pixel shader. A vertex shader program may control the execution of a programmable vertex shader unit or a unified shader unit and include instructions that specify one or more per vertex operations.

Graphics memory may include on chip storage or memory that is physically integrated into the integrated circuit chip of GPU . If graphics memory is on chip GPU may be able to read values from or write values to graphics memory more quickly than reading values from or writing values to system memory via a system bus.

CPU processes instructions for execution within computing device . Host processor may be capable of processing instructions stored in system memory . CPU may generate a command stream using a driver e.g. GPU driver which may be implemented in software executed by CPU for execution by GPU . That is host processor may generate a command stream that defines a set of operations to be performed by GPU .

CPU may generate a command stream to be executed by GPU that causes viewable content to be displayed on display . For example CPU may generate a command stream that provides instructions for GPU to render graphics data that may be stored in output buffer for display at display . In this example CPU may generate a command stream that is executed by a graphics rendering pipeline.

Additionally or alternatively CPU may generate a command stream to be executed by GPU that causes GPU to perform other operations. For example in some instances CPU may be a host processor that generates a command stream for using GPU as a general purpose graphics processing unit GPGPU . In this way GPU may act as a secondary processor for CPU . For example GPU may carry out a variety of general purpose computing functions traditionally carried out by CPU . Examples include a variety of image processing functions including video decoding and post processing e.g. de blocking noise reduction color correction and the like and other application specific image processing functions e.g. facial detection recognition pattern recognition wavelet transforms and the like . In some examples GPU may collaborate with CPU to execute such GPGPU applications. For example CPU may offload certain functions to GPU by providing GPU with a command stream for execution by GPU . In this example CPU may be a host processor and GPU may be a secondary processor.

CPU may communicate with GPU to direct GPU to execute GPGPU applications via GPU driver . GPU driver may communicate to GPU one or more command streams that may be executed by shader units of GPU . GPU may include command processor that may receive the one or more command streams from GPU driver . Command processor may be any combination of hardware and software configured to receive and process one or more command streams. As such command processor is a stream processor. In some examples instead of command processor any other suitable stream processor may be usable in place of command processor to receive and process one or more command streams and to perform the techniques disclosed herein. In one example command processor may be a hardware processor. In the example shown in command processor may be included in GPU . In other examples command processor may be a unit that is separate from CPU and GPU . Command processor may also be known as a stream processor command stream processor and the like to indicate that it may be any processor configured to receive streams of commands and or operations.

Command processor may process one or more command streams including scheduling operations included in the one or more command streams for execution by GPU . Specifically command processor may process the one or more command streams and schedule the operations in the one or more command streams for execution by shader units . In operation GPU driver may send to command processor a command stream comprising a series of operations to be executed by GPU . Command processor may receive the stream of operations that comprise the command stream and may process the operations of the command stream sequentially based on the order of the operations in the command stream and may schedule the operations in the command stream for execution by shader processors of shader units .

Command processor may be able to process multiple command streams by context switching amongst the different command streams. For example GPU driver may direct command processor to switch from processing a first command stream to processing a second command stream. Command processor may in response to receiving a command from GPU driver to switch from processing the first command stream to processing the second command stream perform a context switch. Command processor may interrupt processing of the first command stream and upon interruption of the processing of the first command stream commence processing of the second command stream.

Subsequently at a later point GPU driver may for example direct command processor to interrupt processing of the second command stream and to resume processing of the first command stream. Command processor may in response to receiving a command from GPU driver to switch back from processing the second command stream to process the first command stream perform a context switch by interrupting processing of the second command stream and restart processing of the first command stream. By performing context switching command processor may enable multiple command streams to be executed by GPU thereby more efficiently utilizing GPU .

However upon restarting processing of the first command stream command processor may process operations of the first command stream that may depend on the contents of memory locations in memory e.g. system memory or graphics memory being identical during execution of the operations by GPU to the contents of the memory locations prior to command processor interrupting the first content stream. For example if an operation in the first command stream being executed by GPU subsequent to restarting processing of the first command stream is a memory read operation that reads a specified memory location in memory and if during processing of the second command stream prior to command processor restarting processing of the first stream the GPU CPU or any other suitable device processor executes an operation in or during the second command stream that modifies the value stored in the specified memory location in memory then the GPU executing the memory read operation to read the specified memory location may lead to an inconsistent and or incorrect result.

In accordance with an aspect of the present disclosure command processor may process command stream for execution by GPU including storing by command processor data associated with a first set of one or more operations in command stream in trace buffer . Command processor may use trace buffer to ensure consistency of the contents of certain memory locations across one or more context switches. A trace buffer may be a buffer in memory where typically trace information for an application is stored such as information detailing a history of the application s code execution timing and or memory accesses. Similarly in the example of trace buffer may be any suitable set of memory locations to which command processor has read and write access.

The first set of one or more operations in the command stream may access one or more memory locations in graphics memory and or system memory and the data associated with the first set of one or more operations may include an indication of contents of the one or more memory locations associated with the one or more operations. Command processor may store data associated with operations of a command stream as command processor processes the command stream into trace buffer . For example command processor may store in trace buffer data associated with memory access operations e.g. memory read operations memory write operations and the like as well as data associated with operations that depend upon the value of content in certain memory locations e.g. read operations predicates for control flow and the like . In this way by storing data associated with operations of a command stream trace buffer may enable computing device to refrain from persisting the contents of memory locations in graphics memory and or system memory across context switches.

In the example of trace buffer is stored in system memory . In other examples trace buffer may be stored in any suitable memory of computing device such as system memory graphics memory and the like. Trace buffer may store data associated with memory access operations e.g. memory read operations memory write operations and the like as well as data associated with operations that depend upon the value of content in certain memory locations e.g. read operations predicates for control flow and the like . Trace buffer may also store the intermediate results of operations that command processor has received and that GPU has executed. Thus if command processor resumes processing of a command stream GPU may depend upon data stored in trace buffer to resume processing command stream .

As command processor receives operations of command stream as streamed from GPU driver command processor may process the received operations of command stream including storing into trace buffer data associated with the operations received by command processor from GPU driver . As discussed above the data may be the values of the contents of memory locations accessed by the instructions or the values of the contents of memory locations upon which the results of executing the instructions depend. For example the data associated with operations received by command processor that command processor may store into trace buffer may also include data associated with conditional statements that depend upon the values of the contents of memory locations. The conditional statements for example may be predicates of control flow statements that compare a value with the value stored in a memory location. In another example if an operation received by command processor is a memory write operation the command processor may store into trace buffer the value that is written by the write operation to a memory location along with an indication of the memory location to which the value was written. If the operations received by command processor includes multiple memory accesses to the same memory location e.g. multiple write operations to the same memory location the command processor may write into trace buffer a history of the contents of that memory location. In this way command processor may store into trace buffer intermediate values of the operations it processes.

Command processor may interrupt the processing of command stream to pause command stream in order to process and schedule for execution other command streams in order to efficiently utilize GPU in processing multiple command streams. In response to resuming processing of command stream subsequent to the interrupting of the processing of command stream command processor may replay at least a portion of command stream based at least in part on the data stored in trace buffer including processing a second set of one or more operations of command stream based at least in part on the data stored in trace buffer . Replaying at least a portion of command stream may include resuming processing and scheduling for execution operations of the at least the portion of command stream .

Command stream may include one or more checkpoints that separate blocks of independent operations in command stream . The blocks of operations separated by checkpoints may be relatively independent in that for example operations in one block may not necessarily access a memory location that is accessed by operations in another block if context switching that occurs between the executions of these operations may potentially introduce data hazards. As such command processor may resume processing of command stream from the checkpoint in command stream that command processor has most recently encountered.

Resuming processing of command stream from the checkpoint in command stream that command processor has most recently encountered may result in command processor encountering operations of command stream that command processor has already processed and or scheduled for execution by GPU . As such in resuming processing of command stream command processor may encounter the first set of one or more operations in command stream that it has already previously processed. Command processor therefore may skip processing of operations of command stream it has already processed and scheduled for execution by GPU . For operations command processor has processed but not scheduled for execution by GPU command processor may schedule those operations for execution by GPU based at least in part on the data associated with the operations as well as data associated with previous operations of command stream that command processor may have stored into trace buffer .

Furthermore command processor may also encounter operations of command stream that it has not previously processed. These operations may be the second set of one or more operations that command processor may process based at least in part on the data associated with the first set of one or more operations that is stored in trace buffer . As such command processor may process and schedule for execution by GPU these operations based at least in part on the data associated with previous operations of command stream stored by command processor in trace buffer . For example if command processor encounters a read operation command processor may determine based on the data stored in trace buffer whether the read operation reads from a memory location that a previous operation processed by command processor has written to. If command processor determines that the read operation does read a memory location that a previous operation processed by command processor has written to command processor may retrieve the value of the memory location from trace buffer and may schedule the read operation for execution by GPU based on the value of the memory location from trace buffer thereby ensuring the read operation may result in reading the value of the memory location as retrieved from trace buffer . As such command processor may utilize trace buffer to ensure the correctness of results from executing command stream .

During processing of command stream command processor may perform a context switch to interrupt processing of command stream so that command processor may process another command stream. By interrupting processing of command stream command processor in effect pauses the processing of command stream so that command processor does not further process any operations in command stream and GPU does not further execute any operations in command stream until command processor performs another context switch to switch back to processing command stream .

In response to command processor switching back to processing command stream command processor may resume processing command stream starting at the checkpoint of command stream that command processor had most recently encountered. Because command stream is streamed from GPU driver to command processor command processor processes command stream in order in a sequential fashion. For example if the most recent operation in command stream that was processed by command processor prior to a context switch away from processing command stream is any of operations B H then command processor may resume processing command stream starting from checkpoint A. In another example if the most recent operation in command stream that was processed by command processor prior to a context switch away from processing command stream is any of operations J to O then command processor may resume processing command stream starting from checkpoint I. In this way the checkpoints of command stream provide a waypoint for command processor to determine a position in command stream to restart execution of command stream .

Trace buffer may be a ring buffer that stores data associated with one or more operations in command stream to aid command processor in restarting processing of command stream after one or more context switches. In alternate examples trace buffer may be a linear buffer or any other suitable memory for storing data associated with operations in command stream .

Trace buffer may store one or more indications of operations in command stream that have already been processed by command processor . For example trace buffer may store an index of the operations in command stream as well as an index of operations in command stream that command processor has already processed. Trace buffer may also store an indication of operations in command stream that have been scheduled for execution by GPU . For example trace buffer may store an index of operations command processor has scheduled for execution by GPU . It should be understood that just because command processor has already processed a specified operation does not necessarily also mean that GPU has executed the operation because GPU sub systems may not necessarily be in sync with command processor or CPU . Furthermore command processor may perform a context switch after processing an operation but before command processor has scheduled the operation for execution by GPU . As such trace buffer may not be able to store an indication of whether GPU has executed a certain operation but may be able to store an indication of whether command processor has processed the operation and whether command processor has scheduled the operation to be executed by GPU .

Trace buffer may be able to store at one time or another data associated with each operation in command stream . However if trace buffer is currently storing data associated with a first checkpoint in a command stream and if subsequently command processor processes a second checkpoint in the same command stream command processor may purge from trace buffer data associated with operations in the command stream prior to the second checkpoint. In the example shown in trace buffer may include data associated with checkpoint A as well as data associated with operations B H. Responsive to command processor processing checkpoint I command processor may purge from trace buffer the data associated with checkpoint A as well as data associated with operations B H so that subsequent to purging that data only data associated with checkpoint I is stored in trace buffer . In this way trace buffer may be of a size that is sufficient to store no more than the data associated with operations between two checkpoints in the command stream.

Trace buffer may store nodes A H nodes that each includes data associated with an operation of command stream . Trace buffer may store nodes sequentially according to the order of the associated operations of command stream . For example if node A includes data associated with checkpoint A and node B includes data associated with read operation C node A is sequentially before node B in trace buffer .

In the example of command processor may not record data into trace buffer for every operation of command stream that it processes. Thus trace buffer may not include a node for each operation of command stream that is processed by command processor . Rather command processor may only record into trace buffer data associated with operations whose consistency cannot be guaranteed after interruption and resumption of processing of command stream and may omit from recording into trace buffer data associated with operations whose consistency can be guaranteed after interruption and resumption of processing of command stream .

For example command processor may store data associated with read operation C into nodes B E in trace buffer data associated with write operation E into node F in trace buffer and data associated with if conditional operation K into node H in trace buffer . Command processor may also omit from recording into trace buffer data associated with GPU state operations that are self sufficient and or deterministic as long as the original command stream is present. Thus command processor may not record into trace buffer data associated with state operations B D F G J and the like.

Command processor may utilize read pointer for reading from trace buffer and may utilize write pointer for writing to trace buffer . Read pointer may point to a node of nodes that is associated with the first valid operation in trace buffer . When command processor context switches away from command stream command processor may record data associated with the last operation of command stream it processes into trace buffer and sets read pointer to point to the first node in trace buffer that is associated with a checkpoint. Thus upon command processor resuming processing of command stream command processor may start reading trace buffer from the node that read pointer points to. Meanwhile write pointer may point to a memory location in trace buffer that is subsequent to the last node in trace buffer .

As discussed above in response to command processor switching back to processing command stream command processor may resume processing command stream starting at the checkpoint of command stream that command processor had most recently encountered. Thus even if command processor had already previously processed one or more operations subsequent to the checkpoint in command stream prior to the context switch command processor may encounter those same one or more operations again after resuming processing of command stream .

However because trace buffer may store intermediate results as well as memory contents from processing by command processor and execution by GPU of operations of command stream prior to command processor s interruption of the processing of command stream command processor s subsequent resumption of processing of command stream may be able to rely on the intermediate results stored in trace buffer to ensure the correctness of the results from GPU s execution of the operations of command stream . In the example of prior to command processor performing context switch command processor may have already processed read operation C which may be a data read from a specific memory location of memory . Processing read operation C may include storing by command processor into trace buffer data associated with read operation C. For example the data associated with read operation C may be the memory contents of the specific memory location of memory that is read by read operation C.

In the interim as command processor interrupts processing of command stream it may be possible that GPU may execute a write command to that same specific memory location of memory . Subsequently command processor may resume processing of command stream from checkpoint A. In this example command processor may once again re process read operation C. Because the contents of the specific memory location of memory may have changed in the interim command processor may determine the result of re executing read operation C based at least in part on the data stored in trace buffer that is associated with read operation C. Thus in response to encountering read operation C command processor may for example enable GPU to perform read operation C by reading the memory contents of the specific memory location of memory as stored into trace buffer . In this way command processor may utilize trace buffer to ensure the correctness of results from GPU executing command stream across context switches.

Command processor may receive and process operations of command stream that encompasses branching execution path and may evaluate predicate K including evaluation the value of variable c to determine whether condition is satisfied. Command processor may flatten branching execution path based at least in part on the value of variable c stored in trace buffer to result in flattened execution path . Flattening branching execution path may include determining the operations that command processor takes through branching execution path . For example flattening branching execution path may omit condition from flattened execution path because command processor has resolved the condition. Flattening branch execution path may also include omitting operation from flattened execution path because command processor determines that operation will not be executed based on evaluating the predicate included in condition .

Command processor may store data associated with flattened execution path in trace buffer such as storing an indication of the operations of command stream associated with flattened execution path in trace buffer . Command processor may when scheduling execution of operations associated with branching execution path for execution by GPU instead schedule the operations associated with flattened execution path for execution by GPU . In this way command processor may more efficiently utilize trace buffer by storing less data in trace buffer and may also more efficiently utilize GPU by scheduling flattened execution path for execution instead of branching execution math .

In some examples an indication of contents of the one or more memory locations associated with the first set of one or more operations comprises the contents of the one or more memory locations. In some examples the first set of one or more operations in the command stream comprise at least one of one or more write operations to the one or more memory locations in the memory or one or more read operations from the one or more memory locations in the memory. In some examples the first set of one or more operations in the command stream comprise a comparison of at least one value with the contents of the one or more memory locations.

In some examples the first set of one or more operations in the command stream comprise a control flow statement. In some examples storing by command processor data associated with the first set of one or more operations in command stream in trace buffer further includes evaluating the control flow statement determining an execution path of the first set of one or more operations based at least in part on the evaluation of the control flow statement flattening the execution path and storing data associated with the flattened execution path in the trace buffer . In some examples the method further includes scheduling by the command processor the first set of one or more operations associated with the flatted execution path for execution by the at least one processor.

In some examples a result of executing the second set of one or more operations in command stream depends upon the contents of the one or more memory locations in the memory stored in the trace buffer prior to the interrupting by the command processor of the processing of the command stream regardless of additional one or more write operations to the one or more memory locations in the memory or one or more read operations from the one or more memory locations in the memory subsequent to the interrupting of the processing of the command stream.

In some examples command stream includes a plurality of checkpoints that separates one or more blocks of operations in command stream . In some examples replaying at least a portion of command stream based at least in part on the data stored in trace buffer includes resuming processing of command stream starting from a most recently encountered checkpoint of the plurality of checkpoints in command stream .

In one or more examples the functions described may be implemented in hardware software firmware or any combination thereof. If implemented in software the functions may be stored on or transmitted over as one or more instructions or code on a computer readable medium. Computer readable media may include computer data storage media or communication media including any medium that facilitates transfer of a computer program from one place to another. Data storage media may be any available media that can be accessed by one or more computers or one or more processors to retrieve instructions code and or data structures for implementation of the techniques described in this disclosure. By way of example and not limitation such computer readable media can comprise RAM ROM EEPROM CD ROM or other optical disk storage magnetic disk storage or other magnetic storage devices. Disk and disc as used herein includes compact disc CD laser disc optical disc digital versatile disc DVD floppy disk and Blu ray disc where disks usually reproduce data magnetically while discs reproduce data optically with lasers. Combinations of the above should also be included within the scope of computer readable media.

The code may be executed by one or more processors such as one or more digital signal processors DSPs general purpose microprocessors application specific integrated circuits ASICs field programmable logic arrays FPGAs or other equivalent integrated or discrete logic circuitry. Accordingly the term processor as used herein may refer to any of the foregoing structure or any other structure suitable for implementation of the techniques described herein. In addition in some aspects the functionality described herein may be provided within dedicated hardware and or software modules configured for encoding and decoding or incorporated in a combined codec. Also the techniques could be fully implemented in one or more circuits or logic elements.

The techniques of this disclosure may be implemented in a wide variety of devices or apparatuses including a wireless handset an integrated circuit IC or a set of ICs i.e. a chip set . Various components modules or units are described in this disclosure to emphasize functional aspects of devices configured to perform the disclosed techniques but do not necessarily require realization by different hardware units. Rather as described above various units may be combined in a codec hardware unit or provided by a collection of interoperative hardware units including one or more processors as described above in conjunction with suitable software and or firmware.

Various aspects of the disclosure have been described. These and other aspects are within the scope of the following claims.

