---

title: System and method for storing/caching, searching for, and accessing data
abstract: A system for persistently maintaining data using a network for data packets is provided. The system includes a transmission medium associated with the network, a plurality of switches operatively connected to the transmission medium. Each switch has an intelligent network controller adapted for delivering the data packets to a device operatively connected to the intelligent network controller in response to a request for the data packets from the device and further adapted for re-transmitting unexpired data packets over the network.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09491104&OS=09491104&RS=09491104
owner: Lightwaves Systems, Inc.
number: 09491104
owner_city: Cedar Rapids
owner_country: US
publication_date: 20141205
---
This application is a Continuation application of U.S. Ser. No. 14 016 358 filed Sep. 3 2013 which is a Continuation application of U.S. Ser. No. 13 410 787 filed Mar. 2 2012 now U.S. Pat. No. 8 542 695 issued Sep. 24 2013 which is a continuation of U.S. Ser. No. 10 345 766 filed Jan. 16 2003 now U.S. Pat. No. 8 165 146 issued Apr. 24 2012 which is a conversion of and claims priority to prior U.S. Provisional Patent Application Ser. No. 60 366 803 filed Mar. 22 2002 entitled SYSTEM AND METHOD FOR STORING CACHING DATA ON TRANSMISSION INFRASTRUCTURE Ser. No. 60 349 072 filed Jan. 16 2002 entitled METHOD AND SYSTEM FOR STORING DATA ON TRANSMISSION MEDIUMS Ser. No. 10 345 766 filed Jan. 16 2003 now U.S. Pat. No. 8 165 146 issued Apr. 24 2012 is also a Continuation in Part of U.S. patent application Ser. No. 09 698 793 filed Oct. 27 2000 entitled METHOD OF TRANSMITTING DATA INCLUDING A STRUCTURED LINEAR DATABASE now U.S. Pat. No. 6 868 419 issued Mar. 15 2005 which claims priority to 60 162 094 filed Oct. 28 1999 60 163 426 filed Nov. 3 1999 and 60 220 749 filed Jul. 26 2000 all of which are entitled STRUCTURED LINEAR DATABASES and are all herein incorporated by reference in their entirety.

The present invention relates generally to storing caching data directly on transmission mediums and network transmission hardware. More particularly the present invention relates to systems and methods for searching accessing querying and performing computations of locally or globally distributed data stored cached in the form of data packets protocol data units PDU or protocol payloads etc. continuously transmitted on a telecommunication network and or on a microprocessor data bus or electronic circuit for the life of the data packet s and or data stream s .

Each year it is estimated that between 1 and 2 billion gigabytes of unique information is created and a high percentage of this information is created in a digital format. Of all that data 90 percent is expected to be stored cached digitally. Contributing to this is the rapid growth of digitized books magazines videos music and other rich content and mass access data. This growing volume of data is often located remotely must be transported between computing devices and stored cached in a highly secure accessible method. The exponential growth rate of generated data is expected to outpace improvements in communication bandwidth and storage caching capacity in the near future. Consequently this creates an urgent need to store cache digital information in new ways that make it accessible at high speeds on a storage caching medium and where the medium may be exponentially improved.

The access speed to digital information is ultimately controlled by the input output I O capacity of any electronic device. I O is the lifeblood of computing getting relevant information into and out of the processor compute device or appliance to the end user on a timely basis. This has always been true but never so much as in a networked computing environment.

Many associated I O problems impede high speed access to remotely stored cached data. Ethernet and TCP IP are widely accepted but inefficient protocols which are used to drive LANs WANs and ultimately the Internet. The TCP IP protocol suite has proven itself a basic foundation for communications of all kinds over essentially unreliable networks. But that fact alone makes it inefficient and creates network latency issues. TCP IP based protocols have a complex layered design with many inter layer dependencies that can easily demand extensive processing and significant buffer memory to implement. Open Systems Interconnection OSI is a worldwide communications standard that defines a networking framework for implementing protocols in seven layers. Handling gigabit class network traffic servicing interrupts moving data through long code paths and numerous kernel to application context switches are all expensive operations. Together they yield long message latencies and use up a significant percentage of available processor power.

Another problem that impedes the high speed access to data is the venerable Peripheral Component Interconnect PCI shared data bus which is one of the most prevalent I O architecture for compute devices. For example the bandwidth for board level transfer and processor to cache transfer on a typical PC is much higher than from the PC to a peripheral network device via PCI bus.

Data storage caching centers have developed a variety of specialized networks such as SANs Storage Area Networks specialized cluster links NAS Network Attached Storage and RAID Redundant Array of Independent Disks systems in order to improve access to local and remotely distributed data. However as RAID NAS Fast and Gigabit Ethernet SANs and SCSI Small Computer System Interface links are usually implemented with PCI adapter cards or PCI components all of the data traffic on these network devices is ultimately throttled by the low speed I O devices.

I O problems are further complicated by the architecture of a typical data storage caching center. For example a data storage caching center for Web applications or Business to Business B2B exchanges may have hundreds of servers all requiring shared access to terabytes of file storage caching. The workload is defined by server requests coming in through networked routers switches firewalls load balancers caching appliances and the like. Since file sharing by multiple servers is a fundamental requirement of this environment storage caching is usually aggregated into shared storage caching pools accessed by the servers using a file access protocol such as Network File System NFS . The result is a complex and sophisticated infrastructure that has exploded in importance in just the past few years.

Consequently there are challenges surrounding how individual servers fulfill growing client requests and connections from the outside world and how these challenges impact organization of complex and discrete files data databases and storage. PCI X and Infiniband are two solutions that will greatly improve I O performance and therefore increase broadband access to remotely stored cached digital information.

Infiniband is an architecture and specification for data flow between processors and I O devices that promises greater bandwidth and almost unlimited expandability in tomorrow s computer systems. In the next few years Infiniband is expected to gradually replace the existing Peripheral Component Interconnect PCI shared bus approach used in most of today s personal computers and servers. Offering throughput of up to 2.5 gigabytes per second and support for up to 64 000 addressable devices this architecture also promises increased reliability better sharing of data between clustered processors and built in security. Infiniband is the result of merging two competing designs Future I O developed by Compaq IBM and Hewlett Packard with Next Generation I O developed by Intel Microsoft and Sun Microsystems. For a short time before the group came up with a new name Infiniband was called System I O.

PCI X Peripheral Component Interconnect Extended is a new computer bus technology the data pipes between parts of a computer that increases the speed data can move within a computer from 66 MHz to 133 MHz. This technology was developed jointly by IBM HP and Compaq and PCI X doubles the speed and amount of data exchanged between the computer processor and peripherals. With the current PCI design one 64 bit bus runs at 66 MHz and additional buses move 32 bits at 66 MHz or 64 bits at 33 MHz. The maximum amount of data exchanged between the processor and peripherals using the current PCI design are 532 MB per second. With PCI X one 64 bit bus runs at 133 MHz with the rest running at 66 MHz allowing for a data exchange of 1.06 GB per second. PCI X is backwards compatible meaning that you can for example install a PCI X card in a standard PCI slot but expect a decrease in speed to 33 MHz. You can also use both PCI and PCI X cards on the same bus but the bus speed will run at the speed of the slowest card. PCI X is more fault tolerant than PCI. For example PCI X is able to reinitialize a faulty card or take it offline before computer failure occurs.

PCI X was designed for servers to increase performance for high bandwidth devices such as Gigabit Ethernet cards Fibre Channel Ultra3 Small Computer System Interface and processors that are interconnected as a cluster. Compaq IBM and HP submitted PCI X to the PCI Special Interest Group Special Interest Group of the Association for Computing Machinery in 1998. PCI SIG approved PCI X and it is now an open standard that can be adapted and used by all computer developers. PCI SIG controls technical support training and compliance testing for PCI X. IBM Intel Microelectronics and Mylex plan to develop chipsets to support PCI X. 3Com and Adaptec intend to develop PCI X peripherals.

To accelerate PCI X adoption by the industry Compaq offers PCI X development tools at their Web site.

When remotely storing digital information the following criteria should be considered the frequency of read access frequency of write access size of each access request permissible latency permissible availability desired reliability security etc. Some data is accessed frequently yet rarely changed. Other data is frequently changed and requires low latency access. These factors should be taken into account but are often compromised in the one size fits all design and operation of conventional data storage caching systems.

Preferably a data storage caching system should be designed to be scaleable so a user can purchase only the capacity needed at any particular time. High reliability and high availability are also considerations as data users want remote access to data and have become increasingly intolerant of lost damaged and unavailable data. Unfortunately current conventional data storage caching architectures compromise these factors and no single data storage caching architecture provides a cost effective highly reliable highly available and dynamically scaleable solution.

Today the end user can have high speed access to streaming and non streaming data in the form of websites electronic text documents graphic images or spreadsheets stored cached remotely by purchasing telecommunication bandwidth in the form of a T 1 or a fractional T 3 line a Digital Subscriber Line DSL or through their cable TV provider using a cable modem. However no conventional digital information storage caching system addresses the needs of the end users desire for widespread low latency access to streaming and non streaming multi media data in the form of music TV shows movies radio broadcasts web casts etc.

Advances in fiber optic transmission technology and its declining cost have enabled upgrades in front end network systems such as cable TV network trunk and feeder systems. Traditionally these systems have increased the bandwidth of a telecommunication network sufficiently to provide each subscriber his own dedicated channel to the head end for receiving compressed digital video. In addition direct broadcast satellite technology and other emerging wireless communication technologies also provide dedicated multimedia and video channels between a large number of end users and the server systems. Personal computers and set top boxes for the end user are also emerging which enable networked multimedia applications.

The above mentioned improvements may typically improve the overall performance of current video server systems by a factor of only two or four times whereas the current need in the industry requires improvements in the range of 100 to 1000 times to make interactive streaming video services economically feasible.

While the end user client system and the front end network system infrastructure is evolving rapidly to meet the requirement of non streaming and interactive multimedia services the constraints of current server architectures continue to be expensive and impractical for delivering these services. Current server systems are unable to process the large number of data streams that are required by streaming multimedia and video services. The current choices of servers are typically off the shelf mainframe or workstation technology based parallel computing systems. The hardware and software in both cases is optimized for computation intensive applications and for supporting multiple concurrent users time sharing with very limited emphasis on moving data to and from a telecommunication network interface and the Input Output I O device.

Another key to acceptable multimedia audio and video streaming is the concept of Quality of Service QoS . Quality of Service generally refers to a technique for managing computer system resources such as bandwidth by specifying user visible parameters such as message delivery time. Policy rules are used to describe the operation of data packet s to make these guarantees. Relevant standards for QoS in the IETF Internet Engineering Task Force are the RSVP Resource Reservation Protocol and COPS Common Open Policy Service protocols. RSVP allows for the reservation of bandwidth in advance while COPS allows routers and switches to obtain policy rules from a server.

A major requirement in providing Quality of Service is the ability to deliver multi media frame data at a guaranteed uniform rate. Failure to maintain Quality of Service may typically result in an image that is jerky or distorted.

Traditional server system architectures have not been equipped with the functionality necessary for providing Quality of Service on a large scale. With an increasing load on server systems to provide streaming multimedia applications an increased volume of user end clients and the above mentioned deficiencies in current server system technology a need exists to provide a server system architecture or a new data storage caching system with enhanced search and access capabilities which will be able to address the need of low latency high speed access to data.

U.S. Pat. No. 5 758 085 assigned to the International Business Machine IBM Corporation partially addresses the above named problems by providing a plurality of intelligent switches in a Storage Area Network SAN . When the end user client makes a request to receive video and multimedia data a request is sent to the host processor which in turn sends a request to a plurality of intelligent switches on the SAN. The intelligent switches include a cache for storing the requested data. The data is relayed directly from these switches to the end user client requesting the multimedia data.

While the IBM system described above provides for the storage caching of data onto switches it does not allow the individual switches to cooperate together as a distributed architecture in order to pool bandwidth together to supply the backbone network nor does it allow for the data to reside directly on a telecommunication network medium. Current technology allows for only a 1 2 gigabyte data stream coming out of a single peripheral device such as an array of disks wherein a telecommunication network backbone may accommodate a 10 gigabyte or higher data stream. Also in the above referenced patent the individual switches are not capable of working together to distribute a delivery request over multiple switches for load balancing and streaming of the requested data.

United States Patent Application 20010049740 filed by Karpoff addresses many of the shortcomings of the previously referenced IBM U.S. Pat. No. 5 758 085 by describing various systems and methods for delivering streaming data packets to a client device over a telecommunication network in response to a request for the data packets from the client device. The client request is received by a server or a controller device that is typically located on a network switch device. If received by a server the server sends a request to the intelligent network controller device for the transfer of the requested data to the client.

In addition to the data storage network architecture and bus problems discussed above rapid access to and intelligent searching of data is impeded by the requirements of traditional relational database structures.

It has been 16 months since terrorists attacked the United States and federal agencies are struggling to find a way to best share information to prevent future acts of terrorism. The key to fighting terrorism is the real time free flow of information between federal agencies as well as with state and local governments. More than ever before successful interdiction is dependent upon collecting analyzing and appropriately sharing information that exists in different databases transactions and other data points. The effective use of accurate information from diverse sources is critical to the success in the fight against terrorism. There is no lack of desire to share information in a cooperative way however there is no easy and inexpensive solution to accomplish the sharing of data stored in traditional database structures.

Recently the FBI has chosen to pursue investigative data warehousing as a key technology for use in the war against terrorism. This technology uses data mining and analytical software to sift through vast amounts of digital information to discover patterns and relationships that point to potential criminal activity. The same technology is also widely used in the commercial sector to track consumer activity and predict consumer behavior.

The FBI plans to build a data warehouse that receives information from multiple FBI databases and sources. Eventually this warehouse might receive and send warehoused data to and from other law enforcement and intelligence agencies. In the war against terrorism new information technology is critical to analyzing and sharing information on a real time basis. Also the FBI is working to focus on analytical capabilities far more than it has in the past. For example the FBI might want to put in a request for information on flight schools and access all the reports the FBI has written on flight schools from various FBI databases and then analyze them using artificial intelligence software however they are far from having this capability which is known as enterprise data warehousing in the business world.

Data warehousing and data analysis modeling tools are used extensively in the commercial sector to monitor sales in stores and automatically order new stock when inventories run low monitor individual customer buying habits and try to influence consumer buying. The FBI is considering applying the same analysis techniques tools currently used by the private sector to search vast collections of data to identify suspicious trends. For example analyzing data collected in various FBI databases and by the Immigration and Naturalization Service the CIA and other agencies could indicate suspicious activity that now is overlooked. Add to that data from credit card companies airlines banks phone companies and other commercial entities and actions and events that previously seemed innocent when considered separately begin to trigger alarms when considered in context with other activities.

Most business executives make critical decisions based on data that s been cut and sliced for them by information managers. If executives could get closer to their core business data they would increase their odds of making better informed decisions. The promise of business intelligence software is to make existing enterprise databases accessible through easy to use analytical and reporting functions. Business intelligence software quickly and cheaply allows organizations to extract additional value from existing data warehouses and enterprise systems.

Business intelligence software is nearly useless for companies that have dirty data. Before any quality feedback can be produced databases must have consistent categories language and maintenance. Unfortunately for most organizations due to mergers and acquisitions the tendency is toward chaos. They end up trying to use incompatible databases to force new data into legacy information systems. Consequently uniform data entry protocols are lacking or ignored making it difficult to implement changes. For example a data field such as a supplier s name can be entered any number of ways by employees. Cleanup of such dirty data can be costly and can take from a few months to a few years.

Although the government has a huge effort underway for implementing data mining business intelligence and on line analytical processing OLAP of transactions stored in traditional structured data sources intelligence agencies are in need of unstructured textual analysis to find patterns in unstructured data.

One company Maya Viz combines various elements of collaboration knowledge management and business intelligence to bring data into a visual form that can be manipulated and shared. This technology was first deployed in military command situations. The company s component architecture aims to transform relational database information pieces into nuggets visualize them and then through peer to peer connections allow people to share the information with anyone.

Tacit Knowledge System s software automatically discovers expertise and activity across large organizations and connects people and information. This software taps into existing content sources such as document repositories and e mail archives to discover individual expertise and activity and then makes end users aware of relevant colleagues and data.

The U.S. has approximately 170 000 people working together to prevent attacks on the United States. This is an incredibly complex process using multiple information technology systems to record information about case research various memos etc. In addition a system that could tap into all those multiple information repositories and figure out who is working on what would be phenomenally valuable to make critical connections between different agencies departments and analysts.

However current data mining warehousing and business intelligence technologies are expensive and become difficult to implement particularly when multiple federal state and local agencies become involved all of which use their own proprietary technologies and data formats. The constraint of these current data technologies is the requirement for predetermining storage format for example table structure and upfront analysis.

There is therefore a need for a method of storing caching searching accessing querying and performing computations on data in the form of data packet s and or data streams continuously transmitted for the life of the data on a telecommunication network and or a microprocessor data bus or electronic circuit. The resulting solution needs to be cost effective avoid traditional I O problems overcome the limitations of traditional relational database structures and avoid other problems.

A general object feature or advantage of the present invention is the provision of a method for storing caching data which overcomes the problems found in the prior art.

A further object feature or advantage of the present invention is the provision of a method to store cache data packet s by allowing them to be continuously transmitted on a telecommunications network and or a microprocessor data bus or electronic circuit for the life of the data packet s .

A further object feature or advantage of the present invention is the provision of a method to store cache data stream s by allowing them to be continuously transmitted on a telecommunications network and or a microprocessor data bus or electronic circuit for the life of the data stream s .

A further object feature or advantage of the present invention is the provision of a method for data storage caching that is highly scalable through additional access points.

A further object feature or advantage of the present invention is the provision of a method for data storage caching that is highly scalable through additional parallel connections.

A further object feature or advantage of the present invention is the provision of a method for data that can be easily erased without leaving a trace.

A further object feature or advantage of the present invention is the provision of a method for data storage caching that is redundant and fault tolerant.

A further object feature or advantage of the present invention is the provision of a method for data storage caching system that interfaces with public protocols and standards.

A further object feature or advantage of the present invention is the provision of a method for data storage caching system that interfaces with proprietary protocols and standards.

A further object feature or advantage of the present invention is the provision of a method to access data stored cached in the form of continuously transmitted data packet s and or data stream s .

A further object feature or advantage of the present invention is the provision of a method to search for data stored cached in the form of continuously transmitted data packet s and or data stream s .

A further object feature or advantage of the present invention is the provision of a method to query data stored cached in the form of continuously transmitted data packet s and or data stream s .

A further object feature or advantage of the present invention is the provision of a method to use data stored cached in the form of continuously transmitted data packet s and or data stream s as a chaotic database.

A further object feature or advantage of the present invention is the provision of a method to use data stored cached in the form of continuously transmitted data packet s and or data stream s as a structured linear database.

A further object feature or advantage of the present invention is the provision of a method for performing computations on data stored cached in the form of continuously transmitted data packet s and or data stream s .

One or more of these and or other objects features or advantages of the present invention will be apparent based on the Specification and claims that follow.

According to one aspect of the present invention the present invention provides for storing data by persistently maintaining the data on a network through retransmission. The data can be associated with expiration properties. The expiration properties can include geographical information and or time attributes. The data can be in packets or streams.

Referring to previously filed U.S. Provisional Patent No. 60 349 072 to Melick et al FiberSan was used as a name for one aspect of the present invention and it is sometimes referred to as DataSpace throughout this disclosure and is also referred to as a storage caching system or a network when appropriate. The term network data packet will now be referred to as data packet . The present invention relates generally to storing caching searching accessing querying and performing computations of data persistently maintained through retransmission directly on the telecommunication network and or a microprocessor data bus or electronic circuit. More particularly the present invention relates to systems and methods for accessing searching querying and performing computations on locally or globally distributed data which are stored cached in the form of data packets protocol data units PDUs or protocol payloads etc. continuously transmitted on a telecommunication network and or on a microprocessor data bus or electronic circuit for the life of the data packet s .

As used herein and unless otherwise specified the term data is to be construed broadly to refer to a data packet protocol data unit protocol payload data stream or other form of data.

As used herein and unless otherwise specified the term network is to be construed broadly to refer to a network a telecommunication network or other type of network. It is to be understood that data present on a microprocessor data bus or electronic circuit associated with the network is still present on the network and the microprocessor data bus or electronic circuit of the device can be considered part of the network in this context.

As used herein the term storing is to include caching and querying is to include searching . These and other terms that may have different uses or particular connotation in particular contexts are to be construed broadly in defining the present invention.

Data content and applications have historically resided at the core of the Internet. However in an effort to improve the performance of content delivery distributed computing has evolved. Distributed computing is the process of moving content and applications closer the end user in what is referred to as the edge . To support this transition enterprises are creating their information technology systems on top of the Internet Protocol IP which elevates the need for distribution and computing closer to the edge .

The present invention allows data packets to reverberate on a telecommunication network and or microprocessor data bus or electronic circuit remaining unresolved for delivery on demand for the life of the data packet s and or data stream s . The present invention overcomes limitations associated with existing data storage caching accessing and searching technologies. The present invention creates unique new revenue opportunities for carriers to better utilize their telecommunication network assets.

In the preferred embodiment the present invention provides a number of advantages over traditional remote data storage caching accessing search querying and computational methods. These advantages can include 1 reducing overall latency to and from remote data source s 2 providing direct access to data 3 providing parallel multicasting capabilities 4 improving multicasting efficiency in telecommunication networks 5 reducing latency by moving the data storage caching and data storage caching logic to a telecommunication network and or microprocessor data bus or electronic circuit which allows the synchronized communication between individual intelligent network controller devices 6 eliminating the requirement for server or disk access by moving data storage caching directly onto the telecommunication network and or microprocessor data bus or electronic circuit 7 improving Quality of Service for streaming and non streaming data as a result of reduced latency and increased bandwidth 8 increasing the overall throughput and or reliability by implementing RAID methods on the intelligent network controller device s for example utilizing RAID to mirror the data across two or more separate DataSpaces 9 reducing the time required for data backups data replication and distribution by moving the administrative functions of data storage caching onto the intelligent network controller device and 10 increasing availability by caching multiple copies of the same data which is particularly useful for multi media.

In the preferred embodiment the present invention can 1 lower the cost to store cache data 2 lower overall latency and improving access speeds 3 provide new functionality that enables a host of new applications services to service providers and their customers 4 provide a geographic tag to improve data cache selection and data routing and 5 provide new data search and query capabilities.

The present invention provides systems and methods for storing caching accessing querying searching and performing computations of data on telecommunication network infrastructure which includes mediums such as but not limited to fiber optic cable Category 5 wire coaxial cable airwaves ground waves vacuum space etc. which have been partitioned by the present invention s switches which also may serve as nodes on a telecommunication network. The present invention s switches are enabled with intelligent network controller devices which are capable of copying and or forwarding data streaming or non streaming stored cached in the form of data packets PDUs or protocol payloads to a client device over a telecommunication network and or microprocessor data bus or electronic circuit in response to a request for data from a client device. The client device s request for data is received by a server or directly by the intelligent network controller device. Alternatively the server may send a request to an intelligent network controller device to control the forwarding of the requested data packet s stored cached to the client.

The switches and or intelligent network controller devices of the present invention are not restricted in location and can be accessed remotely by the client. They can be co located on the same physical device as the client and attached via a network data bus or electronic circuit. As an example a switch and intelligent network controller device may be co located on a card or device interconnected by PCI or USB bus on the same computer.

In a preferred embodiment the present invention delivers data stored cached on a telecommunication network infrastructure to a client device making a request for data over a public and or private telecommunication network such as but not limited to a Wide Area Network WAN a Metropolitan Area Network MAN a Local Area Network LAN a Wireless Wide Area Network WWAN a Wireless Local Area Network WLAN a Personal Area Network PAN or a Broadcast Area Network BAN or any combination or sub combination of these or other telecommunication networks and or microprocessor data bus or electronic circuit.

Alternatively in a preferred embodiment the client device s request for data may also be received directly by an intelligent network controller device. The present invention s intelligent network controller device includes the processing capability required for identifying copying or transferring the data and delivering it directly to the client device without involving a server system. The data request may be mirrored to another controller device to handle the data processing and delivery functions. In other cases the controller device may coordinate the delivery of the requested data using one or more other similar controller devices in parallel.

In another embodiment of the present invention data requests for large amounts of data are handled by the present invention s intelligent network controller devices working in parallel synchronization to deliver data packets stored cached on various channels of a storage system or on various disparate storage systems.

In another embodiment of the present invention a storage system of the present invention may be expanded beyond the geographical bounds imposed by the present invention s switches which are used to partition a telecommunication network and or microprocessor data bus or electronic circuit to include a client device as one of the nodes in the network. In this way a client device can efficiently and continually broadcast updated data packets.

In another embodiment of the present invention a the present invention may be used as data storage cache on a microprocessor or data bus or electronic circuit.

These embodiments of the present invention represent various architectures on which data may be stored cached in the form of data packets PDUs or protocol payloads etc. continuously transmitted on a telecommunications network and or a microprocessor data bus or electronic circuit for the life of the data packet.

Some of the unique applications for the present invention include but are not limited to a chaotic database a DNS server update mechanism a storage cache system for data file systems and meta data mobile data systems high read use decision support systems content management and geographical routing and as a support technology for stream querying and grid computing.

Reference to the remaining portions of the specification including the drawings and claims will realize other features and advantages of the present invention. Further features and advantages of the present invention as well as the structure and operation of various embodiments of the present invention are described in detail below with respect to the accompanying drawings. In the drawings like reference numbers indicate identical or functionally similar elements. Additionally the left most digit s of a reference number identifies the drawing in which the reference number first appears.

The present invention generally relates to storage caching systems DataSpace . In particular the present invention relates to methods and systems for storing caching accessing searching querying and performing computations on locally or globally distributed data stored cached in the form of data packets PDUs or protocol payloads etc. continuously transmitted on a telecommunication network and or a microprocessor data bus or electronic circuit. In a DataSpace the term data storage caching does not imply a static physical storage caching device but is defined as data in the form of data packets PDUs or protocol payloads etc. continuously transmitted on telecommunication network and or microprocessor data bus or electronic circuit for the life of the data packet s .

DataSpace complements two existing computing concepts stream querying and grid computing. DataSpace provides a new data storage cache technology that increases the speed and methods of data access searching querying and computing capabilities. A DataSpace differs from stream querying in that it adds a level of persistence to data streams by continuously transmitting them on the telecommunications network and or a microprocessor data bus or electronic circuit.

The following table illustrates a comparison of key metrics between a typical disk storage medium Seagate Cheetah disc drives and a 244 mile long DataSpace.

DataSpace also facilitates access within the grid computing environment by providing an alternative method for the distribution storage and caching of data to remote or grid interconnected computing resources and services. In addition DataSpace can aid in the grid computing support and management systems by storing directory of services meta services resource and service access and availability information.

The STREAM project at Stanford University is supported in part by the National Science Foundation under grant IIS 0118173. This research project addresses applications such as network monitoring telecommunications data management web personalization manufacturing sensor networks and others in which data takes the form of continuous data streams rather than finite stored data sets. Traditional database systems and data processing algorithms are ill equipped to handle data streams effectively and many aspects of data management and processing need to be re examined in the presence of data streams.

The STREAM project is investigating data management and processing in the presence of multiple continuous rapid time varying data streams. Their work addresses problems including basic theory results algorithms and implementing a comprehensive prototype data stream management system. The STREAM project and other data stream technologies are relevant to the present invention as DataSpace is in fact a persistent data stream which is continuous although more repetitious in nature rapidly varying and can be created from a compilation of multiple source streams. Therefore the results and findings of the STREAM project and related work will be fundamentally useful in creating a streaming data manager for the present invention.

The data packets PDUs and or protocol payloads used by the present invention can be defined by any non proprietary or proprietary protocols. Examples of non proprietary protocols for defining data packets include but are not limited to Asynchronous Transfer Mode ATM frames Internet Protocol IP packets or Cellular Digital Packet Data CPCD packets commonly known as IP over wireless . Two proprietary protocols for defining data packets are Novell s IPX SPX protocol and Apple Computer s AppleTalk protocol. Closed network systems used by financial institutions government or the military might use a proprietary data packet protocol internally particularly where security is an issue. A unique proprietary data packet protocol in which a data packet s payload is defined and structured as a linear database is disclosed in the previously mentioned U.S. patent application Ser. No. 09 698 793. Another proprietary data packet protocol Lightwaves Data Link LDL was designed for use with the system described in U.S. Provisional Patent application 60 376 592 to Melick et al entitled High Number Base Encoded Ultra Wideband Over Guided Lines And Non Guided Narrow Band Radio incorporated herein by reference. This proprietary protocol is based on Simple Data Link SDL which is a variable length ATM protocol.

Referring to the general topology of a DataSpace used in the preferred embodiment and several of the alternative network embodiments of the present invention is shown. A DataSpace is comprised of three basic components 1 switches are equipped with a intelligent network controller device as defined in 2 working telecommunication medium and spare telecommunication medium to couple DataSpace switches and 3 a data link to connect the DataSpace to a telecommunication network.

The switches can be configured in many different form factors such as but not limited to carrier class soft switches data network elements such as switches routers hubs and bridges programmable hardware with architecture similar to a Lucent Excel LNX programmable switch host controllers etc. The functions of the switch may be reduced to a microprocessor such as but not limited to an Application Specific Integrated Circuit ASIC or Field Programmable Gate Array FPGA for deployment in a client device such as but not limited to a personal computer cable TV set top box PDA ATM radio as shown in and which enables the client device a personal computer cable TV set top box PDA ATM radio to be used as one of the nodes in a DataSpace .

The DataSpace switches can also be configured to operate as a new class of telecommunication switches based on an emerging technology known as XML switching. XML switching deployed on switches may use XML as a universal translator which can automatically adapt to and transform to a myriad of XML schemas protocols and standards which have been and are being developed for a variety of industries and applications. XML switching intelligence on a telecommunication network will enable a freer and faster flow of information from the DataSpace to other DataSpaces as shown in and systems applications and end users.

Sarvega Inc. manufactures Extensible Mark up Language XML switches powered by their XML Event Stream Operating System XESOS technology to allow the intelligent routing of XML based data at wire speeds.

The explosive growth of XML usage in corporate IT infrastructures has made it necessary to address the performance issues inherent in XML processing. XML processing tasks such as XSL transformation schema validation XPATH based classification XML security and intelligent routing are all inherently processing intensive. This has placed a significant burden on existing server infrastructure that is not optimized to perform these tasks. Sarvega s switches have been designed to provide the specialized processing and intelligence required to transparently offload XML processing from the general purpose server infrastructure.

Sarvega s XML switches could be modified to allow DataSpace switch logic to reside directly on their switch in order to give them the advantages associated with continuously transmitted data packet s or data streams containing information within XML constructs. This combination of Sarvega s mature XML processing integrated with the present invention s switching and processing logic would be one method of enabling applications such as a chaotic database.

Alternatively Sarvega s XML switches could be incorporated as a stand alone component s in a DataSpace controlled by present invention s switching hardware and logic.

The present invention can incorporate XML switching technology to store and tag geographic information for data packets and be used for subsequent routing on a DataSpace . Assigning and storing a DataSpace packet s information can be a self provisioning feature particularly for mobile devices that employ radio frequency positioning technology such as the NAVSTAR Global Positioning System GPS Loran Shoran or the emerging technology for precise local positioning known as ultra wideband UWB . Another self provisioned method which is unique to the present invention uses geographic information related to an end user or hardware device particularly for stationary devices such as desktop personal computers Automatic Teller Machines ATM fax machines etc. This end user information can be acquired for use on the DataSpace through the use of an onboard software utility which maps manually input information such as zip code address or telephone number to a latitude and longitude.

In addition to the above mentioned self provisioning methods for obtaining and incorporating geographic information for use in intelligent data packet routing there are many other public and private sources for obtaining and provisioning geographic information as described in U.S. Provisional Patent Application Ser. No. 60 732 505 to Melick et al. entitled UNIFED MESSAGE SYSTEM incorporated herein by reference. The United States Postal Service databases and systems map longitude and latitude to street address and zip code. Corporate entitles such as telephone companies maintain cross reference databases for telephone number to latitude and longitude information Also fee based service providers such as Quova map IP addresses to latitude and longitude.

Geographical information obtained from of the above mentioned means can be used to augment the intelligent routing capabilities of DataSpace switches in order to cache data particularly data that is geographically demographically sensitive closer to an end user.

The geographical information and or time information can be used in associating expiration properties with the data. Based on expiration or related binding properties access to data can be limited. For example data can be accessible only during pre defined time frames. Geographical and time information can be combined to create more complex binding properties.

A DataSpace uses a telecommunication network infrastructure to store cache data in the form of data packets PDUs or protocol payloads etc. continuously transmitted on the network for the life of the data packet s or data stream s . The time of transit between DataSpace switches will be relatively short in comparison to the time stored in the Random Access Memory RAM on these switches. The RAM will contain a processing buffer for sending a data packet and subsequent receiving and re sending of the same data packet. This buffer may also be provided by intelligently routing data packets over a minimum length of network transmission medium to buffer the time required to process a data packet. On a network the length of transmission medium can be reduced by intelligently routing data packets over multiple channels to buffer the time between the sending and receiving of the same data packet. Alternatively an air gap between terrestrial satellite ground stations and orbiting satellites may be used to create a buffer between the sending and receiving of the same data packet. A buffering device on a DataSpace that uses fiber optic medium could be created in the future by intentionally slowing light down or even stopping it completely by directing it into super cooled sodium atoms as described in a Jan. 25 2001 article by Bill Delaney posted on the CNN.com web site C WINDOWS Temporary Internet Files OLK40D4 CNN.com US Bill Delaney Harvard scientist stops light January 25 2001.html .

For matters of practicality and creating easy migration paths to the widespread use of DataSpaces in the marketplace the DataSpace switches are designed to receive data packets for storage caching over data link using any standard messaging protocol. Typical examples of messaging protocols used in accordance with the present invention for sending messages between the various nodes on the DataSpace include but are not limited to Internet Small Computer System Interface iSCSI Small Computer System Interface SCSI Fiber Channel FC Infiniband IB Gigabit Ethernet GE Ten Gigabit Ethernet 10GE and Synchronous Optical Network SONET . Any messaging protocol or combination of messaging protocols which allows for the communication of messages between the various nodes of a telecommunication network are intended to be within the scope of the invention.

In the preferred embodiment of the present invention the DataSpace switches are coupled to working transmission medium and spare transmission medium configured in a bi directional ring topology. In the preferred embodiment of the present invention the working transmission medium and spare transmission medium are fiber optic cabling but in other non carrier class implementations the transmission medium could be copper or even airwaves. The spare transmission medium or what is commonly referred to as protect ring fibers in the telecommunication industry provide redundancy and greater reliability as a mechanism to re route traffic in the opposite direction in case working transmission medium fails. In addition if a switch on the working transmission medium fails the back up switch on the spare transmission medium will automatically take over.

The present invention can be deployed on a fiber optic network with a modified version of a standard protocol such as but not limited to SONET. SONET is a standard way to multiplex high speed traffic from multiple vendors multiplexing onto fiber optic backbone cabling. SONET is a four layered protocol. Layer is the Photonic Layer which converts electronic signals into optical signals and vice versa. Layer the Section Layer monitors the condition of the transmission between the SONET equipment and optical amplifiers. Layer is the Line Layer which synchronizes and multiplexes multiple streams from multiple sources into a single data stream in a uniform format. Layer is the Path Layer which assembles and disassembles voice and data into frames. In the present invention the Path Layer could use a modified addressing convention to identify which data packets are to be stored cached on the DataSpace by continuously transmitting them on the storage caching network for the life of the data packet. Dense Wavelength Division Multiplexing DWDM is a new high speed replacement technology for SONET which can also be used as the basis to create a DataSpace .

By increasing the size of a telecommunication network and or speed of the network elements such as switches bridges and or routers or by adding DataSpace switches a DataSpace is a highly scalable and load balanced data storage caching solution without adding much complexity.

In the present invention data integrity recovery and re construction can be accomplished by a variety of methods in the case of transmission or equipment failure or maintenance.

Re Directed Data In the event a DataSpace switch or other hardware is removed or ceases to function properly the DataSpace switch responsible for sending data packet s to another DataSpace switch can re route them to a back up DataSpace switch or another DataSpace. The process of re directing data packet s can be manual and or automated.

RAID type Implementation Critical data residing on a DataSpace may be protected using a similar method found in RAID algorithms. Separate and redundant DataSpaces can be used to implement the striping and or mirroring of data across multiple DataSpaces. Under the proper mirroring configuration if one DataSpace becomes inoperable or inaccessible another DataSpace s can re construct data and service requests as needed.

Integrity Node A DataSpace integrity node can be placed on the DataSpace to check for any number of possible situations indicating corrupted or missing data. This node could be used in conjunction with the RAID type Implementation for data recovery. The Integrity Node could be directed to look for out of order packets if ordering is required and or missing packets by performing packet count if the number of packets is static and or CRC checking on segments of a DataSpace.

Alternative Data Storage A DataSpace can export data packet s and or data stream s to other storage devices as a safe store method in the event a DataSpace needs to backup to a form of permanent storage. In addition if data on a DataSpace becomes lost or corrupted a DataSpace can re construct the data from the safe storage device. Examples of these safe storage devices include disk drives floppy drives and or optical drives.

Referring to the intelligent network controller device includes a Central Processing Unit CPU data cache memory which is used to support processing a systems interface typically a Field Programmable Gate Array FPGA or Application Specific Integrated Circuit ASIC which may include an optional computation engine which can be used to accelerate operations such as RAID check sum calculations encryption compression and data routing and at least one communication port which is used to communicate with the external network other intelligent network controller devices or other forms of data storage caching such as SANs NAS etc. or other peripherals. At a minimum the intelligent network controller device would also include a communication port which is used to retrieve data from a DataSpace . Optionally it may include a server communication port used to connect with servers and or a LAN communication port may be included for connection to a LAN and or a communication port for sending data to another network controller device . The intelligent network controller device may include additional communication ports of any of the previously described as required. The intelligent network controller device is not limited to the types of communication ports previously described.

More than one of the above communication ports may be combined into a single communication port. Also each of the communication ports may be operating on a different protocol such as but not limited to iSCSI Infiniband Fiber Channel SONET etc. or proprietary protocols. It should be appreciated to one skilled in the art that the term communication port is intended to be construed broadly to include any combination and sub combination of different communication ports for allowing the data and messaging communication using appropriate protocols over a telecommunication network.

The intelligent network controller device is programmed to be capable of receiving and processing requests for data such as but not limited to copying mirroring backing up performing RAID data check sum functions data routing administrative functions encryption compression and forwarding data to a client and or another DataSpace and or physical disks intended for data storage caching.

Optionally the storage caching management and administration functionality of server as depicted in may be integrated on the intelligent network controller device such that a client may communicate directly with the controller device through a front end network without involving a server .

It should be noted that the intelligent network controller device is capable of executing and fulfilling client requests such as but not limited to Hyper Text Transfer Protocol HTTP File Transfer Protocol FTP or Real Time Streaming Protocol RTSP etc.

The DataSpace hardware configuration may be modified depending upon the optimization of the application s required by the client upon a telecommunication network configuration. U.S. Pat. No. 6 148 414 Brown et al which is hereby incorporated by reference in its entirety for all purposes provides useful device configurations for embodiments of the present invention.

As the present invention stores data in the form of data packets PDUs or protocol payloads etc. continuously transmitted on the storage caching network for the life of the data packet s and or data stream s U.S. Patent Application 20010049740 which is hereby incorporated by reference in its entirety for all purposes provides useful systems and methods for delivering data content particularly streaming data content to a client over a telecommunication network in response to a request for the data content from the client device.

In the following description like reference numbers indicate identical or functionally similar elements. Additionally the left most digit s of a reference number identifies the drawing in which the reference number first appears.

When the data packet s and or data stream s requested by a client device is not located on DataSpace the server communicates with the intelligent network controller device which is located on another DataSpace . The server typically forwards a notification message over a back end network which is connected to the DataSpace . The back end network may also be connected to another front end network . The telecommunication links between the networks may include optical fiber for example but may be comprised of other mediums such as but not limited to fiber optic cable Category 5 wire coaxial cable airwaves ground waves vacuum space etc.

When the data packet s and or data stream s requested by a client device a personal computer cable TV set top box PDA ATM radio is not located on DataSpace the intelligent network controller device located on a DataSpace communicates with a intelligent network controller device which is located on another DataSpace . The intelligent network controller device forwards a notification message over a back end network which is connected to the DataSpace . The back end network may also be connected to another front end network . The telecommunication links between the networks may include optical fiber for example but may be comprised of other mediums such as but not limited to fiber optic cable Category 5 wire coaxial cable airwaves ground waves vacuum space etc.

The inventors have built two DataSpace prototypes. The first is a remote storage caching system accessed by a client via iSCSI over a front end network to a DataSpace. A block like file system architecture typically found on traditional magnetic media was implemented on a DataSpace and integrated with an iSCSI target server on a DataSpace intelligent controller device. An iSCSI target server routed iSCSI block I O operation requests from the client to the DataSpace instead of a traditional magnetic media device. The block like file system on the DataSpace consists of data packets representing media blocks continuously transmitted for the life of the data packets.

The second prototype is remote storage cache system accessed by a client device s web browser through an HTTP server integrated with a DataSpace intelligent controller device. The web pages and graphics requested by the client device s browser HTTP requests are retrieved from a DataSpace where they were previously stored cached. The prototypes demonstrated the ability of a network to serve as a data storage cache mechanism by continuously transmitting data packets between network devices.

DATASPACE PROTOTYPE ONE illustrate the first DataSpace prototype. This prototype consists of two major components a client device specifically a PC that initiates DataSpace client requests and two DataSpace prototype switches built on a PC platform. The code for this prototype was disclosed in U.S. Provisional Patent Application Ser. No. 60 366 803 ENTITLED SYSTEM AND METHOD FOR STORING CACHING DATA ON TRANSMISSION INFRASTRUCTURE previously incorporated by reference.

The DataSpace prototypes include a client device such as but not limited to a personal computer cable TV set top box PDA that is capable of establishing and maintaining a network connection to the DataSpace. Table 1A shows the data flow from an application to a prototype switch from a stack perspective 

The DataSpace prototype switch receives requests for data storage caching operations and performs them on the DataSpace. The DataSpace prototype may also include load balancing data integrity operations and transfer of data to another data storage medium such as but not limited to a physical disk farm or another DataSpace.

Since one goal of the prototypes is to demonstrate the compatibility to co exist with existing and emerging standards and protocols Internet Small Computer Systems Interface iSCSI was selected as the key integration point for the first prototype. Others such as but not limited to Hypertext Transfer Protocol HTTP File Transfer Protocol FTP Real Time Protocol RTP Network Time Protocol NTP Post Office Protocol POP3 etc. can be implemented as well since the primary software developed is built independent of delivery method to a server s .

For the first prototype Intel s iSCSI software was used for the following reasons. First iSCSI is an acknowledged standard based upon two established technologies SCSI and TCP IP. Both of these technology standards are well integrated into existing computing systems and would make integration easier to accomplish with the initial prototype. Since iSCSI encapsulates the data storage caching operations within TCP IP packets it will be simple to examine these packets upon receipt and translate them into DataSpace storage caching operations.

The Intel iSCSI software was found in public source www.sourceforge.com. Some minor modifications to the Intel source were necessary to provide interconnection to the DataSpace prototype system.

The DataSpace client application creates file operations that result in iSCSI transactions to an iSCSI target device which uses the DataSpace as a storage caching device.

iSCSI protocol handles requests between a client and a target. In the first prototype the DataSpace switch is the target. The client loads a device driver for an iSCSI initiator. This device networks with the iSCSI target on the prototype switch. The client creates a disk partition and file system on the iSCSI device which is currently done today with traditional SCSI devices. The client mounts the iSCSI device then runs an application or other programs that use the iSCSI device driver to send disk operation requests to the DataSpace. The DataSpace iSCSI target routes the iSCSI requests to the DataSpace for action and returns the response.

The DataSpace prototypes were built around the concept of representing disk blocks on a network in the form of continuously transmitted data packet s . The prototypes were designed using 512 byte data packets. For example if we wanted to install a disk that has 40 000 512 byte blocks then we would create a DataSpace that has 40 000 512 byte data packets.

The client s file system uses the iSCSI initiator to issue read write block request s on the iSCSI target device. Upon receipt of these block operation requests the iSCSI target places the request into shared memory that is accessed by the DataSpace switch.

While the switch is processing DataSpace packets it scans the memory table to determine if the DataSpace data packet currently in process has a request from the iSCSI target. If there is a request for example a block read write verify etc. then 1 the operation is performed on the DataSpace packet 2 the memory table is updated and 3 the packet is sent to the next DataSpace prototype switch.

The following is a description of DataSpace Prototype One architecture as shown in . This architecture emulates a distributed and shareable RAM disk in which a DataSpace data packet A is used in place of a memory block on a computer RAM disk. Instead of read writing data to a hard storage device a client device such as but not limited to a PC read writes data to data packets continuously transmitted on a network microprocessor data bus or electronic circuit.

DataSpace Prototype One consists of two prototype devices configured as PC s running Redhat Linux 7.2 operating system . Prototype devices are interconnected via standard Ethernet network to an Ethernet 10 100baseT router hub . The DataSpace prototype device is one physical PC unit that consists of two logical devices client device and server device . The hardware used for DataSpace Prototype Device is a Dell Dimension XPS T700r personal computer. The hardware used for DataSpace Prototype Device is a Dell Optiplex GXpro personal computer. The router hub is a Dlink DI 704.

Intel iSCSI software is used to send and receive SCSI instructions between the file system and or operating system and the iSCSI target device . During this operation iSCSI initiator creates informational and error messages to log file .

Intel iSCSI software was modified to allow the storage caching device instructions from client via iSCSI initiator to server to be performed on the DataSpace storage cache prototype. During operation of the iSCSI target information or error logging messages are sent to video display device .

As part of the DataSpace Prototype One setup the DataSpace data packet loader creates and sends a configurable number of DataSpace data packets A to the prototype switch via Ethernet. For example if one desires to build a 10 MG DataSpace with 512 byte data storage caching blocks the DataSpace packet loader will send 20 000 DataSpace data packets A to prototype switch .

For DataSpace Prototype One each DataSpace data packet A is a TCP IP packet formatted for subsequent iSCSI operations. DataSpace data packet A contains space reserved for the DataSpace header A and a space reserved for a data storage caching segment A. The DataSpace header A is for information pertaining to the operation of the DataSpace and also includes a field called block ID . In addition to containing a block ID the DataSpace header A could also be modified to include additional meta data associated with data contained in data segment A and other relevant DataSpace information. The DataSpace loader inserts a unique block number into this field for each DataSpace data packet A created starting at value zero 0 and increasing by one 1 . The DataSpace data storage caching segment A reserves one block like file system block per data packet for storing caching data.

DataSpace data packet A becomes a DataSpace data packet B once data has been written to header A which becomes a B and data storage caching segment A which becomes a B .

After all the required DataSpace data packets A have been created and sent by the DataSpace loader to prototype switch the DataSpace loader creates and sends out a DataSpace loader control packet to prototype switch . This loader control packet contains the number of packets created for the DataSpace by the DataSpace loader . Like other DataSpace data packets A used for the prototype once the DataSpace loader control packet is sent to prototype switch it will be continuously transmitted on the DataSpace.

DataSpace loader creates and sends out DataSpace data packets A to the prototype switch . Prototype switch receives and processes see Table 3 below P DataSpace data packets A and sends them onto the next prototype switch . These DataSpace data packets A are continuously transmitted on the DataSpace and available for read write operations.

During operation the DataSpace loader provides information or error logging messages to video display device .

All the DataSpace data packets A B loader control packets and switch control packets will be continuously transmitted on the DataSpace network from prototype switch to prototype switch to prototype switch to prototype switch etc. This continuous reverberation of DataSpace data packets A B between prototype switches and illustrates one of the key components of the DataSpace concept.

Prototype switch is configured as a switch running in the normal mode and performs the operations as described below in Table 3 

As part of a prototype switch s startup operation once a TCP IP network connection has been established with its next prototype switch it sends out a prototype switch control packet onto the DataSpace which is continuously transmitted for the life of the DataSpace. For example prototype switch sends its switch control packet to prototype switch and prototype switch sends its switch control packet to prototype switch . During the development of the prototype the switch control packet was used for debugging and testing purposes. It can also serve as a pulse indicating the status of the DataSpace contains switch specific information to be used by other DataSpace devices for management performance and analysis operations.

When an application such as vi a UNIX based text editor is used for editing a file that is stored cached on a DataSpace it results in several file system requests to the operating system and or file system . These requests result into iSCSI instructions that are sent from the iSCSI initiator to the iSCSI target in the logical server device . The iSCSI target is the modified Intel iSCSI target software containing added DataSpace functionality.

When iSCSI target receives an iSCSI request from the iSCSI initiator it translates the iSCSI request into a DataSpace request s and places the request s as entry ies into the DataSpace request table . The request table contains a configurable number of re usable table entries . For most of the prototype testing 40 shared memory entries were created for use.

The DataSpace also uses a semaphore table that contains an associated semaphore table entry mapped to each DataSpace request table entry . The prototype switch iSCSI target and the DataSpace software test tool have access to write read and modify request table entries in the request table . As a result the prototype switch iSCSI target and the DataSpace software test tool perform lock and unlock operations to a specific DataSpace request table entry by applying the appropriate semaphore operation on the associated DataSpace semaphore table entry . The use of semaphores is a common compute method used to manage access to shared resources such as memory table entries. By implementing semaphores resources can not simultaneously accessed by more than one competing process thus removing the potential for memory corruption.

The DataSpace request table and the DataSpace Semaphore table can be created by either the prototype switch the iSCSI Target or the DataSpace software test tool.

The DataSpace request operations as shown in Table 4 below can be performed on the DataSpace request table entry depending on the received iSCSI request 

During operation of the prototype switch in normal mode it can provide information or error logging messages to video display device .

During operation of the prototype switch in passthru mode it can provide information or error logging messages to video display device .

When the prototype switch operating in passthru mode receives a data packet A and or B it performs the operations as shown in Table 5 below 

DATASPACE PROTOTYPE TWO DataSpace Prototype Two integrates a DataSpace with an open source Apache Hypertext Transfer Protocol HTTP web server found at http www.apache.org. In this DataSpace prototype all hardware and software components were used in DataSpace Prototype One with the exception of the iSCSI components.

In addition to the DataSpace Prototype One components two other software programs were created. The first program provides the method for uploading Hypertext Markup Language HTML web pages Graphic Interchange Format GIF and Joint Photographic Experts Group JPEG images graphics to the DataSpace for storage caching. After the DataSpace has been initialized including the loading of data packets in the manner outlined in the first DataSpace prototype the HTML GIF and JPEG files and graphics can be uploaded to the DataSpace.

The second program is a Common Gateway Interface CGI program that is responsible for processing the CGI requests received by the Apache HTTP web server from the client. The CGI program extracts the requested HTML JPEG or GIF information stored cached on the DataSpace by issuing a request to the DataSpace switch. The DataSpace switch upon receipt of the request from the CGI program fulfills the request and returns the information requested HTML JPEG or GIF format back to the CGI program. The CGI program returns the information requested HTML JPEG or GIF format back to the Apache HTTP web server which forwards the response back to the requesting client.

The actual Apache source code may be modified or a specific module within Apache source code or framework may be created for tighter and more efficient integration with the DataSpace that would eliminate implementation of a CGI program. Also a more detailed and sophisticated method may be implemented to increase server functionality by storing associated meta information on the DataSpace including but not limited to multiple information identification indicators filename serial number descriptor description key words size author time of upload geographic tag access rights and expiration date.

In addition since CGI is an established method used for adding or extending HTTP server functionality a similar prototype may be built with any number of web server technologies including but not limited to a small proprietary HTTP server specifically developed for use with a DataSpace or other commercially available server like Microsoft s Internet Information Server IIS .

Similar levels of DataSpace and server integration may be built using other protocols including but not limited to File Transfer Protocol FTP for accessing storing caching files Real Time Protocol RTP for the transport of real time data including audio and video Network Time Protocol NTP Post Office Protocol Version 3 POP3 for accessing storing caching e mail Real Networks Protocol for accessing storing caching streaming media Apple s QuickTime Streaming server for accessing storing caching streaming media etc.

Electronic circuit stores caches data in a similar manner described in with the exception that data is stored cached in the form of continuously transmitted data packet s and or data streams without the use of a telecommunication network to interconnect the switches on a DataSpace.

The electronic circuit can be contained in many different form factors such as but not limited to carrier class soft switches data network elements such as switches routers hubs and bridges programmable hardware with architecture similar to a Lucent Excel LNX programmable switch host controllers and client devices such as but not limited to PLCs and PCs TVs PDAs ATMs radios as shown in .

The electronic circuit may be configured to operate using an emerging technology known as XML switching routing. XML switching routing is explained in more detail below in the applications section of the present invention.

Electronic circuit can be designed to use a protocol such as but not limited to Small Computer System Interface SCSI to encapsulate data packets for storage caching as previously discussed in the present invention.

Alternatively electronic circuit can employ structured data streams to store cache data. A structured data steam has been described in U.S. patent application Ser. No. 09 698 793 entitled METHOD OF TRANSMITTING DATA INCLUDING A STRUCTURED LINEAR DATABASE to Melick et al previously incorporated.

In this embodiment of the present invention the DataSpace RAM switches are coupled via transmission medium . A single pair of transmission mediums is shown but the electronic circuit is highly scalable in a parallel manner and the DataSpace RAM switches may include additional ports to reverberate data over additional transmission mediums. A uni directional flow between DataSpace RAM switches and is shown but may be configured as bi directional data flow.

The electronic circuit can have additional DataSpace RAM switches added to balance the load or increase the number of nodes available for tapping into the data flowing on the circuit.

Data integrity on the electronic circuit can be accomplished by implementing RAID type methods in which data packet s or data streams are striped check summed and mirrored on the same electronic circuit or across multiple electronic circuits operating in concert in order to enable data integrity and rapid data reconstruction in the case of a transmission failure.

The DataSpace RAM switches communicate and transmit data with other electronic circuitry or microprocessors through data links . A single data link is shown for each DataSpace RAM switch respectively but additional ports may be included in order to provide additional parallel data links.

The electronic circuit may be configured to operate as a photonic circuit or as a circuit using pulse based methods similar to those described in U.S. Provisional Patent application 60 376 592 to Melick et al entitled High Number Base Encoded Ultra Wideband Over Guided Lines And Non Guided Narrow Band Radio previously incorporated by reference.

The DataSpace RAM switch is programmed to be capable of receiving and processing requests for data in the form of data packet s and or data streams such as but not limited to copying mirroring backing up performing RAID data check sum functions data routing administrative functions encryption compression and forwarding data to another DataSpace RAM switch or other RAM or physical disks intended for data storage caching.

DATASPACE APPLICATIONS Applications of DataSpace technology can be applied to both wireline and or wireless networks and include but are not limited to a chaotic database Domain Name Service DNS a storage cache system for data file systems and meta data mobile data systems high read use decision support systems content management and geographical routing and as a support technology for stream querying and grid computing.

CACHING APPLICATION Caching allows for more efficient use of high latency physical storage mediums such as magnetic disks. By implementing a cache time costly disk I O operations are minimized resulting in reduced access times and contention for disk resources. When data such as file directory information is continually accessed on a typical storage device like magnetic media it makes sense to store that information in a low latency memory location such as cache. Using cache once the first read to a disk is performed the cache is also updated with the content retrieved by the disk read request. As a result subsequent read requests for the same data element previously retrieved will be served from the cache in lieu of performing another disk operation.

Cache can be co located locally with the file system and or operating system or remotely on a storage system such as a Storage Area Network SAN traditional networked server and storage cluster. In the case of remote storage devices the cache can be located on the storage system and is delivered over a standard network transport such as but not limited to TCP IP. Using the present invention to cache data on a DataSpace allows subsequent requests for data to a remote networked storage caching device without having to traverse the entire network.

CONTENT MANAGEMENT AND GEOGRAPHICAL ROUTING APPLICATION Data that is highly accessed for Internet web sites and multi media can be cached to many DataSpaces. For example a DVD movie or series of movies can be stored cached on a network closer to the edge or cached on other DataSpaces between the originating source and the user and continuously transmitted indefinitely for quick access by users.

Combined with geographical routing information data can be tailored for a user s demographics. A DataSpace can maintain information about users served via geographical routing information and intelligently cache data in relevant DataSpace s closest to the user.

FILE SYSTEMS APPLICATION Traditionally file systems typically store relevant information on the data storage caching device they are managing. Sometimes this data is stored cached in superblocks or blocks of data on a disk device. When file system information is stored cached on a DataSpace instead of the actual disk managing file systems would be more easily distributed and many file system operations would become more efficient and faster.

MOBILE DATA SYSTEMS APPLICATION When multiple entities or assets are in a mobile environment such as but not limited to people vehicles freight luggage military assets etc. each of these can be nodes within a hybrid DataSpace. A hybrid DataSpace includes both wireless and wireline network transport mediums. Among the benefits of this are 1 high speed access to real time data by DataSpace nodes 2 faster data distribution to multiple DataSpaces and 3 ease in adding additional DataSpace monitoring or intelligence nodes.

DECISION SUPPORT SYSTEMS APPLICATION When data is characterized as high read low write traditional data systems require a central data store s to be updated before current data is available to users. Examples include asset tracking monitoring systems telematics and broadcast data. Also central data store s may provide other access points via a distribution or replication model to other data storage caching systems and or devices.

A DataSpace provides immediate access to data for a large number of users without the costs normally incurred by adding access for many users to traditional data systems. A DataSpace is suited to this environment because the processing latency at a DataSpace node is negligible in comparison to the contention of many users vying for traditional storage caching resources. When additional DataSpace resources are required to support additional users the addition of DataSpace nodes allows for faster distribution of data rather than the traditional processing of data via a sophisticated distribution and or replication environment that requires data to be completely distributed and or replicated before it can become available to all users.

SEARCH ENGINE APPLICATION The DataSpace may be configured for use as an Internet search engine. When a company user content provider etc. wishes to provide searching capabilities for their data such as but not limited to keywords languages phrases geographical location time stamps speech patterns recording video graphics meta information and other associated data elements etc. it can be uploaded and stored on a DataSpace s . DataSpace switches can be programmed to use various methods to search data using criteria such as but not limited to geographic region languages expiration of search information keywords meta information patterns categories etc. and to control access and permission restrictions.

Current Internet search engines such as but not limited to Yahoo Metacrawler Google etc. could redirect search requests to a DataSpace use the DataSpace to search and or utilize a DataSpace as a resource for their own bot or information acquisition technologies. Users could subscribe to a DataSpace and quickly upload change add delete or modify search criteria and information stored on a DataSpace. When service providers use a DataSpace to update or push data they have more control on subsequent DataSpace search requests. For example a web site owner distributing information regarding their web site to a DataSpace may want search results to be determined by time of day day of week special of the day inventory counts closeouts pricing or other parameters. In addition the web site owner may want to provide different results for different users including but not limited to the content the language and or dialect based upon the origin of the DataSpace search request. A common example of time of day routing can be found in the telephony market where specific 800 numbers are routed based upon parameters such as time of day and or originating call location. In these cases many 800 number customers are allowed access to telephone systems that implement their routing decisions based on a myriad of reasons. Similarly a DataSpace allows users to update specific information real time on a DataSpace that would yield different search engine results.

If a service provider stores the actual web content on the DataSpace a DataSpace could generate and return results based upon the content stored. For example a web page stored on a DataSpace that contains an Iowa basketball sports story titled Iowa Women Beat Purdue Men 90 3. In addition the web content may contain other information keywords or meta tags for search engine purposes such as purdue iowa scores sports college basketball etc. When the DataSpace is searching for a request it will evaluate all the information stored within a page such as the actual score title or news story content itself in combination with and or information pertaining to searching stored in meta tags as previously described.

A DataSpace based search engine could provide the ability to expire or restrict access to searching. This could allow for different levels of search capability for both the user and content provider. Examples include 1 A news story with a related MP3 file has an expiration date for searching because the news story is no longer relevant 2 versioning of content for different users 3 access restrictions by ISP IP address range or specific users 4 geographic location grouping company service etc. 5 service level restrictions by content provider user DataSpace provider DataSpace subscriber etc.

Likewise hosting providers or content providers such as AOL Microsoft WorldCom UUNet Akamai etc. could upload information about content and store service manage and create data directly on the DataSpace. This could be done automatically and dynamically at any time interval or as changes are made to the content.

DOMAIN NAME SERVICES APPLICATION Another application for the present invention is using a DataSpace as a mechanism to update and maintain Domain Name Services DNS or to be a DNS server itself. DNS information on a DataSpace could provide for instantaneous updates for DNS servers located as an example in Botswana the United States and China simultaneously. Today when an application or device needs to resolve a domain name it typically goes to a DNS server which is not updated in real time.

A DataSpace may have global reach and could be a centralized distribution system for DNS services. Registrars could update a DataSpace in near real time and ISP providers can use the DataSpace for up to date DNS resolution directly or indirectly for their customers. One benefit to using the present invention for real time DNS services is having more dynamic capability for re routing requests by time of day load geography outages type of request etc.

LINEAR DATABASE APPLICATION A complimentary technology to a DataSpace is Linear Databases. Linear Databases are described in U.S. patent application Ser. No. 09 698 793 entitled METHOD OF TRANSMITTING DATA INCLUDING A STRUCTURED LINEAR DATABASE to Melick et al. A Linear Database defines a structure for data stored in the form of a data packet s and can be used as a universal data interchange method.

GRID COMPUTING APPLICATION Grid computing is the application of many distributed computer resources in a network dedicated to a single problem at the same time. Among the cornerstones of grid computing are the cataloging and management of compute and network resources and to provide access to these resources using application programming interfaces APIs and tools.

An example is collecting data such as space radio signals at many collection points and distributing the data to various compute facilities for processing. Depending on the task compute resource s located on the grid may be needed for pure raw processing power or because it contains specific hardware and or software developed to complete a specific task.

In addition sets of data may be of interest to many different parties located on the gird for their own analysis and tasks. An example of this type of data would be weather data that would be useful to agriculture aviation defense and other private and public entities. This use of data can require many types of regulated unregulated distribution data access methods. If an entity located on a grid wishes to use this kind of data they either must pull it from a data store or have it pushed or delivered to them.

Grid computing is a methodology and architecture intended to create a system that easily integrates and automates some of the nuances specific to tasks that require high contention devices e.g. super computer resources for sophisticated modeling. Super computing resources are distributed to a few global locations relative to other types of available processing resources and typically require some form of scheduling and permission prior to acquiring the resource. The grid allows for sizeable tasks to be broken down into manageable sub tasks that could be spread across multiple resources. By parsing these sub tasks among different resources one could reduce the total amount of work typically required of a super computer oriented task and or break a task up among different super computer resources.

Depending on the application sizes of the datasets used in grid computing can be quite large and range in size greater than 10 million objects representing gigabytes and terabytes of data. When dealing with different data use methods distribution of resources and types of datasets a DataSpace can aid in the processing of this data by caching and storing it on the network so that more than one compute resource can access it simultaneously. This would allow for the use of multiple resources for analyzing data interconnected by a DataSpace.

A DataSpace is not a replacement for current data storage methods however it can provide persistence of data objects which can be useful in a grid system configured for performing tasks across multiple systems relating to the same object. An example of object processing would be a series of interconnected systems providing services for travelers. The passenger object would be passed among different systems performing different functions for example booking ticketing baggage security billing etc.

A DataSpace is also useful in the event that an object is cached for use by different systems. When tasks are serialized once an object has been processed and placed on the DataSpace the next available resource can perform the next task for the object without having to employ a sophisticated queuing scheme.

As referenced in other areas of the DataSpace and chaotic databases application an object database could easily be developed for storing objects of different sizes and formats. In addition a DataSpace provides a mechanism to store object meta information such as processing history processing performance operation and measurement information origin access etc.

A DataSpace can be useful for caching data used by many systems within the same timeframe. An example of this type of data would be the real time monitoring and analysis by many different military systems for battlefield information. Using a DataSpace to store cache the real time battlefield data eliminates the need to send the data to a common store for analysis systems to pull from.

The predominant benefit a DataSpace provides to grid computing is the ability to add persistence to objects and data elements to make them readily available at the time a resource on the grid becomes available. A DataSpace can span different geographic locations and can be easily integrated into a grid. Within the context of grid computing a DataSpace can be viewed as a large shareable RAM drive that can be easily accessed by all the interconnected grid devices.

CHAOS DATABASE APPLICATION One of the problems with using traditional element storage systems such as a relational database is the need to define database elements such as tables and indexes prior to the import creation or storage of data elements. While advances in technologies such as XML and predictive data modeling are aiding in the effort to reduce the amount of pre implementation design and planning required for the storage of data they are all constrained by the underlying data access speed limits posed by magnetic media devices.

Another limit of traditional database systems is the requirement for a thorough understanding of the data to be received or stored. While in some instances this is a very easy task in other situations it can be very difficult and challenging. There are two trends impacting data storage in the future. The first trend is that more data from more distinct and unknown organizations will need to be processed. Secondly realizing that some data has a short lifetime of usefulness a push towards analyzing data closer to real time will increase the demand for minimizing the amount of resources and time spent performing traditional pre implementation database activities.

A DataSpace may be configured to provide a new type of element storage system we call Chaos Element Base CEB . The CEB is focused primarily towards an element storage system that supports intense queries volatile storage elements with limited updates the import of storage elements in their original format with little modification from many sources and formats and the use of meta data information related to the storage elements.

CEBs equip the end user with the ability to perform their own queries and reporting thus reducing dependency on the IT department. Querying a CEB will employ a natural type of access similar to those found on today s Internet search engines. Other advanced searching querying and reporting applications may be layered on a CEB providing additional functionality. As an example a SQL type of query engine may be is layered on the CEB to provide end users with an applicable SQL instruction set.

Another example of a type of querying application that can be implemented on a chaotic database is associated with the Stanford s Stream Data Manager STREAM systems being development at Stanford University. While STREAM systems will focus on continuous data feeds the CEB focuses on providing a persistent data stream. Querying technologies developed for STREAM such as OpenCQ and NiagraraCQ support continuous queries on data streams and can be applied to a CEB.

Another area a CEB can be implemented is for the storage caching and sharing of business objects. This is accomplished without converting an object into a traditional database thus reducing the complexity of integration. As a CEB stores data independent of formats the storage of objects of different size and complexity are minimized in comparison to force fitting data into traditional database technologies.

When data objects are frequently updated and shared with multiple systems it is essential to provide a method of locking to eliminate the risk of updating the same record simultaneously. There are several types of locking procedures that would be applicable to a CEB including exclusive locks and read only locks. These methods of locking can be implemented on a chaotic database using the meta area of data elements in the CEB architecture which allows only one client access to a particular data at any given point eliminating the risk of contention among clients.

In some cases an object has a short lifespan and yet needs to be shared among disparate systems. A CEB can provide this level of functionality as well and also provide object expiration rules for object garbage collection typically found in object oriented systems today.

When data is stored in its original format it provides two advantages. The original context in which the data was received is preserved which provides added meaning to the data and the steps for importing data elements into a CEB are eliminated or substantially reduced vs. a traditional relational database. The steps eliminated or reduced include 1 pre definition of data elements 2 design of relational database SQL table and indexes 3 creation of SQL table and 4 the import of data and insertion into SQL table s .

Data may be imported directly into a CEB thus reducing the time resources and analysis typically required to load data into a traditional relational database. This is important when dealing with data that is real time time sensitive and or has a short shelf life.

DATA WITHOUT A TRACE In some applications it may be beneficial to delete without leaving a trace. When deleting information from a general computing device s traditional storage device such as magnetic media based disk drives its existence is removed from the eyes of an operating system file system and user however the fingerprint or physical properties of the data remain on the device. An example of a data trace includes pits created in magnetic media devices such as disk drives. Unless additional safe guards are implemented the data will remain in its original physical form on the storage unit until it is overwritten by another operation.

Today special programs provide random generation of data to wipe a file from a disk. This makes it difficult if not impossible to reconstruct the data element once it has been wiped. These programs are slow since it requires numerous I O operations to be performed on the disk as described in Norton s Wipe Info utility describing U.S. government wiping methods.

This utility combines several wiping and overwriting processes conforming to DoD Department of Defense document 5220 22 M and the National Industrial Security Program Operating Manual for the ultimate security level when eliminating data from digital media.

In situations where data needs to be quickly removed and its traces eliminated a DataSpace provides this functionality. As a DataSpace stores caches data on a telecommunication network s infrastructure and or an electronic circuit data bus or microprocessor s RAM all traces of data are eliminated once a DataSpace is shutdown or the life of data packet s and or data stream s has expired.

A DataSpace requires less time than traditional disk wiping methods because it eliminates excessive physical disk I O s associated with traditional medias devices such as magnetic disk drives. In addition when a DataSpace is shutdown it can be configured in a manner where there is no remaining physical fingerprint or evidence of data packet s and or data stream s previous existence.

COMPUTE APPLICATIONS A DataSpace s unique architecture and use of continuously transmitted data packet s and or data stream s can also be configured for various compute applications.

DISTRIBUTED COMPUTE DEVICE An example of the architecture of a distributed compute device is illustrated in . In this embodiment of the present invention the data bus such as but not limited to Universal Serial Bus USB or Peripheral Computer Interface PCI encapsulated in data packet s is continuously transmitted between components of a compute device connected to a DataSpace. The compute device components include keyboard video display and computer processor and are connected to DataSpace via data link and respectively. The keyboard is used to input commands into processor . The video display is used to view output from processor . A peripheral device a web cam is shown connected to the DataSpace via data link . In this embodiment of the present invention the DataSpace serves as the memory and processor cache required by the processor and also serves as the data bus between the video display and processor .

As an example the bus may be encapsulated in Lightwaves Data Link LDL . LDL is a proprietary protocol based on Simple Data Link SDL which is a variable length Asynchronous Transfer Mode ATM protocol. This protocol adapted for use in a DataSpace is discussed in detail later in the present invention. The DataSpace Version octet in the LDL private area of the protocol can be used in a DataSpace distributed compute device to indicate the manner data contained within the LDL payload is to be processed and if it is destined for a particular compute component connected to a DataSpace .

Another example of distributed compute device architecture is illustrated in . In this embodiment of the present invention the functionality of the computer processor shown in is replaced with a DataSpace within a DataSpace or what will be referred to as global processor . In this embodiment the operating system O S and file system are continuously transmitted on DataSpace as shown with a dashed line are encapsulated in continuously transmitted data packet s and or data stream s . The processor cache ROM for processor software and data storage are continuously transmitted on DataSpace .

DataSpace switches are described in . The video display is connected to DataSpace via data link and is used to view output processed by the global processor . The keyboard is connected to DataSpace via data link and is used to input commands into processors and . A peripheral device a web cam is shown connected to the DataSpace via data link .

The O S and file system continuously transmitted on DataSpace perform traditional task management procedures such as but not limited to task scheduling file management and resource and services management for the processors connected to DataSpace and DataSpace . In addition DataSpace reverberates data packet s and or data stream s containing information such as but not limited to dynamic and static O S configuration and operational information semaphores device drivers users system status and instruction sets.

DataSpace reverberates data packet s and or data stream s containing information such as but not limited to processor cache shared memory and instruction sets etc. for use by processors and . Delete One Of The Periods 

TRANSMETA LIKE COMPUTE DEVICE Transmeta Corporation manufactures the Crusoe processor which is an x86 compatible chip specially designed for the handheld and lightweight mobile computing market. The Crusoe processor is a hardware software hybrid chip that consumes significantly less power than standard processors by transferring the function of millions of transistors with their proprietary code morphing software.

The Code Morphing software is designed to dynamically translate x86 instructions into VLIW Very Long Instruction Word instructions for the underlying Crusoe hardware engine. The Code Morphing software resides in flash ROM. The Code Morphing software consists of two main modules that work in conjunction to implement the functions of an x86 processor.

The Interpreter software contains a module that interprets x86 instructions one at a time much like a traditional microprocessor. The Interpreter functionality also filters infrequently executed code from being needlessly optimized and gathers run time statistical information about the x86 instructions it sees for determining whether optimizations are necessary.

The Translator software detects critical frequently used x86 instruction sequences. The Code Morphing software invokes a module that recompiles the x86 instructions into optimized VLIW instructions called Translations. The native translations reduce the number of instructions executed and results in better performance.

Further efficiencies are possible by saving the translations in memory that is inaccessible to normal x86 code. This special memory area is named the Translation Cache and allows the Code Morphing software to re use translations and eliminate redundancies. Upon encountering previously translated x86 instruction sequences the Code Morphing software skips the translation process and executes the cached translation directly out of the Translation Cache.

Caching and re using translations exploits the high degree of repetition typically found in real world workloads. The Code Morphing software matches repeated executions with entries in the Translation Cache and the optimized translation is executed at full speed with minimal overhead. The initial cost of the translation is amortized over repeated executions.

A DataSpace as shown in can be adapted for use with Transmeta or Transmeta like processors to enhance compute functionality on a DataSpace . The DataSpace can function as the ROM normally used to store the Code Morphing software including interpreter and translator modules and also the translator cache. The DataSpace would encapsulate and continuously transmit the Code Morphing software and translator cache in data packet s and or data stream s .

It is not the goal of the present invention to adapt a DataSpace for use with Transmeta and Transmeta like processors in order to increase the battery life of mobile devices but to convert a DataSpace for use a compute device that is easily scalable. Another benefit of a DataSpace integrated with a Transmeta or Transmeta like processor would be to modify upgrade and change Transmeta or Transmeta like processors ROM based on the task the Transmeta processor is to perform.

MATH COMPUTATION DEVICE One example of a DataSpace configured for math computations particularly numbers exceeding 64 bits in length or highly re iterative calculations is illustrated in . Data link is used to connect to the DataSpace . DataSpace switches where N represents a specific bit position value of a number are configured to perform normal DataSpace switch functions on continuously transmitted data packet s and or data stream s such as copying forwarding reading deleting etc. In addition DataSpace switches are programmed to perform addition and subtraction operations on the values represented in the bit frames . Where N equals 1 in a bit frame DataSpace switch would only process bit position within a bit frame and DataSpace switch would only process bits contained within bit position etc.

After the DataSpace switch has added and subtracted bit values in two or more data packet s and or data streams it outputs a resultant data packet s and or data stream s corresponding to bit position it is processing. It may output two data packet s and or two data streams s and or two values in a data stream if there is carryover from the math processing on the bit values. The carryover data packet s and or data stream value s would be identified with a bit position of N 1. As an example DataSpace switch processing bit position will output a resultant data packet and or data stream value identified as the resultant of operations performed on bits with a bit position value of 64. If there is carryover DataSpace switch will also output a data packet and or data stream value with a bit position value of 65 which is N 1.

Table 8 illustrates an example of a bit frame designed to support math computations on a DataSpace s .

The Number ID value is used to indicate which operand the bit value has come from. The frame type is used to indicate what iterative value this is of the bit value contained in the data packet or if the bit value is a resultant etc. The Integer or Decimal value indicates which counting convention to use to determine the correct bit position value. The bit position value indicates which position the bit value occupied in a text string number from right to left for an integer or left to right for a decimal. The bit operation value indicates whether the bits are to be added or subtracted to the operand with a Number ID of the current data packet plus 1 . The bit sign value indicates whether operands should be added or subtracted from one other. The bit value is the actual bit that is being processed.

In the architecture shown in DataSpace switch also functions as the head end switch which delimits the incoming text string numbers and encapsulates them in a bit frame and reverberates them on the DataSpace . In addition the DataSpace switch is capable of acting as a gate keeper in conjunction with other DataSpaces configured architecturally as AND NOT OR NAND NOR and XOR gates etc. in order to perform any logical operation associated with a compute device.

In an alternative embodiment a pair of DataSpace switches with N number of ports could be programmed such that the bit positions of a text string number were related to a port number on the DataSpace switches. In this embodiment each port on a DataSpace switch would be connected to a separate processor.

The method described above is one example of performing computations on numbers stored cached on a DataSpace where long numbers could easily be represented as polynomials. In addition matrices for use in matrix math can be created using data packet s and or data stream s indexed to a switch port to represent rows and columns created using indexed data packet s and or data stream s .

LIGHTWAVES DATA LINK ADAPTED FOR DATASPACE DataSpace is the storage of elements such as data video audio graphics etc. on a telecommunication network. While the concept of a DataSpace is not transport or protocol specific the following describes a DataSpace adapted for use with the Lightwaves Data Link LDL proprietary protocol. LDL was designed for use with the broadband transport system described in U.S. Provisional Patent Ser. No. 60 376 592 to Melick et al entitled HIGH NUMBER BASE ENCODED ULTRA WIDEBAND OVER GUIDED LINES AND NON GUIDED NARROW BAND RADIO which was previously incorporated by reference.

LDL is a proprietary protocol based on Simple Data Link SDL which is a variable length Asynchronous Transfer Mode ATM protocol.

This embodiment of the present invention includes two LDL data frame architectures for use with a DataSpace. The first architecture uses LDL to create a DataSpace of fixed length blocks that looks like a standard disk media device to protocols and subsystems such as iSCSI. The second architecture uses LDL to create a DataSpace of variable length blocks and is oriented towards supporting applications such as the previously discussed chaotic databases.

FIXED BLOCK LENGTH LDL ADAPTED FOR DATASPACE Table 10 illustrates the basic structure of a fixed block length data frame 

Most traditional storage systems utilize fixed length block sizes for example 256 512 1024 bytes. As a DataSpace is created the appropriate number of fixed length blocks will be created to be utilized by the connected operating system OS and or file system.

In this embodiment of the present invention the DataSpace is configured to contain a group of LDL fixed length frames representing data storage blocks similar to what has been previously described in the first prototype as illustrated in . The DataSpace switch receives block requests from an iSCSI client through an iSCSI interface and in turn performs read and write actions on the Data space s LDL payloads representing the memory blocks.

VARIABLE BLOCK LENGTH LDL ADAPTED FOR DATASPACE The DataSpace LDL frame uses some of the same elements in SDL. The core DataSpace LDL data frame fields are outlined in Table 11.

By changing the version of the LDL data frame a different private area can be created in both size and content. The underlying core LDL processing is capable of sending and receiving data frames of varying types. The ability to process the data frame is independent of the device s ability to end process the frame by a higher layer application.

A DataSpace is based upon the continuous reverberation of data frames which could be implemented with or without a directory of elements DOE area which is analogous to a file system allocation tables. The primary benefit to implementing a DOE within a DataSpace is to improve DataSpace efficiency

The LDL Payload Data Area for a DataSpace DOE frame contains the index to other elements within the DataSpace. The DOE information for each element can be defined or enhanced by using an XML based technology.

When a DOE is implemented on a DataSpace separate LDL frames will be created as required for providing the DOE information to the DataSpace switches. Table 14 illustrates the basic LDL DOE data frame structure.

The LDL payload data area for a DataSpace DOE frame contains the index to other elements within the DataSpace. The DOE information for each element can be defined for example using an XML based technology.

LDL frames can be allocated for storing caching elements either registered or not registered under the DataSpace DOE. The LDL frame for DataSpace Element Storage DES can be allocated or de allocated as required by the DataSpace management system and can contain more than one element. Table 15 illustrates the basic LDL DES data frame architecture.

The LDL DataSpace payload area contains the data to be stored on the DataSpace. These data elements may or may not be registered with the DataSpace DOE. They are not limited to one DES data frame and could span multiple data frames.

When a new element is added to a DataSpace the DataSpace switch inserts the data element s into the DataSpace creating a new frame s . In an effort to reduce the complexity of free space management new data frames are allocated for new data elements as they are entered in the DataSpace.

The DataSpace will inspect the DataSpace DES and DOE areas for data that has expired or marked for deletion. These data packets will simply be removed from the DataSpace.

Using LDL as a DataSpace protocol eliminates the need to manipulate the data payloads typically required by other protocols. Other protocols require this manipulation to remove any data segments within the data payloads that are identical to the ones used by the protocol for segregating the separate data payloads. As an example if a DataSpace is implemented in a protocol such as Ethernet a combination of characters such as Ethernet s 7 octet sized preamble would be used as a marker indicator in between multiple PDUs as a means to delineate the multiple PDUs. In this example insertion of an element into the DataSpace DES would require substituting modified sequences that differ from the PDU delineation sequence with sequences identical to those used by the DataSpace element delineation. In addition when data is removed from the DataSpace DES payload for inspection or delivery the payload would have to be inspected again and any substituted sequences removed and the original sequences reconstructed. Using the LDL protocol removes the requirement for manipulating the DES payloads on insertion and or reading.

In cases where payloads to be stored are greater than one frame a linkage is maintained between the frames so that the entire payload can be extracted. The LDL DES extended frame contains a field named Next LDL Frame ID. which is the next sequential 64 K octets of the data element stored cached on a DataSpace. This is an iterative process until no more frames are required for storing the entire data element. When the last frame containing the element is reached its Next LDL Frame ID field is set to a value of zero.

For some data elements it is useful to add an additional meta information frame that describes the nature of the data element contained in the next frame s . Examples of this type of information are source origination method of delivery etc.

When an element is inserted into a DataSpace a separate meta data frame can be constructed and linked to the next series of frame s containing the actual data element. If the data element is managed by the DataSpace DOE a meta data frame will be the first frame in the data element stream of frames.

The fields and block sizes described in Tables 10 through 17 are examples and may be changed deleted modified or eliminated as required during implementation.

While the DataSpace has been illustrated and prototyped in a form that would indicate its architecture is static a DataSpace s configuration can also be dynamic in nature for any period of time including the lifespan of a DataSpace. DataSpace components including but not limited to DataSpace switches intelligent controllers clients network transport mediums processors etc. can be inserted removed and re configured as required. Examples of a when DataSpace re configuration may be required are when DataSpace component s fail DataSpace components are added or removed for performance reliability and scalability reasons adding new functionality or processing capabilities new applications and for general operation management and maintenance functionality.

While the present invention has been described by way of example in terms of two prototype systems and in terms of the specific embodiments it is to be understood that the present invention is not limited to the disclosed embodiments. It is intended to cover various modifications and similar arrangements methodologies and related devices and systems as would be apparent to those skilled in the art. Those skilled in the art to which the present invention pertains will recognize and be able to practice additional variations in the methods and systems described which fall within the teachings of this invention. Accordingly all such modifications and additions are deemed to be within the scope of the invention.

