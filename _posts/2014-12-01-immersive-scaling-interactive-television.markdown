---

title: Immersive scaling interactive television
abstract: A video media viewport/window may be progressively scaled and/or repositioned based on sequential navigational commands received via an input device. A process may include presenting video media within a viewing window that substantially spans an area of the display, and receiving, during playback of the video media, a plurality of sequential user input commands via an input device that indicate a navigational command in a first direction. In response to receiving the sequential user input commands, the system may progressively scale the viewing window to increasingly smaller size viewing windows, position the smaller size viewing windows a distance from a center of the display relative to the direction of the received navigational commands, and present one or more interactive elements outside of the smaller size viewing windows.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09380345&OS=09380345&RS=09380345
owner: Microsoft Technology Licensing, LLC
number: 09380345
owner_city: Redmond
owner_country: US
publication_date: 20141201
---
Display interfaces for conventional video media e.g. broadcast television predominantly rely on panel based overlay technology or picture in picture PiP technology to allow a viewer of the video media to interact with elements on the display screen. For example a viewer may press a button on a remote control that causes an overlay panel to be presented on the display screen while the video media continues to play in the background. In this scenario the overlay panel may present an electronic programming guide EPG television settings or other similar information to the viewer. PiP based interfaces place the video media in a small viewport that is typically positioned near a periphery of the display and is overlaid or composited on top of another video feed or on another type of user interface. In either scenario the user interface is modal meaning that the viewer can choose to be in either a video media viewing mode with the video media presented in full screen or a non viewing mode with the video media presented in the background or in a PiP viewport .

Described herein are techniques and systems for progressively scaling and repositioning a video media viewport window based on sequential navigational commands received via an input device. The size to which the viewport is scaled and or the position on the display where the viewport is placed may be in context of directional navigation from an origin point that corresponds to full screen viewing of the video media. In other words the degree of movement from the origin full screen viewing that is indicated by the sequentially received navigational commands may dictate the amount of scaling and the particular position of the scaled viewport on the display screen. For instance as a viewing user navigates via an input device further and further in a direction from the origin full screen viewing the viewing window or viewport within which the video media is presented may be progressively scaled to increasingly smaller size viewing windows and repositioned at respective distances from a center of the display. In addition upon scaling and repositioning the video media viewport interactive elements may be presented on the display in areas outside and around the scaled video media viewport. The interactive elements may reflow around the viewport as the viewport is progressively scaled and repositioned.

By providing a display interface that progressively scales and repositions the video media viewport in context of received navigational commands a continuum of experience may be provided to a user of the display interface that allows her to intuitively navigate in different directions along the continuum and to customize her viewing experience. A hierarchy of contextual content types may be accessible through the interactive elements that are presented on the display interface in a manner that reduces occlusion of rendered content presented by the interactive elements. Therefore the arrangement of displayed elements is optimized on the screen while leaving the viewport unobstructed. In addition the manner in which the scaled video media viewport is positioned on the display screen gives the user a sense of direction so that she may intuitively navigate to a particular viewing experience. Thus the user can choose how to immerse herself in contextual content at various hierarchically organized levels while keeping the video media in frame i.e. the video media remains within the frame or area of the display via a scaled viewing window. Moreover the display interface respects the user s desired viewing experience by providing a larger video media viewport in instances when it can be inferred that the user is predominantly interested in watching the video media and providing a smaller video media viewport in instances when it can be inferred that the user is predominantly interested in browsing contextual content.

Furthermore the techniques and systems described herein provide optimal user interaction performance and system efficiency. User interaction performance may be optimized through the above described intuitive navigational interfaces that give the user a sense of direction along the continuum of viewing experiences. This intuitive navigational interface works to decrease user selection navigation error rates among other things making the user interaction performance more efficient for the user. For example by providing a notion of an origin location full screen viewing as well as navigational directions that a user can traverse to receive different predetermined viewing experiences a user is less likely to navigate to an undesired experience by error thereby reducing the need for providing additional inputs to the system. In this manner the display interfaces can be specifically tailored and optimized to provide optimal user interaction performance. Additionally through the implementation of predetermined hierarchical levels along the continuum of viewing experiences the systems and techniques disclosed herein may leverage system hardware and software to improve system efficiency. For example display interface modifications may be embodied in system hardware to allow fast computational performance in some instances. Additionally or alternatively high efficiency programming languages e.g. register based operations look up tables etc. may be leveraged for certain modifications of the display interfaces where predetermined configurations can be predicted in advance.

This Summary is provided to introduce a selection of concepts in a simplified form that is further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Embodiments of the present disclosure are directed to among other things techniques and systems for progressively scaling and repositioning a video media viewport window based on sequential navigational commands received via an input device. For illustrative purposes video media is often described as broadcast television herein. However it is to be appreciated that the techniques and systems disclosed herein may utilize video media of any suitable type. A non exhaustive list of video media contemplated herein includes streaming video downloaded video digital versatile disc DVD video Blu ray video recorded video e.g. digital video recorder DVR video and so on. Thus the techniques and systems described herein are not limited to viewing broadcast television. Additionally the video media may provide any type of content such as movies television programs games software programs etc.

The computing device may be implemented as any type of computing device including but not limited to a game console a set top box STB a smart television TV a personal computer a laptop computer a tablet computer a portable digital assistant PDA a mobile phone e.g. a smart phone an electronic book e book reader a portable game player a portable media player and so forth. shows a representative computing device in the form of a game console such as the X box One game console commercially available from Microsoft Corporation of Redmond Wash. Another suitable example of computing devices may include the Apple TV console commercially available from Apple Inc. of Cupertino Calif.

The computing device may be configured to present video media on a display of the computing device . The presented video media may be retrieved from any suitable location or video content source. For example remote sources which are represented by the other computing devices may provide the video media. The other computing devices may include without limitation service providers of broadcast television e.g. cable operators satellite operators etc. service providers of streaming or downloadable video content e.g. Netflix Youtube Hulu etc. and so on. Alternatively the video media may be retrieved from local sources such as a local data store e.g. a hard drive of the computing device or from removable storage e.g. digital versatile discs DVDs Blu Ray discs thumb drives etc. .

The computing device is shown as including one or more processors and one or more forms of computer readable memory . The processor s may be configured to execute instructions applications or programs stored in the memory . In some embodiments the processor s may include hardware processors that include without limitation a hardware central processing unit CPU a field programmable gate array FPGA a complex programmable logic device CPLD an application specific integrated circuit ASIC a system on chip SoC or a combination thereof.

The computing device may also include additional data storage devices such as the removable storage introduced above and or non removable storage e.g. one or more hard disk drives HDDs . Computer readable media may include two types of computer readable media namely computer storage media and communication media. The memory the removable storage and the non removable storage are all examples of computer storage media. Computer storage media may include volatile and non volatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to random access memory RAM read only memory ROM erasable programmable read only memory EEPROM flash memory or other memory technology compact disc read only memory CD ROM DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other non transmission medium that may be used to store the desired information and which may be accessed by the computing device . Any such computer storage media may be part of the computing device . In general computer storage media may include computer executable instructions that when executed by the processor s perform various functions and or operations described herein.

In contrast communication media embody computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transmission mechanism. As defined herein computer storage media does not include communication media.

The memory may include an operating system OS which may include one or more subcomponents such as a user interface UI module and an OS agent . The UI module may be configured to output the display interface on the display of the computing device . The OS agent may be configured to assist a user of the computing device such as by providing searching functionality facilitating companion viewing functionality and other virtual assistant functions as will be described in more detail below.

The memory may further include a content retrieval module that is configured to obtain content from various sources. For example the content retrieval module may retrieve contextual content or information from the other computing devices the retrieved content being ultimately presented via the display interface as the interactive element s . As another example the content retrieval module may retrieve video content from the various aforementioned content sources such as the other computing devices the local data store the removable storage and or the non removable storage .

The local data store may store various types of data such as video content e.g. recorded videos downloaded or imported videos and so on user profile data of the users who operate the computing device and the like. Accordingly users may be able to log sign into respective user profiles e.g. via credentials biometric data e.g. fingerprint scan facial recognition etc. and so on so that the identity of each user may be determined by the computing device to customize a video media viewing experience for the specific user. In this scenario user profiles that are stored in the local data store may represent individuals and or groups of users. For example a shared family computing device may store a family profile for a group of users.

The computing device may include or may be connectable to one or more input devices for interfacing with the computing device . The input device s may include without limitation a pointing device e.g. a mouse joystick etc. physical buttons a remote control a camera s a microphone s e.g. for receiving voice commands a touch screen display and or any other suitable input device . The input device s may be a wired or wireless input device s . shows a representative example input device in the form of a remote control e.g. a game controller . In some embodiments the remote control may include various buttons and or manual actuators including without limitation one or more thumbsticks a directional pad bumper buttons and the like that allow a user to provide various types of user input commands to the computing device .

One type of input command that may be input via the input device s comprises a navigational command. A navigation command indicates a direction and the navigational command may be provided via one or more of the thumbsticks the directional pad and or the bumper buttons to provide directional input e.g. right left up down or any intermediate direction thereof to the computing device . In some embodiments tilting gestures may be enabled by an inertial measurement unit IMU of either the input device s or the computing device when the computing device is a mobile or hand held device. For example gyroscopes accelerometers magnetometers or any combination thereof may allow for sensing orientation of the input device s or the computing device itself that may be analyzed and interpreted as navigational commands. That is a user may tilt or move the computing device to her right to indicate a rightward navigational command.

In some embodiments the input device s may include a three dimensional 3D camera or depth camera that is configured to continuously detect image data i.e. capture video of a user with depth information so that movements of the user may be interpreted by onboard processing units of the computing device as user input commands e.g. navigational commands . For example a user may extend or swipe her hand to her right to indicate a rightwards navigational command. The camera based input device s may use any suitable technique to capture image data with depth information e.g. time of flight ToF structured light imaging stereo imaging etc. to facilitate the techniques described herein. In some embodiments infrared IR sensors may be used to emit and or detect IR light as a means of ToF imaging. One suitable example camera based input device that may be used for detecting user input e.g. navigational commands is the Kinect sensor used with the Xbox console system from Microsoft Corporation of Redmond Wash.

The computing device may further include one or more output devices for providing output to a user of the computing device . The output device s may include without limitation the display speakers tactile feedback mechanisms a printer and so on. For example the display may provide visual output to a user of the computing device such as when outputting the display interface on the display . The display may be of any size as represented by the width w and height h dimensions of the display interface which may span substantially the entire area w h of the display .

The computing device may further include one or more communication connections that allow the computing device to communicate with the other computing devices such as via a network e.g. the Internet . Additionally the communications connection s may enable WiFi based communication such as via frequencies defined by the IEEE 802.11 standards short range wireless frequencies such as Bluetooth or any suitable wired or wireless communications protocol that enables the computing device to interface with the other computing devices .

The computing device may be configured to receive via the network video media from one or more cable operators that maintain equipment . . . P collectively for transmitting video media over the network . For example the cable operator may broadcast television over the network to a plurality of computing devices such as the computing device . Additionally or alternatively the equipment may allow for streaming or downloadable video media that is accessible to the computing device on demand.

The computing device may be configured to retrieve via the network content from one or more content providers that maintain one or more servers . . . Q collectively for transmitting content in response to requests from the computing device . The content provider s may represent various types of content providers including without limitation social networking sites e.g. Facebook Twitter etc. video content sites e.g. Netflix Youtube Hulu etc. encyclopedia information sites e.g. Wikipedia IMDB etc. news sites electronic commerce e commerce sites media file hosting sites e.g. OneDrive commercially available from Microsoft Corporation of Redmond Wash. Google Drive commercially available from Google Inc. of Menlo Park Calif. and so on. In some embodiments the computing device may be configured to utilize one or more search engines e.g. Bing Google Search etc. to search for content available from the content provider s . For instance content that is available from the content provider s may be indexed by a search engine accessible to the computing device so that the computing device may efficiently retrieve content e.g. contextual content from the content provider s based on search queries. In some embodiments the computing device may utilize an application programming interface API to programmatically issue such queries to the search engine.

In some embodiments the computing device may be a thin client configured to display a graphical user interface GUI provided by one or more remote computing resources . The one or more remote computing resources may be provided on one or more servers . . . R collectively for carrying out some or all of the functionality of the techniques and systems described herein. As such server s may include some or all of the components of the computing device described with reference to . In this scenario the thin client computing device may include at least a display and a communication connection s to receive data over the network .

In the example illustrated by a user may have powered on the computing device and caused the computing device to present video media on the display in the full screen viewing state . In the full screen viewing state video media e.g. broadcast television may be presented within a viewing window that is sized to substantially span the entire area w h of the display . For example live television may be presented within the viewing window in the full screen viewing state . The full screen viewing state may correspond to a lowest engagement viewing experience referred to as the now playing viewing experience . The now playing viewing experience may define the origin of the continuum of viewing experiences that the user may navigate between.

In some embodiments the computing device may default to the now playing viewing experience upon power up of the computing device . In other embodiments the user may first invoke an application to view video media on the display where a viewing experience such as the now playing viewing experience may be launched by default. Such an application may be a native application that is integrated into the OS or it may be a standalone aftermarket application downloaded to the computing device or it may be a web based application rendered within a browser or the like.

In response to receipt of sequential user input commands via the input device s that each indicate a first navigational direction different display interfaces such as the display interfaces and may be output on the display . These display interfaces progressively scale and reposition the viewing window in context of the received navigational commands. For example if a user presses the rightmost portion of the directional pad of the remote control the display interface may be output on the display . Upon a subsequently received user input command in the same navigational direction as the first input command i.e. rightward or positive X direction the display interface may be output on the display . Thus as the user continues to navigate further and further to the right the display interfaces and may be output in order to progressively scale down and reposition the viewing window such that the center of the scaled down viewing window is positioned at a distance from the center of the display . The scaling and repositioning of the viewing window may include interpolated data points between two discrete positions to make the scaling and repositioning appear smooth and continuous to the viewer. In some embodiments the scaling and repositioning between two relative positions may be presented as more discrete steps. In some instances a component of the direction from the center of the display to the center of the scaled down viewing window is opposite the direction of the navigational command. For example when a rightward navigational command is received the center of the scaled viewing window may be positioned in a direction from the center of the display that has at least a component direction in the leftward direction. In other words the direction from the center of the display to the center of the scaled viewing window may be in a diagonal direction e.g. upward and leftward direction and therefore the diagonal direction may be represented with two components e.g. an upward component and a leftward component of the diagonal direction at least one of them being different than the direction of the navigational command.

In addition one or more interactive elements may be presented outside of the viewing window in each of the display interfaces and . These interactive elements may provide content in context of the navigational commands that corresponds to hierarchically arranged types of content as shown by the continuum .

In the illustrative example shown in the content to be displayed via the interactive elements may correspond to different viewing experiences along the continuum of viewing experience. In the rightward direction along the continuum viewing experiences may include without limitation a social viewing experience an agent viewing experience and a partners viewing experience each of which will be described in more detail below with reference to the following figures. In other words as the user navigates farther and farther in the rightward i.e. positive X direction she can be immersed in different hierarchically organized viewing experiences e.g. viewing experiences that are output on the display via the dynamically changing display interfaces and for example.

Similarly if sequential user input commands are received via the input device s indicating a leftward i.e. a negative X direction the display interfaces and may be output on the display in response to the received sequential input. The display interfaces and like the display interfaces and progressively scale and reposition the viewing window in context of the received navigational commands only this time the viewing window may be repositioned by moving it in the opposite direction from the center of the display . Thus as the user continues to navigate further and further to the left the display interfaces and may be sequentially output on the display in order to progressively scale down and reposition the viewing window and to present one or more interactive elements outside of the viewing window . These interactive elements may provide content in context of the navigational commands that corresponds to the viewing experiences in the leftward direction along the continuum . illustrates how the interactive elements can be reflowed around the scaled down viewing window allowing the viewing window to remain visible without occluding the presentation of the interactive elements and the associated content therein.

In the illustrative example shown in the hierarchically arranged viewing experiences in the leftward direction may include without limitation a favorites viewing experience a my shows viewing experience and a friends viewing experience each of which will be described in more detail below with reference to the following figures. In other words as the user navigates farther and farther in the leftward i.e. negative X direction she can be immersed in different hierarchically organized viewing experiences e.g. the viewing experiences that are output via the dynamically changing display interfaces and for example. The hierarchical organization of predetermined viewing experiences can be leveraged by the system to utilized high efficiency algorithms and or combinations of hardware and software that improve computational performance and system efficiency. For example having predetermined layouts for the display interface along the continuum may allow for modifications of the display interface between points on the continuum to be implements via hardware algorithms or more efficient programming algorithms e.g. lookup tables .

The example shown in illustrates how the display interfaces give the user a sense of directional navigation when navigating through the continuum . This intuited sense of directional navigation through the continuum provides a significant benefit in user interaction performance by clearly indicating to the user how to navigate the continuum thereby reducing or altogether eliminating selection navigation error rates which cause unnecessary processing of input commands by the system. In other words as the user navigates farther and farther in a particular direction the manner in which the viewing window is positioned relative to the center of the display acts as a visual cue to the user that tells her if you would like to go back to the full screen viewing state you can move toward the viewing window . For example when the user navigates farther and farther to the right she knows intuitively to move toward the viewing window i.e. in the leftward or negative X direction which can be realized through sequential user input commands using the input device s .

It is to be appreciated that the display interfaces may comprise modeless interfaces e.g. modeless GUIs that are implemented as an application configured to simultaneously present the scaled viewing window and the interactive element s while allowing user interaction therewith. In this sense the display interfaces are embodied via a single interactive application. For example the viewing window can be temporarily ignored by the user while the user interacts with the interactive element s of the same application and vice versa. In other words user input is interpreted the same for all presented user interface elements at all times.

The example viewing experiences in the continuum are merely example viewing experiences. Furthermore the example left and right directions shown in are merely example directions that may be utilized with an implementation of the system. For example navigational commands in the upwards i.e. positive Y direction downwards i.e. negative Y direction and or intermediate directions may cause the dynamically changing display interfaces to be output on the display in a similar fashion.

If the user provides user input via the input device s such as pressing a button e.g. a portion of the directional pad on the remote control the display output shown in may be rendered on the display . Specifically a panel sometimes called the now playing panel may be overlaid on top of the video media presentation. Even though the panel takes up a portion of the display area e.g. a portion of the bottom of the display screen the display output of may still be considered as the full screen viewing state because the video media continues to span substantially the entire area of the display i.e. the panel merely obscures a small portion of the bottom of the video media . It is to be appreciated that other relatively minor display elements may be overlaid upon or presented around the video media in the full screen viewing state such that the video media does not have to span the entire area of the display in the full screen viewing state .

In some embodiments the panel may include a navigation bar that provides a visual indicator of the current viewing experience along the continuum . shows the navigation bar at the bottom of the panel but it may be placed anywhere within the panel and oriented in any suitable manner e.g. vertically oriented without changing the basic characteristics of the system. In some embodiments the visual indicator may comprise a slider element that is movable along the navigation bar in response to navigational commands received from the input device s .

If the user moves the focus element to a different channel such as Network that is currently broadcasting a Major League Soccer program and the user selects that channel the video media may present a live broadcast of the program on that channel as is shown by the display output of . The display output shown in is still considered as the full screen viewing state which in this case may still present the panel for at least a period of time. That is the panel may disappear after a period of time has lapsed without any received input from the input device s .

The now playing viewing experience that is represented by may be considered a lowest engagement viewing experience that respects the fact that the user is watching the video media. The now playing panel honors the fact that the user is watching the video media by being rendered on the display as a minimally intrusive panel that allows the user to find out what shows are on when they end and other functionality to aid the user s now playing viewing experience .

From the full screen viewing state corresponding to the now playing viewing experience the user may navigate in any direction along the continuum to immerse themselves in different viewing experiences. illustrates an example where the user has provides input via the input device s that indicates a rightwards i.e. positive X navigational command along the navigation bar . The display output of represents the social viewing experience that was introduced with reference to . To provide the social viewing experience a display interface such as the display interface of may be output on the display as shown in . The display interface presents a scaled down video media viewport in the upper left corner of the display . In the example of the viewing window is shown as comprising about to about of the display area. This particular size range of the viewing window respects the fact that the user may still desire to watch the video media while concurrently browsing the interactive elements that are presented outside of the viewing window . In fact the notion that the display output of represents a viewing experience exemplifies the fact that the user may prefer to watch the video media in the social viewing experience on a more permanent basis. In contrast to typical PiP viewports which are too small to continually watch video media in the size of the viewing window allows for more permanent viewing of video media while interacting with the content of the interactive elements . The continuum allows the user to choose what viewing experience to immerse herself in. In some embodiments the computing device may be configured to remember a particular viewing experience as a favorite viewing experience of a particular user so that the display output can default to the user s favorite viewing experience upon powering on the computing device . In some embodiments the computing device may remember a most recent viewing experience that the user was in before the user exited to the full screen now playing viewing experience . For example the user may have viewed the partners viewing experience then selected a back button B button on the input device to return to full screen and then provided a directional input e.g. selection of the directional pad . In response to the directional input the display interface may return to the most recent viewing experience in this case the partners viewing experience instead of traversing through the intermediate viewing experiences between the now playing viewing experience and the partners viewing experience .

The social viewing experience may include interactive elements that provide social content so that the user can discover activity in a community of users that is related to the program being played back within the viewing window . The content retrieval module may retrieve such content over the network from the content provider s . For example the content retrieval module may retrieve contextual content from social networking sites such as Twitter Facebook Instagram and so on. The content retrieval module may search social networking sites for relevant content based on keywords image analysis or any other suitable search technology. In some embodiments a search engine may be utilized to search the content available from social networking sites. Because of the limited real estate on the display outside of the area allocated for the video media viewport the content retrieval module may filter or otherwise curate the retrieved content to a best content subset that is to be presented via the interactive elements . The selection of the best content may be based on a number of factors such as quality of media files e.g. images or videos of the retrieved content diversity indicators that analyze posts e.g. text images videos etc. that are not too similar age of the posts e.g. newer posts may be selected over older ones and or user interaction characteristics e.g. the number of likes re shares comments top trending posts etc. . Furthermore a current state of relationship between the user of the computing device and other users in the social community may factor into the filtering curating of content e.g. close friends and family activity may be selected over more distant social connections when applicable .

Because the user is watching a soccer game in the viewing window the content retrieval module may search for posts status updates and media files e.g. images videos etc. that are related to soccer in general and or to the specific soccer game being broadcast in the viewing window . For example the interactive elements and may present a social media post from a user of a social networking SNW service regarding an interview of one of the star players in the game that is being broadcast. The interactive element may present buttons that allow the user to save the posted video to the local data store of the computing device to re share the posted video via the social networking service or via another social networking service and or to send the video or a link to the video via electronic mail e mail short message service SMS text and the like. The interactive element may present a picture that a user posted to a social networking site e.g. a user who is at the soccer game being shown in the viewing window . The interactive elements and may present status updates or posts e.g. microblogs from users of various social networking sites that are related to the currently playing video media in the viewing window . The content presented via the interactive elements may be contextual by relating to the currently broadcast program and may provide a more social viewing experience for the user.

From the social viewing experience the user may provide another rightward navigational command e.g. by pressing the rightmost portion of the directional pad on the remote control to navigate to the agent viewing experience illustrated by . It is noted that the size and or position of the video media viewport between the social viewing experience and the agent viewing experience may not change. In other words individual ones of sequentially received navigational commands may not cause any scaling or repositioning of the video media viewport but may cause the type of content of the interactive elements outside of the viewing window to change. The transition from to illustrates this scenario. In this case the additional rightward navigational command caused the interactive elements to be updated with different content that is related to the agent viewing experience . The visual indicator may also move farther to the right in response to the received navigational command in the rightward direction to indicate to the user that she is in the agent viewing experience .

The agent viewing experience may cause the display interface to present an interactive element that indicates to the user that the OS agent is currently viewing the video media together with the user. One suitable example of an OS agent for use with the agent viewing experience is Cortana commercially available from Microsoft Corporation of Redmond Wash. The OS agent may view the video media with the user by analyze metadata e.g. closed captioning associated with the video media performing visual and or audio analysis e.g. voice recognition song recognition etc. of the video stream and the like. As the OS agent performs real time analysis of the video media that is playing in the viewing window the OS agent may create a series of time entries shown as interactive elements and . For example at time 13 45 the OS agent may have analyzed metadata of the video media or the video stream itself to determine that the soccer match is being played at the soccer stadium in Seattle Wash. and created time entry . At a later time 14 21 the OS agent recognized that the teams in the soccer match are Seattle vs. Los Angeles and created time entry . At an even later time 15 02 the OS agent may have recognized via audio recognition that the announcer said the goalie s name John Goalie and created time entry . As new time entries are added the previous time entries may be pushed down until they disappear from the display screen. The user may still scroll back through previous time entries to recall content related to those time entries.

As each time entry is presented and or in response to the focus element being moved over a particular time entry e.g. time entry interactive elements may be updated with content that is relevant to that time entry . For example the content retrieval module may access a sports site that tracks statistics of the soccer match for each player and for the teams to present for example percentage of shots that were saved by John Goalie shown by interactive element . The content retrieval module may also retrieve videos that are relevant to the time entry such as a highlight video . Links to informational encyclopedia and or news sites may be presented such as the link shown in interactive element . Player statistics may be retrieved from any suitable content source and presented via interactive element .

From the agent viewing experience the user may provide another rightward navigational command e.g. by pressing the rightmost portion of the directional pad on the remote control to navigate to the partners viewing experience illustrated by . The visual indicator may be presented in a rightmost position in response to the received navigational command in the rightward direction to indicate to the user that she is in the partners viewing experience . Furthermore the viewing window may be further scaled down in size to a smaller size viewing window e.g. about of the display area or less and repositioned further to the left and further above the center of the display . The size of the scaled viewing window may be based on the notion that it can be inferred that the user is no longer predominantly interested in watching the video media program but is perhaps more interested in immersing themselves deeper into the contextual content provided via the interactive elements . The associated display interface e.g. the display interface may be a highest engagement form of the display interface to engage the user with contextual content via the interactive elements as much as possible. Thus the viewing window may be scaled to various sizes the viewing window is not limited to scaling to only one size depending on the particular viewing experience that the user navigates to along the continuum .

In the viewing window is still positioned in the corner of the display but it is not limited to a corner position. The direction of movement of the viewing window is generally different from the direction of the received navigational commend which in this case is in the rightward i.e. positive X direction. Accordingly the partners viewing experience may be enabled by outputting the display interface of .

The content presented via the interactive elements in the partners viewing experience may comprise news articles blogs exclusive content from the studio that provides the video media program or any similar type of content that is related to the video media program playing in the viewing window . Again because of the limited real estate of the display a curated set of the best content related to the video media program may be presented on the display screen yet the user may be able to scroll vertically and or horizontally or otherwise page through additional off screen interactive elements that provide additional content for the partners viewing experience . shows the interactive element as providing an article from a website that is related to the soccer program being played in the viewing window . The content retrieval module may have leveraged a search engine to retrieve the article presented via interactive element . Interactive element may present a highlights video for one of the teams playing in the soccer program while interactive element may present another highlight clip of a player for one of the two soccer teams named Jim Q. Player. Interactive element may upon selection allow the user to browse soccer related video games. In some embodiments the user may be able to launch a video game that is related to the video media program being played in the viewing window so that the user can play the related game in parallel to watching the program. For example the user may be watching Jeopardy and may decide that they want to play the video game while watching the program.

In some embodiments if the user were to move the focus element over the interactive element as shown in to begin playing the highlights video the computing device may temporarily pause the playback of the video media in the viewing window while the highlights video is played back in another window outside of the viewing window . To provide this functionality the computing device may include a DVR or other recording component to at least buffer the video media as it is played back so that it may be paused and or so that the user may seek backward forward in the video media stream. In some embodiments the highlights video upon selection may relocate to the larger interactive element while it is played back. In some embodiments the highlights video may take over a full screen viewing state at least temporarily while the highlights video is played back and upon termination the display output may revert to the display interface as depicted in .

The hierarchical organization of the viewing experiences in the continuum of may be organized such that the viewing experiences in the rightward positive X direction allow a user to immerse herself further and further into contextual content that is related to the video media program being played back in the viewing window while the viewing experiences in the leftward negative X direction allow the user to immerse herself further and further into content that is not related to the show but is in context of the received navigational commands. Thus illustrate viewing experiences in the rightward positive X direction that provide contextual content that is related to the video media program in the viewing window and the following figures will illustrate the types of content that may be provided in the viewing experiences that are in the leftward negative X direction. It is to be appreciated that the directions and content types can be hierarchically organized in other ways and that the leftward rightward organization illustrated herein are merely one example implementation.

Referring now to an example display output with a navigation interface is shown. The navigation interface may be invoked in response to receipt of user input via the input device such as in response to the user pressing the bumper buttons on the remote control . The navigation interface may replicate the continuum of viewing experiences introduced with reference to and may allow a user to skip to a particular viewing experience along the continuum . For example the user may provide user input via the input device s in order to move the focus element to any particular viewing experience in order to navigate directly to that viewing experience. This may be desirable if the user wants to navigate from the partners viewing experience to the friends viewing experience for example rather than traversing back through each intermediate viewing experience in the continuum . Additionally or alternatively the user may press a back button on the remote control to return to the now playing viewing experience in the full screen viewing state . The above described features work to improve the efficiency of user interaction performance. For example the system can change from one viewing experience to another non adjacent viewing experience without having to process and render the display interfaces associated with intermediate viewing experiences on the continuum . This greatly improves user interaction efficiency as the user navigates the continuum.

Imagine for example that the user navigates to the favorites viewing experience by for example moving the focus element over the favorites viewing experience within the navigation interface of . The resulting display output may be that which is shown in . In the favorites viewing experience the visual indicator may be positioned on a portion of the navigation bar that indicates to the user that she is in the favorites viewing experience which in this case is slightly left of center on the navigation bar . The viewing window may also be scaled and positioned in a direction from the center of the display that is opposite the direction of navigation from the origin i.e. now playing viewing experience to the favorites viewing experience . For example because the favorites viewing experience is oriented to the left of the continuum origin the center of the viewing window may be positioned right of the center of the display and or above or below the center of the display . In the example of the viewing window is positioned in the top right corner of the display and is scaled to a size that is about to about of the display area to honor the fact that the user may be predominantly interested in viewing the video media program while browsing the additional content within the favorites viewing experience .

The favorites viewing experience may provide via interactive elements and presented outside of the viewing window recently viewed channels and or favorite channels of the user. The interactive element may comprise a guide that is scrollable and or pageable by providing input via the input device s . shows that the user has moved the focus element over Network and has provided user input via the input device s to select the program Car show on that network channel for viewing in the video media viewport . Interactive element may provide a brief synopsis of the program being broadcast on the highlighted channel as well as one or more interactive display elements such as a Record element an Add to Favorites element and or a Full Detail element similar to those described with reference to the display output of . Within the favorites viewing experience the user may continue to watch the video media program in the viewing window while browsing through their recently watched and or favorite channels.

From the favorites viewing experience the user may provide a leftward navigational command e.g. by pressing the leftmost portion of the directional pad on the remote control to navigate to the my shows viewing experience illustrated by . The visual indicator may be moved to the left along the navigation bar in response to the received navigational command in the leftward direction to indicate to the user that she is in the my shows viewing experience . Again it is noted that the size and or position of the video media viewport between the favorites viewing experience and the my shows viewing experience may not change in the transition from to yet the type of content of the interactive elements outside of the viewing window may update in context of the navigational command. In this case the additional leftward navigational command from the favorites viewing experience caused the interactive elements to be updated with different content that is related to the my shows viewing experience .

The content presented via the interactive elements of may include programs that the user has recorded using the DVR functionality of the computing device programs are being recorded or marked scheduled for recording programs that the user has marked as favorites programs that the user has recently watched and or system recommendations for programs that are likely to be of interest to the user based on the user s viewing history. shows interactive element as a video that the user has recently recorded or saved to the local memory of the computing device . Interactive element may present a program that the user has marked as a favorite and may further indicate a number of shows that are new at least in terms of whether the user has watched the programs or not . Interactive element may present a program that the user has recently watched which may be more of a system inferred favorite program. The column of interactive elements in may be scrollable and or pageable so that the user can browse additional content in the my shows viewing experience . Interactive element may present a system recommendation of a program that the user may be interested in based on the user s viewing history.

From the my shows viewing experience the user may provide another leftward navigational command e.g. by pressing the leftmost portion of the directional pad on the remote control to navigate to the friends viewing experience illustrated by . The visual indicator may be positioned at a leftmost portion of the navigation bar in response to the received navigational command in the leftward direction to indicate to the user that she is in the friends viewing experience . In addition the viewing window may be scaled and repositioned in a direction from the center of the display that is different from the direction of the received navigational command. In this case in response to the leftward i.e. negative X direction navigational command the position of the viewing window is moved to the right of the center of the display and or above or below the center of the display . In the viewing window is shown as being placed in the upper right corner of the display . The smaller size of the scaled viewing window appreciates the fact that the user may be less interested in watching the video media program and relatively more interested in browsing the additional content provided via the interactive elements outside of the viewing window . The associated display interface e.g. the display interface may be a highest engagement form of the display interface to engage the user with additional content via the interactive elements as much as possible.

The process is described with reference to the architectures and of . Particular reference may be made to the UI module the input device and the display among other elements shown in .

At video media e.g. broadcast television may be presented on a display within a viewing window on the display . In some embodiments the viewing window may substantially span an entire area of the display . In other words a full screen viewing state may be invoked to present the video media full screen. This may be a default viewing state such as when a user powers on the computing device associated with the display .

At the computing device may receive during playback of the video media a first user input via an input device that indicates a navigational command in a first direction within a plane that is parallel to a front surface of the display . The diagram to the right of shows an example where user input may be provided via the directional pad of the remote control . In this case the user may press the rightmost portion of the directional pad to indicate a rightward i.e. positive X direction navigational command within the plane that is parallel to the front surface of the display .

At in response to the first user input received at the UI module scale down and positioned the center of video media viewport on a portion of the display that is a distance from the center of the display . In some embodiments a component direction from the center of the display to the position of the center of the scaled viewing window may be different than e.g. opposite the first direction of the navigational command. For example when the navigational command is in a rightward i.e. positive X direction in the plane of the display screen the movement of the viewing window may be in the leftward upward downward and or intermediate direction in the plane of the display screen. Furthermore one or more interactive elements may be presented outside of the scaled viewing window at . In some embodiments the interactive element s may surround the viewing window on at least two sides of the viewing window . The interactive elements may present contextual content that in some instances may relate to the video media program being played back in the viewing window .

At the computing device may receive a second sequential user input via an input device that indicates a navigational command in the first direction i.e. the same direction as the navigational command at . The second user input at is received after the first user input such that the first and second user inputs make up a series of user inputs or a plurality of sequential user inputs that indicate navigational commands in the same direction.

At in response to the second user input received at the viewing window that presents the video media may be scaled down even further and re positioned on a portion of the display that is in a direction from the center of the display that is different than the first direction of the navigational command. Again if the navigational command is in the rightward direction the movement repositioning of the viewing window may be in the leftward upward downward and or intermediate direction in the plane of the display screen. Furthermore one or more interactive elements may be presented outside of the scaled viewing window at . In some embodiments the interactive elements may present content that corresponds to a different viewing experience than the viewing experience at . That is the interactive element s presented on the display at may include a different type of content e.g. social based content than the content of the interactive element s that are presented on the display at e.g. agent based content .

The process allows the user of the computing device to navigate through a continuum of viewing experiences so that she may immerse herself in a viewing experience of her choice. The dynamically changing display interfaces e.g. display interfaces and progressively scale and reposition the video media viewport in a manner that gives the user a sense of direction for intuitive navigation throughout the continuum .

The environment and individual elements described herein may of course include many other logical programmatic and physical components of which those shown in the accompanying figures are merely examples that are related to the discussion herein.

The various techniques described herein are assumed in the given examples to be implemented in the general context of computer executable instructions or software such as program modules that are stored in computer readable storage and executed by the processor s of one or more computers or other devices such as those illustrated in the figures. Generally program modules include routines programs objects components data structures etc. and define operating logic for performing particular tasks or implement particular abstract data types.

Other architectures may be used to implement the described functionality and are intended to be within the scope of this disclosure. Furthermore although specific distributions of responsibilities are defined above for purposes of discussion the various functions and responsibilities might be distributed and divided in different ways depending on circumstances.

Similarly software may be stored and distributed in various ways and using different means and the particular software storage and execution configurations described above may be varied in many different ways. Thus software implementing the techniques described above may be distributed on various types of computer readable media not limited to the forms of memory that are specifically described.

A computer implemented method comprising causing presentation of video media within a viewing window that substantially spans an area of a display receiving a plurality of sequential user inputs e.g. push button touch screen voice command gestural camera based etc. that indicate a navigational command in a first direction e.g. horizontal vertical or intermediate direction within a plane that is substantially parallel to a front surface of the display and in response to receiving the plurality of sequential user inputs progressively scaling the viewing window to increasingly smaller size viewing windows based at least in part on individual ones of the sequential user inputs positioning respective centers of the smaller size viewing windows at respective distances from a center of the display and causing presentation on the display of one or more interactive elements outside of the smaller size viewing windows.

The computer implemented method of Example One wherein the respective centers of the smaller size viewing windows are positioned in a direction from the center of the display having at least a component of the direction that is in a different e.g. perpendicular orthogonal opposite etc. direction than the first direction of the navigational command.

The computer implemented method of the previous examples alone or in combination wherein the different direction is opposite the first direction.

The computer implemented method of the previous examples alone or in combination wherein the one or more interactive elements are reflowed around the smaller size viewing windows and present or link e.g. hyperlink to content that is related to the video media.

The computer implemented method of the previous examples alone or in combination further comprising receiving a non navigational user input e.g. press of a back button and in response to the receiving the non navigational user input reverting to causing presentation of the video media within the viewing window that substantially spans the area of the display.

The computer implemented method of the previous examples alone or in combination wherein the positioning comprises progressively positioning the smaller size viewing windows at increasingly greater distances from the center of the display.

The computer implemented method of the previous examples alone or in combination further comprising analyzing the video media during playback of the video media and deriving content to be presented by the one or more interactive elements from the analyzing.

The computer implemented method of the previous examples alone or in combination wherein the smaller size viewing windows and the one or more interactive elements displayed after each sequential user input are included within a modeless graphical user interface that is implemented as an application that presents while allowing user interaction with one of the smaller size viewing windows and the one or more interactive elements.

A system comprising a display having a front surface a center and an area an input device e.g. a microphone camera remote control etc. one or more processors and memory storing computer executable instructions that when executed by the one or more processors cause the one or more processors to perform acts comprising causing presentation of video media within a viewing window on the display receiving a plurality of sequential user inputs e.g. push button touch screen voice command gestural camera based etc. via the input device that indicate a navigational command in a first direction e.g. horizontal vertical or intermediate direction within a plane that is substantially parallel to the front surface of the display and in response to receiving the plurality of sequential user inputs progressively scaling the viewing window to increasingly smaller size viewing windows based at least in part on individual ones of the sequential user inputs positioning respective centers of the smaller size viewing windows at respective distances from the center of the display and causing presentation on the display of one or more interactive elements outside of the smaller size viewing windows.

The system of Example Nine wherein the respective centers of the smaller size viewing windows are positioned in a direction from the center of the display having at least a component of the direction that is in a different e.g. perpendicular orthogonal opposite etc. direction than the first direction of the navigational command.

The system of the previous examples alone or in combination wherein the different direction is opposite the first direction and wherein the positioning comprises positioning the smaller size viewing windows in a corner of the display.

The system of the previous examples alone or in combination further comprising an operating system agent stored in the memory and executable by the one or more processors to analyze the video media during playback of the video media and derive content to be presented by the one or more interactive elements based at least in part on analyzing the video media.

The system of the previous examples alone or in combination wherein the smaller size viewing windows and the one or more interactive elements are included within a modeless graphical user interface that is implemented as an application that presents while allowing user interaction with one of the smaller size viewing windows and the one or more interactive elements.

The system of the previous examples alone or in combination wherein the input device comprises a remote control having a directional pad and the user inputs are received via the directional pad.

The system of the previous examples alone or in combination wherein the one or more interactive elements present or link to content that is related to the video media.

A computer implemented method comprising causing presentation of video media within a viewing window on a display receiving a first user input e.g. push button touch screen voice command gestural camera based etc. that indicates a navigational command in a first direction e.g. horizontal vertical or intermediate direction within a plane that is substantially parallel to a front surface of the display in response to receiving the first user input scaling down the viewing window to a first reduced size viewing window positioning a center of the first reduced size viewing window a first distance from a center of the display and causing presentation on the display of one or more first interactive elements outside of the first reduced size viewing window receiving a second user input e.g. push button touch screen voice command gestural camera based etc. that indicates the navigational command in the first direction and in response to receiving the second user input command scaling down the first reduced size viewing window to a second reduced size viewing window positioning a center of the second reduced size viewing window a second distance from the center of the display and causing presentation on the display of one or more second interactive elements outside of the second reduced size viewing window.

The computer implemented method of Example Sixteen wherein the center of the first reduced size viewing window is positioned in a direction from the center of the display that is different e.g. perpendicular orthogonal opposite etc. than the first direction of the navigational command.

The computer implemented method of the previous examples alone or in combination wherein the one or more first interactive elements present or link e.g. hyperlink to a first type of content and the one or more second interactive elements present or link to a second type of content.

The computer implemented method of the previous examples alone or in combination further comprising analyzing the video media during playback of the video media to derive content presented by the one or more first interactive elements or the one or more second interactive elements.

The computer implemented method of the previous examples alone or in combination wherein the first reduced size viewing window and the one or more first interactive elements are included within a modeless graphical user interface that is implemented as an application that presents while allowing user interaction with the first reduced size viewing window and the one or more first interactive elements.

A system comprising means for displaying video media the means for displaying having a front surface a center and an area means for receiving user input means for executing computer executable instructions e.g. processors including for example hardware processors such as central processing units CPUs system on chip SoC etc. and means for storing computer executable instructions e.g. memory computer readable storage media such as RAM ROM EEPROM flash memory etc. that when executed by the means for executing computer executable instructions cause performance of acts comprising causing presentation of video media within a viewing window on the means for displaying receiving a plurality of sequential user inputs e.g. push button touch screen voice command gestural camera based etc. via the means for receiving user input that indicate a navigational command in a first direction e.g. horizontal vertical or intermediate direction within a plane that is substantially parallel to the front surface of the means for displaying and in response to receiving the plurality of sequential user inputs progressively scaling the viewing window to increasingly smaller size viewing windows based at least in part on individual ones of the sequential user inputs positioning respective centers of the smaller size viewing windows at respective distances from the center of the means for displaying and causing presentation on the means for displaying of one or more interactive elements outside of the smaller size viewing windows.

The system of Example Twenty One further comprising means for analyzing the video media the means for analyzing stored in the memory and executable by the means for executing computer executable instructions to analyze the video media during playback of the video media and derive content to be presented by the one or more interactive elements based at least in part on analyzing the video media.

In closing although the various embodiments have been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended representations is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as example forms of implementing the claimed subject matter.

