---

title: Sound visualization method and apparatus of electronic device
abstract: A method and an apparatus are provided for audio data playback in an electronic device. Pieces of color information, included in an image that is matched to audio data, are acquired, when the audio data is requested. At least one of the pieces of color information is mapped to at least one sound level range of predetermined audible sound according to a percentage of a respective color in the image. A predetermined object pattern is displayed using the at least one of the pieces of color information mapped to the at least one sound level range of the audio data, when the audio data is played.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09594473&OS=09594473&RS=09594473
owner: Samsung Electronics Co., Ltd
number: 09594473
owner_city: 
owner_country: KR
publication_date: 20140826
---
This application claims priority under 35 U.S.C. 119 a to a Korean Patent Application filed on Aug. 27 2013 in the Korean Intellectual Property Office and assigned Serial No. 10 2013 0101838 the entire disclosure of which is incorporated herein by reference.

The present invention relates generally to sound visualization in an electronic device and more particularly to a method and an apparatus of an electronic device for visualizing sound with an image associated with the sound.

Various types of electronic devices are equipped with a sound playback function. Examples of the sound playback function equipped electronic device may include mobile phones smartphones tablet computers laptop computers desktop computers Televisions TVs audio players electronic dictionaries electronic pen recorders etc.

The sound playback enabled electronic devices may be designed to play various formats of sound. For example some may be designed to play predetermined audio formats of music and others may be designed to play audiovisual formats of motion pictures. When sound is associated with a certain image the electronic device plays the image in association with the sound. When sound is synchronized with a motion picture the electronic device plays the sound in synchronization with the motion picture.

However even when playing the sound synchronized with an image the electronic device may be required to present a user customized image or a graphic equalizer. In such a case the electronic device may present a sound equalizer graphic animation to the user. When providing the user with the sound equalizer graphic animation the graphic animation pattern may be preconfigured. When the electronic device plays sound it may be configured such that various graphic animation patterns such as circle polygonal and cubical waveforms are selectively presented depending on whether the frequency band of the sound is low intermediate or high.

However when the electronic device plays sound with a predetermined pattern of graphic animation in association with the frequency band of the sound there is a consideration of color tone. For example if any predetermined color pattern is stored in advance or if the user selects a certain color the electronic device displays the graphic animation with the predetermined color pattern or with the color selected by the user.

Thus there is no efficient use of an image matched with the sound. Suppose that a music album of a singer is played. It is likely that the music album may be provided with a visual concept intended by the singer composer or songwriter for expressing the music contained in the album. However the sound interactive graphic animation of the electronic device is limited to using only the sound spectrum data and wave data.

It is likely that the cover image and images matched to the songs contained in the album of a musician express the moods of the songs and are designed to have identities.

The present invention has been made to address at least the above problems and or disadvantages and to provide at least the advantages described below. Accordingly an aspect of the present invention provides a sound visualization method and apparatus of an electronic device that is capable of providing visual effects expressing the mood and emotion of the music by combining color data of the cover image of a music album or the image matched to a specific song of the music album and spectrum data and wave data of the music or song .

Another aspect of the present invention provides a sound visualization method and apparatus of an electronic device that is capable of providing image graphic or animation interactive to the sound using the image matched to the sound or the color of the image.

An additional aspect of the present invention provides a sound visualization method and apparatus of an electronic device that is capable of presenting the user with an image graphic or animation that is corresponds to the sound.

In accordance with an aspect of the present invention a method is provided for audio data playback in an electronic device. Pieces of color information included in an image that is matched to audio data are acquired when the audio data is requested. At least one of the pieces of color information is mapped to at least one sound level range of predetermined audible sound according to a percentage of a respective color in the image. A predetermined object pattern is displayed using the at least one of the pieces of color information mapped to the at least one sound level range of the audio data when the audio data is played.

In accordance with another aspect of the present invention an apparatus is provided for sound visualization of an electronic device. The apparatus includes a memory configured to store audio data images matched to the audio data preconfigured object patterns color conversion information and information for sorting sound level ranges. The apparatus also includes an audio codec configured to convert the audio data to an electric audio signal. The apparatus additionally includes a speaker configured to output the electric audio signal in a form of an audible sound wave. The apparatus further includes a display module configured to display one of the object patterns according to the sound level range of the output audio signal. The apparatus also includes a control unit configured to control acquiring pieces of color information included in an image that is matched to the audio data when the audio data is requested mapping at least one of the pieces of color information to at least one sound level range of predetermined audible sound according to a percentage of a respective color in the image and displaying a predetermined object pattern on the display module using the at least one piece of color information mapped to the at least one sound level range of the audio data when the audio data is played.

Embodiments of the present invention are described in detail with reference to the accompanying drawings. The same or similar components may be designated by the same or similar reference numerals although they are illustrated in different drawings. Detailed descriptions of constructions or processes known in the art may be omitted to avoid obscuring the subject matter of the present invention.

The terms and words used in the following description and claims are not limited to their dictionary meanings but are merely used by the inventor to enable a clear and consistent understanding of the present disclosure. Accordingly it should be apparent to those skilled in the art that the following description of various embodiments of the present invention is provided for illustration purposes only and not for the purpose of limiting the present invention.

It is to be understood that the singular forms a an and the include plural referents unless the context clearly dictates otherwise. Thus for example reference to a component surface includes reference to one or more of such surfaces.

The expressions such as include and may include which may be used herein denote the presence of the disclosed functions operations and constituent elements and do not limit one or more additional functions operations and constituent elements. Terms such as include and or have may be construed to denote a certain characteristic number step operation constituent element component or a combination thereof but may not be construed to exclude the existence of or a possibility of addition of one or more other characteristics numbers steps operations constituent elements components or combinations thereof.

Furthermore the expression and or includes any and all combinations of the associated listed words. For example the expression A and or B may include A may include B or may include both A and B.

Expressions including ordinal numbers such as first and second etc. may modify various elements. However such elements are not limited by the above expressions. For example the above expressions do not limit the sequence and or importance of the elements. The above expressions are used merely for the purpose to distinguish an element from the other elements. For example a first user device and a second user device indicate different user devices although both of them are user devices. For example a first element could be termed a second element and similarly a second element could be also termed a first element without departing from the scope of the present invention.

In the case where a component is referred to as being connected to or accessed by another component it should be understood that the component may not only be directly connected to or accessed by the other component but also that there may exist another component between them. When a component is referred to as being directly connected to or directly accessed by another component it should be understood that there is no component therebetween. The terms used herein are only used to describe specific embodiments and are not intended to limit the present invention. As used herein the singular forms are intended to include the plural forms as well unless the context clearly indicates otherwise.

According to an embodiment of the present invention an electronic device may be a device that includes a communication function. For example the device corresponds to at least one of a smartphone a tablet Personal Computer PC a mobile phone a video phone an e book reader a desktop PC a laptop PC a netbook computer a Personal Digital Assistant PDA a Portable Multimedia Player PMP a digital audio player a mobile medical device an electronic bracelet an electronic necklace an electronic accessory a camera a wearable device an electronic clock a wrist watch home appliances for example an air conditioner vacuum an oven a microwave a washing machine an air cleaner and the like an artificial intelligence robot a TeleVision TV a Digital Video Disk DVD player an audio device various medical devices for example Magnetic Resonance Angiography MRA Magnetic Resonance Imaging MRI Computed Tomography CT a scanning machine an ultrasonic wave device or the like a navigation device a Global Positioning System GPS receiver an Event Data Recorder EDR a Flight Data Recorder FDR a set top box a TV box an electronic dictionary vehicle infotainment device electronic equipment for a ship for example navigation equipment for a ship gyrocompass or the like avionics a security device electronic clothes an electronic key a camcorder game consoles a Head Mounted Display HMD a flat panel display device an electronic frame an electronic album furniture or a portion of a building structure that includes a communication function an electronic board an electronic signature receiving device a projector and the like. It is obvious to those skilled in the art that the electronic device according to an embodiment of the present invention is not limited to the aforementioned devices.

Referring to an electronic device includes a bus a processor a memory a user input module a display module a communication module and other similar and or suitable components.

The bus may be a circuit the interconnects the above described elements and delivers a communication e.g. a control message between the above described elements.

The processor may receive commands from the above described other elements e.g. the memory the user input module the display module the communication module etc. through the bus may interpret the received commands and may execute calculation or data processing according to the interpreted commands.

The memory may store commands or data received from the processor or other elements e.g. the user input module the display module the communication module etc. or generated by the processor or the other elements. The memory includes programming modules including a kernel middleware an Application Programming Interface API an application and the like. Each of the above described programming modules may be implemented in software firmware hardware or a combination of two or more thereof.

The kernel may control or manage system resources e.g. the bus the processor the memory etc. used to execute operations or functions implemented by other programming modules e.g. the middleware the API and the application . Also the kernel may provide an interface capable of accessing and controlling or managing the individual elements of the electronic device by using the middleware the API or the application .

The middleware may serve to go between the API or the application and the kernel in such a manner that the API or the application communicates with the kernel and exchanges data therewith. Also in relation to work requests received from one or more applications the middleware may perform load balancing of the work requests by using a method of assigning a priority in which system resources e.g. the bus the processor the memory etc. of the electronic device can be used to at least one of the one or more applications .

The API is an interface through which the application is capable of controlling a function provided by the kernel or the middleware and may include for example at least one interface or function for file control window control image processing character control or the like.

The user input module may receive a command or data as input from a user and may deliver the received command or data to the processor or the memory through the bus . The display module may display a video an image data or the like to the user.

The communication module may connect communication between another electronic device and the electronic device . The communication module may support a predetermined short range communication protocol e.g. Wi Fi BlueTooth BT and Near Field Communication NFC or predetermined network communication e.g. the Internet a Local Area Network LAN a Wide Area Network WAN a telecommunication network a cellular network a satellite network a Plain Old Telephone Service POTS or the like . Each of the electronic devices and may be a device identical e.g. of an identical type to or different e.g. of a different type from the electronic device . Further the communication module may connect communication between a server and the electronic device via the network .

Hardware includes for example the electronic device illustrated in . Referring to the hardware includes one or more processors a Subscriber Identification Module SIM card a memory a communication module a sensor module a user input module a display module an interface an audio coder decoder codec a camera module a Power Management Module PMM a battery an indicator a motor and any other similar and or suitable components.

The processor e.g. the processor includes one or more Application Processors APs or one or more Communication Processors CPs . The AP and the CP are illustrated as being included in the processor in but may be included in different Integrated Circuit IC packages respectively. According to an embodiment of the present disclosure the AP and the CP may be included in one IC package.

The AP may execute an Operating System OS or an application program and thereby may control multiple hardware or software elements connected to the AP and may perform processing of and arithmetic operations on various data including multimedia data. The AP may be implemented by for example a System on Chip SoC . According to an embodiment of the present invention the processor may further include a Graphical Processing Unit GPU .

The CP may manage a data line and may convert a communication protocol in the case of communication between the electronic device e.g. the electronic device including the hardware and different electronic devices connected to the electronic device through the network. The CP may be implemented by for example an SoC. According to an embodiment of the present invention the CP may perform at least some of multimedia control functions. The CP for example may distinguish and authenticate a terminal in a communication network by using a subscriber identification module e.g. the SIM card . Also the CP may provide the user with services such as for example a voice telephony call a video telephony call a text message packet data and the like.

Further the CP may control the transmission and reception of data by the communication module . In elements such as the CP the PMM the memory and the like are illustrated as elements separate from the AP . However according to an embodiment of the present invention the AP may include at least some e.g. the CP of the above described elements.

According to an embodiment of the present invention the AP or the CP may load to a volatile memory a command or data received from at least one of a non volatile memory and other elements connected to each of the AP and the CP and may process the loaded command or data. Also the AP or the CP may store in a non volatile memory data received from or generated by at least one of the other elements.

The SIM card may be a card implementing a subscriber identification module and may be inserted into a slot formed in a particular portion of the electronic device . The SIM card may include unique identification information e.g. Integrated Circuit Card IDentifier ICCID or subscriber information e.g. International Mobile Subscriber Identity IMSI .

The memory includes an internal memory and an external memory . The memory may be for example the memory illustrated in . The internal memory may include for example at least one of a volatile memory e.g. a Dynamic RAM DRAM a Static RAM SRAM a Synchronous Dynamic RAM SDRAM etc. and a non volatile memory e.g. a One Time Programmable ROM OTPROM a Programmable ROM PROM an Erasable and Programmable ROM EPROM an Electrically Erasable and Programmable ROM EEPROM a mask ROM a flash ROM a Not AND NAND flash memory a Not OR NOR flash memory etc. . According to an embodiment of the present invention the internal memory may be in the form of a Solid State Drive SSD . The external memory may further include a flash drive for example a Compact Flash CF a Secure Digital SD a Micro Secure Digital Micro SD a Mini Secure Digital Mini SD an extreme Digital xD a memory stick or the like.

The communication module includes a wireless communication module or a Radio Frequency RF module . The communication module may be for example the communication module illustrated in . The wireless communication module includes for example a Wi Fi part a BT part a GPS part or an NFC part . For example the wireless communication module may provide a wireless communication function by using a radio frequency. Additionally or alternatively the wireless communication module may include a network interface e.g. a LAN card a modulator demodulator modem or the like for connecting the hardware to a network e.g. the Internet a LAN a WAN a telecommunication network a cellular network a satellite network a POTS or the like .

The RF module may be used for transmission and reception of data for example transmission and reception of RF signals or electronic signals. Although not illustrated the RF unit may include for example a transceiver a Power Amplifier Module PAM a frequency filter a Low Noise Amplifier LNA or the like. Also the RF module may further include a component for transmitting and receiving electromagnetic waves in a free space in wireless communication for example a conductor a conductive wire or the like.

The sensor module includes for example at least one of a gesture sensor A a gyro sensor B an atmospheric pressure sensor C a magnetic sensor D an acceleration sensor E a grip sensor F a proximity sensor G a Red Green and Blue RGB sensor H a biometric sensor I a temperature humidity sensor J an illuminance sensor K and a Ultra Violet UV sensor M. The sensor module may measure a physical quantity or may sense an operating state of the electronic device and may convert the measured or sensed information to an electrical signal. Additionally alternatively the sensor module may include for example an E nose sensor an ElectroMyoGraphy EMG sensor an ElectroEncephaloGram EEG sensor an ElectroCardioGram ECG sensor a fingerprint sensor and the like. The sensor module may further include a control circuit for controlling one or more sensors included therein.

The user input module includes a touch panel a pen sensor e.g. a digital pen sensor keys and an ultrasonic input unit . The user input module may be for example the user input module illustrated in . The touch panel may recognize a touch input in at least one of for example a capacitive scheme a resistive scheme an infrared scheme and an acoustic wave scheme. Also the touch panel may further include a controller. In the capacitive type the touch panel is capable of recognizing proximity as well as a direct touch. The touch panel may further include a tactile layer. In this event the touch panel may provide a tactile response to the user.

The pen sensor e.g. a digital pen sensor for example may be implemented by using a method identical or similar to a method of receiving a touch input from the user or by using a separate sheet for recognition. For example a key pad or a touch key may be used as the keys . The ultrasonic input unit enables the terminal to sense a sound wave by using a microphone e.g. a microphone of the terminal through a pen generating an ultrasonic signal and to identify data. The ultrasonic input unit is capable of wireless recognition. According to an embodiment of the present invention the hardware may receive a user input from an external device e.g. a network a computer or a server which is connected to the communication module through the communication module .

The display module includes a panel or a hologram . The display module may be for example the display module illustrated in . The panel may be for example a Liquid Crystal Display LCD and an Active Matrix Organic Light Emitting Diode AM OLED display and the like. The panel may be implemented so as to be for example flexible transparent or wearable. The panel may include the touch panel and one module. The hologram may display a three dimensional image in the air by using interference of light. According to an embodiment of the present invention the display module may further include a control circuit for controlling the panel or the hologram .

The interface includes for example a High Definition Multimedia Interface HDMI a Universal Serial Bus USB a projector and a D subminiature D sub . Additionally or alternatively the interface may include for example SD Multi Media Card MMC or Infrared Data Association IrDA .

The audio codec may bidirectionally convert between a voice and an electrical signal. The audio codec may convert voice information which is input to or output from the audio codec through for example a speaker a receiver an earphone the microphone or the like.

The camera module may capture an image and a moving image. According to an embodiment of the present invention the camera module may include one or more image sensors e.g. a front lens or a back lens an Image Signal Processor ISP and a flash LED.

The power management module may manage power of the hardware . The power management module may include for example a Power Management Integrated Circuit PMIC a charger Integrated Circuit IC or a battery fuel gauge.

The PMIC may be mounted to for example an IC or a SoC semiconductor. Charging methods may be classified into a wired charging method and a wireless charging method. The charger IC may charge a battery and may prevent an overvoltage or an overcurrent from a charger to the battery. According to an embodiment of the present invention the charger IC may include a charger IC for at least one of the wired charging method and the wireless charging method. Examples of the wireless charging method may include a magnetic resonance method a magnetic induction method an electromagnetic method and the like. Additional circuits e.g. a coil loop a resonance circuit a rectifier etc. for wireless charging may be added in order to perform the wireless charging.

The battery fuel gauge may measure for example a residual quantity of the battery or a voltage a current or a temperature during the charging. The battery may supply power by generating electricity and may be for example a rechargeable battery.

The indicator may indicate particular states of the hardware or a part e.g. the AP of the hardware for example a booting state a message state a charging state and the like. The motor may convert an electrical signal into a mechanical vibration. The processor may control the sensor module .

Although not illustrated the hardware may include a processing unit e.g. a GPU for supporting a module TV. The processing unit for supporting a module TV may process media data according to standards such as for example Digital Multimedia Broadcasting DMB Digital Video Broadcasting DVB media flow and the like. Each of the above described elements of the hardware according to an embodiment of the present invention may include one or more components and the name of the relevant element may change depending on the type of electronic device. The hardware according to an embodiment of the present invention may include at least one of the above described elements. Some of the above described elements may be omitted from the hardware or the hardware may further include additional elements. Also some of the elements of the hardware according to an embodiment of the present invention may be combined into one entity which may perform functions identical to those of the relevant elements before the combination.

The term module used herein may refer to for example a unit including one or more combinations of hardware software and firmware. The module may be interchangeable with a term such as unit logic logical block component circuit or the like. The module may be a minimum unit of a component formed as one body or a part thereof. The module may be a minimum unit for performing one or more functions or a part thereof. The module may be implemented mechanically or electronically. For example the module according to an embodiment of the present invention may include at least one of an Application Specific Integrated Circuit ASIC chip a Field Programmable Gate Array FPGA and a programmable logic device for performing certain operations which have been known or are to be developed in the future.

A programming module may be included or stored in the electronic device e.g. the memory illustrated in or may be included or stored in the hardware e.g. the memory illustrated in . At least a part of the programming module may be implemented in software firmware hardware or a combination of two or more thereof. The programming module may be implemented in hardware e.g. the hardware and may include an OS controlling resources related to an electronic device e.g. the electronic device and or various applications e.g. an application executed in the OS. Referring to the programming module includes a kernel a middleware an API and or the application .

The kernel e.g. the kernel includes a system resource manager and or a device driver . The system resource manager may include for example a process manager a memory manager and a file system manager. The system resource manager may perform the control allocation recovery and or similar system resources. The device driver may include for example a display driver a camera driver a Bluetooth driver a shared memory driver a USB driver a keypad driver a Wi Fi driver and or an audio driver.

Also according to an embodiment of the present invention the device driver may include an Inter Process Communication IPC driver.

The middleware includes multiple modules previously implemented so as to provide a function used in common by the applications . Also the middleware may provide a function to the applications through the API in order to enable the applications to efficiently use limited system resources within the electronic device. For example as illustrated in the middleware e.g. the middleware includes at least one of a runtime library an application manager a window manager a multimedia manager a resource manager a power manager a database manager a package manager a connectivity manager a notification manager a location manager a graphic manager a security manager and any other suitable and or similar manager.

The runtime library may include for example a library module used by a complier in order to add a new function by using a programming language during the execution of the application . According to an embodiment of the present disclosure the runtime library may perform functions that are related to input and output the management of a memory an arithmetic function and or the like.

The application manager may manage for example a life cycle of at least one of the applications . The window manager may manage GUI resources used on the screen. The multimedia manager may detect a format used to reproduce various media files and may encode or decode a media file through a codec appropriate for the relevant format. The resource manager may manage resources such as for example a source code a memory a storage space and or the like of at least one of the applications .

The power manager may operate together with a Basic Input Output System BIOS may manage a battery or power and may provide power information and the like used for an operation. The database manager may manage a database in such a manner as to enable the generation search and or change of the database to be used by at least one of the applications . The package manager may manage the installation and or update of an application distributed in the form of a package file.

The connectivity manager may manage a wireless connectivity such as for example Wi Fi and Bluetooth. The notification manager may display or report to the user an event such as an arrival message an appointment a proximity alarm and the like in such a manner as not to disturb the user. The location manager may manage location information of the electronic device. The graphic manager may manage a graphic effect which is to be provided to the user and or a user interface related to the graphic effect. The security manager may provide various security functions used for system security user authentication and the like. According to an embodiment of the present invention when the electronic device e.g. the electronic device has a telephone function the middleware may further include a telephony manager for managing a voice telephony call function and or a video telephony call function of the electronic device.

The middleware may generate and use a new middleware module through various functional combinations of the above described internal element modules. The middleware may provide modules specialized according to types of OSs in order to provide differentiated functions. Also the middleware may dynamically delete some of the existing elements or may add new elements. Accordingly the middleware may omit some of the elements described in the various embodiments of the present invention may further include other elements or may replace the some of the elements with elements each of which performs a similar function and has a different name.

The API e.g. the API is a set of API programming functions and may be provided with a different configuration according to an OS. For example one API set may be provided to each platform. In another example two or more API sets may be provided to each platform.

The applications e.g. the applications include for example a preloaded application and or a third party application. The applications e.g. the applications includes for example a home application a dialer application a Short Message Service SMS Multimedia Message Service MMS application an Instant Message IM application a browser application a camera application an alarm application a contact application a voice dial application an electronic mail e mail application a calendar application a media player application an album application a clock application and any other suitable and or similar application.

At least a part of the programming module may be implemented by instructions stored in a non transitory computer readable storage medium. When the instructions are executed by one or more processors e.g. the one or more processors the one or more processors may perform functions corresponding to the instructions. The non transitory computer readable storage medium may be for example the memory . At least a part of the programming module may be implemented e.g. executed by for example the one or more processors . At least a part of the programming module may include for example a module a program a routine a set of instructions and or a process for performing one or more functions.

Names of the elements of the programming module e.g. the programming module according to an embodiment of the present invention may change depending on the type of OS. The programming module according to an embodiment of the present invention may include one or more of the above described elements. Alternatively some of the above described elements may be omitted from the programming module. Alternatively the programming module may further include additional elements. The operations performed by the programming module or other elements according to an embodiment of the present invention may be processed in a sequential method a parallel method a repetitive method or a heuristic method. Also some of the operations may be omitted or other operations may be added to the operations.

A description is made of the sound visualization method with reference to . However it is obvious to those in the art that the sound visualization method can be adopted to the configurations of as well as . The application processor of may be replaced by the processor of . Also the operations of the application processor may be performed by the media player of . In the following description the application processor of may include a communication processor . In the following description the application processor may be referred to as control unit. That is the control unit may perform the operations of the application processor and or the communication processor .

In the following description the term audio data may be understood to include all types of sound data output as the user audible sound such as for example sound data sound audio signal sound effect and audible sound band signal.

The control unit receives an image which is matched to audio data that is requested for playback from the memory and a server to which the electronic device is connected in step . Assuming MP3 audio data the MP3 audio data may be stored along with album cover image data. In another example the image file may be stored separately as mapped to the audio file. When the image file is stored separate from the audio data the image file may be stored in the memory of the electronic device or a certain server to which the electronic device has access. When the image file is stored in the server the electronic device may connect to the server to acquire the image data. The electronic device may acquire the image file through a cellular communication network a Wi Fi network or a wired network in the same or similar manner as that of normal data download. When the image is stored along with or mapped to the audio data the audio and image data are provided in response to an audio data playback request.

The control unit decreases the acquired image to a predetermined size in step . Assuming that the acquired image is 1600 1600 it may be decreased to a 200 200 image. The reason for reducing the image to a predetermined size is to facilitate simplifying or extracting the color information included in the acquired image. For example when a red flower image is taken by the camera the colors of the flowers are likely to be different to some extent. This is because the red flower may be taken in different conditions depending on the light angle and or light quantity. If the flower is taken into a picture under different conditions the number of colors to acquire from the image increases greatly and this makes it difficult to determine the ratio of colors included in the image. Accordingly the predetermined size to which the image is downsized may be set to a value for an appropriate size for determining the number of colors to be extracted from the image associated with the audio data.

In reference number denotes the original image and reference number denotes the image reduced to a predetermined size. The original image may be stored along with or matched to the audio file. When the original image is greater than or equal to the predetermined size it is processed to be the size reduced image . The original image may be size reduced by dividing the original image into a plurality of blocks and extracting the pixels up to a predetermined ratio from each block. For example if decreasing the size of the original image as much as 50 the original image is divided into a plurality of blocks and the same percentage of pixels are extracted from each block. In similar way it is also possible to acquire the size reduced image by extracting the pixels up to a predetermined percentage from all positions of the original image . In order to reduce the size of an image various other methods may be used.

Referring back to step may be replaced by a different operation or may be skipped. If step is replaced by an alternative operation in an alternative embodiment of the present invention all the color information included in the original image is extracted without reducing the size of the original image. Afterward it is possible to check the similarity of colors acquired from the original image and if the similarity is greater than or equal to a predetermined value sort the colors into one color information. In this case step may be performed by extracting all the color information and simplifying the color information according to the similarity.

In an alternative embodiment of the present invention if step is skipped the original image is less than or equal to the predetermined size the number of color information is less than or equal to a predetermined value and or the image has been simplified already. In this or other similar cases step may be skipped.

The above description is directed to cases where step is replaced with a modified operation and skipped. In the following embodiment of the present invention step is applied without modification for convenience of explanation.

The control unit sorts the color information included in the size reduced image by ratio or percentage in the corresponding image in step . Since the image has been size reduced and thus the number of colors has been reduced in the size reduced image the number of pieces of color information to be sorted is likely to be less than of the original image .

At step the color information included in the size reduced image is sorted by percentage in the reduced size image . If specific colors occupying the reduced size image are 35 17 11 and 6 this means that the colors are sorted by percentage. This is described in greater detail below with reference to .

Assuming N pieces of color information are extracted from the size reduced image the pieces of color information are sorted by percentage as denoted by reference number . However the pieces of information on the respective colors may have unique code values e.g. 1111000 D7267B 28B3BO 27B3BO 723247 . . . 76722D N as denoted by reference number . The percentages of colors constituting the size reduced image may be 28 18 16 10 . . . 1 respectively. In this way the pieces of color information may be sorted by percentage in an ascending or descending order. Meanwhile the percentages of the colors included in the reduced image may be identical with or similar to the percentages in the original image .

Referring back to the control unit divides the audible sound into a plurality of sub bands and maps the colors to all or some of the sub bands in step . Diving the audible sound band into a plurality of sub bands and mapping the colors to all or some of the sub bands may be performed in various manners. The audible sound band is in the range from 20 Hz to 20000 Hz. However it is possible to use a part of the audible sound band or a sound band broader than the audible sound band of 20 hz to 20000 hz. In the case of using a part of the audible sound band the band may be set to the range from 20 hz to 16000 hz or from 400 hz to 16000 hz. In the case of using the band broader than the audible sound band the band may be set to the range from 0 hz to 22000 hz. In this way it is also possible to map the colors to the frequency band including inaudible frequencies if necessary. Although the description has been made with specific values the embodiments of the present invention are not limited thereto. The frequency band to be used may be determined depending on the properties of the audio file.

The frequency band may be divided in various ways. This is described in greater detail below with reference to .

In a music base band is set to the range of 0 to 40 hz a music low band is set to the range of 41 to 200 hz a music mid band is set to the range of 201 to 1000 hz and a music high band is set to the range of 1001 to 16000 hz. Band is set to the range of 16000 hz to 20000 hz and is a reserved band. The band configuration may be performed differently. For example at least one of the low frequency band intermediate frequency band and high frequency band may be configured narrower than the above ranges. Also the frequency spectrum may be divided into the bands smaller in number than the bands as shown in . The number of bands may be determined in consideration of the load of the control unit in the stage of manufacturing the electronic device. If a large number of bands does not cause significant overload to the control unit it is possible to design the electronic device such that the user can configure the sound visualization function diversely for audio file playback.

In the case of configuring the sound bands depending on the audio data it is possible to use the genre of the audio data. For example when the audio data is of classical music and has information indicating fast playback speed and high frequency band it is possible to preset a frequency band configuration for the fast and high frequency range classical music in the memory and discern the frequency bands according to the preset configuration. In another example it is possible to preset a frequency configuration for heavy metal music which is different from that of the classical music. In this way it is possible to configure the frequency bands using the properties and genre information of the audio data stored along with the audio data.

As described above the control unit divides the audible sound band into a plurality of sub bands depending on the type of the audio data and maps the colors to the corresponding sub bands in step . Various methods of mapping the pieces of color information to the sound level ranges are described below.

When two of the five sound level ranges are used as shown in . The color occupying the highest percentage in the image file is used as the background color of the audio file visualization the colors and occupying the second and third highest percentages are mapped to the music low band and music high band and respectively. As shown in if only the two sound level ranges are used with the color information acquired from the image the audio signals of the other sound level ranges having no mapped color information are not visualized but may be presented as a default color e.g. white or black.

If N colors are extracted as shown in all or some of the N colors may be used depending on the number of sound level ranges and mappings. If the number of sound level ranges is greater than the number of colors acquired from the image no color may be mapped to certain sound level ranges as shown in .

The above description has been directed to the case where the extracted colors are mapped as they are to specific sound level ranges. However all or some of the mapped colors may be inverted. The color inversion may be performed to a complementary color or a certain color acquired by inverting the mapped value digitally. The mapping may be performed in such a way of substituting the extracted colors of the color circle and mapping the color shifted as much as a predetermined value to the left or right on the color circle.

Referring back to the control unit displays a preconfigured object pattern by means of the display module in the course of playing the audio data in step . The audio data is played in such a way that the audio codec decodes the audio data under the control of the control unit. The decoded audio data is converted to electric signals which are transferred to the speaker . The speaker may convert the electric signal to an audible sound wave. In the case that the audio signal is output through an earphone or other device the audio signal is converted to the audible sound wave by the corresponding device.

The object pattern displayed by the display module in step may be of a circle a rectangle or a cubical pattern. The object pattern may be identical or similar to the pattern displayed on the screen when audio data is played by the PC. The object pattern displayed by the display module may be expressed with the color acquired from the image associated with the audio file unlike the pattern of certain colors preconfigured in the PC. In more detail the sound visualization method of embodiments of the present invention divides the audible sound band into several sound level ranges and maps the colors acquired from the image to all or some of the sound level ranges for sound visualization on the display module .

Sound visualization is described in detail with reference to . is a diagram illustrating screen displays of sound visualization according to an embodiment of the present invention in which the audible sound band is divided into a plurality sound level ranges to which the colors acquired from the image associated with the audio data are mapped.

In a first screen image shows a screen display of the display module when only the music low band audio signal or sound is output a second screen image shows a screen display of the display module when only the music high band audio signal or sound is output.

Typically the music is characterized in that the sounds output simultaneously are dispersed across different sound level ranges but not concentrated in a band. When the audio signals of the low and high frequency bands are played simultaneously the display module displays the graphic as shown in a third screen image .

Since the audio data is played with sounds varying as time goes the visualization varies constantly in pattern and color as shown in .

Referring back to the control unit determines whether a request for changing the object is input through the input module in the course of playing the audio and displaying the object pattern in step .

If a request for changing the object is detected the control unit reads the object patterns selectable from the memory and displays the object patterns on the display module in step . The selectable object patterns may be displayed on a part of the display module while step is performed entirely or partially. Since is directed to the audio playback mode the audio playback has to be maintained. The operation of displaying the colors acquired from the image in association with the corresponding bands may be suspended in the course of changing the object pattern. In another embodiment of the present invention the control unit may control the display module to provide the selected object pattern in a preview format in step .

It is possible to display the selected object pattern to which the colors are mapped or the object pattern based on the image e.g. album cover image mapped to the audio data.

For example the control unit may analyze the album cover image and may cut the album cover image according to the object element of the album cover image.

The control unit also may determine the shape to be cut out of the album cover image according to the object element constituting the album cover image.

If a request for changing the object is not detected in step the control unit determines whether a request for changing color is input through the input module in step . If the request for changing color is detected the control unit controls the display module to display the colors mapped to the respective sound level ranges and the color circle stored in the memory in step . Afterward the control unit may converts the pieces of information corresponding to the colors to the complementary colors or colors shifted as much as a predetermined value to the left or right on the color circle. As described above the color change operation is displayed on a part of the display module while step is performed entirely or partially. Since is directed to the audio playback mode the audio playback has to be maintained. Meanwhile the operation of displaying the colors acquired from the image in association with the corresponding bands may be suspended in the course of changing the object pattern. In another embodiment of the present invention the control unit may control the display module to display a preview image based on the changed mapping information of the selected color information in step .

If a request for changing color is not detected in step the control unit determines whether a request for terminating the audio playback is detected in step . If the request for terminating the audio playback is detected the control unit ends the routine of . If the routine of ends the visualization operation based on the image associated with the audio is terminated along with the end of the audio playback. The routine termination may be requested by the user through the input module or triggered by other important events. The other important events may include the receipt of an incoming call when the electronic device is a telephone enable mobile terminal or an incoming text message. Also the events may include arrival of a preset alarm time. If no request for terminating the audio playback is detected in step step is maintained.

As described above the sound visualization method and apparatus of the present invention is advantageous in terms of expressing the mode of a sound using an image matched to the sound. For example the sound visualization method and apparatus of the present invention is capable of using the cover image of a music album and images matched to the songs contained in the album that are mostly intended to express the mood emotion and identity of the music.

Also the sound visualization method and apparatus of the present invention is advantageous in terms of expressing the mood and emotion of the music being currently played by the electronic device effectively by combining the color data of the cover image of the music album and images matched to the songs contained in the music album with the spectrum data and wave data of the music.

Also the sound visualization method and apparatus of the present invention is advantageous in terms of improving the emotional quality of a product in such a way of providing an image graphic or animation that is well matched to the mood of the music to which the user is listening.

While the invention has been shown and described with reference to certain embodiments thereof it will be understood by those skilled in the art that various changes in form and detail may be made therein without departing from the spirit and scope of the invention as defined by the appended claims.

