---

title: Data set capture management with forecasting
abstract: A set of virtualized computing services may include multiple types of virtualized data store differentiated by characteristics such as latency, throughput, durability and cost. A sequence of captures of a data set from one data store to another may be scheduled to achieve a variety of virtualized computing service user and provider goals such as lowering a probability of data loss, lowering costs, and computing resource load leveling. Data set captures may be scheduled according to policies specifying fixed and flexible schedules and conditions including flexible scheduling windows, target capture frequencies, probability of loss targets and/or cost targets. Capture lifetimes may also be managed with capture retention policies, which may specify fixed and flexible lifetimes and conditions including cost targets. Such data set capture policies may be specified with a Web-based administrative interface to a control plane of the virtualized computing services.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09298737&OS=09298737&RS=09298737
owner: Amazon Technologies, Inc.
number: 09298737
owner_city: Reno
owner_country: US
publication_date: 20141217
---
This application is a Continuation of allowed U.S. patent application Ser. No. 13 966 910 filed with the U.S. Patent and Trademark Office on Aug. 14 2013 which is a Divisional of and accordingly claims the benefit of U.S. patent application Ser. No. 12 869 414 filed with the U.S. Patent and Trademark Office on Aug. 26 2010 each of which is incorporated herein by reference for all purposes.

Networked computing environments continue to grow in terms of both the number and type of computing components as well as the complexity of component arrangements in the computing environments. Some such computing environments offer virtualized computing services decoupled to various degrees from the underlying computing hardware that ultimately implement the computing services. There are various advantages to such virtualization for both users and providers of virtualized computing services. For example virtualized computing service users may quickly e.g. on the order of minutes or seconds add virtual computing resources in response to increased demand and just as quickly release the virtual computing resources for other purposes if demand falls. Such flexibility for users of virtualized computing services can entail both challenges and opportunities for providers of virtualized computing services.

A virtualized file system volume is an example of a virtualized computing service. Users of virtualized file system volumes virtual volumes may create delete resize and otherwise reconfigure virtual volumes without concern for the details of how underlying computing resources are allocated. However virtual volumes may be associated with a set of performance expectations such as relatively low read write latency and or relatively high data throughput that can constrain the allocation of the underlying computing resources and may be associated with various costs including financial costs. Some providers of virtualized computing services offer multiple types of virtualized data storage for example each associated with a different set of performance expectations and or costs. Where multiple types of virtualized data storage are available users typically move data between the different types of virtualized data storage on a manual and or ad hoc basis. This can be problematic.

Unmanaged movement of data between different types of virtualized data storage can be suboptimal from the perspectives of both the user and provider of virtualized computing services. For example unmanaged data movement may be incur more costs than necessary to achieve the same and or similar goals. Such costs may include financial costs and or computing resource costs. Unmanaged data movement may exacerbate peak demands on computing resources that support virtualized computing services.

Same numbers are used throughout the disclosure and figures to reference like components and features but such repetition of number is for purposes of simplicity of explanation and understanding and should not be viewed as a limitation on the various embodiments.

In the following description various embodiments will be described. For purposes of explanation specific configurations and details are set forth in order to provide a thorough understanding of the embodiments. However it will also be apparent to one skilled in the art that the embodiments may be practiced without the specific details. Furthermore well known features may be omitted or simplified in order not to obscure the embodiment being described.

In at least one embodiment a set of virtualized computing services includes multiple types of virtualized data storage. For example different types of virtualized data storage may have characteristics with respect to read write latency e.g. time to respond to read write requests data throughput e.g. amounts of data that may be read written during a time period data durability e.g. probability of avoiding data loss due to hardware and or component failure and cost. In at least one embodiment the virtualized data storage types include a relatively low latency data store and a relatively high durability data store. For example the relatively low latency data store may include virtual volumes accessible with conventional file system interfaces and the relatively high durability data store may be a purpose built high redundancy data store accessible with a purpose built interface.

The low latency data store may maintain one or more data sets that are modified over a period of time. For example one data set may include data for a Web based application that is updated in accordance with application user actions and or input. Another data set may include raw and or processed data transmitted from a recording instrument. In at least one embodiment a data set maintained by the low latency data store may be captured at various moments in time and the captures stored in the high durability data store. A capture of a data set is a representation of the data set at a moment in time. Multiple captures of a particular data set may be taken at various moments in time and later captures may depend on one or more earlier captures. For example an initial capture of the data set may involve making a full copy of the data set whereas a later capture of the data set may involve copying data that has changed since an earlier capture.

A sequence of captures of a data set may be scheduled to achieve a variety of virtualized computing service user and provider goals. For example the sequence of captures may be scheduled to reduce a probability of loss of data in the data set to lower data storage costs and or to level one or more utilization loads on computing resources supporting the virtualized computing service. The captures may be scheduled at particular times and dates that is in accordance with a fixed schedule. Alternatively or in addition the captures may be performed in accordance with a flexible schedule and or according to at least one data set capture policy. For example a flexible schedule may specify that a particular capture occur within a time period e.g. hours or days in duration and or that a sequence of captures occur with a target frequency over a time period. In at least one embodiment a sequence of captures may be scheduled in accordance with probability of loss and or cost targets.

Different lifetimes may be specified for various captures. For example a data set capture policy may specify that daily captures are to be stored in a high durability data store for seven days and that weekly captures are to be stored for a month. Different permissions may be specified for certain captures. For example monthly captures may be specified as having an unlimited lifetime and as requiring manual deletion by an authenticated user. In at least one embodiment captures may be specified as having a flexible lifetime. For example a data set capture policy may specify a target cost and captures in a capture set may be deleted to keep costs associated with the high durability data store less than the target cost while minimizing impacts to other goals and or conditions specified by the policy. Specification of capture schedules and or policies may be performed using any appropriate interface exposed to a user such as a Web based user interface.

Various approaches may be implemented in various environments for various applications. For example illustrates aspects of an example environment for implementing aspects in accordance with various embodiments. As will be appreciated although a Web based environment may be utilized for purposes of explanation different environments may be utilized as appropriate to implement various embodiments. The environment shown includes both a testing or a development portion or side and a production portion. The production portion includes an electronic client device which may include any appropriate device operable to send and receive requests messages or information over an appropriate network and convey information back to a user of the device . Examples of such client devices include personal computers cell phones handheld messaging devices laptop computers tablet computers set top boxes personal data assistants electronic book readers and the like.

The network may include any appropriate network including an intranet the Internet a cellular network a local area network a wide area network a wireless data network or any other such network or combination thereof. Components utilized for such a system may depend at least in part upon the type of network and or environment selected. Protocols and components for communicating via such a network are well known and will not be discussed herein in detail. Communication over the network may be enabled by wired or wireless connections and combinations thereof. In this example the network includes the Internet as the environment includes a Web server for receiving requests and serving content in response thereto although for other networks an alternative device serving a similar purpose could be utilized as would be apparent to one of ordinary skill in the art.

The illustrative environment includes at least one application server and a data store . It should be understood that there may be several application servers layers or other elements processes or components which may be chained or otherwise configured which may interact to perform tasks such as obtaining data from an appropriate data store. As used herein the term data store refers to any device or combination of devices capable of storing accessing and or retrieving data which may include any combination and number of data servers databases data storage devices and data storage media in any standard distributed or clustered environment.

The application server may include any appropriate hardware and software for integrating with the data store as needed to execute aspects of one or more applications for the client device and may even handle a majority of the data access and business logic for an application. The application server provides access control services in cooperation with the data store and is able to generate content such as text graphics audio and or video to be transferred to the user which may be served to the user by the Web server in the form of HTML XML or another appropriate structured language in this example.

The handling of all requests and responses as well as the delivery of content between the client device and the application server may be handled by the Web server . It should be understood that the Web and application servers are not required and are merely example components as structured code discussed herein may be executed on any appropriate device or host machine as discussed elsewhere herein. Further the environment may be architected in such a way that a test automation framework may be provided as a service to which a user or application may subscribe. A test automation framework may be provided as an implementation of any of the various testing patterns discussed herein although various other implementations may be utilized as well as discussed or suggested herein.

The environment may also include a development and or testing side which includes a user device allowing a user such as a developer data administrator or tester to access the system. The user device may be any appropriate device or machine such as is described above with respect to the client device . The environment may also include a development server which functions similar to the application server but typically runs code during development and testing before the code is deployed and executed on the production side and becomes accessible to outside users for example. In some embodiments an application server may function as a development server and separate production and testing storage may not be utilized.

The data store may include several separate data tables databases or other data storage mechanisms and media for storing data relating to a particular aspect. For example the data store illustrated includes mechanisms for storing production data and user information which may be utilized to serve content for the production side. The data store also is shown to include a mechanism for storing testing data which may be utilized with the user information for the testing side. It should be understood that there may be many other aspects that are stored in the data store such as for page image information and access right information which may be stored in any of the above listed mechanisms as appropriate or in additional mechanisms in the data store .

The data store is operable through logic associated therewith to receive instructions from the application server or development server and obtain update or otherwise process data in response thereto. In one example a user might submit a search request for a certain type of item. In this case the data store might access the user information to verify the identity of the user and may access the catalog detail information to obtain information about items of that type. The information then may be returned to the user such as in a results listing on a Web page that the user is able to view via a browser on the user device . Information for a particular item of interest may be viewed in a dedicated page or window of the browser.

Each server typically will include an operating system that provides executable program instructions for the general administration and operation of that server and typically will include a computer readable medium storing instructions that when executed by a processor of the server allow the server to perform its intended functions. Suitable implementations for the operating system and general functionality of the servers are known or commercially available and are readily implemented by persons having ordinary skill in the art particularly in light of the disclosure herein.

The environment in one embodiment is a distributed computing environment utilizing several computer systems and components that are interconnected via communication links using one or more computer networks or direct connections. However it will be appreciated by those of ordinary skill in the art that such a system could operate equally well in a system having fewer or a greater number of components than are illustrated in . Thus the depiction of the system in should be taken as being illustrative in nature and not limiting to the scope of the disclosure.

In at least one embodiment one or more aspects of the environment may incorporate and or be incorporated into a distributed program execution service. depicts aspects of an example distributed program execution service in accordance with at least one embodiment. The distributed program execution service provides virtualized computing services including a virtual computer system service and a virtual data store service with a wide variety of computing resources interlinked by a relatively high speed data network. Such computing resources may include processors such as central processing units CPUs volatile storage devices such as random access memory RAM nonvolatile storage devices such as flash memory hard drives and optical drives servers such as the Web server and the application server described above with reference to one or more data stores such as the data store of as well as communication bandwidth in the interlinking network. The computing resources managed by the distributed program execution service are not shown explicitly in because it is an aspect of the distributed program execution service to emphasize an independence of the virtualized computing services from the computing resources that implement them.

The distributed program execution service may utilize the computing resources to implement the virtualized computing services at least in part by executing one or more programs program modules program components and or programmatic objects collectively program components including and or compiled from instructions and or code specified with any suitable machine and or programming language. For example the computing resources may be allocated and reallocated as necessary to facilitate execution of the program components and or the program components may be assigned and reassigned as necessary to the computing resources. Such assignment may include physical relocation of program components for example to enhance execution efficiency. From a perspective of a user of the virtualized computing services the distributed program execution service may supply computing resources elastically and or on demand for example associated with a per resource unit commodity style pricing plan.

The distributed program execution service may further utilize the computing resources to implement a service control plane configured at least to control the virtualized computing services. The service control plane may include a service administration interface . The service administration interface may include a Web based user interface configured at least to enable users and or administrators of the virtualized computing services to provision de provision configure and or reconfigure collectively provision suitable aspects of the virtualized computing services. For example a user of the virtual computer system service may provision one or more virtual computer system instances . The user may then configure the provisioned virtual computer system instances to execute the user s application programs. The ellipsis between the virtual computer system instances and indicates that the virtual computer system service may support any suitable number e.g. thousands millions and more of virtual computer system instances although for clarity only two are shown.

The service administration interface may further enable users and or administrators to specify and or re specify virtualized computing service policies. Such policies may be maintained and enforced by a service policy enforcement component of the service control plane . For example a storage administration interface portion of the service administration interface may be utilized by users and or administrators of the virtual data store service to specify virtual data store service policies to be maintained and enforced by a storage policy enforcement component of the service policy enforcement component . Various aspects and or facilities of the virtual computer system service and the virtual data store service including the virtual computer system instances the low latency data store the high durability data store and or the underlying computing resources may be controlled with interfaces such as application programming interfaces APIs and or Web based service interfaces. In at least one embodiment the control plane further includes a workflow component configured at least to interact with and or guide interaction with the interfaces of the various aspects and or facilities of the virtual computer system service and the virtual data store service in accordance with one or more workflows.

In at least one embodiment service administration interface and or the service policy enforcement component may create and or cause the workflow component to create one or more workflows that are then maintained by the workflow component . Workflows such as provisioning workflows and policy enforcement workflows may include one or more sequences of tasks to be executed to perform a job such as provisioning or policy enforcement. A workflow as the term is used herein is not the tasks themselves but a task control structure that may control flow of information to and from tasks as well as the order of execution of the tasks it controls. For example a workflow may be considered a state machine that can manage and return the state of a process at any time during execution. Workflows may be created from workflow templates. For example a provisioning workflow may be created from a provisioning workflow template configured with parameters by the service administration interface . As another example a policy enforcement workflow may be created from a policy enforcement workflow template configured with parameters by the service policy enforcement component .

The workflow component may modify further specify and or further configure established workflows. For example the workflow component may select particular computing resources of the distributed program execution service to execute and or be assigned to particular tasks. Such selection may be based at least in part on the computing resource needs of the particular task as assessed by the workflow component . As another example the workflow component may add additional and or duplicate tasks to an established workflow and or reconfigure information flow between tasks in the established workflow. Such modification of established workflows may be based at least in part on an execution efficiency analysis by the workflow component . For example some tasks may be efficiently performed in parallel while other tasks depend on the successful completion of previous tasks.

The virtual data store service may include multiple types of virtual data store such as a low latency data store and a high durability data store . For example the low latency data store may maintain one or more data sets which may be read and or written collectively accessed by the virtual computer system instances with relatively low latency. The ellipsis between the data sets and indicates that the low latency data store may support any suitable number e.g. thousands millions and more of data sets although for clarity only two are shown. For each data set maintained by the low latency data store the high durability data store may maintain a set of captures . Each set of captures may maintain any suitable number of captures and of its associated data set respectively as indicated by the ellipses. Each capture and may provide a representation of the respective data set and at particular moment in time. Such captures and may be utilized for later inspection including restoration of the respective data set and to its state at the captured moment in time. Although each component of the distributed program execution service may communicate utilizing the underlying network data transfer between the low latency data store and the high durability data store is highlighted in because the contribution to utilization load on the underlying network by such data transfer can be significant.

For example the data sets of the low latency data store may be virtual file system volumes. The low latency data store may include a low overhead virtualization layer providing access to underlying data storage hardware. For example the virtualization layer of the low latency data store may be low overhead relative to an equivalent layer of the high durability data store . Systems and methods for establishing and maintaining low latency data stores and high durability data stores in accordance with at least one embodiment are known to those of skill in the art so only some of their features are highlighted herein. In at least one embodiment the sets of underlying computing resources allocated to the low latency data store and the high durability data store respectively are substantially disjoint.

The low latency data store and or the high durability data store may be considered non local and or independent with respect to the virtual computer system instances . For example physical servers implementing the virtual computer system service may include local storage facilities such as hard drives. Such local storage facilities may be relatively low latency but limited in other ways for example with respect to reliability durability size throughput and or availability. Furthermore data in local storage allocated to particular virtual computer system instances may have a validity lifetime corresponding to the virtual computer system instance so that if the virtual computer system instance fails or is de provisioned the local data is lost and or becomes invalid. In at least one embodiment data sets in non local storage may be efficiently shared by multiple virtual computer system instances . For example the data sets may be mounted by the virtual computer system instances as virtual file system volumes.

Data stores in the virtual data store service including the low latency data store and or the high durability data store may be facilitated by and or implemented with a block data storage BDS service at least in part. The BDS service may facilitate the creation reading updating and or deletion of one or more block data storage volumes such as file system volumes with a set of allocated computing resources including multiple block data storage servers. A block data storage volume and or the data blocks thereof may be distributed and or replicated across multiple block data storage servers to enhance volume reliability latency durability and or availability. As one example the multiple server block data storage systems that store block data may in some embodiments be organized into one or more pools or other groups that each have multiple physical server storage systems co located at a geographical location such as in each of one or more geographically distributed data centers and the program s that use a block data volume stored on a server block data storage system in a data center may execute on one or more other physical computing systems at that data center.

The BDS service may facilitate and or implement local caching of data blocks as they are transferred through the underlying computing resources of the distributed program execution service including local caching at data store servers implementing the low latency data store and or the high durability data store and local caching at virtual computer system servers implementing the virtual computer system service . In at least one embodiment the high durability data store is an archive quality data store implemented independent of the BDS service . The high durability data store may work with sets of data that are large relative to the data blocks manipulated by the BDS service . The high durability data store may be implemented independent of the BDS service . For example with distinct interfaces protocols and or storage formats.

Each data set may have a distinct pattern of change over time. For example the data set may have a higher rate of change than the data set . However in at least one embodiment bulk average rates of change insufficiently characterize data set change. For example the rate of change of the data set may itself have a pattern that varies with respect to time of day day of week seasonally including expected bursts correlated with holidays and or special events and annually. Different portions of the data set may be associated with different rates of change and each rate of change signal may itself be composed of independent signal sources for example detectable with Fourier analysis techniques. Any suitable statistical analysis techniques may be utilized to model data set change patterns including Markov modeling and Bayesian modeling.

As described above an initial capture of the data set may involve a substantially full copy of the data set and transfer through the network to the high durability data store may be a full capture . The data set may be associated with various kinds of metadata. Some none or all of such metadata may be included in a capture of the data set depending on the type of the data set . For example the low latency data store may specify metadata to be included in a capture depending on its cost of reconstruction in a failure recovery scenario. Captures beyond the initial capture may be incremental for example involving a copy of changes to the data set since one or more previous captures. Captures may be arranged in a hierarchy of classes so that a particular capture may be incremental with respect to a sub hierarchy of capture classes e.g. a capture scheduled weekly may be redundant with respect to daily captures of the past week but incremental with respect to the previous weekly capture . Depending on the frequency of subsequent captures utilization load on the underlying computing resources can be significantly less for incremental captures compared to full captures.

For example a capture of the data set may include read access of a set of servers and or storage devices implementing the low latency data store as well as write access to update metadata for example to update a data structure tracking dirty data blocks of the data set . For the purposes of this description data blocks of the data set are dirty with respect to a particular class and or type of capture if they have been changed since the most recent capture of the same class and or type . Prior to being transferred from the low latency data store to the high durability data store capture data may be compressed and or encrypted by the set of servers. At the high durability data store received capture data may again be written to an underlying set of servers and or storage devices. Thus each capture involves a load on finite underlying computing resources including server load and network load.

Captures of the data set may be manually requested for example utilizing the storage administration interface . In at least one embodiment the captures may be automatically scheduled in accordance with a data set capture policy. Data set capture policies in accordance with at least one embodiment may be specified with the storage administration interface as well as associated with one or more particular data sets . The data set capture policy may specify a fixed or flexible schedule for data set capture. Fixed data set capture schedules may specify captures at particular times of day days of the week months of the year and or any suitable time and date. Fixed data set capture schedules may include recurring captures e.g. every weekday at midnight every Friday at 2 am 4 am every first of the month as well as one off captures.

Flexible data set capture policies may specify that a capture is to occur within a particular time window e.g. 2 am 6 am everyday sometime on Sunday after close of business on the last day of the month or with a particular frequency e.g. once per hour twice per day once per week once per month . In at least one embodiment flexible data set capture policies may specify that captures be scheduled to meet suitable goals targets and or conditions collectively capture conditions . For example each capture may have an associated cost financially and or in terms of computational resources and the flexible data set capture policy may specify a cost target and or cost cap for the capture or set of captures including a budget per time period and or an average cost per capture. As another example in at least one embodiment a probability of data loss of a portion of a data set is a function at least of an amount of uncaptured data in the data set at a given time. Accordingly a flexible data set capture policy may specify a target probability of data loss of a portion of the data set and the storage policy enforcement component may schedule captures of the data set to meet the target by keeping the amount of uncaptured data in the data set below an associated uncaptured data target and or cap.

Data set capture policies may specify any suitable combination of fixed schedules flexible schedules and capture conditions. Data set capture policies may further specify capture lifetimes and or capture retention goals targets and or conditions. For example a seven day lifetime may be specified for daily captures a four week lifetime may be specified for weekly captures and or an annual lifetime may be specified for monthly captures. Captures may have an unspecified and or unlimited lifetime thus requiring manual deletion. Furthermore particular captures may be protected for example may require manual deletion by a designated set of authenticated users. Captures and or capture sets may be associated with costs e.g. a periodic fee for storage per gigabyte and the data set capture policy may specify that captures be automatically deleted to meet a cost target and or cap. Enforcement of data capture retention policies may analyze associated capture sets to prioritize deletion of redundant captures and or prohibit deletion of a capture that would prevent restoration of the data set to its state in time corresponding to the most recent capture .

Enforcing data set capture polices may involve multivariable optimizations. depicts aspects of an example storage policy enforcement component in accordance with at least one embodiment. The storage policy enforcement component is an example of the storage policy enforcement component of . The storage policy enforcement component may maintain one or more collections of data set capture policies specifying schedules and or conditions for data set capture creation and one or more collections of capture retention policies specifying schedules and or conditions for data set capture deletion. For example the storage administration interface may provide the collections to the storage policy enforcement component separately. Alternatively the storage administration interface may provide a unified collection of data set capture policies and the storage policy enforcement component may create the collections in accordance with the unified collection. As another example the storage policy enforcement component may maintain the unified collection received from the storage administration interface .

The storage policy enforcement component may include a data set capture scheduler configured at least to cause data set captures according to fixed schedules. For example some such fixed schedules may have been explicitly specified by a first collection of the data set capture policies and some may have been determined and or derived collectively determined based at least in part on flexible schedules and or capture conditions specified by a second collection of the data set capture policies . A data set capture optimization component may perform such fixed schedule determinations. The data set capture optimization component may draw on any suitable distributed program execution service parameter and or parameter predictions provided by an optimization parameter prediction engine to create fixed schedules for data set captures in accordance with the data set capture polices . Such parameters may include attributes of data set captures already scheduled with the data set capture scheduler including historical and estimated data transfer volumes and durations historical and forecast data store server loads and network loads current computing resource costs including financial costs historical and forecast data set change patterns historical and scheduled pre capture data transfers and distributed program execution service component characteristics such as time taken by the low latency data store to recover from loss of redundancy.

The data set capture optimization component may schedule data set captures to optimize distribute and or level collectively optimize computing resource utilization load. Computing resource utilization load may be further optimized with pre capture data transfers. Where justified by forecast data set change patterns and or forecast computing resource utilization loads dirty portions of the data set may be transferred to the high durability data store in advance of a scheduled capture time with a goal of reducing data transfer in the period following the scheduled capture time reducing post capture data transfer . For example pre capture data transfers may be justified when a resultant benefit from computing resource utilization load reduction following the scheduled capture time exceeds a computing resource utilization load penalty. Such load penalties can occur due to premature pre capture data transfer such as the pre capture transfer of dirty data that becomes re dirtied before the scheduled capture time. A pre capture data transfer component may determine when pre capture transfers are justified based at least in part on suitable distributed program execution service parameters and or parameter predictions provided by the optimization parameter prediction engine .

The storage policy enforcement component may further include a capture deletion scheduler configured at least to delete data set captures when their specified lifetimes expire. For example the capture retention policies may specify explicit lifetimes for some captures and a capture retention optimization component may determine lifetimes for other captures in accordance with the capture retention policies . The capture retention optimization component may make such determinations based at least in part on suitable distributed program execution service parameters including attributes of the capture sets and or parameter predictions provided by the optimization parameter prediction engine .

As an example suppose the data set capture policies include policies specifying data set captures with fixed and flexible schedules. depicts aspects of a corresponding example computing resource utilization load optimization that may be performed by the data set capture optimization component in accordance with at least one embodiment. shows a base load varying over time. The base load corresponds to a distributed program execution service computing resource load. For example the base load may correspond to a data store server load a network load or a combination thereof. The base load may correspond to a computing resource load incurred independent of computing resource loads imposed by data set capture. For example the base load may be due to activities of virtual computing service user applications hosted by the virtual computer system instances . The base load depicted in includes a peak corresponding to a potential period of over utilization and a trough corresponding to a potential period of under utilization however such base load curves may include any suitable number of peaks and troughs.

In the example depicted in the data set capture optimization component is scheduling data set captures in accordance with data set capture policies specifying fixed schedules unfilled rectangles and data set captures in accordance with data set capture policies specifying flexible schedules rectangles filled with diagonal lines . The pre capture data transfer component further schedules pre capture transfers crosshatched rectangles . The size of the rectangles corresponds to the depicted amount of load L placed upon the computing resources for the depicted amount of time t . The storage policy enforcement component is scheduling the data set captures and pre capture transfers over a particular time period from time tto time t. In this example the storage policy enforcement component is performing the scheduling at a time prior to time t so the time period from time tto time tis in the future and is called the forecast period.

The optimization parameter prediction engine may forecast the base load over the forecast period. For example the optimization parameter prediction engine may forecast the base load based at least in part on associated historical computing resource load patterns. The historical computing resource load patterns may be with respect to the distributed program execution service as a whole the virtual data store service particular data sets and or a particular user of the virtual computing services. The optimization parameter prediction engine may further take into account the data set captures scheduled according to a fixed schedule during the forecast period. Given that forecast load during the forecast period the data set capture optimization component may then schedule data set captures associated with flexible schedules with a goal of keeping the total forecast load less than a target load L. The pre capture data transfer component may then schedule pre capture data transfers where justified and again with the goal of keeping the total forecast load less than the target load L. Each type of computational resource and or combination thereof may have a different target load L

In at least one embodiment the low latency data store may maintain data sets with redundant components. For example the set of computing resources allocated to the low latency data store may be utilized to maintain at least one redundant copy of each data set . depicts aspects of an example virtual data store service in accordance with at least one embodiment. The virtual data store service is an example of the virtual data store service of . The virtual data store service includes a low latency data store and a high durability data store corresponding to the low latency data store and the high durability data store respectively of . In this example the low latency data store maintains a data set DScorresponding to the data set of . The low latency data store also maintains a redundant copy DSof the data set DSto guard against data loss due to underlying hardware failures. To further guard against data loss the a corresponding collection of captures C C . . . Cof the data set DShas also been established.

The data sets DS DS DSmay be large. For example on the order of gigabytes terabytes and more. Thus complete restoration of redundancy may take significant time. However it is typical for virtual computing services user applications to access a relatively small proportion of a given data set DS during a particular time period. Utility may be gained by restoring redundancy in an on demand or lazy manner. Until redundancy is restored the data set DSmay be vulnerable to data loss for example due to further hardware failures. A first phase in redundancy restoration may be to copy that portion of the data set DSthat has changed since the most recent capture Cat time t i.e. the uncaptured portion of the data set DS . depicts the first phase as completing at time t. At time t a partial or lazy redundancy restoration may be considered to have occurred with full redundancy restored later at time t when data transfer from the collection of captures C completes.

Once partial redundancy restoration has occurred at time t a risk of data loss from data set DSmay be significantly reduced. The time period from time tto time t may depend upon a redundancy restoration characteristic of the low latency data store for example available bandwidth for copying uncaptured data between the data sets DSand DS. In at least one embodiment the time period from time tto time tmay be reduced by reducing the amount of uncaptured data in data set DS for example by more frequent captures of the data set DS. The data set capture optimization component may have access to the redundancy restoration characteristic of the low latency data store and thus may determine suitable capture frequencies to achieve probability of data loss targets. The times t t t t ton the time line in indicate a sequence of events and are not necessarily to scale.

At step one or more policy updates may be received. For example the storage policy enforcement component may receive the policy updates. At step one or more policy aggregates and or collections may be updated and or maintained. For example one of the collections of data set capture policies and or the collections of capture retention policies may be updated in accordance with the policy updates received at step . At step the updated policies may be enforced for example by the storage policy enforcement component . Steps are enclosed by dashed line to indicate that the steps may be performed by the storage policy enforcement component responsive to received data set capture policies.

At step pertinent server load s may be forecast. For example the optimization parameter prediction engine may forecast server loads associated with the data stores and based at least in part on the historical information collected at step . At step pertinent network load s may be forecast. For example the optimization parameter prediction engine may forecast network loads in the distributed program execution service based at least in part on the historical information collected at step . At step data set capture may be optimized. For example the data set capture optimization component may schedule data set captures in accordance with data set capture policies specifying flexible schedules and or capture conditions and or based at least in part on one or more forecasts provided by the optimization parameter prediction engine such as the forecasts of steps and . At step capture retention may be optimized. For example the capture retention optimization component may schedule capture deletions in accordance with capture retention policies specifying flexible capture lifetimes and or retention conditions and or based at least in part on one or more forecasts provided by the optimization parameter prediction engine such as the forecasts of steps and .

At step one or more probabilities that currently dirty data in the data set will be re dirtied i.e. change again between now and a scheduled and or likely time of capture for the data set may be forecast. For example the optimization parameter prediction engine may forecast such probabilities based at least in part on the data set change information collected at step of . The optimization parameter prediction engine may forecast one such probability for the data set as a whole and or one or more such probabilities for one or more blocks of the data set. At step one or more pre capture transfers of data in the data set may be scored. For example the pre capture data transfer component may score a desirability of the pre capture transfer of one or more blocks of the data set based at least in part on one or more forecasts provided by the optimization parameter prediction engine such as the forecasts of steps and of and or the forecasts of steps and . The desirability of pre capture transfer s may be scored with respect to immediate scheduling for example on a scale of 1 to 1 with 1 corresponding to certainly desirable and 1 corresponding to certainly undesirable. Alternatively or in addition the score s for the pre capture transfer s may be forecast throughout the forecast period.

At step it may be determined whether there are further flexible capture policies to consider. If so a procedure incorporating step may progress to step . Otherwise the procedure may progress to step . The steps are enclosed in a dashed line to indicate that as will be apparent to one of skill in the art the flexible capture policies of one of the collections need not be processed one by one in an iterative loop as illustrated in but may be processed as a collection utilizing equivalent set and or matrix operations for efficiency.

At step one or more data set captures in accordance with data set capture policies specifying flexible schedules and or capture conditions may be scheduled and or re scheduled. For example the data set capture optimization component may select the captures to schedule with the data set capture scheduler based at least in part on the scores determined at step e.g. in order of desirability as indicated by the scores and as constrained by available computing resources and or associated utilization loads. The data set capture scheduler may maintain a collection of tentatively scheduled data set captures that is periodically updated by the data set capture optimization component . At step one or more pre capture data transfers may be scheduled and or re scheduled. For example the pre capture data transfer component may select candidate pre capture transfers to schedule based at least in part on the scores determined at step e.g. in order of desirability as indicated by the scores and as constrained by available computing resources and or associated utilization loads.

At step it may be determined whether there are further flexible capture retention policies to consider. If so a procedure incorporating step may progress to step . Otherwise the procedure may progress to step . The steps are enclosed in a dashed line to indicate that as will be apparent to one of skill in the art the flexible capture retention policies of the collection need not be processed one by one in an iterative loop as illustrated in but may be processed as a collection utilizing equivalent set and or matrix operations for efficiency. At step one or more capture deletions in accordance with capture retention policies specifying flexible lifetimes and or retention conditions may be scheduled and or re scheduled. For example the capture retention optimization component may select the captures to delete based at least in part on the scores determined at step e.g. in order of desirability as indicated by the scores and as constrained by available computing resources and or associated utilization loads.

At step a request may be sent to create a workflow based at least in part on the one or more actions determined at step . For example service administration interface and or the service policy enforcement component may send the request to the workflow component . The request to create the workflow may include the action s action metadata such as type of action and or action parameters. In at least one embodiment the control plane and or the workflow component maintains a job queue for such requests and workflows are created responsive to new additions to the job queue. At step a workflow and one or more component tasks may be created. For example the workflow component may analyze the request of step to determine the appropriate workflow and component tasks to create.

At step execution of the component task s may be guided in accordance with the workflow. For example the workflow component may activate elements of interfaces of components of virtual data store service and or the virtual computer system service . Alternatively or in addition the workflow component may manage bids for execution of the component task s by components of the distributed program execution service . At step it may be determined whether the workflow has finished. For example the workflow component may determine whether a final task in a sequence of tasks managed by the workflow has completed. If so a procedure including step may progress to step . Otherwise the procedure may return to step for a next task and or task sequence. Workflows may guide multiple task sequences executing in parallel. In this case it may be that the workflow is not finished until each of the multiple task sequences completes and or an explicit workflow finished flag is set by one of the component tasks. At step the sender of the request of step may be informed of the result s of the action s .

The various embodiments described herein may be implemented in a wide variety of operating environments which in some cases may include one or more user computers computing devices or processing devices which may be utilized to operate any of a number of applications. User or client devices may include any of a number of general purpose personal computers such as desktop or laptop computers running a standard operating system as well as cellular wireless and handheld devices running mobile software and capable of supporting a number of networking and messaging protocols. Such a system also may include a number of workstations running any of a variety of commercially available operating systems and other known applications for purposes such as development and database management. These devices also may include other electronic devices such as dummy terminals thin clients gaming systems and other devices capable of communicating via a network.

Most embodiments utilize at least one network that would be familiar to those skilled in the art for supporting communications using any of a variety of commercially available protocols such as TCP IP OSI FTP UPnP NFS CIFS and AppleTalk. Such a network may include for example a local area network a wide area network a virtual private network the Internet an intranet an extranet a public switched telephone network an infrared network a wireless network and any combination thereof. The network may furthermore incorporate any suitable network topology. Examples of suitable network topologies include but are not limited to simple point to point star topology self organizing peer to peer topologies and combinations thereof.

In embodiments utilizing a Web server the Web server may run any of a variety of server or mid tier applications including HTTP servers FTP servers CGI servers data servers Java servers and business application servers. The server s also may be capable of executing programs or scripts in response requests from user devices such as by executing one or more Web applications that may be implemented as one or more scripts or programs written in any programming language such as Java C C or C or any scripting language such as Perl Python or TCL as well as combinations thereof. The server s may also include database servers including without limitation those commercially available from Oracle Microsoft Sybase and IBM .

The environment may include a variety of data stores and other memory and storage media as discussed above. These may reside in a variety of locations such as on a storage medium local to and or resident in one or more of the computers or remote from any or all of the computers across the network. In a particular set of embodiments the information may reside in a storage area network SAN familiar to those skilled in the art. Similarly any necessary files for performing the functions attributed to the computers servers or other network devices may be stored locally and or remotely as appropriate. Where a system includes computerized devices each such device may include hardware elements that may be electrically coupled via a bus the elements including for example at least one central processing unit CPU at least one input device e.g. a mouse keyboard controller touch screen or keypad and at least one output device e.g. a display device printer or speaker . Such a system may also include one or more storage devices such as disk drives optical storage devices and solid state storage devices such as random access memory RAM or read only memory ROM as well as removable media devices memory cards flash cards etc.

Such devices also may include a computer readable storage media reader a communications device e.g. a modem a network card wireless or wired an infrared communication device etc. and working memory as described above. The computer readable storage media reader may be connected with or configured to receive a computer readable storage medium representing remote local fixed and or removable storage devices as well as storage media for temporarily and or more permanently containing storing transmitting and retrieving computer readable information. The system and various devices also typically will include a number of software applications modules including program modules services or other elements located within at least one working memory device including an operating system and application programs such as a client application or Web browser. It should be appreciated that alternate embodiments may have numerous variations from that described above. For example customized hardware might also be utilized and or particular elements might be implemented in hardware software including portable software such as applets or both. Further connection to other computing devices such as network input output devices may be employed.

Storage media and computer readable media for containing code or portions of code may include any appropriate media known or used in the art including storage media and communication media such as but not limited to volatile and non volatile removable and non removable media implemented in any method or technology for storage and or transmission of information such as computer readable instructions data structures program modules or other data including RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disk DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which may be utilized to store the desired information and which may be accessed by the a system device. Program modules program components and or programmatic objects may include computer readable and or computer executable instructions of and or corresponding to any suitable computer programming language. In at least one embodiment each computer readable medium may be tangible. In at least one embodiment each computer readable medium may be non transitory in time. Based on the disclosure and teachings provided herein a person of ordinary skill in the art will appreciate other ways and or methods to implement the various embodiments.

The specification and drawings are accordingly to be regarded in an illustrative rather than a restrictive sense. It will however be evident that various modifications and changes may be made thereunto without departing from the broader spirit and scope of the invention as set forth in the claims.

The use of the terms a and an and the and similar referents in the context of describing embodiments especially in the context of the following claims are to be construed to cover both the singular and the plural unless otherwise indicated herein or clearly contradicted by context. The terms comprising having including and containing are to be construed as open ended terms i.e. meaning including but not limited to unless otherwise noted. The term connected is to be construed as partly or wholly contained within attached to or joined together even if there is something intervening. Recitation of ranges of values herein are merely intended to serve as a shorthand method of referring individually to each separate value falling within the range unless otherwise indicated herein and each separate value is incorporated into the specification as if it were individually recited herein. All methods described herein can be performed in any suitable order unless otherwise indicated herein or otherwise clearly contradicted by context. The use of any and all examples or exemplary language e.g. such as provided herein is intended merely to better illuminate embodiments and does not pose a limitation on the scope unless otherwise claimed. No language in the specification should be construed as indicating any non claimed element as essential to the practice of at least one embodiment.

Preferred embodiments are described herein including the best mode known to the inventors. Variations of those preferred embodiments may become apparent to those of ordinary skill in the art upon reading the foregoing description. The inventors expect skilled artisans to employ such variations as appropriate and the inventors intend for embodiments to be constructed otherwise than as specifically described herein. Accordingly suitable embodiments include all modifications and equivalents of the subject matter recited in the claims appended hereto as permitted by applicable law. Moreover any combination of the above described elements in all possible variations thereof is contemplated as being incorporated into some suitable embodiment unless otherwise indicated herein or otherwise clearly contradicted by context.

All references including publications patent applications and patents cited herein are hereby incorporated by reference to the same extent as if each reference were individually and specifically indicated to be incorporated by reference and were set forth in its entirety herein.

