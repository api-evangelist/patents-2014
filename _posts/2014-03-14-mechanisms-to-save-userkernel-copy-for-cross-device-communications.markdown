---

title: Mechanisms to save user/kernel copy for cross device communications
abstract: Central processing units (CPUs) in computing systems manage graphics processing units (GPUs), network processors, security co-processors, and other data heavy devices as buffered peripherals using device drivers. Unfortunately, as a result of large and latency-sensitive data transfers between CPUs and these external devices, and memory partitioned into kernel-access and user-access spaces, these schemes to manage peripherals may introduce latency and memory use inefficiencies. Proposed are schemes to reduce latency and redundant memory copies using virtual to physical page remapping while maintaining user/kernel level access abstractions.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09436395&OS=09436395&RS=09436395
owner: Advanced Micro Devices, Inc.
number: 09436395
owner_city: Sunnyvale
owner_country: US
publication_date: 20140314
---
The disclosure generally relates to cross device communications and more specifically to techniques to reduce redundant copies of data across user and kernel space boundaries in a virtual memory address space.

Central processing units CPUs in computing systems may manage graphics processing units GPUs network processors security co processors and other data heavy devices as buffered peripherals using device drivers. Unfortunately as a result of large and latency sensitive data transfers required between CPUs and these external devices and memory partitioned into kernel access and user access spaces these schemes to manage peripherals may introduce latency and memory use inefficiencies.

For example an exemplary computing system may include a CPU and GPU sharing a common memory address space with each of the CPU and GPU having a page locked buffer in kernel access memory address space. Direct memory access DMA controllers may transfer data between the CPU buffer in kernel access memory address space and the CPU and between the GPU buffer in kernel access memory address space and the GPU without direct intervention of the CPU. However to transfer data for example from the CPU to the GPU may result in creating a redundant non page locked buffer in user access memory address space copying data from the CPU buffer to the user access buffer and copying data from the user access buffer to the GPU buffer. Kernel application programming interfaces APIs may include functionality to copy data between kernel access and user access buffers.

Various proposed schemes to avoid creation of a redundant non page locked buffer during data transfer between devices have included customized hardware support of interconnected devices or collaboration between device vendors during development of device drivers. These schemes introduce additional disadvantages such as incompatibility with new devices and standard hardware interfaces or common device drivers that may drive additional cost and complexity into the development of new devices. As such apparatus and methods to transfer data between devices that minimizes redundant data copies and latency while utilizing existing kernel APIs provides significant advantages.

One exemplary embodiment includes a method to copy data comprising mapping with kernel permissions a first virtual memory address to a first physical memory address mapping with kernel permissions a second virtual memory address to a second physical memory address. This embodiment further includes receiving the data at the first physical memory address mapping with user permissions a third virtual memory address to the first physical memory address and copying with kernel permissions the data from the first physical memory address to the second physical memory address.

Another exemplary embodiment includes a system to copy data comprising a memory and a processor coupled to the memory configured to map with kernel permissions a first virtual memory address to a first physical memory address in the memory. This embodiment includes the processor configured to map with kernel permissions a second virtual memory address to a second physical memory address in the memory and receive the data at the first physical memory address. Still further this embodiment includes the processor configured to map with user permissions a third virtual memory address to the first physical memory address and copy with kernel permissions the data from the first physical memory address to the second physical memory address.

An additional exemplary embodiment includes a non transitory computer readable medium comprising instructions that when executed by a processor cause the processor to map with kernel permissions a first virtual memory address to a first physical memory address and map with kernel permissions a second virtual memory address to a second physical memory address and receive data at the first physical memory address. This exemplary embodiment also includes the non transitory computer readable medium comprising instructions that when executed by a processor cause the processor to map with user permissions a third virtual memory address to the first physical memory address and copy with kernel permissions the data from the first physical memory address to the second physical memory address.

The above exemplary embodiments will become more readily apparent from the following detailed description with reference to the accompanying drawings. However the above exemplary embodiments do not limit additional disclosed embodiments present in the following detailed description.

Embodiments of the disclosure will now be described with reference to the accompanying drawings. In the drawings like reference numbers generally indicate identical functionally similar and or structurally similar elements. The drawing in which an element first appears is indicated by the leftmost digit s in the reference number.

The following Detailed Description refers to accompanying drawings to illustrate exemplary embodiments consistent with the disclosure. References in the Detailed Description to one exemplary embodiment an exemplary embodiment an example exemplary embodiment etc. indicate that the exemplary embodiment described can include a particular feature structure or characteristic but every exemplary embodiment can not necessarily include the particular feature structure or characteristic. Moreover such phrases are not necessarily referring to the same exemplary embodiment. Further when a particular feature structure or characteristic is described in connection with an exemplary embodiment it is within the knowledge of those skilled in the relevant art s to affect such feature structure or characteristic in connection with other exemplary embodiments whether or not explicitly described.

As such as data becomes available at the interface device the DMA controller transfers data from the interface device to the input buffer and the processor may process the data stored therein. When data becomes available in the output buffer the DMA controller may transfer the data stored therein to the interface device . In some embodiments to transfer data from the interface device to the interface the processor may generate an intermediate copy of data stored in the input buffer and subsequently move the data to the output buffer .

Similar to the computing system includes interface devices and each including respective DMA controllers and . The DMA controller may transfer data from the interface device into an input buffer page locked in the kernel address space of the memory . Likewise the DMA controller may transfer data from an output buffer page locked in the kernel address space of the memory to the interface device . As such a process with kernel level permissions executing on a processor not illustrated in may read write or modify the input buffer or output buffer . In some embodiments the input buffer may be copied to a user buffer in the user address space by a process with user level permissions executing a kernel API function such as copy to user that spawns or instructs a process with kernel permissions to allocate the user buffer and copy data from the input buffer to the user buffer . Likewise the user buffer may be copied to the output buffer by a process with user level permissions executing a kernel API function such as copy from user that spawns or instructs a process with kernel permissions to copy data from the user buffer to the output buffer . Thus the memory provides a conduit for data transfer between the interface device and the interface device while maintaining a user kernel permission separation of the memory .

In one embodiment the DMA controller transfers data from the input device into a page locked device buffer in the physical address space . A process with user level permissions executing on a processor executes a kernel API function for example copy to user a process with kernel level permissions may instantiate a non page locked buffer in the physical address space . Subsequently the process with kernel level permissions may instantiate a virtual user buffer and update the page table translator to indicate that the non page locked buffer corresponds to the virtual user buffer . In such an embodiment the copy to user kernel API may further cause a process with kernel level permissions to copy data from the page locked device buffer to the non page locked buffer . At this point a process with user level permissions may read write or modify the data contained in the non page locked buffer and the corresponding virtual user buffer . Likewise the process with user level permissions may execute a kernel API function for example copy from user causing a process with kernel level permissions to copy the data from the non page locked buffer to the page locked device buffer . The DMA controller may transfer the data in the page locked device buffer to an output device thus completing the transfer of data from the input device to the output device . In other embodiments the input device and output device may comprise one device with both input and output capabilities.

The flowchart includes step wherein in some embodiments a DMA controller similar to the DMA controller of transfers data directly from a first device to a first page locked buffer in a kernel address space. The first device may correspond in some embodiments to the input device of and the first page locked buffer may correspond to the non page locked device buffer and the corresponding virtual device buffer in the kernel access virtual address space .

Step includes in some embodiments a process with kernel level permissions executing on a processor copying data from the first page locked buffer in kernel address space to a non page locked buffer in user address space. In a similar embodiment the process with kernel level permissions executing on the processor at step copies data from the non page locked buffer in user address space to a second page locked buffer in kernel address space.

The second page locked buffer in kernel address space in some embodiments corresponds to the page locked device buffer and the corresponding virtual device buffer in the kernel access virtual address space . Step includes in some embodiments a DMA controller transfers data directly from the second page locked buffer in kernel address space to a second device. The DMA controller may correspond for example to the DMA controller in . Likewise the second device may correspond for example to the output device in . Thus the flowchart enables data transfer from the first device to the second device using a memory including a kernel address space and a user address space.

In one embodiment the DMA controller transfers data from the input device into a page locked device buffer in the physical address space . A process with user level permissions executes a modified kernel API function for example a modified version of copy to user . The modified version of copy to user may spawn or cause a process with kernel level permissions to instantiate a virtual user buffer in the user access virtual address space and update the page table translator to indicate that the virtual user buffer also corresponds to the page locked device buffer . Thus the page locked device buffer now has two corresponding buffers the virtual user buffer in the user access address space and the virtual device buffer in kernel address space . The modified version of copy to user may for example be included as a configuration option when a driver is linked into the kernel compiler option. In other embodiments the modified version of copy to user may be a compilation option for the kernel itself.

In the above embodiment in order to preserve the user kernel access abstraction the page locked device buffer may be designated as copy on write. A copy on write designation may indicate that if the page locked device buffer or the corresponding virtual user buffer is modified or over written by a process with user level access that the page locked device buffer be first copied to another physical memory location before modification.

A process with user access may execute for example the copy from user kernel API that causes a process with kernel level permissions to copy data from the page locked device buffer to the page locked device buffer . Thus a similar copy from the page locked device buffer to the page locked device buffer occurs without instantiating the non page locked buffer of while maintaining the user kernel access abstraction. Subsequently the DMA controller may transfer the data in the page locked device buffer to an output device thus completing the transfer of data from the input device to the output device . In other embodiments the input device and output device may comprise one device with both input and output capabilities.

The flowchart includes step wherein in some embodiments a DMA controller similar to the DMA controller of transfers data directly from a first device to a first page locked buffer in a kernel address space. The first device may correspond in some embodiments to the input device of and the first page locked buffer may correspond to the page locked device buffer and the corresponding virtual device buffer in the kernel access virtual address space .

Step includes in some embodiments a process with kernel level permissions that remaps a virtual user buffer in a page table translator to the first page locked buffer in kernel address space. In one embodiment the virtual user buffer corresponds to the virtual user buffer of and the page table translator corresponds to the page table translator of .

Step includes marking the first page locked buffer in kernel address space copy on write. In some embodiments the copy on write indication resides in the page table translator of . In a similar embodiment the process with kernel level permissions executing on the processor at step copies data from the first page locked buffer to a second page locked buffer.

The second page locked buffer in kernel address space in some embodiments corresponds to the page locked device buffer and the corresponding virtual device buffer in the kernel access virtual address space . Step includes in some embodiments a DMA controller transferring data directly from the second page locked buffer in kernel address space to a second device. The DMA controller may correspond for example to the DMA controller in . Likewise the second device may correspond for example to the output device in . Thus the flowchart enables data transfer from the first device to the second device that reduces redundant physical memory copies while maintaining the user kernel access abstraction.

In one embodiment the DMA controller transfers data from the input device into a page locked device buffer in the physical address space . A process with user level permissions executes a modified kernel API function for example a modified version of copy to user . The modified version of copy to user may spawn or cause a process with kernel level permissions to instantiate a virtual user buffer in the user access virtual address space and update the page table translator to indicate that the virtual user buffer also corresponds to the page locked device buffer . Thus the page locked device buffer now has two corresponding buffers the virtual user buffer in the user access address space and the virtual device buffer in kernel address space . The modified version of copy to user may for example be included as a configuration option when a driver is linked into the kernel compiler option. In other embodiments the modified version of copy to user may be a compilation option for the kernel itself.

In the above embodiment in order to preserve the user kernel access abstraction the page locked device buffer may be designated as copy on write. A copy on write designation may indicate that if the page locked device buffer or the corresponding virtual user buffer is modified or over written by a process with user level access that the page locked device buffer be first copied to another physical memory location before modification. When such a modification or over write occurs by a process with user access a process with kernel access instantiates a non page locked buffer and updates the page table translator to indicate that the virtual user buffer corresponds to the non page locked buffer . At this point a process with user level permissions may read write or modify the data contained in the non page locked buffer and the corresponding virtual user buffer .

Similar to the embodiments illustrated in a process with user access may execute for example the copy from user kernel API that causes a process with kernel level permissions to copy data from the page locked device buffer to the page locked device buffer . Thus a similar copy from the page locked buffer to the page locked device buffer occurs without instantiating the non page locked buffer of while maintaining the user kernel access abstraction. Subsequently the DMA controller may transfer the data in the page locked device buffer to an output device thus completing the transfer of data from the input device to the output device . In other embodiments the input device and output device may comprise one device with both input and output capabilities.

The flowchart includes step wherein in some embodiments a process with user access attempts to modify data in a page locked buffer marked copy on write using a user buffer. As a consequence of attempting to modify data in the page locked buffer marked copy on write the processor may issue a page fault for example indicating that the data is unavailable. The page locked buffer marked copy on write may for example correspond to the page locked device buffer of and the user buffer may correspond to the virtual user buffer of .

Step includes in some embodiments a process with kernel level permissions executing on a processor copying data from the page locked buffer in kernel address space to a non page locked buffer in user address space. Step includes remapping the user buffer to the non page locked device buffer. Thus a process with user level permissions may read write or modify the data contained in the non page locked buffer and the corresponding user buffer.

It is to be appreciated that the Detailed Description section and not the Summary and Abstract sections is intended to be used to interpret the claims. The Summary and Abstract sections may set forth one or more but not all exemplary embodiments of the present invention as contemplated by the inventor s and thus are not intended to limit the present invention and the appended claims in any way.

The exemplary embodiments described herein are provided for illustrative purposes and are not limiting. Other exemplary embodiments are possible and modifications may be made to the exemplary embodiments within the spirit and scope of the disclosure. Therefore the Detailed Description is not meant to limit the disclosure. Rather the scope of the disclosure is defined only in accordance with the following claims and their equivalents.

Embodiments of the disclosure may be implemented in hardware firmware software or any combination thereof. Embodiments of the disclosure may also be implemented as instructions stored on a machine readable medium which may be read and executed by one or more processors. A machine readable medium may include any mechanism for storing or transmitting information in a form readable by a machine e.g. a computing device . For example a machine readable medium may include read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices electrical optical acoustical or other forms of propagated signals e.g. carrier waves infrared signals digital signals etc. and others. Further firmware software routines instructions may be described herein as performing certain actions. However it should be appreciated that such descriptions are merely for convenience and that such actions in fact result from computing devices processors controllers or other devices executing the firmware software routines instructions etc.

It is to be appreciated that the Detailed Description section and not the Abstract section is intended to be used to interpret the claims. The Abstract section may set forth one or more but not all exemplary embodiments of the disclosure and thus are not intended to limit the disclosure and the appended claims in any way.

The disclosure has been described above with the aid of functional building blocks illustrating the implementation of specified functions and relationships thereof. The boundaries of these functional building blocks have been arbitrarily defined herein for the convenience of the description. Alternate boundaries may be defined so long as the specified functions and relationships thereof are appropriately performed.

It will be apparent to those skilled in the relevant art s that various changes in form and detail can be made therein without departing from the spirit and scope of the disclosure. Thus the disclosure should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

