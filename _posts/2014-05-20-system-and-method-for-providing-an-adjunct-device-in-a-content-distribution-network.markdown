---

title: System and method for providing an adjunct device in a content distribution network
abstract: A cache server receives content and an instruction indicating an event associated with the content that causes a processor to invoke a call out to an adjunct device. The instruction further indicates an operation that the adjunct device is to perform. The cache server detects the event associated with the content, halts a flow of the content in response to detecting the event associated with the content, passes via the call out the content to the adjunct device to perform the operation, receives from the adjunct device a response and resulting data from the operation, and performs an additional operation on the resulting data based on the response from the adjunct device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09356996&OS=09356996&RS=09356996
owner: AT&T INTELLECTUAL PROPERTY I, L.P.
number: 09356996
owner_city: Atlanta
owner_country: US
publication_date: 20140520
---
This application is a continuation of and claims priority to U.S. patent application Ser. No. 13 159 977 filed Jun. 14 2011 which is hereby incorporated by reference in its entirety.

The present disclosure generally relates to communications networks and more particularly relates to content distribution networks.

Packet switched networks such as networks based on the TCP IP protocol suite can distribute a rich array of digital content to a variety of client applications. One popular application is a personal computer browser for retrieving documents over the Internet written in the Hypertext Markup Language HTML . Frequently these documents include embedded content. Where once the digital content consisted primarily of text and static images digital content has grown to include audio and video content as well as dynamic content customized for an individual user.

It is often advantageous when distributing digital content across a packet switched network to divide the duty of answering content requests among a plurality of geographically dispersed servers. For example popular Web sites on the Internet often provide links to mirror sites that replicate original content at a number of geographically dispersed locations. A more recent alternative to mirroring is content distribution networks CDNs that dynamically redirect content requests to a cache server situated closer to the client issuing the request. CDNs either co locate cache servers within Internet Service Providers or deploy them within their own separate networks.

The numerous innovative teachings of the present application will be described with particular reference to the presently preferred exemplary embodiments. However it should be understood that this class of embodiments provides only a few examples of the many advantageous uses of the innovative teachings herein. In general statements made in the specification of the present application do not necessarily limit any of the various claimed inventions. Moreover some statements may apply to some inventive features but not to others.

AS can further include a Domain Name System DNS server . DNS server can translate a human readable hostname such as www.att.com into an Internet Protocol IP address. For example client system can send a request to resolve a hostname to DNS server . DNS server can provide client system with an IP address corresponding to the hostname. DNS server may provide the IP address from a cache of hostname IP address pairs or may request the IP address corresponding to the hostname from an authoritative DNS server for the domain to which the hostname belongs.

Client systems and can retrieve information from a server . For example client system can retrieve a web page provided by server . Additionally client system may download content files such as graphics audio and video content and program files such as software updates from server . The time required for client system to retrieve the information from the server normally is related to the size of the file the distance the information travels and congestion along the route. Additionally the load on the server is related to the number of client systems and that are actively retrieving information from the server . As such the resources such as processor memory and bandwidth available to the server limit the number of client systems and that can simultaneously retrieve information from the server .

Additionally the network can include cache servers and that replicate content on the server and that can be located more closely within the network to the client systems and . Cache server can link to router and cache server can link to router . Client systems and can be assigned cache server or to decrease the time needed to retrieve information such as by selecting the cache server closer to the particular client system. The network distance between a cache server and client system can be determined by network cost and access time. As such the effective network distance between the cache server and the client system may be different from the geographic distance.

When assigning cache servers and to client systems and the cache server closest to the client can be selected. The closest cache server may be the cache server having a shortest network distance a lowest network cost a lowest network latency a highest link capacity a lowest load or any combination thereof. Client system can be assigned cache server and client systems and can be assigned to cache server . The network costs of assigning client system to either of cache server or may be substantially identical. When the network costs associated with the link between router and router are marginally lower than the network costs associated with the link between router and router client may be assigned to cache server .

Client system may send a request for information to cache server . If cache server has the information stored in a cache it can provide the information to client system . This can decrease the distance the information travels and reduce the time to retrieve the information. Alternatively when cache server does not have the information it can retrieve the information from server prior to providing the information to the client system . In an embodiment cache server may attempt to retrieve the information from cache server prior to retrieving the information from server . The cache server may retrieve the information from the server only once reducing the load on server and network such as for example when client system requests the same information.

Cache server can have a cache of a limited size. The addition of new content to the cache may require old content to be removed from the cache. The cache may utilize a least recently used LRU policy a least frequently used LFU policy or another cache policy known in the art. When the addition of relatively cold or less popular content to the cache causes relatively hot or more popular content to be removed from the cache an additional request for the relatively hot content can increase the time required to provide the relatively hot content to the client system such as client system . To maximize the cost and time savings of providing content from the cache the most popular content may be stored in the cache while less popular content is retrieved from server .

The cache server can provide different core features for handling and processing the content in the CDN such as caching the content distributing the content and the like. In an embodiment the cache server can also be a streaming server or the like. The adjunct servers and can provide additional features that are not provided by the cache server such as compressing the content rewriting a hypertext transfer protocol HTTP header transcoding video content calculating a time to live TTL period for the content in the cache server authenticating the client device to receive the content and the like. The additional features provided by the adjunct servers and may be features that are not often utilized in the CDN or may require a high processor utilization in a server. Thus the additional features can be specialized features that may need hardware and or software to be executed that may not be installed in the cache server or other core devices in the CDN .

In an embodiment there can be more adjunct servers than shown in and each of the adjunct servers can perform a different specialized function or operation. Each of the adjunct servers can have an Internet Protocol IP address assigned and each of the adjunct servers can advertise its IP addresses via Border Gateway Protocol BGP . The cache server can utilize the IP addresses to identify the appropriate adjunct server to which to send an application programming interface API call out. The content can be standardized when it is passed between the cache server and the adjunct servers and such that a wide variety of offloading operations can be supported in the CDN .

Each of the adjunct servers and can include an adjunct processor or set of processors that may support a single instance or multiple instances of the cache server . The adjunct servers and may be in a hierarchical relationship such that adjunct server can include additional functionality that the adjunct server does not have. The additional functionality may enable the adjunct server to perform operations that are more specialized and or that require more processing ability than the operations that can be performed by the adjunct server . The cache server can communicate with the adjunct servers and via HTTP representational state transfer REST interface or any suitable alternative protocol. For example the HTTP REST interface can enable the cache server to send a request to the adjunct server and and can enable the adjunct servers to return a response to the cache server. In an embodiment the adjunct servers and may be proprietary or managed adjunct servers such that the cache server may need to provide authentication information to communicate with the adjunct servers.

The cache server can communicate with the other devices in the CDN via a data channel a provisioning channel and the like. The cache server can utilize the data channel to route content data from the server to the client device from the client device to the server to or from other servers within the CDN and the like. The cache server can receive via the provisioning channel an instruction indicating events in the data channel of the cache server that can trigger an API call out to the adjunct server or . The instruction can also indicate where in a flow of data the call out should occur an operation that the adjunct server or should invoke on behalf of the cache server and the like.

During operation the cache server can cache content received from the server and can distribute the content to the client device via the data channel The cache server may have previously received instructions via the provisioning channel indicating that the adjunct server or should be invoked to perform different operations when the content data is cached. The operations can be calculating the TTL period for the content cached in the cache server transcoding video content and the like.

When the cache server caches the content the cache server can halt the flow of data in the cache server can invoke the adjunct server or to perform an operation and can send the content data to the adjunct server. The cache server can utilize an embedded API to call out the adjunct server or to perform one or more operations. For example the cache server can send an API call out to the adjunct server requesting that the adjunct server calculate a TTL period for specific content cached in the cache server.

The adjunct server can receive the API call out and the content from the cache server via the HTTP REST interface. The adjunct server can then use functionality embedded in the adjunct server to calculate the TTL period for the cached content. The functionality can include software applications processors and other hardware needed to perform the operation. When the adjunct server has calculated the TTL period the adjunct server can send a reply to the cache server via the HTTP REST interface. The reply can include data resulting from the operation such as the calculated TTL period for the cached content.

When the cache server receives the reply from the adjunct server the cache server can determine that another operation such as transcoding video content needs to be performed. The cache server can then determine whether the adjunct server has the functionality to perform the transcoding operation. If the adjunct server does have the functionality the cache server can send an API call to the adjunct server to perform the transcoding operation. The adjunct server can then perform the transcoding operation included in the API call from cache server and can send a reply including data resulting from the transcoding operation to the cache server via the HTTP REST interface.

The cache server can use the replies from the adjunct server and from the adjunct server to carry out an additional set of actions for the content data such as caching the transcoded video content in a memory of the cache server. The cache server can then resume the flow of content data in the CDN . The additional set of actions can be easily implemented such that they can be carried out by any type cache server in the CDN .

In another embodiment the adjunct servers and can be a cloud based adjunct server such that both of the adjunct servers are located in a single remote server. The cloud based adjunct server can include one or more processors hardware software and the like to perform any of the specialized features that may be needed in the CDN . That is the remote server can receive an API call out from one or more cache servers in the CDN and can perform a desired operation on the content. The cloud based adjunct server may have enough functionality to be able to perform multiple operations invoked by different cache servers at the same time. The cloud based server can be allocated more resources when new operations should be performed by the cloud based server such that only one server has to be updated with more resources.

In another embodiment the CDN can be joined together with CDN to be able to provide caching and distribution of larger amounts of content. In this situation a cache server of CDN may not be able to perform a specialized operation and CDN may not have an adjunct server capable of performing the specialized operation. The cache server may discover through BGP that adjunct server can perform the specialized operation. The cache server can then send an API call out to the adjunct server of CDN to invoke the adjunct server to perform the specialized operation on content. Thus the CDNs and may include adjunct servers that support API call outs from devices in other CDNs such that each CDN does need adjunct servers that can perform every possible operation that may be needed in that CDN.

During operation the cache server can cache content received from the server and can distribute the content to the client device via the data channel The cache server may have previously received instructions via the provisioning channel indicating that the adjunct server or should be invoked to perform different operations. The operations can be calculating the TTL period for the content cached in the cache server transcoding video content and the like. The instruction can also indicate that the adjunct servers and should be invoked when the content is cached in the cache server . When the cache server caches the content the cache server can halt the flow of data in the cache server can invoke the adjunct server to perform the one or more of the operations and can send the content data to the adjunct server. The cache server can utilize the API to call out the adjunct server to perform the one or more operations.

The adjunct server can receive the API call out and the content from the cache server via the HTTP REST interface. The adjunct server can then use functionality embedded in the adjunct server to perform one of the operations such as calculating the TTL period for the cached content. When the adjunct server has completed calculating the TTL period the adjunct server can determine whether the API call includes another operation to be performed. If the API call does not include another operation to be performed the adjunct server can send a reply to the cache server via the HTTP REST interface. The reply can include data resulting from the operation such as the calculated TTL period for the cached content. However if the API call does include another operation to be performed such as transcoding the video content the adjunct server can determine whether the adjunct server has the functionality to perform the operation.

If the adjunct server has the functionality to perform the transcoding operation the adjunct server can perform the transcoding operation. However if the adjunct server does not have the functionality the adjunct server can send an API call out to the adjunct server which does have the necessary functionality. In this situation the adjunct servers and can be in a hierarchical relationship such that adjunct server can include additional functionality and the adjunct server can pass operation to the adjunct server . The adjunct server can then perform the transcoding operation included in the API call from the adjunct server . The adjunct server can send a reply including data resulting from the transcoding operation to the adjunct server which in turn can provide the replies associated with both of the operations to the cache server via the HTTP REST interface.

At block the event associated with the content is detected at the server. A flow of the content is halted in the server at block . At block the content is passed via the call out to the adjunct device to perform the operation. A first response and content resulting from the first operation is received from the first adjunct device at block . At block a determination is made whether a next operation needs to be performed. If the next operation does not need to be performed a final operation is performed on the content resulting from the operation performed at the server based on the response from the first adjunct device at block .

If the next operation needs to be performed a second adjunct device is determined to have functionality to perform the next operation at block . At block the content is passed to the second adjunct device via a second call out. A second response based on the next operation is received at the server from the second adjunct device at block . In an embodiment the first adjunct device has more functionality than the server and the second adjunct device has more functionality than the first adjunct device. In another embodiment the first adjunct device and the second adjunct device form a hierarchical relationship in the content distribution network. The first adjunct device and the second adjunct device can be servers in the content distribution network.

If the next operation does need to be performed a determination is made whether the first adjunct device has a functionality to perform the next operation at block . If the first adjunct device has the functionality the next operation is performed in the first adjunct device at block . At block the response is sent to the server based on the requested operation and the next operation performed by the first adjunct device. If the first adjunct device does not have the functionality a second application programming interface call for the next operation is sent from the first adjunct device to a second adjunct device at block . At block a reply based on the next operation is received from the second adjunct device. The response from the first adjunct device and the reply from the second adjunct device are sent to the server at block .

In an embodiment the first adjunct device has more functionality than the server and the second adjunct device has more functionality than the first adjunct device. In another embodiment the first adjunct device and the second adjunct device form a hierarchical relationship for the requested operation and the next operation in the content distribution network. The first adjunct device and the second adjunct device can be servers in the content distribution network.

In a networked deployment the computer system may operate in the capacity of a server or as a client user computer in a server client user network environment or as a peer computer system in a peer to peer or distributed network environment. The computer system can also be implemented as or incorporated into various devices such as a personal computer PC a tablet PC an STB a personal digital assistant PDA a mobile device a palmtop computer a laptop computer a desktop computer a communications device a wireless telephone a land line telephone a control system a camera a scanner a facsimile machine a printer a pager a personal trusted device a web appliance a network router switch or bridge or any other machine capable of executing a set of instructions sequential or otherwise that specify actions to be taken by that machine. In a particular embodiment the computer system can be implemented using electronic devices that provide voice video or data communication. Further while a single computer system is illustrated the term system shall also be taken to include any collection of systems or sub systems that individually or jointly execute a set or multiple sets of instructions to perform one or more computer functions.

The computer system may include a processor such as a central processing unit CPU a graphics processing unit GPU or both. Moreover the computer system can include a main memory and a static memory that can communicate with each other via a bus . As shown the computer system may further include a video display unit such as a liquid crystal display LCD an organic light emitting diode OLED a flat panel display a solid state display or a cathode ray tube CRT . Additionally the computer system may include an input device such as a keyboard and a cursor control device such as a mouse. The computer system can also include a disk drive unit a signal generation device such as a speaker or remote control and a network interface device to communicate with a network . In a particular embodiment the disk drive unit may include a computer readable medium in which one or more sets of instructions such as software can be embedded. The computer readable medium can be a non transitory computer readable medium such as a hard disk drive a flash memory a read only memory a compact disk a digital versatile disk a cache a random access memory and the like. Further the instructions may embody one or more of the methods or logic as described herein. In a particular embodiment the instructions may reside completely or at least partially within the main memory the static memory and or within the processor during execution by the computer system . The main memory and the processor also may include computer readable media.

The illustrations of the embodiments described herein are intended to provide a general understanding of the structure of the various embodiments. The illustrations are not intended to serve as a complete description of all of the elements and features of apparatus and systems that utilize the structures or methods described herein. Many other embodiments may be apparent to those of skill in the art upon reviewing the disclosure. Other embodiments may be utilized and derived from the disclosure such that structural and logical substitutions and changes may be made without departing from the scope of the disclosure. Additionally the illustrations are merely representational and may not be drawn to scale. Certain proportions within the illustrations may be exaggerated while other proportions may be minimized. Accordingly the disclosure and the FIGs. are to be regarded as illustrative rather than restrictive.

The Abstract of the Disclosure is provided to comply with 37 C.F.R. 1.72 b and is submitted with the understanding that it will not be used to interpret or limit the scope or meaning of the claims. In addition in the foregoing Detailed Description of the Drawings various features may be grouped together or described in a single embodiment for the purpose of streamlining the disclosure. This disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim. Rather as the following claims reflect inventive subject matter may be directed to less than all of the features of any of the disclosed embodiments. Thus the following claims are incorporated into the Detailed Description of the Drawings with each claim standing on its own as defining separately claimed subject matter.

The above disclosed subject matter is to be considered illustrative and not restrictive and the appended claims are intended to cover all such modifications enhancements and other embodiments which fall within the true spirit and scope of the present disclosed subject matter. Thus to the maximum extent allowed by law the scope of the present disclosed subject matter is to be determined by the broadest permissible interpretation of the following claims and their equivalents and shall not be restricted or limited by the foregoing detailed description.

