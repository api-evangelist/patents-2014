---

title: Dynamic remapping of cache lines
abstract: A method of managing cache memory includes accessing a cache memory at a primary index that corresponds to an address specified in an access request. A determination is made that accessing the cache memory at the primary index does not result in a cache hit on a cache line with an error-free status. In response to this determination, the primary index is mapped to a secondary index and data for the address is written to a cache line at the secondary index.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09424195&OS=09424195&RS=09424195
owner: ADVANCED MICRO DEVICES, INC.
number: 09424195
owner_city: Sunnyvale
owner_country: US
publication_date: 20140415
---
This invention was made with Government support under Prime Contract Number DE AC52 07NA27344 Subcontract Number B600716 awarded by DOE. The Government has certain rights in this invention.

The present embodiments relate generally to cache memory and more specifically to error protection in cache memory.

Cache memories may be affected by both intermittent and permanent errors which affect the performance of the system and may limit the lifetime of the system. Also occurrence of errors may increase at low voltages such that operating a system at a low voltage to save power may reduce the reliability of the system. Accordingly there is a need for cache memory management techniques that provide error protection.

Embodiments are disclosed in which indices in a cache memory are remapped in response to errors in cache lines and or cache misses.

In some embodiments a method of managing cache memory includes accessing a cache memory at a primary index that corresponds to an address specified in an access request. A determination is made that accessing the cache memory at the primary index does not result in a cache hit on a cache line with an error free status. In response to this determination the primary index is mapped to a secondary index and data for the address is written to a cache line at the secondary index.

In some embodiments a cache controller includes a mapping module to map a primary index to a secondary index. The primary index corresponds to an address specified in an access request. The cache controller also includes a status indicator array to store status indicators for cache lines. The cache controller further includes cache control logic to write data for the address to a cache line at the secondary index in response to a determination that an access at the primary index does not result in a cache hit on a cache line with an error free status.

Reference will now be made in detail to various embodiments examples of which are illustrated in the accompanying drawings. In the following detailed description numerous specific details are set forth in order to provide a thorough understanding of the disclosure. However some embodiments may be practiced without these specific details. In other instances well known methods procedures components and circuits have not been described in detail so as not to unnecessarily obscure aspects of the embodiments.

A cache coherent interconnect couples the L2 cache memories or L2 caches for short on the processing modules to a level 3 L3 cache memory . The L3 cache includes L3 memory arrays to store information e.g. data and instructions cached in the L3 cache . Associated with the L3 cache is an L3 cache controller L3 Ctrl . The L1 caches and and L2 caches also include memory arrays and have associated cache controllers which are not shown in for simplicity. 

In the example of the L3 cache is the lowest level cache memory in the computing system and is therefore referred to as the lowest level cache or last level cache LLC . In other examples a computing system may include an LLC below the L3 cache . In some embodiments the L1 caches and L2 caches and L3 cache are implemented using static random access memory SRAM .

In addition to coupling the L2 caches to the L3 cache the cache coherent interconnect maintains cache coherency throughout the system . The cache coherent interconnect is also coupled to main memory through memory interfaces . In some embodiments the main memory is implemented using dynamic random access memory DRAM . In some embodiments the memory interfaces coupling the cache coherent interconnect to the main memory are double data rate DDR interfaces.

The cache coherent interconnect is also connected to input output I O interfaces which allow the cache coherent interconnect and through it the processing modules and main memory to be coupled to peripheral devices .

The L1 caches and L2 caches L3 cache and main memory form a memory hierarchy in the computing system . Each level of this hierarchy has less storage capacity but faster access time than the level below it the L1 caches and offer less storage but faster access than the L2 caches which offer less storage but faster access than the L3 cache which offers less storage but faster access than the main memory .

A respective level of cache memory in the computing system may be inclusive or non inclusive with respective to another level of cache memory e.g. an adjacent level of cache memory in the computing system . When a first level of cache memory is inclusive with respect to a second level a cache line in the first level is guaranteed to also be in the second level. When a first level of cache memory is non inclusive with respect to a second level a cache line in the first level is not guaranteed to also be in the second level. One example of non inclusive cache memory is exclusive cache memory. When a first level of cache memory is exclusive with respect to a second level a cache line in the first level is guaranteed not to be in the second level. For example if an L2 cache is inclusive with respect to the L3 cache a cache line in the L2 cache is guaranteed to also be in the L3 cache . If an L2 cache is non inclusive with respect to the L3 cache a cache line in the L2 cache is not guaranteed to also be in the L3 cache . If an L2 cache is exclusive with respect to the L3 cache a cache line in the L2 cache is guaranteed not to be in the L3 cache .

The computing system may also include tables and or buffers implemented as cache memories. For example a translation look aside buffer TLB and or a row table in the cache coherent interconnect may each be implemented as a cache memory. The TLB is used to translate virtual addresses to physical addresses. The row table is used to track open rows in the main memory . Other examples of structures that may be implemented as cache memories in a system such as the computing system include but are not limited to branch target buffers BTBs and predictor tables e.g. indirect branch predictor tables conditional branch prediction tables memory dependence predictor tables local address predictor tables value predictor tables etc. .

The computing system is merely an example of a computing system with cache memory other configurations are possible. For example the number of processor cores per processing module may vary as may the number of processing modules . More than two processor cores may share an L2 cache or each processor core and may have its own L2 cache . Other examples are possible.

The cache data array is divided into sets of cache lines in which data is stored. The sets are indexed by indices determined based on addresses for data cached in respective cache lines . The indices are determined by applying a hashing function to the addresses i.e. by hashing the addresses . Indices determined in this manner are referred to herein as primary indices. For example addresses for data cached in respective cache lines in the cache data array are divided into multiple address portions including an index i.e. a primary index and a tag. A cache line may correspond to a plurality of addresses that share common index and tag portions. Extracting the index from the address is an example of applying a hashing function to the address. In this example cache lines are installed in the cache data array at locations indexed by the index portions of the addresses. Tags are stored in the cache tag array at locations indexed by the index portions of the addresses. These addresses are typically physical addresses but in some embodiments may be virtual addresses. In some embodiments e.g. in accordance with the method only one copy of a given tag is stored at a particular index in the cache tag array .

To perform a memory access operation in the cache memory a memory access request is provided to the cache controller e.g. from a processor core or or from a higher level of cache memory in the computing system . The memory access request specifies an address. If a tag stored at a location in the cache tag array indexed by the index corresponding to the address i.e. the primary index matches the tag portion of the address and if a remapping bit has an appropriate value as described below then a cache hit occurs. Otherwise a cache miss occurs. For a read request that results in a cache hit the cache line at a corresponding location in the cache data array is returned in response to the request. For a write request that results in a cache hit the cache line at the corresponding location in the cache data array is modified.

The cache data array may store multiple copies of a cache line . A primary copy may be stored at a primary index which is determined based on an address or addresses of data stored in the cache line . The primary index may be mapped to a secondary index at which a secondary copy of the cache line is stored. This mapping may be performed using a hashing function which may be distinct from the hashing function used to determine the primary index based on the address. The secondary index may be accessed for example if an error is detected in the primary cache line . If an access at a secondary index results in a tag match and if a remapping bit has an appropriate value as described below then a cache hit occurs. Otherwise a cache miss occurs. Examples of accessing the secondary index are described below with respect to the method .

The cache data array and thus the cache memory is set associative for each index it includes a set of n locations at which a particular cache line may be installed where n is an integer greater than one. The cache data array is thus divided into n ways numbered 0 to n 1 each location in a given set is situated in a distinct way. Examples of n include but are not limited to eight and 16 i.e. eight ways and 16 ways respectively . The cache data array includes m sets numbered 0 to m 1 where m is an integer greater than one. The cache tag array is similarly divided into sets and ways. A cache hit resulting from a tag match in a particular way at a specified index in the cache tag array indicates that the cache line in the particular way at the specified index in the cache data array is the cache line to be accessed.

Storing multiple copies of cache lines at distinct indices in the cache reduces the associativity of the cache memory but improves the reliability of the cache memory .

A primary copy of a new cache line to be installed in the cache data array may be installed in any way of the set specified by the primary index. Similarly a secondary copy of a new cache line to be installed in the cache data array may be installed in any way of the set specified by the secondary index. If all of the ways in the specified set already have valid cache lines then a cache line may be either evicted or dropped from one of the ways and the respective copy of the new cache line installed in its place. The cache line to be evicted or dropped which is referred to as the victim cache line may be selected based on a replacement policy. Examples of replacement policies include but are not limited to least recently used LRU and least frequently used LFU . Evicted cache lines are written back to a lower level of memory while dropped cache lines are simply replaced with the new cache line . If write back is to be performed e.g. because the evicted cache line is modified or because the cache memory is exclusive with respect to a lower level cache memory the victim cache line is placed in a victim buffer from where it is written back to a lower level cache memory or to main memory in the computing system .

In some embodiments an error protection module is coupled to the cache data array to detect and or correct errors in cache lines read from the cache data array . For example the error protection module performs parity based error detection of single bit errors using parity bits stored in the cache lines . In other examples the error protection module uses error correction coding ECC to detect and correct errors in cache lines . Examples of ECC include but are not limited to SECDED single error correction double error detection coding which corrects single bit errors and detects double bit errors and DECTED double error correction triple error detection which corrects up to double bit errors and detects triple bit errors. In some embodiments the error protection module is omitted.

The cache controller includes cache control logic which includes replacement logic a mapping module and verification logic . The replacement logic implements a replacement policy for selecting cache lines in respective sets to be evicted or dropped. The mapping module implements the mapping function e.g. a hashing function which may be distinct from the hashing function used to determine primary indices based on addresses that maps primary indices to secondary indices. In some embodiments the mapping function is reversible such that it provides reverse mapping if the mapping function is applied to a first index to produce a second index then applying the mapping function to the second index produces the first index for all indices. The verification logic allows for verification of data written to cache lines . Data written to a cache line may be read back e.g. as part of the process of writing the data and compared to the original data e.g. as fetched from a lower level of memory . The verification logic may include a buffer to store the original data and a comparator to compare the data as read from the cache line to the original data. The verification logic thus may detect any number of errors in the data as read from the cache line in accordance with some embodiments.

The cache controller also includes a status array that stores status information for the cache lines in the cache data array . Each entry in the status array corresponds to a distinct cache line . The entries are indexed for example by set and way. shows an example of an entry in the status array . Each entry includes a field that stores a remapping bit RM . The remapping bit indicates whether the cache line corresponding to the entry is a primary copy or a secondary copy. For example the cache line is a primary copy if RM 0 and a secondary copy if RM 1. This convention which is used throughout herein may be reversed. On an access to a primary index a cache miss occurs if there is no tag match or if a tag match occurs for a cache line with RM 1. A cache hit occurs if there is a tag match for a cache line with RM 0. On an access to a secondary index a cache miss occurs if there is no tag match or if a tag match occurs for a cache line with RM 0. A cache hit occurs if there is a tag match for a cache line with RM 1.

Each entry also includes a field that stores a pair of validity bits VV . The pair of validity bits serves as a status indicator that indicates whether or not the cache line corresponding to the entry is valid and also indicates an error status of the cache line . For example the cache line is valid and error free if VV 11 is valid with a first error status if VV 01 is valid with a second error status if VV 10 and is invalid and thus effectively empty if VV 00. This convention which is used throughout herein is arbitrary and may vary between different embodiments. The first error status is a transient error status that is assigned between detection of an error and the writing of correct data while the second error status is a hard error status assigned in response to a failed attempt to write correct data. Examples of setting the value of VV are provided below with respect to the method . In some embodiments each entry also includes a field that stores a parity bit for the entry . The parity bit provides error protection for RM and VV.

In the method an access request is received that specifies an address. In some embodiments the access request is a demand request e.g. as opposed to a request generated by a prefetcher . The access request may be a read request or a write request.

A primary index that corresponds to the address is accessed . If a tag match occurs Yes the method branches to operation described below . If a tag match does not occur No then a victim cache line is picked and thus selected at the primary index. This victim cache line is referred to as the primary victim.

The status of the primary victim e.g. as specified in the entry of the primary victim is checked . This status check includes checking the RM value and or the VV value. In some embodiments this status check also includes performing error detection e.g. using the error protection module to determine whether the primary victim includes an error e.g. an uncorrectable error . If VV 11 indicating that the primary victim is valid and error free and in some embodiments if no error is detected e.g. by the error protection module then the primary victim is either evicted or dropped . Furthermore if RM 1 indicating that the primary victim is a secondary copy of another cache line then one of two policy options may be implemented. In some embodiments error free secondary copies e.g. RM 1 VV 11 are replaced in the cache memory without replacing faulty primary copies e.g. RM 0 VV 10 . This policy is referred to as Policy 1. Alternatively faulty primary copies are invalidated when an error free secondary copy is evicted or dropped. This policy is referred to as Policy 2. Therefore if the primary victim is a secondary copy as indicated by RM 1 and if Policy 2 is used Yes then the primary copy of the primary victim is evicted or dropped . Furthermore when a faulty primary copy e.g. RM 0 VV 10 is evicted or dropped its valid and error free secondary copy e.g. RM 1 VV 11 is invalidated to maintain coherence in accordance with some embodiments. If the primary victim is a secondary copy as indicated by RM 1 and if Policy 1 is used No then the primary copy of the primary victim is left intact. In either case the method then proceeds to operation described below . Likewise if VV 11 and in some embodiments no uncorrectable error is detected and RM 0 No then the method proceeds to operation described below .

If RM 0 and VV 00 indicating that the primary victim is invalid and thus empty then the method then branches to operation described below .

If checking the status of the primary victim reveals that RM 0 and VV 10 indicating that the primary victim is a primary copy that contains an error or if RM 0 and an error e.g. an uncorrectable error is found by the error protection module then one of two paths result. In some embodiments the primary victim is dropped Yes . The status e.g. in the entry of the primary victim is set to RM 0 in preparation for writing the data requested by the access request and VV 01. Alternatively the primary victim is not dropped No . Instead it is determined whether correct data is available in the secondary copy of the primary victim. If the correct data is available Yes then the secondary copy of the primary victim is evicted . The status of the primary victim is set to RM 0 and VV 01. If the correct data is not available No then an error message is generated and sent for logging. For example the error message is sent to a machine check architecture MCA which logs the error and may raise an exception in response to the error.

After the status of the primary victim is set to RM 0 and VV 01 data for the address specified in the access request of operation is fetched from a lower level of memory. Once fetched the data is written to the primary victim a cache line storing the data is installed at the location of the primary victim as opposed to the primary victim being modified . The VV value for the primary victim thus equals 01 while the data is fetched. Cache lines for which VV 01 are excluded from consideration for being dropped or evicted. Setting VV 01 for the primary victim therefore effectively reserves the primary victim for the data while the data is fetched which takes numerous clock cycles e.g. hundreds of cycles .

The data written to the primary victim is verified . For example the data written to the primary victim is read back and the verification logic compares it to the fetched data. Alternatively the error protection module verifies the data as written to the primary victim and notifies the cache control logic of the result. Operation may be triggered by detecting that VV 01 for the newly installed cache line .

In some embodiments the verification of operation is performed if VV for the primary victim equals 10 before the operation but not if VV for the primary victim equals 00 before the operation . The verification of operation therefore may be selectively performed based on the error status of the primary victim.

If the data is verified to be correct Yes then the status e.g. in the entry for the primary victim is updated to set RM 0 and VV 11 thus indicating that this cache line is a primary copy that is valid and error free. The data is returned in response to the access request of operation and the method ends.

If one or more errors are found the data is determined to be incorrect No . In this case the status e.g. in the entry for the primary victim is updated to set RM 0 and VV 10 thus indicating that this cache line is a primary copy with the second error status. The mapping module maps the primary index is to a secondary index. The secondary index is accessed .

If the access at the secondary index results in a tag match Yes then the status e.g. in the entry of the matching cache line at the secondary index is checked . The value of RM for the matching cache line is expected to be 0 because the replacement logic invalidates secondary copies when their primary copies are dropped or evicted. A cache line with RM 1 that would have produced a tag match in response to the access of operation therefore would already have been invalidated. Accordingly in some embodiments only the value of VV is checked . If VV 11 or 10 then the matching cache line is selected as a victim cache line at the secondary index i.e. as a secondary victim . If VV 01 however then the matching cache line is not selected as the secondary victim because the replacement logic excludes cache lines with VV 01 from victimization. In this case the secondary access may be dropped and the method ends. An error message may be generated and sent to the MCA indicating that the access request failed.

If the access at the secondary index does not result in a tag match No then the replacement logic selects a secondary victim.

The status of the secondary victim is checked . If RM 0 and VV 00 indicating that the secondary victim is invalid and thus empty then the status e.g. in the entry of the secondary victim is updated to set RM 1 and VV 01. Assuming data for the address specified in the access request of operation can be fetched Yes the data is fetched and written to the secondary victim i.e. to the cache line at the location of the secondary victim . In some embodiments this data is buffered in the cache controller since it already has been fetched from a lower level of memory in the operation . Accordingly the operation may involve fetching the data from a buffer in the cache controller instead of from a lower level of memory. If data for the address specified in the access request of operation cannot be fetched No then an error message is generated and sent e.g. to the MCA .

If VV 10 or 11 for the secondary victim as determined in the operation then the secondary victim may or may not be dropped . If the secondary victim is dropped Yes then the method proceeds to the operation described above . If the secondary victim is not dropped No then it is determined whether correct data is available in the secondary copy of the secondary victim. If correct data is available in the secondary copy of the secondary victim Yes then the secondary copy of the secondary victim is evicted . The status e.g. in the entry of the secondary victim is updated to set RM 1 and VV 01. It is determined whether data for the address can be fetched from a lower level of memory. If so Yes the data is fetched and written to the secondary victim and the method proceeds to operation below . If data cannot be fetched however No then an error message is generated and sent for logging e.g. to the MCA which may raise an exception in response and the method ends. If correct data is not available in the secondary copy of the secondary victim No then an error message is generated and sent e.g. to the MCA .

After the operation the data written to the secondary victim is verified e.g. by the verification logic or the error protection module . If one or more errors are found the data is determined to be incorrect No . In some embodiments this determination results in the status e.g. in the entry of the cache line at the location of the secondary victim being updated to set RM 0 and VV 00. The fetched data is returned in response to the access request of operation without having been stored correctly in the cache memory .

If no errors are found in the data as written to the secondary victim Yes then the status e.g. in the entry of the secondary victim is updated to set RM 1 and VV 11 indicating that this cache line now stores an error free secondary copy of the fetched data. The secondary victim therefore is no longer considered a victim at this point a new cache line storing the fetched data is installed at the location of the secondary victim. The data is returned in response to the access request of operation and the method ends.

If accessing the primary index results in a tag match Yes then the RM value of the matching cache line is checked and the status of the matching cache line is checked or . In the specific examples of operations and the RM value is considered to be separate from the status but in other contexts the status may include the RM value. If RM 1 then the tag match is not a cache hit because the matching cache line is a secondary copy of another cache line that happens to have the same tag as the address specified in the access request of operation . This situation is referred to as aliasing. If RM 1 and VV 11 then the matching cache line is selected as the primary victim and the method branches to operation . If RM 1 and VV 01 then the matching cache line is excluded from selection as the primary victim. Instead an error message is generated and sent for logging e.g. to the MCA and the method ends.

If RM 0 the tag match indicates a cache hit. If RM 0 VV 11 and the error protection module does not find an uncorrectable error in the matching cache line then the data in the matching cache line is returned in response to the access request of operation and the method ends. If RM 0 and VV 10 then the mapping module maps the primary index to a secondary index as described for operation . The secondary index is accessed . If RM 0 VV 11 and the error protection module finds an uncorrectable error in the matching cache line then the method branches to operation .

In the operation it is determined whether data for the address specified in the access request of operation can fetched from a lower level of memory. If data cannot be fetched No an error message is generated and sent for logging e.g. to the MCA . If data can be fetched Yes the data is fetched and written to the matching cache line . The written data is verified e.g. using the verification logic . If the data as written is determined to be correct Yes then the data is returned in response to the access request of operation and the method ends. If the data as written is determined to be incorrect No then the status e.g. in the entry of the matching cache line is set to RM 0 and VV 10. The fetched data is returned in response to the access request of operation and the method proceeds to operation followed by operation .

If accessing the secondary index does not result in a tag match No then the method branches to operation a secondary victim is selected and the method proceeds as previously described.

If accessing the secondary index results in a tag match Yes then it is determined whether the matching cache line has one or more errors e.g. one or more uncorrectable errors . This determination is made for example by the error protection module . If no errors are found No then the status e.g. in the entry of the matching cache line is checked . If RM 1 and VV 11 then a cache hit has occurred and the data in the matching cache line is returned in response to the access request of operation . If RM 0 for Policy 1 then a cache miss has occurred the matching cache line is a primary copy that happens to have the same tag as the address specified in the access request i.e. aliasing has occurred . Note that for Policy 2 a tag match will not occur at the secondary index for a cache line with RM 0 because such a cache line would be a primary copy that would have already been evicted. When RM 0 the matching cache line is selected as a secondary victim and the method branches to operation .

When data is returned in response to accessing the secondary index the data may be written e.g. simultaneously with being returned to the appropriate cache line i.e. the primary copy at the primary index. The data written to the primary copy may be verified using the verification logic the data is read from the primary copy and compared to the data returned from the secondary copy in operation . If the data written to the primary copy is determined to be error free then the primary copy is set to an error free status e.g. VV 11 and the secondary copy is invalidated e.g. VV 00 . The data in the secondary copy need not be evicted if it is modified because it has just been written to the primary copy.

If accessing the secondary index results in a tag match Yes and one or more errors e.g. one or more uncorrectable errors are found Yes in the matching cache line then it is determined whether data for the address specified in the access request of operation can be fetched from a lower level of memory. If not No an error message is generated and sent e.g. to the MCA . If the data can be fetched Yes however then the data is fetched and written to the matching cache line . The written data is verified e.g. using the verification logic or error protection module . If the written data is determined to be correct Yes then the data is returned in response to the access request of operation and the method ends. If the written data is not correct No then the fetched data is returned in response to the access request of operation and the status e.g. in the entry of the matching cache line at the secondary index is updated to set RM 0 and VV 00 thus invalidating the matching cache line at the secondary index. If Policy 1 is being used Policy 1 the method then ends . If Policy 2 is being used Policy 2 the primary copy i.e. at the primary index of the matching cache line at the secondary index is invalidated e.g. by setting RM 0 VV 00 and the method ends.

The method provides run time error protection e.g. multi bit error protection against both intermittent and permanent errors. Also by allowing faulty cache lines e.g. cache lines with VV 10 to be selected as victims the method allows for reuse of cache lines with intermittent errors or errors that are deactivated such that the errors do not affect function power or performance. Furthermore by using different indices as opposed to the same index for primary and secondary copies the method may reduce instructions per cycle IPC variation. In addition the method may be implemented in a cache memory that lacks parity or ECC protection e.g. that lacks an error protection module in accordance with some embodiments.

In some embodiments the method is performed in a cache memory that is unprotected e.g. that lacks an error protection module but that verifies data by computing the correct data and comparing it to the data stored in a respective cache line . Examples of such a cache memory include but are not limited to the branch target buffer and various predictor tables. Such buffers and tables store predictions e.g. predicted target addresses . The cache memory is read each time a prediction is made and written each time a prediction is found to be incorrect to correct the prediction. Data verification operations include computing correct data e.g. a correct target address and comparing the correct data to the prediction as read from the cache memory. If the data stored in the cache is found to be correct its status is set to be error free e.g. VV 11 . Also the verification logic may be used to verify write operations that are performed to correct mispredictions.

While the method includes a number of operations that appear to occur in a specific order it should be apparent that the method can include more or fewer operations. An order of two or more operations may be changed performance of two or more operations may overlap and two or more operations may be combined into a single operation.

The foregoing description for purpose of explanation has been described with reference to specific embodiments. However the illustrative discussions above are not intended to be exhaustive or to limit all embodiments to the precise forms disclosed. Many modifications and variations are possible in view of the above teachings. The disclosed embodiments were chosen and described to best explain the underlying principles and their practical applications to thereby enable others skilled in the art to best implement various embodiments with various modifications as are suited to the particular use contemplated.

