---

title: Control of large screen display using wireless portable computer and facilitating selection of audio on a headphone
abstract: A multi-window user interface (UI) on a control device such as a tablet computer communicates commands to a display controller, which may be implemented by a game console. The controller controls presentation on a large screen display according to the commands. A tertiary device such as a wireless phone can obtain an application listing audio feeds associated with various videos presented on the display so that a user can listen via headphones to a first audio stream associated with a first video window on the display when the display speakers are playing audio associated with a second video window on the display.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09348495&OS=09348495&RS=09348495
owner: Sony Corporation
number: 09348495
owner_city: Tokyo
owner_country: JP
publication_date: 20140506
---
The application relates generally to controlling a large screen display using a wireless portable computer such as a tablet or laptop computer interfacing with a display controller such as a game console.

A computer ecosystem or digital ecosystem is an adaptive and distributed socio technical system that is characterized by its sustainability self organization and scalability. Inspired by environmental ecosystems which consist of biotic and abiotic components that interact through nutrient cycles and energy flows complete computer ecosystems consist of hardware software and services that in some cases may be provided by one company such as Sony. The goal of each computer ecosystem is to provide consumers with everything that may be desired at least in part services and or software that may be exchanged via the Internet. Moreover interconnectedness and sharing among elements of an ecosystem such as applications within a computing cloud provides consumers with increased capability to organize and access data and presents itself as the future characteristic of efficient integrative ecosystems.

Two general types of computer ecosystems exist vertical and horizontal computer ecosystems. In the vertical approach virtually all aspects of the ecosystem are owned and controlled by one company and are specifically designed to seamlessly interact with one another. Horizontal ecosystems one the other hand integrate aspects such as hardware and software that are created by other entities into one unified ecosystem. The horizontal approach allows for greater variety of input from consumers and manufactures increasing the capacity for novel innovations and adaptations to changing demands.

An example ecosystem that is pertinent here is an entertainment ecosystem in the home or in a luxury suite at a stadium that includes a large screen high definition display controlled by a controller such as a personal computer PC or game console which receives commands from a portable control device such as a tablet computer.

Accordingly a monitoring device includes at least one computer readable storage medium bearing instructions executable by a processor and at least one processor configured for accessing the computer readable storage medium to execute the instructions to configure the processor for receiving at least one software application executable by the processor. The instructions when executed by the processor configure the processor for executing the application to present on the monitoring device a list of plural audio feeds with each audio feed corresponding to a respective video content being simultaneously provided to a display device separate from the monitoring device. In this way the display device can simultaneously present at least first and second video contents on a display thereof but play only first audio associated with only the first video content. The instructions when executed by the processor configure the processor for receiving selection of an audio feed from the list and responsive to the selection playing the audio feed on the monitoring device.

In some examples the selection is such that a user of the monitoring device can view the display device and listen to the second audio on the monitoring device while viewing the second video content on the display device with the display device playing the first audio. The playing of the audio feed may be executed by playing the audio feed on headphones. The monitoring device may be established by a wireless telephone.

In examples the processor when executing the instructions is configured for receiving the software application by imaging a bar code disposed on or near the display device and correlating the bar code to a network address at which the software application is available. The processor when executing the instructions may be configured for playing the audio feed on the monitoring device responsive to downloading the audio feed from a computer network.

In another aspect a system includes a display device configured for presenting plural video contents in respective windows of the display device and for playing first audio associated with a first one of the video contents. The system includes a controller configured for controlling the display device and a control device configured for communicating commands to the controller to control presentation on the display device. A monitoring device is configured for playing second audio associated with a second one of the video contents on the display device while the display device plays the first audio and presents the first and second video contents simultaneously.

In another aspect a method includes providing plural video contents to a display device for simultaneous presentation thereof on the display device. The method includes providing plural audio streams to the display device for presentation of a user selected one of the audio streams on the display device the audio streams corresponding to respective ones of the video contents. Also the method includes providing a list of the audio streams to a monitoring device for selection of one of the audio streams for play on the monitoring device such that a user of the monitoring device can view the display device and listen to a first audio stream on the monitoring device while viewing a respective first video content on the display device with the display device playing a second audio stream associated with a second video content.

The details of the present invention both as to its structure and operation can be best understood in reference to the accompanying drawings in which like reference numerals refer to like parts and in which 

This disclosure relates generally to computer ecosystems including aspects of consumer electronics CE device based user information in computer ecosystems. A system herein may include server and client components connected over a network such that data may be exchanged between the client and server components. The client components may include one or more computing devices including portable televisions e.g. smart TVs Internet enabled TVs portable computers such as laptops and tablet computers and other mobile devices including smart phones and additional examples discussed below. These client devices may operate with a variety of operating environments. For example some of the client computers may employ as examples operating systems from Microsoft or a Unix operating system or operating systems produced by Apple Computer or Google. These operating environments may be used to execute one or more browsing programs such as a browser made by Microsoft or Google or Mozilla or other browser program that can access web applications hosted by the Internet servers discussed below.

Servers may include one or more processors executing instructions that configure the servers to receive and transmit data over a network such as the Internet. Or a client and server can be connected over a local intranet or a virtual private network. A server or controller may be instantiated by a game console such as a Sony Playstation trademarked a personal computer etc.

Information may be exchanged over a network between the clients and servers. To this end and for security servers and or clients can include firewalls load balancers temporary storages and proxies and other network infrastructure for reliability and security. One or more servers may form an apparatus that implement methods of providing a secure community such as an online social website to network members.

As used herein instructions refer to computer implemented steps for processing information in the system. Instructions can be implemented in software firmware or hardware and include any type of programmed step undertaken by components of the system.

A processor may be any conventional general purpose single or multi chip processor that can execute logic by means of various lines such as address lines data lines and control lines and registers and shift registers.

Software modules described by way of the flow charts and user interfaces herein can include various sub routines procedures etc. Without limiting the disclosure logic stated to be executed by a particular module can be redistributed to other software modules and or combined together in a single module and or made available in a shareable library.

Present principles described herein can be implemented as hardware software firmware or combinations thereof hence illustrative components blocks modules circuits and steps are set forth in terms of their functionality.

Further to what has been alluded to above logical blocks modules and circuits described below can be implemented or performed with a general purpose processor a digital signal processor DSP a field programmable gate array FPGA or other programmable logic device such as an application specific integrated circuit ASIC discrete gate or transistor logic discrete hardware components or any combination thereof designed to perform the functions described herein. A processor can be implemented by a controller or state machine or a combination of computing devices.

The functions and methods described below when implemented in software can be written in an appropriate language such as but not limited to C or C and can be stored on or transmitted through a computer readable storage medium such as a random access memory RAM read only memory ROM electrically erasable programmable read only memory EEPROM compact disk read only memory CD ROM or other optical disk storage such as digital versatile disc DVD magnetic disk storage or other magnetic storage devices including removable thumb drives etc. A connection may establish a computer readable medium. Such connections can include as examples hard wired cables including fiber optics and coaxial wires and digital subscriber line DSL and twisted pair wires. Such connections may include wireless communication connections including infrared and radio.

Components included in one embodiment can be used in other embodiments in any appropriate combination. For example any of the various components described herein and or depicted in the Figures may be combined interchanged or excluded from other embodiments.

 A system having at least one of A B and C likewise a system having at least one of A B or C and a system having at least one of A B C includes systems that have A alone B alone C alone A and B together A and C together B and C together and or A B and C together etc.

Now specifically referring to an example ecosystem is shown which may include one or more of the example devices mentioned above and described further below in accordance with present principles. The first of the example devices included in the system is an example primary display device and in the embodiment shown is an audio video display device AVDD such as but not limited to an Internet enabled TV. Thus the AVDD alternatively may be an appliance or household item e.g. computerized Internet enabled refrigerator washer or dryer. The AVDD alternatively may also be a computerized Internet enabled smart telephone a tablet computer a notebook computer a wearable computerized device such as e.g. computerized Internet enabled watch a computerized Internet enabled bracelet other computerized Internet enabled devices a computerized Internet enabled music player computerized Internet enabled head phones a computerized Internet enabled implantable device such as an implantable skin device etc. Regardless it is to be understood that the AVDD is configured to undertake present principles e.g. communicate with other CE devices to undertake present principles execute the logic described herein and perform any other functions and or operations described herein .

Accordingly to undertake such principles the AVDD can be established by some or all of the components shown in . For example the AVDD can include one or more displays that may be implemented by a high definition or ultra high definition 4K flat screen and that may be touch enabled for receiving user input signals via touches on the display. The AVDD may include one or more speakers for outputting audio in accordance with present principles and at least one additional input device such as e.g. an audio receiver microphone for e.g. entering audible commands to the AVDD to control the AVDD . The example AVDD may also include one or more network interfaces for communication over at least one network such as the Internet an WAN an LAN etc. under control of one or more processors . Thus the interface may be without limitation a Wi Fi transceiver which is an example of a wireless computer network interface. It is to be understood that the processor controls the AVDD to undertake present principles including the other elements of the AVDD described herein such as e.g. controlling the display to present images thereon and receiving input therefrom. Furthermore note the network interface may be e.g. a wired or wireless modem or router or other appropriate interface such as e.g. a wireless telephony transceiver or Wi Fi transceiver as mentioned above etc.

In addition to the foregoing the AVDD may also include one or more input ports such as e.g. a USB port to physically connect e.g. using a wired connection to another CE device and or a headphone port to connect headphones to the AVDD for presentation of audio from the AVDD to a user through the headphones. The AVDD may further include one or more tangible computer readable storage medium such as disk based or solid state storage. Also in some embodiments the AVDD can include a position or location receiver such as but not limited to a cellphone receiver GPS receiver and or altimeter that is configured to e.g. receive geographic position information from at least one satellite or cellphone tower and provide the information to the processor and or determine an altitude at which the AVDD is disposed in conjunction with the processor . However it is to be understood that that another suitable position receiver other than a cellphone receiver GPS receiver and or altimeter may be used in accordance with present principles to e.g. determine the location of the AVDD in e.g. all three dimensions.

Continuing the description of the AVDD in some embodiments the AVDD may include one or more cameras that may be e.g. a thermal imaging camera a digital camera such as a webcam and or a camera integrated into the AVDD and controllable by the processor to gather pictures images and or video in accordance with present principles. Also included on the AVDD may be a Bluetooth transceiver and other Near Field Communication NFC element for communication with other devices using Bluetooth and or NFC technology respectively. An example NFC element can be a radio frequency identification RFID element.

Further still the AVDD may include one or more auxiliary sensors e.g. a motion sensor such as an accelerometer gyroscope cyclometer or a magnetic sensor an infrared IR sensor an optical sensor a speed and or cadence sensor a gesture sensor e.g. for sensing gesture command etc. providing input to the processor . The AVDD may include still other sensors such as e.g. one or more climate sensors e.g. barometers humidity sensors wind sensors light sensors temperature sensors etc. and or one or more biometric sensors providing input to the processor . In addition to the foregoing it is noted that the AVDD may also include an infrared IR transmitter and or IR receiver and or IR transceiver such as an IR data association IRDA device. A battery not shown may be provided for powering the AVDD .

Still referring to in addition to the AVDD the system may include one or more other CE device types. In one example a first CE device may be used to control the display via commands sent through the below described server while a second CE device may include similar components as the first CE device and hence will not be discussed in detail. In the example shown only two CE devices are shown it being understood that fewer or greater devices may be used.

In the example shown to illustrate present principles all three devices are assumed to be members of an entertainment network in e.g. a luxury suite of the stadium or in a home or at least to be present in proximity to each other in a location such as a house. However for illustrating present principles the first CE device is assumed to be in the same room as the AVDD bounded by walls illustrated by dashed lines .

The example non limiting first CE device may be established by any one of the above mentioned devices for example a portable wireless laptop computer or notebook computer and accordingly may have one or more of the components described below. The second CE device without limitation may be established by a wireless telephone.

The first CE device may include one or more displays that may be touch enabled for receiving user input signals via touches on the display. The first CE device may include one or more speakers for outputting audio in accordance with present principles and at least one additional input device such as e.g. an audio receiver microphone for e.g. entering audible commands to the first CE device to control the device . The example first CE device may also include one or more network interfaces for communication over the network under control of one or more CE device processors . Thus the interface may be without limitation a Wi Fi transceiver which is an example of a wireless computer network interface. It is to be understood that the processor controls the first CE device to undertake present principles including the other elements of the first CE device described herein such as e.g. controlling the display to present images thereon and receiving input therefrom. Furthermore note the network interface may be e.g. a wired or wireless modem or router or other appropriate interface such as e.g. a wireless telephony transceiver or Wi Fi transceiver as mentioned above etc.

In addition to the foregoing the first CE device may also include one or more input ports such as e.g. a USB port to physically connect e.g. using a wired connection to another CE device and or a headphone port to connect headphones to the first CE device for presentation of audio from the first CE device to a user through the headphones. The first CE device may further include one or more tangible computer readable storage medium such as disk based or solid state storage. Also in some embodiments the first CE device can include a position or location receiver such as but not limited to a cellphone and or GPS receiver and or altimeter that is configured to e.g. receive geographic position information from at least one satellite and or cell tower using triangulation and provide the information to the CE device processor and or determine an altitude at which the first CE device is disposed in conjunction with the CE device processor . However it is to be understood that that another suitable position receiver other than a cellphone and or GPS receiver and or altimeter may be used in accordance with present principles to e.g. determine the location of the first CE device in e.g. all three dimensions.

Continuing the description of the first CE device in some embodiments the first CE device may include one or more cameras that may be e.g. a thermal imaging camera a digital camera such as a webcam and or a camera integrated into the first CE device and controllable by the CE device processor to gather pictures images and or video in accordance with present principles. Also included on the first CE device may be a Bluetooth transceiver and other Near Field Communication NFC element for communication with other devices using Bluetooth and or NFC technology respectively. An example NFC element can be a radio frequency identification RFID element.

Further still the first CE device may include one or more auxiliary sensors e.g. a motion sensor such as an accelerometer gyroscope cyclometer or a magnetic sensor an infrared IR sensor an optical sensor a speed and or cadence sensor a gesture sensor e.g. for sensing gesture command etc. providing input to the CE device processor . The first CE device may include still other sensors such as e.g. one or more climate sensors e.g. barometers humidity sensors wind sensors light sensors temperature sensors etc. and or one or more biometric sensors providing input to the CE device processor . In addition to the foregoing it is noted that in some embodiments the first CE device may also include an infrared IR transmitter and or IR receiver and or IR transceiver such as an IR data association IRDA device. A battery not shown may be provided for powering the first CE device .

Now in reference to the afore mentioned at least one server it includes at least one server processor at least one tangible computer readable storage medium such as disk based or solid state storage and at least one network interface that under control of the server processor allows for communication with the other devices of over the network and indeed may facilitate communication between servers and client devices in accordance with present principles. Note that the network interface may be e.g. a wired or wireless modem or router Wi Fi transceiver or other appropriate interface such as e.g. a wireless telephony transceiver.

Accordingly in some embodiments the server may be an Internet server and may include and perform cloud functions such that the devices of the system may access a cloud environment via the server in example embodiments. Or the server may be implemented by a game console or other computer in the same room as the other devices shown in or nearby.

The control devices may be without limitation portable computers such as tablet computers or laptop computers also including notebook computers or other devices with one or more of the CE device components shown in . The displays may be monitors only and or may include one or more of the primary display components shown in . The controller may be a personal computer PC or game console or server that contains one or more of the components variously shown in . In the non limiting example shown the control devices communicate directly with the controller using e.g. WiFi or Bluetooth the control devices do not communicate directly with the displays . Instead the controller communicates with the displays to establish presentation thereon in accordance with commands received from the control devices. It is to be understood that while the controller is shown physically separate from the displays in it may be incorporated within the chassis of a display. As also shown the displays may present plural contents in respective content windows .

The controller may receive video from plural video cameras . In the stadium context a first camera may image a first half of a sports field racetrack or other action venue whereas as second camera may image the other half of the action venue with the feeds from the two cameras being combined before being sent to the controller or combined by the controller and stitched to present a single video view of both halves of the action venue on one or both of the displays . That is the combined feed from both cameras may be presented on a single display in an 8K mode or the combined feed may be spread across the juxtaposed displays such that one display shows one half of the action venue and the other display shows the other half. It will be appreciated that the feeds sent to the controller preferably are HD or more preferably UHD.

As well the cameras through appropriate image processing down resolution components can present the same video feeds albeit at a lower resolution to the control devices . The UHD feeds may be sent to the controller over a network from a network address while the lower resolution feeds of the same content may be simultaneously sent to the control devices over the network from the same or a different network address such that the video content on the control devices is the same as the video content presentable on the displays albeit typically of a lower resolution.

Note that a dedicated local server or PS4 may not be required in some embodiments to manage the 4K and thumbnail feeds as well as analyze the commands coming from the tablet. Instead this can happen in the cloud with the 4K TV and tablet having their own MAC address and the cloud server acting as though it were local to permit control of 4K monitors in remote locations as well.

A location sensing system such as any of those described above may be used to determine where the control device is relative multiple 4K display locations to allow the user to roam and have the 4K content follow him. This provides for multiple 4K clusters in a stadium suite each showing the same or different content. In this case what is showing on a particular 4K TV cluster can drive the UI on the tablet or the other way around.

Additionally each camera typically is associated with one or more microphones for capturing audio associated with the video to establish respective audio video AV streams. As more fully described below in reference to the audio from the AV streams as well as other audio may be separately provided to a tertiary monitoring device such as a headphone equipped wireless phone to enable a user of the monitoring device to monitor any audio associated with any of the videos shown in the various windows of the display regardless of which audio the speakers of the display itself are playing.

In a control device such as the control device shown in presents on its display a user interface UI of a user interface UI presenting a video image of content and a border superimposed on a portion of the video image which is smaller than the video image as shown. For illustration assume the video image in is of a football game with Os representing offensive players and Xs representing defensive players.

When a user has instantiated the border by e.g. selecting a pan and zoom selector the control device in response sends a command to the controller to cause a large display such the display in to present on the display only the higher definition portion of the content enclosed in the border on the control device . In the illustration shown the user has positioned the border on the control device over two offensive players and two defensive players with subscripts 1 to distinguish them from the other player symbols in the figure. In response the control device as indicated by the arrow has commanded the controller to present on the display device only the content enclosed by the border on the control device in the example shown to present only the two offensive players and two defensive players with subscripts 1 . It will readily be appreciated that the controller further has zoomed the video presentation on the demanded portion to substantially fill the entire screen of the display device .

In one example the screen of the control device is a touch screen display and a user may touch the border and or portion enclosed thereby and drag as indicated by the arrow the border to a new portion of the video as indicated by the dotted line box releasing the user touch once the border has been dragged to the desired part of the video shown on the control device. In the new portion two defensive players X are shown denoted by subscripts 2 to distinguish them. As indicated by the arrow this drag and drop causes the controller to pan the zoomed video from the first portion to the second portion in the direction of the drag until the second portion of the higher definition video substantially fills the screen of the display device as shown at in the figure.

Thus responsive to the drag and drop of the border on the control device the content related to the video image on the display device is entirely established in temporal sequence by a zoomed presentation of the first portion then a moving pan across at least part of the video image on the display device in concert with the user input to move the border to the second portion of the video image on the control device to end at a zoomed presentation on the display device of the second portion. During the drag and drop process the control device presents both the entire video image of the content and the border superimposed on the portion of the video image as the user input causes the border to move across the video image of the content whereas the display device is caused to present only content from the video image corresponding to content within the border on the control device.

HTML5 may be used along with JavaScript including some JavaScript libraries and CSS in one implementation. Video files may be stored locally on the control device and played in the browser using the video tag of HTML5. Live streaming files from a local streaming server streaming files from internet and live tuner signal can also be used as the source. To select a different file a user drags and drops a tile based on the id of the tile the path of the video in the quad portion on which the tile id dropped of the display presenting video in four quadrants selected is changed to the correct video and this new video is played. A full screen API may not be used since it requires user interaction to allow full screen on the control device. Accordingly as a workaround for full screen all videos can be paused then the video selected can be scaled by the browser to 4K resolution. If a 4K file is present the 4K file is used then no browser scaling is needed. Websocket may be used to communicate through IP from the control device to the controller to control the display device. Messages may be broadcast to all the display devices then each display device browser can use the message it needs. Drag and drop can be done using the jQuery UI library and scrolling can be done using CSS position updating. The stitch image zoom effect can be done by drawing video on the HTML5 canvas sending coordinates from control device to the controller so the controller knows which portion of the video to zoom on in the display device.

A phone application may also be implemented in HTML5 allowing audio files from the server to be played on a speaker e.g. of the display device or other device through IP. The phone application audio matches the audio for the four videos played in the quad view and each audio file can be selected for playback. When selecting an external device connected to a different HDMI input of the display device such as video disk player a satellite feed etc. when a user drags the appropriate tile for the external device the control device may send IP commands to the display device via the controller to change input. If a tile corresponding to a video is drag and dropped another IP command can be sent to the display device via the controller to change input back to PC and or controller and the video file selected is played from the PC and or controller.

A UI is presented on the display of the control device . As shown the UI includes plural main selectors arranged in a layout preferably the same layout as the windows on the display device as shown. Each main selector is established by a respective video feed in the example shown the same content albeit perhaps in lower resolution as the four videos in the quad view of the display device as duly indicated by use of the same video program designators P P.

The UI may further include a row of additional content selectors apart from the programs P P shown in the main selectors although in the embodiment shown for ease of disclosure the same four programs P P establish the first four content selectors in the row while the last two content selectors indicate they may be selected to present content from two additional programs P and P. In some embodiments unlike the main selectors which recall are established by moving video the content selectors in the row may be established by still image thumbnails.

Furthermore a column of audio selectors may be presented on the UI . Each volume selector in the column may correspond to a respective content in the content selectors in the row . Each audio selector may include a respective audio on off symbol with all of the symbols except one having a line through them indicating that the audio represented by those selectors is not being played on the display device . In contrast in the example shown the symbol of the top audio selector does not have a line through it indicating that the audio from the program associated with the top selector in the example shown program P is being played on the display device . Touching an audio selector on the control device causes the control device to command the controller to switch audio play on the display device to the audio represented by the touched audio selector on the control device . This also causes the line through the respective symbol of the touched selector to be removed and a line placed onto the symbol of the selector representing the replaced audio.

The right side of illustrates the dragging and dropping one of the content selectors onto a main selector changes the video in that main selector to the video represented by the dragged and dropped content selector . Not only does the UI on the control device thus change but also as indicated in the top right portion of the video presented in the window in this the top left window of the display device is also caused to change to the video represented by the dragged and dropped content selector . This may be done by the control device responsive to the drag and drop obtaining the network address or channel number of the video represented by the dragged and dropped content selector and commanding the controller to present video from that network address in the window corresponding to the main selector onto which the content selector was dragged and dropped. In any case it will readily be appreciated that the main selectors on the control device mirror the windows on the display device . A user may move his hand left or right on the row of content selectors to cause selectors for additional content to scroll onto the display of the control device. The new content typically includes additional program channels or Internet content related to the theme of the programming presented on the display device including for example sports statistics related to a sporting event in one of the windows .

The left side of illustrates that throwing one of the main selectors on the control device to the display device causes the display device to switch to a full screen presentation shown on the right of of the content represented by the thrown main selector . The processor of the control device may infer that a main selector has been thrown by a user dragging the main selector upwards toward the top of the control device responsive to which the control device sends a command to the controller to present the associated content full screen on the display device .

Although not shown in commanding the display device into the full screen mode as described above may result in the main selectors on the control device merging into a single large selector with the same content shown full screen on the display device. However the row of content selectors and column of audio selectors can remain unchanged. This single large main selector in the area formerly occupied by the four main selectors may be touched to cause the display device pursuant to a command from the control device to revert to the quad view shown on the left side of and to also cause the main selectors on the control device to mirror the display device views in this case to resume the four main selector quad view shown on the bottom left of .

Alternatively throwing a main selector to cause the display device to enter full screen mode as described may not alter the appearance of the main selectors which can remain in the quad view shown on the control device. Subsequently touching any one of the main selectors on the control device may result in the control device commanding the controller to resume the quad view presentation on the display device. Or if desired as shown on the bottom right of when the control device has been configured to command the display device to enter full screen mode with the four main selectors remaining on the control device UI touching one of the main selectors may cause the corresponding content to be presented full screen on the control device. The content presented full screen on the display device may be the same or different than the content presented full screen on the control device depending on what main selector was thrown to the display device and what main selector subsequently was touched by a user. A subsequent touch anywhere on the control device screen may cause the control device and display device to resume the layouts shown on the left side of .

To view the details of any content represented by a content selector as shown in the left side of a user may simply touch the content selector . This may cause a detail screen to appear on the control device but not on the display device so that a person controlling presentation on the display device by means of the control device can observe the detailed information about content prior to presenting the content or information about the content on the display device .

When a single control device is used to control both display device shown in as shown at in main selectors corresponding to the quad view of a first one of the display devices may be presented and used to control that display device according to principles above. Also a smaller quad view of alternate main selectors may be presented representing content being presented on the second display device . To enable control of the second display device using the control device a user need only touch the smaller quad view of alternate main selectors as shown at causing the smaller quad view of alternate main selectors to animate to an enlarged configuration and the quad view of main selectors corresponding to the first one of the display devices to animate to become smaller in size as shown at . The enlarged configuration of main selectors on the control device appertaining to the second display device may then be used to control the presentation on the second display device according to principles above.

The bottom two screen shots in show that tapping on a content selector can cause a detail presentation to be shown on the control device showing the details of the content represented by the tapped content selector. Also as shown at instead of a column of audio selectors as described previously respective audio on off symbols analogous to the symbols in may be presented on each main selector and if touched cause the control device to command the controller to replace the associated audio with the touched symbol to replace the audio currently being played on the display device being controlled.

While a four screen quad view is discussed and shown any number of windows in a multi window arrangements may be used.

Only a single audio preferably is selected for play because recall the display devices as shown have multiple video windows but it is desired to play only audio associated with video in a single one of the windows to avoid distracting overlapping audio. When the displays are side by side or otherwise positioned near each other both display devices may play the same audio regardless of whether the accompanying video is shown on only one or both of the display devices.

As shown the audio control device may present a list e.g. in a column of thumbnail like audio selectors each being selectable to cause the audio control device to command e.g. wirelessly the controllers to play on the display devices the audio represented by the selected audio selector .

In one non limiting example a user of the audio control device may use the camera of the device to image a bar code on a substrate located in the same room as the other devices shown in . The bar code may include e.g. a network address of a web site that the processor of the audio control device reads and in response invokes a browser to navigate to the web site. Of course other means for the audio control device to obtain the address of the web site hosting the audio selector UI may be used. The web site may download an application such as an application programming interface API to the audio control device or may otherwise provide the UI with the audio selectors as shown to the audio control device . It is to be appreciated that the web site associated with the network address from which the UT with the audio selectors is obtained is typically associated with the network sources of the various video streams presented in the windows of the display devices so that for each video stream presented in a window of a display device the audio web site provides a respective audio selector in the list presented on the audio control device that may be selected to cause audio associated with the video stream to be played on speakers of the display device s according to discussion above.

It will now be appreciated that while multiple video streams can be presented on the display device s to avoid distracting overlapping audio the display device s play only a single audio stream associated with one of the videos. As recognized herein however when multiple people are in the room one or more of them may wish to unobtrusively listen to an audio stream that is associated with one the video streams being presented on the display device s but that is not the audio stream selected for play by the display device s . Accordingly a tertiary or monitoring device that can receive audio and play it on headphones that are connected to the monitoring device wired or wirelessly may be employed as described below. In an example the monitoring device may be the wireless smart phone of the user and thus may incorporate some or all of the components shown in the CE devices of . Note that headphones includes any private listening apparatus including for example ear buds.

As shown in the monitoring device can present a list of plural audio feeds with each audio feed corresponding to a respective video content being simultaneously provided to a display device that is separate from the monitoring device . The list includes plural audio selectors and selecting an audio selector causes the monitoring device to play an audio feed associated with the selected audio selector on the monitoring device and preferably to play the audio on the headphones of the monitoring device. In this way a user of the monitoring device can view the display device s and listen to audio on the monitoring device that is associated with video content being presented in one of the windows of the display device but that is not the audio being played on the display device s .

In one non limiting example a user of the monitoring device may use the camera of the device to image the bar code which recall may include e.g. a network address of a web site that the processor of the monitoring device reads and in response invokes a browser to navigate to the web site. Of course other means for the monitoring device to obtain the address of the web site hosting the audio selector UI may be used. The web site may download an application such as an application programming interface API to the monitoring device or may otherwise provide the UI with the audio selectors as shown to the monitoring device . It is to be appreciated that the web site associated with the network address from which the UI with the audio selectors is obtained is typically associated with the network sources of the various video streams presented in the windows of the display devices so that for each video stream presented in a window of a display device the audio web site provides a respective audio selector in the list presented on the monitoring device that may be selected to cause audio associated with the video stream to be downloaded from the web site and played on the headphones .

Without limitation the audio provided from the web site to the monitoring device may be extracted from the AV streams provided by the cameras with associated microphones. This extraction may be effected using an extraction tool such as FFmpeg and or may extract the audio file from an AV object by recognizing and extracting audio file extensions such as but not limited to mp3 aac etc.

While the particular CONTROL OF LARGE SCREEN DISPLAY USING WIRELESS PORTABLE COMPUTER AND FACILITATING SELECTION OF AUDIO ON A HEADPHONE is herein shown and described in detail it is to be understood that the subject matter which is encompassed by the present invention is limited only by the claims.

