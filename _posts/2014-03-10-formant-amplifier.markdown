---

title: Formant amplifier
abstract: A method can include receiving audio data within a band of frequencies; amplifying individualized formant frequencies within the band of frequencies; and outputting audio data that includes at least one of the amplified individualized formant frequencies. Various other apparatuses, systems, methods, etc., are also disclosed.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09531333&OS=09531333&RS=09531333
owner: Lenovo (Singapore) Pte. Ltd.
number: 09531333
owner_city: Singapore
owner_country: SG
publication_date: 20140310
---
Speech may be conveyed as acoustic energy e.g. via longitudinal waves where certain speech sounds include concentrated energy that may be for example characterized with respect to frequency. Various examples of technologies techniques described herein pertain sound for example processing of sound etc.

A method can include receiving audio data within a band of frequencies amplifying individualized formant frequencies within the band of frequencies and outputting audio data that includes at least one of the amplified individualized formant frequencies. Various other apparatuses systems methods etc. are also disclosed.

The following description includes the best mode presently contemplated for practicing the described implementations. This description is not to be taken in a limiting sense but rather is made merely for the purpose of describing general principles of various implementations. The scope of invention should be ascertained with reference to issued claims.

Speech recognition may include translation of audio signals to text commands etc. For example consider an utterance acquired as an audio signal via a pressure sensor such as a microphone. Such an audio signal may be analyzed for one or more characteristics to identify the utterance e.g. recognize the utterance which may then be used initiate further action e.g. presentation of text command of a device etc. . As an example an utterance may be defined as a unit of speech which may be bounded e.g. by a speaker s silence . As an example an utterance may be a sound or sounds.

Speech recognition may include one or more grammars for example for analysis of audio signals that correspond to units of speech e.g. a series of utterances . As an example a grammar may be a set of structural rules that for example govern composition of clauses phrases and words in a language. As an example a language may be a command oriented language such as for example to command operation of a device e.g. a vehicle a computer etc. .

Speech recognition performance may depend on various factors. As an example noise may interfere with analysis of one or more characteristics of an audio signal by a speech recognition system which may be expected to perform in an environment that includes noise e.g. ambient noise machine noise audio signal noise from other speakers etc. .

As an example a method may include receiving audio data e.g. representative of audio signals amplifying individualized portions of the audio data and outputting audio data that includes at least one of the amplified individualized portions. Such a method may act to facilitate analysis of one or more characteristics of the audio data for example to enhance speech recognition. For example such a method may improve signal to noise ratio with respect to a unit or units of speech e.g. at least in part by amplifying audio data associated with a unit or units of an individual s speech .

As humans vary in their physiology and experiences in life e.g. culture training etc. speech generated via the vocal organ of an individual may include certain features that are characteristics of that individual. In other words speech may be at least in part individualized.

As an example speech may be characterized using a framework which may be referred to as the vowel trapezoid which may be as an example a polygon such as a quadrilateral e.g. optionally lacking parallel sides . In other words a vowel trapezoid may be considered a phrase that describes a concept an aspect of a framework etc. rather than a strict geometric shape.

As an example a vowel may be defined as a speech sound. A speech sound may be an utterance. A speech sound may be a phoneme. As an example vowels may be considered as being different tonal spectra e.g. colors and timbres that can be produced with no constrictions in the vocal tract. For example vowel resonation may be dependent upon tuning the vocal tract cavities either separately or as a unit. In general for a particular language each vowel may be recognized at least in part by the human ear e.g. optionally electronically aided as having specific acoustical properties as created by a corresponding configuration of the vocal tract. As an example in the English language vowels may make up about 40 percent of all speech sounds noting that in classical singing the percentage tends to be higher e.g. over 90 percent . Accordingly as vowels play an important role in classical singing a classical singer may generate vowel sounds that differ somewhat from those of a general population e.g. due to training development etc. . As an example with respect to a musical scale for a singer vowel sounds may be shifted in frequency e.g. to sound different notes of a scale .

The International Phonetic Alphabet IPA is a standardized system for transliterating speech sounds into phonetic symbols. Such symbols may be used in conjunction with a framework such as for example the vowel trapezoid framework of . Further as an example a framework may include quantitative information such as frequencies e.g. in hertz etc. . Frequencies may allow for characterization of speech sounds such as vowels for example based in part on formants.

As an example a formant may be a region of concentrated acoustic energy in a speech sound. Formants may be resonance characteristics inherent within an individual s vocal tract. In classical singing a singer may possibly modify the shape of the vocal tract for example to generate a particular speech sound. In the general population an individual s vocal tract may be expected to be relatively consistent in shape for example for a particular environment e.g. sitting at a desk driving a car walking down the street etc. .

With respect to a frequency spectrum formants may be regions of frequencies with relatively high acoustic energy. While a human may perceive a frequency spectrum over a band of frequencies as an example for a vowel that human may rely more on the lowest two formant frequencies of that vowel for purposes of perception e.g. human recognition .

As an example a formant framework may include a first formant a second formant a third formant and a fourth formant. As an example a first formant may be associated with tongue height and jaw opening and a second formant may be associated with front or back tongue positioning. As an example consider the vowel i which may upon being spoken include a first formant centered at about 350 Hz and a second formant centered at about 2500 Hz. As indicated in the vowel trapezoid framework of the vowel i is shown as being an extremum involving the hard palate and the front of the mouth e.g. front close as to shaping and sensing.

As shown in the method may include accessing information for an individual where such information includes frequencies associated with that individual. For example for an Individual information may include a listing of first formant frequencies and a listing of second formant frequencies where the listings correspond to first and second formants of a first vowel first and second formants of a second vowel etc. As an example information for an Individual may differ from that of the Individual . As an example information for an individual may be based on an analysis of speech samples from that individual. Accordingly in such an example the information may be individualized e.g. the information may include individualized formant frequencies .

As mentioned with respect to the vowel trapezoid framework of various sounds may be classified with respect to positions in a vowel trapezoid e.g. front central back close mid open front central back high mid low etc. . As an example a close classification may be further classified as upper close and lower close a mid classification may be further classified as upper mid and lower mid and an open classification may be further classified as upper open and lower open.

As an example a classification scheme may include terms such as for example rounded and unrounded. In such an example rounded may refer to rounding of the lips e.g. as part of articulation whereas unrounded may refer to lack of rounding of the lips e.g. as part of articulation . As an example a classification scheme may include terms such as for example tense and lax. In such an example tense may refer to close e.g. or closed types of sounds which may include more active involvement of the tongue whereas lax may refer to open e.g. or opened types of sounds which may involve less tongue elevation.

In the example of the sounds include a lower mid central unrounded sound e.g. in IPA a lower mid back unrounded sound e.g. in IPA and a lower high back rounded sound e.g. in IPA . As an example an individualized model may be based at least in part on one of the sounds . As an example individualized formant frequencies may be based at least in part on one of the sounds .

As an example an individualized model may be generated at least in part by determining one or more differences between formants of a sound in a base model and measured formants of the sound for an individual. For example an individualized model may be generated by shifting one or more sounds of a base model to match one or more of the sounds of . In such an example shifting may generate an individualized model. As an example a least squares or other error minimization technique may be applied for matching. As an example a technique may include inputting at least two points and shifting a base model based at least in part on the at least two points to output an individualized model.

As an example an individualized model may be formed via a method that includes analyzing utterances for example in the context of a vowel trapezoid framework. In such an example a few detected utterances e.g. sounds words etc. may be acquired received etc. as a sample that may be analyzed to determine a mode of formative sounds within the sample. As an example a sample may include as few as three words which may include particular sounds for purposes of determining an individualized mode. In such an example an individualized model may be constructed based at least in part on the individualized mode. As an example an individualized mode may be a sample of sounds represented in a formant space for example according to a vowel trapezoid framework. As an example an individualized mode may include a spectrum that includes spectral peaks for one or more sounds produced by an individual.

As an example a method may implement circuitry for constructing an individualized model. For example circuitry may perform a sweep or sweeps of low high and noise reducing filters as to an individualized mode e.g. a spectrum . In such an example outputs of the sweep or sweeps may be analyzed with an aim to avoid or minimize aliasing artifacts that could possibly be introduced into one or more regions of a spectrum for example where formants occur or may occur. As an example a method may implement circuitry for checking signal quality for example to help ensure that a reduction in signal quality in one or more formant frequencies is avoided or minimized e.g. to an acceptable level . As an example a method may include outputting one or more values of one or more parameters based at least in part on a sweep or sweeps e.g. of an individualized mode . In such an example the one or more values may be applied e.g. as circuitry for example to produce a least amount of distortion and a largest amount of noise reduction. Such circuitry may be applied to audio signals data etc. for example for purposes of speech recognition. For example such circuitry may perform one or more of filtering and amplifying audio signals data etc. As an example circuitry may include digital signal processing DSP circuitry for example that may be configured to implement one or more filters amplifiers etc. and for example that may be configured to adjust select etc. one or more parameters associated with processing signals e.g. processing audio signals as digital data .

As an example a gain may be at a particular level e.g. amplification factor dB etc. that may optionally be individualized to a formant optionally with respect to another formant. As an example a first formant of a sound may be amplified by a corresponding gain and a second formant of a sound may be amplified by a corresponding gain which may differ from the gain of the first formant of the sound. As an example an amplifier may be configured with respect to a relationship between spectral peaks for two or more formants. For example a first formant of a sound for an individual may have a spectral peak amplitude that exceeds that of a second formant of the sound for the individual. In such an example an amplifier may apply gain in a manner that acts to maintain e.g. preserve a relationship between amplitudes of the spectral peaks e.g. the spectral peak for the first formant and the spectral peak for the second formant . As an example a parameter for a first formant and a second formant of a vowel may be a ratio that may be based at least in part on peak amplitudes .

As an example a spectrum for a sound e.g. an utterance a vowel a unit etc. may include multiple spectral peaks over a range of frequencies see e.g. the plot . As an example circuitry may process a spectrum that may be emitted over a period of time e.g. a spectrogram for example where the period of time corresponds to duration of a sound. In such an example spectral peaks may be amplified and for example portions of the spectrum not corresponding to the spectral peaks may be diminished e.g. over a spectrogram . As an example circuitry may amplify amplitude and diminish amplitude e.g. based at least in part on frequency as associated with amplitude .

As shown in circuitry may operate according to one or more parameters. For example circuitry may operate with respect to one or more cutoff frequencies one or more resonant frequencies one or more Q values one or more gains and or one or more other parameters .

As an example a method may include setting a value for a parameter based at least in part on audio data. For example an input may receive audio data and circuitry may analyze audio data to determine a value or values for one or more parameters. In such an example circuitry may be constructed and or instructed to operate according to a determined parameter value or parameter values. As an example circuitry may operate to amplify individualized formant frequencies. As an example such circuitry may include one or more filters.

As an example circuitry may include a low pass filter. In such an example the low pass filter may pass frequencies less than a maximum formant frequency which may be a maximum second formant frequency e.g. of sounds that each include a first formant frequency and a second formant frequency .

As an example circuitry may include a high pass filter. In such an example the high pass filter may pass frequencies greater than a minimum formant frequency which may be a minimum first formant frequency e.g. of sounds where each includes a first formant frequency and a second formant frequency .

As an example circuitry may include a low pass filter and a high pass filter. As an example circuitry may include a low pass filter defined by a low pass cutoff frequency a high pass filter defined by a high pass cutoff frequency and one or more filters and or amplifiers that operate on at least a portion of the frequencies between the low pass cutoff frequency and the high pass cutoff frequency.

As an example circuitry may be configured to detect a few words as a sample and to analyze that sample to determine a trapezoidal mode of formative sounds within the sample. As an example as few as three words may be used to determine a trapezoidal mode e.g. depending on the utterance . In such an example a sweep of low high and noise reducing filters may be applied to the trapezoidal mode using circuitry e.g. DSP etc. . As an example outputs of sweeps may be analyzed with a goal that aliasing artifacts are not introduced in areas where formants occur. Additionally one or more checks may be made that an unacceptable reduction in signal quality does not occurs in the formant frequencies e.g. to a degree that may impact speech recognition etc. . As an example sweep parameters that produce a least amount of distortion and a largest amount of noise reduction may be used for subsequent filtering e.g. of audio signals digital audio data etc. . In such an example the parameters may be considered to be individualized for example as corresponding to an individual that produced the sample sounds.

As an example circuitry may implement one or more statistical processing techniques to process one or more samples for example to determine one or more parameters e.g. for subsequent implementation . As an example a statistical processing technique may include a network model or other type of model. As an example a processing technique may implement one or more of a neural network model a Hidden Markov Model etc. As an example a method may include model training and model implementation e.g. of a trained model . As an example a model may model one or more circuits e.g. amplification filtering etc. .

As an example the device may acquire audio data locally and transmit the audio data to a remote location for example for processing. In such an example the device may receive a model based at least in part on the remote processing. As an example the device may implement the model using circuitry for example to process audio data for example for purposes of speech recognition.

As an example the speech recognition engine may include circuitry that can implement a method that includes a match block that can access one or more grammars for matching utterances to a grammar an assignment block for assigning a confidence score e.g. or scores to a matched utterance and a decision block for deciding whether the confidence score e.g. or scores exceed a confidence level threshold. As shown in the example of based at least in part on the decision block the method per an acceptance block may include accepting a matched utterance e.g. as being recognized or the method per a rejection block may include rejecting a matched utterances e.g. as not being recognized . In such an example the method may take one or more actions for example instructing one or more of the applications etc. e.g. presentation of text entering a command etc. .

As an example a speech recognition system may include one or more statistically based speech recognition algorithms. As an example a speech recognition algorithm may include one or more Hidden Markov Models HMMs . As an example a HMM may receive as input information that may be for example processed audio information. As an example a HMM may output a sequence of symbols or quantities for example based at least in part on input information. As an example speech recognition algorithm may be trained for example by input of information that may be based on speaking particular text making particular sounds etc.

As an example a speech recognition system may include generation of one or more vectors that may optionally be coefficients resulting from a Fourier transform of a short time window of speech e.g. optionally processed audio data and for example decorrelating a spectrum using a cosine transform. In such an example coefficients may be selected based on order significance etc. As an example a HMM may tend to include in individual states a statistical distribution that may be a mixture of diagonal covariance Gaussians e.g. that may give a likelihood for an observed vector . As an example individual words individual phonemes e.g. sounds etc. may provide for a corresponding output distribution. As an example a HMM for a sequence of sounds e.g. words phonemes etc. may be generated by concatenating individual trained HMMs for individual sounds e.g. separate words phonemes etc. .

As an example one or more components of or associated with a speech recognition system may include one or more application programming interfaces APIs . As an example an API may provide for making calls and receiving responses. As an example an API may provide for interactions between components such as for example components of one or more of an audio processing system a speech recognition system an application an operating system etc.

As an example a system a method etc. may be configurable to or configured for a particular spoken language. Some examples of languages include the Indo European languages e.g. English Spanish Russian Hindustani etc. and the Sino Tibetan languages e.g. Mandarin Chinese Cantonese Japanese Korean etc. . As an example a system may include circuitry for amplification of individualized formant frequencies for a particular language or languages. As an example a system may include trainable circuitry that may be for example trained for a particular language or languages for an individual to generate trained circuitry. As an example such trained circuitry may provide for amplification of individualized formant frequencies for that individual. As an example circuitry may be reset retrained etc. for example for use by another individual for use with respect to another language etc.

As an example a speech recognition system may implement filtering techniques that may be frequency dependent. As an example speech e.g. audio signals or data may have in terms of frequencies a bandwidth for example centered in a range that may vary from individual to individual. As an example speech resonances such as formants may vary with respect to physiology such as for example an individual s height e.g. which may correspond to length of the vocal tract etc. .

As an example a method may include digitizing speech e.g. audio signals or data by applying a low pass filter a high pass comb filter and a noise reduction technique such as beam forming. In such an example cleanliness from artifacts of the noise reduced speech may vary depending on the frequency specific characteristics of such filters. As differences may exist from individual to individual a system that operates according to a fixed set of filter values may be sub optimal e.g. not work well when applied to various individuals . For example the higher the high pass filter used the more aliasing artifacts may leak into lower bands. Further for example the lower a low pass filter is used the more single frequency noise components and their aliased artifacts may show up in a signal. Yet further for example beam forming filters may introduce aliased noise spikes at lower multiples of the noise zero frequencies. As an example a method that may implement one or more parameter values that are based at least in part on individualized formant frequencies may provide cleaner output for an individual. Such cleaner output may in turn enhance performance of speech recognition.

As an example a method may include detecting a set of words e.g. a first few words of sentence etc. and analyzing the set of words to determine a mode of the formative sounds within the sample e.g. using a vowel trapezoid framework etc. . As an example such a mode may be used as a basis for forming a model. As an example a method may include analyzing as few as three words to determine a mode for example depending on the utterance e.g. words consonants vowels etc. . As an example a sweep of low high and noise reducing filters may be applied to a mode for example using circuitry that may include digital signal processing DSP circuitry. As an example outputs of such a sweep may be analyzed for example in an effort to avoid introduction of aliasing artifacts e.g. in regions of a formant space where formants may occur . As an example a method may include checking signal quality for example to avoid reduction in signal quality with respect to one or more formant frequencies. As an example by analyzing one or more sweeps one or more values of one or more parameters may be determined e.g. selected for example that produce the least amount of distortion and largest amount of noise reduction. In such an example the one or more values may be implemented for processing additional audio signals data etc. e.g. via filtering amplifying etc. . As an example parameters may include for example one or more of the parameters of .

As an example the device may include one or more processors memory a power source one or more network interfaces sensor circuitry a display e.g. or displays and audio circuitry . As an example audio circuitry may be operatively coupled to a processor may include a processor etc. As an example the audio circuitry may be configured for one or more of acquiring audio signals filtering amplifying speech recognition etc.

As an example a method can include receiving audio data within a band of frequencies amplifying individualized formant frequencies within the band of frequencies and outputting audio data that includes at least one of the amplified individualized formant frequencies. Such an example may further include receiving audio data associated with an individual analyzing the audio data associated with the individual for at least two vowels and based at least in part on the analyzing outputting parameter values for amplifying the individualized formant frequencies. In such an example the at least two vowels may include at least one of a lower mid central unrounded vowel a lower back mid unrounded vowel and a lower high back rounded vowel.

As an example a method may include receiving audio data associated with an individual as a signal and audio data associated with ambient noise where for example the method includes amplifying that increases the signal with respect to the ambient noise.

As an example a method may include applying a low pass noise filter that filters out ambient noise in the audio data that includes frequencies above a low pass cut off frequency. In such an example the method may include selecting the low pass cut off frequency based at least in part on an individualized mode defined in a formant frequency space.

As an example a method may include applying a high pass noise filter that filters out ambient noise in the audio data that includes frequencies below a high pass cut off frequency. In such an example the method may include selecting the high pass cut off frequency based at least in part on an individualized mode defined in a formant frequency space.

As an example individualized formant frequencies may include frequency pairs that include a first formant frequency and a second formant frequency. As an example a method may include performing speech recognition based at least in part on audio data that includes at least amplified frequency pairs.

As an example a system can include a processor memory operatively coupled to the processor instructions stored in the memory and executable by the processor to instruct the system to receive audio data within a band of frequencies amplify individualized formant frequencies within the band of frequencies and output audio data that includes at least one of the amplified individualized formant frequencies. Such an example may include instructions to receive audio data associated with an individual analyze the audio data associated with the individual for at least two vowels and output parameter values for amplification of the individualized formant frequencies. In such an example the at least two vowels may include at least one of a lower mid central unrounded vowel a lower back mid unrounded vowel and a lower high back rounded vowel.

As an example a system may include instructions to select at least one cut off frequency for at least one pass filter based at least in part on an individualized mode in a formant frequency space. In such an example the at least one pass filter may include a low pass filter a high pass filter or a low pass filter and a high pass filter. As an example a system may include at least one pass filter that filters out frequencies in audio data that do not lie within an individualized mode in a formant frequency space.

As an example a system may include instructions to amplify individualized formant frequencies that include pairs of frequency bands where each band includes a formant frequency associated with a vowel.

As an example one or more computer readable media may include processor executable instructions to instruct a computing device to receive audio data within a band of frequencies amplify individualized formant frequencies within the band of frequencies and output audio data that includes at least one of the amplified individualized formant frequencies. Such an example may include processor executable instructions to instruct a computing device to receive audio data associated with an individual analyze the audio data associated with the individual for at least two vowels and output parameter values for amplification of the individualized formant frequencies.

As an example one or more computer readable media may include processor executable instructions to instruct a computing device to filter out frequencies below a high pass filter cut off frequency and to filter out frequencies above a low pass filter cut off frequency where for example the cut off frequencies are based on an individualized mode in a formant frequency space.

As an example an amplifier may include an input for audio signals a frequency pair map for first and second formants of vowels amplification circuitry to amplify audio signal frequencies according to the frequency pair map and an output for audio signals that comprise at least amplified audio signal frequencies. Such an example may include at least one pass filter that includes a pass frequency that passes frequencies that lie within a vowel trapezoid. As an example an amplifier may include at least one pass filter e.g. a low pass filter a high pass filter a high pass filter and a low pass filter etc. .

The term circuit or circuitry is used in the summary description and or claims. As is well known in the art the term circuitry includes all levels of available integration e.g. from discrete logic circuits to the highest level of circuit integration such as VLSI and includes programmable logic components programmed to perform the functions of an embodiment as well as general purpose or special purpose processors programmed with instructions to perform those functions. Such circuitry may optionally rely on one or more computer readable media that includes computer executable instructions. As described herein a computer readable medium may be a storage device e.g. a memory card a storage disk etc. and referred to as a computer readable storage medium. As an example a computer readable medium may be a computer readable medium that is not a carrier wave.

While various examples of circuits or circuitry have been discussed depicts a block diagram of an illustrative computer system . The system may be a computer system such as one of the ThinkCentre or ThinkPad series of personal computers sold by Lenovo US Inc. of Morrisville N.C. or a workstation computer such as the ThinkStation which are sold by Lenovo US Inc. of Morrisville N.C. however as apparent from the description herein a satellite a base a server or other machine may include other features or only some of the features of the system . As described herein a device such as a device illustrated in or described with respect to e.g. or another device etc. may include at least some of the features of the system .

As shown in the system includes a so called chipset . A chipset refers to a group of integrated circuits or chips that are designed e.g. configured to work together. Chipsets are usually marketed as a single product e.g. consider chipsets marketed under the brands INTEL AMD etc. .

In the example of the chipset has a particular architecture which may vary to some extent depending on brand or manufacturer. The architecture of the chipset includes a core and memory control group and an I O controller hub that exchange information e.g. data signals commands etc. via for example a direct management interface or direct media interface DMI or a link controller . In the example of the DMI is a chip to chip interface sometimes referred to as being a link between a northbridge and a southbridge .

The core and memory control group include one or more processors e.g. single core or multi core and a memory controller hub that exchange information via a front side bus FSB . As described herein various components of the core and memory control group may be integrated onto a single processor die for example to make a chip that supplants the conventional northbridge style architecture.

The memory controller hub interfaces with memory . For example the memory controller hub may provide support for DDR SDRAM memory e.g. DDR DDR2 DDR3 etc. . In general the memory is a type of random access memory RAM . It is often referred to as system memory .

The memory controller hub further includes a low voltage differential signaling interface LVDS . The LVDS may be a so called LVDS Display Interface LDI for support of a display device e.g. a CRT a flat panel a projector etc. . A block includes some examples of technologies that may be supported via the LVDS interface e.g. serial digital video HDMI DVI display port . The memory controller hub also includes one or more PCI express interfaces PCI E for example for support of discrete graphics . Discrete graphics using a PCI E interface has become an alternative approach to an accelerated graphics port AGP . For example the memory controller hub may include a 16 lane x16 PCI E port for an external PCI E based graphics card. A system may include AGP or PCI E for support of graphics. As described herein a display may be a sensor display e.g. configured for receipt of input using a stylus a finger etc. . As described herein a sensor display may rely on resistive sensing optical sensing or other type of sensing.

The I O hub controller includes a variety of interfaces. The example of includes a SATA interface one or more PCI E interfaces optionally one or more legacy PCI interfaces one or more USB interfaces a LAN interface more generally a network interface a general purpose I O interface GPIO a low pin count LPC interface a power management interface a clock generator interface an audio interface e.g. for speakers a total cost of operation TCO interface a system management bus interface e.g. a multi master serial computer bus interface and a serial peripheral flash memory controller interface SPI Flash which in the example of includes BIOS and boot code . With respect to network connections the I O hub controller may include integrated gigabit Ethernet controller lines multiplexed with a PCI E interface port. Other network features may operate independent of a PCI E interface.

The interfaces of the I O hub controller provide for communication with various devices networks etc. For example the SATA interface provides for reading writing or reading and writing information on one or more drives such as HDDs SDDs or a combination thereof. The I O hub controller may also include an advanced host controller interface AHCI to support one or more drives . The PCI E interface allows for wireless connections to devices networks etc. The USB interface provides for input devices such as keyboards KB one or more optical sensors mice and various other devices e.g. microphones cameras phones storage media players etc. . On or more other types of sensors may optionally rely on the USB interface or another interface e.g. IC etc. . As to microphones the system of may include hardware e.g. audio card appropriately configured for receipt of sound e.g. user voice ambient sound etc. .

In the example of the LPC interface provides for use of one or more ASICs a trusted platform module TPM a super I O a firmware hub BIOS support as well as various types of memory such as ROM Flash and non volatile RAM NVRAM . With respect to the TPM this module may be in the form of a chip that can be used to authenticate software and hardware devices. For example a TPM may be capable of performing platform authentication and may be used to verify that a system seeking access is the expected system.

The system upon power on may be configured to execute boot code for the BIOS as stored within the SPI Flash and thereafter processes data under the control of one or more operating systems and application software e.g. stored in system memory . An operating system may be stored in any of a variety of locations and accessed for example according to instructions of the BIOS . Again as described herein a satellite a base a server or other machine may include fewer or more features than shown in the system of . Further the system of is shown as optionally include cell phone circuitry which may include GSM CDMA etc. types of circuitry configured for coordinated operation with one or more of the other features of the system . Also shown in is battery circuitry which may provide one or more battery power etc. associated features e.g. optionally to instruct one or more other components of the system . As an example a SMBus may be operable via a LPC see e.g. the LPC interface via an IC interface see e.g. the SM IC interface etc.

Although examples of methods devices systems etc. have been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described. Rather the specific features and acts are disclosed as examples of forms of implementing the claimed methods devices systems etc.

