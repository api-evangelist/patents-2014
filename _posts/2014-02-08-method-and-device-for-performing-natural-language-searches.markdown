---

title: Method and device for performing natural language searches
abstract: A digital device and a method for parsing a query, in particular a natural language query, and retrieving results from possibly multiple data sources such as relational databases or the Semantic Web. The method includes a parsing procedure for generating a graph-based logical representation of the query using semantically structured resources, consisting of a tokenizer, a node generator, a relationship generator, and a focus identificator. The digital device realizes a modularized architecture, consisting of a parser enabling the processing of a query with possibly multiple vocabularies, a query performer retrieving data of knowledge sources independently from their database management system, and a result processor merging the results.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09448995&OS=09448995&RS=09448995
owner: 
number: 09448995
owner_city: 
owner_country: 
publication_date: 20140208
---
This invention relates to a digital device a method and a computer program according to the appended claims. More specifically the invention relates to the field of performing searches particularly natural language searches on structured data such as relational databases or the Semantic Web.

The World Wide Web WWW stores and administers information on the Internet in an essentially unstructured way. In order to overcome this deficiency increasing efforts aim at structuring or classifying the information on the Internet. These efforts are run by the World Wide Web Consortium W3C see http www.w3.org a major standard setting body for the World Wide Web. The aim of these efforts is to create a Semantic Web of linked data in which data is structured and queried using a common data model see http www.w3.org standards semanticweb . One approach of a descriptive structured data model is presented by the Resource Description Framework RDF http w3.org TR 2004 REC rdf concepts 20040210 which realizes information statements in the form of subject predicate object triples made about instances of specific classes. A common way of identifying resources on the Semantic Web is the employment of Uniform Resource Identifiers URIs . A query language for RDF data has been presented with SPARQL http w3.org TR 2008 REC rdf sparql query 20080115 which introduced the concept of pattern matching of graphs.

The increasing amount of structured data available on the Web increases the necessity to bridge the gap between informal natural language of human users and the formal query languages of structured databases. Natural Language Interfaces NLIs provide a solution for shifting the task of parsing a natural language query generating an appropriate database query and processing the results to a machine in an automated way.

Increasing attention is paid to the issue of portability i.e. the flexibility of NLIs with respect to its vocabularies which are employed to parse a query into a logical representation and its knowledge sources which represent the data corpus for retrieving search results. In this context a promising approach is the emergence of NLIs retrieving data from multiple knowledge sources providing a variety of possible domains. Ideally a distributed NLI would recognize what the query searches for and contact one or multiple appropriate knowledge sources in order to retrieve an answer. Furthermore it would be preferable to employ knowledge sources for a NLI independently from their underlying database management systems.

In general natural language interfaces NLIs incorporate with three stages a The parsing of a natural language query b the knowledge retrieval of various data sources and c the aggregation of the distributed results to a search response.

Considering the parsing of a natural language input the purpose of syntactical parsing is the analysis of a natural language sentence and the generation of an intermediate representation depicting the natural language s semantics in a logical form able to be processed further by subsequent system components. Existing approaches can generally be divided into approaches performing a detailed linguistic analysis based on a formal grammar theory referred to as Deep Parsing and rather fast lightweight approaches focusing on solving a particular task Shallow Parsing .

Grammar based parsers employ a set of rules to identify a sentence s structure and to generate a logical representation in the form of a parse tree. One of the main advantages of grammar based systems is the high accuracy of the parsing process. On the other hand the construction of a set of grammar rules is often a time consuming task while the systems may parse a query incorrectly if it is not formulated correctly according to the linguistic rules.

Shallow parsing methods on the other hand are rather focused on segmenting a sentence into logical units and to determine their semantic roles in the context of the sentence. Among the main approaches for shallow parsing are Part Of Speech POS Tagging Text Chunking Named Entity Recognition and or Semantic Role Labeling.

Considering the process of retrieving search results from a knowledge base existing approaches can be distinguished by their underlying database management systems such as relational databases or RDF repositories. Examples of these and other prior attempts to build natural language search engines are e.g. disclosed in U.S. Pat. Nos. 8 315 998 8 301 438 wherein this document describes the search for a named entity in the natural language question DE 10 2007 000 954 A1 and DE 10 2009 037 848 A1. An early approach for setting up a database of metadata for a Semantic Web specifically for capturing digital media content is disclosed in U.S. Pat. No. 6 311 194 B1. Among the non patent literature reference is made to V. Tablan et al. A natural language query interface to structured information ftp www.dlsi.ua.es people antonio A 20natural 20language 20query 20interface 20to 20structured 20information.pdf Chong Wang et al. PANTO A Portable Natural Language Interface to Ontologies http gate.ac.uk sale dd related work 2007 Wang PANTO.pdf and Ana Maria Popescu et al. Modern Natural Language Interfaces to Databases Composing Statistical Parsing with Semantic Tractability http acl.ldc.upenn.edu coling2004 MAIN pdf 21 783.pdf. In addition a review of existing NLI s to databases is contained in I. Androutsopoulos et al. Natural Language Interfaces to Databases An Introduction http acl.ldc.upenn.edu coling2004 MAIN pdf 21 783.pdf.

The present invention provides a digital device and a method for performing a search in particular but not limited to a natural language search in semantically structured resources such as relational databases or RDF repositories by using a different approach than prior art solutions. In particular it is an object of the present invention to provide a novel solution that reduces the amount of network resources and the processing time required to generate a meaningful response to the query. This object has in general various aspects 

From a technical perspective a major object of the invention is to reduce the amount of processing computer and network time required to perform a search. For example it is an object of this invention to reduce the amount of processor time used to perform and or conclude a search so that the processor is either made available for other jobs and or can process more searches or queries in a given time or that less powerful processors or computers can be used to perform the search.

Another technical object of the invention is to reduce the amount of storage and or other hardware required to produce a meaningful search result.

The invention also aims at sending different commands and queries to the various components of a computer system and or a distributed network to have them work in a novel way i.e. the transmitted signals are different from prior solutions. Also different control signals may be employed.

Furthermore it is a technical object of the invention to reduce the number of network resources used on a distributed network and thus reduce the amount of network traffic and in a client server configuration to enable communication from a small client with limited transmission speed such as a mobile phone.

With respect to the user perspective the invention aims at making the search process as simple as possible in particular by offering the user an easy input method such as a text form in which the user can enter a natural language query as a simple sentence or question providing a query result as fast as possible while the search results are retrieved with high precision and thus save the user further time. It is also desirable to have as few responses are reasonably possible rather than a long list of hits .

From the perspective of the manufacturer of a search engine the invention aims at making the development easy and possible at low cost.

The presented method is aimed at providing a faster and more fault tolerant procedure than prior art solutions.

The present invention aims at solving one or more of the above objects it is understood that although ideally the invention may solve all of the above objects also the solution of one of these objects a partial solution of one or more objects etc. is within the scope of the invention .

In more specific terms the invention provides a distributed natural language search engine using graph based parsing although its application is broader as will become apparent throughout this description . One of its main features is the provision of a new parser and the components thereof. Also it is easier adaptable to new requirements through a novel approach of separating the access to ontologies and semantic resources as will be discussed below.

Focusing first on one method aspect of the present invention the invention relates to a computer implemented method or a method implemented using digital electronic components such as digital gates and application specific integrated circuits for retrieving results in response to a query. The query is preferably a user defined natural language query but could as well be a machine generated query. It makes use of semantically structured resources stored in at least one database. The database can be stored locally as well as on a network such as the Internet and in a preferred embodiment the method according to the invention uses multiple databases and discriminates between them.

Step i. serves to identify semantic tokens i.e. objects with semantic descriptors in the natural language query. A semantic token is characterized by its token type which represents the semantic role of the token. The semantic role of a token is defined in terms of a conceptual data model similar to the one realized by ontologies on the Semantic Web dividing knowledge into terminological knowledge which defines the conceptual data of a defined domain as a set of classes and properties and assertional knowledge describing facts of instances of those classes. In fact the two terms token type and semantic role are interchangeable and although token type is used throughout this description one could also say semantic role . Typical token types of the invention are 

In the context of this invention a token can be described as a quadruple t term identifier token type as explained above u a uniform identifier preferably a Uniform Resource Identifier and r relevance but other definitions are of course possible.

In order to obtain tokens the input query has first to be segmented into terms. A term can be a single word or a combination of words of the query referring to a semantic entity. For example the query Towns in Sweden can be segmented into the terms

Consequently 4 possible segmentations of the initial query are possible. Each individual segmentation is also called a term sequence so that we have 4 possible term sequences in this example.

The segmentation of the query into term sequences can be done in various manners. A particularly advantageous way of segmentation will be described below however other methods are possible. By way of example a preprocessor could remove the stopword in in the above query so that only two possible segmentations remain 

A preferred aspect of the present invention is a segmentation optimizer which is part of the tokenizer and generates various different segmentations of the query calculates the probability of each segmentation preferably based on a relevance factor for a semantic token and selects the most appropriate segmentation. Advantageously the probability calculation is being done by a probability calculator using relevance factors for a semantic token from at least one lexicon wherein the probability calculator computes the probability of each segmentation and chooses a segmentation with a high probability preferably the segmentation with the highest probability.

The term sequences determined in this way are then mapped into the semantic tokens mentioned previously. According to the invention a lexicon is used for this purpose containing mappings between terms and semantic tokens. Each term in a term sequence is sent to or looked up in the lexicon which returns a token provided it exists together with its token type. In the last example above the lexicon would return that town is a class and that sweden is an instance but it would return a zero result for town sweden .

The lexicon may be kept locally or on a network such as the Internet. The term associations contained in a lexicon are preferably extracted from ontologies such as DBpedia http www.dbpedia.org which provide a conceptual world model by their underlying ontology as well as an instance set in the form of the set of articles discussed in the detailed description. Preferably the lexicon is however kept locally optimizing the processing time of an actual query. This has three advantages The processing time of an actual query is reduced since no network traffic is required a local lexicon can be better tailored to the needs of a search engine and lexicons can easily be added or removed thus making the system much more flexible.

Also in a preferred embodiment of the invention the lexicon returns not only the semantic role of a token but also a resource identifier such as a Uniform Resource Identifier pointing to a particular resource on the network that contains or may contain information about the token and in an even more preferred embodiment it computes the token that is considered most relevant for the given term and returns a relevance factor or relevance indicator indicating the probability with which the term matches the token. The advantages of both approaches will be discussed in more detail below.

This process of transforming or mapping a term sequence into semantic tokens by means of segmentation and lexicon look up is appropriately called tokenization and a machine performing the process is called a tokenizer . The tokenizer can be a separate digital machine or more appropriately a virtual machine running on a digital computer wherein the instructions for the machine for performing the tokenization process are stored in a tokenizer memory.

One preferred method according to the invention includes the following steps for tokenizing the query 

This preferred method of implementing the tokenization thus includes computing multiple segmentations and choosing the most relevant or most probable one. In other words multiple segmentations are tried out until the process finds the best segmentation which is then used to generate the graph based representation and later the actual query. Advantageously but not necessarily the method will test all possible segmentations if n is the number of words in a sentence . An example will be discussed in the detailed description.

Calculating the probability of a certain segmentation is relatively easy if a relevance factor for a semantic token can be retrieved from a lexicon and such relevance factor can be stored in the lexicon when it is set up . The relevance factor is not available with ontologies on the web so its generation for locally stored lexicons is a major technical contribution of the present invention to speed up processing and reduce the use of resources. The probability of a term can preferably be calculated by dividing the number of words in a term by the total number of words in the term sequence then multiplying it with the probability of the term. If this process is carried out for all terms and the resulting probabilities are summed up the result will be the probability for the whole term sequence an example will be discussed in the detailed description . However it has to be pointed out that other solutions for calculating the probability of a term sequence a segmentation are possible like just summing up the probabilities of each term without weighting it or the like.

In a preferred embodiment the tokenizer additionally makes use of disambiguation rules selecting the most probable token if a term s meaning is ambiguous. For example pure information may sometimes have a double meaning such as the word Washington in English which can be a city or a person or the word Gericht in German which can be a court or a dish.

Step ii. of the presented method is so to speak a core element of the present invention. Based on the semantic tokens determined in step i. a graph based representation of the query is generated which represents a query as a set of nodes connected by a set of edges. The representation is computed within a transition based procedure employing a set of transformation rules generating stepwise the nodes the relations and the focus of a semantic graph. For this purpose the method employs three types of specific modification rules. This process will be described in more detail.

Referring first to nodes a graph node n u t p is a quadruple representing one or multiple entities with the node indicator the identifier u the node type tand the position p. The position p indicates the node s original position in the natural language query. One important concept to be mentioned here is the distinction between terminal and non terminal nodes and or relations. The Boolean variable indicates whether nrepresents a terminal or a non terminal node.

Intuitively one could therefore say a terminal node is a node already identified and associated with a resource and the semantic role while a non terminal node is a variable of undefined node type representing one or multiple entities described by the node s relationships.

Similar consideration apply to non terminal relationships. A graph branch b n n p of a graph g is a quadruple connecting two graph nodes n nwith a property p. The Boolean value indicates whether the property specifies a specific or an arbitrary property.

Note that a relationship is herein also referred to as a branch the two expressions are synonyms in this context and interchangeable. In a preferred embodiment the calculation of the most probable pattern for modifying an input sequence also takes into account specific values indicating that a specific patterns is correct so called truth values .

In essence the first step of the method is to generate the nodes representing the tokens of the chosen segmentation. This is done by employing the rules in this context called patterns that map the tokens into the appropriate node representation. In one particularly preferred embodiment of the invention patterns are additionally associated with a truth value indicating to what degree the given modification is correct. A pattern employment function is used wherein a pattern defines one or more nodes maybe together with a relationship pertaining to the particular node which is associated with the token type or semantic role of a token. Using a truth value or confidence factor associated with a pattern it can be determined whether the certain pattern maps the token type appropriately and to what degree. If more than one pattern is possible to do the mapping the most probable one is selected.

Mathematically speaking a node pattern pis a pattern indicating how a token is transformed into a graph node. A node pattern consists of an input sequence called the expression e t consisting of a single token t and a modification rule called the annotation a n b indicating a set of nodes and branches to be generated. The node type and the identifier of a node are analogous to the token type and a token s identifier. From various points of view node patterns constitute an intermediate stage in the graph generation process. The node stage realizes relations in the form of role nodes which are transformed into labeled edges in the next stage. A specific form is the generation of class nodes which already realize a node relationship As a class node represents a set of entities of the specified class the pattern includes the generation of a non terminal node to be explained below connected with the generated class node.

The next second step is to generate all relations between the nodes computed in step 1 that can be identified to complete the graph based representation. This is done by employing one or multiple patterns focusing on the identification of missing relations between nodes. As in the previous step a truth value preferably between 0 and 1 can be used to judge whether a particular relationship is a good match or not.

Again mathematically speaking a relation pattern p e a v consists of an expression e an annotation a and a truth value v. The expression e n b consists of a set of nodes and branches indicating the input elements while the annotation a n b is a set of nodes and branches indicating the transformation of the expression into one or more branches. The annotation must contain at least one token from the expression. The truth value v 0 1 indicates the probability that the given correlation is correct. The annotation indicates how the token sequence is transformed into a set of branches.

As the query represented by the graph expresses an information request a graph has to contain at least one non terminal element. Other than the representation of a general set of relations within a graph the realization of a search request requires an element identified as the query s major element indicating the requested data called the graph s focus. The focus determines the major request entities or facts that are described by the graph that is the elements the query searches for. The purpose of the third step of the presented method thus is the identification of a non terminal element of the graph namely either a non terminal node or a non terminal branch representing the focus of the query.

A focus f of a graph g is an entity of the graph representing the elements that are to be retrieved. A focus can either be a node nor a branch b. Each graph can have only one focus.

The focus of a token sequence is identified with focus patterns which identify a graph s focus as well as its request type. Again a focus can be determined by using patterns focus patterns as already described in connection with steps one and two. In this context a focus pattern pis a pattern identifying the focus of a graph g. It consists of

Employing a graph based view of a natural language query the method divides the possible entities a query can search for into two base forms of query types A query can search for resources e.g. persons cities i.e. nodes or the query searches for a relation of an entity such as the value of a specific property or the relationship between two nodes e.g. birthday of a person i.e. a branch relationship . An identified focus node thus represents an entity search while a focus branch indicates a request for a specific relation i.e. a fact search.

It is understood that the above steps one to three can be performed simultaneously e.g. through the use of look up tables. However in view of the required programming effort and execution time the preferred solution executes these step by step such that an advantageous embodiment of the invention may include the following method steps 

Looking at a device suitable for implementing and or using the method described above the invention relates to a digital device in particular digital computer such as a server or a client or a mobile digital device connected with at least one database containing semantically structured resources preferably on a network like the Internet comprising 

Many of the elements mentioned in the digital device aspect of the present invention are already apparent from the previous description of the underlying method. However the basic elements of input and output circuitry the parser the query performer and the results processor should be specifically mentioned here.

The parser one of the essential elements of the present invention includes the tokenizer and the node relationship focus generator. In the above example the node relationship focus generator is described as one component. However in a preferred embodiment three components are used. Accordingly the parser for processing a natural language input consists of the following components 

The 3 generators described in b c and d function essentially as described in the context of the underlying method. In a preferred embodiment the process of retrieving semantic tokens from a lexicon is separated from the main device in one or multiple modularized components called vocabulary modules. These modules communicate through well defined interfaces with the main device enabling a flexible implementation of the system s lexicons. Within a tokenization procedure each vocabulary module receives a segmentation of the natural language query and retrieves a set of tokens from its associated lexicon. The advantages of the modularization of a NLI s access to its vocabularies are the possible employment of multiple vocabularies as well as the independence towards the system s domain. Vocabulary Modules can easily be added or removed at runtime without interrupting or modifying the main system which increases speed and in particular adaptability of the system.

The system s second component is the query performer which receives a logical intermediate query representation of the natural language query from the parser generates a database query and sends it to the at least one database. The intermediate representation namely the semantic graph generated within the three steps above is employed to generate a valid database query appropriate for the database consulted such as SQL SPARQL or XQuery. The query is sent to the database and the response is received thus completing the search process.

While the present invention requires sending the query to at least one database in an advanced embodiment the query is sent to more than one database or to one or more selected databases from a multiplicity of databases. In this way the wealth of information that can be retrieved is increased since many of these databases have a specific domain. In this embodiment each of the system s knowledge sources is registered with one or multiple identifiers indicating the knowledge source s domain i.e. its focus type s . If the parser identified a focus type of a query s semantic graph as described above the query performer selects appropriate knowledge sources for a query by comparing the query s focus type with those of the registered knowledge sources. In this way the system identifies data sources which are expected to have the requested information available. For example if a query is related to a natural person it may be prudent to send the query to a general purpose data source such as DBpedia or to the Application Programming Interface API of a social network but not to the geospatial database LinkedGeoData. This approach thus saves processing and network time i.e. it reduces the amount of resources needed and will speed up the process. This is an easy to implement way of speeding up the process of retrieving information from a multiplicity of knowledge sources and no queries are sent to databases which are not expected to contain relevant results thus reducing network traffic and relieving databases focusing on other domains from processing a request. In a preferred embodiment of the device in a similar fashion as the parser component s vocabulary modules the process of consulting the system s knowledge sources is performed by separated components called data modules. These modules contribute to the system modularity by separating the highly customized process of generating a valid database query from the main system. This is easily possible because each database module is assigned to one specific knowledge database on the network. They communicate with the query performer through well defined interfaces and can dynamically be added or removed thus providing the system a flexible and easily adaptable variety of knowledge sources. A data module receives the intermediate representation generated by the graph based method described above and generates an appropriate database query for its associated knowledge base it returns a set of search results preferably enriched with a relevance factor and diverse meta data such as a title a description an image URL and or geospatial coordinates of the retrieved result. http linkedgeodata.org

The inventive method preferably also includes the step of merging selecting and or ranking the responses. This aspect is of particular importance if the intermediate representation of the query has been sent to more than one knowledge database on the network but can also be applied if only one database has been contacted. The result processor merges results retrieved from one or more data sources and additionally generates a relevance factor for each search result which is the base for a ranking of the retrieved search result set. It returns a list of search results that can be interpreted by a human being or further processed by a machine.

The steps performed by the inventive method can be implemented in hardware components by microprogramming or any other suitable technical method. However in one advantageous embodiment of the invention it can be embodied in a computer program which can be executed on a digital computer. The invention also relates to a computer program product that can at least partially be loaded into the internal memory of a digital computer in particular a server that includes instructions for executing the steps according to the inventive method when executed on such digital computer. The computer program product can be a tangible medium such as a compact disk a USB stick or the memory or the hard disk of a digital computer however it can also be stored on a network computer and be downloadable over the network. In an advantageous embodiment the digital device is server based and the human interface is located on a user operated client. In other words the search engine runs on a server and the user operated client can be a less powerful device and or even be connected with the server through a relatively slow connection such as a telephone modem or a wireless link. This is because the user operated client only needs to run a human interface program in order to enter a natural language query and receive the results and does not have to process the query itself. This is all done on a server which may also have a much faster connection to the Internet or another network available.

Taking the invention from a more hardware oriented perspective it also relates to an apparatus for performing natural language searches comprising 

Other features and advantages of the present invention are described in the appended claims. It should be noted that the invention relates to all possible combinations of claims or features disclosed in this description even if they make no particular reference to each other.

The invention thus provides the technical means described herein such as the parser the query performer the result processor etc. together with the related computer and network components and the software for solving one or more of the objects described at the outset.

Since the search is better directed or tailored processing network and computer time are reduced i.e. the search is performed faster and with less use of technical resources. That way less powerful computers and or less powerful network connections or network connections with a lower transmission rate such as wireless connections can be used to process the search within an acceptable time frame. Elements and resources on the web are used addressed and controlled in a novel technical way using different or differently expressed queries and commands for example data sources that may not contain relevant information are not queried and queries sent to other databases are better tailored to the search.

The technical modularity realized in the separated components parser and query performer as well as in the provision of vocabulary modules and data modules increases the flexibility and reusability of the system s components.

Further in a client server configuration all time consuming processing steps can be executed by the server such that the client side only needs to run a user interface and the traffic between them is reduced to a minimum because only the search is communicated from the client to the server and the results are fed back the other way. The invention is therefore ideally suited to be operated on mobile phones and other clients with a limited communication rate transmission speed .

From the user perspective the main advantages of the present invention are the increased speed the ability to perform effectively a natural language search the accuracy of the results and the reduced number of less relevant hits. The natural language search does not require to enter keywords in the correct grammatical order as is the case with other parsers e.g. grammar based parsers .

Exemplary and preferred embodiments of the invention will now be described in detail with reference to the accompanying drawings.

In this configuration the client is mainly used for entering a search query and displaying the results of the search while most of the actual processing is done by server . It is understood however that this is only one exemplary embodiment and that the search processing components could also be incorporated partially or in full in the same computer that is used for query entry.

The communication between the client and the server is routed through interface circuitry which works on a bidirectional basis.

Signals from interface circuitry including data representing a natural language search are routed line to parser which will be disclosed in more detail in . The parser whose main task is to process the query and generate a graph based logical intermediate representation communicates with one or multiple vocabulary modules and through connections and . As indicated by dots there may be more than 2 vocabulary modules there can also be only one . While the vocabulary modules are shown as part of the server they could also be located on the distributed network.

The vocabulary modules and communicate through bidirectional connections and with lexicons and or more of them as indicated by dotted line however it is also possible to have only one lexicon . The lexicons are preferably implemented as databases associating terms with resources on the web. They hold database tuples for mapping terms into tokens as will be explained below wherein each tuple usually contains

The purpose of the vocabulary modules and is to adapt the output of the parser to the structure and query language of the lexicons and . Parser and vocabulary modules communicate through well defined interfaces e.g. via HTTP where the output of the vocabulary modules can be expressed in an appropriate format e.g. as an XML encoded string. That way the token retrieval process is independent of the underlying database management system.

In dashed line symbolically represents the separation between the server and a distributed network. The network can e.g. be the World Wide Web on the Internet or another like network.

In the context of the present invention the lexicons and can be set up and constructed manually as well as using existing ontologies on the web. The possible employment of existing ontologies is expressed by a dotted representation that is the dotted ontologies and represent data corpora that were possibly employed for constructing the lexicons and in the first place as indicated by dotted connectors and . The dotted representation indicates that these elements need not be used during the actual processing of a search but rather have been used initially to set up the lexicons and . It is understood that this way of making syntactical information available is specific for the particular embodiment of the invention shown in and that other arrangements could be chosen. For example the vocabulary modules and could be placed on the network rather than inside the server.

The syntactic parser whose operation will be described in more detail below is connected line with a query performer . The query performer interacts bidirectional connections and with data modules and or more of them see dots . The data modules and in turn are connected bidirectional connections and with knowledge databases and or more of them see dots . The knowledge databases can be queried independently from their underlying database management system they can be located locally i.e. in the server e.g. as relational databases or be located and accessed on the web. Examples of remotely accessed knowledge databases are SPARQL endpoints e.g. provided by DBpedia or LinkedGeoData or Application Programming Interfaces APIs of data providers on the web.

In this context query performer executes several important tasks in conjunction with data modules and . The query performer receives a query in the form of an intermediate query representation which represents the semantic graph generated by the parser from parser connection and identifies the knowledge databases that may contain the requested information. For example if the query is related to information about a natural person relevant information may be found in a social network but not in a geospatial database accordingly the query performer may decide to contact the API of a social network but not the geospatial database. This is an important aspect of the present invention since it helps reducing processing and network time by avoiding contacting all available knowledge databases. Rather the hardware and software components of the invention are set up such as to communicate only with the relevant knowledge databases with respect to a query.

The data modules and transform the intermediate query representation into the relevant query language used by the associated knowledge database e.g. a SQL query for relational databases a SPARQL query for RDF repositories or a HTTP request for Application Programming Interfaces of external applications.

The response from the relevant knowledge database is then fed back to the query performer via data modules and and routed communication line to result processor . The result processor merges the results received from the various knowledge databases data modules to one result set removes redundant search results and ranks the results. The retrieved result set is returned and may contain meta data for a textual or visual output presentation. For example if the search retrieved location based entities these could be shown on a map which is displayed in addition to the result list. The generated result set of the result processor is then fed back communication line to interface circuitry which returns the result set in an appropriate format e.g. in XML to the client.

The operations inside the server are executed under control of a processor which is schematically indicated by reference numeral . Dotted lines and indicate the control lines to the various modules.

It is a very important aspect of the present invention that the underlying vocabularies lexicons vocabulary modules are independent separated from the parser by communicating through well defined interfaces. By means of this independence or modular architecture it is possible to add or remove new lexicons dynamically such that further vocabularies can be included independently of their underlying data format. Analogously the data modules querying knowledge sources for information retrieval are independent separated from the query performer . In this way new knowledge sources can be added or removed independently from the underlying database management system.

Turning now to the parser is shown in more detail. One of its main elements is the tokenizer which recognizes logical units within a query with employing one or multiple lexicons. The other major elements which form an important and novel aspect of the present invention are node generator sometimes herein also called node relationship generator for reasons to be explained below relationship generator and focus generator each of which employs a set of specified patterns. The three generators and are also referred to as semantic interpreter and could also be incorporated in a joint or common component. All these components will now be explained in detail.

For the scope of this invention the term tokenizer refers to the process of segmenting and identifying logical units referring to a semantic entity. It is not used uniformly throughout the literature.

The tokenizer first performs some syntactical steps to prepare a natural language query for the tokenization. Such preparation may include steps like the removal of punctuation marks putting the input sentence in lower case spelling removal of stopwords and or computing the words stems such as replacing plurals by the singular and or putting verbs into present tense.

After these preparatory steps the first main task of the tokenizer is to break up the query into terms i.e. a word or a set of words that are possibly referring to a semantic entity. This process is called segmentation herein. Typical segmentations of the exemplary natural language query birds of new zealand which will be used further herein to demonstrate the properties of the invention is depicted in one will note that in this example not all preparatory steps have been performed which is perfectly legitimate since birds is still in the plural and the word of could be considered as a stopword .

Reference is now made to the flow chart of in which the basic operating steps of the tokenizer are shown. After entering at START label and the input of the natural language query step the tokenizer counts the number of words in the query step and then executes the segmentation of the query into term sequences step . This is essentially the process described above with reference to .

After the segmentation the tokenizer executes a loop for each of the term sequences. The loop counter is called i reference number and it counts from 1 to the number of segmentations which is 2 2 8 in the given example as discussed above n the number of words is 4 .

During each execution of the loop the tokenizer sends reference number the relevant term j of a term sequence tsto a lexicon preferably through a vocabulary module cf. reference numerals and and in . This step is executed for each term tin the relevant term sequence ts as exemplified by a second inner loop with a counter j that counts the terms in a particular term sequence. The lexicon vocabulary module responds for each term in the term sequence ts with a token type an identifier u and a relevance factor r step . That way each term in the term sequences undergoes a mapping of the form t ts T u r 

wherein tis the term with the index j in the term sequence with index i and T is a token of token type with a URI u and a relevance factor r.

The URI has commonly a form like http dbpedia.org resource New Zealand and the relevance factor is typically a number between zero and 1.

In step the tokenizer computes the segmentation or term sequence ts with the highest probability of being correct. This is done by using the relevance factor r and will be explained below with reference to . Thereafter the tokenizer selects the segmentation or token sequence with the highest probability step which will be used for further processing after which operation of the tokenizer comes to an end step .

The step of selecting the segmentation or term sequence with the highest probability is now explained with reference to wherein two exemplary term sequences tsand tsof have been chosen. In ts the lexicon returns a zero set reference number in return to the query birds of reference number since the term birds of is not known or found. This also means that the probability for this term is 0. In contrast the term new zealand is found reference number such that the lexicon returns a relevance factor of 0.99 together with the information that this is an instance and the resource found is New Zealand reference number .

The probability that term sequence tsis appropriate is now calculated as follows The number of words in a term is divided by the total number of words in the term sequence and the result is multiplied by with the relevance factor. This process is repeated for all terms and the resulting probabilities for all terms are added up to give the total probability that the chosen term sequence is the correct one. For ts this reveals 2 4 0 2 4 0.99 0.495

The second example in relates to term sequence ts with a segmentation into birds reference number of reference number and new zealand reference number . birds is found with a relevance factor of 0.99 reference number of is not found and returns the zero set with a relevance factor of 0 reference number and new zealand is found with a relevance factor of 0.99 reference number . The probability equation for tsthus becomes 0.99 0 2 4 0.99 0.7425

It can be easily seen that the probability for tsis higher than the probability for ts. In fact when calculating the probabilities for all term sequences it turns out that tshas the highest probability of all term sequences and will therefore be chosen by the tokenizer as the segmentation with the highest probability see step in .

The output of the tokenizer i.e. the tokens of the term sequence with the highest probability is then transferred to the semantic interpreter of parser . depicts its basic diagram to illustrate its functionality. The inner structure and functionality of the parser s semantic interpreter is considered one of the major contributions of the present invention. The semantic interpreter generates a graph based representation of the query which represents entities as nodes and relations between those entities as directed labeled edges connecting those nodes.

Returning to the input to the semantic interpreter is shown by box . By way of example the input consists of 3 tokens and which are labeled a b and c and which are fed to the semantic interpreter reference number . Tokens a b and c could e.g. be classes instances roles or constraints as described above. The semantic interpreter or node relationship focus generator actually has three main components namely the node generator or node relationship generator the relationship generator and the focus generator . These are the same elements already schematically depicted in .

While the 3 generators and can be described as separate components with different functionalities one could also say that they are sub components of the semantic interpreter node relationship focus generator . This is merely a matter of convenience. Both descriptions apply equally to the present invention. For the purposes of this description the generators are shown in the figures as individual components of the semantic interpreter but other descriptions could be chosen.

The input to the semantic interpreter is first fed reference number to node generator which generates the nodes and some implied relations for the graph based representation. This is indicated by nodes and . It is important to note that some tokens require the node generator to generate not only a node relating to a token but also a relationship associated with such token. This is for example the case for a token representing a class or a role as will be shown below. It is however important to note that all relations generated by the node generator each relate only to the particular token and not to the relationships with its peer tokens. This distinguishes the node generator from the relationship generator . However in the light of these explanations it will be appreciated than node generator could and will also be designated as node relationship generator .

As shown in the schematic overall diagram of node generator generates three nodes a b and c labeled as and corresponding to the input tokens and then passes control to the relationship generator line . The relationship generator creates the missing relations between the nodes here indicated by reference numerals and . Schematically the relations are connections between the nodes labeled with x and y to indicate that these relations are presently unknown.

Control is then passed to the focus generator reference numeral . The purpose of the focus generator is to select one of them as the query s major information request called focus and generate an appropriate search query for the chosen focus.

In the example shown in the focus generator has chosen token a as the graph s focus variable which is thus labeled a F represents the label focus .

The generated labeled graph can also be denoted using a triple based notation which represents the base for the intermediate query representation which is then passed lines and to the output which is the query performer .

Operation of the three generators and will now be explained in more detail by means of the following figures. is a simplified table like representation of various node patterns of the node relationship generator . A token which is characterized as t t u r wherein tis the term identifier is the token type u is a uniform identifier and r is a relevance factor is transformed into an annotation representing the generated nodes plus some relations related to the particular token . As can be easily seen a token with i instance is transformed into just a corresponding instance node n. In contrast a token with c class is considered a set of entities of the specific class the token is thus transformed into a non terminal node x representing a set of entities connected with a class node n the two nodes are connected through a relation indicating that x is of the type n. Similar considerations apply to a token with r relation generation of two non terminal nodes representing unknown variables x and y connected by a relationship and to a token with ct constraint e.g. a height or an age where one node is a non terminal node and the other represents the actual numerical value of the restriction. It is understood that the table of is of exemplary character only and that an actual implementation may cover more token types.

In a more sophisticated approach the node generator identifies the most probable pattern and maps the input sequence s elements to entities of the pattern s expression. The most probable pattern for a token sequence is the one whose expression resembles the token sequence the most i.e. the pattern which maximizes the similarity function of a token input sequence and the pattern s expression. The similarity between a token sequence and an expression is computed in terms of a string similarity function. The following listing shows some examples of a mapping of node patterns with the token element indicated by a temporal identifier here a and their truth value indicated in brackets at the end of each line 

pindicates the interpretation of a class token which corresponds to a non terminal node x representing a set of entities of the corresponding class c . pproduces a direct transition from an instance token into an instance node i while pgenerates a labeled branch p with undefined nodes from a role token. pdescribes the processing of a constraint token which consists of a property and a value restriction. pgenerates a branch with the token s label as the branch s label and its value as the branch s object node.

Note that a pattern also may contain new nodes with a pre defined URI. URIs were depicted in the Figures in a short form e.g. rdf while the URI prefix is defined in the PREFIX preamble.

Once the most probable pattern has been computed the node generator computes a mapping between the token sequence and the expression sequence which assigns input tokens to expression tokens. The output sequence is indicated by the pattern s annotation by generating an output sequence from the expression. If the annotation contains an element of the expression for which no element of the input sequence could be found the node generator generates a non terminal node.

The output of the node generator is the first stage of the semantic graph G which may consist of a set of nodes and a set of branches.

A simplified operating scheme of the relationship generator is shown in depicting some sample relationship patterns pand p. The relationship generator receives the intermediate graph stage G generated by the node generator employing a set of relationship patterns in order to identify further relationships between the graph s nodes. p provides a simple pattern indicating that a non terminal node of a specific class and an instance node are connected with a non terminal relation y . p merges an instance node and a branch with undefined nodes substituting the object node of the branch z with the actual instance node . The output of the relationship generator is the graph stage G.

The employment of a simple relationship pattern pis shown in . The relationship generator receives G and employs a pattern which connects a non terminal node of a specific class and an instance node with a non terminal branch . The output of the relation generator is the second stage of the semantic graph G.

Focus generator is the third element of the semantic interpreter. Its primary task is to identify the focus of the query among more than one non terminal nodes and non terminal relations using focus patterns. shows two simple focus patterns p p identifying a non terminal element as the graph s focus The annotation indicates the focus x wherein F designates the focus .

The employment of a focus pattern is depicted in . The focus generator receives a graph G computed by the relation generator identifies the most probable focus pattern with respect to Gand identifies a non terminal element as the graph s focus. In the pattern s expression consists of a non terminal node connected by a non terminal branch with an instance token where the annotation identifies the non terminal node as the query s focus. Employing this pattern on the input graph G the focus generator associates the appropriate elements of the graph with elements of the pattern expression identifying the non terminal node x as the graph s focus. As mentioned above if a non terminal node that is connected to a single class node is selected as a focus the corresponding class node is identified as the query s focus type indicating the type of entities the query searches for. In this example the focus pattern not only designates the focus x but also indicates that class c is the query s focus type FT. This is reflected in the output of the focus generator wherein the class node with the URI ontology Birdis determined as the focus type indicator FT.

An example of an output of the focus generator the graph stage Gconsisting of a set of nodes branches and a focus is shown in . The graph contains all the necessary elements to produce a search query. Element is a non terminal node which is also the query s focus. It represents one or multiple entities characterized to be instances of a specific class here birds which also represent the query s focus type indicated by the branch . is an instance namely New Zealand . Elements and are connected through a non terminal relation y .

As mentioned earlier the generated graph can also be expressed using a triple based annotation which is the base for the intermediate query representation that is transmitted to the query performer. For example the graph in can simply be re written in the following triple based notation 

The whole process performed by the semantic interpreter i.e. the node generator the relationship generator and the focus generator for the above example of birds of new zealand is schematically shown in which is a representation of with a concrete example. The same reference numerals have been used for like elements.

The tokenizer has identified a class token bird and an instance token new zealand . These tokens are shown as c reference numeral and i reference numeral . The node generator transforms these into elements non terminal node x rdf type relation and terminal class node c and terminal instance node i resulting the graph G. The relationship generator complements non terminal relation y reference numeral and thus computes G. The focus generator finally selects non terminal node as the query s focus x the final semantic graph is computed in G.

