---

title: Predicting long-term computing resource usage
abstract: Techniques are described for performing automated predictions of program execution capacity or other capacity of computing-related hardware resources that will be used to execute software programs in the future, such as for a group of computing nodes that execute one or more programs for a user. The predictions that are performed may in at least some situations be based on historical data regarding corresponding prior actual usage of execution-related capacity (e.g., for one or more prior years), and may include long-term predictions for particular future time periods that are multiple months or years into the future. In addition, the predictions of the execution-related capacity for particular future time periods may be used in various manners, including to manage execution-related capacity at or before those future time periods, such as to prepare sufficient execution-related capacity to be available at those future time periods.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09106589&OS=09106589&RS=09106589
owner: Amazon Technologies, Inc.
number: 09106589
owner_city: Reno
owner_country: US
publication_date: 20140708
---
This application is a continuation of co pending U.S. patent application Ser. No. 13 937 036 filed Jul. 8 2013 which is hereby incorporated by reference in its entirety. Application Ser. No. 13 937 036 is a continuation of co pending U.S. patent application Ser. No. 12 961 285 filed Dec. 6 2010 which is hereby incorporated by reference in its entirety. Application Ser. No. 12 961 285 is a continuation in part of U.S. patent application Ser. No. 12 950 630 filed Nov. 19 2010 and entitled Predictive Governing of Dynamic Modification of Program Execution Capacity which is now U.S. Pat. No. 8 346 921.

The advent of virtualization technologies for commodity hardware has provided some benefits with respect to managing large scale computing resources for many users with diverse needs allowing various computing resources to be efficiently and securely shared by multiple users. For example virtualization technologies such as those provided by VMWare XEN Linux s KVM Kernel based Virtual Machine or User Mode Linux may allow a single physical computing machine to be shared among multiple users by providing each user with one or more virtual machines hosted by the single physical computing machine with each such virtual machine being a software simulation acting as a distinct logical computing system that provides users with the illusion that they are the sole operators and administrators of a given hardware computing resource while also providing application isolation and security among the various virtual machines.

Techniques are described for performing automated predictions of execution related capacity that will be used by one or more clients in the future such as program execution capacity used to execute software programs for one or more users or other capacity of computing related hardware resources used by one or more users. In at least some embodiments the predictions that are performed are based on historical data regarding corresponding actual prior usage of execution related capacity e.g. for one or more prior years and may include long term predictions for particular future time periods that are multiple months or years into the future. In addition the predictions of the execution related capacity for particular future time periods may be used in various manners in various embodiments including to manage execution related capacity at or before those future time periods such as to prepare sufficient execution related capacity to be available at those future time periods. As one illustrative non limiting example the described techniques may in some embodiments be used to predict and manage execution related capacity that is used by a group of computing nodes that act as Web servers for one or more Web sites such as to predict an amount of Web traffic that will be handled by that computing node group e.g. based on remote client requests for Web pages of a Web site or of a portion thereof or for other types of functionality provided by a Web site . In at least some embodiments the automated techniques for generating predictions of execution related capacity to be used at multiple future times is performed by an embodiment of an automated execution capacity management system. Additional details are included below related to techniques for generating predictions of execution related capacity to be used at multiple future times.

In at least some embodiments the execution related capacity being predicted and managed includes a group of one or more computing nodes that are provided for use in executing one or more software programs. In addition such a group of computing nodes being used to execute one or more software programs may be dynamically modifiable while in use in at least some such embodiments and thus enable an amount of execution related capacity that is available to the user from the computing nodes of the group to be managed while the computing node group is in use. The modifications to the group of computing nodes associated with a user may have various forms in various embodiments e.g. to modify a quantity of computing nodes in the group such as by dynamically adding and or removing computing nodes and may be initiated in various manners in various embodiments. In addition in at least some embodiments the dynamic modification of the execution related capacity is automatically governed by an embodiment of the execution capacity management system such as an execution capacity management system that is part of or otherwise operates in conjunction with a program execution service PES that manages the execution of multiple programs on behalf of multiple customers or other users of the service. In particular in at least some embodiments the execution capacity management system generates predictions of execution related capacity that will be used at each of multiple future times by a group of computing nodes for execution of one or more software programs and then later at one or more of those future times uses the predicted execution related capacity for that time to govern the dynamic modification of the capacity that is available at that time and or to provide other benefits related to the use of the execution related capacity. Additional details are included below related to the dynamic modification of execution related capacity available from a group of computing nodes and to the automatic governing of such dynamic modification.

In some embodiments discussed below the execution related capacity being managed includes program execution capacity used to execute software programs for one or more users. However it will be appreciated that the described techniques may in at least some embodiments be used to manage resource usage capacity that includes access to various types of computing related resources or other hardware resources including in some situations for purposes other than execution of one or more software programs. A non exclusive list of examples of types of hardware resources that may be managed for use by multiple users in accordance with the described techniques include the following persistent data storage capabilities e.g. on non volatile memory devices such as hard disk drives temporary data storage capabilities e.g. on volatile memory such as RAM message queuing and or passing capabilities other types of communication capabilities e.g. network sockets virtual communication circuits etc. database management capabilities dedicated bandwidth or other network related resources input device capabilities output device capabilities CPU cycles or other instruction execution capabilities multiple devices that provide a common type of functionality multiple devices from a common manufacturer or other source multiple devices that are grouped together by the execution capacity management system e.g. in a common pool etc.

When managing program execution capacity used to execute one or more software programs for a user the dynamic modifications that are performed to a group of computing nodes that is in use executing the one or more programs may have various forms and may be initiated in various manners in various embodiments. As one example the program execution capacity of the group of computing nodes may be measured at least in part by the quantity of computing nodes that are part of the group and may be modified by changing the computing node quantity of the group e.g. to increase the program execution capacity by increasing the computing node quantity and to decrease the program execution capacity by decreasing the computing node quantity . In addition a PES or other system that is managing the computing nodes of a group that is in use executing one or more programs for a user may automatically determine to make dynamic program execution capacity modifications for the computing node group in various manners. For example in at least some embodiments and situations the user may dynamically supply specified modification instructions while in other embodiments and situations requests to make dynamic program execution capacity modifications for the computing node group may be based at least in part on one or more of automated determinations that triggers previously defined by the user are currently satisfied of automated operations of a service that is providing the computing nodes of the group etc. Similar techniques apply to managing hardware resources in other situations and additional details are included below related to the dynamic modification of program execution capacity available from a group of computing nodes.

As previously noted in at least some embodiments the dynamic modification of program execution capacity or other resource usage capacity being provided to a user may be automatically governed by an embodiment of an execution capacity management system ECMS . In particular in at least some embodiments the execution capacity management system generates predictions of capacity that will be used at each of multiple future times by a group of computing nodes e.g. for execution of one or more software programs and then later at one or more of those future times uses the predicted capacity information for that time to govern the dynamic modification of the capacity being provided at that time and or to provide other benefits related to the use of the capacity.

The prediction of future program execution capacity usage or other resource usage capacity may be performed in various manners in various embodiments and in at least some embodiments includes generating a range of predicted future capacity usage amounts for each of one or more times such as with a mean or midpoint or other average value for each such range as well as upper and lower bounds for each such range. In some embodiments the predictions of future capacity usage may include long term predictions such as for future times that are days weeks months years etc. into the future and in some embodiments the predictions of future capacity usage may include short term predictions such as for future times that are minutes hours etc. into the future. For example in some embodiments and situations information is obtained about historical execution of a particular program by a particular user such as the amount of program execution capacity or other resource capacity that was historically used at one or more prior times and that historical information is assessed and adjusted to create predictions of future capacity that will be used at one or more future times. In addition in some embodiments and situations information is obtained about recent activity that has occurred and that recent activity information is assessed and adjusted to create predictions of future program execution capacity or other resource capacity that will be used at one or more future times when predicting such future capacity to be used for a particular software program and particular user such recent activity information may for example reflect ongoing execution of that particular program for that particular user e.g. performance characteristics related to that ongoing execution or instead may have other forms e.g. based on recent or ongoing execution of that particular program for a related user recent or ongoing execution of a related program for that particular user etc. .

Short term predictions of future program execution capacity may be made in various manners in various embodiments and in some embodiments may include obtaining information about recent program execution capacity or other recent activity information related to executing one or more software programs of interest and generating predicted future program execution capacity information for one or more future time intervals or future time points that are based in part on that recent activity such as based on performing regression and or extrapolation e.g. based on exponential smoothing . For example a forecasting model may be used to generate three values for each future time interval of interest e.g. every five minutes from the current time into the future for a specified length of time such as for the next 24 hours every hour from the current time into the future for a specified length of time such as for the next 24 hours etc. for a particular group of computing nodes to execute one or more software programs for one or more users with the first value being a predicted execution capacity amount and the remaining two numbers being upper and lower bound values above and below the first value e.g. by using statistical modeling of a margin for error such as a standard deviation a probabilistic assessment of a specified degree of likelihood etc. . The predicted range of values for each such time interval may also optionally be updated as additional information becomes available about recent activity e.g. may be updated after each time interval based on information about the ongoing execution by the particular group of computing nodes during the most recent time interval may be updated every six hours etc. . A non exclusive list of types of forecasting models that may be used to generate such short term predictions include the following exponential smoothing of historical time series data or other historical data such as using the standard Holt Winters algorithm a double seasonal Holt Winters algorithm etc. using an autoregressive moving average ARMA or Box Jenkins model using an autoregressive integrated moving average ARIMA model using other regression and or extrapolation models etc. It will be appreciated that similar techniques may be used for short term predictions of other types of future resource usage capacity e.g. use of hardware resources of one or more types in other embodiments.

Long term predictions of future program execution capacity may be made in various manners in various embodiments and in some embodiments may include obtaining historical program execution capacity information that has time series data over multiple time intervals of interest e.g. multiple days multiple hours etc. and the predicted future program execution capacity information may similarly include predicted time series data over a future period of time e.g. a future period of days weeks months years etc. that includes multiple of those time intervals or that includes multiple time intervals of a different size such as to aggregate multiple historical time intervals into each longer future time interval to disaggregate each historical time interval into multiple shorter future time intervals etc. . The long term prediction of future program execution capacity may in some embodiments include performing one or more of the following non exclusive activities calculating a day of week average of program execution capacity that was used from historical data calculating an average month of year variation of program execution capacity that was used from the historical data estimating a year to year change in program execution capacity optionally based on multiple years of historical data identifying predictable future events that will affect program execution capacity in atypical manners not reflect in day of week month of year and year to year variations such as a holiday season that is not captured in average monthly variations a particular planned item feature release or advertising campaign or other activity that will affect program execution capacity etc. generating predicted average program execution capacity amounts for particular future time intervals based on information from some or all of the prior activities adding upper and lower bounds for some or all predicted program execution capacity amounts for particular future time intervals such as to reflect generated uncertainty for and or confidence intervals for particular predicted program execution capacity amounts etc. It will be appreciated that similar techniques may be used for long term predictions of other types of future resource usage capacity e.g. use of hardware resources of one or more types in other embodiments. Additional details related to such long term predictions are included below.

In other embodiments the prediction of future program execution capacity may be performed in other manners including one or more of the following non exclusive list for only a single future time for only a single predicted program execution capacity amount for a particular future time without using and or generating time series data for only short term predictions for only long term predictions in a manner that is not specific to any particular software programs e.g. for a particular user based on that user s prior use of program execution capacity for one or more programs in a manner that is not specific to any particular user e.g. for a particular software program based on prior program execution capacity used for that software program by one or more users in a manner that is not specific to any particular software programs or any particular users e.g. based on a quantity of computing nodes or other measure of program execution capacity that is used at one or more times etc. Additional details related to generating predicted future program execution capacity are included below.

After information is obtained by the execution capacity management system that indicates predictions of program execution capacity amounts at one or more future times for a group of computing nodes executing one or more software programs e.g. after that prediction information is dynamically generated by the execution capacity management system or is otherwise received by the execution capacity management system the execution capacity management system uses the predicted program execution capacity information in at least some embodiments to govern the dynamic modification of the program execution capacity at one or more future times. In particular the execution capacity management system treats the predicted program execution capacity information for a group of computing nodes at a particular future time in at least some embodiments as being pre authorized or otherwise indicating allowable execution capacity for that group of computing nodes at that future time such that a request to dynamically modify the program execution capacity for that group of computing nodes at that future time will be automatically authorized by the execution capacity management system if the requested amount of program execution capacity is within a range of predicted program execution capacity values for that future time or is otherwise one of one or more predicted program execution capacity values for that future time. Conversely in some embodiments the automatic authorization by the execution capacity management system of a requested amount of program execution capacity for a dynamic modification to a group of computing nodes for a user may be based only in part on such predicted program execution capacity information such as if the automatic authorization also includes determining that one or more other specified criteria are satisfied. Such other criteria may be specified by for example the user the program execution service the execution capacity management system etc. and may have various forms e.g. criteria related to a threshold percentage or absolute change in the program execution capacity to a threshold percentage or absolute change or absolute amount in fees charged by a program execution service to the user to provide requested program execution capacity to a current amount owed or other balance of the user with respect to the program execution service and or execution capacity management system etc. .

Alternatively if the execution capacity management system determines that a request to dynamically modify the program execution capacity for a group of computing nodes for a user at a future time is not one of one or more predicted program execution capacity values for that future time the execution capacity management system may take other actions. For example in some embodiments and situations the execution capacity management system may deny such a request for dynamic modification while in other embodiments and situations the execution capacity management system may identify and perform an alternative dynamic modification that provides an altered amount of program execution capacity that is different from the current amount and from the requested amount. As one example if the requested amount of program execution capacity for a dynamic modification at a particular time is above a highest predicted program execution capacity amount for that time e.g. above an upper bound of a range for that time or otherwise above a highest of one or more predicted amounts the altered amount of program execution capacity that is automatically identified may be that highest predicted program execution capacity amount. Similarly if the requested amount of program execution capacity for a dynamic modification at a particular time is below a lowest predicted program execution capacity amount for that time e.g. below a lower bound of a range for that time or otherwise below a lowest of one or more predicted amounts the altered amount of program execution capacity that is automatically identified may be that lowest predicted program execution capacity amount. In yet other embodiments the execution capacity management system may take further actions if a requested amount of program execution capacity for a group of computing nodes for a user at a future time is determined to not be one of one or more predicted program execution capacity values for that future time such as one or more of the following non exclusive list notifying the user of the requested amount of program execution capacity and or of the determination prompting the user to provide manual approval of the requested amount of program execution capacity and proceeding to provide the requested amount if such approval is obtained prompting the user to provide manual approval of an automatically identified altered amount of program execution capacity and proceeding to provide that altered amount if such approval is obtained deferring the requested amount of program execution capacity until a later time at which the requested amount is within a range of predicted execution capacity values for that later time etc.

In addition in some embodiments the execution capacity management system may use predicted program execution capacity information for a group of computing nodes for a user to provide other benefits whether in addition to or instead of using the predicted program execution capacity information to automatically govern dynamic modifications of the program execution capacity for the group. For example in some embodiments the predicted program execution capacity information for a group of computing nodes for a user may be used to automatically govern the program execution capacity of the group by automatically initiating changes for the group in advance of any user specified or automatically determined requests such as if the execution capacity management system initiates acquisition and or provisioning of additional computing nodes to be added to the group based on an expected or possible future request to use those additional computing nodes in the group such advance provisioning may include for example determining that a predicted program execution capacity value for a current or a future time e.g. an average or otherwise expected predicted value for the time is above the current program execution capacity for the group e.g. by at least a specified threshold and initiating the provisioning immediately e.g. if the predicted program execution capacity value is for the current time or at a selected time in the future e.g. if the predicted program execution capacity value is for a future time at a time this is sufficiently prior to that future time to allow the computing nodes being provisioned to be available at that future time such as based on an amount of time that the provisioning lasts .

As previously noted in some embodiments the execution capacity management system may be part of or otherwise operate in conjunction with a program execution service such that the automatic governing by the execution capacity management system for a group of computing nodes being managed by the program execution service for a user is automatically performed by the execution capacity management system and program execution service without concurrent review and or approval by the user. In other embodiments the execution capacity management system may be used in other manners such as if a particular user executes a copy of the execution capacity management system and the automatic governing by the execution capacity management system for a group of computing nodes includes various other actions taken by the execution capacity management system e.g. if the group of computing nodes is being provided by a separate program execution service taking actions that include sending corresponding instructions from the execution capacity management system to the program execution service . In yet other embodiments the execution capacity management system may be operated by an entity that is a third party to one or more program execution services and to one or more users that are customers of the execution capacity management system e.g. for a fee such that the execution capacity management system performs some or all of the described techniques e.g. the generating of predicted program execution capacity information and or the automatic governing of program execution capacity of a group of computing nodes based on predicted program execution capacity information on behalf of those one or more users and or those one or more program execution services. Furthermore a user who interacts with the program execution service and or the execution capacity management system may have various forms in various embodiments such as an individual human person an executing software program a group or business or other entity that may optionally have one or more human representatives etc.

The described techniques for automatically governing dynamic program execution capacity modifications based on predicted information may provide various benefits in various situations. For example the techniques allow a user to predefine various types of capacity modification triggers that make requests for dynamic program execution capacity modifications for a group of computing nodes based on various factors e.g. based on performance characteristics of the group of computing nodes but with the changes to the program execution capacity being automatically limited to amounts that have been predicted to be reasonable or likely or otherwise allowable for a particular time such as to automatically prevent automated changes that are significantly outside of typical or otherwise expected values. Such automated triggers may have various uses e.g. to reactively increase the program execution capacity of a group of computing nodes to accommodate a temporary increase in the computing load for the computing node group to proactively increase or decrease the program execution capacity of a group of computing nodes to accommodate an expected upcoming need for additional program execution capacity and or an expected upcoming lack of need for existing program execution capacity such as based on trends over time in particular performance characteristics and or historical data indicating recurring patterns of program execution capacity use etc. . Alternatively a user may desire to maintain the program execution capacity for a group of computing nodes at or near a specified level e.g. a specified desired constant quantity of computing nodes and various modifications may be automatically made to the group of computing nodes to maintain the available program execution capacity at that specified level e.g. to return an actual computing node quantity that has deviated from the specified desired quantity back to that specified desired quantity . Such techniques may be of use for example when each of the computing nodes of the group executes a distinct copy of the same program e.g. to serve as alternatives for an aggregate computing load over the group and the quantity of computing nodes are modified to manage the amount of work handled by each computing node or otherwise in situations in which the various computing nodes of a group do not each execute a distinct copy of the same program e.g. if distinct subsets of the group computing nodes each execute copies of different programs such as to have some computing nodes execute an application server program and to have other computing nodes execute an associated database server program if some or all of the computing nodes perform different parts of a single program such as in a distributed manner etc. . Furthermore when adding additional computing nodes to a group the PES or other system may further optionally take other actions in at least some situations such as to provision the added computing node to be ready to execute one or more programs or to further automatically initiate the execution of the one or more programs on the added computing node.

As previously noted the dynamic modifications that are performed to a group of computing nodes that is in use executing one or more programs for a user may have various forms and may be initiated in various manners in various embodiments. For example in at least some embodiments and situations the PES or other system may make some types of program execution capacity modifications in an immediate manner while other types of program execution capacity modifications may be performed periodically or otherwise in a recurrent manner e.g. so as to defer and aggregate multiple modifications that are requested or otherwise determined to be made during a period of time . If multiple program execution capacity modification determinations are aggregated over a period of time information about the aggregated modification determinations may be used to enhance the performance of the program execution capacity modifications in various manners. For example if two determined program execution capacity modifications correspond to opposite types of modifications e.g. to increase and decrease computing node quantity to increase and decrease available aggregate memory etc. the two modifications may be aggregated in various manners such as by being selected to partially or completely offset each other or instead by selecting a higher priority of the two modifications to be performed in lieu of the other modification. In addition if two or more determined program execution capacity modifications correspond to similar or complementary types of modifications e.g. to all increase computing node quantity by specified amounts to all increase available aggregate memory by specified amounts etc. those determined modifications may similarly be aggregated in various manners e.g. to select a single determined modification that satisfies some specified criteria such as the largest the smallest the one with the highest priority the one that was determined first the one that was determined last etc. to accumulate the various determined modifications and use the accumulated modification amount etc. .

In addition the program execution capacity of a group of computing nodes may in some embodiments be measured at least in part by the quantity of computing nodes that are part of the group and may be modified by changing the computing node quantity of the group. Such computing node quantity modifications may be used for example in situations in which some or all of the computing nodes in the group provide or have access to the same or similar amounts of computing resources e.g. amounts of memory hard drive space CPU execution cycles network bandwidth etc. such that a given percentage change in computing node quantity corresponds to the same or similar percentage change in total computing resources and program execution capacity of the group. In other embodiments some or all of the computing nodes of the group may differ in one or more significant manners with respect to the amount of computing resources to which they have access e.g. if two or more distinct types of computing node configurations are used if each computing node is configured independently of the other computing nodes etc. or otherwise with respect to the types of program execution capacity that they provide e.g. based on specialized hardware types of software programs etc. but dynamic program execution capacity modifications for the group may nonetheless be based at least in part on modifying a quantity of the computing nodes of the group or instead may be based in other manners e.g. changing from one type of computing node configuration to another as discussed in greater detail elsewhere.

Furthermore in at least some embodiments and situations the program execution capacity of a group of one or more computing nodes may be measured and modified in manners other than a quantity of the computing nodes such as based on an aggregate amount of one or more types of computing resources provided by the group e.g. amounts of memory hard drive space CPU execution cycles network bandwidth etc. . In addition in at least some embodiments additional factors may be considered in measuring and specifying program execution capacity for a group of computing nodes such as a geographical location of some or all of the computing nodes inter relationships between some or all of the computing nodes e.g. to be separated by at most a maximum geographical distance or at least a minimum geographical distance to be separated by at most a maximum network latency or at least a minimum network latency to be separated into two or more independent data centers or other computing node collections that are unlikely to fail simultaneously etc. availability of specialized hardware capabilities and or software capabilities etc. Additional details related to measuring and specifying program execution capacity are included below.

As previously noted users may predefine various types of triggers related to dynamically modifying program execution capacity for groups of computing nodes and those triggers may be later used to initiate corresponding automated dynamic program execution capacity modifications for computing node groups of the users. As one example a trigger may be defined that specifies a particular desired quantity of computing nodes or desired aggregate amount of one or more computing resources such as may be used to automatically maintain a corresponding computing node group at that desired computing node quantity or desired aggregate computing resource amount or instead to change to a specified computing node quantity or aggregate computing resource amount if specified criteria are satisfied. In other situations a trigger may be defined that specifies a particular absolute or relative change in computing node quantity or aggregate amount of one or more computing resources such as may be triggered if one or more indicated performance characteristics of the computing node group reach a specified threshold or otherwise satisfy a specified criteria e.g. remain within a specified range for a specified period of time show a particular trend such as a specified amount of change over a specified period of time or such as a particular acceleration or rate of change match or other correspond to one or more specified patterns such as from historical data that indicates recurring patterns of program execution capacity use satisfy a specified logical or other combination of values for multiple performance characteristics such as may be combined using logical operators such as AND NOT OR etc. and or in other manners etc. . In other embodiments and situations a predefined trigger may be otherwise satisfied based on information that is not part of the performance characteristics of the computing node group e.g. based on a current time matching one or more specified times that are part or all of the criteria for a particular trigger based on status information for one or more programs being executed on the current computing node group that is measured in manners other than performance characteristics such as a current computing load as indicated by for example an amount of work that is queued for or otherwise known or expected to be performed by the one or more programs based on performance characteristics or other status information for one or more other executing programs that are not being executed by the current computing node group such as if the current computing node group is interacting with or otherwise supporting the other executing programs so as to for example increase the program execution capacity of the current computing node group as the computing load on the other executing programs increases or decreases etc. . Such performance characteristics may be based on any measurable attribute of or other metric corresponding to the operation of one or more of the computing nodes of the group including the following non exclusive list an absolute or relative amount of use of one or more computing resources of a single computing node e.g. a percentage amount of available memory being used or CPU cycle utilization an absolute amount of network bandwidth being used etc. an absolute or relative amount of aggregate use of one or more computing resources of all of the group computing nodes an absolute or relative amount of latency or other delay in responding to communications from external computing systems an absolute or relative amount of failures of the computing nodes in performing one or more desired actions etc. Furthermore in at least some embodiments and situations rather than having a trigger directly specify a particular program execution capacity modification that is to occur when it is satisfied the satisfaction of the trigger may cause a designated system or module to be notified and that system or module may request a particular program execution capacity modification e.g. a predefined capacity modification that does not vary a capacity modification that is dynamically determined at the time of the notification such as based on then current conditions etc. . In addition the PES or other system may in some embodiments perform various operations to monitor a group of computing nodes in order to determine some or all of the performance characteristics for the triggers associated with the group or may otherwise obtain such monitored performance characteristics from another source e.g. from third party software that monitors the computing nodes from software executing on a computing node to monitor that computing node and optionally report the monitored information etc. . Furthermore in some embodiments the PES or other system may have system defined triggers that initiate dynamic program execution capacity modifications when indicated trigger criteria are satisfied or may otherwise automatically determine to make some types of changes to computing node groups in specified circumstances.

When a defined trigger specifies a particular absolute or relative change in computing node quantity or aggregate amount of one or more computing resources and the modification is automatically authorized by the execution capacity management system the PES or other system may automatically determine how to perform the specified program execution capacity modification for the trigger. For example some types of specified program execution capacity modifications may be performed immediately e.g. a request to terminate use of one or more computing nodes a request based on a trigger that the user has designated for immediate performance etc. while other types of specified program execution capacity modifications may be deferred for a period of time in at least some situations. Similarly program execution capacity modifications that are dynamically requested by a user e.g. via a GUI or graphical user interface of the PES or other system by a program of the user via a defined API or application programming interface of the PES or other system etc. may be determined to be performed immediately and or temporarily deferred in a similar manner such as based on the type of dynamic program execution capacity modification based on an explicit request from the user for immediate or deferred performance etc. Additional details related to using user defined triggers and determining performance characteristics are included below.

In the example of various users not shown are using various client computing systems to interact over a network with the PES which is provided in this example by an entity not shown who also provides the execution capacity management system in conjunction with the PES . The various users may or may not be aware of the operations that are performed by the execution capacity management system and or of the existence of the execution capacity management system . In this example at least some of the functionality of the PES is provided by a System Manager module of the PES and other functionality may optionally be provided by other modules not shown of the PES . The module may for example assist particular users in configuring groups of computing nodes to be used to execute programs for the users including specifying initial desired computing node quantities for the groups and specifying triggers for use in later automatically making dynamic modifications to the computing node quantities. In this example the PES makes various computing nodes available for executing programs of the users although in other embodiments at least some of the computing nodes used for at least some of the groups may be provided in other manners e.g. made available by the users and or by third parties such as external computing systems but managed by the PES . In addition one or more modules of the PES may assist in continuously or repeatedly monitoring computing node groups that are in use and optionally attempting to replace any computing nodes that fail or otherwise become unavailable so as to maintain program execution capacity at previously determined levels.

As the PES provides groups of computing nodes for use by various users the PES interacts with the ECMS to provide additional functionality to benefit the users such as in response to fees charged to the users by the PES and or the ECMS . In particular the illustrated embodiment of the ECMS includes a Capacity Prediction Manager module that generates predictions of program execution capacity amounts that are expected to be used by particular groups of computing nodes at particular future times such as based at least in part on historical information from the PES about prior execution capacity amounts used by those groups or related groups and or on current or recent information from the PES about ongoing operation of those groups or related groups . Furthermore the illustrated embodiment of the ECMS includes a Capacity Governing Manager module that performs actions to automatically govern dynamic modifications made to groups of computing nodes provided by the PES based at least in part on previously made predictions from the module of program execution capacity amounts that are expected to be used those groups of computing nodes. The operations of the modules and may include various interactions with the PES such as to obtain historical information provide generated predicted information receive information about requests for dynamic modification of program execution capacity of particular computing node groups provide instructions based on the automatic governing about whether and how to satisfy particular dynamic modification requests etc. Additional details are included elsewhere about the generating of predicted program execution capacity amounts and the automatic governing of requests for dynamic modification of program execution capacity based on the generated predicted information.

The network may for example be a publicly accessible network of linked networks possibly operated by various distinct parties such as the Internet. In other embodiments the network may be a private network such as for example a corporate or university network that is wholly or partially inaccessible to non privileged users. In still other embodiments the network may include one or more private networks with access to and or from the Internet. In the illustrated embodiment the modules and may each include software instructions that execute on one or more computing systems not shown . In addition the modules and various computing nodes may be provided in various manners such as at a single data center or otherwise to use a group of co located computing systems or instead in a distributed manner using various computing systems in various distinct geographical locations.

In some embodiments the illustrated computing nodes may include multiple physical computing systems and or multiple virtual machines that are hosted on one or more physical computing systems as is described in more detail with respect to . Each of the computing nodes has some amount of computing resources available for executing one or more programs which provide a specific amount of program execution capacity such as may be measured for example by a quantity of one or more such computing nodes and or by a combination of one or more of processing capacity e.g. number and or size of processing units memory capacity storage capacity network bandwidth capacity etc. In some embodiments the PES provider may provide preconfigured computing nodes with each preconfigured computing node having equivalent or otherwise similar amounts of resources available for executing programs on behalf of users while in other embodiments the PES provider may provide a selection of various different computing nodes from which a user may choose for executing programs on behalf of the user such as with each selection having varying amounts and or types of computing resources e.g. size speed and or type of processing units number of processing units amount of memory and or storage platform configuration such as 32 bit or 64 bit etc. .

In this illustrated embodiment the program execution service provides functionality for managing groups of one or more computing nodes for each of multiple users. As discussed in greater detail elsewhere the various users may interact with the module to specify requests to initiate use of groups of computing nodes for execution of programs on behalf of the users. In various embodiments such resources may be specified at the time of a request for execution of one or more programs on a group of computing nodes on behalf of a user and or at one or more other times such as when a user initially registers and or subscribes to use services of the PES. In some embodiments the module may provide subscription and or registration services to one or more users such that users may specify information related to one or more programs to execute on behalf of a user e.g. programs source code addressable locations of one or more programs etc. account information e.g. user name billing information etc. terms of use etc. In some embodiments after a user interacts with the module to subscribe and or register for services the user may be issued one or more identifiers e.g. keys tokens user names etc. that are associated with the user and are to be used in conjunction with executing programs on behalf of the user. In other embodiments a module other than the module not shown may be provided to perform various operations related to subscription and or registration services of a PES. While the user interacts directly in these manners with the PES rather than the ECMS in other embodiments the user may similarly interact directly with the ECMS to perform some or all some activities whether instead of or in addition to such interactions with the PES .

After a request is received from a user for use of one or more computing nodes the module may determine whether there are a sufficient number of computing nodes with available resources for satisfying the request and if so the module may initiate execution of one or more programs for the request on an appropriate amount of the computing nodes on behalf of the user. In cases where a user schedules a request for future execution of one or more programs on a group of one or more computing nodes the module may attempt to immediately reserve an appropriate amount of computing nodes for executing the one or more programs at the one or more future times and or may delay the determination of which computing nodes to use for execution until a later time e.g. such as when the one or more future times occur . In the illustrated embodiment if the module is unable to allocate computing nodes for a user request the request may fail such that the programs are not executed. In such cases the user may resubmit a failed request for later execution. As previously noted in some embodiments a user may be charged various fees in association with use of the PES such as based on a number of computing nodes used a type of computing nodes used a duration of time the computing nodes are used particular operations that the computing nodes perform e.g. data transfer and or storage etc.

After a group of one or more computing nodes is provided for use in executing one or more programs on behalf of a user the computing node group may be managed in various manners. For example as previously noted the PESCMM module may monitor the computing nodes of the group such as to determine performance characteristics of some or all of the computing nodes including an actual computing node quantity or other measure of actual program execution capacity being provided by the computing nodes of the group. The actual program execution capacity of the group may change if for example one or more of the computing nodes fail or otherwise become unavailable and in at least some embodiments the PES may perform various operations to maintain the program execution capacity of the computing node group in such situations e.g. by initiating the addition of replacement computing nodes to the group in place of the unavailable computing nodes .

In addition the module may also assist in managing the computing node group in various manners. For example as previously noted the user associated with the group may have previously specified one or more quantity modification triggers that specify types of computing node quantity changes to be made to the group or other types of capacity modification triggers with other specified types of capacity modifications if various specified criteria are satisfied. Furthermore in at least some embodiments the user associated with the group may dynamically specify changes to the operation of their associated computing node group at various times including to change the quantity of the computing nodes of the group. Furthermore the module may perform other activities to track events and particular program execution capacity changes that occur with respect to particular computing node groups and may store information about execution capacity amounts used by particular computing node groups for later use as historical information for generating of predicted execution capacity information.

Although the foregoing example embodiment of is described with respect to a PES that provides various types of functionality for various users it will be appreciated that various other embodiments may exist. For example in at least some embodiments unused portions of a single one of the computing nodes e.g. unused processing unit clock cycles unused portions of memory etc. may be made available for use by one or more users such that one or more programs of a first user may be sharing resources of a single computing node with those of one or more other users. In addition although some embodiments are described with respect to a program execution service and program execution capacity it will be appreciated that the described techniques may be used to manage access to various other groups of computing nodes or other types of computing related resources. A non exclusive list of examples of other types of computing related resources that may be managed for use by multiple users may include the following persistent data storage capabilities e.g. on non volatile memory devices such as hard disk drives temporary data storage capabilities e.g. on volatile memory such as RAM message queuing and or passing capabilities other types of communication capabilities e.g. network sockets virtual communication circuits etc. database management capabilities dedicated bandwidth or other network related resources input device capabilities output device capabilities CPU cycles or other instruction execution capabilities etc.

The illustrated example includes a data center used by the PES and ECMS which is connected to the Internet external to the data center . In this example the Internet provides access to various external computing systems such as computing systems via private network and directly accessible computing systems . The private network may be for example a corporate network that is wholly or partially inaccessible from non privileged computing systems external to the private network . Computing systems may include for example a home computing system that connects directly to the Internet e.g. via a telephone or cable modem a Digital Subscriber Line DSL etc. . In addition one or more other data centers are illustrated that are connected to data center via the Internet such as may further be used by the PES and or ECMS in at least some embodiments.

The example data center further includes a number of physical host computing systems and physical computing systems which are interconnected via an internal network . In this example host computing systems each provide multiple virtual machines and have a virtual machine VM manager component to manage those virtual machines e.g. a hypervisor or other virtual machine monitor such as is illustrated with respect to host computing system with multiple virtual machines and a VM manager component . The other host computing systems may similarly include such components but those other components are not illustrated here for the sake of brevity and some or all of the computing systems may optionally similarly have one or more such virtual machines and or VM manager components not shown . Each of the virtual machines provided by a host computing system may be used as a distinct computing node for the PES such as to have a first virtual machine computing node on a first host computing system and a second virtual machine computing node on a second host computing system each be part of a first computing node group for a first user and to have another virtual machine computing node on the first host computing system that is part of a second computing node group for a second user. Alternatively in other embodiments some or all of the physical host computing systems at the data center may not provide any virtual machines such as to instead directly act as a computing node that executes one or more programs on behalf of an end user customer of the PES. Furthermore in some embodiments various of the computing systems and may have differing capabilities may have different associated fees for use may support different types of user programs e.g. virtual machine software image instances of different sizes or programs with different types of resource criteria and or computing resource usage such as differing patterns of I O and memory access and network usage etc. If so particular users and or their programs may be grouped e.g. automatically according to one or more such factors which may further be used as constraints and or preferences regarding which computing systems to select for executing particular programs. The internal network of the example data center may further include multiple networking devices not shown such as switches edge routers and core routers with computing systems and the module s and the module s connected to the internal network . The various host computing systems and other computing systems may be arranged in various manners including by being grouped in racks that share common backplanes or other interconnection mediums. Furthermore each of the modules and may be executed using one or more computing systems not shown .

The illustrated module s perform at least some of the described techniques of an embodiment of a PES in order to manage execution of programs on groups of computing nodes that are provided using the computing systems and as described in greater detail elsewhere. Similarly the illustrated module s perform at least some of the described techniques of an embodiment of an ECMS in order to automatically govern program execution capacity being provided by groups of computing nodes using the computing systems and as described in greater detail elsewhere. When a particular computing node is selected to execute one or more programs of a user the module s may in some embodiments initiate execution of those programs by interacting with a VM manager component or other manager component that controls execution of programs for that selected computing node or may alternatively directly execute the programs on the selected computing node. Users of the PES may use various computing systems to interact with the module s such as computing systems or or computing systems at one of the other data centers .

It will be appreciated that the data center of is provided for illustrative purposes only and that program execution services and other software execution services and or an execution capacity management system may be provided in other manners in other embodiments including to provide a PES and ECMS in different geographical and network locations. For example module s and or module s may instead be provided using one or more other computing systems external to the data center such as computing systems or at a data center .

In the example user has initiated the use of a group of multiple computing nodes to execute one or more copies of an indicated software program on behalf of the user such as for the multiple computing nodes to each execute a copy and to serve as an alternative to handle requests received by a service that is provided by the executing program e.g. in order to balance the computing load for the service across the multiple computing nodes of the group . As is illustrated in the timeline graph of the user has initiated an event E1 at approximately time T03 that requests that the computing node group be provided and has specified an initial computing node quantity of 8 computing nodes for the group. Information of further indicates various user defined triggers that the user has specified for the computing node group such as at the time of the initial request although in other embodiments some or all of the triggers may be specified in other manners e.g. at other times such as during the use of the group of computing nodes by other entities such as automatically by a PES that is providing the group of computing nodes and or by an execution capacity management system that is managing the execution capacity being provided by the group of computing nodes etc. . In addition timeline graph of illustrates information about two example types of performance characteristics that will be monitored for the computing node group and that will be used to determine whether various of the triggers are satisfied which in this example includes aggregate average CPU utilization for the computing node group and aggregate average network bandwidth utilization for the computing node group.

In response to the event E1 corresponding to the received user request to initiate the providing of the computing node group an example PES not shown initiates a computing node group for the user that initially includes eight computing nodes in accordance with the initial computing node quantity. As is shown in the timeline graph however the eight computing nodes are not actually immediately available as it takes some time to provision and make available the computing nodes for use as part of the computing node group including having the program copy be executed on each of the computing nodes by the PES or the user. In particular after an initial brief time has passed after event E1 some program execution capacity for the computing node group becomes available which corresponds to a first four of the eight computing nodes being available. Accordingly the illustrated actual computing node quantity for the computing node group increases from 0 to 4 at that time. In addition at the same time or shortly thereafter the timeline graph indicates that the aggregate average CPU utilization and aggregate average network bandwidth utilization performance characteristics begin to be tracked based on operation of the available computing nodes of the group. Shortly after the first four computing nodes become available a subsequent change in the available program execution capacity from the group corresponds to three additional computing nodes becoming available for use as part of the computing node group as illustrated by the actual computing node quantity information at approximately time T04. However the final of the initial eight computing nodes does not become available within the group in this example until an additional time after the other seven computing nodes are already available. In the current example a hardware problem occurred with the computing node that is initially selected to be the eighth computing node although in other situations a similar delay may occur if only 7 total computing nodes were initially available for use in the computing node group with the eighth computing node being dynamically added as soon as it later becomes available . Accordingly an event E2 is shown occurring shortly after the event E1 in this example at approximately time T4 in which the PES terminates the original eighth computing node if appropriate e.g. if it is frozen in an intermediate state and initiates the providing of a replacement eighth computing node.

While the time intervals e.g. from time T01 to time T02 from time T02 to time T03 etc. may have varying durations in various embodiments in the illustrated example the time intervals correspond to approximately an hour each with the time to provision a computing node and make it available within the group being for example between 5 minutes and an hour. In addition the computing nodes within the group may optionally be considered for dynamic modification once each time interval as discussed further below although in other embodiments the dynamic medication consideration may be performed in other manners e.g. substantially continuously a specified number of times per time interval once for each specified number of time intervals etc. including to aggregate at least some types of requested modifications for consideration together. In addition in this example the PES or other third party system performs monitoring of the computing nodes of the group in a substantially continuous manner such that the performance characteristics and and the actual computing node quantity information is maintained in an up to date manner.

After the eight computing nodes of the computing node group operate in the intended manner for several time intervals a change occurs in the actual computing node quantity at approximately time T7 prompted by one of the computing nodes of the group failing or otherwise becoming unavailable. A corresponding event E3 is shown at approximately the same time as the change in which the PES terminates the unavailable computing node as needed and in this example automatically initiates the providing of a replacement computing node. Subsequently in this example a change is completed at approximately time T08 that returns the actual computing node quantity to eight as the replacement computing node becomes available for use as part of the computing node group. No other computing node capacity availability changes or related events occur in this example during the remainder of the initial time period from time T01 to time T11 including none of the specified triggers being satisfied so as to trigger a possible dynamic program execution capacity modification for the group and no specified user instructions for such dynamic program execution capacity modification being received.

During the second time period from time T11 to time T21 additional events do occur however. In particular an event E4 first occurs at approximately time T15 in which the user associated with the computing node group provides a dynamically specified request to increase the computing node quantity of the group by 3 computing nodes for a total requested computing node quantity of eleven or alternatively could request that the updated desired computing node quantity be set to eleven regardless of the current computing node quantity . This request may be made for example based on the user noticing that the aggregate average CPU utilization is rising quickly that the total computing load on the computing node group is increasing etc. Accordingly the system initiates an increase of three computing nodes for the user s group as reflected in the corresponding increase in the actual computing node quantity and corresponding increase in program execution capacity for the group that occurs shortly after event E4. In some embodiments the execution capacity management system may not automatically govern such user initiated modifications to program execution capacity based on predicted execution capacity information as discussed in greater detail below with respect to dynamic modification requests that are automatically triggered while in other embodiments the execution capacity management system will automatically govern some or all such user initiated modifications to program execution capacity based on predicted execution capacity information.

After a short additional time has passed at approximately time T16 a next event E5 occurs that corresponds to an automated determination by the PES that trigger TR 1 as shown in has been satisfied by the increasing aggregate average CPU utilization as is graphically illustrated in the timeline graph with a first black oval on the aggregate average CPU utilization line. The trigger TR 1 satisfaction initiates a request to increase the computing node quantity by 4 computing nodes for a total requested desired computing node quantity of fifteen or alternatively could request that the updated desired computing node quantity be set to fifteen regardless of the current computing node quantity . In particular in this example the program execution capacity of the group has just been increased by 3 computing nodes before the event E5 is automatically triggered but the new computing nodes have not had sufficient time to level or reduce the aggregate average CPU utilization before the threshold from the trigger TR 1 is reached. Thus from a conceptual standpoint events E4 and E5 are both attempting to address the same underlying issue with event E5 being at least partially redundant with respect to event E4.

In the illustrated example before fulfilling the request initiated by the automated trigger TR 1 the execution capacity management system automatically governs some or all such automated dynamic requests for program execution capacity modification and in particular performs the automatic governing based at least in part on predicted execution capacity information. In particular in this example the execution capacity management system has previously generated prediction information related to the program execution capacity that is expected to be used by the group of computing nodes at multiple future times such as is reflected in a range of predicted computing node quantities for the group at each of multiple future times that has an predicted computing node quantity upper bound and a predicted computing node quantity lower bound as well as a predicted computing node quantity average . As discussed in greater detail elsewhere the predicted information may be generated at various times e.g. before the use of the computing node group is initiated optionally with later updates during the use of the computing node group such as based on actual performance characteristics from the use of the computing node group when the use of the computing node group is initiated optionally with later updates during the use of the computing node group after the use of the computing node group has been initiated optionally with later updates during the use of the computing node group etc. and may be generated in various manners e.g. by generating predicted time series data based on assessing historical time series data and adjusting it to reflect one or more of a variety of factors .

In order to perform the automatic governing of the requested program execution capacity modification from event E5 the execution capacity management system first determines if the new program execution capacity that would result from the requested modification is within the range that was previously predicted for the current time and optionally may further determine if one or more other criteria are also satisfied as discussed in greater detail elsewhere. In this example the new program execution capacity that would result from the requested modification from event E5 is a total computing node quantity of fifteen which is outside the range of predicted computing node quantities for the current time in particular is larger than the predicted upper bound of 12 computing nodes for the current time . Accordingly in the illustrated example the execution capacity management system selects an altered new amount of program execution capacity that is equal to the predicted upper bound for the current time and initiates an alternative modification that will raise the total program execution capacity to the altered new amount although in other embodiments other actions may be taken instead of or in addition to initiating such an alternative modification thus in this example the alternative modification is for 1 additional computing node to be added to the eleven computing nodes currently in the group to the altered new total amount of twelve computing nodes. Accordingly the system initiates the increase for the alternative modification as reflected in the corresponding increase in the actual computing node quantity and corresponding increase in program execution capacity for the group that occurs shortly after event E5. For comparison purposes the current example illustrates not only the governed actual computing node quantity that results after event E5 but also illustrates a separate hypothetical non governed computing node quantity that might have result if the dynamic program execution capacity modification requests were not governed based at least in part on the predicted execution capacity information.

After further additional time has passed an event E6 next occurs at approximately time T18 corresponding to an automated determination that trigger TR N of has been satisfied by the increasing aggregate average network bandwidth utilization as is graphically illustrated in the timeline graph with a black oval on the aggregate average network bandwidth utilization line. In particular in this example while the addition of the four computing nodes to the group based on events E4 and E5 initiates a gradual reduction in the aggregate average CPU utilization values but the aggregate average network bandwidth utilization has continued to slowly rise e.g. based on the new computing nodes being added at network locations that do not have sufficient excess network bandwidth for the new computing nodes to reduce the aggregate average utilization . The trigger TR N satisfaction initiates a request to increase the desired computing node quantity by 2 computing nodes for a total requested desired computing node quantity of of fourteen based on the group currently having twelve computing nodes or alternatively could request that the updated desired computing node quantity be set to a specific quantity such as fourteen or seventeen regardless of the current computing node quantity although the total requested desired computing node quantity would instead be for seventeen computing nodes if the previous request corresponding to event E5 had not been automatically governed as illustrated by the subsequent hypothetical non governed computing node quantity . In the illustrated example before fulfilling the request initiated by the automated trigger TR N the execution capacity management system automatically governs the request based at least in part on the predicted execution capacity information in a manner similar to that previously described with respect to event E5. In particular with respect to event E6 the execution capacity management system first determines if the new program execution capacity that would result from the requested modification is within the range that was previously predicted for the current time. In this example the new program execution capacity that would result from the requested modification from event E6 is above the range of predicted computing node quantities for the current time since the quantity of computing nodes in the group was previously set to the upper bound and since the predicted information is constant for the first twenty four time intervals of operation e.g. if the predicted data is generated at a granularity of a particular day such that each day has consistent predicted values throughout the day but the predicted values may vary from day to day . Accordingly in the illustrated example the execution capacity management system determines not to make the requested modification and instead leaves the execution capacity of the group at its current level although in other embodiments other actions may be taken instead of or in addition to such a determination to make no change thus in this example the continuing total amount of execution capacity for the group is twelve computing nodes.

During the third time period one or more additional events and computing node capacity availability changes may further occur. In particular in this example the aggregate average CPU utilization eventually drops below a threshold of 20 corresponding to a criterion specified for trigger TR 3 of causing an event E7 to occur that includes a determination that trigger TR 3 has been satisfied as is graphically illustrated in the timeline graph with a second black oval on the aggregate average CPU utilization line. The trigger satisfaction initiates an automated request to decrease the desired computing node quantity by 2 computing nodes for a total requested desired computing node quantity of ten or alternatively could request that the updated desired computing node quantity be set to ten regardless of the current desired computing node quantity although the total requested desired computing node quantity would instead be for fifteen computing nodes if the previous requests corresponding to automatically initiated events E5 and E6 had not been automatically governed as illustrated by the subsequent hypothetical non governed computing node quantity . In the illustrated example before fulfilling the request initiated by the automated trigger TR 3 the execution capacity management system automatically governs the request based at least in part on the predicted execution capacity information in a manner similar to that previously described with respect to events E5 and E6. In particular with respect to event E7 the execution capacity management system first determines if the new program execution capacity that would result from the requested modification is within the range that was previously predicted for the current time. In this example the new program execution capacity that would result from the requested modification from event E7 is within the range of predicted computing node quantities for the current time since the request lowers the current quantity of computing nodes in the group that was previously set to the upper bound although the predicted quantity information is increasing during the second twenty four time intervals of operation. Accordingly in the illustrated example the execution capacity management system accepts the requested new amount of program execution capacity of ten computing nodes as being authorized based at least in part on being within the previously predicted range for the current time and initiates the requested modification to lower the total program execution capacity to the requested new amount. Accordingly the system initiates the decrease for the requested modification as reflected in the corresponding decrease in the actual computing node quantity and corresponding decrease in program execution capacity for the group that occurs shortly after event E7.

In addition in some embodiments the predicted execution capacity information may be used in other manners whether instead of or in addition to automatically governing dynamic modifications to execution capacity for a group of computing nodes. For example in some embodiments the predicted execution capacity information may be used to initiate actions that are expected before they occur such as to begin to provision one or more additional computing nodes for use in the group before a request is made for those additional computing nodes. In the example the predicted information includes a predicted computing node quantity average for each of multiple future times e.g. a mean or midpoint or other average value for the range at a particular future time including a predicted average of approximately 14 computing nodes for a future time of approximately T37. Accordingly in some embodiments the execution capacity management system may use such predicted average information to initiate advance provisioning of computing nodes in at least some situations e.g. if the current computing node quantity at a time is sufficiently different from the predicted average information for that time such as more than a threshold amount in this example the execution capacity management system may automatically create a new event not shown that corresponds to a request at time T36 to initiate advance provisioning of a specified quantity of additional computing nodes if the current computing node quantity of the group at time T36 is less than a threshold value at that time such as with the specified quantity of additional computing nodes being some or all of the difference between the current computing node quantity at the time and the predicted average quantity at the time. Various other related actions may be taken in other embodiments as discussed in greater detail elsewhere.

In addition while the dynamic modification activities corresponding to events E4 E5 and E7 are illustrated in this example as each occurring at a single point in time it will be appreciated that some or all such activities may actually take place over a period of time and further may have other effects that last over a period of time. For example in at least some embodiments some or all changes to program execution capacity of a computing node group that are initiated by the execution capacity management system may result in a temporary lockdown period in which at least some other types of changes may not be allowed. The program execution capacity changes that may cause such a lockdown may include for example program execution capacity increases and or decreases that are automatically initiated by the execution capacity management system e.g. to add new computing nodes to remove existing computing nodes etc. and or program execution capacity changes that are initiated immediately in response to a PES determination e.g. a computing node failure receipt of a user instruction etc. . Such lockdowns may have durations of various types e.g. until a specified result or occurrence such as until a computing node being added has become available a specified length of time such as the average or expected time for a computing node being added to become available etc. and in some embodiments may vary based on the type of change. During such lockdowns at least some types of events or changes may not be allowed such as to not allow user specified triggers to be satisfied or by ignoring any such trigger satisfactions during the lockdown duration and or to not allow user instructions to be accepted or by ignoring any such user instructions during the lockdown duration. Furthermore in some embodiments a user associated with a computing node group may similarly specify a cooldown period that operates in a similar manner to that of a lockdown such as a cooldown period of a specified amount of time that follows a lockdown or instead takes effect at other times. As with the lockdown during the cooldown period at least some types of events or changes may not be allowed such as to not allow user specified triggers to be satisfied or by ignoring any such trigger satisfactions during the cooldown period. It will be appreciated that users and or the PES may control modifications to computing node groups in other manners in other embodiments.

Thus in this manner the execution capacity management system operates to manage the program execution capacity provided to a user by a group of computing nodes including to make various dynamic modifications to the computing node group based on a variety of circumstances. It will be appreciated that the events and changes discussed in are provided for illustrative purposes only and that actual events changes and other operations of an execution capacity management system and or a PES may differ in other embodiments and situations. In addition the preceding examples of are provided for illustrative purposes and other embodiments may differ in various ways from the examples. For example although the program execution capacity is measured and modified based on a quantity of computing nodes in these examples such as if the various available computing nodes are treated as being equivalent e.g. having equivalent computing resources other embodiments may be provided where various of the available computing nodes may be of different types with varying characteristics e.g. different amounts of processing capacity memory platform specification etc. and or in which program execution capacity is tracked in manners other than computing node quantity. In some such embodiments various of the requests may include indications of one or more specific types of the computing nodes for use in groups of computing nodes selected to execute programs associated with the requests and those requests may only be fulfilled on the corresponding specified type of computing node.

In addition in at least some embodiments a PES or other system may further perform other types of activities as part of managing groups of computing nodes. For example as previously noted the PES or other system may determine to add or remove computing nodes from a computing node group at various times including the following in response to one or more satisfied triggers in response to a received user instruction in response to automated activities of the PES or other system such as to replace a failed computing node and or to terminate and remove a computing node whose ongoing operation is inhibited etc. In at least some embodiments the PES or other system may further consider other factors when determining the exact timing for at least some such computing node group modifications. For example in situations in which a user will be held responsible for the use of a given quantity of computing nodes for a given period of time e.g. has already been charged for X computing nodes for the next hour such information may be used to determine timing related to at least some types of modifications to the computing node group. If the PES or other system determines to reduce the quantity of computing nodes in the group below X the PES or other system may determine to wait until near or at the end of a time period e.g. the end of the hour for which the user has already been charged before actually reducing the computing node quantity below X.

As previously discussed various types of functionality may be provided and used by a PES in various embodiments and the functionality may be provided in various ways. For example in some embodiments program execution capacity available from a PES may include multiple computing nodes for executing programs on behalf of users such as via multiple physical computing machines interconnected via one or more networks or other data exchange mediums that are capable of transmitting data between the computing machines. At least some of the computing machines may in some embodiments each include sufficient computing related resources to execute multiple programs simultaneously e.g. sufficient writeable memory non volatile storage CPU cycles or other CPU usage measure network bandwidth swap space etc. and at least some of the computing machines in some such embodiments may each host multiple virtual machine computing nodes that each may execute one or more programs on behalf of a distinct user. Furthermore in various embodiments a PES may execute various types of programs on behalf of multiple users. For example such programs executed on behalf of users may include one or more operating systems applications e.g. servers and or other software applications utilities libraries etc. In addition in at least some embodiments such programs may include executable software images such as virtual machine images that are bootable or otherwise loadable on one or more virtual machine computing nodes and that each may include operating system software software for one or more application programs and or configuration information etc. Furthermore while program execution capacity modifications are made in some examples by changing computing node quantity in other embodiments such capacity modifications may be made by changing the program execution capacity of one or more computing nodes of the group e.g. by replacing a first computing node with a second computing node that has more or less of one or more types of computing resources of interest by modifying the amount of one or more computing resources that are available to one of the computing nodes that are already part of the group etc. .

In at least some embodiments the execution of one or more programs on a group of one or more computing nodes by a PES may be initiated in response to a current execution request for immediate execution of those programs. Alternatively the initiation may be based on a previously received program execution request that scheduled or otherwise reserved the then future execution of those programs for the now current time. Program execution requests may be received in various ways such as directly from a user e.g. via an interactive console or other GUI provided by the program execution service or from an executing program of a user that automatically initiates the execution of one or more other programs or other instances of itself e.g. via an API provided by the program execution service such as an API that uses Web services . Program execution requests may include various information to be used in the initiation of the execution of one or more programs such as an executable or other copy of a program to be executed an indication of a program that was previously registered or otherwise supplied for execution and a number of instances of the program that are to be executed simultaneously e.g. expressed as a single desired number of instances as a minimum and maximum number of desired instances etc. as well as a variety of other types of preferences and or requirements for execution of one or more programs e.g. resource allocation geographical and or logical location for execution proximity of execution to other programs and or computing nodes timing related criteria etc. .

After receiving a request to execute one or more instances of a program at an indicated time the PES may determine one or more computing nodes to use in a group for executing the program instances. In some embodiments the determination of the computing nodes to be used is performed at the time of the request even if for future execution. In other embodiments the determination of the computing nodes to be used for future execution of one or more program instances may be deferred to a later time such as at the future time of execution based on information that is then available. In some embodiments the determination of which computing nodes to use for execution of one or more programs on behalf of a user may be made prior to a request to execute such as at a time when a user subscribes and or registers to use the PES and or at another time prior to a request to execute programs for a user. For example in some such embodiments one or more computing nodes may be associated with a user for a period of time such that programs may be executed on behalf of that user on the associated computing nodes at any time during that period such as at any time a request is received to execute software for the user during the period. In addition in some embodiments the determination of which computing nodes to use to execute programs on behalf of a user may be made when one or more computing nodes and or computing resources of one or more computing nodes become available for executing programs for the user such as for example to execute programs of one or more pending requests on one or more computing nodes at a time when the computing nodes are unused and or are otherwise available for executing the programs. The determination of which computing nodes to use for execution of each program copy or instance may be made in a variety of ways including based on any preferences and or requirements specified in the request or otherwise specified for the program and or associated user e.g. at a time of registration etc. . For example if criteria are determined for preferred and or required resources for execution of a program instance e.g. memory and or storage CPU type cycles or other performance metric network capacity platform type etc. the determination of an appropriate computing node to execute a program instance may be based at least in part on whether a computing node has sufficient resources available to satisfy those resource criteria. Additional details related to executing and configuring programs to execute on a program execution service are included in pending U.S. patent application Ser. No. 11 395 463 filed Mar. 31 2006 and entitled Managing Execution of Programs by Multiple Computing Systems which is hereby incorporated by reference in its entirety.

In some embodiments fees may be associated with the use of a PES and or an ECMS such that the PES may execute programs on behalf of a user in exchange for payment of one or more fees by that user and or such that the ECMS may automatically govern program execution capacity on behalf of a user in exchange for payment of one or more fees by that user. For example in some embodiments fees may be charged to a user of functionality from an ECMS based on amount of functionality provided e.g. a duration of time during which the functionality is available a number of times that the functionality is used etc. such as to perform generation at a particular time of predicted execution capacity information for one or more future times and or to use predicted execution capacity information to automatically govern a particular request for dynamic modification of execution capacity being provided. In addition in some embodiments fees may be charged to a user of functionality from a PES based on an amount and or type of program execution capacity allocated for executing one or more programs on behalf of a user such as based on one or more of a number of processing units an amount of memory an amount of storage an amount of network resources etc. allocated for executing programs of the user. In some embodiments fees may be based on other factors such as various characteristics of the computing resources used to execute programs such as for example based on CPU capabilities or performance platform type e.g. 32 bit 64 bit etc. etc. In some embodiments fees may be charged on the basis of a variety of use factors such as a price per use of the service a price per unit of time that computing services are used a price per storage used a price per data transferred in and or out etc. In at least some embodiments as discussed in more detail below fees may be based on various other factors such as various properties related to executing programs e.g. continuity of execution fault tolerance etc. . In at least some embodiments a provider of a PES may offer one or more of various tiers types and or levels of services or functionality for executing programs on behalf of multiple users and in some such embodiments various fees may be associated with the various tiers types and or levels of services. In addition for example tiers may be used for a specific type of functionality provided by a PES such as to charge fees at a first tier for a first quantity of program execution capacity functionality e.g. up to a specified first threshold of computing nodes being used to charge fees at a second tier e.g. a lower price tier for a second quantity of program execution capacity functionality e.g. above the specified first threshold and up to a specified second threshold of computing nodes being used etc. Additional details related to various fees associated with a program execution service are included in pending U.S. patent application Ser. No. 11 963 331 filed Dec. 21 2007 and entitled Providing Configurable Pricing for Execution of Software Images which is hereby incorporated by reference in its entirety.

Furthermore various other types of functionality may be provided and used by a PES in various embodiments as discussed in greater detail elsewhere.

An embodiment of one or more modules of a program execution service e.g. a system manager module such as module of are executing in memory and in some embodiments each includes various software instructions that when executed program one or more of the CPU processors to provide the described functionality. The module s interact with computing systems and and computing nodes over the network e.g. via the Internet and or the World Wide Web via a private cellular network etc. . In this example embodiment the module s include functionality related to managing use of multiple computing nodes by various users not shown interacting with user computing systems such as in conjunction with a program execution service provided by the module s . The other computing systems and and computing nodes may be executing various software as part of interactions with the module s . For example user computing systems may be executing software in memory to interact with module s e.g. as part of a Web browser or specialized client side application program such as to configure and or request execution of programs on behalf of the users of those systems on one or more computing nodes in various ways as well as to perform various other types of actions as discussed in greater detail elsewhere. Various information related to the functionality of the module s may be stored in storage such as information related to configuration execution and or registration for executing programs on behalf of multiple users information related to program execution capacity modifications for computing node groups e.g. information about predefined user specified triggers information about dynamically specified capacity modification instructions from users information about computing node performance measurements and other information related to determining if specified triggers are satisfied etc. and information related to historical execution capacity usage information for users and or software programs.

After the module s receive requests or other indications to execute one or more programs on a group of one or more computing nodes the module s select the one or more computing nodes for the group and initiate execution of those programs on those computing nodes . In addition the module s may further interact with computing nodes to later terminate execution of initiated programs on the computing nodes to migrate one or more of the programs to one or more other computing nodes or computing systems etc. The computing nodes may have various forms in various embodiments such as to include a number of physical computing systems and or a number of virtual machines executing on one or more physical computing systems. In some embodiments the server computing system and computing nodes may be part of a data center or other group of co located computing systems or may otherwise be computing nodes of a private network. In addition in some embodiments the module s may interact with one or more other computing systems to initiate or terminate execution of one or more programs on those computing systems such as if the computing systems are provided by one or more third party participants who are providing computing nodes for use by other users. In some embodiments the module s may further or instead manage access to one or more types of computing related resources or services other than program execution services e.g. persistent or temporary data storage services messaging services database services etc. .

In addition the module s includes functionality in this example related to monitoring or otherwise interacting with one or more of the computing nodes to track use of those computing nodes such as to determine current actual program execution capacity or other resource usage capacity of a computing node group and or to determine current performance characteristics corresponding to some or all computing nodes of a computing node group. As previously noted such information may be stored on storage and or elsewhere and may be used by the module s and or the execution capacity management system in various manners. For example in some embodiments if the module s discover that a computing node has failed or otherwise become unavailable e.g. as part of provisioning or otherwise initializing the computing node to be used as part of a computing node group after the computing node has been in use as part of a computing node group etc. the module s may automatically take actions to replace the unavailable computing node with a new computing node. In other embodiments the module s may instead not perform some or all of the monitoring of the computing nodes such as if the module s instead obtain information from another source about current actual program execution capacity of a computing node group and or current performance characteristics corresponding to some or all computing nodes of a computing node group e.g. as provided by software executing on the computing nodes and then uses that information to maintain program execution capacity for the computing node group as appropriate.

An embodiment of one or more modules of an execution capacity management system e.g. a capacity prediction manager module and a capacity governing manager module such as modules and of are also executing in memory and in some embodiments each includes various software instructions that when executed program one or more of the CPU processors to provide the described functionality. The module s in this example interact with the program execution service provided by the module s via the server computing system e.g. via shared memory an internal bus etc. although in other embodiments the execution capacity management system and program execution service may instead interact via one or more intervening networks. In this example embodiment the modules include functionality related to generating predicted execution capacity usage information and performing automatic governing of dynamic modifications of provided execution capacity information based on the predicted information as discussed in greater detail elsewhere. In addition in at least some embodiments the modules of the execution capacity management system may simultaneously include multiple capacity prediction manager modules that use different prediction techniques or a single capacity prediction manager module that similarly supports different prediction techniques . Various information related to the functionality of the modules may be stored in storage such as information related to historical execution capacity usage information for users and or software programs that is used by the modules and information related to predicted execution capacity usage information for users and or software programs that is generated and used by the modules .

As discussed in greater detail elsewhere in some embodiments one or more modules of the execution capacity management system may provide functionality to clients distinct from a program execution service whether instead of or in addition to one or more program execution services. Such clients may for example use one or more of the computing systems and or such as to request a capacity prediction manager module of the execution capacity management system to provide predictions of future capacity usage in light of supplied historical capacity usage and optionally other information. In addition in some embodiments particular clients may use predictions of future capacity usage from one or more such capacity prediction manager modules in manners other than to dynamically govern the modifications to a particular computing node group for example one or more other modules may optionally execute in memory of computing system or alternatively on one or more computing systems and or to obtain predicted future capacity usage information from one or more such capacity prediction manager modules and to automatically perform various activities based on that predicted information as discussed in greater detail elsewhere.

It will be appreciated that computing systems and and computing nodes are merely illustrative and are not intended to limit the scope of the present invention. The computing systems and or nodes may instead each include multiple interacting computing systems or devices and the computing systems nodes may be connected to other devices that are not illustrated including through one or more networks such as the Internet via the Web or via private networks e.g. mobile communication networks etc. . More generally a computing node or other computing system may comprise any combination of hardware or software that may interact and perform the described types of functionality including without limitation desktop or other computers database servers network storage devices and other network devices PDAs cell phones wireless phones pagers electronic organizers Internet appliances television based systems e.g. using set top boxes and or personal digital video recorders and various other consumer products that include appropriate communication capabilities. In addition the functionality provided by the illustrated modules and or may in some embodiments be distributed in additional modules. Similarly in some embodiments some of the functionality of the modules and or may not be provided and or other additional functionality may be available.

It will also be appreciated that while various items are illustrated as being stored in memory or on storage while being used these items or portions of them may be transferred between memory and other storage devices for purposes of memory management and data integrity. Alternatively in other embodiments some or all of the software modules and or systems may execute in memory on another device and communicate with the illustrated computing systems via inter computer communication. Furthermore in some embodiments some or all of the systems and or modules may be implemented or provided in other manners such as by using means that are implemented at least partially or completely in firmware and or hardware including but not limited to one or more application specific integrated circuits ASICs standard integrated circuits controllers e.g. by executing appropriate instructions and including microcontrollers and or embedded controllers field programmable gate arrays FPGAs complex programmable logic devices CPLDs etc. Some or all of the modules systems and data structures may also be stored e.g. as software instructions or structured data on a non transitory computer readable storage medium such as a hard disk or flash drive or other non volatile storage device volatile or non volatile memory e.g. RAM a network storage device or a portable media article to be read by an appropriate drive e.g. a DVD disk a CD disk an optical disk etc. or via an appropriate connection. The systems modules and data structures may also in some embodiments be transmitted as generated data signals e.g. as part of a carrier wave or other analog or digital propagated signal on a variety of computer readable transmission mediums including wireless based and wired cable based mediums and may take a variety of forms e.g. as part of a single or multiplexed analog signal or as multiple discrete digital packets or frames . Such computer program products may also take other forms in other embodiments. Accordingly the present invention may be practiced with other computer system configurations.

In the illustrated embodiment the routine begins at block where information or a request is received. The routine continues to block to determine if the received request or information is related to initiating execution of one or more programs on a group of computing nodes such as a request from a user. If so the routine continues to block to obtain information regarding the requested program execution such as an initial desired amount of program execution capacity for the computing node group e.g. a desired computing node quantity optionally one or more programs to be executed and optionally one or more user specified capacity modification triggers. As discussed elsewhere in some embodiments a user may select from one or more of various types of computing nodes and or may otherwise specify various amounts and or types of computing resources desired e.g. processing unit type amount memory amount platform specification etc. . In block the routine then selects the computing nodes to be used for the group and in block initiates making those selected computing nodes available for the user such as by provisioning the selected computing nodes and optionally initiating execution of the one or more programs to be executed. When the computing nodes are available for use on behalf of the user the user may be notified of the availability in various manners or in other embodiments the computing nodes may begin operation in an automated manner without further interaction by the user. The routine then continues to block to store information related to the computing node group including any user specified triggers for the group. After block the routine continues to block to execute a routine to generate predicted execution capacity information for multiple future times for the new computing node group with one example of such a routine being illustrated with respect to although in other embodiments such prediction of execution capacity information may be performed at other times e.g. prior times .

If it is instead determined at block that a request to initiate execution of a group of computing nodes is not received the routine instead continues to block to determine whether a request is received from a user related to modifying program execution capacity for an existing computing node group of the user. If so the routine continues to block to receive the dynamically specified user instruction related to modifying program execution capacity for an indicated existing computing node group and then continues to block .

If it is instead determined at block that a request to modify program execution capacity for a group of computing nodes is not received the routine instead continues to block to determine whether to currently perform periodic or otherwise recurrent activities to monitor information about the program execution capacity for one or more computing nodes groups although in other embodiments such monitoring may be performed in a continuous or substantially continuous manner. If so the routine continues to block to execute a routine to perform monitoring of computing node groups being provided with one example of such a routine being illustrated with respect to optionally by a distinct module from the system manager module such as by a distinct module of and or a distinct module of . In this example embodiment the output of block includes an indication of any dynamic capacity modification requests that result from satisfied triggers at the current time. Accordingly the routine continues from block to block to determine whether any such triggers were satisfied and if not continues to block . If it is instead determined in block that one or more triggers were satisfied or after block the routine continues to block to send a request to a capacity governing manager module of the execution capacity management system to perform automatic governing of the dynamic modification requests with one example of a routine for such an execution capacity management system being illustrated with respect to . In this example embodiment the output of block includes an indication of any dynamic capacity modification requests that are authorized. Accordingly the routine continues from block to block to await the response from the capacity governing manager module and to perform any authorized dynamic execution capacity modifications.

If it is instead determined at block not to currently perform monitoring activities with respect to the program execution capacity for one or more computing nodes groups the routine instead continues to block to optionally perform one or more other indicated operations. For example in some embodiments the routine may receive requests from the execution capacity management system for historical execution capacity usage information and or other information related to program execution capacity being provided by computing node groups for users and retrieves and supplies such information as information. In addition in some embodiments the routine may initiate the generation of updated predicted execution capacity information for particular computing node groups at particular times such as after every time interval for which predicted information was separately generated e.g. every hour every day etc. after a specified length of time e.g. after six hours when new historical information becomes available on which new updated predicted information may be generated etc. Such operations of block may also include for example one or more of the following responding to user requests related to performing other types of program execution if the provided program execution service provides such other program execution types such as to execute a single program on a single computing node responding to user requests to specify additional triggers or otherwise to modify configuration information for an indicated computing node group responding to user requests to obtain various status information related to one or more computing node groups with which the user is associated responding to requests to perform administrative related activities for a user such as subscription registration or payment operations etc.

After blocks or or if it is instead determined in block that no triggers were satisfied the routine continues to block to optionally perform any user billing or reimbursement activities based on the information or request received in block or as is otherwise initiated e.g. periodically such as to charge and or collect fees from one or more users based on program execution functionality provided to the users. The routine may further optionally perform periodic housekeeping operations as appropriate.

After block the routine continues to block to determine whether to continue such as until an explicit indication to terminate execution of the routine is received. If it is determined to continue the routine returns to block and if not continues to block and ends. It will be appreciated that additional types of activities may be performed in some embodiments and situations such as to determine whether users are authorized to perform particular requested operations to immediately obtain payment from users for some types of requested operations etc. In addition while user requests and other operations are indicated in the illustrated embodiment as being performed in a manner specific to a particular computing node group and a particular associated user in other embodiments some or all such operations may instead be applied more generally such as to multiple computing nodes groups associated with a single user and or from multiple users associated with one or more computing node groups.

In the illustrated embodiment the routine begins at block where an indication is received to initiate gathering of information about computing nodes of one or more computing node groups of interest e.g. with respect to a particular computing node group of interest with respect to all computing node groups in use etc. such as may be initiated in block of FIG. while not illustrated here in some embodiments the routine may instead continuously or otherwise in a repetitive or autonomous manner. In block the routine gathers performance characteristics information for one or more such computing nodes including indications of the computing node groups to which those computing nodes belong for later use in generating aggregate information for the computing node groups. The information may be gathered in various manners including by pulling the information by requesting particular computing nodes or associated modules e.g. associated VM manager components for virtual machine computing nodes to provide the information by such computing nodes and or associated components pushing the information to the routine e.g. periodically upon certain types of events such as a detected error condition that will cause the computing node to shutdown or otherwise become unavailable etc. by monitoring network traffic and or individual resource usage by particular computing nodes etc.

The routine then continues to block to determine aggregate performance characteristic information for one or more selected computing node groups and to store that determined information for later use such as for all computing node groups computing node groups for which individual computing node information was just gathered computing node groups for which aggregate performance characteristic information has been requested or has not been generated recently computing node groups for which individual computing node information is available for each of the computing nodes in the computing node group etc. in some embodiments the stored information may later be used as historical information by an embodiment of the capacity prediction manager module of an ECMS to predict future program capacity information. It will be appreciated that aggregate performance characteristic information may be generated in various manners including when only partial information is available regarding the computing nodes of the group such as be extrapolating or otherwise estimating individual performance characteristics information that is not available. In addition particular performance characteristics information that is gathered and or aggregated may vary in various manners such as to always collect certain types of information for all computing node groups in certain embodiments to collect certain types of information based on the criteria specified for determined triggers for particular computing node groups etc. Furthermore while blocks are illustrated in this example as being performed in a sequential manner it will be appreciated that various blocks may instead be performed in other manners in some embodiments. For example in some embodiments the information gathering activities of block may be performed on a continuous basis or near continuous basis but the aggregate information generation of block and or other blocks may be performed only periodically.

After block the routine continues to block to determine and store current actual program execution capacity information for each of one or more computing node groups such as to reflect a current quantity of computing nodes of a group that are currently available and or one or more other measures of program execution capacity for a computing node group and stores the determined information for later use in some embodiments the stored information may later be used as historical information by an embodiment of the capacity prediction manager module of an ECMS to predict future program capacity information.

In block the routine then determines any capacity modification triggers for any computing node groups that have been satisfied for any computing node groups e.g. based on performance characteristics information gathered in block and or aggregated in block and or based on actual program execution capacity information determined in block . If any triggers are determined to be satisfied information about such satisfied triggers is temporarily stored and is used to provide output information as part of block .

In a similar manner the routine in block determines whether any computing nodes of any computing node groups have been initiated to be made available for the computing node group but the initialization has failed or otherwise not completed within a specified period of time e.g. 10 minutes or if any existing computing nodes of computing node groups that were previously in use as part of the computing node groups have now been identified as having failed or otherwise become unavailable. If so the illustrated embodiment of the routine initiates the immediate providing of a replacement computing node for any such computing nodes without using automatic governing functionality of the ECMS although in other embodiments such replacement activities may be handled in the same manner as dynamic execution capacity modification requests from the satisfaction of triggers. In addition as part of initiating replacement activities for such unavailable computing nodes the routine may further take actions to terminate the unavailable computing node e.g. if it is still running but is unresponsive .

After block the routine continues to block and provides information to the requester that invoked the routine about any triggers determined to be satisfied in block . In particular in the illustrated embodiment the routine provides sufficient information for use by the ECMS to perform its automated governing activities such as the following for each satisfied trigger an indication of the computing node group user and or specified program s to which the trigger corresponds an indication of the request for dynamic modification such as a relative computing node quantity change and an indication of the current actual node quantity an absolute new computing node quantity that would result if the request is satisfied optionally any performance characteristics related to the trigger optionally any further specified criteria that are part of the satisfied trigger and for use in determining whether to fulfill the request etc. Various other information may be provided in other embodiments and may be provided in other manners in other embodiments e.g. by storing the corresponding information in a location accessible to the ECMS by directly sending the information to the ECMS etc. .

After block the routine continues to block and ends. While the various activities described with respect to routine are illustrated in this embodiment as being performed by a different module than the module that performs routine in other embodiments some or all of the functionality of the two routines may be performed by a single module or otherwise combined.

In the illustrated embodiment the routine begins at block where an indication is received of a computing node group for which predicted execution capacity information is to be generated including information about one or more particular software programs that will be executed by the computing node group at one or more future times of interest. In the illustrated embodiment the prediction activities are performed based at least in part on information about one or more prior and or ongoing uses of a computing node group to execute the same one or more software programs and so the routine obtains actual execution capacity usage values and optionally other related information from the prior uses in block such as by receiving the information in block by dynamically interacting with one or more program execution services to request the information by retrieving the information from one or more accessible storage locations etc. In at least some embodiments the obtained information includes time series data showing actual program execution capacity that is recently used for a series of prior time points or time intervals. The routine next continues to block to optionally remove outlier values from the obtained information such as based on a statistical analysis e.g. by deviating from a mean or other midpoint by more than a threshold such as 1 or more standard deviations .

The routine next continues to block to assess the obtained information and to use the prior actual capacity usage values to generate corresponding predicted execution capacity usage values for multiple future times. As discussed in greater detail elsewhere such predicted information may have various forms e.g. predicted time series data and may be generated in various manners e.g. by performing regression and or extrapolation using the prior actual capacity usage values . In the illustrated embodiment the predicted information is generated for each of a determined number of multiple future time points or time intervals e.g. a fixed number a number specified in block etc. but in other embodiments may be generated in other manners e.g. for a single future time point or time interval . In addition in the illustrated embodiment the predicted information generated for each future time point or time interval may include one or more predicted execution capacity amount values such as a range of multiple values with an upper and lower bound an enumerated list of multiple predicted values a single predicted value etc. and may optionally have a single predicted expected value for some or all such future time points or time intervals e.g. a midpoint or mean or other average based on multiple predicted values . In some embodiments a single predicted expected value is first generated and then additional predicted values e.g. range that includes the single predicted expected value are determined based on that single predicted expected value such as by determining upper and lower bounds that reflect an error calculation or confidence interval for the single predicted expected value. Additional details related to particular ways to generated predicted values are included elsewhere.

After block the routine continues to block to optionally modify one or more of the generated predicted future capacity usage values such as to reflect expected upcoming atypical events. For example capacity usage may have been growing at a moderate steady rate recently such that some or all of the generated predicted future capacity usage values may correspond to such a moderate steady rate however if a planned future event is likely to significant increase or decrease the capacity usage at least some generated predicted future capacity usage values for related future times may be modified to reflect that event. As one illustrative example if the generated predicted future capacity usage values are for a group of one or more Web servers whose capacity usage values are related to a quantity and or type of received Web page requests and a planned future event is likely to significantly increase Web page requests of one or more types at a future time the generated predicted future capacity usage values for that future time may be adjusted accordingly. After block the routine continues to block in the illustrated embodiment to store the generated predicted execution capacity information for later use such as to later perform automatic governing of the computing node group for which the predicted information is generated. In other embodiments the generated predicted information may be used in other manners whether immediately and or at a later time and whether instead of or in addition to performing automatic governing of the computing node group. After block the routine continues to block and returns.

In the illustrated embodiment the routine begins at block where an indication is received of a computing node group for which a dynamic execution capacity modification request has been initiated including information about the modification request e.g. a relative modification that is requested and information about the current program execution capacity a new current program execution capacity that would result if the dynamic modification is performed etc. . In alternative embodiments rather than receive some or all such information in block the routine may instead obtain such information e.g. by dynamically interacting with a program execution service to request the information by retrieving the information from one or more accessible storage locations etc. . In addition while only a single dynamic modification request is received and handled in block at a single time in the illustrated embodiment in other embodiments multiple such dynamic modification requests may be received and handled e.g. each handled separately in an individual manner by aggregating the multiple requests in one or more manners such that a single modification request is considered etc. . After block the routine continues to block to obtain predicted execution capacity information for the indicated computing node group and at least the current time or a proximate time such as if predicted information is not available for the exact current time such as by receiving the predicted information in block dynamically interacting with the program execution service to request the information retrieving the previously generated predicted information from one or more accessible storage locations newly generating such predicted information based on historical data etc. In at least some embodiments the predicted information includes time series data showing a range of predicted program execution capacity for a series of future time points or future time intervals that include the current time.

After block the routine continues to block to determine if the indicated dynamic execution capacity modification request is allowable based at least in part on the obtained predicted information. In particular the illustrated embodiment of the routine determines in block if a requested execution capacity modification is allowable based on whether the new execution capacity that would result from the modification is within the range of predicted execution capacity values for the current time. In addition in some embodiments the routine may further consider whether one or more other criteria are also satisfied in order to find that that a modification request is allowable. If it is determined in block that the modification request was found in block to be allowable the routine continues to block where an indication is provided by the routine to the requester that the modification request is authorized to be performed.

If it is instead determined in block that the modification request was not found in block to be allowable the routine continues instead to block . In various embodiments various types of actions may be performed in response to such a non allowed modification request including to optionally automatically determine an alternative modification that is allowable to optionally notify the user for the computing node group of the non allowed modification request and further optionally prompt the user to provide a manual authorization of the modification request etc. while in other embodiments some or all such actions may not be performed. In the illustrated embodiment the routine in block attempts to automatically determine an alternative modification that is allowable such as a similar type of modification but one that results in an altered new resulting execution capacity amount that is within the range of predicted values for the current time and or that is otherwise allowable . If it is then determined in block that such an allowable alternative was found in block the routine continues to block to provide an indication to the requester of the authorized alternative modification. In the illustrated embodiment if it is determined in block that such an allowable alternative was not found in block or that such an alternative modification was not attempted to be found the routine continues to block to optionally notify the user for the computing node group of the non allowed modification request. Such a notification may further in some embodiments include additional information such as information about the predicted values for the current time current performance characteristics information for the computing node group and or about any automated attempts to find an allowable alternative modification. In addition in the illustrated embodiment the notification may further optionally provide information to the user that prompts the user to provide a manual authorization of the non allowed modification request if so desired such as via an API invocation a manual GUI interaction etc. After block if it is then determined in block that such a manual authorization was received from the user e.g. within a specified period of time the routine continues to block to provide an indication to the requester of the now authorized original modification request and otherwise continues to block to provide an indication to the requester that no authorized capacity modifications are to be performed e.g. after all of multiple received modification requests are determined to not be allowed .

After blocks or the routine continues to block and returns. While the various activities described with respect to routine are illustrated in this embodiment as being performed by a different module than the modules that perform routines and of and in other embodiments some or all of the functionality of routine and one or more of the other routines may instead be performed by a single module or may be otherwise combined.

In the illustrated embodiment the routine begins at block where an indication is received of a computing node group for which future capacity values will be generated such as to correspond to program execution capacity for one or more software programs or more generally to correspond to use of one or more types of hardware resources during one or more uses. The received indication may correspond for example to a request from another module or a remote customer for generated predicted future capacity values or may instead have other forms in other situations e.g. to periodically generate predicted future capacity values for each of one or more computing node groups . In block the routine then obtains historical capacity usage information for the indicated computing node group from prior use of the group and optionally removes or otherwise limits the weight given to erroneous values in the obtained historical information such as by identifying outlier values from the obtained information based on a statistical analysis e.g. by deviating from a mean or other midpoint by more than a threshold such as 1 or more standard deviations . The historical capacity usage information may be obtained in block in various manners in various embodiments such as by receiving the historical information in block dynamically interacting with one or more program execution services that tracked actual prior use in order to request the information retrieving the historical information from one or more accessible storage locations etc. In at least some embodiments the historical information includes time series data showing actual program execution capacity that is used during the prior uses for a series of prior time points or time intervals although in other embodiments the historical information may represent a set of prior data from which predicted information is desired without that set of prior data having been generated from any actual prior use e.g. if a remote customer or other module supplies a set of test or hypothetical historical data for which corresponding predictions are desired .

After block the routine continues to block to calculate day of week averages for the obtained historical actual capacity values. For example this operation may include extracting day of week data patterns by calculating the averages for each day of a week with all the historical data. The daily value of each day of week i.e. Sunday Monday Tuesday Wednesday Thursday Friday and Saturday is predicted based on the averages from this first step.

After block the routine continues to block to calculate month of year average variations for the obtained historical actual capacity values. For example this second operation computes the monthly changes of the total volume of computing nodes previously used or alternatively of a different measure of capacity usage such as a total volume of Web page views such as by first computing the average capacity values for each of the months of year and then determining the changes in the computed averages. Accordingly a first multiplicative parameter may be determined in this step to represent the relative average value for each month which may be subsequently multiplied to a particular day of week predicted average from the first step thus to generate a predicted execution capacity value for a Monday in September for example the day of week average information for Mondays may be multiplied by the first multiplicative parameter determined for September such that the predicted values for Mondays in September will differ from other days of week in September and from Mondays in other months. In other embodiments the routine may separate historical data into different time periods than days and or months and may calculate historical average execution capacities for different categories than day of week and or month of year such as time based categories that each include multiple of the time periods into which the historical data is separated categories that each include multiple of the time periods into which the historical data is separated but that are not time based etc. In addition the performance of blocks may occur at one or more first times that are after the prior times corresponding to the historical data being used but that are before future times for which the predictions are being generated.

After block the routine continues to block to calculate year to year changes for the obtained historical actual capacity values optionally based on multiple years of historical data. For example this third operation computes the year over year growth rate positive or negative by summing the actual data over each trailing 12 months. Based on the yearly growth rate the future year over year growth rate is estimated for one or more future years at a time of the generating. Accordingly a second multiplicative parameter may be determined in this step to represent the relative year over year growth rate for each future year and may be subsequently multiplied to the combination of data described above for the second step. Thus to generate predicted capacity information for a Monday in September for one year in the future in this third step for example the day of week average information for Mondays is multiplied by the first parameter determined for September and by the second parameter determined for one year in the future such that the predicted values for Mondays in September at one year in the future will differ from Mondays in September now or at other years in the future. It will be appreciated that historical capacity may be tracked for other periods of time than days whether instead of or in addition to day based time periods in some embodiments that average historical capacity may be determined for time based categories other than days of week categories and months of year categories and year to year categories whether instead of or in addition to one or more of the time based categories described with respect to blocks and in some embodiments e.g. for days of month categories days of year categories weeks of year categories seasonal categories corresponding to defined days or other time periods etc. and or that future capacity may be predicted for other periods of time than days in at least some embodiments whether instead of or in addition to day based time periods .

After block the routine continues to block to identify predictable future events that will affect program execution capacity in atypical manners such as a holiday season that is not captured in average monthly variations. This fourth step may be performed in different manners in different embodiments. For example a first manner is to create a holiday shopping pattern based on information extracted for specific historical holiday shopping days while a second manner is to map the recent years holiday data patterns to the future. With respect to the first manner and considering holidays in November and December as an example the creation of such a holiday shopping pattern may be performed by doing a baseline adjustment for the last eight weeks of one or more prior years optionally with a final modification to reflect specific holiday spikes on particular days or days of week . With respect to the second manner the mapping of recent years holiday data patterns to the future may include for example retrieving the past daily aggregates for particular days of interest based on the past two years historical data and modifying those values based on the estimation of the year over year growth rate from the third step discussed above. As one option both such manners may be considered for a particular computing node group and the manner that is more accurate or otherwise useful for that particular computing node group may be selected to be used in the future.

After block the routine continues to block to generate predicted capacity usage amounts for particular future time intervals based on information that is calculated or identified from some or all of the prior activities in steps one through four. This fifth operation includes if a time interval for which prediction is being generated is not a specialized time period based on an event identified with respect to step four of block e.g. is not a holiday period or other period of special handling using predicted data based on the combination of steps one through three in blocks as discussed above with respect to step three. Alternatively if a time interval for which prediction is being generated is a specialized time period based on an event identified with respect to step four of block e.g. falls into holiday shopping seasons this fifth operation includes generating the predicted capacity usage data by adjusting the results of the combination of steps one through three to reflect information identified in step four for the event.

After block the routine continues to block to add upper and lower bounds for some or all predicted capacity usage amounts for particular future time intervals such as to reflect uncertainty for and or confidence intervals for particular predicted capacity usage amounts. This sixth operation includes for example adding uncertainty to the previously discussed predictions in step five of block for particular time intervals so that the resulting generated range of predicted values indicates how likely an actual value is to fall into the predicted range. To compensate for skewedness of the data the upper and lower bounds may optionally be generated separately and the deviation of the predicted data from actual data may be tracked and used to determine the width of the prediction range. Thus the upper and lower bounds may in some embodiments not be symmetric to a predicted single value and may further be varied to reflect a particular type of software program being executed and or because of different monetary and non monetary costs for over prediction and under prediction. This sixth operation may be performed in different manners in different embodiments. For example a first manner is to use the standard deviation of the absolute prediction errors to calculate an uncertainty range while a second manner is to use a percentile of the relative prediction errors to calculate the uncertainty range. As one option both such manners may be considered for a particular computing node group and the manner that is more accurate or otherwise useful for that particular computing node group may be selected to be used in the future.

After block the routine continues to block in the illustrated embodiment to store the generated predicted capacity information for later use such as to enable later acquisition and or provisioning of computing nodes for the computing node group for which the predicted information is generated at particular future times. In addition if the indication received in block was a request for predicted information the routine in block may provide response information to the requester that includes some or all of the generated predicted capacity information or otherwise make that generated predicted capacity information available to the requester optionally instead of performing the storing of the information. In other embodiments the generated predicted information may be used in other manners whether immediately and or at a later time. After block the routine continues to block to determine whether to continue such as until an explicit indication to terminate is received. If it is determined to continue the routine returns to block to wait for another indicated computing node group for which to predict future capacity information and otherwise continues to block and ends.

The prediction techniques illustrated in the embodiment of provides various benefits. As one example these prediction techniques are effective when dealing with unascertained data e.g. without requiring specific period parameter input to extract information from the historical data and to apply it to describe future events enabling the incorporation of known and unknown information together to improve prediction accuracies including the ability to analyze multi dimensional input including discrete and even insufficient data . In addition these prediction techniques are applicable even if sufficient historical data is not available to determine a known statistical distribution in order to make an accurate assessment and prediction of the required parameters. Furthermore outliers can be identified and removed from the input using different criteria such as moving average and standard deviation method but these prediction techniques may also be used even if some or all outlier data remains in the input data set.

As previously noted predictions of future program execution capacity and other resource usage capacity may be made in various manners in various embodiments. The following provides non limiting illustrative examples of additional techniques for generating prediction information in some embodiments. These additional techniques may be used for for example one or more software programs that provide functionality for at least a portion of one or more Web sites e.g. the Web site of an online retailer with the performance characteristics for a corresponding group of one or more computing nodes including information about a volume of Web page views for the at least portion of the one or more Web sites. In addition if a Web site has different types of Web pages with different access patterns and historical data is available regarding capacity usage specific to one or more of those types the prediction techniques may be performed individually for each of those one or more types.

A first example additional prediction technique may be used to forecast the total page views for a specified future day such as to predict the next month s page view traffic. In order to predict today s page view traffic using the first example additional prediction technique the following formula is used 

A second example additional prediction technique may be used to forecast the total page views for a specified future day such as to predict the next month s page view traffic. This prediction technique breaks down historical daily traffic time series data into components to analyze and predict its behavior and may be used to fit a wide range of data with complex patterns e.g. trends seasonal factors cyclical behavior that might include multiple predictors etc. . In addition the model fitting estimations may be smoothed such as by using Holt Winters exponential smoothing if the data exhibits both trend and seasonality in order to separate the pattern from the random error. Exponential smoothing allows continually revising a prediction in the light of more recent experience by assigning exponentially decreasing weights as a historical data point get older so as to give more weight to recent data. In order to predict page view traffic using the second example additional prediction technique the following basic model is used assuming the data has a trend and seasonal components which can be modeled in various ways where is the trend is the seasonal and the is the irregular term. Predictions for particular days may further be adjusted to reflect identified events that affect page view traffic in a manner similar to that previously discussed. The second example additional prediction technique may optionally be used without removing outliers from historical data before the historical data is used.

It will be appreciated that in some embodiments the functionality provided by the routines discussed above may be provided in alternative ways such as being split among more routines or consolidated into fewer routines. Similarly in some embodiments illustrated routines may provide more or less functionality than is described such as when other illustrated routines instead lack or include such functionality respectively or when the amount of functionality that is provided is altered. In addition while various operations may be illustrated as being performed in a particular manner e.g. in serial or in parallel and or in a particular order those skilled in the art will appreciate that in other embodiments the operations may be performed in other orders and in other manners. Those skilled in the art will also appreciate that the data structures discussed above may be structured in different manners such as by having a single data structure split into multiple data structures or by having multiple data structures consolidated into a single data structure. Similarly in some embodiments illustrated data structures may store more or less information than is described such as when other illustrated data structures instead lack or include such information respectively or when the amount or types of information that is stored is altered.

From the foregoing it will be appreciated that although specific embodiments have been described herein for purposes of illustration various modifications may be made without deviating from the spirit and scope of the invention. Accordingly the invention is not limited except as by the appended claims and the elements recited therein. In addition while certain aspects of the invention are presented below in certain claim forms the inventors contemplate the various aspects of the invention in any available claim form. For example while only some aspects of the invention may currently be recited as being embodied in a computer readable medium other aspects may likewise be so embodied.

