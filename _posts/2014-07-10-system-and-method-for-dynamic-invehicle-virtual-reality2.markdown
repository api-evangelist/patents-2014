---

title: System and method for dynamic in-vehicle virtual reality
abstract: A method for in-vehicle dynamic virtual reality, including receiving vehicle data from a portable device, the portable device operably connected for computer communication to an output device, the vehicle data including vehicle dynamics data, and receiving user data from at least one of the portable device or the output device. The method including generating a virtual view based on the vehicle data, the user data and a virtual world model, the virtual world model including one or more components that define the virtual view, wherein generating the virtual view includes augmenting one or more components of the virtual world model according to at least one of the vehicle data or the user data. The method including rendering the virtual view to the output device by controlling the output device to update display of the virtual view according to at least one of the vehicle data or the user data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09536353&OS=09536353&RS=09536353
owner: Honda Motor Co., Ltd.
number: 09536353
owner_city: Tokyo
owner_country: JP
publication_date: 20140710
---
This application is a continuation in part of U.S. patent application Ser. No. 14 177 841 filed on Feb. 11 2014 which claims priority to U.S. Provisional Application Ser. No. 61 886 240 both of which are expressly incorporated herein by reference.

Truly immersive virtual reality and augmented reality systems create environments that submerge the perceptual system of a user in computer generated stimuli e.g. a virtual world and or a virtual view . Typically these immersive systems captivate the senses of the user while blocking out stimuli from the physical world. The virtual world can be altered as a result of an input from the user and or an interaction of the user with the virtual world.

Although a goal of these systems is to create an immersive environment the physical world can still be used to provide a context for the immersive environment. In particular it is important to consider the environment and context of the user. For example in the context of a user in a vehicle immersive virtual reality and augmented reality systems can consider information about the user the vehicle and the user in relation to the vehicle. This information can be used to generate an immersive environment that is customized to the user and the user s environment and can allow the user to perceive the immersive environment comfortably.

According to one aspect a computer implemented method for in vehicle dynamic virtual reality includes receiving vehicle data from a portable device the portable device operably connected for computer communication to an output device the vehicle data including vehicle dynamics data of the vehicle and receiving user data from at least one of the portable device or the output device. The computer implemented method includes generating a virtual view based on the vehicle data the user data and a virtual world model the virtual world model including one or more components that define the virtual view wherein generating the virtual view includes augmenting one or more components of the virtual world model according to at least one of the vehicle data or the user data. The method includes rendering the virtual view to the output device by controlling the output device to update display of the virtual view according to at least one of the vehicle data or the user data.

According to another aspect a system for in vehicle dynamic virtual reality includes a portable device including one or more sensors for gathering vehicle data the portable device operably connected to an output device and a processor. The processor including a virtual reality data module. The virtual reality data module receives vehicle data from the portable device wherein the vehicle data includes vehicle dynamics data of the vehicle and receives user data from at least one of the portable device or the output device. The processor includes a dynamic virtual reality module. The dynamic virtual reality module generates the virtual view based on the vehicle data the user data and a virtual world model wherein generating the virtual view includes augmenting one or more components of the virtual world model according to at least one of the vehicle data or the user data. The processor includes a rendering module. The rendering module renders the virtual view from the dynamic reality module to the output device by controlling the output device to update display of the virtual view according to at least one of the vehicle data and the user data.

According to another aspect a non transitory computer readable storage medium storing instructions that when executed by a vehicle computer causes the computer to perform the steps of receiving vehicle data from sensors of a portable device the portable device operably connected for computer communication to an output device the vehicle data including vehicle dynamics data of the vehicle and receiving user data from at least one of the portable device or the output device. The method includes generating a virtual view based on the vehicle data the user data and a virtual world model the virtual world model including one or more components that define the virtual view wherein generating the virtual view includes augmenting one or more components of the virtual world model according to at least one of the vehicle data or the user data and rendering the virtual view to the output device by controlling the output device to update display of the virtual view according to at least one of the vehicle data or the user data.

The following includes definitions of selected terms employed herein. The definitions include various examples and or forms of components that fall within the scope of a term and that can be used for implementation. The examples are not intended to be limiting.

A bus as used herein refers to an interconnected architecture that is operably connected to other computer components inside a computer or between computers. The bus can transfer data between the computer components. The bus can a memory bus a memory controller a peripheral bus an external bus a crossbar switch and or a local bus among others. The bus can also be a vehicle bus that interconnects components inside a vehicle using protocols such as Controller Area network CAN Local Interconnect Network LIN among others.

 Computer communication as used herein refers to a communication between two or more computing devices e.g. computer personal digital assistant cellular telephone network device and can be for example a network transfer a file transfer an applet transfer an email a hypertext transfer protocol HTTP transfer and so on. A computer communication can occur across for example a wireless system e.g. IEEE 802.11 an Ethernet system e.g. IEEE 802.3 a token ring system e.g. IEEE 802.5 a local area network LAN a wide area network WAN a point to point system a circuit switching system a packet switching system among others.

A disk as used herein can be for example a magnetic disk drive a solid state disk drive a floppy disk drive a tape drive a Zip drive a flash memory card and or a memory stick. Furthermore the disk can be a CD ROM compact disk ROM a CD recordable drive CD R drive a CD rewritable drive CD RW drive and or a digital video ROM drive DVD ROM . The disk can store an operating system that controls or allocates resources of a computing device.

A database as used herein can refer to table a set of tables a set of data stores and or methods for accessing and or manipulating those data stores.

A memory as used herein can include volatile memory and or non volatile memory. Non volatile memory can include for example ROM read only memory PROM programmable read only memory EPROM erasable PROM and EEPROM electrically erasable PROM . Volatile memory can include for example RAM random access memory synchronous RAM SRAM dynamic RAM DRAM synchronous DRAM SDRAM double data rate SDRAM DDR SDRAM and direct RAM bus RAM DRRAM . The memory can store an operating system that controls or allocates resources of a computing device.

A module as used herein includes but is not limited to non transitory computer readable medium that stores instructions instructions in execution on a machine hardware firmware software in execution on a machine and or combinations of each to perform a function s or an action s and or to cause a function or action from another module method and or system. A module may also include logic a software controlled microprocessor a discrete logic circuit an analog circuit a digital circuit a programmed logic device a memory device containing executing instructions logic gates a combination of gates and or other circuit components. Multiple modules may be combined into one module and single modules may be distributed among multiple modules.

An operable connection or a connection by which entities are operably connected is one in which signals physical communications and or logical communications can be sent and or received. An operable connection can include a physical interface a data interface and or an electrical interface.

A processor as used herein processes signals and performs general computing and arithmetic functions. Signals processed by the processor can include digital signals data signals computer instructions processor instructions messages a bit a bit stream or other means that can be received transmitted and or detected. Generally the processor can be a variety of various processors including multiple single and multicore processors and co processors and other multiple single and multicore processor and co processor architectures. The processor can include various modules to execute various functions.

A portable device as used herein is a computing device typically having a display screen with user input e.g. touch keyboard and a processor for computing. Portable devices include but are not limited to handheld devices mobile devices smart phones laptops tablets and e readers.

A vehicle as used herein refers to any moving vehicle that is capable of carrying one or more human occupants and is powered by any form of energy. The term vehicle includes but is not limited to cars trucks vans minivans SUVs motorcycles scooters boats go karts amusement ride cars rail transport personal watercraft and aircraft. In some cases a motor vehicle includes one or more engines. Further the term vehicle can refer to an electric vehicle EV that is capable of carrying one or more human occupants and is powered entirely or partially by one or more electric motors powered by an electric battery. The EV can include battery electric vehicles BEV and plug in hybrid electric vehicles PHEV . The term vehicle can also refer to an autonomous vehicle and or self driving vehicle powered by any form of energy. The autonomous vehicle may or may not carry one or more human occupants. Further the term vehicle can include vehicles that are automated or non automated with pre determined paths or free moving vehicles.

A vehicle system as used herein can include but are not limited to any automatic or manual systems that can be used to enhance the vehicle driving and or safety. Exemplary vehicle systems include but are not limited to an electronic stability control system an anti lock brake system a brake assist system an automatic brake prefill system a low speed follow system a cruise control system a collision warning system a collision mitigation braking system an auto cruise control system a lane departure warning system a blind spot indicator system a lane keep assist system a navigation system a transmission system brake pedal systems an electronic power steering system visual devices e.g. camera systems proximity sensor systems a climate control system an electronic pretensioning system among others.

Referring now to the drawings wherein the showings are for purposes of illustrating one or more exemplary embodiments and not for purposes of limiting same is a schematic view of an operating environment for implementing dynamic in vehicle virtual reality systems and methods according to an exemplary embodiment. The components of environment as well as the components of other systems hardware architectures and software architectures discussed herein can be combined omitted or organized into different architectures for various embodiments. Further the components of the operating environment can be implemented with or associated with a vehicle. For example illustrates a vehicle implementing dynamic in vehicle virtual reality systems and methods which will be described in further detail herein.

In the illustrated embodiment of the environment of includes a computing device with provisions for processing communicating and interacting with various components of a vehicle e.g. the vehicle and other components of the environment . In one embodiment the computing device can be implemented with the vehicle for example as part of a telematics unit a head unit a navigation unit an infotainment unit an electronic control unit among others. In other embodiments the computing device can be implemented remotely from the vehicle for example with a portable device an input output device or at a device connected via a network as will be described in further detail herein. It is understood that the functions and components of the computing device including a processor can be modified and or organized into different architectures for these various implementations discussed above.

Generally the computing device includes the processor a memory a disk a position determination device and an input output I O interface which are each operably connected for computer communication via a bus e.g. a Controller Area Network CAN or a Local Interconnect Network LIN protocol bus and or other wired and wireless technologies. The I O interface provides software and hardware to facilitate data input and output between the components of the computing device and other components networks and data sources which will be described herein. Additionally as will be described in further detail with the systems and the methods discussed herein the processor includes a virtual reality VR engine suitable for providing a dynamic in vehicle virtual reality environment to a user e.g. a vehicle occupant facilitated by the components of the environment .

The computing device is also operably connected for computer communication e.g. via the bus and or the I O interface to one or more vehicle systems . Vehicle systems can include but are not limited to any automatic or manual systems that can be used to enhance the vehicle driving and or safety. The vehicle systems include and or are operably connected for computer communication to various vehicle sensors the vehicle sensors providing and or sensing information associated with the vehicle the vehicle environment and or the vehicle systems . The vehicle sensors can include but are not limited to vehicle state sensors vehicle system state sensors proximity sensors vision sensors audio sensors motion sensors and other sensors. The vehicle sensors can also include sensors of the position determination device for example global positioning system GPS sensors inertial measurement unit sensors IMU among other position and motion sensors. Other specific vehicle system sensors can include but are not limited to vehicle speed sensors accelerator pedal sensors brake sensors throttle position sensors wheel sensors anti lock brake sensors camshaft sensors among others.

The vehicle sensors are operable to sense a measurement of data associated with the vehicle the vehicle environment the vehicle systems and or occupants of the vehicle and generate a data signal indicating said measurement of data. These data signals can be converted into other data formats e.g. numerical and or used by the vehicle systems and or the computing device to generate other data metrics and parameters. In one embodiment the computing device and components thereof can access and or receive data e.g. vehicle data user data and other data from the plurality of vehicle systems and or the vehicle sensors .

The computing device is also operatively connected for computer communication to a network a portable device and an input output I O device . In some embodiments the computing device can access and or receive data e.g. vehicle data user data and other data from at least one of the network the portable device and the I O device . It is understood that the connection from the I O interface to the network the portable device and or the I O device can be facilitated in various ways for example through a network connection e.g. wired or wireless a cellular data network from the portable device a vehicle to vehicle ad hoc network not shown an in vehicle network not shown among others.

The network is for example a data network the Internet a wide area network or a local area network. The network serves as a communication medium to various remote devices e.g. databases web servers remote servers application servers intermediary servers client machines other portable devices not shown . It is appreciated that in some embodiments the portable device and or the I O device can be included in the network accessed by the computing device through the network and or the network can access the portable device and or the I O device independently.

The portable device is generally a device that provides input and or output to the computing device and in particular the VR engine to facilitate and provide a dynamic in vehicle virtual reality environment to a user. The portable device in one embodiment can gather and or provide data relative to the portable device frame of reference. In other embodiments the portable device can gather and or provide data relative to the world s frame of reference.

For example in one embodiment the portable device can gather and or provide data e.g. vehicle data user data other data to the computing device and in particular to the VR engine . It is understood that in some embodiments the portable device can include the components and functions of the computing device including the VR engine . One embodiment and architecture of the portable device wherein the portable device acts as a proxy for vehicle systems and vehicle sensors will be discussed in further detail herein.

The I O device in one embodiment can gather and or provide data relative to the I O device frame of reference. In other embodiments the I O device can gather and or provide data relative to the world s frame of reference. For example the I O device also generally provides input and or output to the computing device and in particular the VR engine to facilitate and provide a dynamic in vehicle virtual reality environment to a user. In one embodiment the I O device is an output device and is used to render and view a virtual world. In particular in one embodiment the portable device is operably connected for computer communication to the output device and can provide the virtual world and render the virtual world to the output device .

In some embodiments the I O device can gather and or provide data e.g. vehicle data user data other data to the computing device and in particular to the VR engine . It is understood that in some embodiments the I O device can include the components and functions of the computing device including the VR engine . Further it is understood that in some embodiments the components and functions of the portable device and the I O device can be combined into one device.

It is understood that the portable device and the input output device can also include speakers or headphones for audio input and output. For example the portable device and the input output device can utilize wireless or wired technology for computer communication with the computing device . In another embodiment the portable device and or the input output device can connect to and utilize the audio input and output hardware and software not shown of the vehicle . Various input output technologies can be implemented with the systems and methods described herein. Additionally it is appreciated that in some embodiments the portable device and or the I O device can be a virtual reality device for example a virtual reality tracking device a head mounted display virtual reality clothing a virtual reality input device virtual reality glasses camera tracking systems in the vehicle for monitoring the user the vehicle and or the vehicle environment among others.

The system of will now be described as implemented within a vehicle in . is a schematic view of an exemplary vehicle and exemplary vehicle occupants implementing in vehicle virtual reality systems and methods according to one or more aspects. In the examples that follow it will be appreciated that the portable devices and or the I O devices can be used in various combinations and located in other areas of the vehicle . In one example the I O device is a head mounted display HMD that can be placed on a user s body e.g. head or attached on a helmet or goggles. For example referring to a vehicle occupant positioned in a seat of the vehicle is wearing an HMD placed on the head of the vehicle occupant . The HMD can provide information about the vehicle occupant for example tracking information input information motion information among others to the VR engine . The HMD can also act as an output device to provide a virtual view generated by the VR engine to the vehicle occupant .

In another embodiment the vehicle occupant is in possession of a tablet e.g. a portable device . The tablet can provide information about the vehicle occupant for example tracking information input information motion information among others to the VR engine . For example in one embodiment the tablet could include position and motion sensors. In other embodiments the tablet can also act as an output device to provide a virtual view generated by the VR engine to the vehicle occupant . It is appreciated that the HMD alone or in combination with the tablet can provide information about the vehicle occupant and provide a virtual view generated by the VR engine . Further it is appreciated that other portable devices and or I O devices can be implemented in other locations and or configurations.

In another embodiment a vehicle occupant for example positioned in a back seat of the vehicle can be in possession of a portable device . In this embodiment the portable device could be a tablet similar to the tablet . The portable device can in one embodiment provide information about the vehicle occupant for example tracking information input information motion information among others to the VR engine . The portable device can also act as an output device to provide a virtual view generated by the VR engine to the vehicle occupant .

In a further embodiment the vehicle occupant can also be associated with a portable device . The portable device can in one embodiment provide information about the vehicle occupant for example tracking information input information motion information among others to the VR engine . The portable device in one embodiment is a mobile device. In one embodiment the portable device obtains vehicle data independently from the vehicle. For example the portable device includes position and motion sensors and can gather vehicle data from the sensors. In this embodiment the portable device is located within a motion frame of reference of the vehicle. Thus the portable device gathers motion and position data that is a reflection of the physical environment i.e. the vehicle in which the device is located. Said differentially the portable device is sensing and monitoring motion relative to the motion frame of reference of the vehicle e.g. the world s frame of reference.

For example in the portable device is attached to an armrest . While positioned in a motion frame of reference of the vehicle the portable device can gather vehicle data including vehicle dynamics data independently from the vehicle. In another example the portable device could be located on a center console of a seat or located in the middle of a seat. It is understood that the portable device can be located attached and or positioned in other areas of the vehicle . It is also understood that the HMD the tablet and or the portable device could also in some embodiments obtain vehicle data independently from the vehicle. Further it is understood that the portable device can also in some embodiments act as an output device to provide a virtual view generated by the VR engine to the vehicle occupant .

Moreover it is appreciated that the portable device alone or in combination with the portable device can provide information about the vehicle occupant and provide a virtual view generated by the VR engine . Further it is appreciated that other portable devices and or I O devices can be implemented in other locations and or configurations.

The VR engine of and a system for in vehicle dynamic virtual reality will now be discussed in detail with reference to . illustrates a block diagram of a virtual reality VR engine e.g. the VR engine according to an exemplary embodiment. For simplicity not all components of are shown in . The VR engine includes a virtual reality data module a dynamic virtual reality VR module and a rendering module . In addition to the functionality described above with reference to the aforementioned modules can access and or receive vehicle data user data and other data as well as communicate with a portable device e.g. the portable device an I O device e.g. the I O device and vehicle systems e.g. the vehicle systems . As discussed above the portable device and or the I O device can provide input and or output to the VR engine . Further the portable device and or the I O device can provide output to a user e.g. a vehicle occupant .

In one embodiment the virtual reality data module receives vehicle data from the one or more vehicle systems e.g. the vehicle systems of a vehicle. For example the vehicle data can include vehicle data metrics and parameters derived from the vehicle systems and or the vehicle sensors .

In a further embodiment the virtual reality data module receives vehicle data from a portable device . In this embodiment the portable device can obtain the vehicle data independently from the vehicle i.e. without directly connecting and or receiving data from the bus e.g. a vehicle CAN bus the vehicle systems and or the vehicle sensors . For example the portable device can include position and motion sensors. The portable device can gather vehicle data utilizing the position and motion sensors. In one embodiment the portable device is operably connected for computer communication to an output device e.g. the I O device . However it is appreciated that in some embodiments the functions of the portable device and the I O device can be combined into one device.

The vehicle data includes vehicle dynamics data of the vehicle. The vehicle data includes vehicle data metrics and parameters derived from the vehicle sensors . For example vehicle data can include but is not limited to vehicle location data vehicle orientation data vehicle system state data data related to one or more vehicle systems and or components vehicle environment data e.g. interior and exterior environment data among others. The vehicle data can also include navigation data for example location data direction data e.g. origin destination point of interest among others.

The vehicle data can also include vehicle dynamics data that describes the dynamics of the vehicle and the motion of vehicle e.g. velocity direction acceleration yaw rate steering rate steering angles . Vehicle dynamics data can include but is not limited to real time data concerning the speed level the acceleration rate the yaw rate the steering wheel position the brake position the throttle position the transmission gear position of the vehicle driver commands dynamic car responses tire and road forces among others. Further vehicle dynamics data can include derivatives of said data.

In some embodiments the vehicle data can be received from remote sources for example the network . In one embodiment the VR data module can receive predictive vehicle data or can determine predictive vehicle data based on the vehicle data and or the vehicle dynamics data. For example vehicle predictive motion data can be based on pedal positions vehicle system status control current vehicle location vehicle destination information among others.

The virtual reality data module also receives user data . For example the user data can be received from at least one of the portable device or the input output device . The user data includes tracking data interaction data user input data among others. The user data can be based at least in part on data from vision sensors e.g. vehicle sensors cameras gesture motion sensors tracking systems the portable device the I O device and other sensors and systems that provide data about the user s interaction position orientation location and motion. For example the user data can include position orientation and location information about the user. In another embodiment the user data can include position orientation and location information about the user in relation to the vehicle for example based in least in part on the vehicle data including the vehicle dynamics data . Thus in one embodiment the user data can provide information on the user s motion and position and how the user s motion and position is affected by the vehicle dynamics. The user data can also include health data about the user for example from health monitoring devices e.g. portable medical devices worn by the user in vehicle biological health monitoring devices . In some embodiments the user data can also be received from other networks and or the vehicle systems .

In another embodiment the virtual reality data module also receives other data for facilitating dynamic in vehicle virtual reality. The other data can include can include big data from the vehicle systems the portable device the I O device and or other networks . For example other data can include environmental data associated with the vehicle e.g. interior exterior road conditions e.g. bumpy roads slick roads traffic conditions weather conditions vehicle temperature among others. In another embodiment the other data can include driver action data for example driving history fuel efficiency interactions with other vehicle systems gestures motion relative to the vehicle among others. Further in some embodiments the other data can include social media data from for example the other networks .

The dynamic VR data module generates a virtual view based on the vehicle data the user data and a virtual world model. In one embodiment a data store stores a virtual world model the virtual world model including one or more components that define the virtual view. For example in a data store can store a virtual world model and design data. The virtual world model and design data can include game themes software or program instructions to define and generate a virtual world and or a virtual view. In another embodiment the memory and or the disk can store some or all of the aforementioned virtual world model and design data. In another embodiment the virtual world model and design data is received from remote sources for example the network .

An exemplary virtual world model will now be described with reference to . illustrates an exemplary virtual world data model diagram including data flow according to an exemplary embodiment. is a schematic class diagram of a virtual reality world including a group of node classes of the virtual world model of according to an exemplary embodiment. The node classes objects properties references methods and events i.e. the one or more components that define the virtual view discussed with are exemplary in nature and are not intended to be limiting. Generally a virtual world model is a collection of many individual operations and objects that define the virtual world and one or more virtual views. The virtual world model can be defined in various modeling and programming languages for example virtual reality modeling language VRML DirectX OpenGL Unity among others. As illustrated in the virtual world can include one or more virtual views . The virtual world and the virtual view can also include one or more virtual objects . The virtual view and the virtual object are defined by node classes and in the example of the group of node classes . In some embodiments nodes can be grouped and applied to one or more virtual views and or virtual objects in a hierarchy structure. For example the group of node classes can apply to parent and child nodes of the virtual views and or virtual objects associated with a particular group of nodes i.e. the group of node classes .

In the illustrated embodiment of the group of node classes includes a view node class a world structure node class an eventsIn node class and an eventsOut node class . Each node class can include components that define and or modify the node classes for example other nodes properties fields methods and or references. In some embodiments the nodes properties fields methods and or references can be predefined based on the virtual world for example for a particular theme game among others. Additionally in some embodiments the nodes properties fields methods and or references can be predefined based on the user for example based on user preferences. Other node classes properties fields methods and or references not included in can be implemented and may be based on the different modeling and programming languages mentioned above.

The group of node classes of will now be discussed in detail. The view node class defines the position and or the orientation of the virtual view the virtual object and or operations associated with the virtual view and or the virtual object . For example in the transform node can be used to perform geometric transformations and includes the properties position rotation and scale. The imageEffect node handles image post processing effects. Exemplary image post processing effects include depth of field motion and blur among others. The behavior node can be used to enable and disable different behaviors for example animation and motion. The visualEffects node can be used to define visual effects for example line renderers halo effects trail renders among others. The rendering node can be used to define settings and components for rendering in game and user interface elements.

The world structure class node defines the structure and appearance of the virtual view the virtual object and or operations associated with the virtual view and or the virtual object . For example the geometry node can be used to define shapes. The appearance node can be used to define texture and material. The terrain node can be used to define aspects of a terrain and landscape. The collision node defines which objects in a virtual view are collidable.

The eventsIn class node defines the types and names of events that each node can receive or generate. For example the EventManager node can define custom events and includes event handlers and listeners that determine event triggers e.g. determined from user data e.g. user input vehicle data to initialize specific events. The type field defines a type of the event the node field defines which node s the event applies to and the set fieldname method can be used to modify a value of a field during the event. The eventsOut class node manages execution and routing of the event. The fieldname changed field indicates what field s are changed during the event the type field defines the type of the event the node field can define which node the event applies to and the route method defines how the event is sent to a node and how the event is received and generated by a node. Again the class nodes and components in are exemplary in nature and other class nodes and components can be implemented with the systems and methods discussed herein. The class nodes and components can be augmented according to at least one of the vehicle data and the user data to generate a dynamic virtual world and or virtual views to a user. Specifically the vehicle data and the user data can be used to initialize nodes set properties and fields and initialize or define events.

Referring again to the model includes one or more components that define a virtual view. For example in the model includes a view class node a world structure class node an eventsIn class node and an eventsOut class node . The class nodes in can include similar methods properties fields and references as the class nodes described with . also illustrates exemplary data flow to the class nodes for example for augmenting the class nodes. Specifically the dynamic VR module can use these types of data to augment specific class nodes. As discussed in the data can include vehicle data user data and or other data . The types of data illustrated in are types of vehicle data user data and or other data in . Specifically in the data includes but is not limited to vehicle motion data including vehicle dynamics data user motion data vehicle motion predictive data navigation data big data and driver action data .

Referring again to the dynamic VR module modifies and or augments one or more components of the virtual world model based on at least one of the vehicle data and the user data. As shown in the arrows illustrate the flow from the different types of data to the VR model components. Accordingly the arrows illustrate exemplary flow of data that can be used to augment specific VR model components. For example vehicle motion data e.g. vehicle dynamics data vehicle velocity direction acceleration jerk vehicle occupant motion data can be used to augment components of the view class node . User motion data e.g. position orientation location input can be used to augmented components of the view class node . Further vehicle motion predictive data e.g. pedal positions auto cruise control can also be used to augment the view class node . In another embodiment the navigation data e.g. navigation location directions can be used to augment the world structure class node . The big data e.g. speed bumps road conditions steering conditions can also be used to augment the world structure class node . Further the big data can be used to augment the eventsIn class node . The driver action data e.g. fuel efficiency driver input audio can also be used to augment the eventsIn class node .

As discussed above the view class node the world structure class node the eventsIn class node and the eventsOut class node define the virtual view and can be augmented using at least one of vehicle data and user data to provide a dynamic virtual view to a user. In particular the data types in can be used to augment the components of the virtual world model thereby generating a virtual view that can include one or more virtual events . In one embodiment the dynamic VR model augments one or more properties of the one or more components of the virtual world model based on the vehicle data and the user data. For example the one or more properties of the one or more components can include those properties of the class nodes illustrated in . In one embodiment one or more of the properties can include a motion property defining a motion of the component. For example the view class node can include a property for example transform class node that defines the position the rotation and or the scale of an object. Based on at least one of the vehicle data and the user data the transform class node can be augmented to change the position rotation and or scale of the object. As an illustrative example and referring to a VR object can be defined as a ball i.e. defined by the world structure class node for example the geometry class node . The vehicle motion data e.g. vehicle dynamics data can be used to augment a feature of the ball. For example using the view class node and the transform class node the position rotation and or the scale of the ball can be set based on the vehicle motion data . Accordingly the VR object i.e. the ball is synchronized with the vehicle motion data .

Referring again to the rendering module renders the virtual view from the dynamic VR module to an output device by controlling the output device to update display of the virtual view according to the vehicle dynamics data. For example the dynamic reality module renders the virtual view the I O device e.g. an output device . In one embodiment the rendering module determines vehicle motion data based on the vehicle dynamics data i.e. the vehicle data . The rendering module can also determine user motion data representing motion of the user relative to the vehicle based on the user data and the vehicle data . For example in one embodiment the portable device and or the I O device can include accelerometer sensors and or gyroscope sensors that help determine a position a location and or an orientation of the user in relation to the vehicle. The vehicle motion data and or the user motion data can be used to augment one or more components of the virtual world model thereby controlling the output device to update display of the virtual view according to the vehicle dynamics data. In another embodiment the rendering module can augment the rendering speed e.g. the frames per second frame rate frame update rate defined and implemented by the graphics rendering hardware software of the I O device directly based on the vehicle motion data and or the user motion data .

In a further embodiment the rendering module determines a temporal motion rendering speed based on the vehicle motion data and the user motion data. The temporal motion rendering speed is a correlation between the vehicle motion data and the user motion data. In another embodiment the temporal motion rendering speed also considers a time component from the vehicle data. The temporal motion rendering speed is a post image processing and rendering property e.g. frames per second frame rate frame update rate that minimizes the difference between the vehicle motion data and the user motion data. The rendering module can render the virtual view to the output device by controlling the output device to update display of the virtual view based on the temporal motion rendering speed. For example the rendering speed e.g. the frames per second frame rate frame update rate implemented by the graphics hardware and or software of the I O device can be augmented based on the temporal motion rendering speed. In another embodiment the dynamic VR module augments one or more properties of the one or more component of the virtual world model based on the temporal motion rendering speed. For example the view class node can include a rendering properties and or properties related to motion See . In one embodiment these properties can include frames per second frame rate and or a frame update rate.

By updating the virtual view according to the vehicle dynamics data in real time the virtual view presented to the user is dynamic and considers the vehicle motion and the user motion thereby simulating the vehicle motion and the user motion in the virtual view in real time. Said differently one or more components of the virtual world model are synchronized based on at least the vehicle data and the user data including the vehicle dynamics data and the user motion data. Not only does this provide a truly immersive virtual reality environment for the user but virtual reality motion sickness can be minimized because the virtual view considers vehicle dynamics and user motion.

As mentioned above in one embodiment the portable device of can obtain vehicle data independently from the vehicle e.g. independently from the vehicle systems and the vehicle sensors . In this way the portable device can act as a proxy for vehicle systems and vehicle sensors . An exemplary portable device architecture for this embodiment will now be described in detail. is a schematic view of an exemplary system architecture of a portable device according to one aspect for example the portable device of .

In the portable device includes an application layer a middleware layer an operating system OS layer and a hardware layer . An exemplary OS layer is further illustrated in implemented as an Android OS. It is understood that other operating systems can be implemented. Further it is understood that components of can be combined omitted or organized into different architectures. For example the application layer can also include components of the Android OS application layer in .

Referring again to the application layer includes native applications non native applications e.g. third party and original equipment manufacturer OEM applications which run on the portable device . The native applications are locally installed and designed by the manufacturer of the portable device to run on the portable device operating system e.g. Android . For example native applications can include the applications contacts phone and browser as illustrated in . Non native applications include applications provided by third parties. OEM applications include specific applications provided by a vehicle OEM for interaction with a vehicle e.g. the vehicle of and the portable device . The OEM applications can be associated with a specific Graphic User Interface GUI for launching OEM applications on the portable device provided by an OEM server e.g. connected to for example the network of .

The middleware layer can include libraries frameworks and application programming interfaces API for operating the portable device and applications on the portable device . For example the communication framework Com FW includes provisions for connectivity and communication with external servers and device and application authentication. The vehicle framework Car FW is a specific framework for communicating with a vehicle e.g. the vehicle of handling vehicle data exchange e.g. with for example the vehicle systems and or the vehicle sensors of and providing touch panel events between the portable device and the computing device of . The virtual reality engine framework VR Engine FW is a framework for facilitating dynamic in vehicle virtual reality. For example in some embodiments the VR Engine FW communicates with the VR Engine of . In other embodiments the VR Engine FW could include the functions of the VR Engine e.g. the VR data module the dynamic VR module the rendering module of .

The operating system OS layer generally provides services for managing hardware and software resources of the portable device and includes an OS Core . The OS Core can be for example Android see iOS Mobile Linux Symbian OS Windows Mobile BlackBerry OS Web OS or other operating systems.

Further the hardware layer includes provisions for direct management and access of hardware resources. The portable device can include hardware such as a processor a memory a disk position and motion sensors and input output devices e.g. a touch screen of the portable device a keyboard of the portable device a microphone of the portable device . The components of the hardware layer can communicate with one another via for example a bus . Note that the portable device can include the same or similar components as the computing device of . Thus in some embodiments the portable device specifically the components of the hardware layer can carry out the functions of the VR engine of .

The position and motion sensors can include hardware and or software based sensors. For example the motion sensors can include a hardware based accelerometer gyroscope magnetometer among others. The motion sensors can also include software based gravity linear acceleration and rotation vector sensors. In some embodiments the software based sensors derive data from the accelerometer and the magnetometer but in other embodiments the software based sensors could use the gyroscope to derive their data. The motion sensors are useful for monitoring device movement such as tilt shake rotation or swing. The movement is usually a reflection of direct user input but it can also be a reflection of the physical environment in which the portable device is sitting. For example the portable device in one embodiment can detect movement of the vehicle in which it is located and or attached. The hardware abstraction layer in illustrates the different components that can derive motion data from such sensors for example the gyro module the accel module the mag module the rotational vector module the linear accel module and the gravity module.

Similarly the position sensors can include a hardware based geomagnetic field sensor ad a proximity sensor. An orientation sensor can be software based and can derive its data from an accelerometer and or the geomagnetic field sensor gyroscope magnetometer among others. Position sensors are useful for determining the portable device physical position in the world s frame of reference or in another frame of reference for example a vehicle frame of reference i.e. a motion frame of reference of the vehicle . In another embodiment the orientation sensor or similar sensor based orientation methods can be used to determine the portable device position in an application s frame of reference. The hardware abstraction layer in illustrates the different components that can derive position data from such sensors for example the gyro module the accel module the mag module the rotational vector module the linear accel module and the gravity module.

It is understood that the portable device can also include other sensors for example environment sensors e.g. humidity luminance ambient pressure ambient temperature . Further in some embodiments a camera not shown of the portable device can be used as a sensor to detect motion position gesture recognition among others from image data acquired by the camera. The position and motion sensors can in one embodiment gather and obtain vehicle data including vehicle dynamics data independently from the vehicle systems and sensors by using the position and motion sensors .

Referring now to a schematic view of the portable device of implemented in an exemplary operating environment e.g. for dynamic in vehicle virtual reality is shown according to one aspect. For purposes of convenience like components of in are indicated with line numerals. As can be seen in this embodiment the VR Engine FW of the portable device is operably connected for computer communication to the VR Engine . In some embodiments this connection is facilitated by the I O interface . Further in some embodiments as shown in the portable device is operable connected for computer communication to the I O device e.g. an output device . The VR Engine FW facilitates transmitting vehicle data including vehicle dynamics data of the vehicle and or user data to the VR Engine . In some embodiments the VR Engine FW of the portable device can also facilitate the output of a virtual view from the VR engine to the I O device . It is understood that in some embodiments the VR Engine FW could include the functions and components of the VR engine . Further in some embodiments the portable device and the I O device e.g. the output device could be combined into one device.

The dynamic in vehicle virtual reality system illustrated in described above will now be described in operation with reference to a method of . It will be appreciated that the systems and components discussed above with references to can similarly be implemented with the method of . The method of includes at block receiving vehicle data from one or more vehicle systems of a vehicle wherein the vehicle data includes vehicle dynamics data. For example referring to the VR data module can receive vehicle data . The vehicle data can include vehicle dynamics data.

In another embodiment at block the method includes receiving vehicle data from a portable device the portable device operably connected for computer communication to an output device the vehicle data including vehicle dynamics data of the vehicle. For example in the portable device can be operably connected to an output device . The portable device in one embodiment obtains the vehicle data independently from the vehicle. For example the portable device includes position and motion sensors for gathering vehicle data and in particular vehicle dynamics data of the vehicle. In one embodiment to gather the vehicle data from the sensors the portable device is located within a motion frame of reference of the vehicle. For example in the portable device is attached to the vehicle e.g. attached to the armrest within a motion reference frame of the vehicle.

Block also includes receiving user data from at least one of a portable device or the output device. For example the VR data module can receive user data from at least one of the portable device or the I O device .

Referring again to at block the method includes generating a virtual view based on the vehicle data the user data and a virtual world model. The virtual world model includes one or more components that define the virtual view. illustrates an exemplary virtual world model diagram including data flow according to an exemplary embodiment. The virtual world model includes one or more components that define the virtual view. For example the view node class the world structure node class the events in node class and the events out node class are exemplary components that define the virtual view. In particular these node classes define one or more virtual views and one or more virtual objects of the virtual world. The node classes can contain other nodes properties fields methods and references See .

In one embodiment generating the virtual view includes augmenting one or more components of the virtual world model according to at least one of the vehicle data and the user data. For example the view node class the world structure node class the events in node class and the events out node class and or nodes properties fields methods and references associated with these nodes can be augmented based on at least one of the vehicle data and the user data. In the vehicle motion data the user motion data the vehicle motion prediction data the navigation data the big data and the driver action data are exemplary types of data that can be used to augment one or more of the components of the virtual world model .

In one embodiment the method includes determining an orientation and a location of the vehicle based on the vehicle data. For example navigation data e.g. from for example the GPS can be used to determine the orientation and the location of the vehicle. The dynamic VR module and or the rendering module can determine the orientation and the location of the vehicle based on the vehicle data . The method can also include determining an orientation and a location of the user relative to the vehicle based on the user data and the vehicle data. For example the dynamic VR module and or the rendering module can determine the orientation and the location of the user relative to the vehicle based on the user data and the vehicle data . For example the portable device and or the I O device can include sensors e.g. accelerometers gyroscopes compasses that provide user data for determining the orientation and the location of the user relative to the vehicle.

Augmenting one or more components of the virtual world model can be based on at least one of the orientation and the location of the vehicle and the orientation and the location of the user. As a non limiting example the dynamic VR module can augment the world structure class node with the orientation and the location of the vehicle and the orientation and the location of the user in relation to the vehicle to provide real time world structures. For example the terrain class node See can be augmented to provide a terrain or landscape in the virtual view that includes a component based on the orientation and the location of the vehicle and the orientation and the location of the user in relation to the vehicle.

In another embodiment one or more virtual events can be augmented or created based on at least one of the vehicle data and the user data . As an illustrative example driver action data can be used to augment the eventsIn class node . Driver action data can include for example driving history fuel efficiency interactions with other vehicle systems gestures motion relative to the vehicle among others. As a non limiting illustrative example a user i.e. a vehicle occupant may roll down a vehicle window not shown . This driver action is determined based on vehicle data from the vehicle systems e.g. power window vehicle system and user data from at least one of the portable device the I O device and or the vehicle systems indicating that the user has rolled down the vehicle window. In response the dynamic VR module can augment for example the eventIn class node to trigger an event in the virtual view associated with the user rolling down the vehicle window. For example a simulation of the wind from the vehicle window can be presented in the virtual view among others. As another illustrative example the dynamic VR module can define the structure of the simulation of the wind based on a temperature determined from the vehicle data . For example if the temperature is a certain degree the simulation of the wind in the virtual view may include particles of snow. This can be defined by augmenting the eventsIn class node of the world structure class node . The eventsOut node can then route the event to create the virtual event .

In a further embodiment the method includes determining vehicle motion data based on the vehicle dynamics data. The dynamic VR module and or the rendering module can determine the vehicle motion data based on the vehicle data which includes vehicle dynamics data. As discussed above vehicle motion data define real time motion of the vehicle. In one embodiment the vehicle motion data includes at least velocity and acceleration data of the vehicle. Further the vehicle motion data can also include predictive vehicle motion data determined based on the vehicle data the user data and or the other data . For example the predictive vehicle motion data can be based on pedal positions cruise control destination information among others.

The method can also include determining user motion data representing motion of the user relative to the vehicle based on the user data and the vehicle data. The user motion data can be based on the vehicle data and the user data and can be determined by the dynamic VR module and or the rendering module . In a further embodiment generating the virtual view at block includes augmenting one or more components of the virtual world model according to at least one of the user motion data and the vehicle motion data.

At block the method includes rendering the virtual view to an output device by controlling the output device to update the display of the virtual view according to the vehicle dynamics data. For example the dynamic reality module renders the virtual view the output device i.e. the HMD the portable device . In one embodiment the rendering module renders the virtual view to an output device by controlling the output device to update the display of the virtual view according to the vehicle motion data and the user motion data . This can be accomplished in one embodiment by directly augmenting the rendering speed e.g. the frames per second frame rate frame update rate implemented by the graphics hardware and or software of the portable device and or the output device . In another embodiment shown at block the dynamic VR module augments one or more components of the virtual world model according to the vehicle motion data and the user motion data .

In another embodiment the method includes determining a temporal motion rendering speed based on the vehicle motion data and the user motion data. Rendering the virtual view can include controlling the output device to update display of the virtual view based on the temporal motion rendering speed. The temporal motion rendering speed is a correlation between the vehicle motion data and the user motion data . In another embodiment the temporal motion rendering speed also considers a time component from the vehicle data. The temporal motion rendering speed is a post image processing and rendering property e.g. frames per second that minimizes the difference between the vehicle motion data and the user motion data . The rendering module can render the virtual view to the output device by controlling the output device to update display of the virtual view based on the temporal motion rendering speed. For example the rendering speed e.g. the frames per second frame rate frame update rate implemented by the graphics hardware and or software of the portable device and or the output device can be augmented based on the temporal motion rendering speed.

In a further embodiment shown at block the dynamic VR module augments one or more properties of the one or more component of the virtual world model based on the temporal motion rendering speed. For example the view class node can include a rendering properties and or properties related to motion See . In one embodiment these properties can include frames per second frame rate and or a frame update rate. In this way the virtual view presented to the user is dynamic and simulates the vehicle motion in real time. Said differently one or more components of the virtual world model are synchronized based on at least the vehicle data and the user data including the vehicle dynamics data and the user motion data. Not only does this provide a truly immersive virtual reality environment for the user but also virtual reality motion sickness can be minimized because the virtual view considers the vehicle dynamics and the user motion. Further each virtual view presented to the user can be updated and maintained based on the vehicle dynamics data. For example if a virtual view presents user settings i.e. not in a game play mode the virtual view is always updated and maintained based on the vehicle dynamics data.

In some embodiments virtual reality objects and or operations can have predefined rendering speeds. As an illustrative example certain objects or certain virtual worlds may be set to rendering speeds of 25 ms. This predefined rendering speed can be adjusted based on the vehicle dynamics data as discussed above. Thus in some embodiments the temporal motion rendering speed can be based on a predefined rendering speed vehicle motion and user motion. Further the temporal motion rendering speed can also consider other types of data based on the user. For example as discussed above other data can include health data associated with the user . If for example the health data indicates motion or sensory issues e.g. disorientation vertigo motion sickness the temporal motion rendering speed can be adjusted based on the health data to minimize the motion or sensor issues.

Illustrative examples of dynamic virtual views generated by the methods and systems discussed herein will now be described with reference to . illustrates a virtual view and illustrates a virtual view from a fishing virtual reality game the objects and operations of which are defined by a virtual world model for example the virtual world model of and the schematic class diagram of a virtual reality world of . Specifically the virtual views are generated based on the vehicle data the user data and the virtual world model the virtual world model including one or more components that define the virtual views . The virtual views can be displayed in one embodiment on the output device . In another embodiment the virtual views can be displayed on the portable device .

The virtual view includes one or more virtual reality objects including a landscape a sun a fish and a water object . The water object includes one or more waves . Again the objects and operations of the virtual view are defined by a virtual world model. One or more components of the virtual world model can be augmented based according to at least one of the vehicle data and the user data. In particular in one embodiment the virtual world model can be augmented based on vehicle dynamics data and or the virtual view can be rendered to an output device by controlling the output device to update display of the virtual view according to the vehicle dynamics data. In this way the virtual view and objects of the virtual view are influenced by the vehicle data and or the user data and the virtual view and objects of the virtual view are synchronized with the vehicle dynamics data. For example the dynamic VR module can augment the world structure class node e.g. the terrain class node to dynamically generate and update the virtual view with objects based on a location and an orientation of the vehicle and a location and an orientation of the vehicle occupant . As an illustrative example the vehicle is driving in a mountainous region during the day. Accordingly based on the location and the orientation of the vehicle and a time component determine from the vehicle data the appearance and the terrain of the landscape object in the virtual view includes mountains and the sun . This is accomplished by augmenting the world structure class node with the location and the orientation of the vehicle and a time component determine from the vehicle data .

As another example the fish object can be generated as a type of fish indigenous to the location and the orientation of the vehicle and the location and the orientation of the vehicle occupant . Further the position of the fish object can also be generated based on the location and the orientation of the vehicle and the location and the orientation of the vehicle occupant . For example the view class node defining the position and the orientation of the fish object can be augmented to present a point of view to the vehicle occupant based on the location and the orientation of the vehicle and the location and the orientation of the vehicle occupant .

As a further example the water object in the virtual view can be generated based on the vehicle dynamics data. As an illustrative example the vehicle data can indicate a steady speed and yaw rate indicating a straight direction. Further the user data can indicate stead user motion. Accordingly in the waves appear calm and steady based on the vehicle data and the user data . However if the vehicle suddenly increases in speed as shown in the water object including one or more waves appear rough. In other embodiments the water object including the one or more waves can be generated by altering the parallax motion or depth of motion of the view class node based on the vehicle dynamics data.

In another embodiment the yaw rate of the vehicle and motion of the vehicle occupant can be used to augment the view class node of the boat object to generate a virtual view with the boat turning or moving based on the yaw rate of the vehicle and the motion of the user . As is apparent many variations of the virtual view can be generated based on the vehicle data the user data and the other data . In addition in a situation where the virtual view is not in a game play mode i.e. the virtual view presents game settings user settings start up instructions the virtual view is still generated and updated according to the vehicle dynamics data. Accordingly by updating the virtual view according to the vehicle dynamics data in real time the virtual view presented to the user is dynamic and considers the vehicle motion and the user motion thereby simulating the vehicle motion and the user motion in the virtual view in real time. Not only does this provide a truly immersive virtual reality environment for the user but virtual reality motion sickness can be minimized because the virtual view considers the vehicle dynamics and the user motion.

The embodiments discussed herein may also be described and implemented in the context of non transitory computer readable storage medium storing computer executable instructions. Non transitory computer readable storage media includes computer storage media and communication media. For example flash memory drives digital versatile discs DVDs compact discs CDs floppy disks and tape cassettes. Non transitory computer readable storage media may include volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures modules or other data. Non transitory computer readable storage media excludes transitory and propagated data signals.

It will be appreciated that various implementations of the above disclosed and other features and functions or alternatives or varieties thereof may be desirably combined into many other different systems or applications. Also that various presently unforeseen or unanticipated alternatives modifications variations or improvements therein may be subsequently made by those skilled in the art which are also intended to be encompassed by the following claims.

