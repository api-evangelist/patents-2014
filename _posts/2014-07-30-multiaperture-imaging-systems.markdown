---

title: Multi-aperture imaging systems
abstract: An example composite imaging system includes a first imaging system further comprising a first image sensor and a first aperture anterior to the first image sensor. The first aperture (i) is defined by an inner perimeter and an outer perimeter and (ii) defines, at least in part, a field of view of the first imaging system. The first imaging system further includes a plurality of reflectors posterior to the first aperture that are configured to redirect light that crosses the first aperture to the first image sensor. The first image sensor, the first aperture, and the plurality of reflectors are arranged around a common optical axis. The composite imaging system further includes a second imaging system arranged substantially anterior to the first imaging system. The second imaging system is arranged such that the second imaging system is outside a field of view of the first imaging system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09258470&OS=09258470&RS=09258470
owner: Google Inc.
number: 09258470
owner_city: Mountain View
owner_country: US
publication_date: 20140730
---
Unless otherwise indicated herein the materials described in this section are not prior art to the claims in this application and are not admitted to be prior art by inclusion in this section.

Advances in computational imaging have led to interesting applications of multi camera imaging systems. Two or more cameras may capture images of the same scene from different viewpoints and or under different capture conditions and computational imaging techniques may be used to form a composite image based on the two or more captured images. Such techniques include dynamic range enhancement and multi spectrum imaging among others. Image processing techniques may be used to overcome or alleviate parallax effects caused by the different viewpoints of the two or more cameras.

Disclosed herein are multi camera systems that are configured to reduce and hopefully eliminate parallax effects caused by capturing images of the same scene from different viewpoints. In particular an example multi camera system may be configured to simultaneously capture two or more images of the same scene from the same imaging axis e.g. such that the centers of the fields of view captured in the images are aligned . For example a first camera may be positioned behind a second camera so that both cameras can capture light originating from a common imaging axis but the second camera does not appear in the field of view of the first camera. Such cameras can have different optical characteristics e.g. field of view light sensitivity spectral response or depth of field while still sharing the same viewpoint which can be advantageous for many applications.

In one example a composite imaging system is provided. The composite imaging system includes a first imaging system comprising a first image sensor and a first aperture anterior to the first image sensor. The first aperture i is defined by an inner perimeter and an outer perimeter and ii defines at least in part a field of view of the first imaging system. The first imaging system further includes a plurality of reflectors posterior to the first aperture that are configured to redirect light that crosses the first aperture to the first image sensor. The first image sensor the first aperture and the plurality of reflectors are arranged around a common optical axis. The composite imaging system further includes a second imaging system arranged substantially anterior to the first imaging system. The second imaging system includes a second image sensor and a second aperture located anterior to the second image sensor. The second aperture defines at least in part a field of view of the second imaging system and the second aperture and the second image sensor are arranged around the common optical axis. The second imaging system is arranged such that the second imaging system is outside a field of view of the first imaging system.

In another example a composite imaging system is provided. The composite imaging system includes a first imaging system that further includes a first image sensor and a first aperture anterior to the first image sensor. The first aperture i is defined by an inner perimeter and an outer perimeter and ii defines at least in part a field of view of the first imaging system. The first imaging system further includes a first plurality of reflectors posterior to the first aperture that are configured to redirect light that crosses the first aperture to the first image sensor. The first image sensor the first aperture and the first plurality of reflectors are arranged around a common optical axis. The composite imaging system further includes a second imaging system arranged substantially anterior to the first imaging system that includes a second image sensor and a second aperture anterior to the second image sensor. The second aperture i is defined by an inner perimeter and an outer perimeter and ii defines at least in part a field of view of the second imaging system. The second imaging system further includes a second plurality of reflectors posterior to the second aperture configured to redirect light that crosses the second aperture to the second image sensor. The second image sensor the second aperture and the second plurality of reflectors are arranged around the common optical axis and the second imaging system is arranged such that the second imaging system is outside the field of view of the first imaging system

In yet another example the composite imaging system also includes a third imaging system arranged substantially anterior to the second imaging system. The third imaging system includes a third image sensor and a third aperture anterior to the third image sensor. The third aperture defines at least in part a field of view of the third imaging system. The third aperture and the third image sensor are arranged around the common optical axis and the third imaging system is arranged such that the third imaging system is outside the respective fields of view of the first and second imaging systems. The composite imaging system may also include a first passband filter having a first transmission band the first passband filter being operably coupled to the first image sensor a second passband filter having a second transmission band the second passband filter being operably coupled to the second image sensor and a third passband filter having a third transmission band the third passband filter being operably coupled to the third image sensor. The first second and third transmission bands respectfully represent primary colors.

These as well as other aspects advantages and alternatives will become apparent to those of ordinary skill in the art by reading the following detailed description with reference where appropriate to the accompanying figures.

Exemplary methods and systems are described herein. It should be understood that the word exemplary is used herein to mean serving as an example instance or illustration. Any embodiment or feature described herein as exemplary or illustrative is not necessarily to be construed as preferred or advantageous over other embodiments or features. More generally the embodiments described herein are not meant to be limiting. It will be readily understood that certain aspects of the disclosed systems and methods can be arranged and combined in a wide variety of different configurations all of which are contemplated herein.

Multi camera systems are useful for simultaneously capturing images of the same object or scene from different viewpoints and or under different capture conditions. But the differing viewpoints of the cameras may cause a parallax effect where the same object appears to be at different respective positions within the fields of view of the cameras. That is along two different lines of sight the same object may have two different apparent positions within captured images. In addition the object may appear to be in front of or behind different surroundings from each viewpoint. While a parallax effect may be advantageous in certain applications such as stereoscopic imaging and depth extraction the parallax effect may complicate computational imaging techniques such as dynamic range enhancement multi spectrum imaging and virtual frame rate enhancement for instance. Because cameras of traditional multi camera systems are not aligned on the same optical axis they do not capture images from the same viewpoint which may result in a parallax effect.

Disclosed herein are multi camera systems that are configured to reduce and hopefully eliminate parallax. In particular an example multi camera system may be configured to simultaneously capture two or more images of the same scene from the same imaging axis e.g. such that the centers of the fields of view captured in the images are aligned . Such cameras can have different optical characteristics e.g. field of view light sensitivity spectral response or depth of field while still sharing the same viewpoint which can be advantageous for the applications such as those listed above.

In some embodiments a first camera and a second camera are aligned along an optical axis with the second camera positioned in front of the first camera. An aperture of the second camera may be positioned in front of an aperture of the first camera. Similarly an image sensor of the first camera may be located behind an image sensor of the second camera. Light that is captured by the first camera may travel past the second camera. Although the second camera lies on the optical axis in front of the first camera the first camera is configured to redirect light to the image sensor of the first camera after the light has passed the second camera.

Each of the applications and may include instructions that when executed cause the computing device to perform specific tasks or functions. Applications and may be native applications i.e. installed by a manufacturer of the computing device and or a manufacturer of the operating system or may be a third party applications installed by a user of the computing device after purchasing the computing device. A non exhaustive list of example applications includes a media player application that accepts media files as inputs and generates corresponding video and or audio to the output device s an e reader application which accepts electronic documents books magazines etc. as input and presents the content of the document via the output device s a feed reader that accepts feeds delivered over the Internet e.g. RSS feeds and or feeds from social network sites as input and presents the feeds via the output device s a map application that displays a map via the output device s a note taking application a bookmarking application and a word processing spreadsheet and or presentation application that accepts specifically formatted files as inputs and presents them via the output devices for viewing and or editing. The applications may also include a still frame image capture application or a video camera application.

The operating system may interact with and manage hardware to provide services for the applications and . For example an application may request that the operating system direct an integrated camera s of hardware to capture a visual image and that the hardware store the image to memory or display a modified image on a user display. Or an application may request that the operating system direct a GPS receiver of hardware to detect the geolocation of the computing device . In some embodiments the computing device may include firmware instead of or in addition to an operating system . Other examples are possible.

The hardware may include for example a central processing unit CPU a graphics processor GPU memory an input output I O interface a GPS receiver image capture devices cameras inertial sensors microphones user input device s and output device s . Components of hardware may be controlled by instructions contained in applications and and operating system . Other examples are possible.

The central processing unit CPU may be operable to effectuate the operation of the computing device by executing instructions stored in memory or disk storage. Such instructions may include the operating system and the applications and . The CPU may for example comprise a single or multi core processor an application specific integrated circuit ASIC field programmable gate array FPGA and or any other suitable circuitry.

The graphics processor may be operable to generate a video stream for output to the screen based on instructions and or data received from the CPU. That is data structures corresponding to images to be displayed on the screen may be stored to and read from the memory or disk storage by the CPU. The data may also be transferred directly from the integrated camera. The CPU may convey such data structures to the graphics processor via a standardized application programming interface API such as for example Standard Widget Toolkit SWT the DirectX Video Acceleration API the Video Decode Acceleration Framework API or other suitable API.

The memory may include program memory and run time memory. The memory may for example comprise non volatile memory volatile memory read only memory ROM random access memory RAM flash memory magnetic storage and or any other suitable memory. Program memory may store instructions executable by the CPU to effectuate operation of the operating system and the applications and . Runtime memory may store data generated or used during execution of the operating system or applications and

The input output I O interface may be operable to receive signals from the input device s and provide corresponding signals to the CPU and or the graphics processor.

The input device s may include for example a mouse a touchpad a motion sensor a trackball a voice recognition device a keyboard or any other suitable input device which enables a user to interact with the computing device .

The output devices may include for example a screen and speakers. The screen may be for example a liquid crystal display LCD screen an OLED screen an e ink screen and or any other suitable device for presenting a graphical user interface.

The computing device may be used in conjunction with an imaging system as described below and shown in A B and .

The imaging system e.g. an origami lens may comprise a disc shaped object made of ceramics plastic and or metals but may assume other shapes and materials as well.

The aperture may have an annular or ring like shape defined by the outer perimeter and the inner perimeter . However in some examples the outer perimeter the inner perimeter or the aperture may have irregular shapes or polygonal shapes other than a circle or a ring. The aperture may be an opening in a top surface of the imaging system or could otherwise include a protective transparent window that does not substantially disturb the path of light rays such as light rays A and B that cross the aperture . The aperture may be defined by a ring shaped portion of a plane that is substantially perpendicular to the optical axis .

The image sensor may be configured to capture an image of light incident upon the image sensor i.e. light such as light rays A and B that cross the aperture and to provide data to a computing system i.e. via an input output interface representing the captured image. The image sensor may include a CMOS complementary metal oxide semiconductor sensor or a CCD charge coupled device sensor among other possibilities. The image sensor may be aligned perpendicularly to the optical axis . As shown in the image sensor may be mounted underneath a hole in the back internal surface however in other examples the image sensor could be mounted on the back internal surface within a cavity defined by the back internal surface and the front internal surface or flush with the back internal surface . Other locations are possible.

As shown in light rays A and B may travel in a downward direction and cross the aperture . After crossing the aperture the light rays A and B may be reflected by the back internal surface toward the front internal surface . The back internal surface may be a continuous reflective surface or include a plurality of distinct reflectors angled to direct light toward the image sensor and or the front internal surface .

After the light rays A and B reflect off the back internal surface the light rays A and B may travel toward the front internal surface . The front internal surface may also be a continuous reflective surface or include a plurality of distinct reflectors angled to direct light toward the image sensor and or the back internal surface . The front internal surface together with the back internal surface may be structured so that the imaging system functions as a lens with a focal length defined by structural characteristics of the back internal surface and the front internal surface .

The light rays A and B may be reflected multiple times by the front internal surface and the back internal surface as the light rays A and B travel from the aperture toward the image sensor . After a number of reflections off the front internal surface and the back internal surface the light rays A and B may become incident upon the image sensor . In this way images of objects within a field of view of the imaging system may be captured.

The inner perimeter forms a radial boundary of the front external surface . The front external surface may be reflective or opaque but generally does not allow a substantial amount of light to pass through the front external surface . This ensures that for light to enter the cavity defined by the back internal surface and the front internal surface such light passes through the aperture and does not impact the front external surface .

The optical axis may define an axis of rotational symmetry or other axis of symmetry for the aperture the outer perimeter the inner perimeter the image sensor the back internal surface and the front internal surface or any reflectors that make up the back internal surface and or the front internal surface .

It should be noted that dimensions of the imaging system in may not be to scale and are for illustrative purposes only. It should also be noted that any depicted angles and or directions of refraction or reflection of light depicted in are purely for illustrative purposes and are not necessarily to scale.

The aperture may be a ring shaped or annular gap or opening similar to the aperture described above with regard to . The aperture may be defined or bounded by the inner perimeter and the outer perimeter .

As shown in light rays C and D may cross the aperture and become incident upon the back internal reflector A. The back internal reflector A may reflect the light rays C and D to be incident upon the front internal reflector . Then the front internal reflector may reflect the light rays C and D to be incident upon the back internal reflector C. Next the back internal reflector C may reflect the light rays C and D to be incident again upon the front internal reflector . Then the front internal reflector may reflect the light rays C and D to be incident upon the back internal reflector E. Next the back internal reflector E may reflect the light rays C and D to be incident yet again upon the front internal reflector . Then the front internal reflector may reflect the light rays C and D to be incident upon the back internal reflector F. Next the back internal reflector F may reflect the light rays C and D to be incident yet again upon the front internal reflector . Finally the front internal reflector may reflect the light rays C and D to be incident upon the image sensor . In other examples the back internal reflectors B and D may reflect light rays indirectly toward the image sensor as well.

Similar to the light rays C and D after the light rays E and F cross the aperture the light rays E and F may be directed to the image sensor by the front internal reflector and or the back internal reflectors G L.

The inner perimeter forms a radial boundary of the front external surface . The front external surface may be reflective or opaque but generally does not allow a substantial amount of light to pass through the front external surface . For light to enter a cavity defined by the back internal reflectors A L and the front internal surface such light generally passes through the aperture and does not impact the front external surface .

It should be noted that dimensions of the composite imaging system or the object represented in may not be to scale and are for illustrative purposes only. It should also be noted that any depicted angles and or directions of refraction or reflection depicted in are purely for illustrative purposes and are not necessarily to scale.

The optical axis may define an axis of rotational symmetry or other axis of symmetry for the image sensors and the apertures and the front internal reflectors and the first and second pluralities of back internal reflectors and and the composite imaging system as a whole.

The first imaging system comprising the first image sensor the first aperture the first front internal reflector and the first plurality of back internal reflectors may be configured to capture images of the object . For example the light ray may travel from the first end A of the object past the second imaging system through the first aperture and be reflected by a reflector of the first plurality of back internal reflectors toward the first front internal reflector . The light ray may further be reflected by the first front internal reflector and the first plurality of back internal reflectors as described above in regard to to become incident upon the first image sensor .

The light ray may travel from the second end B of the object past the second imaging system through the first aperture and be reflected by a reflector of the first plurality of back internal reflectors toward the first front internal reflector . The light ray may further be reflected by the first front internal reflector and the first plurality of back internal reflectors as described above in regard to to become incident upon the first image sensor . As light rays and and other light rays representing the object become incident upon the first image sensor a real image of the object may be formed upon the first image sensor . Rays of light that originate from a point on the optical axis and travel past the second imaging system such as light rays and may be directed by components of the first imaging system to a point on the first image sensor that is on the optical axis .

The second imaging system comprising the second image sensor the second aperture the second front internal reflector and the second plurality of back internal reflectors may be configured to capture images of the object . A back surface of the second imaging system may be mounted to a front surface of the first imaging system so that the second imaging system is outside a field of view of the first imaging system . That is the second imaging system may be sized and mounted such that it is impossible for light originating from or reflected by the second imaging system to cross the first aperture and reach the first image sensor . For example an inner perimeter of the first imaging system may be larger than an outer perimeter of the second imaging system .

The light ray may travel from the first end A of the object through the second aperture and be reflected by a reflector of the second plurality of back internal reflectors toward the second front internal reflector . The light ray may further be reflected by the second front internal reflector and the second plurality of back internal reflectors as described above in regard to to become incident upon the second image sensor .

The light ray may travel from the second end B of the object through the second aperture and be reflected by a reflector of the second plurality of back internal reflectors toward the second front internal reflector . The light ray may further be reflected by the second front internal reflector and the second plurality of back internal reflectors as described above in regard to to become incident upon the second image sensor . As light rays and and other light rays representing the object become incident upon the second image sensor a real image of the object may be formed upon the second image sensor . In some examples the second imaging system could be any sort of imaging system i.e. possibly not include an origami lens as shown in .

The image sensors and may be aligned perpendicularly to the optical axis and face a common direction upward in this example . In this example the first image sensor is located below the second image sensor along the optical axis . In one example the first image sensor may be a black and white image sensor i.e. not operably coupled to a color filter while the second image sensor may be a color image sensor e.g. operably coupled to a mosaic or Bayer color filter . Since the color filter may attenuate an intensity of light that is detected by pixels of the second image sensor it may be beneficial to use color information detected by the second image sensor and brightness information detected by the first image sensor to form a composite image with a high level of detail in both brightness and color. In another example the first image sensor could be a color image sensor and the second image sensor could be a black and white image sensor.

As another example the first image sensor could have a low pixel density i.e. large pixels with a resultant high light sensitivity and the second image sensor may have a high pixel density and resultant low light sensitivity. Here the first image sensor could be used to capture brightness information and the second image sensor could be used to capture better spatial resolution information to form a composite image with images simultaneously respectively captured by the first image sensor and the second image sensor . In another example the first image sensor may have a high pixel density and the second image sensor could have a low pixel density.

In some examples it may be useful for the first imaging system and the second imaging system to have different depths of field. For example the first aperture or a corresponding entrance pupil may be wider or narrower than the second aperture or a corresponding entrance pupil . An entrance pupil of an imaging system may represent a virtual aperture coplanar with an aperture of the imaging system that is wider or narrower than the aperture based on optical characteristics of the imaging system e.g. a focal length . In this case the first aperture or an entrance pupil defined by the first aperture and an effective focal length of the first imaging system may be wider or narrower than the second aperture or an entrance pupil defined by the second aperture and an effective focal length of the second imaging system . In another example it may be useful for the first imaging system and the second imaging system to have substantially equally sized and shaped entrance pupils when measured at each imaging system s respective aperture plane.

Or it may be useful for the first imaging system to have a narrower or a wider field of view than the second imaging system in which case the first front internal reflector and the first plurality of back reflectors may be configured so that the first imaging system has a shorter or a longer focal length i.e. degree of zoom than the second imaging system .

Note that positioning the first aperture at a perimeter region of the first imaging system may allow for almost any type of second imaging system to be stacked on top of or in front of the first imaging system such that the optical axes of the first and second imaging systems are aligned. For example shows a second imaging system with a lens that receives light through an aperture that is centered on the optical axis.

The second imaging system may be configured to capture an image of the object with a field of view being centered on the optical axis . The first imaging system may also be configured to capture an image of the object with a field of view of the image being centered on the optical axis .

For example a light ray and a light ray A travelling parallel to the optical axis may travel respectively from a first end A and a second end B of the object . The light ray and the light ray A may pass through the aperture be refracted by the lens and become incident upon the image sensor to form an image of the object upon the image sensor .

The first imaging system may include an attachment module comprising the first clip A and the second clip B. The first clip A may be configured to restrain the second imaging system against the first imaging system at a first side of the second imaging system and the second clip B may be configured to restrain the second imaging system against the first imaging system at a second side of the second imaging system . The clips A and B may include a tension spring that allows the clips A and B to open to clasp a surface of the second imaging system and to apply a restraining force to the surface of the second imaging system . The clips A and B may have any size shape or location upon the first imaging system that is suitable for restraining various sizes of second imaging systems against the first imaging system .

Further includes attachment features which provide for modular composite imaging system embodiments. The attachment features which are clips A and B in the illustrated embodiment allow the composite imaging system to be modular. That is different second imaging systems with various types of lenses could be interchangeably attached on top or in front of the first imaging system e.g. a first imaging system including an origami lens . For example a user could interchangeably attach to the first imaging system a second imaging system including a macro lens a wide angle lens a portrait lens a fisheye lens and or lenses with different filters among other possibilities on top of the first imaging system . Note that the clips A and B in the illustrated embodiment are but one example of attachment features. In other implementations magnetic adhesive or interlocking attachment features could be used. More generally any type attachment features could be incorporated so long as it allows for a second imaging system lens and or image sensor structure to be removably attached to the first imaging system. Further more or less than two attachment features are possible.

Alternatively the image A could be captured by the second imaging system or respectively of and the image B could be captured by the first imaging system or respectively of .

As shown in the first imaging system and the second imaging system depicted in may be configured to simultaneously capture an image of light sources or light reflecting off objects from a common viewpoint and with very little or zero parallax disparity. For example the first object e.g. a first runner the second object e.g. a second runner and the third object e.g. a flower pot may have the same apparent spatial relationships in both images A and B. For instance the first object may appear to be in front of the second object and the second object may appear to be in front of the third object . Also the objects may appear to overlap at the same places in both images A and B. For instance the first runner s right leg i.e. first object may appear to be in front of the second runner s left leg i.e. the second object . Also the second runner s right leg i.e. the second object may appear to be in front of the flower pot i.e. the third object . It should be noted that the images A and B depict a common viewpoint i.e. both images share a common optical axis .

The first imaging system the second imaging system and the third imaging system may function similarly and have similar structure to the first imaging system or the second imaging system of or the imaging systems and of respectively.

In one example the first image sensor may be operably coupled to a first passband filter not shown having a first transmission band the second image sensor may be operably coupled to a second passband filter not shown having a second transmission band and the third image sensor may be operably coupled to a third passband filter not shown having a third transmission band. The first second and third transmission bands may respectively correspond to primary colors such as red green and blue. In other examples any of the first second or third image sensors and could be operably coupled to passband filters with passbands corresponding to any one of the primary colors such as red 620 750 nm green 495 570 nm and blue 450 495 nm . The composite imaging system could be used to simultaneously i use the first imaging system to capture an image of red wavelengths representing an object ii use the second imaging system to capture an image of green wavelengths representing the object and iii use the third imaging system to capture an image of blue wavelengths representing the object. These images could be combined into a composite image with higher color resolution less color crosstalk and better brightness and or contrast than an image captured using a single image sensor with a traditional mosaic e.g. Bayer filter.

It should be understood that arrangements described herein are for purposes of example only. As such those skilled in the art will appreciate that other arrangements and other elements e.g. machines interfaces functions orders and groupings of functions etc. can be used instead and some elements may be omitted altogether according to the desired results. Further many of the elements that are described are functional entities that may be implemented as discrete or distributed components or in conjunction with other components in any suitable combination and location or other structural elements described as independent structures may be combined.

While various aspects and embodiments have been disclosed herein other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting with the true scope being indicated by the following claims along with the full scope of equivalents to which such claims are entitled. It is also to be understood that the terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting.

