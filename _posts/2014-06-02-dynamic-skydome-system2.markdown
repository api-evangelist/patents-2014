---

title: Dynamic skydome system
abstract: The disclosure provides for a dynamic skydome system for generating dynamic atmospheric and/or sky effects for use in electronic visual media, such as for games and movies. The features of the dynamic skydome system of the disclosure include mimicking real-world behavior of the sky through a 24 hour cycle, providing a physically based rendering model with multiple atmospheric scatterings; simulating astronomically correct celestial bodies; producing god rays; providing aerial perspectives; and dynamically lighting volumetric clouds.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09582929&OS=09582929&RS=09582929
owner: CONFETTI INTERACTIVE INC.
number: 09582929
owner_city: Encinitas
owner_country: US
publication_date: 20140602
---
This application claims priority under 35 U.S.C. 119 from Provisional Application Ser. No. 61 831 115 filed Jun. 4 2013 the disclosure of which is incorporated herein by reference.

This disclosure provides for a system of generating real time dynamic atmospheric and or sky based effects for electronic visual media.

Developments in atmospheric or sky effects for electronic visual media have had a profound impact on many types of media and have revolutionized animation movies and the video game industry.

The disclosure provides for a dynamic skydome system that generates dynamic atmospheric and or sky effects for use in electronic visual media such as for games and movies. The features of the dynamic skydome system include but not limited to mimicking real world behavior of the sky through a 24 hour day night cycle providing a physically based rendering model with multiple atmospheric scatterings simulating astronomically correct sun stars and moon producing god rays providing aerial perspectives and dynamically lighting volumetric clouds.

Disclosed herein is a system for generating dynamic atmospheric effects for electronic visual media i.e. a dynamic skydome system . The dynamic skydome system disclosed herein provides innovative methods for generating dynamic lighting effects for atmospheric objects sky coloring and scene presentation that are of a quality which greatly exceed those produced by current methods in electronic visual media.

In a certain embodiment the disclosure provides a dynamic skydome system that performs dynamic actual lighting for all accumulated objects in one rendering pass and or calculates the color of the sky or atmosphere in the vertex shader wherein the dynamic skydome system is carried out using a device comprising a graphics processing pipeline. In a further embodiment the disclosure provides for a dynamic skydome system which comprises lighting one or more objects using depth encoding and or blending rendering the one or more objects into a single impostor and lighting the one or more objects in a single rendering pass.

In another embodiment the disclosure provides a dynamic skydome system that performs actual lighting for all accumulated objects e.g. clouds celestial bodies and atmospheric particles such as fog haze or smoke in one rendering pass comprising one or more steps of rendering one or more objects accumulated depth and weight into a texture buffer using a blending algorithm to perform actual accumulation reading the accumulated depth and depth weight from the texture buffer once all of the one or more objects are rendered to the screen and smoothing the read data using hardware texture bilinear interpolation reconstructing the depth of the one or more objects using the smoothed read data and or performing actual lighting for all accumulated objects in one rendering pass by using the reconstructed depth to reconstruct position of the one or more objects.

In a particular embodiment the disclosure provides for lighting one or more objects by implementing a blending algorithm comprising 1 DepthAcc OldDepthAcc 1 newDepthWeight NewDepth NewDepthWeight 2 DepthWeightAcc OldDepthWeightAcc 1 newDepthWeight NewDepthWeight and 3 Final depth DepthAcc DepthWeightAcc. In a further embodiment a two channel floating point 16 bit render target stores the accumulated depth and normalization weight of multiple particles for each pixel of impostor. In an alternate embodiment a four channel floating point 16 bit render target stores the accumulated depth and normalization weight of multiple particles for each pixel of an impostor and also stores normal or per particle ambient occlusion data.

In a particular embodiment a dynamic skydome system disclosed herein calculates the color of a sky or an atmosphere in the vertex shader by moving the texture coordinates and texture read into the vertex shader and utilizing the vertex to pixel shader hardware interpolators to perform the interpolation in the 4dimension.

In another embodiment the disclosure provides a dynamic skydome system that calculates the color of the sky and or atmosphere in the vertex shader comprising one or more steps of reading the low frequency 4 dimensional data from the 3 dimensional texture using hardware linear interpolation in the vertex shader writing the data from the previous step to a hardware interpolator with linear interpolation enabled interpolating data for every pixel being generated by rasterizer using the hardware interpolator reading the pixel data into the pixel shader from the hardware interpolator and using the data to calculate sky and or atmosphere color.

In a certain embodiment a dynamic skydome system disclosed herein can perform one or more of the following mimicking the real world behavior of a sky through a 24 hour day night cycle performing physically based rendering with multiple atmospheric scatterings simulating of celestial bodies that are astronomically correct generating god rays providing aerial perspectives and dynamically lighting volumetric clouds.

In a further embodiment the dynamic skydome system is carried out using a device comprising a graphics processing pipeline such as a computer e.g. a video game console or flight simulator.

As used herein and in the appended claims the singular forms a and and the include plural referents unless the context clearly dictates otherwise. Thus for example reference to value includes a plurality of such values and reference to polygon includes reference to one or more polygons and equivalents thereof known to those skilled in the art and so forth.

Unless defined otherwise all technical and scientific terms used herein have the same meaning as commonly understood to one of ordinary skill in the art to which this disclosure belongs.

The realistic simulation of outdoor scenes presents significant challenges. A common approach to simulate outdoor scenes is by modeling a dome i.e. a skydome to provide the impression of a sky and objects typically seen in the sky such as clouds moon stars and sun. A skydome can also be used to simulate outdoor scenes from hypothetical environments such as atmospheres from imaginary worlds and moons.

Clouds play an important role in simulating outdoor environments. Realistic looking clouds can be one of the most compelling graphical components of outdoor scenes especially for real world applications such as flight simulators and movie productions. The appearance of clouds is affected by the light cast by the sun and filtered from the sky which must be reflected in the cloud shading. Moreover in the real world clouds do not remain static they are dynamic. They move across the sky from areas of moisture and unstable air and dissipate when these conditions abate. Therefore the presentation of clouds in electronic visual media should accurately reflect their dynamic nature.

Additionally the computing device may include a graphics card processor for handling one or more graphics processing functions of the computing device for displaying graphics images user interfaces or any other type of visual element to the display device . In one embodiment the computing device includes an expansion card that interprets drawing instructions sent by the central processor CPU processes them via a dedicated graphics processor and writes the resulting frame data to the frame buffer also called or otherwise is part of the video adapter . The graphics processor may perform one or more graphics processing functions such as bitmap transfers and painting window resizing and repositioning line drawing font scaling and polygon drawing. The graphics processor may be designed to handle these tasks in hardware at far greater speeds than the software running on the system s central processor . The graphics processor may be any type of graphics processor such as any graphic processing chip provided or manufactured by Nvidia Corporation of Santa Clara Calif. or Advanced Micro Devices Inc. of Sunnyvale Calif. The graphics processor may be part of any type of graphics card such as any of the graphics cards incorporating the Nvidia graphics processor such as Nvidia s series of GeForce graphics chip or the Radeon series of graphics cards from Advanced Micro Devices. One ordinarily skilled in the art will recognize and appreciate the various types and wide range of graphics card processors that may be used in the computing device .

Although generally described as a graphics processor or a processor dedicated to graphics processing functions the processor can be any type of general purpose processor GPP or any other type of integrated circuit such as a Field Programmable Gate Array FPGA Programmable Logic Device PLD or Application Specific Integrated Circuit ASIC . Furthermore although the illustrative embodiment of the computing device is described with a separate processor for graphics related processing the central processor may provide for such graphics related processing. Alternatively the computing device may have multiple processors to distribute processing of computing tasks along with any graphics processing functions. In one embodiment the graphics card processor of the computing device has multiple graphics processors such as for example the dual GPU graphics card provided or manufactured by Giga Byte Technology Co. LTD of Taipei Hsien Taiwan. In another embodiment the graphics processor performs graphics oriented operations but also other computations such as any operation of the processor such as a CPU. One ordinarily skilled in the art will recognize and appreciate that any type of computing device with any type of processor may be used to perform the operations of the present invention as described herein.

In the dynamic skydome system disclosed herein provides a simulation environment for generating modeling creating editing or otherwise handling manipulating and processing images. In brief overview the simulation environment provides a platform for image based design processing and simulation of outdoor and or indoor scenes including naturally occurring atmospheres and terrains naturally occurring dynamic systems along with any man made objects structures and or system. The simulation environment may include one or more images representing visually graphically or otherwise a scene such as an outside scene. For example the image may comprise a photo realistic near photo realistic or otherwise substantially realistic representation of an outside scene including an atmosphere such as a sky sun stars moon and clouds.

The simulation environment includes a graphical user interface for interactively creating and working with images and may also provide for simulating editing configuring and processing the images . The simulation environment may read save interpret or otherwise process image files in any format known to one ordinarily skilled in the art.

The simulation environment may comprise any suitable configuration mechanism for configuring any elements and properties of the image the simulation and rendering of one or more images and or the simulation environment . The configuration mechanism may comprise any type of user interface such as a graphical user interface or command line interface. As such it may comprise any user interface mechanisms such as menu items forms toolbars etc. as known by ordinarily skilled in the art to provide a user interface to receive user input with regards to configuration.

The simulation environment also comprises one or more libraries to provide for the processing of images and at least a portion of the operations of the present invention described herein. Although described as libraries the libraries may take the form of any type of executable instructions capable of performing the operations described herein.

In an exemplary embodiment the libraries may include Direct3D or DirectX SDK manufactured by Microsoft Corporation of Redmond Wash. to provide an application programming interface API in the operating system to graphics and sounds functionality provided by the hardware of the computing device . In some embodiments the libraries include any application programming interfaces APIs supporting the OpenGL standards and specifications as known by those ordinarily skilled in the art.

Additionally the libraries may include any portion of the CG Toolkit manufactured by Nvidia Inc. of Santa Clara Calif. wherein Cg is a high level language for graphics programming. The libraries may also include any portion of executable instructions manufactured by The Freetype Project located at www.freetype.org which is a high quality portable font engine and in other embodiments may include any suitable font engine. Additionally the libraries may include any executable instructions of the Developer s Image Library DevIL manufactured by Denton Woods.

The libraries of the simulation environment may include any programming related APIs and libraries such as STLport manufactured by STLport Consulting of San Francisco Calif. Xerces of the Apache XML Project provided by the Apache Software Foundation Inc. of Forest Hill Md. and any publicly available libraries authored by Beman Dawes and David Abrahams located at boost.org. Additionally to support file and data compression related functionality in the simulation environment the libraries may include any type of compression libraries such as the Zlib library provided by The GNU Project of the Free Software Foundation of Boston Mass. Furthermore the libraries may include windowing and graphical widgets for graphics APIs and engines such as Crazy Eddie s GUI System located at cegui.org.uk which is a publicly available object orientated tool for building graphical user interface systems.

The simulation environment comprises a simulation engine and rendering mechanism . The simulation engine provides the graphics processing functionality and instructions of the present invention for image simulation and the rendering of the image via the rendering mechanism . The rendering mechanism includes means and mechanisms as known by those ordinarily skilled in the art to cause the rendering of the image to the visual display device of the computing device . In the rendering stage of graphics image processing typically performed by the graphics card processor in conjunction with the video adapter the pixels are drawn to the video display device .

The graphics processing portion of the simulation engine comprises shader programs such as pixel shader program and vertex shader program . The terms shaders may be used instead of program or shader program to refer to the portions of executable instructions that program certain parts of the graphics processing pipeline. The computational frequency that may be supported in graphics related hardware such as a graphics card processor is per vertex and per pixel fragment. As such there are two different kinds of shaders vertex shaders and pixel shaders . A pixel shader provides graphics processing on a pixel basis and a vertex shader provides graphics processing on a vertex basis.

Pixel shaders may also include or be referred to as fragment shaders. As known by those ordinarily skilled in the art fragments are all the points of three dimensional scene that are projected onto a two dimensional xy plane such as in an OpenGL based implementation. A fragment contains information such as position and texture coordinates and several fragments can be added together when displayed to a pixel on the screen.

As known by those ordinarily skilled in the art a vertex shader is a set of graphics processing instructions used to add special effects to objects in a three dimensional 3D environment by performing mathematical operations on an object s vertex data. Objects in a 3D scene such as those provided by the image of the simulation environment may be described using polygons such as triangles which in turn are defined by their vertices. Vertex data refers to the data set identifying and or describing the vertices of the triangles representing the 3D scene. A vertex shader can change the position or any other attributes of a vertex. Vertex shaders may get executed for each vertex that passes through the graphics processing pipeline.

Pixel shaders as known by those ordinarily skilled in the art are graphics processing instructions that calculate effects on a per pixel basis. In some embodiments the pixel shader receives as input computational results from a vertex shader such as the vertex position. Generally in the art the pixel shader uses input provided by the vertex shader and any other attributes such as user defined attributes generated or modified colors and texture coordinates and combine the information to form a final color value that gets passed to the final stages of rendering. However in a particular embodiment the dynamic skydome system disclosed herein calculates the sky and or atmosphere color in the vertex shader instead of the pixel shader by utilizing hardware interpolators between the vertex shader and the pixel shader .

With the graphics cards processor of the computing device being programmable the pixel shader and vertex shader can comprise customized executable instructions to provide desired graphics processing of vertex and pixel fragment data associated with the image . In an exemplary embodiment the simulation environment provides at least a portion of the real time execution of the realistic approximation of natural atmospheric lighting phenomena of the present invention via one or more vertex shaders and or pixel shaders .

The simulation environment and any portion thereof can be an application module library software component or any other type of computer program or executable instruction which is designed to and capable of executing the functionality of the simulation environment as described herein. Additionally the simulation environment and any portion thereof may be executed as an application program service process task or any other form of execution unit known by those skilled in the art. Furthermore the simulation environment and any portion thereof may be designed to run on any type of processor microprocessor operating system or computing device .

The simulation environment can be capable of and configured to operate on and take advantage of different processors of the computing device . For example the simulation environment can run on a 32 bit processor of one computing device and a 64 bit processor of another computing device . Additionally the simulation environment can be capable of and configured to operate with and take advantage of different graphical cards processors of the computing device . For example any shader program of the simulation engine may be designed to operate on and take advantage of any type of graphical processor . Furthermore the simulation environment can operate on computing devices that can be running on different processor architectures with different graphical processing cards and processors in addition to different operating systems. One ordinarily skilled in the art will recognize the various combinations of operating systems processors or graphical cards that can be running on the computing device . In summary the simulation environment may be deployed across a wide range of different computing devices different operating systems and different processors in various configurations. One ordinarily skilled in the art will appreciate the various ways the present invention may be practiced in a computing device.

In a particular embodiment for the dynamic skydome system disclosed herein the image provided by the simulation environment comprises a realistic graphical and or visual representation of an outdoor scene including a natural atmospheric environment. In one embodiment the image is a photo realistic near photo realistic or otherwise substantially realistic representation of the outdoor scene. The scene may comprise any combination of naturally occurring and or man made objects. In a brief overview the scene may comprise a terrain and an atmosphere. The terrain may include any physical features and characteristics of a planet s surface such as the earth or any other orbiting celestial object. As such the terrain may include a landscape with any type of land mass and one or more bodies of water. For example the land mass may include any type of mountain or hill or any range of mountains and hills. The bodies of water may be any type of water such as a puddle pond lake sea or ocean. Additionally the terrain may include any man made objects and or structures such as vehicles buildings houses and bridges. For example the terrain may provide a realistic representation of any man made structures or objects seen in any city town or country side known in the world. Also the terrain may include any flora or any other type of animal or creatures either living or fictional. Additionally the terrain may include any fauna or any other type of plant life or vegetation either actual or fictional.

The atmosphere represented by the scene of the image may include the sky a sun one or more clouds one or more celestial objects and one or more types of atmospheric particles. The clouds may be any type and or any portion of a formation of a cloud. The atmosphere may represent any portion of the atmosphere of the earth or any other planet or orbiting celestial land mass. The celestial objects may be any naturally occurring objects in the atmosphere sky or space such as the sun moon planets and stars. The atmosphere generally represents air molecules such as clean air molecules that may be available in any portion of the sky or atmosphere of the scene. The atmosphere may include any man made objects such as aircraft or satellites. Additionally the atmosphere may include any flora or any other type of animal or creature either living or fictional. The atmospheric particles represent portions of the atmosphere other than air molecules such as ice rain water droplets crystals snow fog haze dust smoke pollutants and any other particles solid or otherwise that may be an element of the atmosphere and or sky.

Although the scene is generally described as a photo or near photo realistic representation of known and existing terrain and atmosphere the scene may provide a photo or visual realistic representation of fictional terrain and atmosphere. Instead of the terrain and or atmosphere of the scene of the image being provided by terrain data related to actual measurements of terrain and atmospheric components related to the earth the terrain and or atmosphere may be generated or otherwise provided to realistically represent an imaginary scene. As such the scene may not be a scene of a terrain and atmosphere existing in the world but nevertheless may look as an actual existing terrain and atmosphere due to the photorealistic or visual realism of the image .

In order to provide for photorealistic or otherwise visually realistic representation of the scene the effect of the physics of light and optics needs to be considered for the many objects of the terrain and or atmosphere and the dynamic interactions between them. For example the effect of light from the sun and the sky along with shadows casted by clouds need to be considered to determine the color of a rendered object in the image as seen by a viewer from a certain viewing position with respect to a view of the scene.

In another aspect the present invention relates to the simulation and rendering of the natural atmospheric lighting phenomena associated with the scene of the image and any objects of the scene.

As a realistic representation image represents a three dimensional 3D view of an outdoor scene. This 3D representation needs to be projected and rendered to a two dimensional 2D display of the visual display device of the computing device . In a brief overview a scene comprises a terrain mesh and a skydome mesh integrated to form a geometric polygon representation of a scene which includes image . The terrain mesh provides a mesh for the terrain portion of a scene and the skydome mesh for the atmospheric e.g. sky portion of the scene. In an exemplary embodiment the atmosphere s geometry is defined as the set of all points below an infinite plane with some user specified height above the viewer although more complex models can be used as known by those ordinarily skilled in the art.

In one embodiment the invention provides techniques for determining the color of the triangle primitives of a skydome mesh to graphically render a scene to realistically represent natural atmospheric lighting. These techniques enable the graphical processing and rendering of the simulation of the natural atmospheric lighting to occur at sufficiently high enough rates to allow for a realistic representation of atmospheric objects in a scene. Furthermore the dynamic skydome system disclosed herein not only provides for real time rendering speeds but also provides for photo realistic near photo realistic visually realistic or otherwise substantially realistic simulation of natural atmospheric lighting. As such the present invention provides a simulation environment that can simulate and render images in real time and in a continuous manner to show the realistic visual effects of changes in natural atmospheric lighting upon one or more images .

In an exemplary embodiment the graphics processing pipeline depicted by illustrative method is programmable via shaders and . As such a vertex shader of the graphics processing portion of the simulation engine may provide desired vertex processing operations at step to provide for the realistic simulation and real time rendering of the natural atmospheric lighting of the dynamic skydome system disclosed herein. Likewise a pixel shader may provide desired pixel fragment processing operations at step to provide for the realistic simulation and real time rendering of the natural atmospheric lighting.

At step of the illustrative method the final colors of each of the primitives of the mesh representation of the image are rendered as impostors to a visual display device . Via the rendering mechanism impostors are written and or read to the frame buffer of the video adapter of the computing device . There may be hundreds to thousand or more polygons for each frame of a scene which must be updated and transmitted to the frame buffer. The frames are further processed converted or transformed into suitable analog and or digital output signals of the visual display device . The rate of transfer to the frame buffer and or visual display device is known as frame rate and is measured in frames per second fps . Each frame of a scene must be updated and transmitted through the frame buffer at a certain rate to give the illusion of movement.

In order to accelerate rendering imposters have generally been utilized. Imposters are transparent polygons i.e. billboards with an opaque texture mapped onto them. Impostors are used to accelerate rendering by exploiting frame to frame coherence. Impostors are particularly well suited to clouds even in circumstances under which they cannot be applied to the rendering of polygonal geometry. By using impostors the dynamic skydome system of the disclosed can render cloudy scenes of hundreds of clouds and hundreds of thousands of particles at very high frame rates. For example the dynamic skydome system disclosed herein can be used to render multiple cloud images into a single imposter and provide lighting effects for each cloud image in a single rendering pass e.g. see .

Steps for rendering an imposter into a scene can comprise cleaning the texture buffer setting up the view for rendering the object rendering a part of the view the size of the objects bounding box onto a texture that is stored in texture memory and placing a billboard in the virtual world and rendering the imposter texture onto it. Impostors can be updated dynamically. With this strategy if the user moves slowly or comes to a complete halt the image can be progressively refined to the correct image that is the one that would have been obtained by rendering the original geometry. A disadvantage of dynamically generated impostors arises from the potentially unbounded complexity of the geometry that needs to be converted into the image based representation. As the updates are done on the fly they must fit into the frame time budget allocated for generating the image .

The dynamic skydome system disclosed herein can visually and realistically simulate and render in real time natural atmospheric lighting and related phenomena for one or more images in an outdoor scene at high frame rates per second. Further the dynamic skydome system disclosed herein provides methods to approximate the visual effects of natural atmospheric lighting and related phenomena that are visually realistic which are computed in real time to render frames of a scene at high frame rates per second. The dynamic skydome system presented herein accounts for the light scattering effects due to sunlight and ambient light in relation to objects atmospheric particles and other scene elements.

The dynamic skydome system disclosed herein can provide images and simulations having visually realistic representations of sunlight at any time of day including from dawn to twilight along with accurate shadowing effects. The dynamic skydome system of the disclosure can also provide images and simulations having visually realistic representations of night or darkness cycles including the presentation of celestial objects such as stars and moons.

Additionally the dynamic skydome system of the disclosure provides visually realistic representations of a wide range of cloud formations resulting cloud cover over the landscape of a scene and shadows cast by clouds on elements of the scene. Furthermore the present invention provides a realistic simulation of the visual effects from light scattering by the cloud cover such as god rays and also provides visually realistic simulation of atmospheric particles of water i.e. rain hail snow mist and fog including accurate reflections refractions and turbulence. In a particular embodiment an atmospheric particle represents a portion of one or more of the following a cloud rain ice dust fog haze smoke pollutants and air. In a further embodiment at least one of the one or more atmospheric objects represents one or more of the following a sky a cloud a celestial body and a man made item. In yet a further embodiment the dynamic skydome system of the disclosure can determine the appropriate color for an object by calculating a realistic approximation of a visible effect on the natural atmospheric lighting phenomenon from one or more of the following in scattering light from atmospheric particles out scattering light from atmospheric particles sunlight illumination ambient illumination cloud appearance cloud density cloud lighting and cloud shadowing. In another embodiment the dynamic skydome system disclosed herein includes depicting the movement of at least one atmospheric object in the scene.

One of the many challenges with lighting a large number of visually depicted objects is that each object is an imposter and the imposter is flat. Accordingly to calculate a reasonable position for lighting each pixel is extremely difficult e.g. see . The disclosure provides a dynamic skydome system that overcomes these difficulties by providing an innovative way to calculate lighting each pixel in imposter space. In a particular embodiment the disclosure provides for a dynamic skydome system which comprises one or more steps of lighting one or more objects using depth encoding and or blending rendering the one or more objects into a single impostor lighting the one or more objects in a single rendering pass and or calculating the color of the sky or atmosphere in the vertex shader. In a further embodiment a dynamic skydome system performs actual lighting for all accumulated objects in one rendering pass e.g. see comprising the steps of rendering one or more objects accumulated depth and weight into a texture buffer using blending state to perform actual accumulation reading the accumulated depth and depth weight from the texture buffer once all of the one or more objects are rendered to the screen and smoothing the read data using hardware texture bilinear interpolation reconstructing the depth of the one or more objects using the smoothed read data performing actual lighting for all accumulated objects in one rendering pass by using the reconstructed depth to reconstruct position of the one or more objects .

In yet a further embodiment a dynamic lighting system disclosed herein stores the accumulated depth and normalization weight of multiple particles e.g. cloud particles for each pixel of impostor by a computer implementing a linear depth re construction algorithm of 

In yet a further embodiment a computer stores the accumulated depth and the normalization weight using a two channel floating point 16 bit render target. Typically when read by a computer the content of the two channel floating point 16 bit render target will be bilinear filtered. While the division of values is not linear the values are substantially consistent. In another embodiment a computer stores the accumulated depth and the normalization weight using a four channel floating point 16 bit render target. By utilizing a four channel floating point 16 bit render target in addition to bilinear filtering a normal or per particle ambient occlusion data may also be stored by a computer so as to allow for more complex lighting effects. The resulting Final depth value can then be applied to an image such as a representation of clouds e.g. see . An example of the implementation of the linear depth re construction method of the dynamic skydome system disclosed herein is demonstrated by the lighting of the clouds in .

The disclosure further provides for a dynamic skydome system disclosed herein which calculates sky or and or atmosphere color in the vertex shader instead of the pixel shader see . The dynamic skydome system disclosed herein calculates texture coordinates to read the textures and uses 4 dimensional interpolation. Hardware only provides 3 dimensional interpolation of texture data. Universally the 4dimension is interpolated in the pixel shader. By moving the texture coordinates and the texture read into the vertex shader the system utilizes the vertex to pixel shader hardware interpolators to perform the interpolation in the 4dimension thereby increasing the calculation s efficiency. In a further embodiment the sky color calculated in the vertex shader is of the same or higher quality as sky color calculated in a pixel shader. In particular embodiment the disclosure provides a dynamic skydome system that calculates sky and or atmosphere color comprising the steps of reading the low frequency 4 dimensional data from the 3 dimensional texture using hardware linear interpolation in the vertex shader writing the data from the previous step to a hardware interpolator with linear interpolation enabled interpolating data for every pixel being generated by rasterizer using the hardware interpolator reading the pixel data into the pixel shader from the hardware interpolator using the data to calculate sky and or atmosphere color . In a further embodiment additional data processing may be performed during the reading of data step .

In an alternate embodiment the dynamic skydome system disclosed herein performs the interpolation in the 4dimension using the pixel shader.

A number of embodiments have been described herein. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of this disclosure. Accordingly other embodiments are within the scope of the following claims.

