---

title: Methods and apparatus for load balancing across member ports for traffic egressing out of a port channel
abstract: Methods and apparatus for load balancing across member ports for traffic egressing out of a port channel are provided herein. An example method according to one implementation may include: assigning a quantized value based on current load to each of the network ports in the port channel; receiving a data packet addressed to egress through the port channel; identifying a traffic flow with which the received data packet is associated; determining whether the identified traffic flow is a new traffic flow; and selecting one of the network ports in the port channel as an egress port. Selection of the egress port may be weighted according to the quantized value of each of the network ports in the port channel.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09197564&OS=09197564&RS=09197564
owner: Cisco Technology, Inc.
number: 09197564
owner_city: San Jose
owner_country: US
publication_date: 20140811
---
This application is a continuation of co pending U.S. Utility application Ser. No. 13 476 114 filed May 21 2012 entitled Methods and Apparatus for Loan Balancing Across Member Ports for Traffic Egressing Out of a Port Channel which is hereby incorporated by reference in its entirety.

A port channel or ether channel link aggregation group load balancing group etc. is a single logical interface connection that is created by combining multiple network ports in order to provide higher throughput i.e. bandwidth as compared to each of the network ports alone. In addition to providing higher throughput a port channel also provides redundancy in the case of failure of individual network ports. A port channel is commonly deployed in network devices such as switches routers hubs gateways etc. in different environments including campus networks data center networks enterprise networks as well as service provider networks.

One challenging problem when using a port channel is how to effectively load balance the traffic flow through the network ports in the port channel. In addition care must be taken so that data packets associated with a given traffic flow egress from the network device along the same path in order to avoid packet out of sequence issues. Traffic flows are defined by unique combinations of fields included in the data packet headers including but not limited to the source and destination MAC addresses the source and destination IP addresses the source and destination ports and the protocol. In conventional load balancing schemes a hash value is calculated for each data packet. The inputs to the hash function can include any combination of user configured fields such that different hash values correlate with different traffic flows. A modulo operation can be performed on the calculated hash value with the number of network ports in the port channel in order to yield the egress network port. For example for an n bit hash such as a 5 bit hash there are 32 i.e. 2 different hash values which can be evenly divided among the network ports in the port channel. Data packets that hash to a particular hash value are forwarded through a particular network port. Because data packets associated with the same traffic flow hash to the same value data packets associated with the same traffic flow egress through the same network port.

However when using traditional load balancing schemes the network port selection logic is agnostic to the load on each of the network ports in the port channel. Therefore if two or more elephant traffic flows egressing out of the port channel happen to hash to the same hash value then both of the two or more elephant traffic flows will be forwarded over the same network port. As a result the two or more elephant traffic flows will burden the same network port while the other network ports in the port channel are relatively underutilized.

Methods and apparatus for load balancing across member ports for traffic egressing out of a port channel are provided herein. An example method according to one implementation may include assigning a quantized value based on current load to each of the network ports in the port channel receiving a data packet addressed to egress through the port channel identifying a traffic flow with which the received data packet is associated determining whether the identified traffic flow is a new traffic flow and selecting one of the network ports in the port channel as an egress port. Selection of the egress port may be weighted according to the quantized value of each of the network ports in the port channel.

In addition the method may include calculating an n bit hash value for the received data packet dividing a plurality of possible n bit hash values among the network ports in the port channel and selecting one of the network ports in the port channel as an egress port by selecting a network port in the port channel associated with the calculated n bit hash value. For example a network port in the port channel having a greater quantized value may be associated with a greater number of the possible n bit hash values than a network port in the port channel having a lesser quantized value. Accordingly the probability of selecting the network port in the port channel having the greater quantized value as the egress port may be greater than the probability of selecting the network port in the port channel having the lesser quantized value as the egress port.

In some implementations the current load of each of the network ports in the port channel may be defined by an exponential weighted moving average of data packets egressing from each of the network ports in the port channel. Additionally the current load of each of the network ports in the port channel may be normalized based on a network port speed of each of the network ports in the port channel.

In another implementation the method may include maintaining a flow table including a plurality of entries and determining whether the identified traffic flow is a new traffic flow by determining whether the flow table includes an entry corresponding to the identified traffic flow. Each of the entries may include a traffic flow identifier and a corresponding egress port. In addition the method may include selecting one of the network ports in the port channel as an egress port using the flow table.

Optionally the traffic flow identifier may be at least one of a source MAC address a destination MAC address a source IP address a destination IP address a source port a destination port and a protocol identifier.

Alternatively the traffic flow identifier may be a hash value of at least one of a source MAC address a destination MAC address a source IP address a destination IP address a source port a destination port and a protocol identifier.

It should be appreciated that the above described subject matter may also be implemented as a computer controlled apparatus a computer process a computing system or an article of manufacture such as a computer readable storage medium.

Other systems methods features and or advantages will be or may become apparent to one with skill in the art upon examination of the following drawings and detailed description. It is intended that all such additional systems methods features and or advantages be included within this description and be protected by the accompanying claims.

Unless defined otherwise all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art. Methods and materials similar or equivalent to those described herein can be used in the practice or testing of the present disclosure. While implementations will be described for improving load balancing across member ports for traffic egressing out of a port channel in a network device having a modular architecture with a centralized forwarding engine it will become evident to those skilled in the art that the implementations are not limited thereto but are applicable for improving load balancing across member ports for traffic egressing out of a port channel in a network device having a modular architecture with other configurations.

Referring now to an example network device is shown. For example the network device can be a network device having a modular architecture with a centralized forwarding engine. The network device can be a switch router hub gateway etc. and can be configured to forward i.e. switch route etc. data packets and or frames between network nodes such as a client device and a server device. For example the network device can include a chassis a forwarding engine and a plurality of line cards A B N. Optionally the line cards A B N can be dumb line cards. The line cards A B N can each include a plurality of network ports i.e. the interfaces into which the physical links are connected and the forwarding engine may be configured to implement all of the forwarding decisions participating in routing protocols etc. Upon ingress of a data packet into one of the network ports the data packet is forwarded to the forwarding engine and the forwarding engine then implements the forwarding decisions i.e. performs the L2 and or L3 table lookup for example . It should be understood that the network device shown in can include more or less components than are shown in such as for example an additional forwarding engine for redundancy and or additional line cards. It should also be understood that the network device can be a network device where some of the processing is offloaded from the forwarding engine to distributed forwarding engines such as the line cards for example. In the case that processing is offloaded to distributed forwarding engines statistics from each distributed forwarding engine can be exported to the other distributed forwarding engines. This allows each distributed forwarding engine to make forwarding decisions i.e. select a network port in the port channel based on global statistics. The ability to export statistics among the distributed forwarding engines can be accomplished with additional hardware support. For example if the distributed forwarding engines are line cards the ASIC of each line card can be configured to export statistics.

As discussed above a plurality of network ports can be grouped into a single logical interface connection which is referred to as a port channel. The forwarding engine can be configured to maintain input and output statistics such as input and output byte and packet counts for example for the network ports in the port channel. Input and output byte and packet counts are commonly maintained by an ASIC of the forwarding engine for example and in some implementations the input and output byte and packet counts are raw byte and packet counts. The input and output statistics can be representative of the load on each of the network ports in the port channel. The input and output statistics can be used when selecting an egress network port. For example instead of selecting an egress network port based solely on a calculated hash value of the received data packet and the number of network ports in the port channel information regarding the load on each of the network ports in the port channel can be accounted for when selecting the egress network port. Thus a network port having a lower load can have a higher probability of selection as the egress network port for each new traffic flow.

The input and output statistics can be utilized to measure the current load on each of the network ports in the port channel. For example a normalized exponential weighted moving average of the number of bytes egressing from each of the network ports in the port channel can provide a metric for measuring the current load on each of the network ports in the port channel. The weighting factors can decrease exponentially with time for example in order to reduce the influence of progressively older data on the weighted average. In addition the period of time over which the exponential weighted moving average is calculated can be variable. In some implementations the weighted moving average may be calculated over a period of day s . While in other implementations the weighted moving average may be calculated over a period of hour s or minute s . The period of time may for example depend on the type of network and or the volume of network traffic. The period of time and weighting factors can be selected to reduce the influence of relatively older data on the exponential moving average. Optionally the exponential weighted moving average can be normalized where the normalization factor is a function of the physical link speed i.e. 1 G 10 G 40 G etc. of each of the network ports in the port channel for example. By normalizing the exponential weighted moving average it is possible to compare the relative load of the network ports in the port channel having different performance characteristics.

In addition after obtaining the normalized exponential moving average the forwarding engine can be configured to determine a quantized representation of the current load on each of the network ports in the port channel. The quantized representation of the current load can be an N bit quantized representation of the current load for example. The quantized representation of the current load for each of the network ports in the port channel can be maintained in order to minimize the amount of state information to be stored. For example the quantized representation of the current load can be a 4 bit quantized value. Instead of storing the normalized exponential moving average as a raw number for each of the network ports i.e. 1 G 10 G 40 G etc. network ports in the port channel the normalized exponential moving average can be quantized into one of sixteen different current load levels i.e. 0 15 . For example a network port in the port channel having lower current load can be assigned a higher quantized value i.e. a larger magnitude than a network port in the port channel having higher current load. Thus the quantized representation of the current load i.e. a 4 bit value occupies substantially less memory than the raw normalized exponential moving average i.e. a 10 20 or 30 bit value in some instances . It should be understood that there are many other ways for providing a metric for measuring the current load on each of the network ports in the port channel and that the normalized exponential moving average of the bytes egressing from each of the network ports in the port channel is only an example. In addition it should be understood that the N bit quantized representation of the current load is not limited to a 4 bit quantized representation and that N can be any integer.

Referring now to an example flow table is shown. The flow table can be maintained by the forwarding engine for example and can contain information regarding the traffic flows egressing from the port channel. The flow table can include a plurality of entries each entry being uniquely associated with a traffic flow. As discussed above traffic flows are defined by unique combinations of fields included in the data packet headers including but not limited to the source and destination MAC addresses the source and destination IP addresses the source and destination ports and the protocol. Therefore each entry in the flow table can include a traffic flow identifier Flow ID F F F F a traffic flow age Flow Age A A A Aand a network port identifier Port ID P P P P. In order to avoid packet out of sequence issues data packets associated with the same flow preferably egress from the same network port in the port channel.

The traffic flow identifier F F F Fcan identify the traffic flow. For example a data packet can be associated with a traffic flow based on the fields of the data packet header. In this implementation the traffic flow identifier F F F Fis the unique combination of fields of the data packet header such as the source and destination MAC addresses the source and destination IP addresses the source and destination ports and the protocol that define the traffic flow. When a new data packet is received the forwarding engine can be configured to perform a table lookup in the flow table based on the unique combination of fields of the new data packet header to determine if the new data packet is associated with an existing traffic flow.

Alternatively a data packet can be associated with a traffic flow using a hash based scheme. In this implementation the forwarding engine can be configured to apply a hashing function to at least one of the fields of the new data packet header to obtain a hash value. For example the hashing function can be applied to the entire data packet header only the source and destination IP address only the destination IP address and the destination port or any other combination of fields. The calculated hash value may be uniquely associated with the traffic flow. Therefore the traffic flow identifier F F F Fcan be the calculated hash value. When a new data packet is received the forwarding engine can be configured to perform a table lookup in the flow table based on the calculated hash value to determine if the new data packet is associated with an existing traffic flow. It should be understood that when the flow identifier F F F Fis a hash value as compared to the unique combination of fields the flow identifier F F F Foccupies less memory space.

The flow age A A A Acan indicate how much time has elapsed since the last data packet associated with the traffic flow was received by the forwarding engine . The flow age A A A Aprovides an indication of how recently the traffic flow was active. The forwarding engine can be configured to periodically age the flow age A A A Aincluded in each entry of the flow table . The forwarding engine can be configured to age the flow age A A A Aevery predetermined period of time that a new data packet is not received for example. The forwarding engine can be configured to use the flow age A A A Ato age out entries with a flow age greater than a predetermined age i.e. a stale entries . For example the forwarding engine can be configured to age out entries as follows. First after expiration of a first period of time without receiving a new data packet the entry can be marked to be aged out. Then after expiration of a second period of time without receiving a new data packet the entry marked to be aged out can be deleted from the flow table . If however a new data packet is received before expiration of the second period of time the entry marked to be aged out can be reset. By aging out stale entries it is possible to prevent the size of the flow table from growing beyond a desired size. It should be understood that the predetermined period of time first period of time second period of time and predetermined age can be any period of time or age respectively and may be related to the type of network and or volume of network traffic.

The port identifier P P P Pcan identify the egress network port in the port channel for the traffic flows. Initially the value of the port identifier P P P Pcan be set to an initialization value such as 0 for example to indicate that a data packet associated with the traffic flow has not yet been received. After a data packet is received the forwarding engine can be configured to update the port identifier P P P Pto identify the egress network port for the traffic flow with which the data packet is associated. Because the entries in the flow table associate a traffic flow with a port identifier it is possible to avoid packet out of sequence issues by forwarding data packets associated with the same traffic flow through the same network port in the port channel. In the event that a traffic flow is forwarded to a different network port in the port channel care should be taken to update the corresponding entry in the flow table accordingly.

Referring to an example computing device upon which embodiments of the invention may be implemented is illustrated. In particular the forwarding engine discussed above may be a computing device such as computing device shown in . The computing device may include a bus or other communication mechanism for communicating information among various components of the computing device . In its most basic configuration computing device typically includes at least one processing unit and system memory . Depending on the exact configuration and type of computing device system memory may be volatile such as random access memory RAM non volatile such as read only memory ROM flash memory etc. or some combination of the two. This most basic configuration is illustrated in by dashed line . The processing unit may be a standard programmable processor that performs arithmetic and logic operations necessary for operation of the computing device . Alternatively the processing unit may be an ASIC that is configured to perform arithmetic and logic operations necessary for operation of the computing device .

Computing device may have additional features functionality. For example computing device may include additional storage such as removable storage and non removable storage including but not limited to magnetic or optical disks or tapes. Computing device may also contain network connection s that allow the device to communicate with other devices. Computing device may also have input device s such as a keyboard mouse touch screen etc. Output device s such as a display speakers printer etc. may also be included. The additional devices may be connected to the bus in order to facilitate communication of data among the components of the computing device . All these devices are well known in the art and need not be discussed at length here.

The processing unit may be configured to execute program code encoded in tangible computer readable media. Computer readable media refers to any media that is capable of providing data that causes the computing device i.e. a machine to operate in a particular fashion. Various computer readable media may be utilized to provide instructions to the processing unit for execution. Common forms of computer readable media include for example magnetic media optical media physical media memory chips or cartridges a carrier wave or any other medium from which a computer can read. Example tangible computer readable media may include but is not limited to volatile media non volatile media and transmission media. Volatile and non volatile media may be implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data and common forms are discussed in detail below. Transmission media may include coaxial cables copper wires and or fiber optic cables as well as acoustic or light waves such as those generated during radio wave and infra red data communication.

In an example implementation the processing unit may execute program code stored in the system memory . For example the bus may carry data to the system memory from which the processing unit receives and executes instructions. The data received by the system memory may optionally be stored on the removable storage or the non removable storage before or after execution by the processing unit .

Computing device typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by device and includes both volatile and non volatile media removable and non removable media. Computer storage media include volatile and non volatile and removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. System memory removable storage and non removable storage are all examples of computer storage media. Computer storage media include but are not limited to RAM ROM electrically erasable program read only memory EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media may be part of computing device .

It should be understood that the various techniques described herein may be implemented in connection with hardware or software or where appropriate with a combination thereof. Thus the methods and apparatuses of the presently disclosed subject matter or certain aspects or portions thereof may take the form of program code i.e. instructions embodied in tangible media such as floppy diskettes CD ROMs hard drives or any other machine readable storage medium wherein when the program code is loaded into and executed by a machine such as a computing device the machine becomes an apparatus for practicing the presently disclosed subject matter. In the case of program code execution on programmable computers the computing device generally includes a processor a storage medium readable by the processor including volatile and non volatile memory and or storage elements at least one input device and at least one output device. One or more programs may implement or utilize the processes described in connection with the presently disclosed subject matter e.g. through the use of an application programming interface API reusable controls or the like. Such programs may be implemented in a high level procedural or object oriented programming language to communicate with a computer system. However the program s can be implemented in assembly or machine language if desired. In any case the language may be a compiled or interpreted language and it may be combined with hardware implementations.

It should be appreciated that the logical operations described herein with respect to the various figures may be implemented 1 as a sequence of computer implemented acts or program modules i.e. software running on a computing device 2 as interconnected machine logic circuits or circuit modules i.e. hardware within the computing device and or 3 a combination of software and hardware of the computing device. Thus the logical operations discussed herein are not limited to any specific combination of hardware and software. The implementation is a matter of choice dependent on the performance and other requirements of the computing device. Accordingly the logical operations described herein are referred to variously as operations structural devices acts or modules. These operations structural devices acts and modules may be implemented in software in firmware in special purpose digital logic and any combination thereof. It should also be appreciated that more or fewer operations may be performed than shown in the figures and described herein. These operations may also be performed in a different order than those described herein.

Referring now to a flow diagram illustrating example operations for providing load balancing is shown. At a data packet is received by a network device. For example the data packet can be a data packet flowing over a network between network nodes. The data packet ingresses into the network device through an ingress network port. As discussed above upon ingress the data packet can be forwarded to the forwarding engine configured to implement the forwarding decisions i.e. perform the L2 and or L3 table lookup for example . At a determination is made as to whether the received data packet is addressed to egress out of a port channel. If the received data packet is not addressed to egress out of a port channel the data packet undergoes regular forwarding operations at . For example after a forwarding table look up is performed the data packet is forwarded to the egress network port.

If the received data packet is addressed to egress out of a port channel additional operations can be performed to select an egress network port. In some implementations the forwarding engine can be configured to perform the selection operations discussed below for example. At a traffic flow with which the received data packet is associated is identified. As discussed above traffic flows are defined by unique combinations of fields included in the data packet headers including but not limited to the source and destination MAC addresses the source and destination IP addresses the source and destination ports and the protocol. In some implementations the traffic flow with which the received data packet is associated can be identified directly from the unique combination of fields of the data packet header. The unique combination of fields of the data packet header therefore can serve as the traffic flow identifier. Alternatively the traffic flow with which the received data is associated can be identified using a hash value. When using a hash value to identify the traffic flow a hash function is applied to any combination of fields of the data packet header to obtain a hash value. Different traffic flows may be associated with different calculated hash values. The calculated hash value therefore can serve as the traffic flow identifier.

At a flow table is consulted to determine if an entry corresponding to the identified traffic flow exists. As discussed above the flow table can include a plurality of entries each entry including a traffic flow identifier a flow age and a port identifier. Optionally the flow table can be searched based on the traffic flow identifier. At if an entry corresponding to the identified traffic flow exists the flow table is utilized to select the egress network port through which to forward the received data packet. The egress network port for the traffic flow with which the received data packet is associated can be stored in the flow table as the port identifier. The received data packet can then be forwarded to the egress network port at which is selected using the flow table. Thus by using the flow table it is possible to avoid packet out of flow issues by forwarding data packets associated with the same traffic flow through the same egress network port.

At if an entry corresponding to the identified traffic flow does not exist i.e. the identified traffic flow is a new flow an egress network port can be selected while accounting for the current load on the network ports in the port channel at . For example a probability of selecting each of the network ports in the port channel as the egress network port can be weighted according to the current load of each of the network ports in the port channel. As discussed above input and output statistics are maintained for each of the network ports in the port channel and can be utilized as a metric of the current load on each of the network ports in the port channel. For example a normalized exponential moving average of data packets egressing from each of the network ports in the port channel can represent the current load. Optionally a quantized value can be assigned to each of the network ports in the port channel based on the normalized exponential moving average. The quantized value can represent the current load on each of the network ports in the port channel. Additionally in some implementations a network port in the port channel having lower current load can be assigned a higher quantized value i.e. a larger magnitude than a network port in the port channel having higher current load. Thus the probability of selecting the network ports in the port channel as the egress network port can be weighted based on the quantized value.

For example a hash value can be calculated for the received data packet based on any combination of fields of the data packet header. The hash value can be an n bit hash value. In addition a plurality of possible n bit hash values can be divided among the network ports in the port channel based on the weights assigned to the network ports in the port channel. A network port in the port channel having a greater quantized value can associated with a greater number of the possible n bit hash values than a network port in the port channel having a lesser quantized value such that the probability of selecting the network port in the port channel having the greater quantized value as the egress network port is greater than the probability of selecting the network port in the port channel having the lesser quantized value as the egress network port.

An example scenario is discussed below to illustrate selecting an egress network port while accounting for the current load on the network ports in the port channel. In this example the hashing function may generate a 5 bit hash value. Accordingly there are 32 possible hash values. In addition in this example there may be two network ports in the port channel and the current load for each network port may be represented by a 4 bit quantized value i.e. the current load can be 15 different quantized values where greater magnitudes are associated with lower current load and lesser magnitudes are associated with higher current load . The current load on the first network port may be 8 and the current load on the second network port may be 5 for example. In other words the first network port is assigned a greater magnitude quantized value based on its lower current load as compared to the second network port. The plurality of possible hash values can then be divided among the network ports in the port channel according to Eqn. 1 below.

In this example the possible hash values can be divided between the network ports in the port channel as shown below in Eqns. 2 and 3 below.

Thus if the calculated hash value for the received data packet is between 0 and 19 then the first network port can be selected as the egress network port. On the other hand if the calculated hash value for the received data packet is between 20 and 31 then the second network port can be selected as the egress network port. Accordingly because a greater number of the possible n bit hash values are associated with the network port having the lower current load i.e. the first network port the probability of selecting the first network port as the egress network port is greater than the probability of selecting the second network port as the egress network port. In other words selection of the egress network port is weighted according to the current load on the network ports in the port channel. It should be understood however that the scheme for selecting the egress network port discussed above requires that for a generated n bit hash value the maximum number of port channel members is less than 2.

Additionally upon selecting the egress network port for the identified traffic flow the received packet can be forwarded to the egress network port at and the flow table can be updated at . Specifically the flow table can be updated to include an entry for the identified traffic flow that includes a traffic flow identifier flow age and port identifier i.e. the selected egress network port . Accordingly the egress network port for subsequently received data packets associated with the same traffic flow can be obtained using the flow table.

Initially the flow table may be empty and there may not be an entry corresponding to the identified traffic flow. When the flow table is empty the current load on each of the network ports in the port channel is equal i.e. the current load is 0 for the network ports . Accordingly a load balancing scheme that does not account for the current load may be utilized to select an egress network port. In this case the forwarding engine may default to the traditional load balancing scheme. For example a hash value can be calculated for the received data packet based on any combination of fields of the data packet header. A modulo operation can be performed on the calculated hash value with the number of network ports in the port channel in order to yield the egress network port. For example for an n bit hash such as a 5 bit hash there are 32 i.e. 2 different hash values which can be evenly divided among the network ports in the port channel. Because the current load is initially equal on all of the network ports in the port channel the probabilities of selecting any of the network ports in the port channel as the egress network port can be equal. Upon selecting an egress network port the flow table can be updated. Specifically the flow table can be updated to include an entry for the identified traffic flow that includes a traffic flow identifier flow age and port identifier i.e. the selected egress network port . Accordingly the egress network port for subsequently received data packets associated with the same traffic flow can be obtained using the flow table. In addition the flow age for the traffic flow can be periodically updated to indicate how recently the traffic flow was active.

Optionally when the flow table is full and it is not possible to add new entries the egress network port can also be selected without accounting for the current load on the network ports in the port channel. In this case a load balancing scheme that does not account for the current load similarly to the load balancing scheme discussed above when the flow table is initially empty may be utilized to select an egress network port. For example the forwarding engine can be notified that the flow table is full and if an entry in the flow table does not correspond to the received data packet an egress network port can be selected by performing a modulo operation on the calculated hash value with the number of network ports without weighting the network ports based on current load .

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

