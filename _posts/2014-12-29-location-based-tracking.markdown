---

title: Location based tracking
abstract: Location information is used to build a database of locations having associated audio, video, image, or text data. In some implementations, a device includes a touch-sensitive display and collects data associated with a geographic location of interest. The geographic location of interest can be displayed on a map using an indicator. A touch selection of the indicator provides access to the data through an interface displayed on the touch-sensitive display. One or more locations of interest can be displayed and grouped together by an attribute.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09310206&OS=09310206&RS=09310206
owner: Apple Inc.
number: 09310206
owner_city: Cupertino
owner_country: US
publication_date: 20141229
---
This application is a continuation of U.S. patent application Ser. No. 13 361 897 filed Jan. 30 2012 and entitled LOCATION BASED TRACKING which is a continuation of U.S. patent application Ser. No. 12 164 866 filed Jun. 30 2008 and entitled LOCATION BASED TRACKING which claims priority to U.S. Provisional Patent Application Ser. No. 60 946 813 filed Jun. 28 2007 and entitled LOCATION BASED TRACKING the contents of each of which are incorporated herein by reference.

Mobile devices have grown more powerful and feature rich and now include such features as personal digital assistant PDA capabilities cameras to capture video and still images Internet access etc. Location based services have been developed for determining and tracking the locations of the users of mobile devices. Location based services provide location specific information to mobile devices including for example global positioning system GPS data to locate the mobile device on a map of a geographic region.

A number of applications are available for aiding users in navigation and route planning. Some of these applications use mobile devices containing global positioning systems to define the location of the mobile device and plan a route to a desired destination. Currently however these route planning systems do not provide a way to document items of interest to a user while a route is traveled. In conventional systems the information the route planning systems provide is limited to what is pre programmed. This information can become obsolete in time and may be of little or no interest to the user.

Location information is used to build a database of locations having associated audio video image or text data.

In some implementations a method includes presenting a map of a geographic region on a touch sensitive display receiving touch input selecting a geographic location determining geographic positioning information of the geographic location receiving data in response to an input received by a touch sensitive display associating the data with the geographic positioning information of the geographic location to produce geographically tagged data and storing the geographically tagged data.

In some implementations a method includes presenting indications of a predetermined group of geographic locations on a touch sensitive display receiving a selection of a geographic location from the group of geographic locations displayed on the touch sensitive display and presenting geographically tagged data associated with the geographic location in a user interface on the touch sensitive display.

In some implementations a user interface includes a touch sensitive display area for displaying indications of a predetermined group of geographic locations associated by an attribute wherein each indication represents geographically coded data associated with a geographic position and wherein a name of the attribute is displayed in the user interface.

Other implementations are disclosed including implementations directed to systems methods apparatuses computer readable mediums and user interfaces.

In some implementations the mobile device includes a touch sensitive display . The touch sensitive display can implement liquid crystal display LCD technology light emitting polymer display LPD technology or some other display technology. The touch sensitive display can be sensitive to haptic and or tactile contact with a user.

In some implementations the touch sensitive display can comprise a multi touch sensitive display . A multi touch sensitive display can for example process multiple simultaneous touch points including processing data related to the pressure degree and or position of each touch point. Such processing facilitates gestures and interactions with multiple fingers chording and other interactions. Other touch sensitive display technologies can also be used e.g. a display in which contact is made using a stylus or other pointing device. Some examples of multi touch sensitive display technology are described in U.S. Pat. Nos. 6 323 846 6 570 557 6 677 932 and U.S. Patent Publication 2002 0015024A1 each of which is incorporated by reference herein in its entirety.

In some implementations the mobile device can display one or more graphical user interfaces on the touch sensitive display for providing the user access to various system objects and for conveying information to the user. In some implementations the graphical user interface can include one or more display objects . In the example shown the display objects are graphic representations of system objects. Some examples of system objects include device functions applications windows files alerts events or other identifiable system objects.

In some implementations the mobile device can implement multiple device functionalities such as a telephony device as indicated by a phone object an e mail device as indicated by the e mail object a network data communication device as indicated by the Web object a Wi Fi base station device not shown and a media processing device as indicated by the media player object . In some implementations particular display objects e.g. the phone object the e mail object the Web object and the media player object can be displayed in a menu bar . In some implementations device functionalities can be accessed from a top level graphical user interface such as the graphical user interface illustrated in . Touching one of the objects or can for example invoke corresponding functionality.

In some implementations the mobile device can implement network distribution functionality. For example the functionality can enable the user to take the mobile device and its associated network while traveling. In particular the mobile device can extend Internet access e.g. Wi Fi to other wireless devices in the vicinity. For example mobile device can be configured as a base station for one or more devices. As such mobile device can grant or deny network access to other wireless devices.

In some implementations upon invocation of device functionality the graphical user interface of the mobile device changes or is augmented or replaced with another user interface or user interface elements to facilitate user access to particular functions associated with the corresponding device functionality. For example in response to a user touching the phone object the graphical user interface of the touch sensitive display may present display objects related to various phone functions likewise touching of the email object may cause the graphical user interface to present display objects related to various e mail functions touching the Web object may cause the graphical user interface to present display objects related to various Web surfing functions and touching the media player object may cause the graphical user interface to present display objects related to various media processing functions.

In some implementations the top level graphical user interface environment or state of can be restored by pressing a button located near the bottom of the mobile device . In some implementations each corresponding device functionality may have corresponding home display objects displayed on the touch sensitive display and the graphical user interface environment of can be restored by pressing the home display object.

In some implementations the top level graphical user interface can include additional display objects such as a short messaging service SMS object a calendar object a photos object a camera object a calculator object a stocks object a weather object a maps object a notes object a clock object an address book object and a settings object . Touching the SMS display object can for example invoke an SMS messaging environment and supporting functionality likewise each selection of a display object and can invoke a corresponding object environment and functionality.

Additional and or different display objects can also be displayed in the graphical user interface of . For example if the device is functioning as a base station for other devices one or more connection objects may appear in the graphical user interface to indicate the connection. In some implementations the display objects can be configured by a user e.g. a user may specify which display objects are displayed and or may download additional applications or other software that provides other functionalities and corresponding display objects.

In some implementations the mobile device can include one or more input output I O devices and or sensor devices. For example a speaker and a microphone can be included to facilitate voice enabled functionalities such as phone and voice mail functions. In some implementations a loud speaker can be included to facilitate hands free voice functionalities such as speaker phone functions. An audio jack can also be included for use of headphones and or a microphone.

In some implementations a proximity sensor can be included to facilitate the detection of the user positioning the mobile device proximate to the user s ear and in response to disengage the touch sensitive display to prevent accidental function invocations. In some implementations the touch sensitive display can be turned off to conserve additional power when the mobile device is proximate to the user s ear.

Other sensors can also be used. For example in some implementations an ambient light sensor can be utilized to facilitate adjusting the brightness of the touch sensitive display . In some implementations an accelerometer can be utilized to detect movement of the mobile device as indicated by the directional arrow . Accordingly display objects and or media can be presented according to a detected orientation e.g. portrait or landscape. In some implementations the mobile device may include circuitry and sensors for supporting a location determining capability such as that provided by the global positioning system GPS or other positioning systems e.g. systems using Wi Fi access points television signals cellular grids Uniform Resource Locators URLs . In some implementations a positioning system e.g. a GPS receiver can be integrated into the mobile device or provided as a separate device that can be coupled to the mobile device through an interface e.g. port device to provide access to location based services.

The mobile device can also include a camera lens and sensor . In some implementations the camera lens and sensor can be located on the back surface of the mobile device . The camera can capture still images and or video.

The mobile device can also include one or more wireless communication subsystems such as an 802.11b g communication device and or a Bluetooth communication device . Other communication protocols can also be supported including other 802.x communication protocols e.g. WiMax Wi Fi 3G code division multiple access CDMA global system for mobile communications GSM Enhanced Data GSM Environment EDGE etc.

In some implementations a port device e.g. a Universal Serial Bus USB port or a docking port or some other wired port connection can be included. The port device can for example be utilized to establish a wired connection to other computing devices such as other communication devices network access devices a personal computer a printer or other processing devices capable of receiving and or transmitting data. In some implementations the port device allows the mobile device to synchronize with a host device using one or more protocols such as for example the TCP IP HTTP UDP and any other known protocol. In some implementations a TCP IP over USB protocol can be used.

The mobile devices and can also establish communications by other means. For example the wireless device can communicate with other wireless devices e.g. other wireless devices cell phones etc. over the wireless network . Likewise the mobile devices and can establish peer to peer communications e.g. a personal area network by use of one or more communication subsystems such as the Bluetooth communication device shown in . Other communication protocols and topologies can also be implemented.

The mobile device can for example communicate with one or more services and and or one or more content publishers over the one or more wired and or wireless networks . For example a navigation service can provide navigation information e.g. map information location information route information and other information to the mobile device . In the example shown a user of the mobile device has invoked a map functionality e.g. by pressing the maps object on the top level graphical user interface shown in and has requested and received a map for the location 1 Infinite Loop Cupertino Calif. 

User devices can for example communicate with the one or more services and and or one or more content publishes 260 over the one or more wired and or wireless networks to access content and services as well as communicate with the mobile device . The user devices can be for example a personal computer a set top a gaming device a digital video recorder a portable audio or video player an in vehicle navigation system etc.

A messaging service can for example provide e mail and or other messaging services. A media service can for example provide access to media files such as song files movie files video clips and other media data. One or more other services can also be utilized by the mobile device .

The mobile device can also access other data and content over the one or more wired and or wireless networks . For example content publishers e.g. content publisher s such as news sites RSS feeds web sites blogs social networking sites developer networks etc. can be accessed by the mobile device . Such access can be provided by invocation of a web browsing function or application e.g. a browser in response to a user touching the Web object .

Sensors devices and subsystems can be coupled to the peripherals interface to facilitate multiple functionalities. For example a motion sensor a light sensor and a proximity sensor can be coupled to the peripherals interface to facilitate the orientation lighting and proximity functions described with respect to . Other sensors can also be connected to the peripherals interface such as a positioning system e.g. GPS receiver a temperature sensor a biometric sensor or other sensing device to facilitate related functionalities.

A camera subsystem and an optical sensor e.g. a charged coupled device CCD or a complementary metal oxide semiconductor CMOS optical sensor can be utilized to facilitate camera functions such as recording photographs and video clips.

Communication functions can be facilitated through one or more wireless communication subsystems which can include radio frequency receivers and transmitters and or optical e.g. infrared receivers and transmitters. The specific design and implementation of the communication subsystem can depend on the communication network s over which the mobile device is intended to operate. For example a mobile device may include communication subsystems designed to operate over a GSM network a GPRS network an EDGE network a Wi Fi or WiMax network and a Bluetooth network. In particular the wireless communication subsystems may include hosting protocols such that the device may be configured as a base station for other wireless devices.

An audio subsystem can be coupled to a speaker and a microphone to facilitate voice enabled functions such as voice recognition voice replication digital recording and telephony functions.

The I O subsystem can include a touch screen controller and or other input controller s . The touch screen controller can be coupled to a touch screen . The touch screen and touch screen controller can for example detect contact and movement or break thereof using any of a plurality of touch sensitivity technologies including but not limited to capacitive resistive infrared and surface acoustic wave technologies as well as other proximity sensor arrays or other elements for determining one or more points of contact with the touch screen .

The other input controller s can be coupled to other input control devices such as one or more buttons rocker switches thumb wheel infrared port USB port and or a pointer device such as a stylus. The one or more buttons not shown can include an up down button for volume control of the speaker and or the microphone .

In one implementation a pressing of the button for a first duration may disengage a lock of the touch screen and a pressing of the button for a second duration that is longer than the first duration may turn power to the mobile device on or off. The user may be able to customize a functionality of one or more of the buttons. The touch screen can for example also be used to implement virtual or soft buttons and or a keyboard.

In some implementations the mobile device can present recorded audio and or video files such as MP3 AAC and MPEG files. In some implementations the mobile device can include the functionality of an MP3 player such as an iPod . The mobile device may therefore include a 36 pin connector that is compatible with the iPod. Other input output and control devices can also be used.

The memory interface can be coupled to memory . The memory can include high speed random access memory and or non volatile memory such as one or more magnetic disk storage devices one or more optical storage devices and or flash memory e.g. NAND NOR . The memory can store an operating system such as Darwin RTXC LINUX UNIX OS X WINDOWS or an embedded operating system such as VxWorks. The operating system may include instructions for handling basic system services and for performing hardware dependent tasks. In some implementations the operating system can be a kernel e.g. UNIX kernel .

The memory may also store communication instructions to facilitate communicating with one or more additional devices one or more computers and or one or more servers. The memory may include graphical user interface instructions to facilitate graphic user interface processing sensor processing instructions to facilitate sensor related processing and functions phone instructions to facilitate phone related processes and functions electronic messaging instructions to facilitate electronic messaging related processes and functions web browsing instructions to facilitate web browsing related processes and functions media processing instructions to facilitate media processing related processes and functions GPS Navigation instructions to facilitate GPS and navigation related processes and instructions camera instructions to facilitate camera related processes and functions and or other software instructions to facilitate other processes and functions.

Each of the above identified instructions and applications can correspond to a set of instructions for performing one or more functions described above. These instructions need not be implemented as separate software programs procedures or modules. The memory can include additional instructions or fewer instructions. Furthermore various functions of the mobile device may be implemented in hardware and or in software including in one or more signal processing and or application specific integrated circuits.

In some implementations the user provides a friendly name to identify the location or group of locations of interest. If for example a user would like to save data related to a trip to California the user can identify the data by entering e.g. My Trip to California into the display area . A user can save the data in accordance with any attribute.

In some implementations an indicator can be placed on the map display area to indicate a particular geographic location of interest. For example if the location if interest is in Cupertino user input can be received from the touch sensitive display to place the indicator on the map display area at either the current location of the mobile device shown as reference numeral or a user specified location.

Where the current location of the mobile device is used to specify the geographic location of interest according to some implementations geographic position information can be provided to the mobile device from for example Global Positioning System GPS coordinate data. The GPS coordinate data can be processed by the GPS Navigation instructions and can be provided from an external or internal GPS navigation system. Triangulation and external GPS information can be provided to the mobile device through the wireless communication subsystems or port device .

In some implementations the geographic information regarding the geographic location of interest is manually input by the user. The user can input a street address a latitude longitude pair or other identifying geographic information to specify the geographic location of interest.

After a geographic location of interest has been indicated in some implementations an example user interface shown in is presented on the mobile device in response to invoking the camera object . A next object and back object are provided to navigate within the user interface . A save object and delete object are provided to operate on pictures captured by the mobile device . In some implementations audio data is captured as the picture data is captured by the mobile device .

In some implementations pictures captured by the mobile device are geographically associated with the geographic location of interest when the save object is selected to save the currently displayed picture. In some implementations the geographic association is automatically performed using the determined position of the mobile device. In some implementations the geographic association is manually input by a user when touching the save object on the touch sensitive display .

In some implementations the association of geographic information with data is performed by geo tagging the data. For example geographic position information e.g. latitude and longitude geographic place names or geographical regions are associated with the data. In the example of the geographic information could be for example latitude 37.331837 longitude 122.030799 or 1 Infinite Loop Cupertino Calif. USA. In some implementations the geographic information can be included as meta tags in a document.

In some implementations the user interface can be used to capture video when the camera object is invoked by a user. The video data is saved on the mobile device with associated geographic information as described above with regard to pictures data.

Referring to notes e.g. text information or audio information about the geographic location of interest can be recorded using the notes object . The next object and back object are provided to navigate within the user interface . The save object and delete object are provided to operate on the notes entered on the mobile device . In the manner described above notes received by the mobile device are geographically associated with the geographic location of interest when the save object is selected to save the current notes on the mobile device .

In some implementations touching the indicator presents a menu item to invoke a reviewing user interface such as shown in . Objects such as view notes view pictures and view video can be displayed on the user interface . If for example the view notes object is selected the user interface of can be displayed. If for example the view pictures object or the view videos object is selected the user interface of can be displayed. A navigation object is provided for example to return to the previous display e.g. map display area shown in .

As shown in in some implementations multiple indicators and can be placed on the map display area to indicate multiple locations of interest. In some implementations for each geographic location of interest the user can capture data such as pictures notes audio and video and save it to the mobile device with an association to the geographic location of interest as described above with regard to indicator . In the example interface of data associated with Palo Alto Calif. indicator and San Francisco Calif. indicators and is saved on the mobile device .

In some implementations the data associated with the geographic locations identified by indicators and or can be reviewed in the reviewing user interface of in response to a selection of indicators and or . For example if indicator is selected the user interface is presented however the information display area would indicate Stanford University. Likewise if indicator or is selected the information display area would indicate San Francisco or Downtown San Francisco Golden Gate Bridge or Alcatraz Island respectively if a higher level of detail is desired.

In some implementations the data on the mobile device associated with locations of interest can be uploaded to a remote storage location at one of the service providers and and or content publishers or directly to an end user device .

In some implementations the data associated with locations of interest can be played back for later viewing as a multimedia presentation. For example in response to a selection of the maps object the data saved to My Trip to California is retrieved and displayed in a user interface such as .

In some implementations the multimedia presentation begins by displaying the indicator on the map display area as shown in . The presentation continues by showing selected a predetermined portion or all pictures notes audio and or video associated with the geographic location specified by the indicator . For example the user interfaces of can be displayed in response to a selection of the indicator such that users can step through the pictures notes and or videos using the navigation objects and .

In some implementations as shown in the multimedia presentation includes an indicator illustrating a traveled route associated with the saved My Trip to California. The traveled route can be indicated for example by a line or an arrow that moves from indicator to indicator to illustrate a direction of travel over time. Notes pictures audio and or videos associated with the location specified by indicator e.g. Stanford University are accessible to the user as discussed above.

As shown in the multimedia presentation illustrates the traveled route indicator moving to the end in San Francisco Calif. where indicators and are located. Data associated with indicators and can be displayed as indicated above with regard to indicator . For example notes pictures audio and or video associated with downtown San Francisco e.g. indicator the Golden Gate Bridge e.g. indicator and or Alcatraz Island e.g. indicator can be displayed.

In some implementations all of the data saved to My Trip to California is available at once rather than conveying a notion of time as described above. The user interface of is used for the presentation of the pictures notes audio and or video associated with the all or a predetermined subset of the locations of interest indicated by indicators and . The user interfaces of can be displayed in response to a selection of one of the indicators or such that users can step through the pictures notes and or videos using the navigation objects and .

In some implementations the pictures notes and or videos are compiled into a movie using an authoring application that converts and aggregates the pictures notes audio and or video into a multimedia video data file such as an MPEG 2 MPEG 4 AVL Quicktime Windows Media RealVideo DivX etc. movie file. The movie can be compiled on a mobile device or remotely by one of the services or or content publishers . For example in some implementations the movie begins by displaying a map of the first geographic location of interest e.g. Cupertino and then displaying associated pictures notes and videos taken by the mobile device in succession. The movie changes scenes to a second geographic location of interest e.g. Stanford University to display a map and associated pictures notes audio and videos. Finally the movie continues until the pictures notes audio and videos for a final geographic location of interest e.g. Alcatraz Island are displayed.

In some implementations the data associated with geographic locations can be requested by the end user devices for display. A suitable application running on an end user device makes a request over the wide area network to e.g. the media service the content publisher or the wireless device the data to be downloaded or to download the compiled movie.

At stage the geographic position information of the geographic location of interest is ascertained. For example this information can be manually input or obtained from GPS coordinate data. At stage data associated with location is received. For example notes pictures audio and or video associated with the geographic location of interest is input to the mobile device by a selection of the camera object or the notes object .

At stage data is stored with the geographic position information. For example the notes pictures audio and or video received at stage are saved with the geographic position information in the mobile device . The geographic position information can be automatically appended to the notes pictures audio and or video or manually input by the user during the save operation.

At stage it is determined if more data is to be associated with the geographic location of interest. If so the process flows to stage . If no more data is to be associated with the geographic location of interest the process returns to stage .

At stage an indication of an action is received. For example a user input from one of objects and or is received by the mobile device . At stage the received action is performed. For example a next picture is displayed if the next object is selected or a previous picture is displayed if the back object is selected. A displayed picture is saved if the save object is selected or deleted if the deleted object is selected by the user.

At stage a user interface is displayed. For example the user interface of is displayed on the mobile device . At stage an indication of location is received. For example the user selects indicator on the touch sensitive display . At stage data is presented. For example the interface of is displayed from which the user can select to view notes pictures audio and or video. In accordance with the selection made by the user the user interface or is presented to view the data requested.

After the data is presented the flow returns to stage . For example when the user selects the back object the user interface of or is displayed.

At stage an application is launched. For example a playback application e.g. media player executing on the mobile device or end user device is launched. At stage data is retrieved. For example data associated with the geographic location of interest is retrieved from the memory or from a remote location and communicated over the wide area network and or wireless network to the mobile device or end user device .

At stage a user interface is presented. For example the user interface associated with the media player is displayed on the mobile device or end user device .

At stage the data associated with the geographic location of interest is presented in the user interface. In accordance with a playback mode the notes pictures and or video associated with the geographic locations of interest are played back in sequence without any user interaction.

The disclosed embodiments can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of what is disclosed here or any combination of one or more such back end middleware or front end components.

The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN e.g. the Internet.

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other.

While this specification contains many specifics these should not be construed as limitations on the scope of what being claims or of what may be claimed but rather as descriptions of features specific to particular embodiments. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable sub combination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a sub combination or variation of a sub combination.

Similarly while operations are depicted in the drawings in a particular order this should not be understand as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multitasking and parallel processing may be advantageous. Moreover the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

Various modifications may be made to the disclosed implementations and still be within the scope of the following claims.

