---

title: Apparatus, systems and methods for dynamic on-demand context sensitive cluster analysis
abstract: A particular method includes selecting a subset of a plurality of dimension members of a multi-dimensional data set. The method also includes computing a plurality of dimensional scores for the dimension members in the selected subset. Each dimensional score is associated with a particular dimension member in the subset and is a measure of a dimensional influence of the associated dimension member on a metric associated with the multi-dimensional data set. A dimension member with greater dimensional influence affects a value of the metric over a population more than a dimension member with less dimensional influence. The method further includes ranking the dimension members in the selected subset based on the dimensional scores.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08898175&OS=08898175&RS=08898175
owner: Visier Solutions, Inc.
number: 08898175
owner_city: Vancouver, British Columbia
owner_country: GB
publication_date: 20140417
---
This application is a continuation patent application of and claims priority from U.S. patent application Ser. No. 13 584 810 filed on Aug. 13 2012 and entitled APPARATUS SYSTEMS AND METHODS FOR DYNAMIC ON DEMAND SENSITIVE CLUSTER ANALYSIS which is hereby incorporated by reference in its entirety.

The present invention relates to the field of business intelligence and in particular to apparatus systems and methods for facilitating dynamic on demand context sensitive cluster analysis in business intelligence systems.

In modern organizations strategic planning can be central to the evaluation of business risks and for efficient and optimal deployment of organizational resources including human resources. For example strategic planning may involve determining current resource demands and utilization including both human and material resources forecasting future resource demands and planning to satisfy current and estimated future resource demands in a cost optimal manner. Accordingly many organizations use a variety of systems such as Enterprise Resource Planning ERP systems which facilitate automated organizational integration of management information. Typically ERP systems take the form of a complex software suite facilitating the flow of information between various organizational entities such as sales finance accounting manufacturing human resources etc.

Business Intelligence BI systems can process data generated by ERP systems to calculate key performance indicators for various organizational entities and processes and drive decisions. For example information in ERP systems may be aggregated by a BI system in a variety of ways to match the specific needs of departments. For example the data aggregation may occur in one fashion for the sales department and in another manner for manufacturing. BI systems thus support planning budgeting forecasting and reporting including for example the setting of targets for organizational entities and processes and the monitoring of progress toward those targets.

Traditional BI systems exhibit several drawbacks because of their inherent complexity. For example the complexity of BI systems makes deployment and customization for specific applications difficult. In addition BI systems are not easily adapted to deal with unstructured or semi structured data or to changes in the format of the underlying data. Further non technical organizational staff may often experience difficulty in using BI systems. The lack of employee comfort or competence with BI systems can lead to problems in quickly generating intelligence for a specific department or application. Moreover the large cost and support overheads associated with ERP and BI systems are an impediment to their wide use and deployment. Finally while traditional ERP and BI systems may permit calculations of various metrics these systems do not facilitate analysis of the impact of one or more populations on the calculated metrics. Therefore organizations are often deprived of the competitive advantage of good business intelligence.

Thus there is a need for apparatus systems and methods that facilitate dynamic on demand context sensitive cluster analysis in business intelligence systems in a cost and resource optimal manner.

Consistent with embodiments disclosed herein apparatus systems and methods for facilitating dynamic on demand context sensitive cluster analysis in business intelligence systems are presented. In some embodiments a method for performing on demand cluster analysis on a multi dimensional data set comprising a plurality of dimension members comprises selecting of a subset of the plurality of dimension members wherein the selected subset of the plurality of dimension members is dynamically determined based on a current context associated with the multi dimensional data set computing a plurality of dimensional scores for a plurality of dimension members in the selected subset wherein each dimensional score is associated with a distinct dimension member and is a measure of a dimensional influence of the associated dimension member on a metric associated with the multi dimensional data set and ranking the plurality of dimension members in the selected subset based on the dimensional score. In some embodiments the current context may be dynamically determined based on a portion of the multi dimensional data set determined to be relevant. In some embodiments the methods may be performed on compute clouds server farms and or various computing devices.

Embodiments also relate to software firmware and program instructions created stored accessed or modified by computers and or processors using computer readable media or computer readable memory. The methods described may be performed on various computing devices including distributed computing systems such as clouds.

Consistent with embodiments disclosed herein apparatus systems and methods for facilitating dynamic on demand context sensitive cluster analysis in business intelligence systems are presented.

As shown in exemplary system may include one or more customer or user locations such as exemplary user locations . . . N. In general user locations may comprise one or more networked computing devices. Computing devices may include some combination of one or more networked desktop computers computer servers and or mobile computing devices such as laptops tablets handheld or wearable computing devices and or smartphones. Computing devices in user locations may have graphics and video capability and include one or more integrated or external displays projection devices modems network controllers and or printing devices as well as various other peripherals. Networking between computing devices in user locations and or Data Center s may be implemented using high speed wired networks such as Gigabit Ethernet or wireless local area networks WLANs for example using IEEE 802.11a b g n standards.

In some embodiments system may use a client server architecture where one or more clients running on computing devices in user locations interact with and access services provided by Data Center which may include services to facilitate dynamic on demand context sensitive cluster analysis for business intelligence in multi dimensional databases. In some embodiments these services may be executed on demand in response to requests originating from a client. The term context sensitive refers to the use of a current context associated with the multi dimensional database during analysis query generation and other business intelligence operations. The current context may be seen as specifying a cube view or a portion of the multi dimensional database for the current fact population being analyzed. The term dynamic refers in part to the capability to automatically determine and keep track of changes to the current context and to perform real time cluster analysis on demand in a context sensitive manner.

For example a user at user location may use a browser running on a smartphone with a high resolution display to access services provided by Data Center using Virtual Private Network VPN tunnel over a wireless 3G or 4G cellular network. As another example several users at a user location may be logged in to a computer server and access services provided by Data Center through VPN tunnel . In general VPN tunnels may be implemented over some combination of wired and or wireless networks. Further in the example above the use may use a client which may take the form of a web browser to view data in a multi dimensional database for a Human Capital Management HCM application. For example the use may browse data in the multi dimensional HCM database to view employees by geography and the current context may be Location North America. The user may move further down in the same geographical dimension to view data for employees by Country in Canada and the system may update the current context to Country Canada. If the user further views data for employees with Job Status Full Time Employee FTE the system may add a Job Status dimension member Full Time Employee to the current context so that the current context may be given by Location North America Country Canada Job Status FTE . In the example above Location and Country are members of a geographical dimension while Job Status is a distinct dimension.

In some embodiments if the user requests data regarding Terminated Employees using a query then the system may utilize the user s current context Canada FTE to generate a query of the form Terminated FTEs in Canada which may be sent by the client servers in Data Center . In some embodiments the query may be processed in real time and the results may be returned to the client for display.

In some embodiments services to facilitate dynamic on demand context sensitive cluster analysis for business intelligence provided by Data Center may be cloud based. Cloud computing can refer to the use of a company s own computer cluster a private cloud but more often the term refers to the use of computing resources that are made available over the Internet often through Web browser based or client side applications. In some embodiments services to facilitate dynamic on demand context sensitive cluster analysis for business intelligence provided by Data Center may use virtualization and or sophisticated systems management solutions to provide a flexible fault tolerant and highly available view of underlying resources so that hardware resources in Data Center can be dynamically shared across several users instead of being assigned individually. These computing resources which are often made available as virtual machines and in some instances as physical machines may be accessed using Application Programming Interfaces APIs and or portals which may be websites accessed through a web browser.

In some embodiments a user at one of user locations may access cloud based services through Analytic Client . In general Analytic Client may be some combination of hardware and software that facilitates access to cloud based services providing dynamic on demand context sensitive cluster analysis for business intelligence. For example Analytic Client may comprise a web browser running on a computing device and an application container which may take the form of a web browser add on extension and or plug in may hold a variety of analytic application front ends.

Predefined workflows may be used to couple one or more analytics applications front ends hosted by the application container. Predefined workflows may comprise a collection of functions used for analysis of specific business problems. In some embodiments where calculations and specific formulas are used by one or more of the workflows some functions can be prebuilt. In some embodiments the predefined workflows may be specified by customizable declarative application configuration files that describe data security policies visualizations workflows schema in both client and server at run time. Further in some embodiments the predefined workflows may be context sensitive and use functions that take in the current application data context.

For example in a Human Capital Management HCM domain for a user browsing data pertaining to employees by geography the current context may be North America. In the example above a simple function to determine Terminated Employees may utilize the user s current context North America to generate a vQuery of the form Terminated employees in North America. In general a vQuery may be viewed as a set of processing function calls associated metrics and or parameter values that define an execution path to be used by Function Based Analytics Application Engine to generate a result set for Analytic Client . A processing function is any function called upon by Function Based Analytics Application Engine . In some embodiments processing functions may include data transformation functions data fetch functions exporting functions and other custom user defined functions. As another example in a Sales domain with a user viewing quarterly sales data by geography and time period the current context may be Canada and Q1 2011. Accordingly a request to determine Annualized Turnover Rate for Products may generate a vQuery of the form Annualized Turnover Rate for Products in Canada in Q1 2011. 

In general a vQuery may comprise and or depend on other nested functions or further vQueries. If a parent vQuery depends on other child vQueries then the child vQueries will be evaluated before the parent vQuery. Further in some embodiments a vQuery may return multi dimensional cell sets source records from a database or web service and or various other record sets. In some embodiments Analytics Client may communicate with servers in Data Center using JavaScript Object Notation JSON which is a lightweight data interchange format that is easy for humans to read and write and easy for machines to parse and generate. JSON is based on a subset of the JavaScript Programming Language Standard ECMA 262 3rd Edition December 1999. In some embodiments Analytic Client and servers at Data Center may communicate using Representational State Transfer REST over secure Hypertext Transfer Protocol https over VPN tunnel and JSON wire format may be used by to serialize and exchange structured data.

REST is a style of software architecture which may be used for distributed systems including clouds. In REST style architectures clients initiate requests to servers which servers process returning appropriate responses. Requests and responses are built around the transfer of resource representations which may take the form of a document that captures a current or expected state of a resource. In REST client requests may include all of the information to service the client request and any session state is maintained by the client.

VPN tunnels enable communication through Firewalls at user locations and the Firewall s at Data Center . Communication may occur through some combination of wired and wireless networks. In some embodiments Data Center may comprise multiple servers that serve users. In some embodiments multiple Data Centers not shown may be used to serve users. The use of multiple servers at a Data Center and or the use of multiple Data Centers may improve system performance and scalability by enabling load balancing shared caching and or enforcing security policies.

In some embodiments Data Centers in system that facilitate cloud based on demand context sensitive cluster analysis for business intelligence may support multiple customers where each customer may have one or more users. For example in a provider of dynamic on demand context sensitive cluster analysis services for business intelligence may use Data Center to serve multiple customers who may be geographically distributed at a plurality of user locations through N. In some embodiments security and other policies at Data Center may ensure the privacy security integrity and availability of customer information stored in databases . Thus organizations can significantly reduce the cost of infrastructure overhead maintenance etc. associated with on demand context sensitive cluster analysis services for business intelligence. Moreover even smaller organizations may be able to avail of on demand context sensitive cluster analysis services for business intelligence thereby increasing their competitive advantage vis a vis larger competitors.

Note that the architecture of system shown in is exemplary and for descriptive purposes only and various other configurations that would be apparent to one of ordinary skill in the art are possible and envisaged. For example in some embodiments on demand context sensitive cluster analysis services for business intelligence provided by a Data Center may be used by a single customer. In other embodiments Data Center may be an alternate computing platform offering private cloud based services and may be internal to a large organization. In general depending on customer specifications the architecture of system may be adapted so that one or more services provided by Data Center may be distributed between private infrastructures and public clouds in a manner consistent with embodiments disclosed herein.

In some embodiments Analytic Client may also include graphics and visualization components and controls. In some embodiments Analytic Client may comprise reusable visualization components. For example Analytic Client may comprise Adobe Flash Player to view rich multimedia streaming video and audio on a computer web browser or on supported mobile devices. In some embodiments results returned by Data Center from performing dynamic on demand context sensitive cluster analysis in business intelligence systems may be displayed in Analytic Client using Flash player.

In some embodiments requests from Analytic Client may be received by Web Server Client Interface . In some embodiments Web Server Client Interface may perform or assist in performing services such as authenticating users processing log in and user account related information route or relay requests from Analytic Clients to function based analytics application engine and or send responses to Analytic Clients . In some embodiments exemplary Web Server Client Interface may also interact with Operations Infrastructure to aid in performance monitoring application logging configuration management and or to receive software updates.

In some embodiments exemplary Function Based Analytics Application Engine may interact with databases or data sources to generate a response or portion of a response related to requests or vQueries received from analytic clients . For example a vQuery received from analytics client may be parsed by function based analytics application engine broken into its constituent sub queries which may be used to obtain information from databases or data sources and the results returned from executing the sub queries may be combined in accordance with the execution path specified in the original vQuery. The combined result may then be returned to analytics client . In some embodiments simple vQueries may be directly executed without breaking the vQuery up into sub queries. In some embodiments the sub queries may be executed in parallel.

Databases data sets or data sources . . . M may store customer data in a structured or unstructured format. For example the data may be stored as relational database tables multi dimensional tables multi dimensional data sets Excel spreadsheets and various other formats. In some embodiments data stored in one or more databases or data sources may be backed up and or mirrored to increase availability. Users and or a system administrator may set permissions that limit or prevent user access to data sets within a database data source and or to database data source of other customers.

Shared Services module may provide primary and secondary domain name services DNS and resolve names into IP addresses for the purpose of locating various computer services and devices. Shared Services module may also provide support for implementing Network Time Protocols NTP which allows clients and servers to synchronize their clocks to a common time reference and to support various other shared services such as but not limited to Simple Mail Transfer Protocol SMTP which allows the exchange of e mail messages.

In some embodiments Operations Infrastructure module may provide support for load balancing performance monitoring application logging system and user configuration management user and system administration and or to receive and disseminate software updates.

Upon receiving a request from the Core Server Management in some embodiments Analytic Processor may determine if security rules are met using Security Module . For example Security Module may be used to ensure that the user is authorized to execute requested vQuery . Next Analytic Processor may determine if the requested result is available in its cache and if so returns it to the Analytic Client . Otherwise in some embodiments Analytic Processor may delegate the execution of the processing functions for vQuery which may be specified in vQuery Definitions module to Function Engine in Calculator Module after ensuring that relevant Customer Data has been loaded into In Memory Data Storage . If relevant Customer Data has not been loaded into In Memory Data Storage then in some embodiments Analytic Processor may invoke special vQueries termed Data Connector vQueries to load customer data into In Memory Data Storage prior to invoking Function Engine . In some embodiments the final result obtained as a result of processing vQuery originating from Analytic Client may be cached.

In some embodiments Analytic Processor may accept requests which may take the form of vQuery requests originating from Analytic Client check security policies for the user look up the definition of vQuery in repository manage the loading of relevant data into In Memory Data Storage process the requests in part by using one or more modules in server architecture such as Function Engine generate the appropriate data sets and cache and return results to Analytic Client through core server management layer .

In some embodiments Core Server Management layer may help manage the server environment and provide client interfaces to handle requests from the Analytic Client including any vQueries . In some embodiments Web Server Client Interface and or operations infrastructure module may form part of core server management layer . For example core server management layer may facilitate integration with web application containers on analytic clients . In some embodiments the integration with web application containers may be achieved using Jetty and Java API for RESTful Web Services JAX RS may be used to implement the entry points available to the server s clients. Jetty is a Java based HTTP server and Java Servlet container.

In addition in some embodiments Core Server Management layer may expose one or more web services to clients such as Analytic Client . In some embodiments the web services that are exposed may include a data service used to retrieve the output of a vQuery a session service for managing user sessions and user accounts and an admin service for managing servers. The data service may be used for example by Analytic Client to send vQuery requests for processing to request validation of a client s authentication token and for routing the request to an appropriate analytic processor . In some embodiments core Server Management layer may also perform or facilitate the performance of user session management tasks perform JSON wire format data serialization and deserialization peer server discovery and management and event logging.

In some embodiments Repository may include Analytic Data Model Source Data Model and Processing Model . Processing Model may also include vQuery Definitions module and Function Declarations of any available processing functions metric content definitions and assets such as images available to Analytic Client . In some embodiments Repository may also maintain Metadata and application configuration information. In some embodiments Repository can be used directly by the Analytic Processor or by the Calculator during the execution of a query. For example upon receiving a vQuery request Analytic Processor may look up the requested vQuery definition in Repository to discover the parameter values and an execution path comprising a sequence of processing function calls corresponding to that vQuery.

In some embodiments Source Data Model may specify a maximal set of fact tables dimensions and cubes that can be constructed for any customer dataset. Source Data Model may comprise Templates including fact table templates Calculated Values and Measures . Templates Calculated values and Measures may be bound to customer data using Data Connector vQueries.

In general customer data may be stored in structured or unstructured form. In some embodiments customer data may comprise fact tables which may include measures or facts pertaining to a business process. Facts in the fact table may be associated with one or more dimensions which in some instances may be foreign keys that index one or more dimension tables which describe the facts in the fact table. In the dimension tables the labels may be described by members. Thus members may be viewed as categorizing facts in the fact table. For example in a sales application a sale fact may associated with a key such as a geographical identifier dimension and the geographical identifier may be used to determine the location or place of sale member .

In general each fact table may comprise several dimensions. For example a sale may be associated with a date time dimension geographical dimension customer dimension etc. In addition there may be multiple hierarchy levels of members for a given dimension. In the example if a Country dimension member associated with the geographical dimension refers to countries then potential choices for places of sale may be one of Canada UK or the US. However a Province dimension member at a lower level in the geographical dimensional hierarchy from Country could refer to provinces of Canada in which case the members might be British Columbia Alberta etc. Thus Country and Province are both members of the geographical dimension but at different levels of hierarchy within the geographical dimension.

In a cube facts in the fact table may be aggregated and associated across multiple dimensions to form a hypercube referred to as a cube . In general a cube or multi dimensional cube be constructed by aggregating facts by both dimension and hierarchy levels within the dimension. For example a sales number in a cube may be associated with a time period dimension with members Q1 2010 Q2 2010 etc. a geographic dimension Canada US Japan etc. a Product dimension Laptop Tablet etc. . Accordingly the cube may be used to quickly retrieve a result for a query of the type Sales of Tablets in Canada in Q1 2010. A cube view may be generated by constraining a cube. For example by limiting the cube to sales in the years 2011 and 2012. Cube views may be seen as the result of performing operations on the cube such as 

 i Slicing where a rectangular subset of a cube is selected by choosing a single value for one of its dimensions creating a new cube with one fewer dimension. For example choosing a specific year such as 2010 for sales.

 ii Dicing where a sub cube is selected by choosing specific values across multiple dimensions. For example the sales of laptops and tablets in the US and Canada for the years 2010 and 2011.

 iii Drill Down Up where the user may view the data at different levels of a dimensional hierarchy from the most summarized up to the most detailed down .

 iv Roll up where data is summarized along a dimension. For example by adding sales across products to obtain total sales.

In some embodiments a user may also set filters to specify which members of one or more dimensions may be relevant to a query. Filters may sometimes serve as hidden dimensions of the resulting cell set. For example in a HCM application a user may want a list of names of female employees in a current context displayed on a user interface in Analytic Client . If the current context is given by the location British Columbia then in the example above the user may run a query to list all employees which would be limited based on context to the employees in British Columbia from which employees who are male would be filtered out. Effectively the user specified filter serves to limit the results to female members without directly including a Gender dimension in the context.

In some embodiments Templates may include fact table templates which specify the calculated values that exist within the table as well as measures that can be evaluated on sets of facts from the fact table. Calculated Values may comprise information that may be calculated or derived from Customer Data . Calculated Values do not directly exist in Customer Data . For example in a HCM application Employee Tenure changes continuously with the passage of time and therefore cannot be represented as a static value. Accordingly a function which uses Employee Hire date and a current or user specified date as input and outputs Employee Tenure may be used to represent Employee Tenure.

Measures may take the form of functions that take in a set of facts from the fact table as input and output one or more values as output. In some embodiments the input set of facts may arise from a cube view. For example a measure function may simply count all of the facts in a set of cells and return the count as the result. In some embodiments Measures may be used by Aggregator to compute results from cube views.

In some embodiments Analytic Data Model may include Analytic Concepts and Analytic Models . Analytic Concepts may comprise functions that use the current application context as input and output a set of dimension members. For example in an HCM application for a current context given by Low Performers functions in Analytic Concepts may output a set of performance levels given by PerfLevel1 PerfLevel2 . . . . Similarly for a current context given by Locations functions in Analytic Concepts may output a set of Canadian provinces given by British Columbia Alberta . . . . In some embodiments Analytic Models may take the form of formulas or code which may be given the output of one or more vQueries as input and output results based on the formula or code. In some embodiments the formulas or code may be specified using R or Excel . For example we could define an Excel model for Cost of Turnover that takes in as input the results of a vQuery returning the number of employees who left an organization in Q1 2012 as well as the average salary of the employees who left and that outputs the dollar cost associated with replacing these employees.

In some embodiments Repository may also comprise Processing Model . In one implementation Processing Model may comprise vQuery Definitions Applications Function Declarations and Security module . In some embodiments Function Declarations for processing functions called by Analytic Processor may be held in Processing Model in Repository . For example processing function declarations held in Function Declarations may include for example Analytic Concept Builder which is responsible for executing multi dimensional queries Remove Attribute which removes a column from a result set or UnionOverPeriod which stitches together the results from a number of vQueries executed at different points in time in order to construct the result set needed to render a line chart. In general processing functions may be one of the following types i Data Transformation Aggregate Functions such as ExcelFormula ExecuteOverYear ExtractCauses etc. are responsible for calculating result sets and transforming and transforming the results of other functions into the forms required for display purposes ii Fetch Functions for fetching data from various sources such as SqlDatabaseFetch WebServiceFetch XlsFetch etc. iii Exporting Functions for exporting results in a variety of data formats such as XlsExport SqlExport etc. and iv Custom processing functions which may be user defined.

In some embodiments Processing Model may also comprise vQuery Definitions . A vQuery may take the form of a parameterized function that returns a result set. In general vQueries can be collections of Analytic Data Models and or Source Data Models processing functions and may be composed of sub vQueries. In some instances a vQuery may return a result which may take the form of a multi dimensional cell set source records from a database or webservice or any other multi dimensional data or record set. In some embodiments vQueries may be classified as Data Connector vQueries and Analytic vQueries. Data Connector vQueries may load data from an external source such as a Database Web Service Excel spreadsheet etc. and may provide that data to components or modules in Function Based Analytics Application Engine . For example Data Connector vQueries may be used to load customer data at initialization time into the In Memory Data Storage . Thus Data Connector vQueries may execute even if customer data has not been loaded into In Memory Data Storage . In other instances Data Connector vQueries may be used to directly provide external data to Analytic Client . For example external benchmarking data for comparison purposes such as an industry s average compensation or the nation s current unemployment rate may be provided to Analytic Client .

In some embodiments Analytic vQueries may be used to calculate the result sets that are returned to the client by executing a set of processing functions and or other vQueries. For example in an HCM application the cost of employee turnover may return a scalar number as a result. The Cost of Turnover Analytic Model may use the result from a Turnover vQuery as its input. Turnover vQuery in turn may use Organization Concept and DateRange Concept functions in Analytic Concepts as inputs. Organization Concept may use a specific department or organizational unit as input or may use application context to determine the organizational unit. Thus the Cost of Turnover Business Concept may use as input the result of a Turnover Business Concept function in Analytic Concepts which in turn may use Organization Concept with two parameters the name of the specific organizational unit and the date range. Accordingly the chain of evaluation can be expressed for example by Cost of Turnover Turnover Organization Engineering 2011 2012 373 000 The example above illustrates how higher order Business Concepts such as Cost of Turnover may be evaluated through functional decomposition. In the example above Organization and Turnover may be implemented as vQueries and the organizational unit Engineering and date range 2011 2012 are parameters. In some embodiments higher order analytic concepts may be created by binding the concepts to a series of functions resulting in complex vQueries. Metrics may be viewed as analytic business concepts that are capable of being calculated by one or more vQueries. In some embodiments a metric may correspond to a specific vQuery. For example in an HCM application a metric to determine the Direct Compensation per Full Time Employee may be evaluated by invoking an associated vQuery called directCompensationPerFTE .

In some embodiments Calculator Module may execute Processing Functions and calculate the vQuery results originating from Analytic Client . As shown in Calculator Module may comprise Function Engine Analytic Concept Builder Aggregator Cube Manager and In Memory Data Storage . In some embodiments In Memory Data Storage may comprise a proprietary In Memory Column Based Database.

Function Engine may be invoked by Analytic Processor . In some embodiments Function Engine may split or decompose vQueries to sub vQueries. In some embodiments some of the sub vQueries may be executed in parallel. For example when a vQuery generates a set of results and each result is based on a distinct set of dimension members then the vQuery may be decomposed into parallel executing sub vQueries where each sub vQuery operates on one of the distinct sets of the dimension members. For example in a sales application for vQuery to determine sales by quarter over some date range in one implementation the vQuery may be broken up into sub vQueries where each sub vQuery determines sales for one quarter in the date range. A similar approach may be used to decompose vQueries into parallel executing sub vQueries to determine sales by geography sales by organizational unit etc.

In some embodiments parallelizable vQueries received by Function Engine may be split into sub vQueries. Function Engine may then call Analytic Processor with the new set of sub vQueries to be executed in parallel. In some embodiments a Cube View may be constructed for each sub vQuery appropriately constrained by dimension member values and a result obtained for each sub vQuery. In some embodiments Analytic Processor may call i a UnionOverPeriod processing function which may perform a set union operation and place all the results into a single data set and ii a Tag processing function which appends appropriate dimension member values such as the appropriate value of the sales quarter Q1 2010 Q2 2010 etc. to each result. The result set may then be returned to Analytic Client through Core Server Management layer .

In some embodiments Function Engine may load and execute processing function plugins used by Analytic Processor . Processing function plug ins provide an extension to the capabilities of Function Engine . In one embodiment Function Engine may use a predefined interface to discover load and execute a function. In some embodiments in addition to a rich set of predefined functions the predefined interface may be used to permit third party plug ins thereby extending the capability of Function Engine . For example any new user defined formulas mathematical models business rules data transformations export formats or data connectivities can be supported by developing a processing function implementing the well defined interface for example by using Java classes and making the function available to Function Engine . For example third party function libraries such as the SAS XLS engine and R engine may be made available to Function Engine . A processing function may be any function called by Analytic Processor . In some embodiments processing functions may be able to recursively call back into Analytic Processor to retrieve relevant result sets and or manipulate result sets themselves and or call into Calculator Module to build a result set from cube views and customer provided data.

In some embodiments Analytic Concept Builder may be implemented as a processing function and may be called by Analytic Processor to execute Analytic Concepts by communicating with Cube Manager to obtain relevant cube views from Cube Manager and calling Aggregator to compute results. For example if a Products organization includes organizational units Manufacturing and R D and exemplary Analytic Concept such as All sub organizations within a Products organization was a part of a vQuery then upon evaluation of the analytic concept by the Analytic Concept Builder relevant dimension members Manufacturing and R D which are hierarchically below Products may be retrieved.

In some embodiments Customer Data may be split into Shards. A Shard may be viewed as a subset of the Customer Data including that subset of data matching a specific filter. For example the data for one quarter of a year or for some other specified time period. When the filter is applied on a quarter by quarter basis to entire Customer Data the set of individual shards constitute the entire customer data set. In some embodiments shards may be created from Customer Data and may be held on different physical servers. In some instances holding shards on different physical servers may facilitate load balancing and improve fault tolerance and data availability.

When a vQuery spans multiple shards Analytic Concept Builder may split the vQuery request into smaller sub vQueries called chunks . Further in some embodiments Analytic Concept Builder may call Analytic Processor with chunk requests . Analytic Processor may use information pertaining to the physical distribution of data to send the sub vQuery chunk requests to appropriate servers. The results obtained from executing the various sub vQuery chunks may be used by Analytic Processor to obtain a final result which may be returned to Analytic Client through Core Server Management layer .

In some embodiments the chunk sub vQuery requests may be further split into finer granularity sub sub vQuery requests. For example each physical server may have several multi threading processors or processor cores and a processor or processor core may be assigned one or more sub sub vQuery requests. The finer granularity requests may then be executed in parallel. For example when a vQuery operates on data over a year whereas the data shards contain data for one quarter Analytic Concept Builder may split the vQuery into chunks where each sub vQuery chunk operates on data for a distinct quarter. Analytic Concept Builder may then send the sub VQuery chunks to Analytic Processor which may relay them to appropriate servers for processing. In some embodiments the sub vQuery chunks may be further split by Analytic Processor for example into sub sub vQueries that operate on data for one month within each quarter so the original vQuery operating on data over a year may be broken up into twelve parallel executing sub sub vQueries. In some embodiments each of the twelve parallel executing sub sub vQueries may be executed on a distinct processor core. The results of the twelve parallel executing sub sub vQueries may be combined by Analytic Processor to obtain a final result.

In some embodiments Cube Manager may receive requests for cube views from Analytic Concept Builder . In some embodiments Cube Manager may cache cube views it constructs and construct new relevant cube views when the views do not exist in the cube view cache. If a requested cube view is in the cache Cube Manager may retrieve and return the cube view. In the event that requested cube view does not exist in the cache then Cube Manager may construct the cube view. In some embodiments cube views may be transient so that they are built on the fly for quick calculations and then destroyed when no longer used. Various optimization algorithms may be used to maintain and or replace cube views in the cache such as Least Recently Used LRU Least Frequently Used LFU Random Replacement Most Recently Used MRU etc. In some embodiments cube views may be removed from the cache after some pre defined time period.

In some embodiments Analytic Concept Builder may also call Aggregator and pass cube view s filters and any members and dimensions specified by the client and or generated by Analytic Concept Builder so that Aggregator has all the resources necessary to compute results. Aggregator may determine results from cube views and return results to the Analytic Concept Builder . In some embodiments Aggregator may execute a multi dimensional query or a drillthrough query on relevant cells in the cube view s to obtain results.

Multi dimensional queries executed by Aggregator to calculate results from cube views identify the data source relevant cube members and dimensions and relevant cube slices. Accordingly the multi dimensional queries executed by Aggregator may identify members in specific dimensions For example the multi dimensional query may request total sales over members of a time period dimension such as Q1 2010 and Q2 2010 a geographic dimension such as US and Canada and a Product dimension Laptops and Tablets . A cube constructed by Cube Manager may then be used to quickly retrieve a result for the multi dimensional query Total Sales of Laptops and Tablets in US and Canada in Q1 2010 and Q2 2010 . In some embodiments Aggregator may also aggregate or summarize values from cells to obtain results. For example Aggregator may perform various aggregate mathematical or statistical operations which may be defined in Measures module on values. The mathematical operations may include counts sum and or averages of values.

For drillthrough queries Aggregator may return actual fact data. In some instances for a drillthrough query a user may want fact data to be returned such as list of all of the employees in the current context e.g. location Canada related to a metric which may be absent days in March. Accordingly Aggregator may identify relevant dimension members apply appropriate filters and return fact results.

In some embodiments In Memory Data Storage may hold an In Memory Column Based Database which may comprise customer data . In some embodiments Customer Data may be loaded by Data Connector vQueries called by the Analytic Processor . In some embodiments Cube Manager may use In Memory Column Based database to build cube views. Cube views permit quick responses to multi dimensional queries. For example if a vQuery requests data such as Female Analysts in the Products organization in Canada the cube view would use the female member of the Gender dimension the analyst member of the Role dimension the Products member of the Organization dimension and the Canada member of the Locations dimension. The resulting cells in the cube view would contain relevant facts to calculate the result.

In some embodiments the algorithm may start in step where various initialization and housekeeping operations may be performed. In traditional BI systems while users may perform slicing dicing and other operations on the data the user s ability to run application specific queries on demand to derive information about underlying relationships and or trends in customer data is limited. Accordingly in some embodiments pre defined application specific queries may be provided to the user to facilitate decision making and to uncover latent relationships and trends. In some embodiments these predefined application specific queries may serve as an entry point for facilitating on demand context sensitive cluster analysis. In some embodiments method may start in step when a user invokes one or more pre defined application specific queries. In some embodiments the pre defined application specific queries may take the form of one or more vQueries.

Next in step the current context may be determined In some embodiments the current context may be indicated by the user or determined automatically by current hierarchy level s of member s of one or more dimensions based on the data set being viewed in a user s browser. For example the current context may be determined automatically by a browser or other application through which the user may view business intelligence information. The term context sensitive refers to the use of the current context for analysis query generation and other business intelligence operations. The current context may be seen as specifying a cube view or the current fact population being analyzed.

In general a set of facts may be analyzed by grouping them based on dimension members so that each dimension member may correspond to some subset of the fact set. In some embodiments for a given metric one or more underlying trends or relationships between the metric and dimension members may be uncovered by identifying and or ranking dimension members by the extent of to which they positively or negatively influence the metric. Positive influencers of a metric may be termed contributors and negative influencers may be termed as reducers . For example in an HCM application a user may be interested in determining influencers of a metric Direct Compensation per Full Time Employee. Accordingly the user may be provided with a pre defined application specific query which may take the form of a vQuery to evaluate influencers of the metric Direct Compensation per Full Time Employee . The predefined application specific query to evaluate influencers of the metric Direct Compensation per Full Time Employee may start by invoking another vQuery called directCompensationPerFTE to calculate the metric Direct Compensation per Full Time Employee based on the current context.

Accordingly in step a first or next dimension D may be considered. If current dimension D appears in the current context Y in step then in step let M designate the member of D appearing in the current context. Any child dimension members M at a lower hierarchical level may be considered. If there are child dimension members of M at the lower hierarchical level Y in step then in step the child dimension members of M may be selected. If there are no child dimension members of M at the lower hierarchical level N in step then in step then the current dimension member M may be selected in step .

On the other hand if current dimension D does not appear in the current context N in step then in step all top level members of the current dimension D are selected in step .

In step dimensional score s may be computed for the selected dimensional member s . In some embodiments a dimensional score may represent one measure of the influence of the selected dimension member s on the metric. The sign of the score may indicate whether the dimension member has a positive or negative influence on the metric. For example a higher absolute score may indicate that the dimension member has a greater influence on a metric. Further a positive score may indicate that the dimension member is a contributor while a negative score may indicate that the dimension member is a reducer.

In general a dimension member may be considered as an influencer of a metric if the dimension member skews the value of the metric over the population being considered. For example if 200 employees in Canada have quit in some time period out of a total of 1000 employees in Canada i.e. a 20 employee turnover whereas only 250 employees have quit worldwide out of a total of 5000 employees i.e. a 5 employee turnover then dimension member Canada may be considered a large contributor to the overall employee turnover rate. In some embodiments the dimensional member score computed in step may offer a quantitative assessment of the influence of the selected dimensional member on the metric over the population being considered.

In some embodiments a quantitative score to measure the degree of influence of a dimension member over a metric may be computed as Score GM OM GP OP if OP 0 Score 0 otherwise equation 1 where GM is the Group Metric value and is defined as the value of the metric over the selected dimension member OM is the Overall Metric value and is defined as the value of the metric over the entire population being considered GP is the Group Population count defined as the size of the population or number of individual data points or facts in the selected dimension member and OP is the Overall Population count defined as the size of the overall population.

In equation 1 Score factors both the deviation of the dimension member s metric value from the overall value as well as a relative significance of the influencer by weighting the deviation by the population size of the dimension member relative to the overall population. Note the equation 1 merely provide one quantitative measure of the influence of the selected dimension member. In general various other measures of score may be used. For example in one embodiment Score may be computed as Score GM OM GP if OP 0 Score 0 otherwise equation 2 Equation 2 make use of the fact that in Equation 1 OP the overall population count being considered is constant and does not vary with dimension member. Therefore ranking dimension members for influence based on equations 1 and 2 will yield identical results. As a further example in another embodiment in instances where the metric is a count of some sort i.e. a counting type metric Score may be computed as Score GM OM GP OP equation 3 In equation 3 Score is measured as the difference between the actual contribution of an influencer GM OM to an expected contribution of the influencer GP OP .

Next in step algorithm may consider additional dimensions if any. If there are additional dimensions Y in step the algorithm returns to step to begin another iteration with the next dimension. If there are no more dimensions to be considered N in step then the algorithm proceeds to step .

In step the dimension members considered are ranked based on the scores computed in step . In one embodiment dimension members with positive score values and dimension members with negative score values may be separated. Positive scores may be sorted in decreasing order of score value to rank contributor dimension members in order of influence on the metric. Similarly negative score values may be sorted in decreasing order of score magnitude to rank reducer dimension members in order of influence on the score metric. In some embodiments the algorithm may output the top N contributors and reducers. The method ends at step .

In some embodiments instead of including the top N contributors and reducers a rank diversification algorithm may introduce lower ranked members from different dimensions while removing higher ranked dimension members. The rank diversification algorithm may operate to increase the number of distinct populations included in the output results.

For example suppose that the top drivers of the turnover rate metric for a company with overall turnover rate of 1 are Location Canada turnover 25 population size 250 turnover rate 10 and Pay Level F turnover 18 population size 200 rate 9 and within this organization almost all employees assigned to pay level F are located in Canada so that there are 190 employees in Canada who are assigned to pay level F. Both of these characteristics are strong influencers of the metric value but we can see that Pay Level F is subsumed by Location Canada and as this latter characteristic has very high population overlap with the former. Thus we may want to diversify our results by not including Pay Level F in our top N results and thus making room in the top N for another more different characteristic influencer. In situations where the overlap in populations between a pair of dimension members of different ranks exceeds some threshold diversification may operate to remove the lower ranked dimension member of the pair from the output results while adding a third lower ranked member to increase the number of distinct populations included in the output results. In general diversification may operate to remove one or more lower ranked dimension members from the output results when the population overlap between the dimension members exceeds some threshold.

As shown in UI screen displays information pertaining to an HCM application to the user. Note that exemplary UI screen showing information pertaining to an HCM application is used in this document for explanatory and illustrative purposes only. In general the techniques disclosed herein may be used in a variety of other applications as would be apparent to one of ordinary skill in the art. UI screens may be user configurable and a variety of techniques may be used to display the data and interrelationships in a clear and intuitive manner.

In some embodiments UI may provide a variety of predefined application specific queries based on the current context to analyze one or more metrics by identifying ranking and or otherwise categorizing dimension members by the extent of to which they positively or negatively influence the metric s . For example as shown in the user may use drop down menu to select a query in order to determine which employee characteristics have the greatest positive or negative influence on compensation in the current context.

As shown in UI also permits the user to select one or more metrics that apply to the current context. For example tab selection permits the user to select Direct Compensation per Full Time Employee FTE Direct Compensation Increase and Overtime Compensation Ratio as a metric of interest.

Overall metric value is presented to the user to show the user the average direct compensation per FTE for the current context.

As shown in UI also displays the results and of running the pre defined dynamic on demand context sensitive cluster analysis relating to employee characteristics that influence compensations selected from drop down menu . In some embodiments each listed dimension member that influences the metric being considered may be shown with a unique icon.

As shown in histogram displays dimension members that are reducers and negatively impact the metric direct compensation per FTE in decreasing order of rank. Conversely histogram display dimension members that are contributors and positively impact the metric direct compensation per FTE in decreasing order of rank. For example histogram shows that locations classified as low cost geographic groups Geographic cost group Low have the greatest impact in reducing direct compensation per employee and that Vancouver is the location with greatest negative impact. Conversely histogram shows that locations classified as high cost geographic groups Geographic cost group High have the greatest impact in increasing direct compensation per employee and that London is the location with greatest positive impact. In addition histogram lists full time status as a factor influencing employee compensation negatively while histogram list pay level 5 as a factor influencing employee compensation positively. In some embodiments UI may include links that explain the ranking methodology. In some embodiments links may also allow users to alter the ranking methodology by selecting an alternate scoring mechanism or by applying rank diversification algorithms.

It should be noted that the examples provided above are for explanatory purposes only and many other variations of disclosed embodiments are possible and envisaged. For example a variety of methods and or models may be used to score and rank dimension members create predefined dynamic and on demand context sensitive cluster analysis routines. In addition systems disclosed for performing on demand context sensitive cluster analysis may be deployed on public and or private clouds accessible over the Internet through a browser or other clients. Further the methods disclosed may be used with various proprietary systems. In some embodiments the methods and techniques disclosed may be embodied as program code in computer readable media. Computer readable media may include magnetic solid state and optical media including but not limited to hard drives solid state drives flash drives memory cards optical disks etc. In some embodiments the user interfaces disclosed may be extended to enable more detailed control over program parameters and enhanced visualization of content.

Other embodiments of the present invention will be apparent to those skilled in the art from consideration of the specification and practice of one or more embodiments of the invention disclosed herein. It is intended that the specification and examples be considered as exemplary only with a true scope and spirit of the invention being indicated by the following claims.

