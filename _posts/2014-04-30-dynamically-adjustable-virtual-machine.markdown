---

title: Dynamically adjustable virtual machine
abstract: A system including a collection of local data processing devices and a collection of remote data processing devices. At least one local data processing device executes instructions configuring the at least one local data processing device to implement a resource manager, a virtual machine, and a virtual machine manager. The resource manager associates application threads of a software application executing on a data processing device with local processors. The virtual machine includes a plurality of virtual processors, and each virtual processor emulates a data processing device. The virtual machine associates local processors with virtual processors. Finally, the virtual machine manager associates at least one virtual processor with a local data processing device and at least one virtual processor with a remote data processing device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09280375&OS=09280375&RS=09280375
owner: Google Inc.
number: 09280375
owner_city: Mountain View
owner_country: US
publication_date: 20140430
---
A data processing device may include one or more physical processors. The physical processors may execute instructions configuring the data processing device to instantiate an instance of a virtual machine. Moreover the virtual machine may have one or more virtual processors and each virtual processor may emulate a corresponding physical processor. The virtual machine may execute an operating system and a software application.

One aspect of the disclosure provides a system including a collection of local data processing devices and a collection of remote data processing devices. At least one local data processing device executes instructions configuring the at least one local data processing device to implement a resource manager a virtual machine and a virtual machine manager. The resource manager associates application threads of a software application executing on a data processing device with local processors. The virtual machine includes a plurality of virtual processors and each virtual processor emulates a data processing device. The virtual machine associates local processors with virtual processors. Finally the virtual machine manager associates at least one virtual processor with a local data processing device and at least one virtual processor with a remote data processing device.

In some implementations the virtual machine manager determines a number of application threads and a number of virtual processors of the virtual machine. The virtual machine manager may determine the number of application threads by counting the number of application threads. Alternatively a software application may specify the number of application threads for example as metadata. The virtual machine manager compares the number of application threads with the number of virtual processors and instantiates one or more additional virtual processors based on the comparison. In some examples the virtual machine manager gauges a computation load of the application threads. The virtual machine manager configures the additional one or more virtual processors to emulate corresponding remote data processing devices and assigns one or more application threads to the additional one or more virtual processors.

In some implementations the resource manager allocates application threads among the local processors. The virtual machine manager and or the resource manager maintain a threshold range of application threads associated with each local processor by instantiating or removing local processors when the number of application threads per local processor is outside the threshold range.

The virtual machine may instantiate or remove virtual processors to maintain a one to one association of local processors to virtual processors. The virtual machine manager and or the resource manager may instantiate one or more remote processors after all the local processors have been instantiated. The virtual machine manager and or the resource manager may remove all the remote processors before removing a local processor. The resource manager may migrate all application threads executing on a remote processor to the local processors before removing the remote processor.

In some implementations the virtual machine manager replicates the remote data processing device by instantiating a replica of the remote data processing device. The virtual machine manager may switch over to the replica when the remote data processing device fails or become unresponsive. The virtual machine manager may determine an amount of time that has passed since a last communication with the remote data processing device. Moreover the virtual machine may switch the virtual processor executing on the remote data processing device to the replica of the remote data processing device in response to the amount of time exceeding a threshold period of time.

The remote data processing device may include a non transitory remote memory and the virtual machine may be configured to directly access the non transitory remote memory without communicating with the remote processors. For example the virtual machine may access the remote memory using remote direct memory access RDMA . In some implementations the virtual machine may use remote memory and local memory. However a resource manager and or a software application executing on the virtual machine may be unaware of the difference between the local memory and the remote memory. In other words to the resource manager and or the software application the remote memory and the local memory may appear as a single contiguous block of memory.

Another aspect of the disclosure provides a computer implemented method. The method includes executing instructions on a local data processing device to implement a virtual machine. The virtual machine includes virtual processors that emulate physical processors. The method includes associating one or more of the virtual processors with local processors in the local data processing device. The method further includes associating at least one virtual processor with a remote processor in a remote data processing device.

In some implementations the method includes executing a software application in the virtual machine. The software application includes application threads. The method includes associating at least one application thread with the local processor in the local data processing device and associating at least another application thread with the remote processor in the remote data processing device.

In some implementations the method includes determining a number of application threads and a number of virtual processors of the virtual machine. The method may determine the number of application threads by counting the number of application threads. Alternatively the method may determine the number of application threads by receiving the number of application threads from the software application. The method may include gauging a computation load of the application threads. The method includes comparing the number of application threads with the number of virtual processors and instantiating one or more additional virtual processors based on the comparison. The method further includes configuring the additional one or more virtual processors to emulate corresponding remote processors in a remote data processing device and assigning one or more application threads to the additional one or more virtual processors.

The method may include allocating application threads among the local processors. The method may further include maintaining a threshold range of application threads associated with each local processor by instantiating or removing local processors when the number of application threads per local processor is outside the threshold range. In some implementations the method includes instantiating or removing virtual processors to maintain a one to one association of local processors to virtual processors. The method may include instantiating one or more remote processors after all the local processors have been instantiated.

In some implementations the method includes removing all the remote processors before removing a local processor. The method may further include migrating all application threads executing on the remote processors to the local processors before removing the remote processors.

The method may include replicating the remote data processing device by instantiating a replica of the remote data processing device. The method may further include determining an amount of time that has passed since a last communication with the remote data processing device. The method may also include switching the virtual processor executing on the remote data processing device to the replica of the remote data processing device in response to the amount of time exceeding a threshold period of time. In some implementations the method includes accessing a non transitory remote memory associated with the remote data processing device without communicating with the remote processors.

Yet another aspect of the disclosure provides a system for executing a virtual machine. The system includes a local data processing device including local processors and a remote data processing device including remote processors. The local data processing device executes instructions configuring the local data processing device to implement a virtual machine having a plurality of virtual processors. The virtual machine can execute a software application with multiple application threads. A virtual machine manager associates each virtual processor with a corresponding local processor and allocates the application threads to the virtual processors. The virtual machine manager determines a current load of the virtual processors and instantiates an additional virtual processor when the current load exceeds a threshold. The virtual machine manager associates the additional virtual processor with a remote processor when all the local processors are already associated with virtual processors.

In some implementations the virtual machine manager removes the virtual processor associated with the remote processor when the current load is below the threshold. The virtual machine manager may determine the current load of the virtual processors by determining a number of application threads determining a number of virtual processors in the virtual machine and comparing the number of application threads with the number of virtual processors. In other implementations the virtual machine manager may determine the current load of the virtual processors by determining the number of application threads allocated to the virtual processors. In other implementations the virtual machine manager may determine the current load of the virtual processors by determining the percentage of time the virtual processors are idle. The virtual machine manager may instantiate or remove virtual processors to maintain the idle time within a threshold range of percentages.

The remote data processing device may include a non transitory remote memory. The virtual machine may be configured to directly access the remote memory without communicating with the remote processors for example using remote direct memory access RDMA . The virtual machine may use remote memory in combination with local memory. The virtual machine may present the remote memory and the local memory as a single contiguous block of memory to the resource manager and or the software application.

The VM layer includes one or more virtual machines . Each virtual machine may include one or more virtual central processing units vCPUs virtual processor hereinafter . In the example shown a first virtual machine includes a first set of one or more virtual processors and a second virtual machine includes a second set of one or more virtual processors . While the second set is shown as only including one virtual processor any number of virtual processors are possible. Each virtual processor may emulate a physical processor . Referring again to the example shown the first virtual processors emulates a first set of one or more physical processors and the second virtual processor emulates a second set of one or more physical processors .

The application layer includes applications that may execute in the virtual machine s . In the example shown in a first application executes in the first virtual machine and a second application executes in the second virtual machine . The applications may have application threads . In some implementations the application threads are separable or divisible chunks of the application that can be executed on different virtual processors . The application may identify the application threads or alternatively the virtual machine executing the application may identify the application threads in the application . The application may identify the application threads by separating the application threads with a marker. Additionally or alternatively the application may specify the number of application threads for example as metadata. By segregating the application into separately executable application threads the application can be executed using multiple virtual processors .

As exemplified in the first application includes application threads and the second application includes application threads . Since the first application has more application threads than the second application the first application may require more virtual processors than the second application . Accordingly the first virtual machine executing the first application with more application threads includes the first set of three virtual processors whereas the second virtual machine executing the second application with fewer application threads includes the second set of only a single virtual processor . The first virtual machine allocates the application threads of the first application to each of the virtual processors in the first virtual machine . Since the first set of virtual processors emulates the corresponding first set of physical processors once the first virtual machine allocates the first application threads to the associated virtual processors the first set of physical processors execute the allocated application threads

The virtual machine may include a resource manager . The resource manager may include an operating system that is executing in the virtual machine . The resource manager allocates the application threads among the virtual processors . The virtual processors include local virtual processors L and at least one remote virtual processor R. Each local virtual processor L emulates a local physical processor L whereas the remote virtual processor R emulates a remote physical processor R. Although the local physical processors L are located distant from the remote physical processor R the local virtual processors L and the remote virtual processor R need not be stored in distant memory locations.

The virtual machine manager maintains a mapping of the virtual processors to the physical processors . The virtual machine manager configures the local virtual processors L to emulate local physical processors L. The virtual machine manager further configures the remote virtual processor R to emulate the remote physical processor R. exemplifies a single remote virtual processor R emulating a single remote physical processor R. However in other examples the virtual machine manager may instantiate additional remote virtual processors R. The virtual machine manager may configure the additional remote virtual processors R to emulate additional remote physical processors R. In some implementations the virtual machine manager may instantiate the additional remote virtual processors R when a current load of the existing virtual processors exceeds a maximum load threshold. Additionally or alternatively the virtual machine manager may instantiate the additional remote virtual processors R when the number of application threads exceeds a threshold number of application threads.

In some implementations the resource manager categorizes the application threads as local application threads L or remote application threads R based on various criteria. The resource manager may allocate the local application threads L to local virtual processors L and the remote application threads R to the remote virtual processor R. Consequently the resource manager may cause the local physical processors L to execute the local application threads L and the remote physical processor R to execute the remote application threads R.

The resource manager may categorize the application threads into local application threads L and remote application threads R based on priorities of the application threads . In some implementations the resource manager determines the priorities of the application threads . Alternatively the application may associate a priority with at least some of the application threads . The resource manager may designate application threads with a high priority as local application threads L and applications threads with a low priority as remote application threads R. Consequently the local physical processors L execute the local application threads L that may have a high priority and the remote physical processor R executes the remote application threads R that may have a low priority.

In some implementations the number of application threads may vary while the virtual machine executes the application . In some scenarios the number of application threads may increase. The number of application threads may increase for a variety of reasons for example more users may start using the application the application may be receiving more data from the user or the application may be performing a task that requires more application threads . If the number of application threads increases and virtual machine manager keeps the number of virtual processors constant then the resource manager allocates the additional application threads to the existing virtual processors .

In order to maintain a fast response time for each virtual processor the virtual machine manager the resource manager the application a developer of the application and or a user of the application may specify a threshold maximum number of application threads that the resource manager may allocate to each virtual processor . If the number of application threads increases significantly the number of application threads allocated to the virtual processors may exceed the threshold. In some implementations when the number of application threads allocated to a virtual processor exceeds the threshold the virtual machine manager instantiates the remote virtual processor R. The virtual machine manager R maps or associates the newly instantiated remote virtual processor R to a remote physical processor R so that the remote virtual processor R emulates the remote physical processor R. The resource manager detects the instantiation of the remote virtual processor R and allocates at least some of the application threads to the remote virtual processor R. Advantageously the number of virtual processors in the virtual machine is not limited by the number of local physical processors L in the local data processing devices L of the local collection L.

The virtual machine manager may instantiate additional remote virtual processors R and associate the additional remote virtual processors R with corresponding remote physical processors R in the remote collection R of the remote data processing devices R. In some implementations the virtual machine manager may instantiate the additional remote virtual processors R in response to the number of application threads exceeding a threshold number of application threads. In some examples the virtual machine manager gauges a computation load of the application threads and instantiates additional remote virtual processors R to handle increased loads. Additionally or alternatively the virtual machine manager may instantiate an additional remote virtual processor R in response to losing communication with a local virtual processor L or the local virtual processor L becoming unresponsive. The resource manager may transfer or migrate the application threads from an unresponsive local virtual processor L to a newly instantiated remote virtual processor R.

The guest processors may include local guest processors L and a remote guest processor R. The resource manager maps the local guest processors L to the local virtual processors L that emulate local physical processors L. The resource manager further maps the remote guest processor R to the remote virtual processor R that emulates the remote physical processor R. Although the guest processors are denoted as local guest processors L and remote guest processors R the remote guest processor R may be stored in the same memory as the local guest processors L. In other words the remote guest processor R need not be in a different location than the local guest processor L. However as stated earlier the remote physical processor R is located at a different location from the local physical processor L.

In operation the resource manager allocates the application threads to the guest processors . The resource manager may allocate the local application threads L to local guest processors L and the remote application threads R to the remote guest processors R. Further the local guest processors L interact with the local virtual processors L and the remote guest processor R interacts with the remote virtual processor R to execute the application threads . Consequently the local physical processors L execute the local application threads L allocated to the local guest processors L and the remote physical processor R executes the remote application threads R allocated to the remote guest processor R.

The virtual machine manager determines whether the local virtual processors L are capable of executing the additional remote application threads R. When the virtual machine manager determines that the local virtual processors L are not capable of executing the additional remote application threads R then the virtual machine manager instantiates the remote virtual processor R. The virtual machine manager maps the remote virtual processor R to the remote physical processor R. Therefore virtual machine manager can instantiate the remote virtual processor R even if there are no available local physical processors L.

In some implementations the virtual machine manager includes a load determiner a load threshold and a virtual processor instantiator . The load determinor determines a current load of the virtual processors . The load determinor may determine the current load of the virtual processors by determining the number of application threads and dividing the number of application threads by the number of virtual processors that are currently instantiated. In the example of there are two local virtual processors L that are currently instantiated and there are eight applications threads L. The load determinor may determine the load by dividing the number of application threads eight by the number of local virtual processors L two currently instantiated. In this example the load is four application threads per virtual processor 8 2 4 .

The load threshold may include a maximum number of application threads that a virtual processor is permitted to execute. For example the load threshold may state that each virtual processor is permitted to execute a maximum of five application threads . Since the current load is four application threads per virtual processor the current load is less than the maximum load threshold of five application threads per virtual processor . However when the application generates the additional remote application threads R the current load threshold increases from four applications threads per virtual processors to six application threads per virtual processors 6 12 2 . The new current load of six application threads per virtual processor exceeds the load threshold of five application threads per virtual processor .

The virtual processor instantiator instantiates a remote virtual processor R in response to the current load e.g. 6 application threads per virtual processor exceeding the maximum load threshold e.g. 5 application threads per virtual processor . The newly instantiated remote virtual processor R emulates a remote physical processor R in a remote data processing device R of a remote collection R. After the remote virtual processor R is instantiated the resource manager may reallocate the application threads in order to balance the load on each virtual processor . After reallocating the application threads the current load becomes four applications threads per virtual processors 12 3 4 . Since the current load is now lower than the load threshold of five application threads per virtual processor the virtual machine manager may not instantiate another virtual processor .

In some implementations the load determiner determines the current load of the existing virtual processors by measuring an amount of time that the virtual processors are busy. The load threshold may include a first threshold percentage e.g. 80 . If the percentage of time that the virtual processors are busy is above the first threshold percentage then the virtual machine manager may instantiate additional remote virtual processors R. The load threshold may include a second threshold percentage e.g. 20 . If the percentage of time that the virtual processors are busy is below the second threshold percentage then the virtual machine manager may remove one or more virtual processors . The virtual machine manager may instantiate or remove virtual processors to maintain the percentage of busy time within the second threshold percentage and the first threshold percentage e.g. 20 80 .

In other implementations the load determiner may use an amount of idle time instead of the amount of busy time to add or remove virtual processors . If the percentage of time that the virtual processors are idle is above a third threshold percentage e.g. 80 then the virtual machine manager may remove virtual processors . The virtual machine manager may start by removing remote virtual processors R. Similarly if the percentage of time that the virtual processors are idle is below a fourth threshold percentage e.g. 20 then the virtual machine manager may add one or more virtual processors . The virtual machine manager may instantiate or remove virtual processors to maintain the percentage of idle time within the fourth threshold percentage and the third threshold percentage e.g. 20 80 .

As discussed above in some implementations the virtual machine manager may determine the current load of the two local virtual processors by dividing the number of local application threads L by two. Other methods for determining the current load are also possible for example by determining an amount of idle time or amount of busy time of the virtual processors . For example the virtual machine manager may take into account the complexity of each application thread the number of executable instructions in each application thread the lines of software code in each application thread the number of APIs invoked by each application thread and or the reliance of each application thread on user input.

At the virtual machine manager determines whether the current load of any instantiated virtual processor exceeds a load threshold for example the load threshold . If the current load of any virtual processor that is currently instantiated exceeds the load threshold then the virtual machine manager instantiates a remote virtual processor R at . At the virtual machine manager maps or associates the remote virtual processor R with a remote physical processor R. The remote virtual processor R emulates the remote physical processor R.

Referring to in some implementations the virtual machine manager replicates the remote data processing device R by instantiating a replicated data processing device R . The replicated data processing device R is a replica of the remote data processing device R. The replicated data processing device R includes the same hardware components as the remote data processing device R. Furthermore the replicated data processing device R executes the same operating system as the remote data processing device R. In the example of the replicated data processing device R is in another remote collection R . In other words the replicated data processing device R and the remote data processing device R are in different remote collections R thereby decreasing the chances of the replicated data processing device R suffering from the same problems as the remote data processing device R. For example a power outage may not affect both the remote collections R and R . However in other implementations the replicated data processing device R may be in the same remote collection R as the remote data processing device R.

The virtual machine manager instantiates a replicated virtual processor R . The replicated virtual processor R is a replica of the remote virtual processor R. The virtual machine manager maps the replicated virtual processor R to the replicated data processing device R so that the replicated virtual processor R emulates a replicated physical processor R . The replicated physical processor R may be of the same type and architecture as the remote physical processor R.

In some implementations the resource manager directs the remote application threads R to both the remote virtual processor R and the replicated virtual processor R . Both the remote virtual processor R and the replicated virtual processor R execute the remote application threads R. Further both the remote virtual processor R and the replicated virtual processor R return the results of executing the remote application threads to the resource manager . The resource manager uses the results from whichever virtual processor R or R that returns the results first.

In other example implementations the virtual machine manager uses the replicated virtual processor R and the replicated data processing device R as a backup for the remote virtual processor R and the remote data processing device R respectively. The remote virtual processor R and or the remote data processing device R may be more prone to failure than local virtual processors L and the local data processing devices L due to network congestion and or latency. The virtual machine manager monitors a health status of the remote virtual processor R and or the remote data processing device R. If the health status changes from healthy to unhealthy then the virtual machine manager switches from the remote virtual processor R to the replicated virtual processor R .

In some implementations the virtual machine manger switches from the remote virtual processor R to the replicated virtual processor R after a threshold amount of time has passed since the last communication with the remote data processing device R. For example the virtual machine manager may switch ten seconds after not receiving a communication signal from the remote data processing device R. Other threshold amounts of time are also contemplated. In other implementations the virtual machine manager may switch to the replicated data processing device R immediately after the virtual machine manager detects a failure of the remote data processing device R.

In some implementations the virtual machine manager may restart the failed or unresponsive remote virtual processor R remote physical processor R and or remote data processing device R. In other implementations the virtual machine manager removes the failed or unresponsive remote virtual processor R instantiates a new virtual processor and associates the newly instantiated virtual processor with a different remote physical processor than the failed or unresponsive remote physical processor R. The virtual machine manager may use the newly instantiated virtual processor as a backup for the replicated virtual processor R that has taken over the failed or unresponsive remote virtual processor R.

Referring to B and C the number of application threads may decrease while the application is executing in the virtual machine . The number of application threads may decrease when fewer users are using the application less data is being received by the application or when the application is performing a relatively simple task. As the number of application threads decreases the load on each virtual processor decreases. When the load on the virtual processors decreases below a minimum load threshold then the virtual machine manager may remove one or more virtual processors from the virtual machine . In some implementations the virtual machine manager removes all remote virtual processors R before removing a local virtual processor L.

When the virtual machine manager removes a virtual processor the virtual machine manager dissociates the physical processor that was associated with the virtual processor . The dissociated physical processor may be used by another virtual machine . By removing an idle or a relatively idle virtual processor the virtual machine manager mitigates waste of physical processors . Moreover a dissociated remote physical processor R may be used as a local physical processor L by a virtual machine executing on one of the remote data processing devices R in the remote collection R. Therefore by removing a remote virtual processor R before removing any local virtual processors L the virtual machine manager makes the remote physical processor R available sooner for another virtual machine executing in the remote collection R.

As depicted in when the current load on the virtual processors is below a minimum load threshold the virtual machine manager removes the remote virtual processor R that emulates the remote physical processor R. If after removing the remote virtual processor R the current load is still below the minimum load threshold then the virtual machine manager removes a local virtual processor L that emulates a local physical processor L.

If any of the virtual processors is emulating a remote physical processor R then at the virtual machine manager removes the remote virtual processor R that is emulating the remote physical processor R. If however the virtual machine manager determines that no virtual processor is associated with a remote physical processor R then the virtual machine manager removes a local virtual processor L that is emulating a local physical processor L at .

After the virtual machine manager removes a virtual processor the resource manager reallocates the application threads among the remaining virtual processors . The virtual machine manager determines the new current load of the virtual processors after the resource manager reallocates the application threads . The virtual machine manager continues to remove virtual processors until the current load is above the minimum load threshold.

Referring to in some implementations a distributed system includes loosely coupled data processing devices e.g. computers or servers each having a physical processor e.g. one or more central processing units CPUs or other computing resource in communication with storage resources e.g. memory flash memory dynamic random access memory DRAM phase change memory PCM and or disks having spindles that may be used for caching data . A storage abstraction e.g. key value store or file system overlain on the storage resources allows scalable use of the storage resources by one or more clients . The clients may communicate with the data processing devices through a network e.g. via RPC . A virtual machine executing in the distributed system may use a first storage resource and a second storage resource . However the virtual machine may present the first storage resource and the second storage resource as a single contiguous block of memory to a resource manager and or a software application executing on the virtual machine.

The distributed system may include multiple layers of redundancy where data is replicated and or encoded and stored in multiple data centers. Data centers not shown house computer systems and their associated components such as telecommunications and storage systems. Data centers usually include backup power supplies redundant communications connections environmental controls to maintain a constant temperature and security devices. Data centers may be large industrial scale operations that use a great amount of electricity e.g. as much as a small town . Data centers may be located in different geographical locations e.g. different cities different countries and different continents . In some examples the data centers or portions thereof requires maintenance e.g. due to a power outage or disconnecting a portion of the storage system for replacing parts or a system failure or a combination thereof . The data stored in these data centers and in particular the distributed system may be unavailable to users clients during the maintenance period resulting in the impairment or halt of a user s operations. Therefore it is desirable to provide a distributed system capable of efficiently using the storage resources of the data processing devices during a maintenance and or certain data center hardware software failures without moving the data in advance of such a maintenance or failure. The system may adjust a load of the available resources and jobs of the adjusted load may be executed in a predefined order such as high availability jobs before the low availability jobs.

In some implementations the distributed system is single sided eliminating the need for any server jobs for responding to remote procedure calls RPC from clients to store or retrieve data on their corresponding data processing devices and may rely on specialized hardware to process remote requests instead. Single sided refers to the method by which most of the request processing on the data processing devices may be done in hardware rather than by software executed on physical processors of the data processing devices . Rather than having a physical processor of a data processing device e.g. a server execute a server process that exports access of the corresponding storage resource e.g. non transitory memory to client processes executing on the clients the clients may directly access the storage resource through a network interface controller NIC of the data processing device . In other words a client process executing on a client may directly interface with one or more storage resources without requiring execution of a routine of any server processes executing on the physical processors . This single sided distributed storage architecture offers relatively high throughput and low latency since clients can access the storage resources without interfacing with the physical processors of the data processing devices . This has the effect of decoupling the requirements for storage and CPU cycles that typical two sided distributed systems carry. The single sided distributed system can utilize remote storage resources regardless of whether there are spare CPU cycles on that data processing device furthermore since single sided operations do not contend for server physical processor resources a single sided system can serve cache requests with very predictable low latency even when data processing devices are running at high CPU utilization. Thus the single sided distributed system allows higher utilization of both cluster storage and physical processor resources than traditional two sided systems while delivering predictable low latency.

In some implementations the distributed system includes a storage logic portion e.g. encoding system a data control portion and a data storage portion . The storage logic portion may include a transaction application programming interface API e.g. a single sided transactional system client library that is responsible for accessing the underlying data for example via RPC or single sided operations. The data control portion may manage allocation and access to storage resources with tasks such as allocating storage resources registering storage resources with the corresponding network interface controller setting up connections between the client s and the data processing devices handling errors in case of machine failures etc. The data storage portion may include the loosely coupled data processing devices 

The distributed system may store data in dynamic random access memory DRAM and serve the data from the remote data processing device R via remote direct memory access RDMA capable network interface controllers . A network interface controller also known as a network interface card network adapter or LAN adapter may be a computer hardware component that connects a physical processor to the network . Both the data processing devices and the client may each have a network interface controller for network communications. A host process executing on the physical processor of the data processing device registers a set of remote direct memory accessible regions of the memory with the network interface controller . The host process may register the remote direct memory accessible regions of the memory with a permission of read only or read write. The network interface controller of the data processing device creates a client key for each registered memory region 

The single sided operations performed by the network interface controllers may be limited to simple reads writes and compare and swap operations none of which may be sophisticated enough to act as a drop in replacement for the software logic implemented by a traditional cache server job to carry out cache requests and manage cache policies. The transaction API translates commands such as look up or insert data commands into sequences of primitive network interface controller operations. The transaction API interfaces with the data control and data storage portions of the distributed system .

The distributed system may include a co located software process to register memory for remote access with the network interface controllers and set up connections with client processes . Once the connections are set up client processes can access the registered memory via engines in the hardware of the network interface controllers without any involvement from software on the local physical processors of the corresponding local data processing devices L.

Various implementations of the systems and techniques described here can be realized in digital electronic circuitry integrated circuitry specially designed ASICs application specific integrated circuits computer hardware firmware software and or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and or interpretable on a programmable system including at least one programmable processor which may be special or general purpose coupled to receive data and instructions from and to transmit data and instructions to a storage system at least one input device and at least one output device.

These computer programs also known as programs software software applications or code include machine instructions for a programmable processor and can be implemented in a high level procedural and or object oriented programming language and or in assembly machine language. As used herein the terms machine readable medium and computer readable medium refer to any computer program product apparatus and or device e.g. magnetic discs optical disks memory Programmable Logic Devices PLDs used to provide machine instructions and or data to a programmable processor including a machine readable medium that receives machine instructions as a machine readable signal. The term machine readable signal refers to any signal used to provide machine instructions and or data to a programmable processor.

Implementations of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. Moreover subject matter described in this specification can be implemented as one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device a composition of matter affecting a machine readable propagated signal or a combination of one or more of them. The terms data processing apparatus computing device and computing processor encompass all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them. A propagated signal is an artificially generated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.

A computer program also known as an application program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Moreover a computer can be embedded in another device e.g. a mobile telephone a personal digital assistant PDA a mobile audio player a Global Positioning System GPS receiver to name just a few. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user one or more aspects of the disclosure can be implemented on a computer having a display device e.g. a CRT cathode ray tube LCD liquid crystal display monitor or touch screen for displaying information to the user and optionally a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input. In addition a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user for example by sending web pages to a web browser on a user s client device in response to requests received from the web browser.

One or more aspects of the disclosure can be implemented in a computing system that includes a backend component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a frontend component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification or any combination of one or more such backend middleware or frontend components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN an inter network e.g. the Internet and peer to peer networks e.g. ad hoc peer to peer networks .

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other. In some implementations a server transmits data e.g. an HTML page to a client device e.g. for purposes of displaying data to and receiving user input from a user interacting with the client device . Data generated at the client device e.g. a result of the user interaction can be received from the client device at the server.

While this specification contains many specifics these should not be construed as limitations on the scope of the disclosure or of what may be claimed but rather as descriptions of features specific to particular implementations of the disclosure. Certain features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable sub combination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a sub combination or variation of a sub combination.

Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multi tasking and parallel processing may be advantageous. Moreover the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly other implementations are within the scope of the following claims.

