---

title: Interactive partitioning and mapping of an application across multiple heterogeneous computational devices from a co-simulation design environment
abstract: In an embodiment, a method for interactively changing allocation of an application including multiple algorithm components executing on a heterogeneous target environment (HTE) provides a user interface in a co-simulation design environment. The user interface is associated with the application having multiple algorithm components executing on the HTE that includes multiple computing devices with different processing capabilities. The method also sets attributes of the allocation scheme of the application using the user interface. The setting occurs when the application is executing. The method further receives data associated with the executing of the application in the co-simulation design environment when the application is executing subsequent to the setting of the attributes of the allocation scheme.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09442696&OS=09442696&RS=09442696
owner: The Math Works, Inc.
number: 09442696
owner_city: Natick
owner_country: US
publication_date: 20140116
---
Co simulation is a technique used by developers to design test and optimize an application that is to be implemented on particular target hardware. With co simulation one or more components of an application in development execute on the target hardware. The target hardware may be a heterogeneous target environment HTE with computational devices having different processing capabilities. An HTE may include computational devices having different execution characteristics. For example a first computational device may have first execution characteristics and a second computational device may have second execution characteristics where the first and second execution characteristics differ from each other.

During co simulation execution of the application under development may include one or more application components that are simulated in the host simulation environment and one or more application components that are executed on the heterogeneous target environment.

According to various embodiments an application is designed in a co simulation design environment. The application may be designed by a user. A user may be a person an algorithm a program that is part of an application running in simulation or any combination thereof. The user may interact with a co simulation design environment discussed below. Accordingly interaction may refer to an interaction with a person a program or any combination thereof.

Exemplary co simulation design environments may include graphical programming environments e.g. block diagram environments BDEs and or textual programming environments TPEs . An application designed in a BDE may be a BDE model and an application designed in a TPE may be a TPE model. According to various embodiments a TPE model may include but is not limited to one or more of a textual program a script a function another TPE model etc. A BDE model may include but is not limited to one or more of a block a subsystem another BDE model etc.

An application designed in the co simulation design environment may include one or more elements. An element of the application may refer to any constituents of the application. For example for a BDE model an element may include a line representing a signal or a block representing an operation to be performed on the signal. An application component may be formed by grouping together one or more elements of the application. An application component may be a subset of the application that is able to run independently from the rest of the application and that has defined boundaries along with a defined input and output.

In a TPE the application components may be formed by grouping elements of the application by function object method model textual program other demarcated boundary e.g. a conditional statement etc.

In a BDE the application components may be formed by grouping elements of the application by block subsystem rate sub model e.g. Referenced Model other demarcated boundary etc. An application component may be composed of one or more executions of an algorithm that may be mapped to computation devices of a heterogeneous target environment HTE .

An application component may be designated to execute on the HTE. The HTE may include one or more computational devices. For example heterogeneous computational devices may include a general purpose preprocessor GPP a graphics processing unit GPU a digital signal processor DSP a programmable logic controller PLC a field programmable gate array FPGA an application specific integrated circuit ASIC or simulators of computational devices including a hardware description language HDL simulator SystemC simulator transaction level model TLM based virtual platform etc.

Two or more of the computational devices in the HTE may be connected by an input output I O interface that allows for the transfer of data between the connected devices. The I O interface may include a physical connection such as an Ethernet connection or a serial interface connection and or an associated protocol for transmitting and receiving data such as a Transmission Control Protocol Internet Protocol TCP IP a Serial Peripheral Interface SPI etc. Each of the I O interfaces may have specific characteristics that makes the I O interface suitable for certain tasks. For example a serial RapidIO SRIO interface is a serialized high bandwidth communication interface that may be used to exchange large amounts of data such as video data.

An allocator may allocate or map one or more application components to computational devices of the HTE when the application is compiled i.e. at compile time or synthesis time or when the application is executing i.e. at run time or at execution time . Conventionally the allocator may be implemented in a target processing device such as found in the HTE. A conventional allocator may include a conventional static allocator CSA i.e. where the allocation occurs at compile time or synthesis time or a conventional dynamic allocator CDA i.e. where the allocation occurs at run time or at execution time . According to various embodiments an allocator may implement one or more allocation schemes.

According to some embodiments the computational devices of the HTE illustrated in may include for example GPP as computational device DSP as computational device GPU as computational device and FPGA as computational device .

For example the allocation scheme implemented by CSA illustrated in has the following fixed mapping execution of application components and is allocated to computational device execution of application component is allocated to computational device execution of application component is allocated to computational device and execution of application components and is allocated to computational device . The mapping between the execution of application components and computational devices implemented by CSA remains unchanged during the execution of the application components on the HTE with computational devices .

The allocation scheme implemented by CSA illustrated in has a different fixed mapping . As shown in CSA allocates execution of application components and to computational device execution of application components and to computational device execution of application component to computational device and execution of application component to computational device . The mapping between the execution of application components and computational devices remains unchanged during the execution of the application components on the HTE that includes computational devices .

The allocation scheme implemented by CSA illustrated in has a different fixed mapping . As shown in CSA allocates execution of application components and to computational device execution of application component to computational device execution of application components and to computational device and execution of application component to computational device . The mapping between the execution of application components and computational devices remains unchanged during the execution of the application components on the HTE that includes computational devices .

Other rule sets for exemplary conventional dynamic allocation scheme may implement for example a shortest execution time dynamic allocator. A shortest execution time dynamic allocator allocates an application component having a shortest predicted execution to a computational device that is the least busy. An application component having the second shortest execution time is allocated to a computation device that is the second least busy. One of ordinary skill in the art will appreciate that load balancing and shortest execution time allocation execution rules and or rule sets are used for illustrative purposes only and that the execution criteria may employ other execution techniques such as rules and or rule sets without departing from the spirit of the invention.

For example CDA illustrated in may change the mapping between execution of application components and computational devices when application components are executing on the HTE. In an embodiment CDA may implement allocation schemes and used by a CSA as illustrated in . At time t 0 CDA may implement first mapping . At time t 1 CDA may change the mapping and implement second mapping . While the execution of algorithms of the application components continues on the computational devices of the HTE CDA implements third mapping at time t 3.

As shown in CDA may change the mapping of an execution algorithm of an application component to a specific computational device multiple times during the execution of the application. One of ordinary skill in the art will appreciate that CDA does not have to allocate execution algorithm of the application components to each computational device of the HTE. According to various embodiments CDA may choose to allocate execution of no application component or all application components to a given computational device of the HTE.

If a CDA is implemented in the co simulation design environment such allocator is referred as a co simulation dynamic allocator. Accordingly the co simulation dynamic allocator is an allocator implemented in the co simulation environment with a dynamic mapping between execution of algorithm and computational devices. The mapping implemented by a co simulation dynamic allocator is similar to the mapping illustrated in . However contrary to a CDA which is implemented on the target environment the co simulation dynamic allocator is implemented in the co simulation design environment.

According to various embodiments interactive allocators may be constructed from the co simulation allocators. For example an interactive static allocator may be constructed from a co simulation static allocator. The interactive static allocator is an allocator implemented in the co simulation environment that may interactively change from one co simulation static allocator to another co simulation static allocator during co simulation without re generating re compiling or re running code for application components executing in the co simulation environment.

The interactive static allocator may re allocate execution of application components to computational devices operating on HTE during co simulation i.e. at run time or execution time from the co simulation environment. This form of operation by an interactive static allocator may be referred to as changing of co simulation static allocators. The changing of one co simulation static allocator to another co simulation static allocator may be prompted by the user. Changing one co simulation static allocator to another co simulation static allocator has the effect of changing the mapping of application components to computational devices without re generating re compiling or re running code for the one or more application components.

At time t 0 ISA implements a first co simulation static allocator where execution of the application components and is allocated to computational device execution of the application component is allocated to computational device execution of the application component is allocated to computational device and execution of the application components and is allocated to computational device .

At time t 1 ISA may change to co simulation static allocator without re generating re compiling or re running code for the one or more application components. As illustrated in at time t 1 execution of the application components and is allocated to computational device execution of the application components and is allocated to computational device execution of the application component is allocated to computational device and execution of the application component is allocated to computational device .

At time t 2 ISA may change to co simulation static allocator without re generating re compiling or re running code for the one or more application components. As illustrated in at time t 2 execution of the application components and is allocated to computational device execution of the application component is allocated to computational device execution of the application components and is allocated to computational device and execution of the application component is allocated to computational device .

The technique of changing the mapping between execution of algorithm and computational devices at run time or at execution time such as changing from co simulation static allocator to co simulation static allocator may be thought of as changing of co simulation static allocators during co simulation i.e. run time or execution time without re generating re compiling or re running code for the one or more application components. In certain embodiments a desired co simulation static allocator may be chosen during co simulation. Based on the selected co simulation static allocator a desired co simulation static allocator that will implement a static mapping of components to computational devices at compile time of the application may be automatically generated. This generated co simulation static allocator may be reused for subsequent executions of the application on HTE.

According to various embodiments interactive dynamic allocators may be constructed from co simulation allocators. For example an interactive dynamic allocator may be constructed from a co simulation dynamic allocator. The interactive dynamic allocator is an allocator implemented in the co simulation environment that may interactively change from one co simulation dynamic allocator to another co simulation dynamic allocator during co simulation without re generating re compiling or re running code for the one or more application components.

The interactive dynamic allocator re allocates execution of application components to computational devices during co simulation i.e. at run time or at execution time from the co simulation environment. Accordingly the interactive dynamic allocator is an allocator implemented in the co simulation environment that may vary from one co simulation dynamic allocator to another co simulation dynamic allocator at run time or at execution time during co simulation without re generating re compiling or re running code for the one or more application components. This form of operation by an interactive dynamic allocator can be referred to as changing of co simulation dynamic allocators. The changing of one co simulation dynamic allocator to another co simulation dynamic allocator may be prompted by the user. As provided above the user may be a person an algorithm a program that is part of an application running in simulation or any combination thereof.

A co simulation dynamic allocator re allocates execution of application components to computational devices based on for example conditions and or rule sets of the run time or execution time environment during co simulation without re generating re compiling or re running code for the one or more application components. For example an interactive dynamic allocator may change a first co simulation dynamic allocator to a second co simulation dynamic allocator. The first co simulation dynamic allocator may be based on load balancing where the execution algorithm of an application component is allocated to a least busy computational device at that instance of time. The second co simulation dynamic allocator may allocate the execution of the application component to the computational device that has been running the longest. Other conditions and or rule sets such as dependency among algorithms e.g. requiring two or more application components to run on the same computational device etc. can be used to determine how co simulation dynamic allocators may allocate execution of application components to computational devices. In some embodiments a desired co simulation dynamic allocator may be selected during co simulation. Based on the selected co simulation dynamic allocator a desired co simulation dynamic allocator may be automatically generated using an embodiment of the invention. The generated co simulation dynamic allocator may be reused for subsequent executions of the application on the HTE.

At time t 0 IDA implements the first mapping of co simulation dynamic allocator where execution of the application components and is allocated to computational device execution of the application component is allocated to computational device execution of the application component is allocated to computational device and execution of the application components and is allocated to computational device .

At time t 1 IDA may change to co simulation dynamic allocator without re generating re compiling or re running code for the one or more application components. IDA may implement a second mapping of co simulation dynamic allocator where execution of the application components and is allocated to computational device execution of the application components and is allocated to computational device execution of the application components and is allocated to computational device .

At time t 2 IDA may change back to co simulation dynamic allocator without re generating re compiling or re running code for the one or more application components. IDA may implement a third mapping of co simulation dynamic allocator where execution of the application components and is allocated to computational device execution of the application component is allocated to computational device execution of the application components and is allocated to computational device and execution of the application component is allocated to computational device .

Changes to an execution mapping of application components to computational devices at run time or execution time such as changing from co simulation dynamic allocator to co simulation dynamic allocator is a technique that can be referred to as changing co simulation dynamic allocators during co simulation i.e. run time or execution time without re generating re compiling or re running code for the one or more application components. In certain embodiments a desired co simulation dynamic allocator may be chosen during co simulation. Based on the selected co simulation dynamic allocator a desired co simulation dynamic allocator that will implement a dynamic mapping of application components to computational devices at compile time of the application may be automatically generated. This generated co simulation dynamic allocator may be reused for subsequent executions of the application on the HTE.

A co simulation dynamic allocator can re allocate execution of application components to computational devices during co simulation i.e. at run time or at execution time from the co simulation environment. The changing of one execution mapping of application components to another execution mapping of application components is performed by the co simulation dynamic allocator. A co simulation dynamic allocator can change the execution mappings of application components to computational devices without re generating re compiling or re running code for the one or more application components.

A co simulation dynamic allocator may operate in a manner similar to that of an ISA. By way of example the co simulation dynamic allocator of may operate in a manner similar to that of ISA of . According to various embodiments an interactive static allocator may help to generate an optimal CSA. For example interactive static allocator of may be used to generate an optimal CSA such as the CSA or .

In some embodiments a co simulation dynamic allocator may help to generate a CDA. For example the co simulation dynamic allocator or of may be used to generate a CDA such as the CDA or . In some embodiments a co simulation dynamic allocator may be used to construct an IDA which may be used to generate an optimal CDA. For example the co simulation dynamic allocator and or of may be used to construct an IDA such as the IDA illustrated in . IDA may be used to generate an optimal CDA such as the CDA or .

The interactive static and dynamic allocators discussed above may allow a user to interactively reallocate execution of application components to different computational devices of the HTE the one or more application components are executing i.e. without stopping execution of the one or more application components . The re allocation may not alter the design of the one or more application components and may not involve re generating re compiling or re running code for the one or more application components. Accordingly re allocation may provide improved efficiency and or time savings as compared to conventional approaches that require re generating re compiling and re running of code for the components when determining a suitable conventional static and or dynamic allocator. For example conventional allocation schemes assess a single candidate conventional allocator. If a different allocation scheme is desired conventional schemes require stopping an HTE re generating re compiling and re running code for the application using the different allocation scheme.

According to various embodiments a desired co simulation static or dynamic allocator may be identified during co simulation using interactive allocation. The desired conventional static or dynamic allocator that corresponds to the identified co simulation static or dynamic allocator may then be generated for standalone deployment of the application on the HTE. Contrary to conventional allocation schemes embodiments allow for interactively altering co simulation static or dynamic allocators to generate the desired conventional static or dynamic allocator without re generating re compiling or re running code for the application.

Embodiments allow profiling results i.e. run time statistics or execution time statistics of various static and dynamic allocation schemes to be considered and used. For example relevant run time or execution time statistics such as computational load observed latency memory usage power consumption etc. may be streamed back to the co simulation design environment from an HTE in real time i.e. while the code for the application components is executing on the HTE .

A portion of the run time or execution time statistics may be provided to a user in various graphical and or textual formats if desired. Based on the profiling results the user may change the co simulation static or dynamic allocation scheme to improve execution efficiency of the code. For example improved execution speed may include but is not limited to increasing execution speed minimizing memory usage minimizing power consumption improving load distribution across computational devices minimizing power consumption minimizing communication among the computational devices minimizing latency at various computing devices etc. For example a user may change an allocation scheme to achieve faster execution speeds for an application and or to better meet application design constraints.

Exemplary embodiments may allow for run time or execution time allocation experiments to be conducted in the co simulation design environment. Experiments may be used to determine and subsequently generate allocators that satisfy a design requirement for an application. A generated allocator may identify an allocation scheme for executing the application being designed in the co simulation design environment on the HTE. The generated allocator may be reused in subsequent executions of the application on the HTE.

Optionally electronic device may include multiple CPUs for executing software loaded in memory and other programs. Each of the CPUs can be a single processing device or may include multiple processing devices on a single board or substrate. The code loaded in memory may run in a virtualized environment such as in a Virtual Machine VM . Multiple VMs may be resident on a single processing device. Also part of the code may be run in hardware for example by configuring a field programmable gate array FPGA using an application specific instruction set processor ASIP using an application specific integrated circuit ASIC etc.

Storage can include code for the operating system OS of the electronic device code for one or more applications executed by the OS. For example storage can include applications for the co simulation design environment . Storage may also hold data generated from the co simulation design environment . Those of ordinary skill in the art will appreciate that parts of applications can be stored in the CPU e.g. CPU cache and or CPU memory as well stored on a network based storage device etc.

Input device may include a keyboard mouse microphone camera multipoint touchpad accelerometer based device gyroscope based device etc. Electronic device may receive through input device input data such as the input data for developing a model performing a co simulation etc. Electronic device may display information on output device .

As discussed above electronic device may host co simulation design environment . For example electronic device may host a BDE or TPE. The co simulation design environment may be used to create and test application . Application may include one or more of a block diagram a state based diagram a textual program a technical computing program etc.

For example co simulation design environment may be used to develop a block diagram application or a textual application having executable semantics. Application may have one or more application components such as application components and . Furthermore co simulation design environment may include code generator . Code generator may be used to generate code that executes on a HTE . For example code generator may generate code for application components and where the generated code is capable of executing on HTE . Code generator may be implemented in hardware or a combination of hardware and software.

An allocator for application may be developed in co simulation design environment . Allocator may be an ISA or an IDA. Allocator may implement a mapping that allocates application components and to individual computational devices on HTE . For example HTE may include computational devices such as but not limited to a GPP a DSP a GPU and a FPGA . It will be appreciated that the number of computational devices depicted in HTE is exemplary and the actual number and types of computational devices in HTEs utilized by embodiments may differ from the number and or types of devices illustrated in .

Based on the mapping code for application components and may be allocated to and executed on the designated computational devices and during a co simulation of application . For example application component may be allocated to execute on GPP . Application component may be allocated to execute on DSP . Application component may be allocated to execute on GPU . The mapping may maintain data synchronization within application and across application components and . That is if application includes multiple copies of a dataset application may be allocated to execute such that the multiple copies are kept in synchronization with one and other and therefore data integrity is maintained. Component synchronization primitives may be implemented to maintain data synchronization.

HTE may include one or more I O interfaces that may be used when computational devices and communicate with each other. According to various embodiments a user may assign an I O interface to each application component and . Thus when application components and execute on allocated computational devices and the communication between computational devices and is established using I O interfaces according to determinations made by the user. In some embodiments the user may assign I O interfaces to application components and while application components and are executing on allocated computational devices and . Other embodiments may allow a single I O interface to be assigned to multiple computational devices operating on HTE .

It will be appreciated that application can contain at least one application component that is simulated in co simulation design environment while other application components from application are executed on HTE .

During a co simulation of application HTE may generate profiling results corresponding to the execution of application on HTE . HTE may provide the profiling results to co simulation design environment in real time during run time or execution time. Profiling results may include performance statistics associated with the computational devices of HTE . For example profiling results may include but are not limited to metrics and or run time or execution time statistics associated with the execution of application on HTE . Exemplary profiling results may include processor load a metric associated with the execution utilization of a computational device memory usage power consumption stack usage cache utilization e.g. hit miss statistics latency information etc. Profiling results may also include metrics relating to a buffer allocation algorithm data synchronization inter algorithm wait times resource utilization by applications execution priorities of applications power consumption information a gate count a transaction count a processing element count etc. Different computational devices may have different metrics. For example metrics associated with computational device may differ from metrics associated with computational device .

A user of co simulation design environment may output profiling results via user interface . According to various embodiments user interface may include a graphical user interface GUI or an application programming interface API . In an embodiment user interface may be provided via output device in communication with electronic device . Based on the review the allocation scheme of allocator may be varied during the execution of application . In an embodiment input device may be used to interact with user interface . The allocation scheme may be interactively varied without halting execution of application .

According to various embodiments application components may be formed by grouping e.g. factoring together various components of application . depict an exemplary technique for factoring an application into application components within a BDE.

Output signal is fed into if block . If output signal satisfies the condition specified in the if block output signal is added with output signal at adder block . The output of adder block is fed into block which may contain a Boolean expression such as AND . Output signal is also fed into block . The output of block may be generated as the final output of the block diagram model illustrated in . Block diagram model may be an executable block diagram model that represents a dynamic system that can be simulated on target hardware. Additionally block diagram may be factored according to a received instruction. The factorization of block diagram is illustrated in .

As illustrated in blocks and may be grouped together to form a first factored region . Region includes blocks and and may represent a group. Blocks and of block diagram remain outside region and thus are not part of the group. Grouping of the elements illustrated in is for illustrative purposes and should not be construed as limiting. In an embodiment region can be demarcated using e.g. a dashed border.

In the group within region is designated as application component in block diagram . Use of application component to represent blocks and does not alter the design or operation of block diagram . As illustrated in three outputs and leave the demarcated boundary of application component . These three outputs are maintained as output signals of application component in . further illustrates an additional grouping of blocks and using second factored region and denoted by the dashed border in the lower portion of . Similarly block is included in third factored region and denoted by the dashed border in the upper right portion of .

According to various embodiments factoring may break components of an application into groups according to criteria. illustrates a block diagram that has been factored. Blocks and are designated as application component . Block is designated as application component .

According to various embodiments a factored application may be re factored during co simulation. For example application component may be divided into two separate components. Blocks may be grouped to form a first component C and blocks and may be grouped to form a second component C. Accordingly a re factored version of block diagram may include application components C C and .

According to various embodiments profiling results may be generated during execution of application and provided to co simulation design environment from HTE in real time i.e. while application is executing. Relevant profiling results may be displayed in connection with associated application components . illustrates profiling results associated with the execution of application components on computational devices respectively. The profiling results are displayed in corresponding computational devices . As illustrated different computational devices may have different metrics. For example the metric for DSP is code coverage and the displayed profiling result indicates that the code coverage was 77 in connection with the execution of application component . The metric for HDL simulator is critical path length and the displayed profiling result indicates that the critical path length was 9502 nanoseconds nS in connection with the execution of application component . The metric for FPGA is power consumption and the displayed profiling result indicates that the power consumption was 32 milli watts mW in connection with the execution of application component . Profiling results are discussed below in greater detail.

During co simulation exemplary allocation scheme can be modified by reallocating application components to different computational devices for execution. For example an input may be received via input device and allocation scheme may be changed based on the received input.

For example selecting a computational device on graphical affordance of user interface may transfer execution of application component from HDL simulator to DSP when application component is next invoked i.e. the next time application component runs . It should be noted that co simulation may not need to be stopped during the computational device selection and execution transfer processes. That is the execution of application component is transferred from HDL simulator to another computational device without re generating re compiling or re running code for application component or application components and .

Two or more of the computational devices in the HTE may be connected by an input output I O interface that allows for the transfer of data between the connected devices. User interface may further be used to select an appropriate I O interface for a connection between two computational devices or a connection between an input device and a computational device or a connection between a computational device and an output device. For example the I O interface that connects DSP and FPGA may be selected for a computational device via graphical affordance as illustrated in . Graphical affordance may include for example a button a dropdown menu a list etc. For example VLYNQ may be selected as the I O interface using graphical affordance . Accordingly DSP may communicate with FPGA and or with other computational devices at target environment via I O interface VLYNQ.

As illustrated in profiling results for DSP indicate that the code coverage is 87 and the power consumption associated with FPGA is 50 mW. While modified allocation scheme alters which application components are executed on which computational devices modified allocation scheme does not stop execution of application components . Modifying mapping of application components from allocation scheme to allocation scheme does not require stopping application execution nor does it require re generating re compiling and or re running code for application components .

As provided above an interactive static allocator or a co simulation dynamic allocator may be used to modify the allocation scheme allocating the execution of code associated with application components to computational devices on the HTE. That is an interactive static allocator or a co simulation dynamic allocator may be used to re allocate the execution of code associated with application components to different computational devices on the HTE during co simulation.

Modifying an allocation scheme as illustrated in provides improvements such as but not limited to improved load balancing on the HTE faster execution of the application improved processing efficiency and optimal memory usage. In an embodiment a best or optimum allocation of application components to computational devices may be determined using real time information such as statistics about the computational devices processing the application components to better determine which modifications may improve processing efficiency among the computational devices. For example profiling results such as relevant run time or execution time statistics such as computational load and memory usage may be streamed back to the co simulation design environment from the HTE in real time i.e. while the code for the application components is being executed on the HTE. Accordingly it may be beneficial to provide relevant run time or execution time statistics to the co simulation design environment.

According to various embodiments the HTE may send continuous run time or execution time statistics updates to the co simulation design environment. As further illustrated in profiling results may be generated during execution of application and provided to co simulation design environment from HTE in real time i.e. while application is executing. Profiling results may be sent to co simulation design environment . Profiling results may include performance statistics associated with computational devices of HTE .

For example profiling results may include but are not limited to metrics and or run time or execution time statistics associated with the execution of application on HTE . Exemplary profiling results may include processor load a metric associated with the execution utilization of a computational device memory usage power consumption stack usage cache utilization e.g. hit miss statistics etc. Profiling results may also include metrics relating to a buffer allocation algorithm data synchronization an inter algorithm wait time resource utilization by other applications and the execution priorities of those applications.

A portion of the profiling results may be provided in various graphical and or textual formats if desired. For example profiling results may be provided on output device . Based on the profiling results changes may be made to the interactive static or dynamic allocation scheme to improve execution efficiency of the code. The execution efficiency of the code may include but is not limited to increasing execution speed minimizing memory usage minimizing power consumption improving load distribution across computational devices minimizing power consumption minimizing communication among the computational devices etc. For example the user may change the allocation scheme of application components to computational devices using user interface via input device for faster execution or to better meet application design constraints.

According to various embodiments relevant run time or execution time statistics may be provided in the co simulation design environment and back annotated to corresponding application components. For example run time or execution time statistics associated with each application component may be displayed in the co simulation design environment along with the corresponding application component.

In the exemplary embodiment illustrated in all application components may be assigned to each of computational devices . The allocation scheme may enable or disable the execution of the application components on computational devices .

For example application component is allocated to execute on computational device . Therefore application component is linked to corresponding I O interface to enable execution of application component on computational device . Computational device may communicate with one or more of other computational devices via I O interface while executing application component . If any other application component is allocated for execution on computational device I O interfaces may be linked to the other application components as well. In some embodiments more than one application component may be linked to a same I O interface.

In processing may begin by executing application components of an application provided in a co simulation design environment on computational devices of a HTE according to a first mapping block . The application may be co simulated by executing some application components in the co simulation design environment and executing other application components on the HTE using the assigned computational device s . For example in one embodiment default settings may initially allocate all application components to one computational device of the HTE. Allocating all application components to execute on a single computational device may predict the processing time computational load of each application component. However such allocation may not predict the potential I O wait times if dependent data were to come from a different computational device i.e. wait times caused by inter algorithm communications and synchronization . As a result in other embodiments the application components may be allocated to multiple computational devices rather than all of the components being assigned to execute on the same computational device.

A request for changing the mapping to a second mapping may be received at the co simulation design environment block . Processing allows for interactively changing the allocation scheme by reallocating one or more application components to available computational devices during co simulation block . Re allocation of execution of the application components to available computational devices according to a second mapping i.e. a modified allocation scheme. The interactive changing of allocation scheme occurs without a user or program first having to re generate re write re compile re link re download and or re run the application code.

Processing may proceed by executing the reallocated application components on the computational devices of the HTE according to the second mapping block . Embodiments may allow for implementing application components deployed as algorithms of execution in a multi algorithm process.

Co simulation results may be generated based on the second mapping of the application components to computational devices of the HTE block .

The processing described above in reference to illustrates an exemplary sequence in which the mapping between application components and computational devices is modified during co simulation without first having to re generate re write re compile re link re download and or re run the application code.

Processing may start with generating code for application components block . The application components may be part of an application such as a model in either a BDE or TPE. As provided above an application component can be defined in a BDE by block by subsystem by rate by model by demarcated boundary etc. Similarly application components in a TPE may be defined by function by object method by pragma instrumentation by model by demarcated boundary etc.

Processing may allocate execution of code for the application components to one or more computational devices of the HTE block . For example in one embodiment default settings may initially allocate all application components to one computational device. Allocating all application components to execute on a single computational device may predict the processing time computational load of each application component. However such allocation may not predict the potential I O wait times if dependent data were to come from a different computational device i.e. wait times caused by inter algorithm communications and synchronization . Also the profiling results of the single computational device execution may not account for cache effects associated with multi computational device parallel execution. That is run time or execution time statistics such as computational load may not be an exact predictor for computational load when the application components are distributed across multiple computational devices executing in parallel. To remedy these potential consequences the application components may be allocated to multiple computational devices rather than all of the components being assigned to execute on the same computational device.

The I O interfaces may be determined to enable communication between the computational devices of the HTE block . In some embodiments the user may determine the I O interfaces. Once allocated the application may be co simulated by executing some application components in the co simulation design environment and executing other application components for which code has been generated on the HTE using the assigned computational device s block . During co simulation the computational devices may communicate with each other using the assigned I O interfaces.

Optionally in some embodiments profiling may be performed on various components running on the HTE computational devices during co simulation. Run time or execution time statistics for the application components can be captured and stored or displayed block . The run time or execution time statistics may be displayed in the co simulation design environment in various graphical and textual formats during co simulation. For example run time or execution time statistics may be displayed by back annotating to the corresponding application components in the co simulation design environment. For example a textual display of run time or execution time statistics may include computational load memory usage power consumption cache utilization cache hit miss statistics system throughput input wait times buffer use re use algorithm dependencies graph timelines etc. One of ordinary skill in the art will appreciate that performing profiling is an optional feature of the present application and may be omitted in various embodiments.

The processes sing may determine whether the modified allocation scheme meets requirements for example based on comparing the run time or execution time statistics to pre determined criteria block . If the run time or execution time statistics indicate that the modified allocation scheme meets design requirements yes for block a conventional static or dynamic allocator implementing the modified allocation scheme may be generated for the application block .

If the allocation scheme does not meet requirements no for block the allocation scheme may be interactively modified by reallocating one or more application components to available computational devices during co simulation block . Re allocation of the application components to available computational devices results in a modified mapping i.e. modified allocation scheme. The interactive changing of allocation scheme occurs without a user or program first having to re generate re write re compile re link re download and or re run the application code. Embodiments allow implementing application components deployed as algorithms of execution in a multi algorithm process to allow for changing the allocation scheme.

With the modified allocation scheme the I O interfaces may be re determined. The code for the application components may be executed on the HTE computational devices according to the modified allocation scheme. Run time or execution time statistics may also be updated for the new modified allocation scheme. In some embodiments the run time or execution time statistics may be sent back to the co simulation design environment and back annotated to the corresponding application components. If the updated run time or execution time statistics indicate that the modified allocation scheme meets design requirements a conventional static or dynamic allocator implementing the modified allocation scheme is generated for the application. If the allocation scheme does not meet requirements the allocation scheme may be interactively modified once again. According to various embodiments the processing may end without generating a conventional static or dynamic allocator.

The processing described above in reference to illustrates an exemplary sequence in which an allocator that satisfies a design requirement may be produced. Processing depicted in may stop once a conventional static or dynamic allocator satisfying the design requirements is found. In another exemplary embodiment the processing of may be adjusted so as to attempt to generate an optimal conventional static or dynamic allocator. The processing can include determining whether the current conventional static or dynamic allocator is the best so far in the co simulation. The determination may be made based on pre determined criteria. For example design requirements for the application may be automatically compared to the profiling results of the modified allocation scheme to see if the profiling result passes a pre determined threshold. One or more modified allocation schemes may be compared and a best scheme may be determined e.g. as the best so far allocation scheme. The resulting allocator may be the best so far conventional static or dynamic allocator implementing the best so far allocation scheme.

The potential re factoring of the application design by assembling new application component combinations provides greater flexibility in identifying an optimal conventional static or dynamic allocator that meets application design requirements than does the changing of mappings alone. Thus using the exemplary techniques described above a generated conventional static or dynamic allocator that meets design requirements can continually be refined and improved to identify an optimal conventional static or dynamic allocator for an application under development in the co simulation design environment.

If the co simulation techniques described above are unable to identify a satisfactory conventional static or dynamic allocator a user may need to change some of the variables affecting the co simulation of the application design. For example a different HTE platform with different characteristics may be chosen complexity of the application design may be reduced allocation requirements may be altered or other changes may be made. The above described techniques may be performed again to attempt to identify a satisfactory conventional static or dynamic allocator.

In processing may begin by generating code for the application components block . Processing may allocate execution of code for all application components to one or more computational devices of the HTE block . The I O interfaces may be determined for use during communication between the computational devices of the HTE block . Once allocated the application may be co simulated by executing some application components in the co simulation design environment and executing other application components for which code has been generated on the HTE using the assigned computational device s block . During co simulation the computational devices may communicate with each other using the assigned I O interfaces.

In some embodiments profiling may be performed on different components running on the HTE computational devices during co simulation. Run time or execution time statistics for the application components can be captured and stored or displayed block . The run time or execution time statistics may be displayed in the co simulation design environment in various graphical and textual formats during co simulation. For example run time or execution time statistics may be displayed by back annotation to the corresponding application components in the co simulation design environment. For example a textual display of run time or execution time statistics may include computational load memory usage power consumption cache utilization cache hit miss statistics system throughput input wait times buffer use re use algorithm dependencies graph timelines etc.

The processing may determine whether the modified allocation scheme meets pre determined design requirements based on comparing the run time or execution time statistics to pre determined criteria block . If the run time or execution time statistics indicate that the modified allocation scheme meets design requirements yes for block a conventional static or dynamic allocator implementing the modified allocation scheme is generated for the application block . The process ends with generating the conventional static or dynamic allocator.

If the allocation scheme does not meet requirements no for block processing allows for interactively changing the allocation scheme by enabling and or disabling execution of one or more application components on one or more of the computational devices during co simulation block . For example execution of some application components may be disabled on a given computing device while execution of some other application components may be enabled on the given computing device. Enabling disabling of the application components on given computational devices results in a modified mapping i.e. modified allocation scheme. The interactive changing of allocation scheme occurs without a user or program first having to re generate re write re compile re link re download and or re run the application code.

With the modified allocation scheme the I O interfaces may be re determined. The code for the application components may be executed on the HTE computational devices according to the modified allocation scheme. Run time or execution time statistics may also be updated for the new modified allocation scheme. In some embodiments the run time or execution time statistics may be sent back to the co simulation design environment and back annotated to the corresponding application components. If the updated run time or execution time statistics indicate that the modified allocation scheme meets design requirements a conventional static or dynamic allocator implementing the modified allocation scheme is generated for the application. If the allocation scheme does not meet requirements the allocation scheme may be interactively modified once again. According to various embodiments the processing may end without generating a conventional static or dynamic allocator.

The processing described above in reference to illustrates an exemplary sequence in which an allocator that is good enough to meet a design requirement is produced. Processing depicted in may stop once any conventional static or dynamic allocator that meets design requirements is found.

In other exemplary embodiments the processing of can be adjusted so as to attempt to generate an optimal conventional static or dynamic allocator. The processing can include determining whether the current conventional static or dynamic allocator is the best so far in the co simulation. The determination may be by a user or programmatically determined without user input based on pre determined criteria. For example design requirements for the application may be automatically compared to the profiling results of the modified allocation scheme to see if the profiling result passes a pre determined threshold. One or more modified allocation schemes may be compared and the best scheme may be determined for example as the best so far allocation scheme. The resulting allocator may be the best so far conventional static or dynamic allocator implementing the best so far allocation scheme.

In the network environment computing devices and may provide software components or products under a particular condition such as a license agreement. The software components or products may include those for providing co simulation design environment and or implementations of code for select elements. In one example computing device may perform program development in the co simulation design environment while computing device hosts a target hardware used in the co simulation.

Although the embodiments described above take place within a co simulation design environment other embodiments are also possible within the scope of the present invention. For example in another embodiment the search to identify static and dynamic allocators as described above may take place completely within a simulation environment. In such an embodiment instead of generating code that will be executed on HTE during co simulation the performance of the HTE computational devices may be completely simulated within a simulation design environment. During the simulation attributes of the allocation scheme may be adjusted based on performance data for the virtual computational devices. One type of application that can be co simulated may include a block diagram model representing a real world system. It should be noted that the term block diagram may also refer to and can include other graphical modeling formalisms. For instance flow charts are block diagrams of entities that are connected by relations. Flow charts may be used to capture process flow and may not generally be suitable for describing dynamic system behavior. Data flow block diagrams are diagrams of entities with relations between them that describe a graphical programming paradigm where the availability of data is used to initiate execution of blocks in the diagram. In data flow diagrams a block may represent an operation and a line may represent execution dependency describing the direction of data flowing between blocks. It will be appreciated that a block diagram model provided in one modeling formalism may include entities from other modeling formalisms.

Embodiments described herein may be provided as one or more computer readable programs embodied on or in one or more physical and non transitory computer readable storage media. The media may be a floppy disk a hard disk a compact disc a digital versatile disc a flash memory card a PROM an MRAM a RAM a ROM a magnetic tape etc. In general the computer readable programs may be implemented in any programming language. Some examples of languages that can be used include MATLAB programming language FORTRAN C C C Python FLASH JavaScript or JAVA . A programming language may be an array based language. An array based language is a language where an array is a basic unit of data storage. An array may have zero or more dimensions. An example of an array based language may be a language at least a subset of which is executable in the MATLAB programming environment. The software programs may be stored on or in one or more mediums as object code. Hardware acceleration may be used and all or a portion of the code may run on a FPGA an Application Specific Integrated Processor ASIP or an Application Specific Integrated Circuit ASIC . The code may run in a virtualized environment such as in a virtual machine. Multiple virtual machines running the code may be resident on a single processor.

Since certain changes may be made without departing from the scope of the present invention it is intended that all matter contained in the above description or shown in the accompanying drawings be interpreted as illustrative and not in a literal sense. Practitioners of the art will realize that the sequence of steps and architectures depicted in the figures may be altered without departing from the scope of the present invention and that the illustrations contained herein are singular examples of a multitude of possible depictions of the present invention.

The foregoing description of example embodiments of the invention provides illustration and description but is not intended to be exhaustive or to limit the invention to the precise form disclosed. Modifications and variations are possible in light of the above teachings or may be acquired from practice of the invention. For example while a series of acts has been described herein the order of the acts may be modified in other implementations consistent with the principles of the invention. Further non dependent acts may be performed in parallel.

In addition implementations consistent with principles of the invention can be implemented using devices and configurations other than those illustrated in the figures and described in the specification without departing from the spirit of the invention. Devices and or components may be added and or removed from the implementations described herein depending on specific deployments and or applications. Further disclosed implementations may not be limited to any specific combination of hardware.

Further certain portions of the invention may be implemented as logic that performs one or more functions. This logic may include hardware such as hardwired logic an application specific integrated circuit a field programmable gate array a microprocessor software wetware or a combination of hardware and software.

No element act or instruction used in the description of the invention should be construed as critical or essential to the invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items. Where only one item is intended the term one or similar language is used. Further the phrase based on as used herein is intended to mean based at least in part on unless explicitly stated otherwise.

