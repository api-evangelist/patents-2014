---

title: Method for improving an MCU's performance using common properties of the H.264 codec standard
abstract: This disclosure describes an apparatus () for improving performance of a multipoint control unit (). The apparatus () provides a video stream manipulator () and a multipoint control unit (). The video stream manipulator () may encode one or more video streams in a predetermined video codec standard separately. Each of the encoded video streams includes at least one encoded video frame made of a plurality of macroblocks, where the macroblocks are segregated into a predetermined number of macroblock lines. The multipoint control unit () may assemble predetermined number of macroblock lines from each of the encoded video streams in a predetermined composition.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09432624&OS=09432624&RS=09432624
owner: ClearOne Communications Hong Kong Ltd.
number: 09432624
owner_city: Hong Kong
owner_country: HK
publication_date: 20141229
---
This application claims priority and the benefits of the earlier filed Provisional U.S. Application No. 61 923 248 filed 3 Jan. 2014 which is incorporated by reference for all purposes into this specification.

Additionally this application claims priority and the benefits of the earlier filed Provisional U.S. Application No. 61 935 545 filed 4 Feb. 2014 which is incorporated by reference for all purposes into this specification.

This disclosure relates to video data processing techniques. More specifically the disclosure relates to an apparatus for improving performance of a multipoint control unit MCU and related methods.

Various applications such as video surveillance and news broadcast require multiple video streams to be displayed simultaneously on a single terminal device. Such video streams may be encoded in a diversity of video encoding standards and are often processed by a central unit such as multipoint control unit MCU before being transmitted to an intended terminal device such as a display screen mobile phone or a television. For example in a video conference session involving communication between two or more participants the MCU processes encoded video streams from the participants and returns a dedicated re encoded video stream in a predefined video codec standard such as H.264 also known as Moving Pictures Experts Group 4 MPEG 4 Part 10 or MPEG 4 Advanced Video Coding AVC to each participant.

In the H.264 AVC standard a video includes a series of pictures or frames with each frame consisting of a two dimensional array of pixels. The pixels are divided into macroblocks a 16 16 array of pixels . Each macroblock has a macroblock number in general the macroblocks are numbered starting at the top left of the frame in increasing order from left to right and top to bottom. The macroblocks can be grouped into slices and the slices can be grouped into slice groups. Macroblocks within a slice are arranged in ascending order by macroblock number. A slice can include any number of macroblocks which may or may not be contiguous that is macroblocks in one slice may be interspersed among macroblocks of one or more other slices of other slice groups however macroblocks from slices in the same slice group are not interspersed with each other. H.264 has a feature referred to as flexible macroblock ordering FMO that allows macroblocks to be grouped into slices.

FMO is one of the error resiliency tools that can be used by a decoder to conceal errors if slices are lost or corrupted during transmission. Macroblocks in a missing or corrupted slice can be reconstructed by interpolating or extrapolating macroblock information from another slice. More specifically a correctly received slice can be decoded and the information in that slice can be used to derive information for another slice.

Another H.264 feature is generally referred to as arbitrary slice ordering ASO . With ASO slices can be transmitted in any order. For example a slice may be sent as soon as it is ready that is a slice may be streamed to a decoder as soon as all of the macroblocks which make up that slice are encoded. As a result a slice from one slice group may be sent followed by a slice from another slice group followed by another slice from the first slice group and so on. Yet another feature of the H.264 AVC standard allows the MCU to implement the FMO and the ASO in combination with each other to generate an encoded video stream.

Typically the MCU encodes video streams from multiple participants either separately or as a combined encoded single video stream. Although the single video stream saves on the MCU computing cost user experiences a lag in his own video at the terminal device. Therefore the MCU usually encodes video streams from each participant separately to optimize the user experience which increases the MCU processing or computing cost. Therefore there exists a need for a solution that improves the MCU performance to optimally handle multiple video streams encoded in different video codec standards.

One embodiment of the present disclosure includes an apparatus for improving performance of a multipoint control unit. The apparatus comprises a video stream manipulator and a multipoint control unit. The video stream manipulator may be configured to encode one or more video streams in a predetermined video codec standard separately. Each of said encoded one or more video streams includes an encoded video frame made of a plurality of macroblocks. Each of said plurality of macroblocks may be segregated into a predetermined number of macroblock lines. The multipoint control unit may be configured to assemble said predetermined number of macroblock lines from each of said encoded one or more video streams in a predetermined composition.

Another embodiment of the present disclosure includes a method to use an apparatus for improving performance of a multipoint control unit. The method comprises encoding one or more video streams in a predetermined video codec standard separately with a video stream manipulator wherein each of said encoded one or more video streams comprises an encoded video frame made of a plurality of macroblocks each of said plurality of macroblocks being segregated into a predetermined number of macroblock lines and assembling said predetermined number of macroblock lines from each of said encoded one or more video streams in a predetermined composition with said multipoint control unit.

Yet another embodiment of the present disclosure includes a method to manufacture an apparatus for improving performance of a multipoint control unit. The method comprises providing a video stream manipulator configured to encode one or more video streams in a predetermined video codec standard separately wherein each of said encoded one or more video streams comprises an encoded video frame made of a plurality of macroblocks each of said plurality of macroblocks being segregated into a predetermined number of macroblock lines and providing said multipoint control unit configured to assemble said predetermined number of macroblock lines from each of said encoded one or more video streams in a predetermined composition.

Still another embodiment of the present disclosure includes a non transitory program storage device readable by a computing device that tangibly embodies a program of instructions executable by said computing device to perform a method for improving performance of a multipoint control unit. The method comprises encoding one or more video streams in a predetermined video codec standard separately with a video stream manipulator wherein each of said encoded one or more video streams comprises an encoded video frame made of a plurality of macroblocks each of said plurality of macroblocks being segregated into a predetermined number of macroblock lines and assembling said predetermined number of macroblock lines from each of said encoded one or more video streams in a predetermined composition with said multipoint control unit.

Other and further aspects and features of the disclosure will be evident from reading the following detailed description of the embodiments which are intended to illustrate not limit the present disclosure.

This disclosure describes an apparatus for improving an MCU s performance using inherent feature s of a video codec standard. This disclosure describes numerous specific details in order to provide a thorough understanding of the present invention. One ordinarily skilled in the art will appreciate that one may practice the present invention without these specific details. Additionally this disclosure does not describe some well known items in detail in order not to obscure the present invention.

In various embodiments of the present disclosure definitions of one or more terms that will be used in the document are provided below.

An endpoint is used in the present disclosure in the context of its broadest definition. The endpoint refers to one or more computing devices capable of establishing a communication channel for exchange of at least video streams in a communication session. Examples of the computing devices may comprise but are not limited to a desktop PC a personal digital assistant PDA a server a mainframe computer a mobile computing device e.g. mobile phones laptops tablets etc. an internet appliance calling devices e.g. an internet phone video telephone etc. .

An aspect ratio is used in the present disclosure in the context of its broadest definition. The Aspect ratio may be defined as a ratio of width to length of a display screen operatively connected to the endpoint.

The numerous references in the disclosure to the video management device are intended to cover any and or all devices capable of performing respective operations on the endpoints in a conferencing environment relevant to the applicable context regardless of whether or not the same are specifically provided.

Embodiments are disclosed in the context of environments that represent a multipoint video conference among multiple users via respective endpoints capable of receiving decoding or rendering video streams. Other embodiments may be applied in the context of other scenarios e.g. broadcast video news broadcasts video surveillance digital signage etc. involving mixing of different video streams from one or more endpoints to render a composite video stream of different compositions. Such embodiments include a video management device configured to improve performance of a multipoint control unit MCU using inherent features of video codec standards that support non standard slice shapes or sequences of macroblocks in a picture or video frame of a video stream. The video management device includes an MCU configured for processing video data using a predetermined video codec standard in combination with a video stream manipulator that uses encoded realm composition rather than raw bitmap realm composition for generating an output frame thus saving a considerable amount of computing power on re encoding the same video frame in multiple layouts for multiple users. The video management device encodes video frames which may be pre scaled from all sources separately and slices the encoded macroblocks in the pre scaled frames at bit level into macroblock lines. The macroblock lines may be assembled into final scan lines of various desired output compositions through bit shifting to adjust for a macroblock line that begins at a bit which is not at a byte boundary.

The network may comprise for example one or more of the Internet Wide Area Networks WANs Local Area Networks LANs analog or digital wired and wireless telephone networks e.g. a PSTN Integrated Services Digital Network ISDN a cellular network and Digital Subscriber Line xDSL radio television cable satellite and or any other delivery or tunneling mechanism for carrying data. The network may comprise multiple networks or sub networks each of which may comprise for example a wired or wireless data pathway. The network may comprise a circuit switched voice network a packet switched data network or any other network that is able to carry electronic communications. For example the network may comprise networks based on the Internet protocol IP or asynchronous transfer mode ATM and may support voice using for example VoIP Voice over ATM or other comparable protocols used for voice data communications. In some embodiments the network may comprise a cellular telephone network configured to enable exchange of at least video data independently or in combination with textual data and audio data between at least two of the terminals .

The terminals may comprise or be coupled with one or more hardware devices either wirelessly or in a wired fashion for enabling a user to dynamically interact with other users via the network . For example the terminals may be coupled with an imaging device not shown including but are not limited to a video camera a webcam a scanner or any combination thereof and an audio device not shown including but are not limited to a speaker a microphone or any combination thereof. The terminals may be compatible with any other device not shown connected to the network to exchange at least audio video textual or symbolic data streams with each other or any other compatible devices.

In one embodiment an endpoint such as the terminal may be coupled to integrated or in communication with a video management device configured to at least one of 1 establish a communication bridge or channel between the terminals 2 receive decode manipulate or encode multiple video streams 3 scale or resize a frame of the video streams received from each of the terminals for the resized frame being compatible with a supported resolution of a target terminal such as a terminal 4 compress the encoded resized video frame into a predetermined sequences of macroblocks also referred to as macroblock lines or slices e.g. relative to the aspect ratio of a display screen of the target terminal 5 store and manage video data corresponding to the received video streams and 6 request services from or deliver services to or both various devices connected to the network . Other embodiments may include the video management device being coupled to integrated or in communication with one or more of the other terminals .

The video management device may represent any of a wide variety of devices capable of providing video processing optimization services to the network devices. The video management device may be implemented as a standalone and dedicated device including hardware and installed software where the hardware is closely matched to the requirements and or functionality of the software. Alternatively the video management device may be implemented as a software application or a device driver on existing hardware devices such as a multipoint control unit. The video management device may enhance or increase the functionality and or capacity of the network such as the network to which it is connected. In some embodiments the video management device may be configured for example to perform e mail tasks security tasks network management tasks including IP address management and other tasks. In some other embodiments the video management device may be configured to expose its computing environment or operating code to a user and may include related art I O devices such as a keyboard or display. The video management device of some embodiments may however include software firmware or other resources that support remote administration and or maintenance of the video management device .

In further embodiments the video management device either in communication with any of the networked devices such as the terminals or independently may have video voice and data communication capabilities e.g. unified communication capabilities by being coupled to or including various imaging devices e.g. cameras printers scanners medical imaging systems etc. various audio devices e.g. microphones music players recorders audio input devices speakers audio output devices telephones speaker telephones etc. various video devices e.g. monitors projectors displays televisions video output devices video input devices camcorders etc. or any other type of hardware in any combination thereof. In some embodiments the video management device may comprise or implement one or more real time protocols e.g. session initiation protocol SIP H.261 H.263 H.264 H.323 etc. and non real time protocols known in the art related art or developed later to facilitate communication of video streams between the terminals the video management device or any other network device.

In some embodiments the video management device may be configured to convert communications which may include instructions queries data etc. from the terminals into appropriate formats to make these communications compatible with the terminals and vice versa. Consequently the video management device may allow implementation of the terminals using different technologies or by different organizations e.g. a third party vendor managing the terminals or associated services using a proprietary technology.

In yet another embodiment the terminals may be configured to interact with each other via a server not shown over the network . The server may be installed integrated or operatively associated with the video management device . The server may be implemented as any of a variety of computing devices including for example a general purpose computing device multiple networked servers arranged in clusters or as a server farm a mainframe or so forth.

In some embodiments the video management device may include in whole or in part a software application working alone or in conjunction with one or more hardware resources. Such software applications may be executed by the processor s on different hardware platforms or emulated in a virtual environment. Aspects of the video management device may leverage known related art or later developed off the shelf software. Other embodiments may comprise the video management device being integrated or in communication with a mobile switching center network gateway system Internet access node application server IMS core service node or some other communication systems including any combination thereof. In some embodiments the video management device may be integrated with or implemented as a wearable device including but not limited to a fashion accessory e.g. a wrist band a ring etc. a utility device a hand held baton a pen an umbrella a watch etc. a body clothing or any combination thereof.

The video management device may include a variety of known related art or later developed interface s including software interfaces e.g. an application programming interface a graphical user interface etc. hardware interfaces e.g. cable connectors a keyboard a card reader a barcode reader a biometric scanner an interactive display screen etc. or both.

The video management device may further include a system memory a video stream manipulator and a multipoint control unit MCU . The system memory may store at least one of 1 video data such as spatial data e.g. picture width picture height luminance and chrominance values of each picture pixel etc. and motion data e.g. frame rate sequence frame number end of stream flag motion vectors pointers to locations of different components in a picture such as pixels macroblocks MBs slices slice groups and so on including other related attributes such as MB mode MB type MB motion type etc. corresponding to each video frame in a video stream and 2 a log of profiles of network devices and associated communications including instructions queries conversations data and related metadata.

The system memory may comprise any computer readable medium known in the art related art or developed later including for example a processor or multiple processors operatively connected together volatile memory e.g. RAM non volatile memory e.g. flash etc. disk drive etc. or any combination thereof. In some embodiments the system memory may include one or more databases which may be sub divided into further databases for storing electronic files. The system memory may have one of many database schemas known in the art related art or developed later for storing video data from the terminals via the video management device . For example a database may have a relational database schema involving a primary key attribute and one or more secondary attributes. In some embodiments the video management device may perform one or more operations but not limited to reading writing indexing encoding decoding manipulating and updating the video data and may communicate with various networked computing devices such as the terminals and the network appliance .

In one embodiment the video stream manipulator may operate in communication with the MCU and exchange data including but not limited to that corresponding to each frame of the video stream and the terminals . The video stream manipulator may be configured to at least one of 1 decode an encoded video stream received from one or more of the terminals 2 resize one or more video frames in the decoded video stream into a predetermined resolution compatible with a target terminal 3 encode resized video frames using a predetermined video codec standard that supports non standard sequencing of macroblocks or slices in the encoded video frames and 4 compress each of the encoded video frames that construct the video stream from an input terminal such as the terminal into a predetermined sequence of macroblocks or slices e.g. relative to the aspect ratio of a display screen of a target terminal such as the terminal .

The MCU may be configured to implement various real time and non real time communication protocols for rendering one or more video streams either separately or as a combined or composite video stream to one or more of the terminals . In some embodiments the MCU may be configured to determine various characteristics of the endpoints such as the terminals for handling the respective received video streams. The characteristics may comprise but are not limited to type of endpoint e.g. a mobile phone a laptop an television a video display etc. supported video resolution s aspect ratio and supported codecs of the terminals network connection speed and so on.

In some embodiments the MCU may be configured to switch between various video streams received from different terminals to either continuously display a received video stream while operating in a continuous presence mode or tile a video stream received from each of the terminals on that terminal from which a respective audio stream is actively received while the MCU is operating in a voice switched mode. In the voice switched mode the MCU may be configured to assemble the compressed predetermined sequence of macroblocks or slices related to each of the terminals by mapping the corresponding byte arrays for generating a composite video stream having different video streams tiled at different locations respective to each terminal receiving the composite video stream.

The input terminal may provide a video stream including multiple video frames such as a frame encoded in any of the known related art or later developed video codec standards such as the MPEG and the H.264 AVC standards. The video stream manipulator may receive and decode the encoded video stream from the input terminal . Each video frame not shown in the decoded video stream may be resized or scaled by the video stream manipulator to a resolution that is supported by a target terminal . In one embodiment the video stream manipulator may be configured to encode each of the scaled video frames constructing the video stream using a predetermined video codec standard that supports non standard or desired sequencing of macroblocks or slice shapes in the scaled video frames. Examples of such standards include but are not limited to H.264 H.265 and Scalable Video Coding SVC standards.

In the above embodiment the video stream manipulator may be further configured to segregate the encoded macroblocks in the encoded video frames such as an encoded video frame at bit level into macroblock lines or slices. All the segregated macroblock lines or slices that collectively construct a particular video frame are compressed into a predetermined sequence of macroblocks or macroblock lines or slices thereby reducing the size of the encoded video frame relative to an aspect ratio of a display screen of the target terminal .

In one example the display screen of the target terminal may have length and width being 60 inches and 30 inches respectively thereby having an aspect ratio of 0.5. The video stream manipulator may compress the encoded resized video frame to one third of the dimensions of the display screen to increase the aspect ratio of the encoded resized video frame relative to the aspect ratio of the display screen . In other words the width of the compressed encoded video frame may be reduced from 30 inches to 10 inches while keeping the length same as that of the display screen to increase the aspect ratio of the compressed frame to six. The compressed frame may include all the macroblock lines or slices such as macroblock lines . . . collectively macroblock lines or slices that construct the originally encoded video frame . The video stream manipulator may be configured to encode only those macroblock lines such as the macroblock lines that are within a compressed frame such as the compressed frame based on a predetermined aspect ratio of the compressed frame relative to the aspect ratio of the display screen .

The compressed frame may include multiple macroblock lines or slices . . . collectively macroblock lines or slices the compressed frame may include multiple macroblock lines or slices . . . collectively macroblock lines or slices the compressed frame may include multiple macroblock lines or slices . . . collectively macroblock lines or slices and the compressed frame may include multiple macroblock lines or slices . . . collectively macroblock lines or slices .

In the video management device the MCU may receive the compressed frames and and assemble them in a predetermined composition based one or more inherent feature of the video codec standard in which the compressed frames and are encoded.

In one example the MCU may implement flexible macroblock ordering FMO technique known in the art to assemble slices from each of the compressed frames and by mapping the corresponding byte arrays into a predetermined composition when the video codec standard in which the compressed frames and are encoded supports FMO. In another example the MCU may assemble the macroblock lines corresponding to each of the compressed frames and into scan lines based on raster scan or interleaved scan to obtain a predetermined composition. Such predetermined composition may be achieved in accordance with at least one of the target terminal such as the terminal and a selected mode continuous presence mode or voice switched mode of the MCU by shifting bits corresponding to each of the macroblock lines or slices to adjust for a macroblock line or slice that begins at a bit within a byte boundary of the compressed video frames and . The assembled slices or macroblock lines are outputted as a composite video stream including a sequence of compressed video frames each having slices or macroblock lines assembled in the predetermined composition. For example if each of the compressed frames are made of 160 160 pixels with each slice or macroblock line having ten macroblocks of 16 16 pixels then a composite video frame may be made of 320 320 pixels having a first set of compressed frames comprising of the compressed frames and may be arranged over a second set of compressed frames comprising of the compressed frames and . Other exemplary compositions for the compressed video frame are illustrated in .

Such assembling of the compressed video frames and substantially reduces the computation or processing cost of the MCU and may require the resized video frames such as the frame to be encoded only once if a change in spatial or motion information occurs in another frame of the composite video frame . An example of this use would be a video stream of a news cast taking up the top of the target video streams with the bottom containing a different ticker for different screens containing information specific to this display but not requiring the news cast to be encoded multiple times.

Thus the video management device facilitates to provide output composite video streams based on encoded realm composition rather than raw bitmap realm composition thereby saving a considerable amount of computing power on re encoding the same video frame in multiple layouts for multiple users. Further the video management device avoids scaling of the video stream at a receiving terminal to cause a poor quality display since the composite video stream is already scaled to the exact required resolution supported by the receiving terminal. Additionally the video management device provides either an MCU with an improved computing capacity to support a relatively greater number of video streams or implement a low cost MCU having the computing capacity to support the same number of video streams.

To summarize one embodiment of the present disclosure includes an apparatus for improving performance of a multipoint control unit. The apparatus comprises a video stream manipulator and a multipoint control unit. The video stream manipulator may be configured to encode one or more video streams in a predetermined video codec standard separately. Each of said encoded one or more video streams includes an encoded video frame made of a plurality of macroblocks. Each of said plurality of macroblocks may be segregated into a predetermined number of macroblock lines. The multipoint control unit may be configured to assemble said predetermined number of macroblock lines from each of said encoded one or more video streams in a predetermined composition.

Another embodiment of the present disclosure includes a method to use an apparatus for improving performance of a multipoint control unit. The method comprises encoding one or more video streams in a predetermined video codec standard separately with a video stream manipulator wherein each of said encoded one or more video streams comprises an encoded video frame made of a plurality of macroblocks each of said plurality of macroblocks being segregated into a predetermined number of macroblock lines and assembling said predetermined number of macroblock lines from each of said encoded one or more video streams in a predetermined composition with said multipoint control unit.

Yet another embodiment of the present disclosure includes a method to manufacture an apparatus for improving performance of a multipoint control unit. The method comprises providing a video stream manipulator configured to encode one or more video streams in a predetermined video codec standard separately wherein each of said encoded one or more video streams comprises an encoded video frame made of a plurality of macroblocks each of said plurality of macroblocks being segregated into a predetermined number of macroblock lines and providing said multipoint control unit configured to assemble said predetermined number of macroblock lines from each of said encoded one or more video streams in a predetermined composition.

Still another embodiment of the present disclosure includes a non transitory program storage device readable by a computing device that tangibly embodies a program of instructions executable by said computing device to perform a method for improving performance of a multipoint control unit. The method comprises encoding one or more video streams in a predetermined video codec standard separately with a video stream manipulator wherein each of said encoded one or more video streams comprises an encoded video frame made of a plurality of macroblocks each of said plurality of macroblocks being segregated into a predetermined number of macroblock lines and assembling said predetermined number of macroblock lines from each of said encoded one or more video streams in a predetermined composition with said multipoint control unit.

Other embodiments of the present invention will be apparent to those ordinarily skilled in the art after considering this disclosure or practicing the disclosed invention. The specification and examples above are exemplary only with the true scope of the present invention being determined by the following claims.

