---

title: Isolating tenants executing in multi-tenant software containers
abstract: Technologies are described herein for isolating tenants executing in a multi-tenant software container. Mechanisms for resource isolation allow tenants executing in a multi-tenant software container to be isolated in order to prevent resource starvation by one or more of the tenants. Mechanisms for dependency isolation may be utilized to prevent one tenant executing in a multi-tenant software container from using another tenant in the same container in a manner that requires co-tenancy. Mechanisms for security isolation may be utilized to prevent one tenant in a multi-tenant software container from accessing protected data or functionality of another tenant. Mechanisms for fault isolation may be utilized to prevent tenants in a multi-tenant software container from causing faults or other types of errors that affect other tenants executing in the same software container.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09471353&OS=09471353&RS=09471353
owner: Amazon Technologies, Inc.
number: 09471353
owner_city: Seattle
owner_country: US
publication_date: 20140321
---
Various types of execution environments can be utilized to execute software applications. Execution environments can provide functionality for not only executing applications but also for managing application execution and for providing other types of functionality. For example one type of execution environment is a software container. Software containers typically provide functionality for loading application dependencies interconnecting applications at run time and for managing application lifecycles including integrated application deployment and eviction. Standard configuration mechanisms can typically be utilized to access this functionality.

Executing programs in an execution environment such as a software container may provide benefits over executing applications using traditional application architectures. For example executing applications in a software container might permit applications to be constructed and deployed in a modular fashion by deploying the modules to a software container independently and interconnecting the modules at run time. Executing applications in a software container might also permit multiple applications which may be referred to herein as tenants to execute in the same multi tenant software container thereby sharing common frameworks in memory and potentially reducing resource utilization.

Because multi tenant software containers provide functionality for hosting multiple tenants multi tenant software containers typically also provide mechanisms to isolate different tenants from one another. For simple tenants the basic level of isolation provided by a software container may be sufficient. For software operating in a high performance latency sensitive secure highly available environment however this model may be lacking. For example a tenant executing in a multi tenant software container may consume so many resources that it can starve other tenants executing in the software container or even take down the software container. A tenant executing in a multi tenant software container might also access protected data owned by another tenant or handle failure improperly and take down the entire software container.

The following detailed description is directed to technologies for isolating tenants executing in multi tenant software containers. In particular mechanisms for resource isolation are provided that among other things allow tenants executing in a multi tenant software container to be isolated in order to prevent resource starvation by one or more of the tenants. Mechanisms for dependency isolation are also provided that may be utilized to prevent one tenant executing in a multi tenant software container from using another tenant in the same container in a manner that requires co tenancy. Mechanisms for security isolation are also provided that may be utilized to prevent one tenant in a multi tenant software container from accessing protected data or functionality of another tenant. Mechanisms are also provided for fault isolation that may be utilized to prevent tenants in a multi tenant software container from being affected by the failure of another tenant in the same software container.

As discussed briefly above the mechanisms disclosed herein may be implemented in conjunction with a software container which might also be called a Web container an application container a servlet container or an application server . As also mentioned briefly above a software container can provide functionality for executing applications loading application dependencies interconnecting applications at run time for managing application lifecycles including integrated application deployment and eviction and other types of functionality. A multi tenant software container is a software container configured to execute applications in process on behalf of two or more tenants. It should be appreciated that while the embodiments disclosed herein are primarily presented in the context of a multi tenant software container the embodiments disclosed herein might also be utilized with other types of multi tenant execution environments.

As also described briefly above a tenant executing in a multi tenant software container may consume a disproportionate amount of computing resources such that it starves other tenants executing in the software container for resources or even takes down the software container. In order to address this consideration and potentially others mechanisms are provided herein for resource isolation that among other things allow tenants executing in a multi tenant software container to be isolated in order to prevent resource starvation by one or more of the tenants.

As used herein the term resource includes but is not limited to disk space central processing unit CPU cycles system memory heap and garbage collection occurrences disk input output I O operations and bandwidth network I O operations and bandwidth virtual IP load balancer connections file descriptor count and execution threads. For each of these resource types and potentially others various mechanisms might be utilized to isolate the resource utilization of a tenant and to prevent the tenant from resource starvation of other tenants executing in the same multi tenant software container.

The resource isolation mechanisms disclosed herein might be implemented at various locations within the software stack utilized to execute the tenants. For example and without limitation these mechanisms might be implemented within the tenants themselves within a software container within a classloader within an operating system within a virtual machine and or at other locations within the software stack utilized to execute the tenants. Mechanisms that may be utilized to determine the amount of resources utilized by tenants in the same container include but are not limited to bytecode weaving interception tracing heap dumps and shadow environments. Other techniques might also be utilized to determine the amount of resources utilized by each of the tenants executing in a multi tenant software container.

Various types of actions might also be taken with regard to a tenant utilizing a disproportionate amount of resources. For example and without limitation a resource request might be denied a tenant might be evicted from the software container a tenant might be allocated fewer CPU cycles and or the execution of a tenant might be paused and or throttled. Per tenant resource use limits and or resource utilization thresholds might be utilized to determine when a particular tenant has utilized or is about to utilize an undesirable amount of a resource. Additional details regarding the mechanisms disclosed herein for resource isolation of tenants executing in a multi tenant software container will be provided below with regard to .

Mechanisms are also disclosed herein for dependency isolation that may be utilized to prevent one tenant executing in a multi tenant software container from using another tenant in the same container in a manner that requires co tenancy. In particular a mechanism is disclosed herein for dependency isolation of tenants in a software container utilizing tenant and container classloaders. In particular tenants executing in a multi tenant software container are associated with individual tenant classloaders for loading non shared classes on behalf of the tenants. When a tenant classloader receives a request from its associated tenant to load a class the tenant classloader determines whether the class is a class that is shared with other tenants in the same multi tenant software container. Various mechanisms might be utilized to determine if the class to be loaded is a shared class.

If the class to be loaded is not a shared class the tenant classloader loads the class on behalf of the requesting tenant. The tenant classloader might also be configured to perform bytecode weaving on the loaded class at load time. If however the class to be loaded is a shared class the tenant class loader delegates loading of the shared class to a container classloader. The container classloader in turn loads the shared class. The container classloader is configured to allow two or more tenants to utilize the same class definition. Instances of the class created by the tenants however are maintained separately from one another. In this way each tenant cannot access a class instance created by another tenant. The container classloader might also be configured to perform bytecode weaving on the loaded class at load time. Other mechanisms for dependency isolation of tenants executing in a multi tenant software container may also be utilized. Additional details regarding the mechanisms disclosed herein for dependency isolation of tenants executing in a multi tenant software container will be provided below with regard to .

Mechanisms are also disclosed herein for security isolation that may be utilized to prevent one tenant in a multi tenant software container from accessing protected data or functionality of another tenant. In one implementation of these mechanisms the tenants of a multi tenant software container are assigned individual trusted identities. For example in one implementation a trusted identity and access policy management TIAPM service external to the multi tenant software container assigns a trusted identity to each of the tenants for which security isolation is desirable. The TIAPM service might also maintain an access policy or policies that defines the components that are authorized to access the tenants other services external to the software container and potentially host resources e.g. operating system resources container resources and or virtual machine resources. The TIAPM service might also maintain access policies for other systems and components.

The TIAPM service might also provide the access policies to various components that are configured to enforce the policies. For example in one embodiment a framework within the software container is configured to enforce an access policy for accessing the tenants of the multi tenant software container. In another embodiment the tenants themselves may be configured with functionality for identity based access control thereby permitting the tenants themselves to enforce their own access policies. The TIAPM service might also provide an access policy or policies to other services external to the software container that may be called by the tenants of the multi tenant software container. Additionally the access policy might be provided to a component such as a security manager tasked with enforcing an access policy associated with host resources.

When a tenant generates a request to access another tenant in the multi tenant software container or another container the tenant includes their associated trusted identity with the request. The trusted identity can then be utilized along with the relevant access policy to determine if the tenant s request can be granted. For example if the request is to a second tenant in the same multi tenant application container a framework in the container or the second tenant itself may utilize the trusted identity of the requesting tenant and an access policy associated with the second tenant to determine if the request should be granted.

A tenant might also make a request to access a service outside the multi tenant container that includes the trusted identity associated with the tenant. The service will utilize the tenant s trusted identity and an appropriate access policy to determine whether the request can be granted. In a similar fashion a tenant may request to access or otherwise utilize host resources container resources and or virtual machine resources. A framework security manager or other type of component may utilize the tenant s trusted identity and an access policy associated with the host resources container resources and or virtual machine resources to determine if the request can be granted.

Incoming requests directed to tenants of the multi tenant software container might also include a trusted identity associated with a calling client. In this case the trusted identity of the calling client and an access policy associated with the called tenant can be utilized to determine whether the incoming request should be permitted or denied. Other mechanisms for security isolation of tenants executing in a multi tenant software container might also be utilized. Additional details regarding the mechanisms disclosed herein for security isolation of tenants executing in a multi tenant software container will be provided below with regard to .

Mechanisms are also disclosed herein for fault isolation that may be utilized to prevent tenants in a multi tenant software container from causing a fault and or taking other types of actions that negatively impact another tenant executing in the same software container. In particular mechanisms may be implemented for preventing a tenant from shutting down the software container a virtual machine an operating system or a host computer if such a shutdown would impact other currently executing tenants. The number of active releases of each tenant in a software container might also be limited thereby reducing the possibility that a tenant will consume a disproportionate amount of memory and cause a fault that impacts other tenants. Tenants ability to execute native code might also be restricted thereby preventing tenants from launching processes outside of the software container that may consume significant memory and or cause other types of faults.

In order to limit tenants usage of memory an inactive tenant might also be dynamically unloaded based upon the utilization of the tenant. For example a tenant that is inactive might be swapped to disk to reduce memory usage by the software container. If a request is received for the tenant the tenant may be reloaded and executed in order to respond to the request. Other mechanisms might also be utilized to reduce the possibility of a fault caused by excessive memory utilization of a software container.

Errors generated by a tenant that might cause a fault impacting other tenants might also be intercepted. The context of an intercepted error might then be determined based upon a stack trace and or other information. A determination may then be made as to whether to permit or prohibit the error from being generated based upon the context of the error.

In some embodiments tenants might be prevented from utilizing the same Uniform Resource Identifier URI in order to prevent routing conflicts that might generate a fault. Tenants might also be prevented from passing objects to one another that are mutable. Additionally tenants might be prevented from making changes to the configuration of the software container a virtual machine an operating system and or a host computer. In this way the tenants can be prevented from making configuration changes that might induce a fault that affects other tenants of the software container. Other mechanisms for fault isolation of tenants executing in a multi tenant software container might also be utilized. Additional details regarding the mechanisms disclosed herein for fault isolation of tenants executing in a multi tenant software container will be provided below with regard to .

It should be appreciated that the subject matter presented herein may be implemented as a computer process an electronic computer controlled apparatus a computing system or an article of manufacture such as a computer readable storage medium. These and various other features will become apparent from a reading of the following disclosure and a review of the associated drawings.

While the subject matter described herein is presented in the general context of program modules that execute on one or more computing devices those skilled in the art will recognize that other implementations may be performed in combination with other types of program modules. Generally program modules include routines programs components data structures and other types of structures that perform particular tasks or implement particular abstract data types. Moreover those skilled in the art will appreciate that the subject matter described herein may be practiced on or in conjunction with other computer system configurations beyond those described below including multiprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers handheld computers personal digital assistants cellular telephone devices electronic book readers special purposed hardware devices network appliances and the like. The embodiments described herein may also be practiced in distributed computing environments where tasks are performed by remote processing devices that are linked through a communications network. In a distributed computing environment program modules may be located in both local and remote memory storage devices.

In the following detailed description references are made to the accompanying drawings that form a part hereof and that show by way of illustration specific embodiments or examples. The drawings herein are not drawn to scale. Like numerals represent like elements throughout the several figures.

As mentioned above the software container might provide functionality for executing applications loading application dependencies interconnecting applications at run time managing application lifecycles including integrated application deployment and eviction multi tenant execution and other types of functionality. It should be appreciated that while the embodiments disclosed herein are primarily presented in the context of a software container the embodiments disclosed herein might also be utilized with other types of containers and execution environments.

It should be appreciated that software containers are available for use in many development and execution environments. For example software containers are commonly available that utilize the JAVA programming language from ORACLE CORPORATION. Examples of software containers include but are not limited to WEBSPHERE from IBM CORPORATION SPRING FRAMEWORK from VMWARE CORPORATION GUICE from GOOGLE CORPORATION the PICOCONTAINER and PLEXUS projects from CODEHAUS the FELIX TOMCAT TOMEE and GERONIMO projects from the APACHE SOFTWARE FOUNDATION EQUINOX GEMINI JETTY and ECLIPSE from the ECLIPSE FOUNDATION JBOSS from REDHAT CORPORATION and GLASSFISH WEBLOGIC and FUSION from ORACLE CORPORATION. Although the embodiments disclosed herein are primarily presented in the context of a software container the embodiments disclosed herein might also be utilized with other types of containers and with other types of execution environments.

As shown in the host computer provides various hardware resources that may be utilized by the tenants executing in the software container . For example and without limitation hardware resources include but are not limited to CPU cycles system memory mass storage disk I O and bandwidth and network I O and bandwidth. The host computer might also provide other types of hardware resources for utilization by the tenants .

As also shown in the operating system might provide various types of software resources for use by the tenants . For example and without limitation the software resources include but are not limited to load balancer connections file descriptors and other types of software resources . The virtual machine might also provide virtual machine resources for use by the tenants . For example and without limitation the virtual machine resources include but are not limited to heap old generation young generation permanent generation code cache and execution threads. Other types of virtual machine resources might also be provided.

It should be appreciated that the hardware resources software resources and virtual machine resources collectively resources described above are merely illustrative. In this regard it should also be appreciated that the embodiments disclosed herein may be utilized to provide isolation with respect to other types of resources not specifically identified herein. It should be further appreciated that the operating environment illustrated in is merely illustrative and that the embodiments disclosed herein might be utilized in other types of operating environments and with other types of containers.

As discussed briefly above mechanisms are disclosed herein for resource isolation that among other things allow tenants executing in a multi tenant software container to be isolated in order to prevent resource starvation caused by excessive resource utilization by one or more of the tenants . Additional details regarding these mechanisms for resource isolation are described below with regard to .

Each new thread that is created by a tenant consumes CPU resources. Therefore a tenant that utilizes an excessive number of threads might cause other tenants to be unable to obtain threads. In order to isolate the utilization of threads among the tenants various mechanisms might be utilized in order to monitor the number of threads that each tenant is creating and potentially to place a cap which might be referred to herein as a quota or a threshold on the number of threads that can be created per tenant . If a tenant reaches the maximum number of threads that can be allocated to it then no further threads may be allocated to that tenant . In this regard it should be appreciated that the various caps described herein might be calculated in various ways. For example and without limitation caps might be computed dynamically based upon various conditions such as the load on the host computer at a given point in time. Other factors might also be utilized to dynamically determine a cap for the various resource types described herein.

In order to monitor the number of threads created by each tenant bytecode weaving may be utilized to instrument an application programming interface utilized by the tenants APIs for thread creation. In particular when a tenant requests to create a new thread bytecode weaving may be utilized to increment a counter that indicates the number of threads created by that tenant . As known in the art bytecode weaving permits the injection of program code at run time to perform certain tasks. Bytecode weaving may be utilized in embodiments where the tenants are expressed utilizing the JAVA programming language and wherein the virtual machine is a JAVA virtual machine JVM . Other similar mechanisms might also be utilized in conjunction with other programming languages in order to modify program code at run time in the manner described herein.

In other implementations interception may be utilized to monitor the number of threads created by each of the tenants . In particular when a tenant creates a new thread a notification may be provided to the operating system indicating that the new thread has been created. In this way the operating system can be aware of the threads that are being created by the virtual machine . A process referred to herein as an interceptor might be implemented at the level of the operating system in order to monitor these notifications and increment a counter associated with each tenant as thread creation notifications are received. Interception might also be implemented at the level of the virtual machine in other implementations.

Tracing might also be utilized to monitor the number of threads created by each of the tenants . For example and without limitation a tracing tool such as PERF or PTRACE might be utilized to monitor the number of threads created by each of the tenants . As known to those skilled in the art these tools provide functionality for one process i.e. a tracer to observe and potentially control the execution of another process i.e. the tenants . In this embodiment the tracer may be utilized to monitor thread creation and maintain a counter for the tenants indicating the number of threads that have been created.

In view of the above it should be appreciated that bytecode weaving interception and or tracing may be utilized to keep track of the number of threads created by the tenants executing in the multi tenant software container . It should be appreciated that these mechanisms are merely illustrative and that other mechanisms might also be utilized in other embodiments to monitor the number of threads created by tenants in a multi tenant software container .

If a tenant requests to create threads in excess of a specified thread cap an exception may be thrown and the tenant may not be permitted to create the requested thread or any additional threads. In this way each tenant can be prevented from creating a disproportionate number of threads that may starve the other tenants from being able to create threads. Other types of actions might also be taken with respect to a tenant that attempts to create threads in excess of a specified thread cap. Additionally the mechanisms described above might also be utilized to keep track of each thread that is created by the tenants . If a tenant is removed from the software container this information may be utilized to reap the threads previously created by that tenant . Tracking of threads created by each tenant might be performed utilizing a thread group. Mechanisms might also be utilized to prevent tenants from creating threads outside of a thread group.

In order to restrict each of the tenants to a particular directory bytecode weaving may be utilized in conjunction with calls made by the tenants to write to the file system . Using this mechanism an exception may be thrown if a write request is received from a particular tenant for a directory other than the directory assigned to that tenant . In this way write requests to a directory not assigned to the tenant may be restricted. Other mechanisms might also be utilized to prevent tenants from writing data to a directory other than their assigned directory .

A disk space quota might also or alternatively be imposed on each tenant . Any data that the tenant writes to their directory on the file system will count against the disk space quota for that tenant . In order to implement this functionality bytecode weaving may be utilized to instrument calls to write to the file system made by the tenants at the level of the virtual machine . For example when a tenant makes a call to the virtual machine to write to the file system the number of bytes to be written may be determined and a counter incremented for that tenant . Additionally the quota may be enforced by tracking and recording write calls at the operating system level to determine which thread i.e. tenant is reading or writing to the file system . If a tenant writes an amount greater than their quota to the file system the tenant may not be permitted to make further writes. Other mechanisms might also be utilized in order to limit the amount of data written to a file system by each of the tenants .

In order to prevent a tenant from utilizing a disproportionate number of file descriptors bytecode weaving of file descriptor requests at the virtual machine level might be utilized to maintain a counter indicating the number of file descriptors utilized by each of the tenants . Alternatively an interceptor may be utilized at the operating system level to intercept calls to the operating system to create file descriptors and maintain a count of the number of file descriptors created by each of the tenants . Once the counter for a tenant reaches a specified number of file descriptors i.e. a cap the tenant may not be permitted to create additional file descriptors.

Utilizing the mechanisms disclosed herein tenants in a multi tenant software container might also be prohibited from running separate processes outside of the virtual machine . For instance and without limitation bytecode weaving at the virtual machine level interception at the operating system level and or other mechanisms might be utilized to instrument calls made by the tenants to create processes outside the virtual machine and to prevent such processes from being created. If the tenants are permitted to create processes outside the virtual machine bytecode weaving and or interception might be utilized to keep track of the amount of memory utilized by the processes that are created by each tenant outside of the virtual machine . Additional details regarding various mechanisms disclosed herein for isolating the utilization of memory among tenants executing in a multi tenant software container will be provided below.

A virtual Internet protocol address VIP which might be hosted on a load balancer for example might also be considered a shared resource for which excessive utilization by one of the tenants might starve out other tenants . In order to address this possibility the software container might be instrumented utilizing bytecode weaving in order to emit metrics showing how much network traffic is being received by each of the tenants . These metrics might then be utilized to take various types of actions such as pausing execution or execution throttling for instance with respect to tenants that are receiving an excessive amount of network traffic from the VIP. Other mechanisms might also be utilized in order to determine the amount of network traffic each tenant is receiving and for taking action with regard to a tenant receiving an excessive or undesirable amount of network traffic.

It should be appreciated that in some embodiments functionality might also be implemented within a software container for intercepting network requests from tenants executing within the software container and routing the requests based on one or more factors. For example and without limitation a software container might be configured to route tenant requests based upon the geographic or physical proximity of the destination e.g. a host computer or a data center . A software container might also be configured to route tenant requests based upon other types of factors. Byte code weaving might also be utilized within a virtual machine to route network traffic to a specific host computer rather than a load balancer. Other mechanisms for modifying network traffic and performing other types of optimizations within a software container might also be implemented in other embodiments. Other such mechanisms are described in U.S. patent application Ser. No. 13 592 922 entitled Optimized Deployment and Execution of Programs in a Distributed Computing Environment which was filed on Aug. 23 2012 the entirety of which is expressly incorporated herein by reference.

The permanent generation is a pool containing all the reflective data of the virtual machine such as class and method objects and related metadata. With JVMs that use class data sharing the permanent generation may be divided into read only and read write areas. The permanent generation typically does not shrink but only grows. When multiple tenants are executing in a multi tenant software container the tenants contend for the available permanent generation . Consequently the utilization of a disproportionate amount of the permanent generation by one tenant might result in the inability of the virtual machine to allocate the permanent generation to other tenants . Running out of the permanent generation might also cause execution of the virtual machine to fail.

In order to address this problem and potentially others a classloader may be configured to monitor the creation of objects by the tenants . For example the classloader might be configured to monitor the utilization of the permanent generation by each of the tenants . Monitoring the utilization of the permanent generation in this manner permits permanent generation counters to be maintained indicating the amount of permanent generation utilized by each of the tenants . If a tenant exceeds their permanent generation allowance the virtual machine may not allocate additional data to the permanent generation for the tenant .

The virtual machine utilizes the young generation to store short lived objects that are immediately garbage collected. The virtual machine might move objects that persist longer to the old generation. Garbage collection of the old generation by the virtual machine might impose a performance penalty on tenants executing within the multi tenant software container . Consequently disproportionate utilization of the old generation by one of the tenants might impose a performance hit on the other tenants executing in the multi tenant software container .

In order to address this problem and potentially others bytecode weaving might also be utilized to keep track of the amount of young generation and or new generation utilized by each of the tenants . Bytecode weaving might also be utilized to keep track of the new objects created by the tenants . The volume of new objects created by each of the tenants might be utilized as an indicator of the amount of permanent generation young generation and or old generation utilized by each of the tenants . This mechanism might be utilized if it is not possible to bytecode weave the amount of permanent young or old generation utilized by each of the tenants .

Other mechanisms might also be utilized to determine the amount of each generation utilized by each of the tenants . For example and without limitation a dump of the heap might be utilized to determine the amount of young generation and or old generation utilized by each of the tenants . A heap dump might be performed periodically e.g. every few minutes in order to maintain a current count of the young generation and old generation utilized by each of the tenants . The dump may be utilized to determine whether one of the tenants is utilizing an excessive amount of the young and or old generation. Various types of actions may then be taken with regard to a tenant that is utilizing too much of the young or old generation.

 Shadow environments might also be utilized in some embodiments to determine if one of the tenants is utilizing a disproportionate amount of permanent young or old generation. In this embodiment individual tenants may be configured in shadow environments where they execute independently i.e. one tenant per software container . Requests received for the tenants may be routed to the shadow environments . The virtual machines executing in the shadow environments may then be utilized to determine the utilization of permanent young and old generation by each of the tenants individually. A specific example of this embodiment is shown in .

As shown in two tenants A and B may be executed in a multi tenant software container that has very high utilization of permanent generation young generation and or old generation. In this example it may be difficult to determine which of the tenants A and B or both are responsible for the high resource utilization. In order to identify the tenant A or B that is responsible for the high resource utilization a shadow environment A might be created for executing only the tenant A. A separate shadow environment B might also be created for executing only the tenant B. Incoming requests can be routed to the software container for processing in a typical fashion. Incoming requests can also be routed to the shadow environments A and B for processing by the tenants A and B executing in those shadow environments A and B. The utilization of resources in each of the shadow environments A and B can then be monitored to determine whether the tenant A or B or both is responsible for the high resource utilization in the multi tenant software container . It should be appreciated that shadow environments might also be utilized to isolate the utilization of other types of resources by the tenants .

In some embodiments bytecode weaving is utilized in conjunction with a finalizer in order to determine the number of objects that were garbage collected. As known in the art JVMs may utilize a finalizer following garbage collection. By bytecode weaving the finalizer a counter that describes the amount of memory utilized by each of the tenants might be reduced by the amount of objects that were garbage collected for each of the tenants . Other mechanisms might also be utilized in conjunction with JVMs and other types of virtual machines in order to maintain an accurate count of the memory utilized by the tenants by reducing the count of the amount of memory utilized by each tenant following garbage collection.

In a similar manner to that described above with regard to bytecode weaving at the virtual machine level and or interception at the operating system level might also be utilized to determine the total number of disk reads and disk writes per second or other time period for each of the tenants . In a similar manner and as also described above tracing tools and shadow environments might also be utilized to determine the number of disk I O operations performed by each of the tenants executing in the multi tenant software container . Various actions might then be taken with regard to tenants that utilize an excessive amount of disk I O. For example and without limitation execution of the tenant might be throttled paused or terminated. Other types of actions might also be taken to reduce the amount of disk I O per time period utilized by a particular tenant .

In a similar manner to that described above with regard to bytecode weaving at the virtual machine level and or interception at the operating system level might also be utilized to determine the total number if network reads and writes per second or other time period for each of the tenants . In a similar manner and as also described above tracing tools and shadow environments might also be utilized to determine the number of network I O operations performed by each of the tenants executing in the multi tenant software container . Various actions might then be taken with regard to tenants that utilize an excessive amount of network I O. For example and without limitation execution of the tenant might be throttled paused or terminated. Other types of actions might also be taken to reduce the amount of network I O per time period utilized by a particular tenant .

The implementation of the various components described herein is a matter of choice dependent on the performance and other requirements of the computing system. Accordingly the logical operations described herein are referred to variously as operations structural devices acts or modules. These operations structural devices acts and modules may be implemented in software in firmware in special purpose digital logic and any combination thereof. It should also be appreciated that more or fewer operations may be performed than shown in the FIGS. and described herein. These operations may also be performed in parallel or in a different order than those described herein. Some or all of these operations might also be performed by components other than those specifically identified.

The routine begins at operation where resource usage by tenants in a multi tenant software container is monitored. As discussed above the various types of resources for which usage might be monitored includes but is not limited to disk space CPU utilization system memory heap and garbage collection occurrences disk I O operations and bandwidth network I O operations and bandwidth load balancer connections file descriptor count and execution threads. It should be appreciated that this list of resources is merely illustrative and that the utilization of other types of resources by tenants in a multi tenant software container might also be monitored.

As also discussed above various mechanisms might also be utilized to monitor the utilization of the resources described above by the tenants . For example and without limitation bytecode weaving might be utilized at various levels of the stack shown in in order to monitor resource utilization by the tenants . An interceptor might also be utilized at the level of the operating system or another level of the stack. As also discussed above one or more shadow environments might also be utilized to isolate the execution of a particular tenant and to determine its resource utilization. Tracing tools memory dumps and other mechanisms might also be utilized to determine the resource utilization of the tenants in other implementations.

From operation the routine proceeds to operation where a determination is made as to whether one of the tenants has utilized a specific resource in excess of a specified threshold or cap. For example a determination might be made as to whether one of the tenants has utilized permanent generation in excess of a specified cap. As another example a determination might be made as to whether a tenant has utilized file descriptors or disk space in excess of a specified quota. If a tenant has not utilized a resource in excess of a specified threshold the routine proceeds back to operation where resource usage monitoring might continue in the manner described above. If however a tenant has utilized a resource in excess of a specified cap threshold or quota the routine proceeds from operation to operation .

At operation one or more actions might be taken with regard to a tenant that utilizes resources in excess of a specified threshold. For example and without limitation a resource request might be denied a resource request might be redirected to another location a tenant might be evicted from the software container a tenant might be moved to another software container on another host computer a tenant might be allocated fewer CPU cycles and or the execution of a tenant might be paused and or throttled. Other actions might also be taken with regard to a tenant that utilizes resources in excess of a specified threshold. From operation the routine proceeds back to operation where processing may continue in the manner described above.

It should be appreciated that the results of the various types of resource monitoring described above for enforcing resource isolation among tenants might also be utilized for other purposes in certain implementations. For example and without limitation results of the resource monitoring described above might be provided to a billing system not shown and utilized to charge a customer for the actual use of computing resources on a per tenant basis. As a specific example a customer might be billed for the use of disk space memory CPU utilization and or other resources in an amount that is based upon monitoring the use of these resources by an associated tenant using one or more of the various mechanisms described above. The results of the monitoring described above might also be utilized for other purposes not specifically mentioned herein.

As discussed briefly above mechanisms are also disclosed herein for dependency isolation that may be utilized to prevent one tenant A executing in a multi tenant software container from utilizing another tenant B in the same container in a manner that requires co tenancy i.e. in a manner that requires that both tenants A and B co exist in the same container . One such mechanism is shown in which is a software architecture diagram illustrating aspects of one mechanism for dependency isolation of tenants in a multi tenant software container utilizing tenant classloaders A and B and a container classloader .

The mechanism shown in and described in detail below is configured to ensure that tenants A and B executing in the same multi tenant software container do not communicate with one another directly through classes exposed by one another i.e. one tenant A calling a particular method on a class exposed by another tenant B directly or sharing a class in memory . Rather utilizing the mechanism shown in the tenants A and B can be required to communicate with one another or with the container through classes that are available through a container classloader or through mechanisms provided outside of the container e.g. a properly formatted HTTP request that passes through a common layer of the stack like the operating system .

In order to address the considerations set forth above and potentially others each of the tenants in a multi tenant software container is associated with a tenant classloader . For instance in the example shown in the tenant A is associated with the tenant classloader A. Similarly the tenant B is associated with the tenant classloader B. If a multi tenant software container includes additional tenants those tenants would also be associated with respective tenant classloaders .

The tenant classloaders are responsible for loading classes on behalf of their associated tenants that are not shared with other tenants i.e. unshared classes . In the example shown in for instance the tenant A utilizes the tenant classloader A to load the unshared classes A. Similarly the tenant B utilizes the tenant classloader B to load the unshared classes B.

When a tenant requests a class from a tenant classloader the tenant classloader determines if the requested class is a shared class . For example and without limitation the tenant classloader might examine a package or bundle that contains the requested class to determine if the class is a shared class . If the requested class is an unshared class the tenant classloader will load the requested class. If however the tenant classloader determines that the requested class is a shared class the tenant classloader delegates the responsibility for loading the requested class to the container classloader .

The container classloader is responsible for loading shared classes . Through functionality provided by the container classloader two tenants A and B can utilize the same class definition. Both tenants A and B cannot however use the same class definition to interpret one object in memory. So the container classloader can load the class definition and both tenants A and B can utilize the class definition to create instances of the class. However the instances created by each tenant A and B will be located in separate pools. In this way a common shared class can be loaded into memory only once and instances for use by different tenants A and B may be created and utilized independently e.g. the tenant A cannot access an object of the same class loaded by tenant B and vice versa .

The shared classes loaded by the container classloader might be classes for enabling tenant to tenant communication. The shared classes loaded by the container classloader might also be classes for enabling tenant to container communication. Other types of shared classes might also be loaded by the container classloader and managed in the manner described herein.

As shown in the container classloader might also load shared classes that utilize bytecode weaving of static variables. Through the use of bytecode weaving of static variables classes not originally intended for execution in a multi tenant software container might be modified for proper execution within the multi tenant software container . One mechanism for bytecode weaving of static variables in this manner is described in U.S. patent application Ser. No. 13 800 783 entitled MODIFICATION OF PROGRAM CODE FOR EXECUTION IN A MULTI TENANT OR DISTRIBUTED COMPUTING ENVIRONMENT filed on Mar. 13 2013 and which is expressly incorporated herein by reference in its entirety.

As also shown in the tenant classloaders and the container classloader might also perform bytecode weaving . In particular the tenant classloaders and the container classloader might utilize bytecode weaving in order to modify unshared classes at load time to perform certain functionality. For example and without limitation bytecode weaving might be utilized to implement various mechanisms described above for resource isolation and or various mechanisms described below for fault isolation. For instance and without limitation a tenant classloader might perform bytecode weaving to instrument unshared classes that load objects allocate memory or use disk space in order to maintain a counter indicating the amount of a particular resource that has been utilized. Similarly a tenant classloader might utilize bytecode weaving to throw an exception whenever a loaded unshared class makes a call to shutdown the software container a virtual machine an operating system and or the host computer. The tenant classloaders and or the container classloader might also implement bytecode weaving in order to implement other aspects of the various mechanisms disclosed herein for resource isolation security isolation dependency isolation and or fault isolation.

As shown in a security manager might also be utilized in conjunction with the mechanism described above for enforcing dependency between the tenants through the utilization of tenant classloaders and a container classloader . The security manager might also be configured to provide additional functionality in this regard. For example and without limitation the security manager might be configured to prevent one tenant from loading unshared classes associated with another tenant . The security manager might also implement other types of functionality for enforcing dependency between the tenants . Additional details regarding the mechanism shown in will be provided below with regard to .

It should be appreciated that the container classloader may be considered another tenant of the multi tenant software container . For example and without limitation the container classloader can be swapped out of the multi tenant software container like any other tenant . In order to achieve this a second classloader may be created in the multi tenant software container with a slightly modified class path. Newly created tenants will use the second classloader. Older tenants executing in the multi tenant software container can be migrated to the second classloader. In this way the application executing in the multi tenant software container can be redeployed without having to take down the virtual machine .

Turning now to one mechanism for enforcing dependency isolation of tenants in a multi tenant software container by modifying the parent classloaders of tenant and container classloaders will be described. When a classloader is created its parent is by default the system classloader on a JAVA platform. Having the system classloader as a default allows tenants to share classes without delegating to the container classloader first. The parent classloader of the system classloader is the extension classloader . The parent classloader of the extension classloader is the bootstrap classloader .

In order to achieve better isolation between tenants the bootstrap classloader may be designated as the parent classloader for the tenant classloaders A and B. The bootstrap classloader might also be designated as the parent classloader for the container classloader . In this way tenants may be prevented from loading classes through the system classloader and or the extension classloader . In another embodiment a similar result may be achieved by configuring the tenant classloaders A and B and the container classloader such that they do not have a parent classloader.

Turning now to a flow diagram showing an illustrative routine will be described that illustrates aspects of the operation of a tenant classloader . The routine begins at operation where a tenant classloader receives a request from an associated tenant to load a class. In response to such a request the routine proceeds from operation to operation where the tenant classloader determines whether loading of the class requested by the tenant should be delegated to the container classloader . For example and as discussed above the tenant classloader might examine a package containing the requested class to determine if the requested class is a shared class that should be loaded by the container classloader . Other mechanisms might also be utilized to determine if the requested class is an unshared class that can be loaded by the tenant classloader or whether the requested class is a shared class that should be loaded by the container classloader .

If loading of the requested class is to be delegated to the container classloader the routine proceeds from operation to operation . At operation the tenant classloader delegates loading of the requested class to the container classloader . Additional details regarding operation of the container classloader will be provided below with reference to . From operation the routine proceeds to operation where it ends.

If at operation the tenant classloader determines that loading of the requested class is not to be delegated to the container classloader the routine proceeds from operation to operation where the tenant classloader loads the requested unshared class . The routine then proceeds from operation to operation where the tenant classloader might perform bytecode weaving on the loaded unshared class in order to implement various types of functionality such as that described above for instrumenting the unshared class to determine resource utilization and or for intercepting a shutdown request or other type of operation implemented by the unshared class . Bytecode weaving might also be utilized by the tenant classloader to modify the loaded unshared class in other ways. From operation the routine proceeds to operation where it ends.

Turning now to a flow diagram showing an illustrative routine will be described that illustrates aspects of the operation of the container classloader . The routine begins at operation where the container classloader receives a request from a tenant classloader to load a shared class . As discussed above the responsibility for loading the shared class might be delegated from the tenant classloader to the container classloader . In response to receiving such a request the container classloader loads the shared class as requested by the tenant classloader i.e. the class requested by the tenant at operation .

From operation the routine proceeds to operation where the container classloader may perform bytecode weaving on the loaded shared class in order to implement various types of functionality such as that described above for bytecode weaving of shared classes in order to enable program code not specifically programmed for execution within the multi tenant software container to execute properly within the multi tenant environment. Bytecode weaving might also be utilized by the container classloader to modify the loaded shared classes and in other ways. From operation the routine proceeds to operation where it ends.

As mentioned briefly above the embodiments disclosed herein also provide mechanisms for security isolation of tenants executing in a multi tenant software container . Security isolation refers to a process of isolating tenants executing in a software container such that one tenant A cannot access another tenant B i.e. the tenant s methods or data without authorization. illustrate various mechanisms disclosed herein for security isolation of tenants in a multi tenant software container .

As also shown in the TIAPM service might also maintain an access policy or policies that defines the components that are authorized to access the tenants other services external to the software container such as the service and potentially host resources of the host computer e.g. operating system resources that the multi tenant software container is executing upon. The TIAPM service might also maintain access policies for other systems and components. It should be appreciated that while a single access policy is illustrated in the TIAPM service might maintain a separate access policy for each component for which resource access control is desirable.

The TIAPM service might also provide the access policies to various components that are configured to enforce the policies. For example in one embodiment a framework not shown in within the software container is configured to enforce identity based access control A for accessing the tenants of the multi tenant software container . In another embodiment described below in detail with regard to the tenants themselves may be configured with functionality for identity based access control thereby permitting the tenants to enforce their own access policies .

The TIAPM service might also provide an access policy or policies to other systems components and or services external to the software container that may be called by the tenants of the multi tenant software container . For instance in the example shown in the TIAPM service provides an access policy to the service for use by the identity based access control B in enforcing access restrictions to the service . Additionally the TIAPM service might provide an access policy to be provided to a component such as a security manager not shown in tasked with imposing resource access control for host resources . Additional details regarding this process will be provided below.

It should be appreciated that the TIAPM service might also provide other types of functionality. For example and without limitation the TIAPM service might vend encryption keys and or other types of data that permits clients to verify to called services that they are who they claim to be. For example and without limitation an entity that has been assigned a trusted identity might also be assigned a public private encryption key pair that the entity may utilize to sign and verify requests made by that entity. The TIAPM service might also vend other types of data e.g. certificates to the various entities described herein for use in determining their identity in a trusted fashion and or perform other types of functionality not specifically described herein.

It should also be appreciated that the various components described herein might cache the access policy for use in evaluating access requests. The access policy might be periodically refreshed by pulling an updated version of the access policy from the TIAPM service . The TIAPM service might also periodically push an updated access policy to the various components tasked with enforcing the access policy . Other mechanisms might also be utilized to ensure that an updated version of the access policy is made available to the various consumers of the access policy .

When a tenant A generates a request D to access another tenant B in the multi tenant software container or in another container the tenant A includes their associated trusted identity A with the request. D. The supplied trusted identity A can then be utilized along with the relevant access policy i.e. the access policy for the requested tenant B to determine if the request D can be granted. For example if the request D is to a second tenant B in the same multi tenant application container a framework not shown in in the container or the second tenant B itself may utilize the trusted identity A of the requesting tenant A and an access policy associated with the second tenant B to determine if the request D should be granted.

A tenant A might also make a request B to access a service outside the multi tenant container that includes the trusted identity A associated with the tenant A. The service will utilize the trusted identity A supplied with the request B and an appropriate access policy i.e. the access policy for accessing the service to determine whether the request B can be granted.

Incoming requests directed to tenants of the multi tenant software container such as the request A might also include a trusted identity C associated with the calling client . In this case the trusted identity C of the calling client and an access policy associated with the called tenant can be utilized to determine whether the incoming request A should be permitted or denied. In the example shown in for instance the client has presented a request A that is directed to the tenant A. If the access policy associated with the tenant A indicates that the client is permitted to call the tenant A then the request A will be routed to the tenant A. It should be appreciated that a framework or other component in the software container might evaluate the request A. Alternately and as discussed in greater detail below with regard to the called tenant i.e. the tenant A shown in might evaluate the request A against the appropriate access policy .

In addition to controlling access between tenants A and B on the same or different host computers it might also be desirable to control access to data stored on the host computer and or other types of resources provided by the host computer . For example data stored by one tenant A locally on a host computer should not be accessible to other tenants executing on the same host computer . Since tenants A and B in the same software container execute in the same process it can be difficult to restrict the ability of each tenant to access locally stored data. It might be similarly difficult to restrict access to other types of resources provided by the host computer to individual tenants executing in a multi tenant software container because the tenants appear to the operating system executing on the host computer to be the same user.

In order to address these considerations and potentially others the embodiments disclosed herein also include functionality for providing resource access control of host resources . As used herein the term host resources encompasses any software or hardware resource provided by the host computer that executes the multi tenant software container . For example and without limitation host resources might include operating system resources file and block data storage resources networking resources hardware resources and others. Secure access might also be provided to other resources provided by the host computer not specifically identified above.

In order to provide secure access to the host resources the software container or another component such as a security manager not shown in provides resource access control for the host resources . In particular the TIAPM service provides an access policy for the host resources . The access policy for the host resources identifies the components that are permitted to access the host resources . For example and without limitation the access policy for the host resources might indicate that the tenant A is authorized to access the host resources .

When a request C is received to access the host resources resource access control is utilized to determine whether the request C to access the host resources should be granted. In order to make this determination the software container or another component determines whether the trusted identity A in the received request C is identified in the appropriate access policy as being authorized to access the host resources . Access to the host resources will be permitted if the access policy indicates that the entity making the request i.e. the tenant A in the example shown in is permitted to access the host resources . Otherwise the request will be denied. Additional details regarding the mechanisms presented herein for security isolation of tenants in a multi tenant software container will be described below with regard to .

In a similar manner to that described above with regard to host resources resource access control might also be utilized to provide secure access to container resources not shown in virtual machine resources shown in and other types of resources. Container resources are resources provided by the multi tenant software container . As described above with regard to virtual machine resources are resources provided by a virtual machine .

In the example shown in for instance a request A has been received at the tenant A that includes the trusted identity C associated with the calling client . In this example the identity based access control C within the tenant A is utilized to evaluate the request A against the appropriate access policy i.e. the access policy for the tenant A . The request A will be granted if the access policy indicates that the client is authorized to access the tenant A.

In the example shown in the tenant A has also submitted a request D to access the tenant B. In this example the identity based access control D within the tenant B is utilized to evaluate the request D against the appropriate access policy i.e. the access policy for the tenant B . The request D will be granted if the access policy indicates that tenant A is authorized to access the tenant B.

It should be appreciated that the mechanisms described above for security isolation are illustrative and that other mechanisms for security isolation of tenants executing in a multi tenant software container might also be utilized. It should also be appreciated that in order to effectively implement some of the concepts described above for security isolation it may be necessary to configure the multi tenant software container to prohibit certain types of activities. For example and without limitation it may be necessary to configure the multi tenant software container such that the tenants cannot execute native code e.g. JAVA or C . It might also be necessary to disable or restrict tenants from accessing other types of functionality such as but not limited to attaching a debugger utilizing reflection utilizing bytecode weaving and or accessing other features or mechanisms that might be utilized to defeat the security isolation functionality described above.

From operation the routine proceeds to operation where identity based access control is implemented in the software container and or in the tenants . As mentioned above with regard to a framework or other component in the software container might implement the identity based access control . Alternately and as discussed above with regard to the tenants in the software container might implement the identity based access control directly. Other implementations might also be utilized.

From operation the routine proceeds to operation where various components tasked with identity based access control receive an appropriate access policy from the TIAPM service . For example when the tenants implement the identity based access control directly each tenant might receive an access policy defining the components that are authorized to access it. Similarly the service might receive an access policy defining the components that are permitted to access it.

From operation the routine proceeds to operation where a request is received to access a tenant . As discussed above such a request might be received from another tenant or from outside the software container such as the request A received from the client in the example shown in . From operation the routine proceeds to operation .

At operation the identity specified in the received request is utilized in conjunction with the appropriate access policy to determine if the request is to be granted or denied. For example if a request D is received to access the tenant B the access policy associated with the tenant B may be utilized to determine if the trusted identity A associated with the received request D is authorized to access the tenant B.

If the request is to be granted the routine proceeds from operation to operation where the request is granted. If the request is to be denied the routine proceeds from operation to operation where the request is denied. From operations and the routine proceeds to operation where it ends. It should be appreciated that requests generated by a tenant for access to host resources and requests generated by a tenant for access to other services might be processed in a similar manner.

It should be appreciated that in some embodiments the tenants might not require a trusted identity for all types of requests for access. In these embodiments the tenant might first determine whether a trusted identity is required in response to receiving a request . If a trusted identity is not required then the access request may be granted without examination of a trusted identity . If a trusted identity is required the tenants might perform the processing described above with regard to to determine whether an access request is to be granted based upon the supplied trusted identity and the access policy associated with the tenant or resource for which access has been requested.

As discussed briefly above mechanisms are also provided herein for fault isolation that may be utilized to prevent tenants in a multi tenant software container from causing faults and or other types of problem conditions that impact the execution of other tenants in the same software container . The mechanisms disclosed herein for fault isolation might also prevent tenants from performing malicious and or unintentional actions that might impact the operation of another tenant and or the software container . Additional details regarding these mechanisms are described below with regard to .

As shown in a tenant A might issue a shutdown request to the software container the virtual machine the operating system or the host computer . If other tenants such as the tenants A and B are executing in the same software container such a shutdown request will cause these tenants A and B to also be shut down.

In order to address the possibility described above bytecode weaving or another mechanism may be utilized to intercept a shutdown request issued by one of the tenants executing in a multi tenant software container . If no other tenants are executing in the same multi tenant software container then the shutdown request may be permitted. If however other tenants are executing in the same software container then the shutdown request may be denied. Additionally other actions might also be taken such as informing the tenant A that issued the shutdown request that the request was denied shutting down only the tenant A that issued the shutdown request and or other types of actions. It should be appreciated that certain types of tenants such as privileged tenants might be permitted to shut down the software container the virtual machine the operating system and or the host computer . Additional details regarding this mechanism are described below with regard to .

From operation the routine proceeds to operation where a determination is made as to whether other tenants are executing in the multi tenant software container . If no other tenants are executing in the multi tenant software container the routine proceeds from operation to operation where the shutdown request is performed. From operation the routine proceeds to operation where it ends.

If at operation it is determined that other tenants are executing in the multi tenant software container the routine proceeds from operation to operation . At operation the shutdown request is denied. As mentioned above other actions might also be taken such as for example shutting down the tenant that submitted the shutdown request notifying the tenant that submitted the shutdown request that the request has been denied and or another type of action. From operation the routine proceeds to operation where it ends.

The exhaustion of certain types of resources by a tenant in a multi tenant software container might result in a fault that impacts other tenants executing in the same multi tenant software container . For example and without limitation running out of heap memory permanent generation memory disk space file descriptors or other types of resources might induce a fault or other problem condition that impacts all of the tenants of a multi tenant software container . In order to address these possibilities bytecode weaving may be utilized to enforce a quota on the tenants utilization of certain types of resources. For example and without limitation bytecode weaving might be utilized to instrument each tenant and enforce a per tenant quota on the amount of disk space utilized.

Other mechanisms might also be utilized to restrict the amount of memory or disk space that a tenant is permitted to allocate. For example the virtual machine might be modified to keep track of the amount of various types of memory e.g. heap permanent generation etc. and or disk utilized by each tenant and to restrict each tenant from allocating more than some predetermined amount of a particular memory type and or from utilizing other types of resources beyond a predefined threshold. In particular the loading of classes by each tenant might be instrumented in order to determine the amount of memory utilized by each tenant and to enforce a per tenant quota thereupon. The quota might be enforced based upon a total amount of memory or disk utilized by a tenant or based upon an amount of memory or disk utilized by the tenant during some time period e.g. one second or one hour . Objects and or files utilized in excess of the specified threshold might be deleted.

As another example static code analysis might be utilized to determine the amount of permanent generation or other resources required to execute a tenant . The tenant may then be permitted to execute in the container or denied execution depending upon the amount of permanent generation and or other resources utilized by the tenant .

Another mechanism that might be utilized to restrict the amount of memory utilized by a tenant is to limit the number of active releases i.e. versions of the same tenant per tenant in the software container . Tenants running multiple versions in the same process at the same time may result in a significant utilization of permanent generation and or other resources. However by restricting the number of active releases per tenant the amount of permanent generation and or other types of resources utilized by each tenant might be limited.

Another mechanism that might be utilized to restrict the amount of memory utilized by a tenant is to load each tenant into main memory only when the tenant is being utilized. When a tenant is not being utilized the tenant and its associated objects and metadata may be paged out to disk or a memory location outside of that reserved for the virtual machine . When a request is subsequently received for the tenant the tenant and its related objects and metadata may be loaded back into the portion of memory utilized by the virtual machine and executed.

Some virtual machines utilize a string table that is utilized to provide efficient lookup for interned strings. Such a string table is not however typically resized when it grows. Consequently interning a significant number of strings can cause lookups on the string table to become drastically slower. While significant utilization of the string table would not likely cause a fault it might cause a significant performance penalty depending upon the manner in which it is utilized. So mechanisms such as bytecode weaving may be utilized to determine the manner in which tenants are utilizing the string table and to take various actions e.g. limiting further string creation depending upon each tenant s utilization of the string table.

It is also possible for certain conditions to arise that cause the host computer to run out of memory. For example and without limitation the virtual machine may allocate a sufficient amount of memory to cause the host computer to run out of memory. As another example a process external to the virtual machine might allocate a sufficiently significant amount of memory to cause the host computer to run out of memory. Memory leaks within the virtual machine and or the software container might also cause the host computer to run out of memory. A tenant might also allocate a significant number of file descriptors and or sockets that cause the virtual machine to allocate additional memory that results in the host computer running out of memory.

Various actions might be taken in order to prevent the host computer from running out of memory due to the conditions described above. For example and without limitation the virtual machine might be configured in order to prevent the tenants from running native code that might utilize host memory directly. As another example bytecode weaving and or a security manager might be utilized to prevent tenants from allocating an excessive number of file descriptors network sockets and or other resources. As a further example a quota might be enforced per tenant that limits that amount of memory utilized.

Creation of new processes by a tenant might also impact other tenants in the same multi tenant software container by generating an out of memory condition. In order to prevent this possibility bytecode weaving and or a security manager might be utilized to limit the number of new processes that can be created by a tenant . Additional details are provided below with regard to regarding the mechanisms described above for prevention of faults due to resource exhaustion.

In response to detecting such an action or in response to another type of stimulus various types of operations might be performed in order to prevent the detected action from causing a fault that might affect tenants executing in the multi tenant software container . For example and without limitation at operation restrictions might be imposed on the ability of the tenants in the multi tenant software container to utilize various resources provided by the virtual machine the operating system and or the host computer . As mentioned above for example bytecode weaving might be utilized to monitor the loading of classes by the tenants and to impose restrictions on the amount of memory utilized by the tenants .

Other mechanisms might also be utilized to monitor and or restrict the amount of memory and other types of resources utilized by the tenants in order to prevent a fault condition that might impact other tenants . For example and without limitation mechanisms might be implemented to monitor and restrict the utilization of disk storage host memory virtual machine memory a string table file descriptors network sockets and other types of resources.

As another example at operation the software container might limit the number of active releases that each tenant might have in the software container . As mentioned above the number of active releases of each tenant utilizes permanent generation and other types of resources. Accordingly by limiting the number of active releases that each tenant might have in the software container at one time exhaustion of these resources may be prevented.

As another example at operation tenants and or their objects and metadata might be unloaded based upon demand for the tenants . As discussed above for example idle tenants and or their objects and metadata might be swapped to disk and or another location in memory. When a request is received for a tenant that has been swapped out the tenant and or its objects may be reloaded and executed in order to process the incoming request. Tenants might also be moved to a different container or host computer based upon their utilization.

As another example at operation the ability of the tenants to create new processes external to the software container might be limited. As mentioned above the creation of new processes by a tenant might consume significant amounts of memory and or cause other problems. Accordingly in order to prevent this possibility the virtual machine and or the software container might be configured such that the tenants cannot create new processes. For example the ability of the tenants to execute native code might be restricted in order to prevent the tenants from creating new processes. Bytecode weaving and or a security manager might also be utilized to prevent tenants from creating new processes. Other mechanisms might also be utilized.

Other mechanisms might also be implemented at operation in order to prevent resource exhaustion by tenants executing in the multi tenant software container . For example and without limitation the entire multi tenant software container might be migrated to a different host computer. The routine ends at operation .

Tenants in a multi tenant software container might also throw errors that result in the software container or the virtual machine shutting down. In order to address this possibility bytecode weaving may be utilized to intercept these errors and make an appropriate response. For example depending upon the type of error it may be desirable to shut down the software container and or the virtual machine . For other types of errors it may not be necessary or desirable to shut down the software container or the virtual machine . Other types of actions might also be taken based upon the type of error thrown by a tenant of the multi tenant software container .

In order to implement this functionality bytecode weaving may be utilized to instrument an error and or any of its subclasses when a tenant or another component creates the error. When an error is generated the context that the error was generated in may be determined by examining a stack trace and or other information. Based upon the determined context the tenant or other component generating the error may be permitted to create the error or prevented from creating the error. If the tenant or other component is not permitted to create the error the tenant can be prevented from shutting down the virtual machine or taking other actions that might impact other tenants of the multi tenant software container .

Each tenant in a multi tenant software container has its own URI prefix or other type of identifier that clients may utilize to route to the tenant . Any tenant however can claim to have any arbitrary identifier e.g. URI prefix . Conflicts can arise therefore when two tenants in the same multi tenant container have the same identifier. In order to address this possibility an exception can be thrown when a tenant tries to utilize an existing identifier i.e. a URI prefix in use by another tenant in the same multi tenant software container . Other mechanisms might also be utilized to prevent tenants executing in the same multi tenant software container from obtaining identical identifiers. Other mechanisms might also be utilized to prevent other types of routing conflicts between tenants in the same multi tenant software container .

Tenants in the multi tenant software container may utilize native code e.g. assembly code in order to shut down the software container the virtual machine the operating system and or the host computer . Native code might also be utilized in other ways that may generate a fault or otherwise negatively impact other tenants executing in the same multi tenant software container . In order to address this possibility and potentially others the virtual machine may be configured to prevent tenants from loading native code. Alternatively native code utilized by tenants might be executed in a sandbox. In this way native code may be executed in a trusted manner but undesirable activities e.g. launching processes outside of the software container performed by the native code may be prohibited.

In some embodiments a tenant A of a multi tenant software container may be permitted to pass an object or a reference to an object to another tenant B in the same container . If the object is mutable and the calling tenant A maintains a reference to the object the calling tenant A can manipulate the passed object even after the called tenant B has performed its checks on the passed object. Manipulation of the passed object might however create problems with execution of the called tenant B. In order to address this possibility bytecode weaving might be utilized to make objects passed between tenants immutable. In this way the calling tenant A cannot manipulate a passed object once the object has been passed to the called tenant B. Other mechanisms might also be utilized in order to prevent tenants from passing mutable objects to other tenants in the same multi tenant software container .

A tenant might cause a fault impacting other tenants in the same multi tenant software container if the tenant causes the local file system to become read only. To prevent this possibility the virtual machine might be executed by a user that does not have permission to remount the local file system. Alternately or in addition thereto each tenant might be prohibited from running operating system shell commands that might be utilized to remount the local file system as read only. Other mechanisms might also be utilized to prevent tenants from causing the local file system to become read only.

In a similar manner the virtual machine might be executed by a user that does not have other types of permissions such as permissions to reconfigure a network interface or firewall. In this manner tenants might be prohibited from making other types of configuration changes that might impact the execution of other tenants in the same multi tenant software container . Additional details regarding these processes are provided below with regard to .

At operation various mechanisms might be implemented in order to prevent routing conflicts between tenants in a container . For example and without limitation different tenants in the same software container may be prevented from utilizing the same URI or other type of identifier. As mentioned above utilization of the same identifier by different tenants in the same software container might cause a fault condition due to routing conflicts. In order to address this possibility an exception can be thrown when a tenant tries to utilize an identifier that is currently in use by another tenant . Other mechanisms might also be utilized to prevent routing conflicts between tenants executing in the same multi tenant software container .

At operation tenants may be prohibited from executing native code e.g. assembly code . Alternately if it is desirable to permit tenants to execute native code the native code might be executed in a sandboxed environment that limits the ability of the native code to perform certain types of potentially harmful actions. Other mechanisms might also be utilized to permit the tenants to execute native code in a way not likely to cause a fault that might impact other tenants in the multi tenant software container .

At operation bytecode weaving or another suitable mechanism is utilized in order to make objects passed between tenants immutable. In this way one tenant cannot manipulate an object that has been passed to another tenant . Other mechanisms might also be utilized in order to prevent tenants from passing mutable objects to other tenants in the same multi tenant software container .

At operation tenants executing in the multi tenant software container may be prevented from making configuration changes to the software container the virtual machine the operating system and or the host computer that might cause a fault impacting other tenants in the software container . For example and as described above the tenants might be prevented from remounting the local file system as read only from reconfiguring a network interface on the host computer or reconfiguring a firewall implemented by the operating system . Various mechanisms might be utilized to prevent the tenants from making configuration changes some of which have been described above. Other mechanisms might also be described for preventing other types of fault conditions caused by tenants of a multi tenant software container . The routine ends at operation .

The computer includes a baseboard or motherboard which is a printed circuit board to which a multitude of components or devices may be connected by way of a system bus or other electrical communication paths. In one illustrative embodiment one or more central processing units CPUs operate in conjunction with a chipset . The CPUs are standard programmable processors that perform arithmetic and logical operations necessary for the operation of the computer .

The CPUs perform the necessary operations by transitioning from one discrete physical state to the next through the manipulation of switching elements that differentiate between and change these states. Switching elements may generally include electronic circuits that maintain one of two binary states such as flip flops and electronic circuits that provide an output state based on the logical combination of the states of one or more other switching elements such as logic gates. These basic switching elements may be combined to create more complex logic circuits including registers adders subtractors arithmetic logic units floating point units and the like.

The chipset provides an interface between the CPUs and the remainder of the components and devices on the baseboard. The chipset may provide an interface to a random access memory RAM used as the main memory in the computer . The chipset may further provide an interface to a computer readable storage medium such as a read only memory ROM or non volatile RAM NVRAM for storing basic routines that help to startup the computer and to transfer information between the various components and devices. The ROM or NVRAM may also store other software components necessary for the operation of the computer in accordance with the embodiments described herein.

According to various embodiments the computer may operate in a networked environment using logical connections to remote computing devices and computer systems through the network such as a LAN a WAN the Internet or any other networking topology known in the art that connects the computer to remote computers. The chipset includes functionality for providing network connectivity through a network interface controller NIC such as a gigabit Ethernet adapter. The NIC is capable of connecting the computer to other computing devices over the network . It should be appreciated that multiple NICs may be present in the computer connecting the computer to various types of networks and remote computer systems.

The computer may be connected to a mass storage device that provides non volatile storage for the computer . The mass storage device may store system programs application programs other program modules and data which are described in greater detail herein. The mass storage device may be connected to the computer through a storage controller connected to the chipset . The mass storage device may consist of one or more physical storage units. The storage controller may interface with the physical storage units through a serial attached SCSI SAS interface a serial advanced technology attachment SATA interface a fiber channel FC interface or other standard interface for physically connecting and transferring data between computers and physical storage devices.

The computer may store data on the mass storage device by transforming the physical state of the physical storage units to reflect the information being stored. The specific transformation of physical state may depend on various factors in different implementations of this description. Examples of such factors may include but are not limited to the technology used to implement the physical storage units whether the mass storage device is characterized as primary or secondary storage and the like. For example the computer may store information to the mass storage device by issuing instructions through the storage controller to alter the magnetic characteristics of a particular location within a magnetic disk drive unit the reflective or refractive characteristics of a particular location in an optical storage disk or the electrical characteristics of a particular capacitor transistor or other discrete component in a solid state storage unit. Other transformations of physical media are possible without departing from the scope and spirit of the present description with the foregoing examples provided only to facilitate this description. The computer may further read information from the mass storage device by detecting the physical states or characteristics of one or more particular locations within the physical storage units.

In addition to the mass storage device described above the computer may have access to other computer readable storage media to store and retrieve information such as program modules data structures or other data. It should be appreciated by those skilled in the art that computer readable storage media can be any available non transitory media that may be accessed by the computer . By way of example and not limitation computer readable storage media may include volatile and non volatile removable and non removable media implemented in any method or technology. Computer readable storage media includes RAM ROM erasable programmable ROM EPROM electrically erasable programmable ROM EEPROM flash memory or other solid state memory technology compact disc ROM CD ROM digital versatile disk DVD high definition DVD HD DVD BLU RAY or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium that can be used to store the desired information in a non transitory fashion.

The mass storage device may store an operating system utilized to control the operation of the computer . According to one embodiment the operating system comprises the LINUX operating system. According to another embodiment the operating system comprises the WINDOWS SERVER operating system from MICROSOFT Corporation of Redmond Wash. According to further embodiments the operating system may comprise the UNIX or SOLARIS operating systems. It should be appreciated that other operating systems may also be utilized. The mass storage device may store other system or application programs and data utilized by the computer . For example the mass storage device may store the virtual machine and the software container described above. The mass storage device might also store other programs and data not specifically identified herein.

In one embodiment the mass storage device or other computer readable storage media may be encoded with computer executable instructions that when loaded into the computer may transform the computer from a general purpose computing system into a special purpose computer capable of implementing the embodiments described herein. These computer executable instructions transform the computer by specifying how the CPUs transition between states as described above. According to one embodiment the computer may have access to computer readable storage media such as an optical disk a solid state storage device or a magnetic storage device storing computer executable instructions that when executed by the computer perform the various routine described above with regard to .

The computer might also include an input output controller for receiving and processing input from a number of input devices such as a keyboard a mouse a touchpad a touch screen an electronic stylus and or other type of input device. Similarly the input output controller may provide output to a display such as a computer monitor a flat panel display a digital projector a printer a plotter or other type of output device. It will be appreciated that the computer may not include all of the components shown in may include other components that are not explicitly shown in or may utilize an architecture completely different than that shown in .

Based on the foregoing it should be appreciated that various concepts and technologies for isolating tenants executing in multi tenant software containers have been presented herein. Although the subject matter presented herein has been described in language specific to computer structural features methodological acts and computer readable media it is to be understood that the invention defined in the appended claims is not necessarily limited to the specific features acts or media described herein. Rather the specific features acts and mediums are disclosed as example forms of implementing the claims.

1. A non transitory computer readable storage medium having computer executable instructions stored thereupon which when executed by a computer cause the computer to 

2. The non transitory computer readable storage medium of clause 1 wherein the one or more resources comprise one or more of disk space CPU cycles system memory permanent generation young generation old generation disk I O operations disk bandwidth network I O operations network bandwidth load balancer connections file descriptors processes or execution threads.

3. The non transitory computer readable storage medium of clauses 1 2 wherein the one or more actions to be taken with regard to the tenant that is utilizing resources in excess of the specified threshold comprise one or more of denying a resource request from the tenant redirecting a resource request evicting the tenant from the multi tenant software container moving the tenant to another multi tenant software container reducing CPU cycles allocated to the tenant pausing execution of the tenant or throttling execution of the tenant.

4. The non transitory computer readable storage medium of clauses 1 3 wherein the utilization of the one or more resources by the plurality of tenants is monitored by one or more of memory dumps or tracing tools.

5. The non transitory computer readable storage medium of clauses 1 4 wherein the bytecode weaving is performed at a virtual machine level and wherein interception is performed at an operating system level.

6. An apparatus for isolating the utilization of resources by a plurality of tenants executing in a multi tenant software container the apparatus comprising 

a computer readable storage medium having computer executable instructions stored thereupon which when executed by the processor cause the apparatus to

monitor the utilization of the resources by the plurality of tenants executing in the multi tenant software container and

take one or more actions with respect to a tenant of the plurality of tenants that utilizes a resource in excess of a specified threshold.

7. The apparatus of clause 6 wherein at least one of the resources comprises execution threads and wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the processor cause the apparatus to

maintain a per tenant counter for the plurality of tenants indicating a number of execution threads created by the plurality of tenants and

utilize the counter to prevent the plurality of tenants from creating threads in excess of a specified thread cap.

8. The apparatus of clause 7 wherein the counter is generated using one or more of bytecode weaving interception or tracing.

9. The apparatus of clauses 7 8 wherein at least one of the resources comprises execution threads and wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the processor cause the apparatus to

utilize the data to reap the execution threads created by a tenant if the tenant is removed from the multi tenant software container.

10. The apparatus of clauses 7 9 wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the processor cause the apparatus to

prevent the tenant from writing to a directory on the file system other than the directory that is associated with the tenant.

11. The apparatus of clauses 7 10 wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the processor cause the apparatus to

prevent the tenant from writing an amount of data to a file system in excess of the disk quota associated with the tenant.

12. The apparatus of clauses 7 11 wherein at least one of the resources comprises file descriptors and wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the processor cause the apparatus to

maintain a per tenant counter for the plurality of tenants indicating a number of file descriptors created by the plurality of tenants and

utilize the counter to prevent the plurality of tenants from creating file descriptors in excess of a specified file descriptor cap.

13. The apparatus of clauses 7 12 wherein at least one of the resources comprises memory and wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the processor cause the apparatus to

maintain a per tenant counter for the plurality of tenants indicating an amount of memory utilized by the plurality of tenants and

utilize the counter to prevent the plurality of tenants from utilizing memory in excess of a specified cap.

14. The apparatus of clauses 7 13 wherein the per tenant counter is generated by bytecode weaving a virtual machine and wherein the memory comprises one or more of permanent generation young generation or old generation.

15. The apparatus of clauses 7 14 wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the processor cause the apparatus to execute the tenants in individual shadow environments in order to monitor the utilization of the resources by the plurality of tenants.

16. A computer implemented method for isolating the utilization of one or more resources by a plurality of tenants executing in a multi tenant software container the method comprising 

monitoring the utilization of the one or more resources by the plurality of tenants executing in the multi tenant software container and

causing one or more actions to be taken with respect to a tenant of the plurality of tenants that utilizes a resource of the one or more resources in excess of a specified threshold.

17. The computer implemented method of clause 16 wherein the monitoring is performed by using one or more of bytecode weaving interception shadow environments memory dumps or tracing tools.

18. The computer implemented method of clauses 16 17 wherein the one or more resources comprise one or more of disk space CPU cycles system memory permanent generation young generation old generation disk I O operations disk bandwidth network I O operations network bandwidth load balancer connections file descriptors or execution threads.

19. The computer implemented method of clauses 16 18 wherein the one or more actions to be taken with regard to the tenant that utilizes a resource in excess of the specified threshold comprise one or more of denying a resource request from the tenant evicting the tenant from the multi tenant software container reducing CPU cycles allocated to the tenant pausing execution of the tenant or throttling execution of the tenant.

20. The computer implemented method of clauses 16 19 wherein the bytecode weaving is performed at a virtual machine level and wherein interception is performed at an operating system level.

1. A non transitory computer readable storage medium having computer executable instructions stored thereupon which when executed by a computer cause the computer to 

in response to receiving the request to load the class from the tenant determine whether the class is a shared class that is shared between two or more tenants executing in the multi tenant software container for which loading is to be delegated to a container classloader 

in response to determining that the class is not a shared class for which loading is to be delegated to the container classloader loading the class by way of the tenant classloader and

in response to determining that the class is a shared class for which loading is to be delegated to the container classloader delegating loading of the class to the container classloader.

2. The non transitory computer readable storage medium of clause 1 wherein determining whether the class is a shared class for which loading is to be delegated to a container classloader comprises examining a package containing the class to determine if the class is a shared class for which loading is to be delegated to the container classloader.

3. The non transitory computer readable storage medium of clauses 1 2 wherein the shared class comprises a class for enabling communication between the tenant and another tenant executing in the multi tenant software container.

4. The non transitory computer readable storage medium of clauses 1 3 wherein the shared class comprises a class for enabling communication between the tenant and the multi tenant software container.

5. The non transitory computer readable storage medium of clauses 1 4 having further computer executable instructions stored thereupon which when executed by the computer cause the computer to 

implement bytecode weaving within the tenant classloader to modify the class loaded by the tenant classloader.

6. The non transitory computer readable storage medium of clauses 1 5 having further computer executable instructions stored thereupon which when executed by the computer cause the computer to 

implement bytecode weaving within the container classloader to modify the shared class loaded by the container classloader.

7. The non transitory computer readable storage medium of clauses 1 6 wherein a bootstrap classloader comprises a parent classloader for the tenant classloader and the container classloader.

8. The non transitory computer readable storage medium of clauses 1 7 wherein the tenant classloader and the container classloader have no parent classloader.

9. An apparatus for dependency isolation between two or more tenants executing in a multi tenant software container the apparatus comprising 

a computer readable storage medium having computer executable instructions stored thereupon which when executed by the processor cause the apparatus to

in response to receiving the request from the tenant to load the class determine whether the class is a shared class 

in response to determining that the class is not a shared class loading the class by way of a tenant classloader and

in response to determining that the class is a shared class loading the class by way of a container classloader.

10. The apparatus of clause 9 wherein the tenant classloader is configured to receive the request from the tenant to load the class and to delegate loading of the class to the container classloader in response to determining that the class is a shared class.

11. The apparatus of clauses 9 10 wherein the determination as to whether the class is a shared class is made by examining a package containing the class to determine if the class is a shared class for which loading is to be delegated to the container classloader.

12. The apparatus of clauses 9 11 wherein the shared class comprises a class for enabling communication between the tenant and another tenant executing in the multi tenant software container or a class for enabling communication between the tenant and the multi tenant software container.

13. The apparatus of clauses 9 12 wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the processor cause the apparatus to 

implement bytecode weaving within the tenant classloader to modify the class loaded by the tenant classloader or

implement bytecode weaving within the container classloader to modify the shared class loaded by the container classloader.

14. The apparatus of clauses 9 13 wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the processor cause the apparatus to 

execute a security manager configured to prevent the tenant from loading unshared classes associated with a second tenant.

15. The apparatus of clauses 9 14 wherein the container classloader comprises a tenant of the multi tenant software container.

16. A computer implemented method for providing dependency isolation between two or more tenants executing in a multi tenant software container the method comprising 

in response to receiving the request determining if the class is a shared class that is shared between two or more tenants of the multi tenant container 

loading the class using a first classloader in response to determining that the class is not a shared class and

loading the class using a second classloader in response to determining that the class is a shared class.

17. The computer implemented method of clause 16 wherein the first classloader comprises a tenant classloader associated with the tenant and wherein the second classloader comprises a container classloader.

18. The computer implemented method of clauses 16 17 wherein determining if the class is a shared class that is shared between two or more tenants of the multi tenant container comprises examining a package containing the class to determine if the class is a shared class.

19. The computer implemented method of clauses 16 18 wherein the shared class comprises a class for enabling communication between the tenant and another tenant executing in the multi tenant software container or a class for enabling communication between the tenant and the multi tenant software container.

implementing bytecode weaving within the first classloader to modify the class loaded by the first classloader and

implementing bytecode weaving within the second classloader to modify the shared class loaded by the second classloader.

1. A non transitory computer readable storage medium having computer executable instructions stored thereupon which when executed by a computer cause the computer to 

generate an access request from the first tenant of the multi tenant software container to the second tenant of the multi tenant software container the access request comprising the trusted identity associated with the first tenant and

determine based at least in part on the access policy for the second tenant and the trusted identity of the first tenant whether to grant the access request received from the first tenant.

2. The non transitory computer readable storage medium of clause 1 wherein a framework in the multi tenant software container is configured to determine whether to grant the access request received from the first tenant.

3. The non transitory computer readable storage medium of clauses 1 2 wherein the second tenant is configured to determine whether to grant the access request received from the first tenant.

4. The non transitory computer readable storage medium of clauses 1 3 having further computer executable instructions stored thereupon which when executed by the computer cause the computer to 

receive an access request from a client external to the multi tenant software container directed to the second tenant of the multi tenant software container the access request comprising a trusted identity associated with the client and

determine based at least in part on the access policy for the second tenant and the trusted identity associated with the client whether to grant the access request received from the client external to the multi tenant software container.

5. The non transitory computer readable storage medium of clauses 1 4 having further computer executable instructions stored thereupon which when executed by the computer cause the computer to 

generate an access request from the first tenant of the multi tenant software container to a service external to the multi tenant software container the access request comprising the trusted identity associated with the first tenant whereby

the service external to the multi tenant software container can determine whether to grant the access request received from the first tenant based at least in part on the trusted identity associated with the first tenant.

6. The non transitory computer readable storage medium of clauses 1 5 having further computer executable instructions stored thereupon which when executed by the computer cause the computer to 

receive an access policy for one or more host resources container resources or virtual machine resources 

receive an access request from the first tenant of the multi tenant software container to utilize one or more of the host resources container resources or virtual machine resources the access request comprising the trusted identity associated with the first tenant and

determine based at least in part on the trusted identity associated with the first tenant and the access policy for the one or more host resources whether to grant access to the one or more host resources container resources or virtual machine resources to the first tenant of the multi tenant software container.

7. An apparatus for security isolation of tenants executing in a multi tenant software container the apparatus comprising 

a computer readable storage medium having computer executable instructions stored thereupon which when executed by the processor cause the apparatus to

receive a request to access a tenant of the multi tenant software container from a client external to the multi tenant software container 

determine whether a trusted identity is required to perform the requested access the tenant of the multi tenant software container 

in response to determining that a trusted identity is required to perform the requested access determine whether to grant the request for access received from the client external to the multi tenant software container based at least in part on an access policy for the tenant and a trusted identity associated with the client received with the request to access the tenant and

in response to determining that a trusted identity is not required to perform the requested access granting the request to access the tenant of the multi tenant software container.

8. The apparatus of clause 7 wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the processor cause the apparatus to 

generate a request to access the second tenant the request comprising the trusted identity associated with the tenant and

determine based at least in part on the access policy for the second tenant and the trusted identity of the tenant whether to grant the request to access the second tenant.

9. The apparatus medium of clauses 7 8 wherein a framework in the multi tenant software container is configured to determine whether to grant the access request received from the first tenant and to grant the request for access received from the client.

10. The apparatus of clauses 7 9 wherein the second tenant is configured to determine whether to grant the access request received from the first tenant.

11. The apparatus of clauses 7 10 wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the computer cause the computer to 

generate a request from the tenant to access a service external to the multi tenant software container the request comprising the trusted identity associated with the tenant and

wherein the service external to the multi tenant software container is configured to determine whether to grant the access request received from the tenant based at least in part on the trusted identity associated with the first tenant.

12. The apparatus of clauses 7 11 wherein the computer readable storage medium has further computer executable instructions stored thereupon which when executed by the computer cause the computer to 

receive a request from the tenant to utilize one or more of the resources the request comprising the trusted identity associated with the tenant and

determine based at least in part on the trusted identity associated with the tenant and the access policy for the one or more resources whether to grant the request received from the tenant to access to the one or more resources.

13. The apparatus of clauses 7 12 wherein the access policy for the tenant the access policy for the second tenant and the access policy for the one or more resources are provided by a service external to the multi tenant software container.

14. The apparatus of clauses 7 13 wherein the one or more resources comprise one or more host resources container resources or virtual machine resources.

15. A computer implemented method for security isolation of tenants executing in a multi tenant software container the method comprising 

generating an access request from a first tenant executing in the multi tenant software container the access request comprising the trusted identity associated with the first tenant and

determining whether to grant the access request generated by the first tenant based at least in part on an access policy and the trusted identity associated with the first tenant.

16. The computer implemented method of clause 15 wherein the access request comprises a request to access a second tenant of the multi tenant software container and wherein a framework in the multi tenant software container is configured to determine whether to grant the access request.

17. The computer implemented method of clauses 15 16 wherein the access request comprises a request to access a second tenant of the multi tenant software container and wherein the second tenant is configured to determine whether to grant the access request.

18. The computer implemented method of clauses 15 17 wherein the access request comprises a request to access a service external to the multi tenant software container and wherein the service external to the multi tenant software container is configured to determine whether to grant the access request.

19. The computer implemented method of clauses 15 18 wherein the access request comprises a request to access host resources container resources or virtual machine resources.

receiving a request to access a tenant of the multi tenant software container from a client external to the multi tenant software container the request comprising a trusted identity associated with the client and

determining based at least in part on an access policy for the tenant and the trusted identity associated with the client whether to grant the request for access received from the client external to the multi tenant software container.

1. A non transitory computer readable storage medium having computer executable instructions stored thereupon which when executed by a computer cause the computer to 

implement one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container the mechanisms comprising one or more of

preventing the tenants from shutting down the software container a virtual machine an operating system or a host computer 

2. The non transitory computer readable storage medium of clause 1 wherein the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container further comprise restricting an ability of the tenants to create new processes.

3. The non transitory computer readable storage medium of clauses 1 2 wherein the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container further comprise dynamically unloading a tenant from memory based upon utilization of the tenant.

4. The non transitory computer readable storage medium of clauses 1 3 wherein the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container further comprise 

5. The non transitory computer readable storage medium of clauses 1 4 wherein the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container further comprise preventing two of the plurality of tenants in a multi tenant software container from utilizing the same uniform resource identifier URI .

6. The non transitory computer readable storage medium of clauses 1 5 wherein the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container further comprise making objects passed between the tenants immutable.

7. The non transitory computer readable storage medium of clauses 1 6 wherein the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container further comprise preventing the tenants from making configuration changes to the software container a virtual machine an operating system or the host computer.

8. An apparatus for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container the apparatus comprising 

a computer readable storage medium having computer executable instructions stored thereupon which when executed by the processor cause the apparatus to

implement one or more mechanisms in conjunction with the execution of the plurality of tenants to prevent a fault from being caused by one of the tenants of the multi tenant software container that would impact another tenant of the multi tenant software container.

9. The apparatus of clause 8 wherein at least one of the mechanisms for preventing a fault from being caused by one of the tenants of the multi tenant software container that would impact another tenant of the multi tenant software container comprises preventing the tenants from shutting down the software container a virtual machine an operating system or a host computer.

10. The apparatus of clauses 8 9 wherein at least one of the mechanisms for preventing a fault from being caused by one of the tenants of the multi tenant software container that would impact another tenant of the multi tenant software container comprises limiting a number of active releases of each tenant executing in the software container.

11. The apparatus of clauses 8 10 wherein at least one of the mechanisms for preventing a fault from being caused by one of the tenants of the multi tenant software container that would impact another tenant of the multi tenant software container comprises restricting an ability of the tenants to execute native code.

12. The apparatus of clauses 8 11 wherein at least one of the mechanisms for preventing a fault from being caused by one of the tenants of the multi tenant software container that would impact another tenant of the multi tenant software container dynamically unloading a tenant from memory based upon utilization of the tenant.

13. The apparatus of clauses 8 12 wherein at least one of the mechanisms for preventing a fault from being caused by one of the tenants of the multi tenant software container that would impact another tenant of the multi tenant software container comprises 

14. The apparatus of clauses 8 13 wherein at least one of the mechanisms for preventing a fault from being caused by one of the tenants of the multi tenant software container that would impact another tenant of the multi tenant software container comprises preventing two of the plurality of tenants in a multi tenant software container from utilizing the same identifier.

15. A computer implemented method for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container the method comprising 

implementing one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container.

16. The computer implemented method of clause 15 wherein at least one of the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container comprises making one or more objects passed between the tenants immutable.

17. The computer implemented method of clauses 15 16 wherein at least one of the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container comprises preventing the tenants from making configuration changes to the software container to a virtual machine to an operating system or to a host computer executing the multi tenant software container.

18. The computer implemented method of clauses 15 17 wherein at least one of the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container comprises preventing the tenants from shutting down the software container a virtual machine an operating system or a host computer.

19. The computer implemented method of clauses 15 18 wherein at least one of the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container comprises limiting a number of active releases of each tenant executing in the software container.

20. The computer implemented method of clauses 15 19 wherein at least one of the one or more mechanisms for preventing a fault caused by one of the tenants of the multi tenant software container from impacting another tenant of the multi tenant software container comprises restricting an ability of the tenants to execute native code.

The subject matter described above is provided by way of illustration only and should not be construed as limiting. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure. Various modifications and changes may be made to the subject matter described herein without following the example embodiments and applications illustrated and described and without departing from the true spirit and scope of the present invention which is set forth in the following claims.

