---

title: Systems and methods for automatically connecting a user of a hands-free intercommunication system
abstract: A hands-free intercom may include a user-tracking sensor, a directional microphone, a directional sound emitter, and a communication interface. The user-tracking sensor may determine a location of a user so the directional microphone can measure vocal emissions by the user and the directional sound emitter can deliver audio to the user. The hands-free intercom may determine whether the user is communicatively coupled via a mobile device to a remote entity. The hands-free intercom may be configured to receive a handoff of the communicative coupling, for example, by acting as a peripheral of the mobile device, by requesting the handoff, and/or the like. The hands-free intercom may be configured to deliver communications from the user to an appliance and vice versa. The hands-free intercom may manage access rights of the various entities to prevent unauthorized communications.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09565284&OS=09565284&RS=09565284
owner: ELWHA LLC
number: 09565284
owner_city: Bellevue
owner_country: US
publication_date: 20140416
---
If an Application Data Sheet ADS has been filed on the filing date of this application it is incorporated by reference herein. Any applications claimed on the ADS for priority under 35 U.S.C. 119 120 121 or 365 c and any and all parent grandparent great grandparent etc. applications of such applications are also incorporated by reference including any priority claims made in those applications and any material incorporated by reference to the extent such subject matter is not inconsistent herewith.

The present application claims the benefit of the earliest available effective filing date s from the following listed application s the Priority Applications if any listed below e.g. claims earliest available priority dates for other than provisional patent applications or claims benefits under 35 USC 119 e for provisional patent applications for any and all parent grandparent great grandparent etc. applications of the Priority Application s .

If the listings of applications provided above are inconsistent with the listings provided via an ADS it is the intent of the Applicant to claim priority to each application that appears in the Domestic Benefit National Stage Information section of the ADS and to each application that appears in the Priority Applications section of this application.

All subject matter of the Priority Applications and of any and all applications related to the Priority Applications by priority claims directly or indirectly including any priority claims made and subject matter incorporated by reference therein as of the filing date of the instant application is incorporated herein by reference to the extent such subject matter is not inconsistent herewith.

This application relates to systems and methods for automatically handing off calls to a hands free intercommunication system.

A hands free intercommunication system hands free intercom may be able to communicatively couple a user to an entity of interest without requiring a tactile input and or a specific verbal phrase. The hands free intercom may be able to determine from gestures and or vocal emissions with whom the user wishes to speak. For example the hands free intercom may determine the entity of interest from the subject matter of the vocal emissions a tone of voice an uttered name a spoken command and or the like. A communication interface may be configured to communicatively couple the user to a communication device of the entity of interest. The communication interface may determine an optimal communication device of the entity of interest with which to communicatively couple.

The hands free intercom may include a directional microphone to receive vocal emissions from the user and a directional sound emitter to deliver audio to the user. The communication interface may communicatively couple the directional microphone and directional sound emitter to the communication device of the entity of interest to allow the user and entity of interest to communicate. The hands free intercom may also include a user tracking sensor configured to determine the location of the user. The directional microphone and directional sound emitter may target the user based on the location determined by the user tracking sensor. The directional microphone may include a phased array and or a metamaterial array to permit gain to be maximized in the direction of the user without any moving parts. The directional sound emitter may be configured to emit ultrasonic sound waves towards the user. The emitted ultrasonic sound waves may be configured to frequency convert to produce audio that is audible by the user. The frequency conversion may be produced by beating a plurality of ultrasonic sound waves together by downshifting the ultrasonic sound waves in the air and or in or on a material on the user and or the like.

The hands free intercom may determine whether a remote entity requesting to communicatively couple with the user should be allowed to do so. The hands free intercom may apply access rules based on context data which may include data about the remote entity sensing of the user data from one or more computer systems and or the like. The hands free intercom may decide whether to automatically couple the remote entity automatically refuse to couple the remote entity prompt the user about the remote entity and or the like. The hands free intercom may refuse connections for example if the user is sleeping if another person is present with the user and or the like. The hands free intercom may monitor for eavesdroppers and may warn the user of an eavesdropper and or refuse to communicatively couple the user while the eavesdropper is present.

The hands free intercom may be configured to automatically receive call handoffs from mobile communication devices. A user may be communicatively coupled to a remote entity via a mobile communication device of the user. To hand off the call the directional microphone and or directional sound emitter may be communicatively coupled to a communication device of the remote entity. The directional microphone and or directional sound emitter may be communicatively coupled to the mobile communication device of the user which may remain coupled to the remote entity. Alternatively the communication interface may communicatively couple with the remote entity without sending communications via the mobile communication device of the user. The user may indicate through vocal emissions and or gestures that the communicative coupling should be handed off the mobile communication device may indicate the communicative coupling should be handed off the communication interface may automatically determine that the communicative coupling should be handed off e.g. anytime the user is in range and or the like.

The hands free intercom may be configured to automatically communicatively couple a user to an appliance. The communication interface may be configured to communicatively couple the directional microphone and or the directional sound emitter to the user. The user may indicate that the user would like to be communicatively coupled with the appliance though vocal emissions gestures and or the like. The communication interface may deliver notifications from the appliance to the user. The communication interface may allow the user to send and or receive communications via a mobile communication device. The communication interface may translate communications from appliances to be understandable by users and or from user to be understandable by appliances. The communication interface may communicatively couple appliances with one another.

The communication interface may manage access rights between users and or appliances. The communication interface may determine which users may access the appliances and what privileges they have when access is permitted. The communication interface may determine when and or if an appliance is permitted to send notifications to the user. The communication interface may determine when communication between an appliance and a mobile communication device are permitted. The communication interface may determine whether appliances are permitted to communicate with one another.

The foregoing summary is illustrative only and is not intended to be in any way limiting. In addition to the illustrative aspects embodiments and features described above further aspects embodiments and features will become apparent by reference to the drawings and the following detailed description.

In the following detailed description reference is made to the accompanying drawings which form a part hereof. In the drawings similar symbols typically identify similar components unless context dictates otherwise. The illustrative embodiments described in the detailed description drawings and claims are not meant to be limiting. Other embodiments may be utilized and other changes may be made without departing from the spirit or scope of the subject matter presented here.

A conventional intercom may be able to communicatively couple users e.g. occupants of a building occupants of a vehicle etc. to each other via a plurality of user interfaces. Unfortunately the intercom may require a tactile input to specify a desired interface rather than being able to determine a desired user based on a non tactile input such as a gesture or a verbal input. The intercom may require the user to wear or carry communication equipment such as a microphone a speaker or a wireless transceiver. The intercom may also be unable to interact with other systems such as cell phone networks computer networks local appliances local computers and or the like and thus may only be able to interact with entities via the user interfaces. The intercom may also require the user to select which device to communicate with rather than the intercom automatically selecting the communication device based on the user to be contacted. The intercom may lack access and privacy control. For example the intercom may connect a remote entity to the user regardless of the time who is with the user the identity of the remote entity etc. The intercom may not protect against eavesdroppers or keep conversations private from others near the user. Therefore there is a need for an improved intercom that remedies these deficiencies.

A hands free intercom may include a user tracking sensor to determine a location of a user a directional microphone configured to target the user and measure vocal emissions by the user a directional sound emitter configured to target the user and deliver audio to the user and a communication interface configured to communicatively couple the user to an entity of interest e.g. by communicatively coupling the directional microphone and directional sound emitter to a communication device of the entity of interest . The directional microphone and directional sound emitter may be located remote from the user. The directional microphone and directional sound emitter may be wirelessly coupled to the communication interface wired to the communication interface and or the like. The directional microphone may include a phased array a metamaterial array e.g. an acoustic analog of metamaterial surface antenna technology and or the like. The directional microphone and the directional sound emitter may receive an indication of the location of the user from the user tracking sensor and may target the indicated location for measurement of vocal emissions and delivery of audio. The directional microphone and or directional sound emitter may move focal direction as the user moves to track the user. The directional sound emitter may be configured to emit ultrasonic sound waves configured to frequency convert to produce desired sounds that are audible to the user. The ultrasonic waves by virtue of their short wavelengths can be selectively directed and focused to the user without spreading to other regions in some embodiments different ultrasonic waves can be directed to the left and right ears of the user. For example the ultrasonic sound waves may be premodulated with audible frequency signals and then be nonlinearly frequency downshifted in the air and or frequency downshifted in a nonlinear acoustic material in or on the user e.g. natural tissue near the ear or nonlinear material in an earpiece so as to produce audible sounds. The premodulation can be selected such that the audible sounds produced following the nonlinear frequency downshifting form desired sounds e.g. intelligible human speech. Alternatively or in addition a plurality of ultrasonic sound waves may be beat together to frequency convert to the desired frequency. For instance a 100 kHz wave can be beat together in a nonlinear material e.g. air tissue or an earpiece with a modulated beam having frequencies of 102 120 kHz to generate audible sounds with frequencies between 2 kHz and 20 kHz.

The communication interface may identify the entity of interest based on a non tactile input received from the user. In an embodiment the user tracking sensor and or an associated camera may detect a gesture by the user indicative of the entity of interest. For instance the user may employ 8 different gestures to identify eight different entities of interest. In one embodiment the user may use fingers or other gestures to display numbers or letters which identify the entities of interest e.g. from a list . In another embodiment the user may simply use a pointing gesture to identify a nearby entity of interest. The gestures may include purposely employed facial expressions such as a blink a purposely raised eyebrow etc. For example a user with a disability may be able to use a facial gesture rather than an arm or hand gesture.

Alternatively or in addition the directional microphone may receive vocal emissions from which the communication interface identifies the entity of interest. For example the vocal emissions may include a spoken command a name of the entity of interest and or the like and or the communication interface may identify the entity of interest based on a tone of voice a subject matter of the vocal emission and or the like. Such identifiers need not be by themselves globally unique but can serve to identify the entity of interest from a limited list of likely entities of interest. For example if the user has only one acquaintance named Sam he can identify him by Sam rather than by Samuel James Tyler. Or if he has 5 acquaintances named William the phrase Bill what did you think of yesterday s meeting may be sufficient to identify the specific entity of interest based on the partial name and the joint attendance at a defined meeting. The communication interface may be configured to add additional participants based on vocal emissions and or gestures by the user which may be used with any or all of the previous discussed methods of identifying the entity of interest.

The communication interface may perform one or more speech recognition algorithms on the vocal emissions to identify the subject matter of the vocal emissions. The communication interface may track one or more previous subject matters of one or more previous conversations and or may store one or more keywords from one or more previous conversations which may then be used to identify the entity of interest. There may be one or more than one subject matter and or keyword per conversation and or a subject matter and or keyword may be associated with multiple conversations. The communication interface may gather information from an external source e.g. a website such as a social media site and or the like to identify the entity of interest. The communication interface may identify the entity of interest based on a recency in time of a previous conversation. The communication interface may simply select a most recent conversation may weight conversations based on recency and relevance and or the like. The communication interface may select the entity of interest based on a single most relevant and or recent conversation and or based on a plurality of conversations with the entity of interest. The communication interface may identify the entity of interest based on a physical proximity to the user e.g. the entity of interest is in an adjacent room a location of the entity of interest determined by a satellite positioning system etc. . The communication interface may identify the entity of interest based upon a calendar of the user e.g. based on the time of a scheduled conversation the relative order of several scheduled conversations or the like.

The communication interface may analyze the subject matter of the vocal emissions and or previous conversations using a language analysis algorithm. In an embodiment the communication interface may weight the results from a plurality of language analysis algorithms to determine the subject matter of the vocal emissions and or previous conversations. The communication interface may reject an identification of the entity of interest if a confidence score is below a predetermined threshold. If the identification is rejected the communication interface may prompt the user to specify the entity of interest. The communication interface may suggest a most likely candidate e.g. one with a highest confidence score when prompting the user. In an embodiment the communication interface may use the language of the vocal emissions to help identify the entity of interest.

The communication interface may be configured to identify the entity of interest solely in response to the vocal emissions without the hands free intercom first receiving a tactile input. Alternatively or in addition the communication interface may determine whether the user would like to communicate using the hands free intercom without first receiving a predetermined phrase. The communication interface may determine whether the user is talking to an entity other than the user s self e.g. based on the subject matter of the user s utterances. The communication interface may determine whether the user is talking to a nonresponsive object such as a plant.

The communication interface may be configured to determine whether or not the entity of interest is within listening range of the user and may communicatively couple the user to the entity of interest if the entity of interest is not within listening range. The communication interface may determine whether the entity of interest is within listening range based on responsive vocal emissions and or the lack thereof by the entity of interest. The communication interface may determine whether the entity of interest is within listening range based on responsive motion from the entity of interest e.g. head motion body motion eye motion etc. . The communication interface may determine whether the entity of interest is within listening range based on a measured volume of the vocal emissions e.g. a volume measured by a directional microphone near the user a volume measured by a directional microphone near the entity of interest etc. . The communication interface may determine whether the entity of interest is within listening range based on whether entities of interest were able to hear vocal emissions by the user in previous instances under similar circumstances.

The communication interface may select the entity of interest from among one or more entities being tracked by the user tracking sensor and or a plurality of user tracking sensors. The user tracking sensor and or plurality of user tracking sensors may occupy a plurality of locations and or structures. The communication interface may select the entity of interest from among one or more entities that nominally occupy a structure such as a structure containing the hands free interface. The communication interface may select the entity of interest from among one or more entities on a contact list such as a cell phone contact list a member employee list for an organization and or the like and or from among a user identified set of entities from the contact list e.g. a set smaller than the entire contact list . The communication interface may select the entity of interest from among family members of the user. In some embodiments the entity of interest may be a domesticated animal such as a pet. The communication interface may select the entity of interest from among frequently contacted entities. The communication interface may identify the user for example based on a spoken name vocal characteristics a code phrase facial recognition and or the like. The entity of interest may be identified based on which user is using the hands free intercom.

The communication interface may be configured to determine the communication device to which to couple based on an identity of the entity of interest a location of the entity of interest and or the like. The communication interface may be configured to determine whether the entity of interest is located in a structure containing the hands free intercom a structure containing another hands free intercom a home a workplace a vehicle and or the like. The communication interface may be configured to determine whether the entity of interest is accessible via a computer system such as if the entity of interest is logged into a computer communication service. The communication interface may be configured to determine whether a mobile communication device of the entity of interest e.g. a cell phone tablet etc. is communicatively coupled to a wireless network. If the communication device is external to the hands free intercom external to a structure in which the user is located and or the like the communication interface may encrypt the communicative coupling.

The communication device of the entity of interest may be part of the hands free intercom. For example another directional microphone and another directional sound emitter may couple the entity of interest to the user. The communication interface may locate the entity of interest using the user tracking sensor. For example the user tracking sensor may identify the entity of interest based on a gait a breathing sound a breathing rate facial recognition and or the like. The communication interface may locate the entity of interest based on a location of a mobile communication device of the entity of interest for example by detecting the location of wireless transmission by the mobile communication device by receiving the location from the mobile communication device by using a phone number of the mobile communications device and or the like. The communication interface may locate the entity of interest based on a beacon coupled to the entity of interest such as a beacon configured to transmit a signal e.g. a radio frequency signal an infrared signal an electromagnetic signal an ultrasonic signal etc. a beacon configured to distinctively reflect a signal and or the like. The communication interface may locate the entity of interest by tracking which doorways the entity of interest has traversed e.g. by tracking the last doorway traversed by the entity of interest . The hands free intercom may include sensors configured to detect passage of the entity of interest through doorways. Once the entity of interest is located the communication interface may couple the user to a directional microphone and directional sound emitter closest to the entity of interest. Alternatively the communication interface may couple the user to a cell phone work phone internet phone or communication service and or the like for example if the entity of interest is not near a user interface of the hands free intercom. Accordingly the communications interface may connect to the entity of interest s communication device via an existing communications network such as a cellular network a Wi Fi network the internet a wired network a wireless network etc. In an embodiment the communication device of the entity of interest can interact with the user s communication interface without consideration that the user is employing a hands free intercom e.g. just as it would interact with a wired or wireless phone.

The communication interface may be configured to summon the entity of interest to a nearest communication device. The communication interface may summon the entity of interest by playing a loud undirected sound such as a name vocal emissions from the user a tone etc. from a sound emitter nearest the entity of interest by transmitting a text message by transmitting an email and or the like. The communication device may receive a communications request from the communications interface and may summon the entity of interest via summoning signals from the device such as ringtones vibrations lights etc. The communication device may include a mobile communication device the hands free intercom another hands free intercom a computer system and or the like.

The communication interface may be configured to determine the availability of the entity of interest. The communication interface may report the determined availability to the user e.g. using a visual indication an audible indication etc. . In some embodiments the determined availability may be reported only if the entity of interest is unavailable. The availability may include available occupied in a call and or the like. The communication interface may update the user on the availability of the entity of interest when the availability changes.

The communication interface may be configured to record vocal emissions from the user e.g. the vocal emissions used to identify the entity of interest and deliver the recorded vocal emissions after identification of the entity of interest. In some embodiments the communication interface may strip out identification phrases before delivering the body of the message. In other embodiments the identification material forms part of the body of the message and can be analyzed used to identify and connect to the entity of interest and then delivered to him. The communication interface may disguise a connection delay from being observable by the entity of interest. The communication interface may deliver an audio indication to the user prior to delivery of the recorded vocal emissions to the entity of interest. The audio indication may include a contact status indicator associated with the communication device such as a ringing a sound a busy sound and or the like. The communication interface may be configured to mute pause terminate etc. the communicative coupling responsive to a vocal command by the user a gesture by the user e.g. a facial gesture an arm gesture a hand gesture etc. and or the like. The communication interface may also or instead be configured to mute pause terminate etc. the communicative coupling responsive to a command from the entity of interest such as a vocal command an electronic signal from the communication device and or the like. The hands free intercom may indicate to the user when the communicative coupling is paused and or terminated.

The communication interface may receive a request from a remote entity to communicatively couple to the user. The communication interface may determine whether to couple the remote entity to the user for example based on one or more access rules. The communication interface may determine whether to couple the remote entity to the user based on which room the user is occupying e.g. a bedroom a bathroom an office a kitchen etc. based on an activity of the user e.g. an activity determined by the user tracking sensor based on a time of day based on a day of the week and or the like. In an embodiment the access rules may include room specific time restrictions. The communication interface may be configured to determine whether to couple the remote entity to the user based on an identity of the remote entity. For example the communication interface may connect the remote entity without prompting refuse the request to couple prompt the user on whether to couple and or the like depending on the identity of the remote entity. The communication interface may determine whether to couple the remote entity to the user based on an identity of the user.

The communication interface may determine whether to couple the remote entity by prompting the user and or the communication interface may determine whether to prompt the user based on access rules. The user may accept the communicative coupling with a vocal command a gesture e.g. a facial gesture an arm gesture a hand gesture etc. and or the like. The user may be able to accept a communication without speaking or even responding to the communication. For example the remote entity may deliver a communication without expecting a response and or the user may be unable to respond to communications. In an embodiment the user may be an appliance and the communication interface may determine whether the remote entity can couple to the appliance. In an embodiment the remote entity may be an appliance and the communication interface may determine whether the user can couple to the appliance e.g. whether he is authorized to do so .

The communication interface may be configured to determine whether to couple the remote entity to the user based on a subject matter of the request an urgency level a user status received from an electronic calendar an indication of user availability received from the user and or the like. The communication interface may be configured to prompt the user periodically to update the indication of user availability when the user has indicated unavailability. The communication interface may receive an indication of a user specified period for prompting at the time the user indicates unavailability. The communication interface may determine whether to couple the remote entity to the user based on whether the user is alone based on an identity of a person near the user based on a relationship between the remote entity and the person near the user based on a relationship between a subject matter and the person near the user and or the like. The communication interface may be configured to determine whether to forward the request to a user device when the user is out of range of the sound emitter. The communication interface may determine whether to forward the request based on the user device to which the request would be forwarded based on an identity of the remote entity and or the like.

The user tracking sensor may be configured to detect an eavesdropper. The hands free intercom may warn the user when an eavesdropper is present. The hands free intercom may produce an audio indication that an eavesdropper is present e.g. a tone a buzz a vocal indication etc. a visual indication that an eavesdropper is present e.g. a light etc. and or the like. The communication interface may refuse to communicatively couple when an eavesdropper is present. The user tracking sensor may be configured to detect eavesdroppers in the same room as the user to detect eavesdroppers within a listening range of the user e.g. to detect eavesdroppers outside a doorway of a room with the user and or the like. The user tracking sensor may be configured to continuously monitor for eavesdroppers during communicative coupling.

The hands free intercom may be configured to automatically receive call handoffs for example from mobile communication devices. The communication interface may be configured to determine the user is communicatively coupled to a remote entity via a mobile communication device of the user. The communication interface may be configured to communicatively couple the directional microphone and or the directional sound emitter to a communication device of the remote entity.

In an embodiment the communication interface may be configured to communicatively couple the directional microphone and or the directional sound emitter to the user s mobile communication device to communicatively couple them with the remote entity. For example the directional microphone and or directional sound emitter may be configured to act as peripherals for the user s mobile communication device and the user s mobile communication device may treat them as such. The communication interface may be configured to communicatively couple the directional microphone and or directional sound emitter to the user s mobile communication device using a short distance wireless protocol such as Bluetooth Wi Fi etc. The communication interface may be configured to pair with the mobile communication device prior to coupling.

The communication interface may instruct the user s mobile communication device to disable a local microphone and or a local sound emitter before during or after coupling. The communication interface may instruct the user s mobile communication device to perform one or more actions to save power. The one or more actions may include dimming a display turning off a display reducing communication with a service provider and or the like. The communication interface may compare the quality of the communicative coupling of the directional microphone and or directional sound emitter with the remote entity s communication device to the quality of the communicative coupling of the user s mobile communication device with the remote entity s communication device. The communication interface may perform the comparison before terminating the communicative coupling between the user s mobile communication device and the remote entity s communication device and or before instructing the user s mobile communication device to disable the local microphone and or local sound emitter.

In some embodiments the communication interface may be configured to communicatively couple the directional microphone and or the directional sound emitter to the remote entity s communication device over a communication network without routing communications through the mobile communication device of the user. The communication interface may transmit a request to the user s mobile communication device to transfer the communicative coupling with the remote entity. The user s mobile communication device may provide the request to a service provider. Alternatively or in addition the communication interface may transmit the request to transfer the communicative coupling directly and or indirectly to the service provider. The communication interface may verify with the service provider that the user s mobile communication device is proximate to the communication interface and or may verify that the user s mobile communication device has provided permission to hand off the coupling. The service provider may also or instead verify proximity and or permission to hand off directly with the user s mobile communication device.

The communication interface may be configured to communicatively couple with the user s mobile communication device and route communications between the user s mobile communication device and the remote entity s communication device e.g. while the user is still interfacing with the local microphone and or local sound emitter of the user s mobile communication device . The communication interface may next communicatively couple the directional microphone and or directional sound emitter to the communication device of the remote entity. The communication interface may then disconnect the user s mobile communication device from the remote entity s communication device. The communication interface may communicatively couple with the user s mobile communication device using a wireless network protocol e.g. Wi Fi etc. a mobile communication device protocol e.g. a cellular protocol such as Wi MAX LTE etc. and or the like. In an embodiment the communication interface may act as a cellular base station for the user s mobile communication device. Alternatively the communication interface may initially couple the directional microphone and or direction sound emitter with the mobile communication device prior to directly coupling with the remote entity.

The communication interface may determine the user is communicatively coupled to the remote entity by detecting vocal emissions by the user e.g. using the directional microphone . For example the communication interface may determine the user is communicatively coupled to the remote entity based on the content of the vocal emissions. Alternatively or in addition the communication interface may determine the user is communicatively coupled to the remote entity by receiving an indication from the user tracking sensor that the remote entity is outside of listening distance of the user by receiving an indication from the user tracking sensor of the position of the user s mobile communication device e.g. next the user s ear by prompting the user s mobile communication device for a status by receiving a notification from the user s mobile communication device and or the like. The notification may be transmitted by the user s mobile communication device in response to a transmission by the communication interface of its availability to couple. The transmission by the communication interface may be sent directly to the user s mobile communication device may be sent indirectly e.g. via a service provider to the user s mobile communication device may be broadcast to a plurality of devices within listening range may be transmitted directionally to the user s mobile communication device and or the like.

The communication interface may be coupled paired and or the like with the user s mobile communication device prior to the user coupling with the remote entity and or a decision to hand off a coupling. The communication interface may be configured to determine the user is communicatively coupled to the remote entity by receiving a wake up notification from the user s mobile communication device by receiving a notification from the user s mobile communication device without prompting by receiving data intended for the directional sound emitter from the user s mobile communication device by receiving a request from the user s mobile communication device for data e.g. vocal emissions from the directional microphone and or the like.

The communication interface may determine the directional microphone and or directional sound emitter should be communicatively coupled to the remote entity s communication device based on a user gesture detected by the user tracking sensor. The communication interface may determine the directional microphone and or directional sound emitter should be communicatively coupled to the remote entity based on vocal emissions received by the directional microphone and or the local microphone. The vocal emissions may indicate that the directional microphone and or directional sound emitter should be communicatively coupled to the remote entity. Alternatively or in addition the user s mobile communication device may be configured to determine when to communicatively couple the directional microphone and or directional sound emitter to the remote entity. For example the user s mobile communication device may receive a user input and or may automatically determine the directional microphone and or directional sound emitter should be communicatively coupled to the remote entity.

The communication interface may update the user s mobile communication device and or a service provider with a status of a communicative coupling of the directional microphone and or directional sound emitter with the user and or the remote entity. The communication interface may transmit a notification to the user s mobile communication device and or the service provider that the directional microphone and or the directional sound emitter are or are not communicatively coupled to the user. The communication interface may transmit a notification to the user s mobile communication device and or the service provider that the directional microphone and or the directional sound emitter are not available to be communicatively coupled to the user e.g. to inform the user s mobile communication device and or the service provider not to attempt a hand off .

The communication interface may terminate the communicative coupling between the remote entity and the directional microphone and or directional sound emitter may hand off the communicative coupling to another directional microphone and or another directional sound emitter and or may hand off the communicative coupling back to the user s mobile communication device under certain circumstances. For example the communication interface may determine that the user is leaving the range of the directional microphone and or the directional sound emitter e.g. by using the user tracking sensor by analyzing the amplitude of vocal emissions and or the like . The communication interface and or the user tracking sensor may be configured to predict a likelihood that the user will leave the range to predict a time at which the user will leave the range and or the like. The communication interface and or the user tracking sensor may determine the user is leaving the range based on at least one of a location of the user a direction of motion of the user a velocity of the user and or the like. The communication interface and or the directional microphone may be configured to determine the user is leaving the range based on a sound quality received by the directional microphone.

The communication interface may also or instead determine that the user s mobile communication device is leaving the range of a communicative coupling between the communication interface and the user s mobile communication device and or that another cellular base station would provide a stronger cellular signal. The user may indicate that the communicative coupling between the directional microphone and or the directional sound emitter and remote entity s communication device should be terminated and or handed off. For example the user tracking sensor may be configured to receive a user gesture and or the directional microphone may be configured to receive vocal emissions indicating the communicative coupling should be terminated and or handed off.

The directional sound emitter may alert the user prior to terminating the communicative coupling between the directional microphone and or directional sound emitter and the remote entity. The communication interface may be configured to determine whether the user stays within the range of the directional microphone directional sound emitter and or communication interface in response to the alert e.g. by using the user tracking sensor by analyzing the amplitude of vocal emissions by monitoring signal strength and or the like . The communication interface may be configured to indicate to the user s mobile communication device and or a service provider that the communicative coupling between the directional microphone and or directional sound emitter and the remote entity s communication device is being terminated. The communication interface may be configured to indicate to the user s mobile communication device and or a service provider that a communicative coupling should be established between the user s mobile communication device and the remote entity s communication device.

The user s mobile communication device may be configured to determine that the communicative coupling between the directional microphone and or the directional sound emitter and the remote entity should be terminated and or handed off. The user s mobile communication device may notify the communication interface to terminate and or hand off the communicative coupling and or the user s mobile communication device may terminate and or recover the communicative coupling itself. The user s mobile communication device may be configured to determine the communication interface is out of range and or out of communicative contact to determine a cellular signal from another cellular base station is stronger than the signal from the communication interface to determine a sound quality of the communicative coupling between the directional microphone and or directional sound emitter and the remote entity s communication device is below a predetermined threshold to receive a user indication that the communicative coupling should be terminated and or handed off and or the like.

The communication interface may be configured to determine whether the user has rights to use the directional microphone and or the directional sound emitter. The communication interface may determine whether the user has rights based on an identifier received from the user s mobile communication device based on a previous coupling with the user s mobile communication device based on whether the communication interface and the user s mobile communication device are paired based on an identity of the user based on facial recognition of the user performed by e.g. the user tracking sensor based on vocal emissions from the user e.g. based on voice recognition performed on the vocal emissions based on a code phrase in the vocal emissions etc. based on a gesture detected by e.g. the user tracking sensor and or the like.

The hands free intercom may be configured to automatically connect a user to an appliance. The communication interface may be configured to communicatively couple the directional microphone and or directional sound emitter to the appliance. The user may indicate to which appliance the communication interface should couple. For example the user tracking sensor may detect a user gesture indicating an appliance the directional microphone may detect a vocal emission including a vocal identification of an appliance e.g. a vocal identification preceded by vocalized keyword and or the like. The communication interface may communicatively couple the user to the appliance in response to the indication of which appliance.

The appliance may include a laundry washing machine a laundry drying machine a dish washing machine a refrigerator a freezer a water heater a thermostat a furnace an air conditioner an oven a range a microwave oven a coffee machine a rice cooker a bathtub a shower an alarm clock a home control center an outdoor sprinkler system an electrical energy storage system an electrical charging system a security control system a door lock a room light a window covering a water softener and or the like. The appliance may include a television a radio a stereo a projector a DVD player a video game console a digital video recorder a home theater system a home entertainment system and or the like. The appliance may include a printer a copy machine a fax machine a computer a message center an answering machine and or the like.

The directional microphone may receive vocal emissions from the user intended for the appliance. The vocal emissions may include a request to change a setting of the appliance. The vocal emissions may include a request for the appliance to start an activity such as preheating an oven washing a plurality of objects drying a plurality of objects changing a temperature of a room turning on a television playing a song recording a television program starting to fill a bathtub locking a door sending an email printing a document playing answering machine messages and or the like. The request may indicate the appliance should notify the user when the activity is completed e.g. notify the user via the directional sound emitter . The request may indicate a time period for which the activity should be performed.

The vocal emissions from the user may include a request for a status of the appliance. The status may include a current activity being performed by the appliance a time to complete an activity a time to complete all activities and or the like. One appliance may request information from another appliance to determine the time to complete an activity and or all activities. For example the appliance may be a laundry washing machine and the laundry washing machine may request a drying time from a laundry drying machine. Alternatively or in addition the appliance may be a water heater and the water heater may request a room temperature from a thermostat. The information may be requested via the communication interface and or directly from the other appliance.

The vocal emissions from the user may include a request to change settings of the appliance. The request may include a request to repeat an activity an additional time e.g. repeating a wash cycle a rinse cycle a spin cycle a drying cycle etc. . The request may include a request to minimize a time to completion. The appliance may shorten one or more activities to complete task faster. The communication interface may automatically instruct the appliance to change settings for example based on an activity of the user e.g. an activity determined by a user tracking sensor a location of the user and or the like. The communication interface may instruct a thermostat to change one or more room temperatures based on the location of the user instruct a water heater to change water temperature based on a location of the user instruct a dish and or laundry washing and or drying machine to target a particular completion time based on a location of the user and or the like. The vocal emissions from the user may include a request to stop an activity.

The appliance may be configured to report information to the user via the communication interface and or the directional sound emitter. The user may respond to the reported information e.g. vocally by inter alia requesting a reminder after an indicated time request a reminder when the user changes rooms and or the like. The reported information may include that an activity and or task has been completed. The reported information may include that a consumable substance is low. The consumable substance may include soap bleach drying agent static removing agent fuel salt paper ink etc. The reported information may include a reminder of current settings such as an indication that an oven is on that a door is locked etc. Alternatively or in addition the communication interface may determine the information to report to the user. The communication interface and or directional sound emitter may deliver a notification of a change in activity such as an indication a thermostat is changing a target temperature according to a predetermined schedule an indication that a current appliance cycle has changed and or the like.

The communication interface and or directional sound emitter may deliver a request for permission to change settings. The request may be from the communication interface the appliance another user and or the like. For example the appliance and or communication interface may determine that the settings should be changed based on a sensor measurement. The appliance and or communication interface may determine that an additional activity is needed e.g. an extra wash cycle rinse cycle spin cycle drying cycle extra drying time etc. . The communication interface and or directional sound emitter may indicate an additional time required to complete an activity and or task if settings are changed for example by the user the other user the appliance the communication interface etc. The appliance communication interface and or directional sound emitter may be configured to deliver a report of an error with the appliance. The vocal emissions from the user may include a user command to the appliance in response to the reported error. The appliance communication interface and or directional sound emitter may deliver a request for permission to contact a maintenance provider. The user may respond e.g. vocally to indicate whether permission is granted or not.

The communication interface may be configured to determine whether the appliance is permitted to communicate with the user. The communication interface may evaluate user settings to determine whether the appliance is permitted to communicate with the user. The communication interface may determine whether the appliance is permitted to communicate with the user based on time of day user location e.g. a location determined by the user tracking sensor a user indication of availability whether another person is with the user an identity of the appliance an identity of the user and or the like. The communication interface may determine that the user is accessible via a mobile user device and may determine whether the appliance is permitted to have communications forwarded to a mobile user device.

The communication interface may determine based on context whether the appliance is permitted to communicate with the user. The communication interface may determine whether the user requested the communication from the appliance may determine historical user behavior in similar situations and or the like. The communication interface may determine whether the appliance is permitted to communicate with the user based on user activity e.g. an activity determined by the user tracking sensor . For example the user tracking sensor may determine whether the user is sleeping and the communication interface may determine whether communication is permitted based on whether the user is sleeping. The user tracking sensor may determine whether the appliance is permitted to communicate with the user based on a type of communication from the appliance. The communication interface may allow certain types of communications such as urgent maintenance requests notifications of activity and or task complete etc. despite other factors weighing against permitting communication. The communication interface may decide to notify the user of a detected and or suspected leak despite the user sleeping the time being 3 00 AM and or the like.

The communication interface may determine whether the user is permitted to communicate with the appliance. The communication interface may determine whether communication is permitted based on settings by a primary user based on an identity of the user based on whether the user instructed the appliance to begin its current activity and or the like. The communication interface may identify the user by performing voice recognition on vocal emissions received by the directional microphone and or communication interface. The communication interface may determine whether communication is permitted based on security information provided by the user e.g. a passcode a password a passphrase a gesture etc. . The communication interface may determine whether communication is permitted based on a location of the user. For example a remotely located user may be prevented from communicated with the appliance and or only some users may be permitted to communicate with appliances while remotely located. The communication interface may determine whether communication is permitted based on a type of communication. Certain users may be able to request and receive status information but may be prevented from delivering commands e.g. to perform an activity and or task change a setting etc.

The communication interface may determine whether a first appliance is permitted to communicate with a second appliance. The communication interface may evaluate user settings to determine whether inter appliance communication is permitted. The communication interface may determine whether is communication is permitted based on a type of communication. For example appliances may be able to request and receive status information but may be prevented from delivering commands and or prevented from making updates or changes to software and or firmware. The communication interface may determine whether communication is permitted based on an identity of the first appliance and or an identity of the second appliance. The communication interface may be configured to record and store copies of communications between the appliance and the user of the hands free intercom such recordings may include metadata such as time of day appliance settings location and or activity of the user etc. The communication interface may record communications between appliances.

Various divisions of labor between the appliance and the communication interface are contemplated. In an embodiment the communication interface may transmit all communications it receives to the appliance and the appliance may determine access rights for the communications. The communication interface may be configured to convert vocal emissions e.g. audio representations thereof into messages understood by the appliance. Alternatively or in addition the communication interface may deliver vocal emissions e.g. audio representations thereof to the appliance and the appliance may be configured to decipher the vocal emissions e.g. audio representations thereof . The communication interface may be configured to convert messages from the appliance into an audible and or user interpretable form and or the appliance may be configured to deliver audible and or user interpretable messages to the communication interface. The appliance may be configured to receive and respond to communications from the communication interface. Alternatively or in addition the communication interface may directly retrieve information from and or write information to a non transitory computer readable storage medium of the appliance and or the communication interface may be configured to request and deliver information via an application programming interface API of the appliance.

The hands free intercom may occupy one or more houses apartments office buildings warehouses restaurants stores malls outdoor facilities transportation facilities hospitals and or the like. The hands free intercom may be located indoors and or outdoors. The hands free intercom may include a persistent storage device for automatically recording a conversation between the user and the entity of interest. Alternatively or in addition the persistent storage device may store a transcription of the conversation. The communication interface may automatically transmit the recording to the participants. The entity of interest and or remote entity may include a person an appliance a computer system and or the like. The user may include a person an appliance a computer system and or the like.

Embodiments may include various steps which may be embodied in machine executable instructions to be executed by a computer system. A computer system includes one or more general purpose or special purpose computers or other electronic devices . The computer system may include hardware components that include specific logic for performing the steps or may include a combination of hardware software and or firmware.

Embodiments may also be provided as a computer program product including a computer readable medium having stored thereon instructions that may be used to program a computer system or other electronic device to perform the processes described herein. The computer readable medium may include but is not limited to hard drives floppy diskettes optical disks CD ROMs DVD ROMs ROMs RAMs EPROMs EEPROMs magnetic or optical cards solid state memory devices or other types of media computer readable media suitable for storing electronic instructions.

Computer systems and the computers in a computer system may be connected via a network. Suitable networks for configuration and or use as described herein include one or more local area networks wide area networks metropolitan area networks and or Internet or IP networks such as the World Wide Web a private Internet a secure Internet a value added network a virtual private network an extranet an intranet or even standalone machines which communicate with other machines by physical transport of media a so called sneakernet . In particular a suitable network may be formed from parts or entireties of two or more other networks including networks using disparate hardware and network communication technologies.

One suitable network includes a server and several clients other suitable networks may contain other combinations of servers clients and or peer to peer nodes and a given computer system may function both as a client and as a server. Each network includes at least two computers or computer systems such as the server and or clients. A computer system may include a workstation laptop computer disconnectable mobile computer server mainframe cluster so called network computer or thin client tablet smart phone personal digital assistant or other hand held computing device smart consumer electronics device or appliance medical device or a combination thereof.

The network may include communications or networking software such as the software available from Novell Microsoft Artisoft and other vendors and may operate using TCP IP SPX IPX and other protocols over twisted pair coaxial or optical fiber cables telephone lines radio waves satellites microwave relays modulated AC power lines physical media transfer and or other data transmission wires known to those of skill in the art. The network may encompass smaller networks and or be connectable to other networks through a gateway or similar mechanism.

Each computer system includes at least a processor and a memory computer systems may also include various input devices and or output devices. The processor may include a general purpose device such as an Intel AMD or other off the shelf microprocessor. The processor may include a special purpose processing device such as an ASIC SoC SiP FPGA PAL PLA FPLA PLD or other customized or programmable device. The memory may include static RAM dynamic RAM flash memory one or more flip flops ROM CD ROM disk tape magnetic optical or other computer storage medium. The input device s may include a keyboard mouse touch screen light pen tablet microphone sensor or other hardware with accompanying firmware and or software. The output device s may include a monitor or other display printer speech or text synthesizer switch signal line or other hardware with accompanying firmware and or software.

The computer systems may be capable of using a floppy drive tape drive optical drive magneto optical drive or other means to read a storage medium. A suitable storage medium includes a magnetic optical or other computer readable storage device having a specific physical configuration. Suitable storage devices include floppy disks hard disks tape CD ROMs DVDs PROMs random access memory flash memory and other computer system storage devices. The physical configuration represents data and instructions which cause the computer system to operate in a specific and predefined manner as described herein.

Suitable software to assist in implementing the invention is readily provided by those of skill in the pertinent art s using the teachings presented here and programming languages and tools such as Java Pascal C C database languages APIs SDKs assembly firmware microcode and or other languages and tools. Suitable signal formats may be embodied in analog or digital form with or without error detection and or correction bits packet headers network addresses in a specific format and or other supporting data readily provided by those of skill in the pertinent art s .

Several aspects of the embodiments described will be illustrated as software modules or components. As used herein a software module or component may include any type of computer instruction or computer executable code located within a memory device. A software module may for instance include one or more physical or logical blocks of computer instructions which may be organized as a routine program object component data structure etc. that perform one or more tasks or implement particular abstract data types.

In certain embodiments a particular software module may include disparate instructions stored in different locations of a memory device different memory devices or different computers which together implement the described functionality of the module. Indeed a module may include a single instruction or many instructions and may be distributed over several different code segments among different programs and across several memory devices. Some embodiments may be practiced in a distributed computing environment where tasks are performed by a remote processing device linked through a communications network. In a distributed computing environment software modules may be located in local and or remote memory storage devices. In addition data being tied or rendered together in a database record may be resident in the same memory device or across several memory devices and may be linked together in fields of a record in a database across a network.

Much of the infrastructure that can be used according to the present invention is already available such as general purpose computers computer programming tools and techniques computer networks and networking technologies digital storage media authentication access control and other security tools and techniques provided by public keys encryption firewalls and or other means.

The directional sound emitter may emit ultrasonic sound waves from the plurality of ultrasonic speakers . The plurality of ultrasonic speakers may be aimed so that the ultrasonic sound waves frequency convert to audible frequencies at or near the user s ears. For example the ultrasonic sound waves may be modulated so as to produce audio of interest in the beat frequency created when the waves interfere. Alternatively or in addition the ultrasonic sound waves may be downshifted in the air and or in a material in or on the user . The directional sound emitter may be configured to maximize the volume of audible sound waves at or near the user while minimizing the volume of audible sound waves in other locations. If the user moves the hands free intercom may reorient the directional microphone and directional sound emitter towards the user s new position. The directional sound emitter or individual ultrasonic speakers may be steered mechanically and or may include a phased array and or metamaterial array to produce the directional emission.

Once the hands free intercom has determined that the first user wishes to speak to the second user the hands free intercom may locate the second user . The hands free intercom may locate the second user for example with user tracking sensors on one or more user interfaces . The hands free intercom may then couple the directional microphone and directional sound emitter of the second user interface to the directional microphone and directional sound emitter of the first user interface so the users are able to communicate. There may be some delay while the hands free intercom analyzes the vocal emissions of the first user identifies the second user locates the second user and communicatively couples the first user to the second user . This delay may be hidden from the second user e.g. by delivering the vocal emissions offset by the delay so the conversation appears to happen in real time. The first user may be aware of the delay so the hands free intercom may alert the first user when the vocal emissions are delivered e.g. by playing a ringing sound until the vocal emissions are delivered by playing a tone once the vocal emissions are delivered by playing the vocal emissions for the first user as they are delivered to the second user etc. . Remaining vocal emissions by the first and second users may be delivered in substantially real time e.g. only delayed by any inherent delays in the hands free intercom . The first user and or the second user may be able to control the communicative coupling e.g. pause terminate mute etc. using gestures vocal emissions and or the like.

The hands free intercom may measure vocal emissions from the user if the user says something. Based on the vocal emissions the hands free intercom may identify the entity of interest to whom the user wishes to speak. The hands free intercom may also be configured to determine from the vocal emissions if the user is not interested in using the hands free intercom. In which case the hands free intercom may continue to measure vocal emissions until it determines that the user is interested in communicating to an entity of interest using the hands free intercom.

Once an entity of interest has been identified the entity of interest may be located by the hands free intercom. In some embodiments the hands free intercom may prelocate potential entities of interest e.g. the user s family members the last five entities he s communicated with entities identified by his calendar or schedule etc. so that the specific entity of interest may be rapidly connected to once identified by the user. The hands free intercom may locate the entity of interest using a user tracking sensor based on a cell phone of the user based on a beacon and or the like. The hands free intercom may determine an optimal communication device of the entity of interest based on the location of the entity of interest. The hands free intercom may communicatively couple the user to the optimal communication device of the entity of interest determined in step . During communicative coupling the hands free intercom may deliver audio received from the entity of interest to the user emitting ultrasonic sound waves to the user. When the communicative coupling is terminated the method may end.

The user may be able to provide verbal instructions to the hands free intercom requesting privacy. The user may be able to specify a predetermined time for the privacy criteria for ending the privacy period who or what subject matters may be allowed to couple despite the privacy request and or the like. The access rules and or privacy request may specify entities and or subject matters that should be rejected outright entities and or subject matters that should result in the user being prompted to connect and entities and or subject matters that should be automatically connected without prompting. In an embodiment the hands free intercom may notify the user of any attempted connections once the access rules no longer prohibit coupling and or any period of requested privacy has ended. Alternatively or in addition the remote entity may record a message be instructed to call back and or the like.

The communication interface may inform an access rules block of the request to couple. The access rules block may analyze the identity and or subject matter of the request to determine whether to couple. The access rules block may be coupled to one or more user tracking sensors which may be used to determine which room the user is occupying and or an activity of the user. Based on the room and or activity the access rules block may determine whether to couple the remote entity to the user. The access rules block may be further coupled to a time date block configured to provide the time date day of the week a user calendar and or the like to the access rules block for use in determining whether to couple. The time date block may be an internal clock an external time source a calendar program operating on a user device and or the like.

The access rules block may use any combination of data available to it to determine whether to couple the remote entity. The access rules block may use default rules user specified rules rules learned from past user behavior and or the like when analyzing the available data to determine whether to couple the remote entity to the user. The communication interface may communicatively couple a directional microphone and a directional sound emitter to the remote communication device if the access rules block determines that coupling should be allowed.

Based on the context data the hands free intercom may determine whether to couple the remote entity to the user. In an embodiment access rules may be used to determine whether to couple the remote entity to the user. The access rules may include a user specified and or default set of conditions contingent on elements of the context data. Alternatively or in addition the hands free intercom may compare the context data to user behavior when previous requests were received to determine whether to couple the remote entity to the user. The hands free intercom may communicatively couple the remote entity to the user if it determines that coupling should be performed. The method may end until another request is received.

The hands free intercom may use the user tracking sensor and or user tracking sensors from additional interfaces not shown to detect the presence of the eavesdropper . Alternatively or in addition the user tracking sensor may detect the presence of the eavesdropper based on the location of a mobile communication device of the eavesdropper by tracking passage of the eavesdropper through one or more doorways and or the like. The hands free intercom may warn of an eavesdropper in a room other than that of the user if it determines that the eavesdropper is still within a listening range. Accordingly the hands free intercom may be configured to sense the presence of the eavesdropper in rooms other than the room occupied by the user e.g. using user tracking sensors doorway sensors sensing of mobile communication devices etc. .

The hands free intercom may warn the user of the eavesdropper using the eavesdropper warning light . Alternatively or in addition the hands free intercom may produce an audio indication that the eavesdropper is present. The audio indication may be a noise a tone speech e.g. computer synthesized speech and or the like. The directional sound emitter may emit the audio indication so it is only audible by the user . In an embodiment the hands free intercom may refuse to complete a communicative coupling and or may pause or terminate a communicative coupling when an eavesdropper is detected. The refusal to complete the communicative coupling may be in addition to or instead of the warning to the user .

It may be more convenient and or more comfortable for the user to communicate with the remote entity via the hands free intercom . However the user may have initiated the call with the remote entity using the mobile phone for example because the user was initially out of range of the hands free intercom . The hands free intercom may detect that the user is within range of the hands free intercom and or may detect that the user is coupled to the remote entity. For example the user may be within range if audible emissions from the user can be detected by the directional microphone if audio can be delivered to the user by the directional sound emitter if the hands free intercom can wirelessly communicate with the mobile phone and or the like. The hands free intercom may detect the user is coupled to the remote entity by detecting a position of the mobile phone e.g. near the user s ear near the user s mouth etc. with the user tracking sensor by receiving vocal emissions e.g. when no other person is present using the directional microphone by communicating with the mobile phone and or the like.

The mobile phone may hand off the communicative coupling with the remote entity to the hands free intercom . The mobile phone may act as an intermediary that communicatively couples the hands free intercom to the remote entity and or the hands free intercom may communicatively couple to the remote entity without assistance from the mobile phone after the hand off is completed. In an embodiment the hands free intercom may act like a peripheral device coupled to the mobile phone by for example a Bluetooth protocol. In another embodiment the hands free intercom may request the hand off from a service provider. Alternatively or in addition the hands free intercom may act as a base station such as a cellular base station a Voice over Internet Protocol VOIP base station etc. for the mobile phone in order to perform a gradual hand off.

The hands free intercom may transition from the directional microphone and directional sound emitter to other directional microphones and directional sound emitters not shown as the user moves from one room to another. The communicative coupling may be returned to the mobile phone if the user leaves the range of the hands free intercom . While the hands free intercom remains coupled to the remote entity the hands free intercom may provide some or all of its functionality to the user such as adding and or removing parties recording conversation storing keywords terminating the communicative coupling etc. and may respond to user commands e.g. gestures voice commands etc. .

In the illustrated embodiment the communication interface couples the directional microphone and directional sound emitter to the remote communication device without sending communications to the mobile communication device . For example the communication interface may use plain old telephone service POTS the Internet a mobile telephone service provider and or the like to communicate with the remote communication device . The communication interface may be communicatively coupled with the mobile communication device to coordinate handing off of the communicative coupling. For example the communication interface may inform the mobile communication device when it is available to receive communicative couplings when a communicative coupling has been received when a communicative coupling is being returned etc. Similarly the mobile communication device may inform the communication interface when it is coupled to a remote entity when it handing off a communicative coupling when it has received a returned communicative coupling etc.

The directional microphone and or directional sound emitter may be communicatively coupled to the remote entity if it is determined that they should be. For example the directional microphone and or directional sound emitter may be communicatively coupled to the mobile device which may remain coupled to the remote entity. In an embodiment a request to communicatively couple may be sent to a service provider which may transfer the communicative coupling with the remote entity from the mobile device to the directional microphone and or directional sound emitter. Alternatively or in addition a communicative coupling may be established with the remote entity and the communicative coupling may be distinct and or separate from the communicative coupling between the remote entity and the mobile device. Before during or after communicatively coupling to the remote entity a mobile device microphone and or mobile device sound emitter may be uncoupled from the remote entity. The mobile device microphone and or mobile device sound emitter may be disabled the mobile device may be uncoupled from the remote entity and or the like.

The user may then communicate hands free with the remote entity using the directional microphone and or directional sound emitter. The user may move around while communicating via the directional microphone and directional sound emitter. At some point it may be determined that the user is leaving the range of the directional microphone and or directional sound emitter e.g. the user has gone into a different room . A user tracking sensor the quality of audio received by the directional microphone a location of the mobile device and or the like may be used to determine that the user is leaving the range of the directional microphone and or directional sound emitter. If a directional microphone and or directional sound emitter closer to the user is available the user may be transferred to the closer directional microphone and or directional sound emitter. The closer directional microphone and or directional sound emitter may be determined based on a direction being traveled by the user a location of a mobile device detection of the user by the closer directional microphone and or directional sound emitter and or a user tracking sensor associated with the closer directional microphone and or directional sound emitter and or the like.

The user may leave the range of every directional microphone and or directional sound emitter e.g. by leaving a building and or an area containing the directional microphones and or directional sound emitters . Accordingly it may be determined if the user is leaving the range of all directional microphones and or directional sound emitters. For example the user tracking sensor the audio quality detected by the closer directional microphone the location of the mobile device and or the like may be used to determine that the user is leaving the range of all directional microphones and or directional sound emitters. A warning may be sent to the user if the user is leaving the range. The mobile device microphone and or sound emitter may be communicatively coupled if the user is leaving the range. In an embodiment step may include doing the reverse of one or more of the actions taken in step . The closer directional microphone and or directional sound emitter may be uncoupled from the remote entity. Step may include doing the reverse of one or more of the actions taken in step . Once the communicative coupling has been returned to the mobile device and or terminated the method may end.

The hands free intercom may allow the user to communicate with the appliances using the directional microphone the directional sound emitter and or a mobile device not shown . The user may request a status change settings request that an activity be commenced and or the like. The hands free intercom may also or instead allow the appliances to communicate with the user e.g. via the directional microphone directional sound emitter and or mobile device. The appliance may report changes in activity status updates and or the like. In some embodiments the hands free intercom may communicatively couple the appliances to each other. For example a clothes washing machine may communicate with a clothes drying machine to determine how long it will take for clothes to be washed and dried and or to attempt to align completion times. Similarly the clothes drying machine may communicate with a thermostat and adjust setting based on an ambient temperature and or humidity.

The hands free intercom may manage which entities have rights to communicate with each other. The user tracking sensor may be configured to identify the user and or determine whether the user provides a gesture required for access. The hands free intercom may determine which communications from the appliances should be forwarded to a mobile device and or may prevent unauthorized mobile devices and or remote users from accessing the appliances . Users may have different rights for example depending on identity location and or the like. Similarly the appliances may have various rights for accessing the user as well as having various rights for accessing one another. The hands free intercom may authenticate entities to determine what rights they have.

The appliance may be able to send communications to the user when authorized by the communication interface . The communication interface may locate the user and deliver the communications. A user accessible via the directional sound emitter and or directional microphone may receive the communication via the directional sound emitter . If a user is not accessible via the directional sound emitter and or directional microphone the communications interface may attempt to deliver the communication to a mobile communication device to which the communication interface is coupled. Alternatively or in addition communications may be sent to a computer an e mail address etc. The communication interface may also or instead deliver incoming communications from the mobile communication device to the appliance if the incoming communications are authorized.

The user may wish to have the appliance begin and or change an activity and or task. A user request for the appliance to start an activity may be received from the user. It may be determined whether the user is permitted to provide commands to the appliance. The right to provide commands to the appliance may be distinct from the right to receive information from the appliance. For example a repair company and or manufacturer may be able to access information but unable to send commands. If the user is permitted to provide commands the request to start the activity may be provided to the appliance.

The appliance may decide that it would like to receive information from another appliance. For example the appliance may be planning to adjust its settings based on the received information and or may plan on including the information in a report provided to the user. A request for information from the other appliance may be received from the appliance . It may be determined whether the appliance is permitted to communicate with the other appliance for example based on the identity of the appliance the identity of the other appliance user settings and or the like. The request may be delivered to the other appliance and the requested information from the other appliance may be provided to the appliance if communication is permitted. By restricting access malicious attacks on appliances may be prevented. If a malicious attack is successful restricting access may prevent any harm from spreading among appliances.

The appliance may decide to provide information to the user. For example the appliance may alert the user to a change in activity remind the user of a current status and or the like. A request may be received from the appliance to provide information to the user. It may be determined whether the appliance is permitted to communicate with the user. For example the time of day activity of the user location of the user identity of the user urgency of the information to be provided and or the like may be considered when determining whether the appliance is permitted to communicate with the user. If the appliance is permitted to communicate with the user the information may be provided to the user. The information may be provided via a directional sound emitter via a mobile communication device etc. Once any received communications have been routed to the appropriate location and or denied the method may enter a standby state until another communication is received and or may end.

While various aspects and embodiments have been disclosed herein other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting with the true scope and spirit being indicated by the following claims.

