---

title: Augmented reality user interface facilitating fulfillment
abstract: Disclosed are various implementations for updating information displayed in a user interface for a worker in a fulfillment center. Information changing relative to a previous user interface can be provided in response to location data that indicates the worker's location within a fulfillment center.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09632313&OS=09632313&RS=09632313
owner: Amazon Technologies, Inc.
number: 09632313
owner_city: Seattle
owner_country: US
publication_date: 20140327
---
Items are stored or stocked in distribution or fulfillment centers. Shipments of items can be assembled and fulfilled from distribution or fulfillment centers where the items are stored. Items are retrieved or picked from the inventory storage locations within the fulfillment center by workers and are then packed and shipped. Items in the inventory in the fulfillment center may be stored in one or more locations within the fulfillment center either together as a group or separately throughout the fulfillment center. Workers in the fulfillment center are tasked with retrieving items from and or placing items within the fulfillment center at various locations.

The present disclosure relates to generating and or rendering a user interface upon a display of a device that displays information related to various types of tasks. For example a task can be related to the fulfillment process of electronic commerce orders by personnel or workers in a fulfillment center. Such a task can also be related to delivery of a parcel by a package delivery service. The present disclosure also relates to determining a location of a worker within the fulfillment center which can facilitate rendering information on a user interface on the display to facilitate a given task. The user interface can be rendered and displayed by a wearable computing device such as augmented reality glasses that overlay a user interface over a field of view of a fulfillment center worker.

For example if a location of a worker within a fulfillment center can be determined location specific information such as for example turn by turn directions to a destination within the fulfillment center can be rendered in the user interface. A destination within the fulfillment center can include a particular floor row shelf bin or a particular item or product that is stocked within the fulfillment center. Accordingly embodiments of the disclosure can facilitate providing various types of information to a worker in a fulfillment center in a user interface that is rendered by a wearable computing device where the information is also based at least in part on the location of the user as detected in accordance with embodiments described herein.

Beginning with shown is an example scenario according to various embodiments of the disclosure in which a user interface rendered by a wearable computing device such as augmented reality glasses or any other device in which a user interface is rendered in a field of view of a user is shown. The user interface can display a worker instruction that is rendered within the field of view of the user. For example the worker instruction can identify a particular location within a fulfillment center to which a worker should proceed as well as a task to perform at the particular location.

In the depicted scenario the worker instruction can be generated by the wearable computing device and or one or more computing devices in communication with the wearable computing device . The worker instruction identifies a particular bin in the fulfillment center to which the worker should proceed to retrieve an item or product. The item can be retrieved for the purposes of fulfillment of the item in response to an order placed via an electronic commerce site. The user interface can also include a visual indicator that can provide a visual cue or direction that is overlaid onto the field of view of the user in the user interface . Such a visual cue can be provided as a part of turn by turn directions to a destination within the fulfillment center. In some embodiments the visual cue can also be overlaid onto the user interface to highlight the location of an item that is within the field of view of the user. For example if the bin to which the user is directed appears within the field of view the visual indicator can point to or highlight the bin in the field of view.

The worker instruction may also include specific instructions or actions for the worker to take such as remove orange box from shelving unit on the left. In other words the worker instruction can comprise instructions beyond turn by turn directional instructions to a destination in the fulfillment center. For example a worker instruction can identify a particular item in the fulfillment center that the worker should retrieve. A worker instruction can also include an instruction to place a particular item in a particular location in the fulfillment center. In other words a worker instruction can include any instruction related to any step of a task conducted by the worker in a fulfillment center.

Such a visual indicator can be updated or redrawn within the field of view of the user as the orientation and or location of the wearable computing device is updated. In other words as a user wearing the wearable computing device moves throughout the fulfillment center the visual indicator can be updated or repositioned on a heads up display of the wearable computing device to account for the location and orientation of the wearable computing device .

The wearable computing device can detect its location within a fulfillment center by detecting location identifiers within the fulfillment center and determining its location within the fulfillment center relative to the location identifiers . Such location identifiers can include for example barcode indicators such as two dimensional or quick response codes QR codes that are positioned throughout the fulfillment center such that they are visible within the field of view of a user wearing the wearable computing device . In this scenario the wearable computing device can be configured with one or more image capture devices that are configured to capture imagery within the field of view of a user and the image capture devices can capture imagery of the user s field of view periodically. A numeric or alphanumeric identifier associated with such a barcode indicator can be uniquely associated with a particular location within the fulfillment center such that when scanned by the wearable computing device the wearable computing device can identify a particular location within the fulfillment center.

To this end the wearable computing device can then be configured with a barcode scanner image capture devices a radio frequency identification RFID scanner a near field communication NFC scanner Bluetooth radio or any other device that can capture information from a barcode NFC tag RFID tag location beacon or other type of identifier that can be placed within a fulfillment center. In one embodiment location identifiers can be positioned along the floor or other surfaces of a fulfillment center e.g. shelves bins etc. .

The depicted user interface can be facilitated by embodiments of the disclosure. In the example of the user interface displays structured information that can be rendered upon the display of a wearable computing device worn by a user or worker in a fulfillment center in order to facilitate fulfillment of orders or other tasks in the fulfillment center by providing the worker with information about a particular task such as the retrieving or stowing of items that are stocked in the fulfillment center.

In the example scenario shown in the wearable computing device can capture a representation of the location identifier such as a numerical or alphanumerical representation of a two dimensional barcode an RFID tag an NFC tag etc. and communicate the representation of the location identifier to another computing device which can be carried by a worker or affixed to a cart being pushed by the worker through the fulfillment center. In some embodiments the capture device can transmit the representation of the location identifier to a fulfillment application executed by a computing environment via a network. In response to capturing of a location identifier the user interface rendered upon the display of the wearable computing device can be updated in response to the changing location of the wearable computing device . In other words as the worker moves throughout the fulfillment center information about a task being performed by or assigned to the worker can be provided in the user interface rendered by the wearable computing device based upon the cart s location and or a step in a task being performed by the worker.

The user interface can also be updated in response to the changing orientation of the wearable computing device . Because the wearable computing device can take the form of augmented reality glasses that are worn on the user s head and in which the user interface is rendered upon one or more lenses of the augmented reality glasses it may be the case that the visual indicator requires updating as the user moves his or her head while moving through the fulfillment center as well as when the user is standing still within the fulfillment center. Accordingly the wearable computing device can also be equipped with one or more sensors that can detect movement acceleration orientation and other aspects of the position of the device.

In the example of the visual indicator comprises a target that indicates the location within the field of view of the user of the particular bin that corresponds to the worker instruction that is also rendered within the user interface . The visual indicator can take one form when the user is located outside of a particular proximity radius of the particular bin and as the user approaches the particular bin the visual indicator may change as the bin is more visible within the field of view. As will be described herein the bins within a fulfillment center may also be associated with a barcode identifier or other type or location identifier or location beacon that can be detected by the wearable computing device so that a particular bin can be identified when it is within the field of view of the wearable computing device .

Reference is now made to which depicts a non limiting example pictorial diagram of a fulfillment center . In the context of the present disclosure a fulfillment center is any materials handling facility where items are received and stored orders for items are fulfilled and or shipments of items corresponding to orders originate. As such a fulfillment center may for example correspond to a warehouse a distribution center a processing center or a similar structure. A fulfillment center may be divided into multiple sections. For example a fulfillment center may include one or more inventory storage areas one or more sorting packing areas and one or more receiving loading areas where shipments are received into the fulfillment center or loaded onto delivery vehicles for delivery to customers or other recipients pursuant to orders for such items. The fulfillment center may also have one or more mechanisms or methods for moving items between sections including conveyors forklifts robotic handling equipment and other means. In addition a fulfillment center may have one or more pickers or other employees who traverse pick routes or other paths generated by a shipment or order fulfillment system or process in order to retrieve items within the fulfillment center for shipment.

The inventory storage area includes one or more item locations where one or more items may be located for long term or bulk storage. An item location may correspond to any number of physical structures. For example a shelf set of shelves a pallet on a floor a bin and or a series of bins or similar structures may be considered to be an item location . Item locations can be arranged in rows within the inventory storage area and or any other area of the fulfillment center .

Items stored or stocked in the fulfillment center include physical goods available for order and shipment from the fulfillment center . Items may include for example books compact discs CDs digital video discs DVDs televisions cameras stereo systems computers pots pans appliances exercise equipment power tools garden tools furniture toys clothes cosmetics medicine medical supplies jewelry sporting goods and or equipment meat fruit vegetables canned goods dairy products and or other goods or products.

There is no requirement that identical items be stored together at the same or neighboring item locations . In some embodiments it may be more efficient to organize the inventory storage area such that identical or similar items are stored together. For example all DVD s may be stored in a group or cluster of adjacent item locations with all DVD s corresponding to a particular movie located in a single item location . In other embodiments it may be more efficient to store an item in any item location with sufficient capacity. In such embodiments multiple instances of the same item may be stored in separate item locations in various locations of the inventory storage area . For example DVD s corresponding to a particular movie may be located in multiple item locations spread throughout the inventory storage area for more efficient accessibility in certain situations or scenarios.

Additionally in some embodiments items may be randomly or pseudo randomly assigned to item locations throughout the fulfillment center based upon availability of space in an item location . In other words a worker and or robot can stock or stow an item in a given item location if there is space in the item location and then identify to an application or program tasked with tracking inventory the item location in which an item is placed. In some embodiments identification of an item location in this way can be accomplished by scanning a barcode or other identifier associated with the item location and transmitting an identifier of the item location to the application or program tasked with tracking inventory.

The sorting packing area is where items are sorted and packed for shipment or received and sorted for storage. Within a sorting packing area items may be located at item locations according to various embodiments of the present disclosure. Items at item locations within the sorting packing area may be located such that workers may be able to quickly and efficiently retrieve items for fulfillment or shipments. Generally as items within the item locations of the sorting packing area are used to fulfill shipments items at item locations within the inventory storage area are automatically moved from the inventory storage area to the sorting packing area . The automated movement of items between the inventory storage area and the sorting packing area may be directed by automated systems or processes that track inventory levels at item locations within the sorting packing area and dispatch employees or automatons to transfer goods between the item locations within the inventory storage area and the item locations within the sorting packing area . The loading area is where items can be received shipped from the fulfillment center and or handed over to a carrier tasked with movement of the items to another location or destination external to the fulfillment center .

As noted above location identifiers can be positioned throughout the various areas of the fulfillment center . Location identifiers can uniquely identify a particular location within the fulfillment center . A location identifier as noted above can comprise a two dimensional barcode such as a quick response code that is positioned on the floor of the fulfillment center . If implemented as a visual identifier such as a barcode location identifiers can be sized such that an image capture device mounted on the wearable computing device that is moved through the fulfillment center by a worker can capture a representation of location identifiers as the user moves to various locations.

Location identifiers can be positioned throughout the entire fulfillment center or within certain areas of the fulfillment center . In one embodiment location identifiers can be positioned every few feet within individual rows in a fulfillment center within aisles linking rows of the fulfillment center to one another as in any other area of the fulfillment center at which a location identifier is desired. Location identifiers can also take the form of devices that transmit a localized wireless signal or identifier that can be detected by a wireless capability of the wearable computing device . Such an identifier can uniquely identify a location within the fulfillment center in the same way that a visible barcode identifier may identify a location within the fulfillment center .

Additionally it should be appreciated that the depicted diagram of a fulfillment center is given for illustrative purposes and that fulfillment centers can vary in size in terms of the number of item locations the number of rows of item locations the number of floors in the fulfillment center the arrangement of item locations and or rows of item locations and other properties of the fulfillment center as can be appreciated.

With reference to shown is a networked environment according to various implementations. The networked environment includes a computing environment as well as one or more wearable computing devices in data communication via a network . The network includes for example the Internet intranets extranets wide area networks WANs local area networks LANs wired networks wireless networks or other suitable networks etc. or any combination of two or more such networks.

The computing environment may comprise for example a server computer or any other system providing computing capability. Alternatively the computing environment may employ a plurality of computing devices that are arranged for example in one or more server banks or computer banks or other arrangements. Such computing devices may be located in a single installation or may be distributed among many different geographical locations. For example the computing environment may include a plurality of computing devices that together may comprise a hosted computing resource a grid computing resource and or any other distributed computing arrangement. In some cases the computing environment may correspond to an elastic computing resource where the allotted capacity of processing network storage or other computing related resources may vary over time.

Various applications and or other functionality may be executed in the computing environment according to various implementations. Also various data is stored in a data store that is accessible to the computing environment . The data store may be representative of a plurality of data stores as can be appreciated. The data stored in the data store for example is associated with the operation of the various applications and or functional entities described below.

The components executed on the computing environment for example include a fulfillment application and other applications services processes systems engines or functionality not discussed in detail herein. The fulfillment application is executed in order to facilitate fulfillment tasks within a fulfillment center. For example the fulfillment application can provide information about one or more tasks performed by workers within a fulfillment center such as the location of an item that the worker is directed to retrieve. It should be appreciated that while discussion of the fulfillment application is made in the context of fulfillment of orders made by users or customers of an electronic commerce system via a fulfillment center that the fulfillment application can also facilitate stocking of items in the fulfillment center or the stowing of items. To this end the fulfillment application can provide information about the location of a bin within the fulfillment center in which the worker is directed to stow an item that is being stocked.

The data stored in the data store includes for example fulfillment data . The fulfillment data includes data with which the fulfillment application can facilitate fulfillment of items via a fulfillment center in response to orders that are placed by users or customers of an electronic commerce system. In other words the fulfillment application can initiate locating retrieval from a stowage location packing and subsequent shipment of an item to a user ordering the item via an electronic commerce system. In one embodiment the fulfillment data can include a fulfillment center map which contains information about the location of items bins or other stowage locations in which items can be stored within one or more fulfillment center.

The fulfillment center map can identify one or more bins or stowage locations by an identifier as well as information about where in the fulfillment center the bin and or stowage location are located. For example a given bin can be identified by a unique identifier a floor row number shelf number bin location or any other information from which a worker and or robot within a fulfillment center can locate the given bin. Additionally the fulfillment center map can map location identifiers to specific locations within the fulfillment center . The fulfillment application using the fulfillment center map can facilitate the routing of workers within one or more fulfillment centers for efficient fulfillment of orders via the fulfillment centers. The fulfillment application can also determine routes from other points within the fulfillment center to a given location identifier such as from an entry or exit of the fulfillment center . The fulfillment application can also calculate routes between two or more location identifiers within the fulfillment center .

The fulfillment center map can also include a reference image of various rows or aisles within the fulfillment center along with an image map that maps a particular item location to the reference image. In this way the location within the image of a particular item location can be determined in relation to other item locations appearing within the image. Accordingly an image analysis can be performed using the reference image such that a location of a particular item location such as a bin can be identified in terms of a vector or distance from another item location appearing within the reference image.

Fulfillment data can also include order data from which fulfillment application can initiate fulfillment of items. Order data can include information about orders placed by users via an electronic commerce system and the fulfillment application can direct a worker and or robot within a fulfillment center to retrieve the item from a location within the fulfillment center based upon the order data . For example the order data can include information about which items are associated with a particular order a class of shipping associated with an order e.g. shipping speed a class of fulfillment associated with the order e.g. fulfillment speed or other information with which the fulfillment application can determine when and how a particular item associated with an order should be retrieved and shipped to a recipient.

Item data includes information about items that are stocked within a fulfillment center. Item data can include information such as product descriptions specifications or other information. Item data can also include an item identifier with which the item can be uniquely identified within a fulfillment center in which it is stocked. Item data can also include an item location which can identify one or more locations within a fulfillment center in which an item is stocked. The item location can also identify how many of a particular item are stocked in a given location. Such a location can be identified by one or more of a bin identifier a floor number a row number shelf number region or other data by which a given location can be identified within a fulfillment center.

The wearable computing device is representative of a plurality of wearable computing devices that may be coupled to the network . The wearable computing device may comprise for example a processor based system such as a computer system. Such a computer system may be embodied in the form of augmented reality glasses that project or render a user interface within the field of view of a user wearing or carrying the wearable computing device . It should be noted that a wearable computing device can be a device that can be carried by the user as opposed to literally worn by the user. In such a scenario the wearable computing device may be in communication with another device or display that renders a user interface within the field of view of the user. The wearable computing device may include a display . The display may comprise for example lenses that are positioned in front of the user s eyes upon which the user interface can be rendered such that the user interface is within the field of view of a user wearing or carrying the wearable computing device . Accordingly the display can comprise a miniaturized projection system that is integrated within the wearable computing device that projects the user interface onto lenses or glasses that are positioned in front of one or more eyes of the user.

The wearable computing device may be configured to execute various applications such as a client application and or other applications. The client application may be executed in a wearable computing device for example to access content served up by the computing environment and or other servers thereby rendering a user interface on the display . The client application can also render a user interface based upon data that is stored or cached within storage or memory of the wearable computing device . The wearable computing device may be configured to execute applications beyond the client application such as for example other augmented reality applications mobile applications messaging applications social networking applications photography applications location based applications and or other applications.

The wearable computing device can also include an image capture device which can include one or more cameras or image capture devices that can capture imagery and or video of items within a field of view of the user. In one embodiment the image capture device can be mounted on a frame of the wearable computing device and aimed toward the wearer s field of view such that it captures imagery of what is located in front of the user s head. The image capture device can be accessed by the client application so that the client application can perform analyses on the imagery captured by the image capture device . In some embodiments the client application can be configured to sample imagery captured by the image capture device to facilitate the rendering of a user interface that is displayed on the display .

The wearable computing device can also be configured with wireless communication capabilities such as wireless local area network WLAN capability that can be employed to facilitate communications with the computing environment via the network . Additionally the wearable computing device can also be equipped with personal area network PAN wireless communications capabilities such as a Bluetooth capability. In any form the wireless communications capabilities of the wearable computing device can allow the wearable computing device to detect location beacons that are positioned throughout the fulfillment center . A location beacon can comprise a device that emits a wireless signal indicating a location within the fulfillment center . Such a location beacon can emit a location identifier that can be captured by the wireless communications capabilities of the wearable computing device and in turn by the client application .

The wearable computing device can also be equipped with one or more position sensors that can provide information about orientation and or movement of the wearable computing device . For example position sensors can include accelerometers altimeters speedometers or other sensors that can provide pitch data yaw data roll data velocity acceleration or other information related to movement and orientation of the wearable computing device . In one embodiment the wearable computing device can execute an operating system that provides an application programming interface API that provides API calls with which the client application can access information about device position and or orientation or other data obtained by the position sensors .

The wearable computing device can also be configured to store map data that can correspond to at least a subset of the fulfillment center map . In other words the wearable computing device can cache information about location identifiers positioned throughout the fulfillment center as well as information about products and or inventory storage locations that are positioned throughout the fulfillment center . In this way the client application can rely upon cached map data to facilitate the rendering of information in the user interface including worker instructions and or visual indicators rather than relying upon the fulfillment application executed in the computing environment to provide location information with which the user interface can be created. For example map data can include reference images of aisles or rows within the fulfillment center that correspond to items that the worker may encounter during a shift or a given period of time so that the client application can perform image analyses on the reference image as compared against imagery captured by the image capture device in order to render or update a visual indicator appearing within a user interface .

The wearable computing device can also be configured to store a work queue which can include information about the various tasks associated with a given worker or user assigned to a particular wearable computing device . For example a user may authenticate with the fulfillment application via a login user interface provided by the client application and the wearable computing device . The fulfillment application can then transmit information about the various tasks to be performed by the user during a particular shift and or a given period of time. In such a scenario the client application can also retrieve and cache map data identifying location information about item locations of the items to be retrieved by the user during the given period of time as well as data regarding location identifiers that are near the item locations . In this way the client application can generate worker instructions and or visual indicators in the user interface without relying exclusively on data obtained in real time from the fulfillment application .

Next a general description of the operation of the various components of the networked environment is provided. To begin the fulfillment application can facilitate providing information in the form of a user interface and or user interface updates that are rendered upon the display of a wearable computing device that provides information about a task for a worker within the fulfillment center . For example such a task can include an instruction to retrieve an item from an item location within the fulfillment center to a sorting packing area . As another example a task can include an instruction to stow an item in an item location within the fulfillment center . Accordingly a user interface rendered by the wearable computing device can be generated by the client application and or the fulfillment application that includes a worker instruction a visual indicator and or information about at least a portion of a task to be completed by the worker.

For example the worker instruction can include a location of an item that needs retrieval from an item location in the fulfillment center as well as turn by turn directions to the item location as determined from the current location of the wearable computing device as determined by the client application in response to detection of a location identifier within the field of view of the wearable computing device that is captured by the image capture device . As another example the worker instruction can also include turn by turn directions to an item location and or a region within the fulfillment center at which an item can be stowed by the worker. Accordingly as a user wearing a wearable computing device moves throughout the fulfillment center the wearable computing device can capture representations of location identifiers within the fulfillment center . These location identifiers can be affixed to the floor of the fulfillment center or other surfaces within the fulfillment center . These location identifiers can be captured periodically such as every few seconds milliseconds or other quantum of time.

As the wearable computing device captures these representations they can be transmitted to the fulfillment application . In response to receiving a representation of a location identifier the fulfillment application can determine whether a worker instruction displayed in a user interface should be updated in response to a changed location of the wearable computing device . In one embodiment the fulfillment application can generate turn by turn instructions to a destination within the fulfillment center based upon the location of the wearable computing device and the worker instruction and or visual indicator on the user interface that directs the user as to a direction in which the worker should proceed can be updated as the location of the wearable computing device is updated in the form of location identifiers that are captured by the wearable computing device .

Additionally should a worker proceed too far or pass a destination to which the worker has been directed the fulfillment application can generate a worker instruction that informs the worker to stop and or turn around in order to arrive at the destination. In some embodiments the worker instruction can also include an alert that the worker has arrived at his or her destination such as a particular item location within the fulfillment center . In some embodiments the client application may alert the worker about an arrival at a destination via a vibration caused by a motor or other tactile haptic feedback an audible alert or a visual alert rendered on the display of the wearable computing device .

In some embodiments the fulfillment application and or client applications executed by multiple instances of wearable computing devices can generate turn by turn instructions to optimize the flow of workers through the fulfillment center . In other words the fulfillment application can direct workers via turn by turn instructions according to a route that minimizes collisions with other workers wearing wearable computing devices in the fulfillment center .

As shown in the example scenario shown in the client application can also render a visual indicator in the user interface that can serve various purposes. The visual indicator can highlight or identify an item of interest that is located within the field of view of the user. Such an item of interest may be identified by the wearable computing device via the image capture device . The item of interest may comprise for example an item location such as a bin shelf or item in the fulfillment center .

In order to identify an item of interest the client application can perform an image analysis of imagery captured by the image capture device . Items in the fulfillment center such as item locations e.g. bins shelves etc. can have location identifiers affixed to them such as a barcode identifier RFID tag location beacon etc. Accordingly as a user wearing a wearable computing device moves throughout the fulfillment center the client application can periodically capture location identifiers that appear within the fulfillment center via the image capture device and or wireless capabilities of the wearable computing device . In response to capturing a location identifier for which location information can be determined from the map data the client application can render or update a visual indicator in the user interface .

For example if a current task of a user comprises the storage or retrieval of an item from a particular item location a visual indicator can indicate a location within the field of view of the user at which the item location is located. In order to render such a visual indicator the client application performs an image analysis of the field of view by comparing it against a reference image of a particular aisle or row in which the item location is located. Accordingly even if a location identifier of a particular item location is not visible within the field of view the image capture device or wireless capabilities of the wearable computing device may be able to capture a location identifier within the field of view of another item location appearing within the field of view.

As noted above map data or the fulfillment center map can include a reference image of an aisle or row along with an image map that maps the location of item locations in relation to one another. Therefore the image analysis performed by the client application can determine the location within the field of view of the user by comparing the field of view as captured by the image capture device with the reference image. Accordingly the visual indicator highlighting a location of an item location within the field of view can be rendered upon the display upon performing such an image analysis. Such an analysis can be performed periodically such as multiple times per second or any other quantum of time such that the visual indicator is updated as the user moves his or her head or moves throughout the fulfillment center .

The visual indicator can also be updated in response to data from the position sensors of the wearable computing device . For example as the user moves his or her head or moves throughout the fulfillment center the client application can update the location of the visual indicator in response to detecting movement from position sensor data. Such data can include orientation data pitch yaw accelerometer data or other data from which the orientation of the wearable computing device can be determined.

In some embodiments the client application executed by the wearable computing device can be configured to provide worker instructions and or visual indicators to a worker wearing the wearable computing device who is not moving or navigating throughout a fulfillment center . For example a worker may be positioned in an area of a fulfillment center to which items are brought by robotic devices and or a conveyor system and where the worker is directed to pack and or ship items that are brought to the location of the worker. In one scenario the client application executed by the wearable computing device can capture identifiers that are associated with an item retrieved by the robotic device and consult the fulfillment application and or the work queue to determine whether the worker instruction and or visual indicator rendered upon the display should be updated.

In one embodiment a robotic device can be configured to transmit an identifier to the wearable computing device that uniquely identifies the robotic device with respect to other robotic devices. In response to obtaining such an identifier the client application can consult the fulfillment application and or the work queue to determine whether and how to update the worker instruction and or visual indicator . For example the worker instruction can be updated to instruct the worker as to which item to retrieve from a robotic device arriving within a proximity of the wearable computing device .

Referring next to shown is an example of a user interface rendered by a wearable computing device illustrating an example of a worker instruction as well as a visual indicator that can be rendered upon a display of the wearable computing device according to various embodiments of the disclosure. The user interface shown in includes a worker instruction that is based upon a location determined by the client application in response to capturing a representation of one or more location identifiers appearing within the field of view of the wearable computing device . The location identifiers are captured by the image capture device that can be integrated within the wearable computing device or in communication with the wearable computing device . In the depicted example the worker instruction comprises a navigational direction to a destination within the fulfillment center as well as information about a task to be performed by the user. As shown in the worker instruction comprises an identity of an item location to which the worker should proceed as well as an instruction to retrieve an item that is stored in the item location .

The worker instruction can be generated by the client application and be generated based at least in part upon a current location within the fulfillment center of the wearable computing device as determined by the client application and or the fulfillment application . Additionally the user interface also includes a visual indicator that can provide a visual aid to the worker and that is also rendered upon the display by the wearable computing device . In the example shown in the visual indicator rendered by the client application comprises an arrow indicating a turn by turn direction that facilitates navigation to the item location identified by the worker instruction .

In this way the worker instruction and the visual indicator can be generated by the client application based at least in part upon the work queue associated with a particular worker the location of the wearable computing device within the fulfillment center and the map data that is cached in the wearable computing device . In some embodiments the fulfillment application can generate the worker instruction and visual indicator rather than the client application executed by the wearable computing device . In such a scenario the fulfillment application can transmit the worker instruction and visual indicator to the client application via the network which can be rendered upon the display by the client application .

Continuing the example of reference is now made to which illustrates an updated user interface rendered by the client application upon the display of the wearable computing device . In the example of the worker instruction is updated based upon an updated location of the wearable computing device as determined by the client application as well as an image analysis performed by the client application . As noted above the client application can perform an image analysis on imagery of the field of view of the user wearing the wearable computing device that is captured by the image capture device of the wearable computing device .

In the example of the visual indicator is overlaid onto a location of the item or item location within the field of view of the user that is associated with a task indicated by the worker instruction . As described above the location of the item within the field of view of the user can be determined based upon an image analysis of the field of view as compared against a reference image of the aisle in which the item or item location is located.

Continuing the example of reference is now made to . illustrates an updated user interface in which the visual indicator has been updated based upon an updated location and or orientation of the wearable computing device relative to the scenario shown in . In the example of the user has moved forward into the aisle in which the item location specified by the worker instruction is located. Accordingly the client application can detect the updated location of the wearable computing device by detecting one or more location identifiers appearing within the field of view of the wearable computing device . The wearable computing device can then update the visual indicator by capturing location identifiers within the field of view of the user and determining a relative distance from the location identifiers that are visible within the field of view to the item location .

In other words as is described above the client application can determine a location within the display at which the visual indicator should be placed by performing an image analysis of the field of view of user as reflected in imagery captured by the image capture device . The client application can perform such an image analysis periodically such as multiple times per second multiple times per millisecond or any other quantum of time. Additionally an event based model can be employed where the visual indicator is updated when one or more position sensors indicate that the location and or orientation of the wearable computing device has changed by more than a threshold amount. In such a scenario a change in the location or orientation of the wearable computing device by more than a threshold amount indicates that the location of the visual indicator should be updated.

Accordingly the position of the item location within the field of view in this scenario is determined based upon the relative location of the item location as compared to those location identifiers that can be identified within the field of view. The relative location of the item location as compared to those location identifiers that can be identified within the field of view is determined by performing an image analysis of the field of view as captured by the image capture device of the wearable computing device .

Reference is now made to which continues the example of . In the user has approached and found the item location associated with a particular task. In the example shown in the client application can identify a barcode identifier or other type of identifier associated with the item location to which a particular item to be retrieved by the worker is assigned. Accordingly as shown in as the user approaches the item location the client application can identify the location identifier associated with the item location that is associated with the task that the user was tasked with completing. In the example shown in the location identifier comprises a QR code but the location identifier can comprise any barcode identifier textual identifier or any other identifier that can be captured by the image capture device and or the client application .

Accordingly once the user has arrived at the specified item location the client application can transmit an indication that the user has arrived at the item location and or update the work queue to indicate that the user has arrived at the item location associated with a given task assigned to the worker. As noted above such a task can include retrieval of an item from a particular item location as well as stowage of an item at the item location .

Continuing the example of reference is now made to which illustrates an example of how the client application can also identify a barcode identifier associated with a particular item or product stored within the fulfillment center . Accordingly the client application can verify whether the item located in the item location is the item expected to be in the item location . Accordingly the client application can report to the fulfillment application that the item has been retrieved by the worker and or update the work queue stored in the wearable computing device . Additionally the worker instruction can also be updated by the client application to provide confirmation to the user that the item was identified by the client application . In this way upon confirmation that the item was identified the user may then place the item in a cart and proceed to a next task in the user s workflow.

Continuing the example of reference is now made to which continues the example of . As shown in upon confirmation that the item in the item location was scanned by the image capture device of the wearable computing device the client application can update the worker instruction to provide information about a next task to which the worker is assigned. Information about the next task to which the worker is assigned can be retrieved from the work queue and or from the fulfillment application . Such a next task can include for example another item that the worker should retrieve from an item location instructions to proceed to another portion of the fulfillment center such as to the sorting packing area .

Referring next to shown is a flowchart that provides one example of the operation of a portion of the fulfillment application and or client application according to various implementations. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the fulfillment application and or client application as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the computing environment and or wearable computing device according to one or more implementations.

Beginning with box the fulfillment application and or client application can obtain a representation of a location identifier captured by an image capture device or other capability of a wearable computing device being moved through the fulfillment center by a worker. At box the wearable computing device can determine its location within the fulfillment center based upon an analysis of the location identifier transmitted to the fulfillment application . At box the client application and or fulfillment application can determine whether a worker instruction and or visual indicator in a user interface rendered by the client application should be updated in response to the updated location of the wearable computing device .

As noted above such an updated worker instruction and or visual instruction can be a turn by turn instruction the identity of an item to be picked or stowed or any other instruction that can be updated in response to the location of the wearable computing device . At box the client application can render the updated user interface in response to determining that the user interface should be updated.

Referring next to shown is a flowchart that provides one example of the operation of a portion of the client application according to various implementations. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the client application as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the wearable computing device according to one or more implementations.

At box the client application can capture imagery of a field of view of the wearable computing device via the image capture device associated with the wearable computing device . At box the client application can obtain a representation of at least one location identifier within the field of view. As noted above a location identifier may be affixed to various locations within the fulfillment center such as a floor walls onto item locations or other positions within the fulfillment center . At box the client application can perform an image analysis of the field of view of the wearable computing device by comparing the field of view to reference images of the location corresponding to the field of view.

At box the client application can identify an item of interest within the field of view relative to the identified location identifiers within the field of view. The item of interest can correspond to an item location an item or other location within the fulfillment center that is related to a particular task associated with the user and for which a worker instruction and or visual indicator is displayed. In some situations a location identifier identified within the field view corresponds to the particular item of interest corresponding to the worker instruction and or visual indicator . At box the client application can identify the relative position of the item of interest from identified location identifiers within the user interface . At box the client application can render the user interface including a worker instruction and or a visual indicator .

Referring next to shown is a flowchart that provides one example of the operation of a portion of the client application according to various implementations. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the client application as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the wearable computing device according to one or more implementations.

At box the client application can detect a change in the position and or orientation of the wearable computing device from position sensor data. At box the client application can obtain a representation of at least one location identifier within the field of view of the wearable computing device . As noted above a location identifier may be affixed to various locations within the fulfillment center such as a floor walls onto item locations or other positions within the fulfillment center . At box the client application can perform an image analysis of the field of view of the wearable computing device by comparing the field of view to reference images of the location corresponding to the field of view.

At box the client application can identify an item of interest within the field of view relative to the identified location identifiers within the field of view. The item of interest can correspond to an item location an item stocked within the fulfillment center or other location within the fulfillment center that is related to a particular task associated with the user and for which a worker instruction and or visual indicator is displayed. In some situations a location identifier identified within the field view corresponds to the particular item of interest corresponding to the worker instruction and or visual indicator . At box the client application can identify the relative position of the item of interest from identified location identifiers within the user interface . At box the client application can render the user interface including a worker instruction and or a visual indicator .

With reference to shown is a schematic block diagram of the computing environment according to an embodiment of the present disclosure. The computing environment includes one or more computing devices . Each computing device and or the wearable computing device includes at least one processor circuit for example having a processor and a memory both of which are coupled to a local interface . To this end each computing device may comprise for example at least one server computer or like device. The local interface may comprise for example a data bus with an accompanying address control bus or other bus structure as can be appreciated.

Stored in the memory are both data and several components that are executable by the processor . In particular stored in the memory and executable by the processor is the fulfillment application and potentially other applications. Also stored in the memory may be a data store and other data. In addition an operating system may be stored in the memory and executable by the processor .

It is understood that there may be other applications that are stored in the memory and are executable by the processor as can be appreciated. Where any component discussed herein is implemented in the form of software any one of a number of programming languages may be employed such as for example C C C Objective C Java JavaScript Perl PHP Visual Basic Python Ruby Flash or other programming languages.

A number of software components are stored in the memory and are executable by the processor . In this respect the term executable means a program file that is in a form that can ultimately be run by the processor . Examples of executable programs may be for example a compiled program that can be translated into machine code in a format that can be loaded into a random access portion of the memory and run by the processor source code that may be expressed in proper format such as object code that is capable of being loaded into a random access portion of the memory and executed by the processor or source code that may be interpreted by another executable program to generate instructions in a random access portion of the memory to be executed by the processor etc. An executable program may be stored in any portion or component of the memory including for example random access memory RAM read only memory ROM hard drive solid state drive USB flash drive memory card optical disc such as compact disc CD or digital versatile disc DVD floppy disk magnetic tape or other memory components.

The memory is defined herein as including both volatile and nonvolatile memory and data storage components. Volatile components are those that do not retain data values upon loss of power. Nonvolatile components are those that retain data upon a loss of power. Thus the memory may comprise for example random access memory RAM read only memory ROM hard disk drives solid state drives USB flash drives memory cards accessed via a memory card reader floppy disks accessed via an associated floppy disk drive optical discs accessed via an optical disc drive magnetic tapes accessed via an appropriate tape drive and or other memory components or a combination of any two or more of these memory components. In addition the RAM may comprise for example static random access memory SRAM dynamic random access memory DRAM or magnetic random access memory MRAM and other such devices. The ROM may comprise for example a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other like memory device.

Also the processor may represent multiple processors and or multiple processor cores and the memory may represent multiple memories that operate in parallel processing circuits respectively. In such a case the local interface may be an appropriate network that facilitates communication between any two of the multiple processors between any processor and any of the memories or between any two of the memories etc. The local interface may comprise additional systems designed to coordinate this communication including for example performing load balancing. The processor may be of electrical or of some other available construction.

Although the fulfillment application and client application and other various systems described herein may be embodied in software or code executed by general purpose hardware as discussed above as an alternative the same may also be embodied in dedicated hardware or a combination of software general purpose hardware and dedicated hardware. If embodied in dedicated hardware each can be implemented as a circuit or state machine that employs any one of or a combination of a number of technologies. These technologies may include but are not limited to discrete logic circuits having logic gates for implementing various logic functions upon an application of one or more data signals application specific integrated circuits ASICs having appropriate logic gates field programmable gate arrays FPGAs or other components etc. Such technologies are generally well known by those skilled in the art and consequently are not described in detail herein.

The flowcharts of show the functionality and operation of an implementation of portions of the fulfillment application and or client application . If embodied in software each block may represent a module segment or portion of code that comprises program instructions to implement the specified logical function s . The program instructions may be embodied in the form of source code that comprises human readable statements written in a programming language or machine code that comprises numerical instructions recognizable by a suitable execution system such as a processor in a computer system in the wearable computing device or other system. The machine code may be converted from the source code etc. If embodied in hardware each block may represent a circuit or a number of interconnected circuits to implement the specified logical function s .

Although the flowcharts of show a specific order of execution it is understood that the order of execution may differ from that which is depicted. For example the order of execution of two or more blocks may be scrambled relative to the order shown. Also two or more blocks shown in succession in may be executed concurrently or with partial concurrence. Further in some embodiments one or more of the blocks shown in may be skipped or omitted. In addition any number of counters state variables warning semaphores or messages might be added to the logical flow described herein for purposes of enhanced utility accounting performance measurement or providing troubleshooting aids etc. It is understood that all such variations are within the scope of the present disclosure.

Also any logic or application described herein including the fulfillment application and or client application that comprises software or code can be embodied in any non transitory computer readable medium for use by or in connection with an instruction execution system such as for example a processor in a computer system or other system. In this sense the logic may comprise for example statements including instructions and declarations that can be fetched from the computer readable medium and executed by the instruction execution system. In the context of the present disclosure a computer readable medium can be any medium that can contain store or maintain the logic or application described herein for use by or in connection with the instruction execution system.

The computer readable medium can comprise any one of many physical media such as for example magnetic optical or semiconductor media. More specific examples of a suitable computer readable medium would include but are not limited to magnetic tapes magnetic floppy diskettes magnetic hard drives memory cards solid state drives USB flash drives or optical discs. Also the computer readable medium may be a random access memory RAM including for example static random access memory SRAM and dynamic random access memory DRAM or magnetic random access memory MRAM . In addition the computer readable medium may be a read only memory ROM a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other type of memory device.

Further any logic or application described herein including fulfillment application and client application may be implemented and structured in a variety of ways. For example one or more applications described may be implemented as modules or components of a single application. Further one or more applications described herein may be executed in shared or separate computing devices or a combination thereof. For example a plurality of the applications described herein may execute in the same computing device or in multiple computing devices in the same computing environment or within the wearable computing device . Additionally it is understood that terms such as application service system engine module and so on may be interchangeable and are not intended to be limiting.

Disjunctive language such as the phrase at least one of X Y or Z unless specifically stated otherwise is otherwise understood with the context as used in general to present that an item term etc. may be either X Y or Z or any combination thereof e.g. X Y and or Z . Thus such disjunctive language is not generally intended to and should not imply that certain embodiments require at least one of X at least one of Y or at least one of Z to each be present.

It should be emphasized that the above described embodiments of the present disclosure are merely possible examples of implementations set forth for a clear understanding of the principles of the disclosure. Many variations and modifications may be made to the above described embodiment s without departing substantially from the spirit and principles of the disclosure. All such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims.

