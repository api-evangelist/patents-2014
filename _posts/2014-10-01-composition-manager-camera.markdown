---

title: Composition manager camera
abstract: A system and method may be provided to access images through a camera service, where the images are generated by a non-sensor image source, such as a composition manager. The system may include the camera service and the non-sensor image source. The non-sensor image source may generate a processed image from a source other than a sensor. The camera service may provide the processed image generated by the non-sensor image source to an image consuming application.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09183657&OS=09183657&RS=09183657
owner: 2236008 Ontario Inc.
number: 09183657
owner_city: Waterloo, Ontario
owner_country: unknown
publication_date: 20141001
---
This application is a continuation application of and claims priority to U.S. non provisional application Ser. No. 13 591 574 filed Aug. 22 2012 which issued as U.S. Pat. No. 8 878 862 on Nov. 4 2014.

Graphics systems may have multiple software applications that generate content. The content from the software applications may be composited together into a single graphic. The composition may occur in software hardware or a combination of both.

A system may access images through a camera service where the images are generated by a non sensor image source instead of a camera. The system may include an image buffer the camera service and the non sensor image source that populates the image buffer. The non sensor image source may generate an image from sources other than a sensor. One example of the non sensor image source is a composition manager which may include a processor that generates a processed image in the image buffer based on an application image where the application image is rendered in an application buffer by a first application. The camera service may receive a request from a second application to select an image source from which to receive graphics content. The image source may be selected from among a set of possible image sources such as from a set that includes the non sensor image source and a camera. The camera service may provide the graphics content in the image buffer to the second application based on a selection of the non sensor image source as the image source by the second application.

Because the camera service may provide the graphics content from the non sensor image source to an application the camera service may facilitate the application receiving a screen shot a screen capture video or some other type of image generated by the non sensor image source. For example the composition manager may generate the screen shot or the screen capture video in the image buffer and the camera service may provide the screen shot or the screen capture video to the application in a desired format.

Alternatively or in addition the camera service may facilitate spanning or mirroring of displays by providing the graphics content from the non sensor image source to a remote display driver. For example the image buffer of the non sensor image source may be a writeback buffer the camera service may provide the graphics contents of the writeback buffer to the remote display driver and the remote display driver may encode the graphics content in a video stream that is transmitted to an external or remote display device.

In some examples a second display may be supported by selecting a media player as the non sensor image source. The media player may provide a video stream to the camera service and the camera service may provide the video stream to an application that encodes and transmits the video stream to an external or remote display device. The media player may provide a different display image for an integrated display. For example the display image for the integrated display may include a graphical user interface to control the video stream that is provided to the external or remote display device.

The system may include the camera service and one or more image sources and such as the non sensor image source and the sensor image source . The system may also include applications and that obtain images through the camera service applications that do not use the camera service application buffers an integrated display and an external display .

One or more components of the system may be included in a device such as a mobile computing device or any other type of computing device. For example the applications and the application buffers the camera service the sensor image source the non sensor image source and the integrated display may be included in the device .

The sensor image source may be any component that generates an image from a sensor . Examples of the sensor image source include a camera an integrated camera an external camera a video camera an infrared camera a thermal imaging device a web cam a scanner a facsimile machine or any other component that may generate the image from the sensor .

The sensor image source may include the sensor an image signal processor and a sensor image buffer . The sensor may be any type of sensor that detects light heat or any other physical characteristics from which the sensor image source may generate an image. The image signal processor may be any processor that converts signals generated by the sensor into an image represented in the sensor image buffer .

In contrast the non sensor image source may be any component that generates and or includes an image from sources other than a sensor. For example the non sensor image source may include an application display component or other type of image processor. The non sensor image source does not include devices that merely read image data from a storage medium such as optical drives hard drives and flash drives. Alternatively the non sensor image source may be any software or hardware component that generates renders or decodes graphic images. For example the non sensor image source may include an application such as Microsoft Word POWERPOINT a registered trademark of Microsoft Corporation of Redmond Wash. or PHOTOSHOP a registered trademark of Adobe Systems Incorporated of San Jose Calif. that populates a corresponding application buffer . Additional examples of the non sensor image source may include an HTML Hypertext Markup Language rendering engine such as WEBKIT a registered trademark of Apple Inc. Cupertino Calif. a YOUTUBE a registered trademark of Google Inc. of Mountain View Calif. HTML5 Hypertext Markup Language version 5 player or a video decoding application or engine such as a FLASH a registered trademark of Adobe Systems Incorporated of San Jose Calif. player. Alternatively or in addition the non sensor image source may be or include memory such as a buffer a cache or a storage medium.

The application display component may be any component that generates the image from an application image and or a graphical user interface GUI where the application image and or the GUI is generated by one or more of the applications and the image generated is to be displayed. For example the application display component may include a composition manager . The composition manager may be any component that generates a composite image for display on a display device such as the integrated display and or the external display . In particular the composition manager may generate the composite image by combining application images represented in the application buffers and rendered by the applications and . The composition manager may include one or more processors such as a Central Processing Unit CPU a Graphics Processing Unit GPU a 2D two Dimensional engine and or a display controller.

In addition to or instead of the composition manager the application display component may include a different type of application display component. For example the application display component may be a window manager a display controller or a graphics converter implemented in software or hardware. The application display component may include a processor that modifies pixel data read from the application buffer s in any number of ways when generating the image for display. For example the application display component may include a processor that converts a color space of pixels of the application image and or a combination of the application images when generating the image from the application image and or the combination of the application images. Alternatively or in addition the application display component may include a processor that resizes pixel data of the application image and or the combination of the application images crops the pixel data blits the pixel data and or filters the pixel data.

The non sensor image source may include the composition manager and or any other type of application display component. In addition the non sensor image source may include an image buffer and an image buffer controller .

The image buffer may be memory in which the image generated by the non sensor image source is stored. For example the image buffer may be a writeback buffer populated by the composition manager . The writeback buffer may be a buffer populated by a hardware component of the composition manager where the data stored in the buffer represents an image output by the hardware component as a byproduct of the generation of the image for display. The writeback buffer may represent the composite image. Alternatively the writeback buffer may represent an image that is derived from the composite image such as an off screen portion of one or more of the application images. Alternatively the writeback buffer may represent some other image such as the application image generated by one of the applications .

The image buffer controller may be any component that controls characteristics of the image represented in the image buffer and or processes the contents of the image buffer before delivering the processed contents to the camera service . The image buffer controller may be a component separate from the application display component or alternatively included in the application display component. For example the image buffer controller may be separate from the composition manager or alternatively included in the composition manager .

The camera service may be any component that provides access to the image sources and through a camera oriented interface to one or more image consuming applications such a video chat application a remote display driver and a camera application . The camera service may execute as part of a process that invokes the camera service . Alternatively or in addition the camera service may execute as a background process a web service or as any other type of process.

The camera oriented interface may include an implementation of a camera API Application Programming Interface . The camera API may provide a unified view of the image sources and that treats each of the image sources and as a camera even if the respective image source and is not a camera. In addition the camera API may provide access to the image sources and that is specific to one or more types of the image sources and .

The camera API may include a camera oriented interface through which the image consuming application or may select the image source or from which to receive graphics content. Alternatively or in addition the camera API may provide a camera oriented interface through which the image consuming application or may receive the graphics content. Alternatively or in addition the camera API may provide a camera oriented interface through which the image consuming application or may specify a target format in which to receive the graphics content. The camera API may provide the graphics content to the image consuming application or in the target format specified.

The applications and that receive graphics content through the camera service may include for example a video chat application a remote display driver and a camera application . The applications and that receive graphics content through the camera service may include additional fewer or different applications.

The camera application may be any application that provides a GUI through which a user may take a picture and or stream a video received from a camera through the camera service . An example of the camera application is a mobile app entitled Camera on a mobile device such as an IPHONE which is a registered trademark of Apple Inc. of Cupertino Calif. and a device running the ANDROID operating system which is a trademark of Google Inc. of Mountain View Calif.

The remote display driver may be a component that provides a video stream and or a static image to a remote display device where the remote display driver receives the static image and or the video stream or sequence of images through the camera service from the selected image source or . The remote display device may be any electro optical device for displaying data such as a light emitting diode LED display a liquid crystal display LCD a cathode ray tube CRT an electro luminescent display a plasma display panel PDP a vacuum florescent display VFD a projector or any other display device. The remote display driver may transmit the static image and or the video stream to the remote display device over a network and or over cabling such as an HDMI High Definition Multimedia Interface cable HDMI is a registered trademark of HDMI LICENSING L.L.C. of Sunnyvale Calif. . The network may include a local area network LAN a wireless local area network WLAN a WI FI a registered trademark of Wireless Ethernet Compatibility Alliance Inc. of Austin Tex. network a personal area network PAN a wide area network WAN the Internet an Internet Protocol IP network a DLNA Digital Living Network Alliance network DLNA is a registered trademark of the Digital Living Network Alliance of Lake Oswego Oreg. any other communications network or any combination thereof. In some examples the remote display device may be a WI FI display. In a different example the remote display device may be a monitor and or a television that receives the video stream and or the static image over an HDMI cable.

The video chat application may be a component that provides a user interface through which a user may communicate with other users over audio and or video channels. The video chat application may for example communicate between two or more devices using Voice over Internet Protocol VoIP or any other voice communication protocols such as any of International Telecommunications Union ITU standards H.320 H.264 H.324 or V.80.

During operation of the system each of the applications and that generates a respective application image may render the respective application image in the corresponding application buffer . The applications and that generate the application images may include a set of the applications that generate a GUI and do not use the camera service . Alternatively or in addition the applications and that generate the application images may include a set of the applications and that generate a GUI and use the camera service such as the video chat application and the camera application . For example the video chat application may render a GUI in the application buffer corresponding to the video chat application . The GUI rendered by the video chat application may be a user interface through which a user may control the video chat application .

The application display component such as the composition manager may generate a processed image in the image buffer from the application images that are represented in the application buffers . For example the composition manager may generate a composite image in the image buffer that is a composition of the application images represented in the application buffers . The composition manager and or additional hardware may cause the composite image to be displayed on a display device such as the integrated display and the external display . Alternatively the processed image represented in the image buffer may be an image different than the composite image. For example the processed image may be an off screen portion derived from one or more of the application images.

Any of the applications and may communicate with the camera service and select the non sensor image source as the image source. For example the remote display driver may select the non sensor image source as the image source through the camera service . By selecting the non sensor image source the remote display driver may receive an image and or a video from the non sensor image source as if the non sensor image source were a camera. When the non sensor image source is the application display component such as the composition manager the image buffer may represent the composite image displayed in the integrated display . When the image buffer represents the composite image the remote display driver may receive a screen snapshot and or a screen capture video from the application display component through the camera service . The remote display driver may transmit the screen snapshot and or the screen capture video to the remote display device thereby mirroring the image displayed on the integrated display to the remote display device .

Alternatively or in addition the video chat application may implement a share my screen feature or share an application feature by selecting the application display component such as the composition manager as the image source from which to receive the graphics content through the camera service . The share my screen feature shares the content of the image displayed on the integrated display with devices on the network . The share an application feature shares the content of the application image generated by one or more of the applications and with devices on the network .

When the image buffer represents the image on the integrated display then the video chat application may receive a screen snapshot and or a screen capture video from the application display component through the camera service . The video chat application may communicate the screen snapshot and or the screen capture video received from the camera service to one or more remote devices as part of an implementation of the share my screen feature.

When the image buffer represents the application image generated by one of the applications or then the video chat application may receive a screen snapshot and or a screen capture video of the application image from the application display component through the camera service . The video chat application may communicate the screen snapshot and or the screen capture video of the application image received from the camera service to one or more remote devices as part of an implementation of the share an application feature.

The image buffer controller may control what type of image is represented in the image buffer . For example the video chat application may direct the image buffer controller directly indirectly through the camera service or indirectly through some other component to populate the image buffer with the composite image. Alternatively the video chat application may direct the image buffer controller directly indirectly through the camera service or indirectly through some other component to populate the image buffer with the application image.

The image consuming application or may select the image source or by sending a request that is received by the camera service . The request may be any type of request such as a SOAP Simple Object Access Protocol request or a local invocation of a programmatic procedure within a thread or a process.

In one example the image consuming application or may select the image source or with a factory class through which a programming object may be instantiated. The image source or may be identified in an invocation of a programmatic procedure of the factory class with an image source identifier that identifies the image source to select. In a second example the image consuming application or may select the image source or by invoking a programmatic procedure on a previously instantiated programming object and passing the image source identifier of the image source as a parameter.

The instantiated programming object may be specific to the image source or identified by the image source identifier. Programmatic procedures and or properties of the instantiated programming object may be common to all types of the images sources or and or be specific to a subset of the types of the image sources or . For example the target format in which to receive the graphics content may be specified in one or more programmatic procedures and or properties of the instantiated object. Table 1 below describes an example of selecting the image source or with the camera API receiving the graphics content from the image source or with the camera API and specifying a target format of the graphics content to be received with the camera API.

The code in Table 1 describes using a create procedure to instantiate a camera object. A parameter of the create procedure may select the image source or . The procedures of the instantiated camera object may be invoked by the image consuming application or to receive graphics content from the camera service and or to communicate with the camera service .

The code in Table 1 describes using a captureImage procedure of the instantiated object to receive a single image from the image source or . The camera object is the instantiated programming object. The captureImage is an example of a programmatic procedure on the camera API that causes a picture to be taken or captured when the programmatic procedure is invoked and the image source selected is a camera.

The code in Table 1 also describes using a captureVideo procedure of the instantiated object to receive a video stream. The captureVideo is an example of a programmatic procedure on the camera API that causes a video capture to begin when the programmatic procedure is invoked and the image source selected is a camera.

The code in Table 1 further describes specifying a desired duration of the video stream by passing the desired duration 5000 milliseconds in the example code listing of Table 1 as a parameter of the captureVideo procedure. A target format of the video stream may be specified in any number of ways such as in one or more image specification parameters. The image specification parameters may be passed as parameters to the captureVideo procedure or in some other programmatic procedure. The image specification parameters may include for example a memory location of the processed image a pixel format of the processed image a timestamp of the processed image an indication of the availability of the processed image and or any other type information about the processed image or the graphics content received from the camera service by the image consuming application or .

The camera API may be implemented in many different ways. For example the image consuming application and may select the image source to be one of multiple image buffers within the non sensor image source and or one of multiple sensor image buffers of the sensor image source . Each one of the image buffers in the non sensor image source may include a different image than any of the other image buffers in the non sensor image source . The image source identifier may identify which of the image buffers is to be the image source . The image source identifier may include a name a number and or any other type of identifier.

The camera service may select one of the image sources and that is different than the non sensor image source when the image source identifier does not identify a buffer populated by the non sensor image source . For example the camera service may select a default image source such as an integrated camera whenever the image source identifier does not identify a buffer populated by the non sensor image source .

The system may include additional fewer or different components than illustrated in . For example the system may include just include the camera service . In another example the system may include the components in the device as illustrated in but not any of the components external to the device such as the external display the network and the remote display device . In yet another example the system may include just the camera service and the remote display driver .

The system may include a non sensor image source device and or a sensor image source device. The non sensor image source device may be the non sensor image source when the non sensor image source comprises hardware or firmware. The sensor image source device may be the sensor image source when the sensor image source device comprises hardware or firmware.

Each of the components of the system may include additional fewer or different components than illustrated in . For example the non sensor image source may include just a hardware compositor that includes the image buffer but not the image buffer controller . In another example the camera service may include the image buffer controller instead of the non sensor image source including the image buffer controller . In still another example the sensor image source may not include the sensor but instead receive a signal from the sensor . The system may include any number of the image sources and .

The application buffers the image buffer and or the sensor image buffer may be double buffered. In some examples each of the application buffers the image buffer and or the sensor image buffer may be triple buffered or buffered using any number of buffers.

The system may be implemented in many different ways. For example one or more of the components in the device may be included in a system on a chip SOC . The non sensor image source may be included in the SOC. Alternatively or in addition the sensor image source may be included in the SOC. As another example the components illustrated in as being in the device may be distributed across multiple devices that are physically coupled together and or electrically coupled together.

The device may include any number of the components of the system . Components that are integrated components such as the integrated display may be included in the device . Components that are external components such as the external display may not be included in the device .

The composition manager may include hardware such as the processor and or be implemented entirely in hardware or firmware. Alternatively the composition manager may be implemented entirely in software.

Although some components may be described as stored in computer readable memories for example as logic implemented as computer executable instructions or as data structures in memory all or part of the system and its logic and data structures may be implemented in hardware or firmware. For example the camera service may be implemented in hardware or firmware. Alternatively or in addition all or part of the system and its logic and data structures may be stored on distributed across or read from multiple machine readable storage media. The machine readable storage media may include memories hard disks floppy disks CD ROMs or any other type computer readable storage medium.

Alternatively or in addition some components described as implemented in hardware or firmware may be implemented as computer executable instructions stored in memory. For example part of the image signal processor may be implemented as computer executable instructions stored in memory.

Some of the components such as the applications and the camera service and all or part of the composition manager may be stored in a memory. The memory may hold programs and processes that implement the logic described above and be executable by a processor such as the processor of the composition manager illustrated in .

The processor such as the processor illustrated in may be one or more devices or hardware components operable to execute computer executable instructions or computer code embodied in the memory to perform the features of one or more components of the system . The processor may be implemented as any type of processor such as a microprocessor a microcontroller a DSP a CPU a GPU a display controller an application specific integrated circuit ASIC discrete logic and or an analog or digital circuit. The computer code may include instructions executable with the processor. The computer code may be written in any computer language now known or later discovered such as C C Java Pascal Visual Basic Perl HyperText Markup Language HTML JavaScript assembly language shell script or any combination thereof. The computer code may include source code and or compiled code.

The memory may be a non volatile and or volatile memory such as a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM flash memory and or any other type of memory. The memory may include a cache a flash drive an optical drive a magnetic hard drive and or any other type of data storage device. The buffers such as the application buffers the image buffer and the sensor image buffer may be areas of the memory or memories.

The processor may be in communication with the memory. In one example the processor may also be in communication with additional components such as the integrated display .

At the start of the operations the camera service may be provided through which the image consuming application or selects the non sensor image source device as the image source from which to receive graphics content . For example the camera service may be stored in a memory and or the device may be provided that includes the camera service .

Next the processed image may be generated in the image buffer from the application buffer with the non sensor image source device . The request from the image consuming application or to select the non sensor image source device as the image source may be received by the camera service .

The operations may end in an operation in which the processed image which was generated by the non sensor image source device in the image buffer may be provided to the image consuming application or through the camera service based on the request to select the non sensor image source device as the image source . For example the instantiated programming object may provide the processed image to the image consuming application or because the programming object was instantiated with the image source identifier that identifies the non sensor image source device. Instead of the operations ending with the operation in which the processed image is provided to the image consuming application or the operations may loop back to the start of the operations or proceed to some other operation.

All of the discussion regardless of the particular implementation described is exemplary in nature rather than limiting. For example although selected aspects features or components of the implementations are depicted as being stored in memories all or part of systems and methods consistent with the disclosure may be stored on distributed across or read from other computer readable storage media for example secondary storage devices such as hard disks floppy disks and CD ROMs or other forms of ROM or RAM either currently known or later developed. The computer readable storage media may be non transitory computer readable media which includes CD ROMs volatile or non volatile memory such as ROM and RAM or any other suitable storage device. Moreover the various modules are but one example of such functionality and any other configurations encompassing similar functionality are possible.

Furthermore although specific components were described in the disclosure methods systems and articles of manufacture consistent with the disclosure may include additional or different components. For example memories may be DRAM SRAM flash or any other type of memory. Flags data databases tables entities and other data structures may be separately stored and managed may be incorporated into a single memory or database may be distributed or may be logically and physically organized in many different ways. The components may operate independently or be part of a same program. The components may be resident on separate hardware such as separate removable circuit boards or share common hardware such as a same memory and processor for implementing instructions from the memory. Programs may be parts of a single program separate programs or distributed across several memories and processors.

The respective logic software or instructions for implementing the processes methods and or techniques discussed above may be provided on computer readable media or memories or other tangible media such as a cache buffer RAM removable media hard drive other computer readable storage media or any other tangible media or any combination thereof. The tangible media may include various types of volatile and nonvolatile storage media. The functions acts or tasks illustrated in the figures or described herein may be executed in response to one or more sets of logic or instructions stored in or on computer readable media. The functions acts or tasks are independent of the particular type of instructions set storage media processor or processing strategy and may be performed by software hardware integrated circuits firmware micro code and the like operating alone or in combination. Likewise processing strategies may include multiprocessing multitasking parallel processing and the like. In one embodiment the instructions are stored on a removable media device for reading by local or remote systems. In other embodiments the logic or instructions are stored in a remote location for transfer through a computer network or over telephone lines. In yet other embodiments the logic or instructions are stored within a given computer central processing unit CPU graphics processing unit GPU or system.

To clarify the use of and to hereby provide notice to the public the phrases at least one of . . . and or at least one of . . . or combinations thereof or . . . and or are defined by the Applicant in the broadest sense superseding any other implied definitions herebefore or hereinafter unless expressly asserted by the Applicant to the contrary to mean one or more elements selected from the group comprising A B . . . and N that is to say any combination of one or more of the elements A B . . . or N including any one element alone or in combination with one or more of the other elements which may also include in combination additional elements not listed.

While various embodiments have been described it will be apparent to those of ordinary skill in the art that many more embodiments and implementations are possible within the scope of the disclosure. Accordingly the disclosure is not to be restricted except in light of the claims and their equivalents.

