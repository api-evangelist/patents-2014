---

title: Method and apparatus for filling images captured by array cameras
abstract: Image filling utilizing image data captured by an array of cameras having different camera viewpoints. Image data, such as a pixel value or gradient value associated with a spatial point in a source region of an image is transferred to the same or another image to fill a target region. Visual artifacts may be reduced by filling portions of the target region visible from other viewpoints with expanded source patches to reduce the size of the target region to be inpainted. In embodiments, a shifted mask corresponding to the target region is determined for each supplementary image based on an estimate of foreground disparity. In further embodiments, partially occluded regions are detected based on an estimate of background disparity. Source patches may be expanded based on a baseline between camera viewpoints into large coherent regions that agree well with the target region boundary may be filled without hallucinating image data from similar patches.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09514523&OS=09514523&RS=09514523
owner: Intel Corporation
number: 09514523
owner_city: Santa Clara
owner_country: US
publication_date: 20141118
---
A digital camera is a component often included in commercial electronic media device platforms. Digital cameras are now available in wearable form factors e.g. video capture earpieces video capture headsets video capture eyeglasses etc. as well as embedded within smartphones tablet computers and notebook computers etc.

Often a digital camera user wishes to fill in a region of an image for example to remove a foreground object from a scene after the image is captured. Image inpainting is a technique used to fill regions in digital images and may be used to remove unwanted objects. From a captured image a user can specify a target or destination region to be filled. The target region is automatically replaced with hallucinated image contents that look plausible and combine naturally with retained parts of the image scene. In one conventional approach to image filling illustrated in image patches sourced from background region of image captured by digital camera are combined to fill in target region and replace foreground object . Image patches are identified as similar exemplars and transferred to the boundaries of the target region. This process is repeated along the target contour until the target region is completely filled. However when only a single image viewpoint is employed inpainting of relatively large portions in a scene can result in an output image that suffers significant visual artifacts .

Advanced mobile devices with multiple cameras embedded in the same device are now becoming commercially available. For such a platform multiple images may be captured from different viewpoints of a scene at one instant in time. Some conventional stereo inpainting techniques have employed depth information derived from disparity between images collected from stereo cameras. These techniques however have thus far proven to be too computationally intensive for ultra light and low power mobile platforms.

Computationally inexpensive automated image filling techniques capable of reducing visual artifacts by leveraging a richer set of input information available through multiple image viewpoints are therefore highly advantageous.

One or more embodiments are described with reference to the enclosed figures. While specific configurations and arrangements are depicted and discussed in detail it should be understood that this is done for illustrative purposes only. Persons skilled in the relevant art will recognize that other configurations and arrangements are possible without departing from the spirit and scope of the description. It will be apparent to those skilled in the relevant art that techniques and or arrangements described herein may be employed in a variety of other systems and applications beyond what is described in detail herein.

Reference is made in the following detailed description to the accompanying drawings which form a part hereof and illustrate exemplary embodiments. Further it is to be understood that other embodiments may be utilized and structural and or logical changes may be made without departing from the scope of claimed subject matter. Therefore the following detailed description is not to be taken in a limiting sense and the scope of claimed subject matter is defined solely by the appended claims and their equivalents.

In the following description numerous details are set forth however it will be apparent to one skilled in the art that embodiments may be practiced without these specific details. Well known methods and devices are shown in block diagram form rather than in detail to avoid obscuring more significant aspects. References throughout this specification to an embodiment or one embodiment mean that a particular feature structure function or characteristic described in connection with the embodiment is included in at least one embodiment. Thus the appearances of the phrase in an embodiment or in one embodiment in various places throughout this specification are not necessarily referring to the same embodiment. Furthermore the particular features structures functions or characteristics described in the context of an embodiment may be combined in any suitable manner in one or more embodiments. For example a first embodiment may be combined with a second embodiment anywhere the particular features structures functions or characteristics associated with the two embodiments are not mutually exclusive.

As used in the description of the exemplary embodiments and in the appended claims the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will also be understood that the term and or as used herein refers to and encompasses any and all possible combinations of one or more of the associated listed items.

As used throughout the description and in the claims a list of items joined by the term at least one of or one or more of can mean any combination of the listed terms. For example the phrase at least one of A B or C can mean A B C A and B A and C B and C or A B and C.

The terms coupled and connected along with their derivatives may be used herein to describe functional or structural relationships between components. It should be understood that these terms are not intended as synonyms for each other. Rather in particular embodiments connected may be used to indicate that two or more elements are in direct physical optical or electrical contact with each other. Coupled may be used to indicated that two or more elements are in either direct or indirect with other intervening elements between them physical optical or electrical contact with each other and or that the two or more elements co operate or interact with each other e.g. as in a cause an effect relationship .

Some portions of the detailed descriptions provide herein are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. Unless specifically stated otherwise as apparent from the following discussion it is appreciated that throughout the description discussions utilizing terms such as calculating computing determining estimating storing collecting displaying receiving consolidating generating updating or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s circuitry including registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

While the following description sets forth embodiments that may be manifested in architectures such system on a chip SoC architectures for example implementation of the techniques and or arrangements described herein are not restricted to particular architectures and or computing systems and may be implemented by any architecture and or computing system for similar purposes. Various architectures employing for example multiple integrated circuit IC chips and or packages and or various computing devices and or consumer electronic CE devices such as set top boxes smartphones etc. may implement the techniques and or arrangements described herein. Further while the following description may set forth numerous specific details such as logic implementations types and interrelationships of system components logic partitioning integration choices etc. claimed subject matter may be practiced without such specific details. Furthermore some material such as for example control structures and full software instruction sequences may not be shown in detail in order not to obscure the material disclosed herein.

Certain portions of the material disclosed herein may be implemented in hardware for example as logic circuitry in an image processor. Certain other portions may be implemented in hardware firmware software or any combination thereof. At least some of the material disclosed herein may also be implemented as instructions stored on a machine readable medium which may be read and executed by one or more processors graphics processors and or central processors . A machine readable medium may include any medium and or mechanism for storing or transmitting information in a form readable by a machine e.g. a computing device . For example a machine readable medium may include read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices electrical optical acoustical or other similarly non transitory tangible media.

One or more system apparatus method and computer readable media is described below for image filling with image data captured by an array of cameras having different camera viewpoints. Image data such as a pixel value or gradient value associated with a spatial point or pixel position in a source region of an image is transferred to a corresponding point in another image to fill a target region. Visual artifacts may be reduced by filling portions of the target region visible from other viewpoints with expanded source patches thereby reducing the size of the target region to be inpainted and improving image coherence at the boundary of the target region.

A target region is received as another input to method . Target region defines a region in the reference image Ithat is to be filled in replaced with other image data. Target region may be predetermined upstream of method using any technique as embodiments are not limited in this respect. In one exemplary embodiment target region is predetermined based on a device user s input for example through a highlighting of a portion of the reference image Ioutput to a display on the user s device. Referring again to an exemplary target region overlays a foreground object within image . As such filling method is to remove object from image and transfer in place of object image contents that look plausible and combine naturally with retained portions of the image e.g. background region .

In embodiments the target region is transferred to the other camera positions viewpoints. To the extent target region is visible from other cameras camera viewpoints in the array the regions in each of the supplementary images corresponding to the target region are masked to ensure target region is excluded from an inpainting process sourcing image data from multiple images output by the array. In one exemplary embodiment where the objects in target region correspond to a single depth plane target region is assumed shifted by a constant amount in the other images as a function of their associated camera baseline. Referring again to method proceeds to operation where a shifted mask is computed for the kimage I. A shifted mask may be computed for each of the supplementary non reference images. is a schematic further illustrating determination of masks in supplementary images collected by an array camera in accordance with an embodiment. As shown shifted masks and are computed by applying T I which is a translation of image I by displacement d to target region . The translation displacement d applied to the target region for each image may be determined by a variety of techniques. In one exemplary embodiment the kth shifted mask is translated by distance equal to a disparity value for foreground objects d. The foreground disparity value dmay be estimated as the translation distance that minimizes a difference summed over the target region between data values in the reference image Iand data values of corresponding positions pixel locations within the kth image I. As one example dis estimated as 1 where p is the pixel location. Alternative difference sums e.g. SSD may be utilized as well. Notably although Eq. 1 performs the estimation in a pairwise manner a shift mask may be determined for all images concurrently e.g. using any known multi baseline stereo technique where baselines for all cameras in the array are known. The shifted mask for image Iis then be determined as . 2 

Method continues at operation where a source region from which candidate patches may be determined is generated by combining unmasked portions of all input images 3 where Irepresents the entire image region of the kth camera. At operation the target region is filled by replacing destination patches each associated with a point pixel position in the target region with similar source patches determined from an unmasked region in one of the plurality of images reference or supplemental . The target region may be iteratively filled with an inpainting technique that follows target region contour and successively fills destination patches along the contour with similar source patches identified from source region . In one advantageous embodiment a source patch is selected based on a comparison between neighborhood elements of candidate source patches and neighborhood elements of the destination patch. Following known techniques an exemplar in may be determined by minimizing the sum of per pixel distances with corresponding values copied into the target region. The iterative filling process may be repeated until the entire target region is filled and method ends with storing the modified reference image to an electronic memory. Ordering of the image filling iterations may be determined following known techniques to preserve coherence in image structures as target contour fill front advances.

In further embodiments operation further includes detection of partially occluded target regions and the image filling operation is made a function of detecting such partially occluded regions. As used herein a partially occluded region is a portion of target region for which additional image data is available because that region is visible from another camera viewpoint. further illustrates an example of partially occluded regions and for target region . As shown target region includes partially occluded region as a result of the viewpoint of camera and partially occluded region as a result of the viewpoint of camera . Only portions of target region are fully occluded from all camera viewpoints such that no image information about background region is known. Partially occluded regions may vary in size as a function of camera array baselines and depth of the object s within target region . Partially occluded regions may be efficiently filled using image data from the other cameras so that only the fully occluded regions e.g. portions need then be filled by exemplars from source region . One advantageous filling method that is dependent on a partial occlusion determination is summarized as pseudo code 

Notably the above image filling method is conditioned on a pixel location being within a partially occluded region. In response to determining a point in the target region is occluded from all of the viewpoints a destination patch is inpainted e.g. a similar source patch is selected based on a comparison between neighborhood elements of candidate source patches and neighborhood elements of the destination patch . However in response to determining a point in the target region is only partially occluded i.e. visible in a second image a source patch and advantageously a source patch expanded to a larger coherent region corresponding to the partially occluded region that is visible in a second image is transferred to fill in an associated target region .

From the estimated disparity value d partially occluded region O may be determined as 4 where the kth occluded region Omay be represented as 5 Following Eq. 5 an intersection of the complement of the target region translated by the foreground disparity value and the target region translated by the background disparity value is determined. Occluded region Ois then identified as a translation of this intersection by a distance equal in to but in a direction opposite of the background disparity value. Ois empty if the foreground disparity value dis equal to the background disparity value d meaning no occlusion region is detected.

Referring still to if a point associated with pixel position p is not included in occluded region O method proceeds to operation where source region is searched for source patch similar to destination patch following a known inpainting technique. At operation image data for selected similar patch is then transferred to destination patch and method iterates to a next pixel position p on target contour .

If instead pixel position p is included in partially occluded region O method proceeds to operation where an occlusion index K is assigned to each pixel in the partially occluded region O. Occlusion index K may serve as a basis for selecting a source patch from the image captured by a camera located the furthest away from the reference camera which gives the largest occluded regions. In one exemplary embodiment occlusion index K is determined as 

Method continues to operation where occlusion index K p for the destination patch is selected for example based on the votes from K p p . At operation occluded region Ois searched for a similar source patch in a rectangular e.g. r r window Wthat is centered at p d. In other words the disparity of the background dis utilized as an initial estimate and a small local search is applied over a sub region of the selected occluded region to allow for possible deviation resulting from variation in object depth. Notably the search at operation is fast because the size of sub region Wis generally much smaller than source region .

Method then completes an image filling iteration with a connected region in Obeing transferred to target region . In the exemplary embodiment this connected region is obtained by first expanding in the direction of the associated camera baseline at operation . Then at operation the expanded source patches in Oare copied into corresponding expanded destination patches. In the exemplary embodiment all expanded source patches represented as are copied to corresponding expanded destination patches where is a positive scaling factor and vis a vector representing the baseline between the kth camera and the reference camera. is an illustration of a portion of an image to be filled with an expanded patch from a partially occluded region in accordance with an embodiment of method . As depicted in target region includes partially occluded region and fully occluded region . Target region contour interfaces target region with background source region . Following embodiments herein with destination patch associated with point overlapping partially occluded region as depicted the search for the similar patch occurs around the sub region as described above. The vector v is then utilized to determine the direction and or magnitude of expanded patch .

In further embodiments the image filling methods describe above are employed in a multi scale technique. For such embodiments the image filling is better able to manage image structures in different scales and the filling quality may improve i.e. fewer visual artifacts . is a flow diagram of a multi scale method for generating a plurality of filled candidate images in accordance with an embodiment. In method the image filling method described above e.g. method further employing method is repeatedly applied from coarse to fine spatial scales.

Method begins with receiving the image data for a plurality of input images at operation substantially as described elsewhere herein. Downsampled images are then employed in the performance of the image filling methods above. Depending on the embodiment one two or three different scales may be utilized to generate different candidate results. illustrates three reduced scale levels with the first being downsampled from a non scaled implementation where image filling methods described above are performed at operation . In exemplary embodiments the scale factor between two nearest scales is set to 2. For a first scaled candidate result input images are downsampled at operation . These downsampled images are then used at operation to fill the target region by the methods described above. The filled result is then upsampled at operation to obtain a low resolution initial guess of the target region in the next finer scale. At operation a search is performed for similar patches that also agree with the initial guess. These patches are then employed to fill target region to generate the first scaled candidate result. For a second scaled candidate result input images downsampled at operation are further downsampled at operation . These downsampled images are then used at operation to fill the target region by the methods described above. The filled result is then upsampled at operation to obtain a low resolution initial guess of the target region in the next finer scale. At operation a search is performed for similar patches that also agree with the initial guess. These patches are then employed to fill target region at operation . This filled result is then upsampled at operation and operations and are performed to generate the second scaled candidate result. For a third scaled candidate result input images downsampled at operations and are further downsampled at operation . These downsampled images are then used at operation to fill the target region by the methods described above. The filled result is then upsampled at operation to obtain a low resolution initial guess of the target region in the next finer scale. At operation a search is performed for similar patches that also agree with the initial guess. These patches are then employed to fill target region at operation . This filled result is then upsampled at operation and operations and are performed. This filled result is further upsampled at operation and operations and are performed to generate the third scaled candidate result. At operation the various candidate results are then evaluated for example by presenting them to a user and allowing a user to select one of candidate images. The selected candidate is then stored to memory as the modified output image and method completes.

Noting that a composition of image patches may suffer from visible seams when image patches from different locations are combined in further embodiments the composition is performed in the gradient domain. When a low resolution initial guess is available gradient values may be also used to guide the estimation of the target region. In one advantageous embodiment the per pixel distance for a patch comparison is defined in the gradient domain as 

As further illustrated in ACIF device further includes a mask shift calculator calculation module coupled to receive the input images from CM CM CM etc. Mask shift calculator is further coupled to receive a target region selection . One or more mask shift calculator may be coupled in parallel to the CM . Mask shift calculator includes logic to determine a mask for a subset of the images e.g. from CM based on the target region and a foreground disparity estimated for each image in the subset. In further embodiments mask shift calculator further includes logic to estimate the foreground disparity for each image in the remainder by determining a translation distance that minimizes a difference summed over the target region between data values in the first image and data values of corresponding positions within one of the remaining images.

An output port of mask shift calculator is coupled to an input of partial occlusion region detector . Partial occlusion detector includes logic to determine if a portion of the target region is visible in a supplementary image. In further embodiments partial occlusion detector further includes logic to determine for the second image an intersection of a complement of the target region translated by the foreground disparity value and the target region translated by the background disparity value. In further embodiments partial occlusion detector further includes logic to determine spatial positions in the second image corresponding to a translation of the intersection that is equal and opposite to the background disparity value

An output of partial occlusion detector is coupled to an input of occlusion based image filling module . Filling module includes logic to modify the first image by filling a destination patch associated with a point in the target region with a source patch determined from an unmasked region in one of the images. In embodiments filling module further includes logic to select the source patch from a union of all unmasked regions of the plurality of images. In advantageous embodiments filling module further includes logic to select and expand in a direction of the second camera baseline a source patch from the portion of the target region that is visible in a second image. In further embodiments filling module further includes logic to search for the source patch in a sub region of the portion of the target region that is visible in the second image the sub region comprising a rectangular window centered at the point in the target region translated by a background disparity value estimated for the second image.

ACIF device further includes an output image generator coupled to at least one CM designated as capturing the reference image to be modified by an image filling method performed by ACIF device . Output image generator generates a modified output image based on image patch data generated or otherwise identified by filling module . An output port of output image generator is coupled to memory and output image generator is to store an output image to memory .

Platform includes CM and . In the exemplary embodiment CM further includes a camera sensor and CM includes a camera sensor . Sensor may be a HD FHD QXGA WQXGA QSXGA or UHD format digital image device for example. In one embodiment sensor has at least 8 megapixel resolution. Sensor may be a HD FHD QXGA WQXGA QSXGA or UHD format digital image device for example. In one embodiment sensor has a lower pixel resolution than sensor for example 1 5 mega pixel. Although not illustrated in in further embodiments platform further includes a third CM including a third camera sensor substantially the same as sensor and three images output by the three sensors are utilized by the platform for example to provide image data for image filling.

Camera sensors may provide a color resolution of 8 bits or more per pixel is operable to capture continuous video frames progressively. Sensor may have a pixel frequency of 170 MHz or more. Camera sensors may include an RGB Bayer color filter an analog amplifier an A D converter other components to convert incident light into a digital signal corresponding to raw image data. Sensors may be controlled to operate a rolling shutter or electronic focal plane shutter process where pixels are read out progressively in a line sequential fashion for a frame. In exemplary video embodiments sensors output multiple consecutively exposed frames. CM may output raw data associated with the consecutively exposed frames in conformance with any known streaming protocol such as a MIPI. Raw image video data is input to ISP . ISP is to receive and analyze frames of raw video data during the horizontal and or vertical blanking periods associated with CM . During raw image data processing ISP may perform one or more of color space conversion noise reduction pixel linearization and shading compensation for example.

Pre processed video data output by ISP may be buffered and queued as input image data ready for image filling based on two or more images. In exemplary embodiments applications processor APU implements one or more of the functional modules depicted in . APU may for example include one or more programmable logic circuits to perform one or more stages of the image filling methods described above. Subsystem drivers within a kernel space of an operating system OS instantiated by APU may control various image filling parameters such as scaling factors camera baseline parameters reference camera designation etc. Access to the image filling control parameters may be further provided through an application layer executing in a user space of the OS.

Both software and hardware implementations of the image filling device described above are well suited to implementing the image filling methods at minimal power. For software implementations any known programmable processor including a core of APU an execution unit of a graphics processor or other similar vector processor may be utilized to implement the logic of ACIF . In one exemplary embodiment the ACIF device is instantiated through the user space or kernel space of APU for examples upon a user initiating an image capture routine. APU executes the image filling algorithms and outputs a modified reference image to a downstream image processing pipeline. APU may be programmed with instructions stored on a computer readable media to cause the processor to perform any of the operations of image filling methods .

As further illustrated in output image data may be output to storage display transmission pipeline . In one exemplary storage pipeline embodiment modified filled output image data is written to electronic memory e.g. DDR etc. . Memory may be a part of a main memory accessible to APU . Alternatively or in addition storage display transmission pipeline is to transmit modified filled output image data off image video capture device .

System includes a device platform that may implement all or a subset of the various image filling methods described above in the context of . In various exemplary embodiments video processor executes image filling methods for example as described elsewhere herein. Video processor includes logic circuitry implementing ACIF to remove an object from and image for example as described elsewhere herein. In some embodiments one or more computer readable media may store instructions which when executed by CPU and or video processor cause the processor s to execute one or more thresholded pixel value matching algorithm such as any of those described in detail above. Two or more data frames exposed by CM and or CM may then be stored in memory as normalized matched rectified image data.

In embodiments device platform is coupled to a human interface device HID . Platform may collect raw image data with CM and which is processed and output to HID . A navigation controller including one or more navigation features may be used to interact with for example device platform and or HID . In embodiments HID may include any monitor or display coupled to platform via radio and or network . HID may include for example a computer display screen touch screen display video monitor television like device and or a television.

In embodiments device platform may include any combination of CM chipset processors memory storage applications and or radio . Chipset may provide intercommunication among processors memory video processor applications or radio .

One or more of processors may be implemented as one or more Complex Instruction Set Computer CISC or Reduced Instruction Set Computer RISC processors x86 instruction set compatible processors multi core or any other microprocessor or central processing unit CPU .

Memory may be implemented as a volatile memory device such as but not limited to a Random Access Memory RAM Dynamic Random Access Memory DRAM or Static RAM SRAM . Memory may also be implemented as a non volatile storage device such as but not limited to flash memory battery backed up SDRAM synchronous DRAM magnetic memory phase change memory and the like.

Radio may include one or more radios capable of transmitting and receiving signals using various suitable wireless communications techniques. Such techniques may involve communications across one or more wireless networks. Example wireless networks include but are not limited to wireless local area networks WLANs wireless personal area networks WPANs wireless metropolitan area network WMANs cellular networks and satellite networks. In communicating across such networks radio may operate in accordance with one or more applicable standards in any version.

In embodiments system may be implemented as a wireless system a wired system or a combination of both. When implemented as a wireless system system may include components and interfaces suitable for communicating over a wireless shared media such as one or more antennas transmitters receivers transceivers amplifiers filters control logic and so forth. An example of wireless shared media may include portions of a wireless spectrum such as the RF spectrum and so forth. When implemented as a wired system system may include components and interfaces suitable for communicating over wired communications media such as input output I O adapters physical connectors to connect the I O adapter with a corresponding wired communications medium a network interface card NIC disc controller video controller audio controller and the like. Examples of wired communications media may include a wire cable metal leads printed circuit board PCB backplane switch fabric semiconductor material twisted pair wire co axial cable fiber optics and so forth.

The thresholded pixel value matching and associated object processes comporting with exemplary embodiments described herein may be implemented in various hardware architectures cell designs or IP cores. 

As described above system may be embodied in varying physical styles or form factors. further illustrates embodiments of a mobile handset device in which platform and or system may be embodied. In embodiments for example device may be implemented as a mobile computing handset device having wireless capabilities. As shown in mobile handset device may include a housing with a front and back . Device includes a display an input output I O device and an integrated antenna . Device also may include navigation features . Display may include any suitable display unit for displaying information appropriate for a mobile computing device. I O device may include any suitable I O device for entering information into a mobile computing device. Examples for I O device may include an alphanumeric keyboard a numeric keypad a touch pad input keys buttons switches microphones speakers voice recognition device and software and so forth. Information also may be entered into device by way of microphone not shown or may be digitized by a voice recognition device. Embodiments are not limited in this context. Integrated into at least the back is cameras and e.g. each including a lens an aperture and an imaging sensor both of which may be components of one or more CM through which image data is exposed and output to an array camera image filling device for example as described elsewhere herein.

As exemplified above embodiments described herein may be implemented using hardware elements software elements or a combination of both. Examples of hardware elements or modules include processors microprocessors circuitry circuit elements e.g. transistors resistors capacitors inductors and so forth integrated circuits application specific integrated circuits ASIC programmable logic devices PLD digital signal processors DSP field programmable gate array FPGA logic gates registers semiconductor device chips microchips chip sets and so forth. Examples of software elements or modules include applications computer programs application programs system programs machine programs operating system software middleware firmware routines subroutines functions methods procedures software interfaces application programming interfaces API instruction sets computing code computer code code segments computer code segments data words values symbols or any combination thereof. Determining whether an embodiment is implemented using hardware elements and or software elements may vary in accordance with any number of factors considered for the choice of design such as but not limited to desired computational rate power levels heat tolerances processing cycle budget input data rates output data rates memory resources data bus speeds and other design or performance constraints.

One or more aspects of at least one embodiment may be implemented by representative instructions stored on a machine readable storage medium. Such instructions may reside completely or at least partially within a main memory and or within a processor during execution thereof by the machine the main memory and the processor portions storing the instructions then also constituting a machine readable storage media. Programmable logic circuitry may have registers state machines etc. configured by the processor implementing the computer readable media. Such logic circuitry as programmed may then be understood to be physically transformed into a system falling within the scope of the embodiments described herein. Instructions representing various logic within the processor which when read by a machine may also cause the machine to fabricate logic adhering to the architectures described herein and or to perform the techniques described herein. Such representations known as cell designs or IP cores may be stored on a tangible machine readable medium and supplied to various customers or manufacturing facilities to load into the fabrication machines that actually make the logic or processor.

While certain features set forth herein have been described with reference to embodiments this description is not intended to be construed in a limiting sense. Hence various modifications of the implementations described herein as well as other implementations which are apparent to persons skilled in the art to which the present disclosure pertains are deemed to be within the spirit and scope of the present disclosure.

In one or more first embodiment a computer implemented image processing method comprises receiving a plurality of images each image associated with a different camera viewpoint. The method further comprises receiving a target region defining a portion of a first of the images that is to be filled with image data. The method further comprises computing a shifted mask for a remainder of the images each shifted mask defining a region in one of the remaining images corresponding to the target region. The method further comprises modifying the first image by filling a destination patch associated with a point in the target region with a source patch determined from an unmasked region in one of the images. The method further comprises storing the modified first image to a memory.

In furtherance of the first embodiments each shifted mask is computed based on the target region and a foreground disparity estimated for the target region in each image of the remainder.

In furtherance of the embodiment immediately above the method further comprises estimating the foreground disparity in each image of the remainder by determining a translation distance that minimizes a difference summed over the target region between data values in the first image and data values of corresponding positions within one of the remaining images.

In furtherance of the first embodiment filling the destination patch with the source patch further comprises selecting the source patch from a union of all unmasked regions of the plurality of images.

In furtherance of the embodiment immediately above filling the destination patch with the source patch further comprises selecting a portion of the target region that is visible in a second image.

In furtherance of the embodiment immediately above the method further comprises determining the portion of the target region that is visible in a second image. The method further comprises searching for the source patch in a sub region of the portion of the target region that is visible the sub region comprising a rectangular window centered at the point in the target region translated by a background disparity value estimated for the second image.

In furtherance of the embodiment immediately above the method further comprises estimating the background disparity value by determining for the first image a minimum bounding box containing the target region determining an intersection of the bounding box and a complement of the target region and determining a translation distance that minimizes a difference summed over the intersection between data values in the first image and data values of corresponding positions within the second image.

In furtherance of the embodiment above the method further comprises determining the portion of the target region that is visible in a second image by determining an intersection of a complement of the target region translated by the foreground disparity value for the second image and the target region translated by the background disparity value for the second image and determining spatial positions in the second image corresponding to a translation of the intersection that is equal to and opposite of the background disparity value.

In furtherance of the embodiment above the method further comprises expanding the source patch in the direction of the baseline of the camera viewpoint associated with the second image.

In furtherance of the embodiment above the second image is selected from a plurality of images in which a portion of the target region is visible to maximize the baseline distance from the camera viewpoint associated with the first image.

In furtherance of the first embodiment the method further comprises determining the point in the target region is occluded from all of the viewpoints and wherein the source patch is selected based on a comparison between neighborhood elements of candidate source patches and neighborhood elements of the destination patch in response to determining the point in the target region is occluded from all of the viewpoints.

In furtherance of the first embodiment the image data comprises pixel values or gradient values and the method further comprises upsampling the modified result and modifying the upscaled first image by filling a destination patch associated with another point in the target region.

In one or more second embodiment a computerized array camera image filling apparatus comprises a means to perform the method recited in any one of the preceding claims.

In furtherance of the second embodiment the means further comprises an applications processor including a user space and a kernel space.

In one or more third embodiment a computerized image filling apparatus comprises an input port to receive a plurality of images each image associated with a different camera viewpoint. The apparatus further comprises a mask shift calculation module including logic to receive a target region defining a region to be filled within a first of the images and compute a shifted mask for a remainder of the images each shifted mask defining a region in one of the remaining images corresponding to the target region. The apparatus further comprises an image filling module to modify the first image by filling a destination patch associated with a point in the target region with a source patch determined from an unmasked region in one of the images. The apparatus further comprises a memory to store the modified first image.

In furtherance of the third embodiment the mask shift calculation module is to compute each shifted mask based on the target region and a foreground disparity estimated for each image in the remainder. The mask shift calculation module further includes logic to estimate the foreground disparity for each image in the remainder by determining a translation distance that minimizes a difference summed over the target region between data values in the first image and data values of corresponding positions within one of the remaining images. The image filling module further comprises logic to select the source patch from a union of all unmasked regions of the plurality of images.

In furtherance of the third embodiment the apparatus further comprises a partial occlusion detector including logic to determine that a portion of the target region is visible in a second image and the image filling module further comprises logic to select the source patch from the portion of the target region that is visible in a second image.

In furtherance of the embodiment immediately above the partial occlusion detector further comprises logic to determine for the second image an intersection of a complement of the target region translated by the foreground disparity value and the target region translated by the background disparity value. The partial occlusion detector further comprises logic to determine spatial positions in the second image corresponding to a translation of the intersection that is equal to and opposite of the background disparity value.

In furtherance of the embodiment above the image filling module further comprises logic to search for the source patch in a sub region of the portion of the target region that is visible in the second image the sub region comprising a rectangular window centered at the point in the target region translated by a background disparity value estimated for the second image and expand the source patch in the direction of the baseline of the camera viewpoint associated with the second image.

In furtherance of the embodiment above the apparatus further comprises a plurality of image sensors to output the plurality of images.

In one or more fourth embodiment one or more computer readable storage media with instructions stored thereon which when executed by a processor cause the processor to perform any one of the first embodiments.

In one or more fifth embodiment one or more computer readable storage media with instructions stored thereon which when executed by a processor cause the processor to perform a method comprising receiving a plurality of images each image associated with a different camera viewpoint receiving a target region defining a target region within a first of the images computing a shifted mask for a remainder of the images each shifted mask defining a region in one of the remaining images corresponding to the target region modifying the first image by filling a destination patch associated with a point in the target region with a source patch determined from an unmasked region in one of the images and storing the modified first image to a memory.

In furtherance of the fifth embodiment the media further stores instructions thereon which when executed by a processor cause the processor to further perform a method comprising estimating the foreground disparity for each image in the remainder by determining a translation distance that minimizes a difference summed over the target region between data values in the first image and data values of corresponding positions within one of the remaining images.

In furtherance of the fifth embodiment the media further stores instructions thereon which when executed by a processor cause the processor to further perform a method further comprising selecting the source patch from a portion of the target region that is visible in a second image.

In furtherance of the embodiment immediately above the media further stores instructions thereon which when executed by a processor cause the processor to further perform a method further comprising determining the portion of the target region that is visible in a second image and searching for the source patch in a sub region of the portion of the target region that is visible the sub region comprising a rectangular window centered at the point in the target region translated by a background disparity value estimated for the second image.

In furtherance of the embodiment immediately above the media further stores instructions thereon which when executed by a processor cause the processor to further perform a method comprising determining the portion of the target region that is visible in a second image by determining for the second image an intersection of a complement of the target region translated by the foreground disparity value and the target region translated by the background disparity value and determining spatial positions in the second image corresponding to a translation of the intersection that is equal to and opposite of the background disparity value.

It will be recognized that the embodiments are not limited to the exemplary embodiments so described but can be practiced with modification and alteration without departing from the scope of the appended claims. For example the above embodiments may include specific combination of features. However the above embodiments are not limited in this regard and in embodiments the above embodiments may include undertaking only a subset of such features undertaking a different order of such features undertaking a different combination of such features and or undertaking additional features than those features explicitly listed. Scope should therefore be determined with reference to the appended claims along with the full scope of equivalents to which such claims are entitled.

