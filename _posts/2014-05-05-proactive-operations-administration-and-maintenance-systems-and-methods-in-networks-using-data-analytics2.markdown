---

title: Proactive operations, administration, and maintenance systems and methods in networks using data analytics
abstract: A computer-implemented method, a system, and a network include receiving network data from a network and non-network sourced data from one or more external sources relative to the network; performing data mining on the network data and the non-network sourced data; developing a predictive analytics model based on the data mining; and performing predictive analytics on the network data and the non-network sourced data using the predictive analytics model to detect likely future failures in the network. The network can include a Software Defined Network (SDN) operating at any of Layers 0, 1, 2 and/or 3.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09628340&OS=09628340&RS=09628340
owner: Ciena Corporation
number: 09628340
owner_city: Hanover
owner_country: US
publication_date: 20140505
---
The present disclosure relates generally to networking systems and methods. More particularly the present disclosure relates to proactive operations administration and maintenance OAM systems and methods using data analytics such as with software defined networking SDN .

Network resiliency is of critical importance to network operators service providers and associated end users. Everyone expects always on network connectivity and any down time can result in lost revenue opportunities etc. As such various OAM instrumentation techniques are available at each network level layer 0 or the photonic layer layer 1 or the time division multiplexing layer layer 2 Ethernet MPLS etc. layer 3 IP etc. Operators intently monitor OAM at all of the network levels. The existing approach to the monitoring of network health is explicit and deterministic. This is not a bad thing. However today s OAM methods typically provide knowledge about network conditions in real time. For example a network failure is identified at the time of the failure or a short time after so as to initiate a protection switch and OAM information provides guidance as to where the failure has occurred for reactive maintenance purposes. Pre forward error correction FEC bit error rate BER does provide some advanced warning of the degradation of an optical signal but the change in BER value is typically very steep and so does not provide much advanced warning. Note that the correlation of explicit OAM information from different network sources exists today with a primary objective to help suppress the many alarms that can be created after a failure for example. Such alarm correlation techniques are still reacting to an event after it has occurred and are not being used to predict possible future issues.

Modern high powered computing platforms are allowing the application of data mining techniques aka data analytics or big data to services by helping them learn more about their subscribers usage patterns. By processing a vast array of somewhat unrelated data associated with particulars such as usage patterns applications locations client devices etc. service providers aim to improve service value by focusing precisely on individual customer needs. In today s networks the general area of data mining is primarily focused on the identification of patterns and trends associated with mobile network services and IP network Layers 3 7 where knowledge about IP and associated service characteristics may be most easily extracted. It is also recognized that an interesting application of data mining is its potential to predict future events to some degree of statistical certainty based on past trends or by correlating data sets that were previously regarded as unrelated. For example rather than monitoring a well defined set of data for an explicit or deterministic actionable threshold the data analytics approach monitors potentially unstructured data patterns associated with historical trends and identifies probable consequences to those patterns. A network service provider may then choose to act in advance and in anticipation of such consequences to improve service value or network performance. Another example is that of police and security organizations who use similar techniques to predict the likelihood of a crime being committed.

It would advantageous to utilize data analytics in a network OAM capacity to predict network related failures in advance.

In an exemplary embodiment a computer implemented method includes receiving network data from a network and non network sourced data from one or more external sources relative to the network performing data mining on the network data and the non network sourced data developing a predictive analytics model based on the data mining and performing predictive analytics on the network data and the non network sourced data using the predictive analytics model to detect likely future failures in the network. The network can include a Software Defined Network SDN control environment operating at any of Layers 0 1 2 or 3. The computer implemented method can further include receiving the network data from the network via an SDN controller in the network via an Application Programming Interface API on the SDN controller. The computer implemented method can further include receiving a notification from the predictive analytics that a network resource such as a component sub system system device facility etc. in the network is likely to fail and performing a proactive maintenance activity on the resource. The computer implemented method can further include continually updating the data mining and the predictive analytics model based on ongoing occurrences of failures and data associated therewith. The network data and the non network data can each be classified as either analog or digital and either internal to the network or external to the network. The network data can include network Operations Administration and Maintenance OAM data collected by the network and the non network data can include data collected from external sources relative to the network.

In another exemplary embodiment a system includes a network interface a data store and a processor each communicatively coupled therebetween and memory storing instructions that when executed cause the processor to receive via the network interface network data from a network and non network sourced data from one or more external sources relative to the network perform data mining on the network data and the non network sourced data develop a predictive analytics model based on the data mining and perform predictive analytics on the network data and the non network sourced data using the predictive analytics model to detect likely future failures in the network. The network can include a Software Defined Network SDN control environment operating at any of Layers 0 1 2 or 3. The network data can be received from the network via an SDN controller in the network via an Application Programming Interface API on the SDN controller. Responsive to a failure prediction by the predictive analytics a notification can be provided when a network resource such as a component sub system system device facility etc. in the network is likely to fail to alert an operator for proactive maintenance activity on the network resource. The memory storing instructions that when executed can further cause the processor to continually update the data mining and the predictive analytics model based on ongoing occurrences of failures and data associated therewith. The network data and the non network data can each be classified as either analog or digital and either internal to the network or external to the network. The network data can include network Operations Administration and Maintenance OAM data collected by the network and the non network data can include data collected from external sources relative to the network.

In yet another exemplary embodiment a network includes a plurality of network elements communicatively coupled therebetween and operating at any of Layers 0 3 a controller communicatively coupled to one or more of the plurality of network elements wherein the controller includes a processor and memory storing instructions that when executed cause the processor to receive via the network interface network data from a network and non network sourced data from one or more external sources relative to the network perform data mining on the network data and the non network sourced data develop a predictive analytics model based on the data mining and perform predictive analytics on the network data and the non network sourced data using the predictive analytics model to detect likely future failures in the network. The controller can include a Software Defined Network SDN controller and wherein the network data can be received from the network via the SDN controller in the network via an Application Programming Interface API on the SDN controller. Responsive to a failure prediction by the predictive analytics a notification can be provided when a network resource such as a component sub system system device facility etc. in the network is likely to fail to alert an operator for proactive maintenance activity on the network resource. The memory storing instructions that when executed can further cause the processor to continually update the data mining and the predictive analytics model based on ongoing occurrences of failures and data associated therewith. The network data and the non network data can each be classified as either analog or digital and either internal to the network or external to the network. The network data can include network Operations Administration and Maintenance OAM data collected by the network and the non network data can include data collected from external sources relative to the network.

Again the use of big data or data analytics is recognized as a new and interesting approach to solution solving. In the context of proactive OAM systems and methods instead of monitoring real time data sets for a definitive threshold crossing data analytics can review historical data trends and consequences to identify possible future outcomes e.g. a network event with a high degree of statistical probability. The application of data analytics to a network provides a wealth of new and proactive business opportunities in the area of network operations network optimization and service monetization. For network operations in various exemplary embodiments proactive OAM systems and methods use big data or data analytics techniques to observe changes to patterns in data collected from a network and other sources such as via traditional Network Management Systems NMS or modern Software Defined Network SDN control systems. When a historical association between certain patterns and network events such as equipment failures is identified it leads to an increase in confidence that when the same patterns show up in the future they are likely to correlate with future network events such as equipment failures . The proactive OAM systems and methods i use a combination of OAM data and other non OAM data that is collected for purposes not directly related to traditional OAM monitoring ii process collected data in a manner that is not typical for traditional OAM instrumentation and iii provide a result that is predictive of rather than responsive to network behavior. The ability to predict network failures in advance provides a network operator with time to repair network equipment before it impacts a service. This improves network availability increases customer loyalty and speeds up network repair and maintenance.

Referring to in an exemplary embodiment a network diagram illustrates an exemplary network for describing the proactive OAM systems and methods. Those of ordinary skill in the art will recognize that any network configuration at Layers 0 1 2 and or 3 is contemplated with the proactive OAM systems and methods. The network is a SDN network which includes an SDN controller with the ability to logically centrally program provisioning of forwarding in the network in order for more flexible and precise control over network resources to support new services. Application Programmable Interfaces APIs provide programmatic communication between an SDN controller and either i specific applications or ii programmable network devices. OpenFlow www.openflow.org is an example implementation of a special OpenFlow interface from the SDN controller to programmable network devices. It may or may not communicate via mediation software to each switch in the network in order to provision the forwarding table at each switch along a connection path in order to instantiate the forwarding behavior needed for the connection. OpenFlow is described for example in the OpenFlow Switch Speciation Version 1.1.0 February 2011 Version 1.3.0 June 2012 the contents of which are incorporated by reference herein. While OpenFlow describes one version of a SDN interface other SDN protocols besides OpenFlow such as Netflow REST etc are also contemplated with the systems and methods described herein.

Again for illustration purposes the network includes an OpenFlow controlled packet switch various packet optical switches and packet switches with the switches each communicatively coupled to the SDN controller via the OpenFlow interface and the mediation software at any of Layers 0 3 L0 being DWDM L1 being OTN and L2 being Ethernet . The switches again for illustration purposes only are located at various sites including an Ethernet Wide Area Network WAN a carrier cloud Central Office CO and data center an enterprise data center a Reconfigurable Optical Add Drop Multiplexer ROADM ring a switched OTN site another enterprise data center a central office and another carrier cloud Central Office CO and data center . The network can also include IP routers and a network management system NMS . Note there can be more than one of the NMS e.g. an NMS for each type of equipment each communicatively coupled to the SDN controller . Again the network is shown just to provide context and typical configurations at Layers 0 3 in an SDN network for illustration purposes. Those of ordinary skill in the art will recognize various other network configurations are possible at Layers 0 3 in the SDN network.

The switches can operate via SDN at Layers 0 3. The OpenFlow packet switch for example can be a large scale Layer Ethernet switch that operates via the SDN controller at Layer 2 L2 . The packet optical switches can operate at any of Layers 0 3 in combination. At Layer 0 the packet optical switches can provide wavelength connectivity such as via DWDM ROADMs etc. at Layer 1 the packet optical switches can provide time division multiplexing TDM layer connectivity such as via Optical Transport Network OTN Synchronous Optical Network SONET Synchronous Digital Hierarchy SDH etc. at Layer 2 the packet optical switches can provide Ethernet or Multi Protocol Label Switching MPLS packet switching and at Layer 3 the packet optical switches can provide IP packet forwarding. The packet switches can be traditional Ethernet switches that are not controlled by the SDN controller . The network can include various end user access technologies such as without limitation cable modems digital subscriber loop DSL wireless fiber to the X e.g. home premises curb etc. and the like.

The network has various networking components that have associated OAM such as for example DWDM OTN SONET SDH Ethernet Multiprotocol Label Switching MPLS IP etc. Today s traditional method of instrumenting network performance involves network elements e.g. the switches collecting lots of raw data associated with simple OAM packets and bytes. The raw data is uploaded at a coarse time interval typically 15 minute bins into a Network Management System NMS where it is organized according to a structured database and monitored for threshold crossing alarms. This approach is based on a narrow scope of cause and effect for each OAM mechanism. At Layer 0 with the introduction of coherent DWDM technology the network can have a suite of photonic data measured by the Digital Signal Processor DSP technology including but is not limited to information relating to the real time monitoring of pre FEC Bit Error Ratio BER optical loss optical propagation delay and variations in power levels optical amplifier gain optical noise optical signal to noise ratio polarization and chromatic dispersion. At Layer 1 the network can have access to a well defined suite of OAM bytes defined by the ITU T OTN standard G.709 that include details of connection performance continuity connectivity and latency for end to end paths as well as individual links. At Layers 2 and 3 the network can have access to packet OAM statistics defined by standards organizations like MEF IEEE ITU T and IETF for Ethernet MPLS and IP packet flows and tunnels. Currently this OAM data is collected and monitored on a per layer basis it is directly associated with the layer service in question and it is monitored in pseudo real time.

In the context of the proactive OAM systems and methods described herein the SDN controller and associated applications thereon are continually monitoring OAM and performance monitoring data over time in the network . The proactive OAM systems and methods take advantage of the SDN paradigm to access relevant network data through open Application Programming Interfaces APIs such as associated with the SDN controller . Data sourced from different networking locations is collected in a database that is independent of other existing functional databases to maintain independence and security. Data collected from the local network is combined with data pushed to the Internet from external global sources. A data analytics computation of the proactive OAM systems and methods operates on its dedicated data set independently of other network databases.

Referring to in an exemplary embodiment a block diagram illustrates functional components of the SDN controller environment . The SDN controller functions and can be implemented on a server or the like such as illustrated in and the functional components can be implemented in software executed on the server. The SDN controller environment includes a programmable infrastructure layer a control layer and an application layer . The programmable infrastructure layer comprises network devices such as the switches and is communicatively coupled to the control layer via a control plane interface such as OpenFlow for example. The control layer facilitates communication between the application layer and the network devices located in programmable infrastructure layer . The control layer includes SDN control software with a plurality of network services . The control layer provides SDN functionality to manage network services through abstraction of lower level functionality. The application layer communicates to the control layer through various Application Programming Interfaces APIs . The application layer provides end user connectivity to the SDN such as software modules and or functions responsible for creating desired path and flow connections on the physical network through various business applications . In an exemplary embodiment the proactive OAM systems and methods are implemented as one of the business applications on the SDN controller and or on a separate server .

Referring to in an exemplary embodiment a block diagram illustrates a server which may be used to realize the SDN controller in other systems or standalone. The server may be a digital computer that in terms of hardware architecture generally includes a processor input output I O interfaces a network interface a data store and memory . It should be appreciated by those of ordinary skill in the art that depicts the server in an oversimplified manner and a practical embodiment may include additional components and suitably configured processing logic to support known or conventional operating features that are not described in detail herein. The components and are communicatively coupled via a local interface . The local interface may be for example but not limited to one or more buses or other wired or wireless connections as is known in the art. The local interface may have additional elements which are omitted for simplicity such as controllers buffers caches drivers repeaters and receivers among many others to enable communications. Further the local interface may include address control and or data connections to enable appropriate communications among the aforementioned components.

The processor is a hardware device for executing software instructions. The processor may be any custom made or commercially available processor a central processing unit CPU an auxiliary processor among several processors associated with the server a semiconductor based microprocessor in the form of a microchip or chip set or generally any device for executing software instructions. When the server is in operation the processor is configured to execute software stored within the memory to communicate data to and from the memory and to generally control operations of the server pursuant to the software instructions. The I O interfaces may be used to receive user input from and or for providing system output to one or more devices or components. User input may be provided via for example a keyboard touch pad and or a mouse. System output may be provided via a display device and a printer not shown . I O interfaces may include for example a serial port a parallel port a small computer system interface SCSI a serial ATA SATA a fibre channel Infiniband iSCSI a PCI Express interface PCI x an infrared IR interface a radio frequency RF interface and or a universal serial bus USB interface.

The network interface may be used to enable the server to communicate on a network such as the Internet a wide area network WAN a local area network LAN and the like etc. The network interface may include for example an Ethernet card or adapter e.g. 10BaseT Fast Ethernet Gigabit Ethernet 10 GbE or a wireless local area network WLAN card or adapter e.g. 802.11a b g n . The network interface may include address control and or data connections to enable appropriate communications on the network. A data store may be used to store data. The data store may include any of volatile memory elements e.g. random access memory RAM such as DRAM SRAM SDRAM and the like nonvolatile memory elements e.g. ROM hard drive tape CDROM and the like and combinations thereof. Moreover the data store may incorporate electronic magnetic optical and or other types of storage media. In one example the data store may be located internal to the server such as for example an internal hard drive connected to the local interface in the server . Additionally in another embodiment the data store may be located external to the server such as for example an external hard drive connected to the I O interfaces e.g. SCSI or USB connection . In a further embodiment the data store may be connected to the server through a network such as for example a network attached file server.

The memory may include any of volatile memory elements e.g. random access memory RAM such as DRAM SRAM SDRAM etc. nonvolatile memory elements e.g. ROM hard drive tape CDROM etc. and combinations thereof. Moreover the memory may incorporate electronic magnetic optical and or other types of storage media. Note that the memory may have a distributed architecture where various components are situated remotely from one another but can be accessed by the processor . The software in memory may include one or more software programs each of which includes an ordered listing of executable instructions for implementing logical functions. The software in the memory includes a suitable operating system O S and one or more programs . The operating system essentially controls the execution of other computer programs such as the one or more programs and provides scheduling input output control file and data management memory management and communication control and related services. The one or more programs may be configured to implement the various processes algorithms methods techniques etc. described herein.

Referring to in an exemplary embodiment a logical flow diagram illustrates a data analytics system for predicting a statistical likelihood of a network event from network data and non network sourced data . Collectively the network data and the non network sourced data can be referred to as OAM data. The data analytics system can be implemented for example through the server and the data store which can be internal or external to the server . Alternatively the data analytics system can be implemented in the SDN controller environment and other embodiments are also contemplated. The data store is configured to interface to the network data such as via APIs through the SDN controller environment i.e. various network data can be exposed across open APIs. Examples of the network data can include without limitation customer data equipment data topology data maintenance data EMS NMS OAM data and NE OAM data. The data store is also configured to interface to the non network sourced data such as over the Internet. For example the non network sourced data can be pushed to the data store via subscriptions over the Internet. Examples of the non network sourced data include without limitation holiday calendars weather updates road maintenance notices sports calendars news fees energy pricing etc. The server includes a pattern recognition algorithm that analyzes all of the data from the data store i.e. the network data and the non network sourced data to predict statistical likelihoods of network events.

The idea that by observing the network one can predict the occurrence of a failure in advance is attractive. If a network operator can get sufficient advance notice the operations team can act to repair or move service traffic around the anticipated failure location in a managed manner minimizing impact to customer services. By combining the above OAM expertise at Layer through with data analytical techniques the data analytics system has an opportunity to advance network operations with predictive fault analysis. As the network data is collected over time it is possible to identify patterns in the network data along with the non network sourced data that exist consistently prior to actual network failures. With the supply of additional information such as previously known bad sites or known fiber type or quality or fiber splice age it may become possible to predict the timing of a network failure with high enough probability that a network operator can plan around the failure before it happens. This allows the operations team to troubleshoot recurring events or correct instable network fluctuations before they become a revenue impacting action. Further such knowledge aids in the development of a cost efficient sparing strategy as spare equipment would then be located at distribution sites closest to locations identified to trend the highest probability failure rates.

In the context of predictive analytics it is possible to consider the addition of the non network sourced data to aid in proactive resiliency. For example in addition to the observation of the network data by monitoring weather conditions such as for hurricane data it becomes possible to anticipate a need for network backup in advance and away from the predicted weather disturbance. By providing sufficient advanced warning network capacity may be redirected temporarily to the area in need so as to accommodate overload conditions. Similarly emergency information provided by monitoring real time news broadcasts provides an opportunity for the network operator to re prioritize network traffic in anticipation of network stress.

In the data analytics system data from many different network sources such as OAM from different network layers knowledge about nodal failure history knowledge about operations teams maintenance events i.e. any knowledge about and relating to the network is fed to the pattern recognition algorithm . The raw data is archived and when an event such as a link failure or an interface failure occurs the raw data from all sources is analyzed for prior tell tale patterns. After the occurrence of a number of events the pattern recognition algorithm in the analytics engine recognizes a consistent pattern of data changes prior to the event. The correlation between this pattern and the likelihood of an event occurring grows as more data is collected. Ultimately the identification of a unique data pattern leads to a statistical probability that an event will occur in the future as a consequence of the existence of the data pattern .

The data collected in the data store may be categorized and prioritized to aid the pattern recognition process. In an exemplary embodiment the data collected in the data store can be categorized in six categories and stamped with information associated with time of occurrence and geographic location. The six categories include i Digital and ii Analog data is collected from iii Internal and iv External sources associated with v Network and vi non Network environments. The network data is collected from OAM data sourced across different network layers and the non network sourced data is collected from external subscription sources etc. Digital data includes data which is true false i.e. 1 or 0 whereas analog data is a numerical value. The scope of internal external may refer to a network operator external or a vendor internal i.e. internal is within the network owned by an operator whereas external is outside the network not owned by the operator . Today the world is becoming increasingly instrumented. Consequently input data can come from a wide range of sources. A non exhaustive list of some examples of data that can be monitored and can impact the behavior of a network are shown in the following table 

The data collected in the data store may be pre sorted or prioritized to aid the pattern recognition process based on network operator s priorities perceived importance or the data s temporal characteristics. For example there may be many data inputs associated with laser current levels or optical amplifier pump power levels and a few data inputs associated with a network operator s choice of vendor device. In such a case a pattern recognition algorithm may support different prioritization levels for example high priority for the small number of data inputs and lower priority for the large number of data inputs . Such an approach may make the implementation of the algorithm easier when faced with very large volumes of data. Also different data types may be classified as dynamic and static. Some data is constantly changing or changes over short timescales whereas some data is fixed or only changes over long timescales . For example the measurement of polarization mode dispersion PMD in an optical fiber can fluctuate widely based on the amount of stress placed on the fiber whereas a train timetable is fixed.

Different network operators will have access to different types of data and may choose to limit the data set that is analyzed by the pattern recognition algorithm . The data collected in the data store may be pre sorted into sub groups for analysis based on a network operator s preference. For example an initial implementation of this invention may be to use internal OAM data only. The pattern recognition algorithm may act usefully on a sub set of data that comprises only internal conventional OAM data from different internal network layers. An evolution to this approach may be to add the location of device equipment and its association with equipment vendor. A further evolution to this data set may be to add temperature and humidity information associated with each network office.

Again the network generates data at different network layers to support the instrumentation of different network technologies. Today this data is monitored to gain explicit knowledge about its local significance to a single system or sub system i.e. the data has local meaning Instrumentation systems operate at a given network layer but they are typically not combined with each other to determine broader global network significance. Non OAM data about the network also has relevance. Different equipment vendors using different component choices with different temperature responses may be used in different geographic locations. For example a problem may only show up when one vendor s product is exposed to excessive humidity or altitude. The non network sourced data provides information about possible global environmental impacts to the network . Many of the data sources are made available for public consumption. For example news items or weather updates are pushed to our smartphone apps calendars remind us of important events such as a significant sports game or a national holiday and local authorities advertise when roads are going to be closed for maintenance. Competing energy companies advertise their energy rates for different applications in different geographies and train timetables advertise when trains are expected to pass through certain geographies. The data analytics system taps into these apparently unassociated data streams for recognizing patterns that affect the network . As evolution towards the Internet of Things IoT occurs the range and scale of possible data sources will increase. Billions of communication sessions e.g. to from refrigerators thermostats and light bulbs will in themselves provide a sensor network that will generate a significantly larger data set for analysis.

The network data includes OAM data and the like collected by the network . For example the network data can be from Layers 0 3. At Layer 0 DWDM the network data can include information about fiber cut fiber characteristics age spice dates equipment choice vendor components optical power threshold WDM frequency optical signal to noise ratio SNR optical power values pre FEC BER chromatic dispersion polarization mode dispersion PMD polarization dependent loss PDL etc. At Layer 1 OTN the network data can include restoration or protection event customer service level agreement SLA history Network maintenance action Loss of Signal Loss of Frame Section Path alarms Network maintenance schedule etc. At Layers 2 and 3 packet the network data can include Link utilization Packet Delay Packet Delay Variation Packet Loss Packet Continuity Buffer utilization Timing synchronization etc. Of course some of the network data is directly correlated to service outages e.g. no optical power extremely high pre FEC BER Loss of Signal Frame etc. The goal of the data analytics system is to take massive amounts of data and look for correlations that frequently occur in advance of service outages e.g. correlations that are not necessarily obvious.

In the data analytics system the data is collected and machine pattern recognition techniques are performed based on supervised or unsupervised learning techniques to determine the probability of future events. For example a training set of data may be generated through prior monitoring of data sets and actual network events. In the public domain many pattern recognition algorithms exist that are used to identify patterns of information from large seemingly noisy data sets. The pattern recognition algorithm contemplates any choice of algorithm. Temporal spatial event correlation analysis is then performed on the statistically classified output from the pattern recognition algorithm using the time and location information associated with each data source to predict the statistical probability of time and location of future events.

While the source data is contextual it is not obvious that the pattern recognition algorithm may need to understand the context of the source data. What is important is the relative change in each value and the identification of a pattern of changes across multiple data sources that result in a consequential network event. Each data source will have a baseline value that represents steady state and healthy operation . Deviation from this value beyond an identified threshold in terms of rate of change and absolute new value local to the context of the data both represent input to the prediction process. The ability to index data and remove it from its contextual environment provides an opportunity to simplify the computation process.

Again today s network architecture may be classified as closed and proprietary. The flow of information is constrained for use within rigid functional boundaries. For example OAM information flow between network elements is typically constrained to a single network technology and while reactive results are shared with an operations support system OSS they are typically not shared outside the scope of the OAM process. While interfaces between hardware and or software systems may be standardized information flow and access to information databases is limited. Note that partitioning and restrictions are often encouraged for security reasons. A consequence of this rigid structure is that it is difficult to gain access to the different data sources described above for application reasons e.g. the pattern recognition algorithm .

Within the network the new software defined networking SDN control paradigm provides a better opportunity for practical implementation of the data analytics system . SDN promotes the use of open Application Programming Interfaces APIs between different network systems to enable increased network flexibility through network element programmability. In the data analytics system it is proposed that flexible API s be programmed to expose the data types described above and streamline the flow of data through the SDN controller environment to the data analytics data store . Sources of external data are increasingly pushing data out to the Internet for subscribers to access. It is proposed that the data analytics data store subscribes to these information flows as well.

In the network and the data analytics system some of the OAM data can be separated out and used for simple minimal computation to predict future failures. This OAM data is directly correlated with failures and examples can include without limitation laser pump current FEC BER etc. That is e.g. a trend where the FEC increases the laser pump current decreases increases etc. can directly predict a future failure. Other OAM data may not have such a direct correlation effect that is easily noticeable but may have correlation when combined with other OAM data. This is an exemplary objective of the data analytics system take as much OAM data is possible perform predictive analytics and determine to some statistical likelihood a future failure. For example the data analytics system can identify OAM data that can be watched and learned as network normal and flag when abnormal happens but not necessarily knowing if that would cause any issues. For example a rare predicted weather problem might be such an event a prolonged dry spell combined with record heat etc. The data analytics system can also identify OAM data that can be watched and that has caused network problems often enough for data analytics system to have learned some specifics about them such that the data analytics system can identify such occurrences in advance.

Referring to in an exemplary embodiment a flowchart illustrates a pattern recognition method that can be implemented through the data analytics system . The pattern recognition method can be implemented as the pattern recognition algorithm . The pattern recognition method includes receiving network data and non network sourced data step . Here the data analytics system can continually receive the network data from the SDN controller environment and the non network sourced data from various sources as described herein. The network data can be received at periodic intervals e.g. every minute 15 minutes etc. as is common with OAM data. The non network sourced data can also be received at periodic intervals or continually. Specifically the data analytics system is set up to continually receive the OAM data i.e. the network data and the non network sourced data and to perform various predictive techniques to determine a prospective failure in the network .

The pattern recognition method includes performing data mining on the network data and the non network sourced data step . Here in the data mining the pattern recognition method looks to analyze the network data and the non network sourced data to identify underlying trends patterns or relationships for normal network operation and abnormal network operation. That is the data mining is used to develop from the vast amount of OAM data the network data and the non network sourced data a predictive model for determining a prospective failure in the network. The data mining is used to gather knowledge about relationships and correlation between different data points in the OAM data e.g. data that is not necessarily known to be directly correlated based solely on a priori knowledge. The benefit of data mining is it catalogs relationships and correlation between the OAM data regardless of what causes the relationship. For example the data mining may determine there is a correlation between humidity and failures of a particular device or model in the network etc.

In the pattern recognition method the data mining includes an automatic or semi automatic e.g. operator involvement to guide the analysis analysis of large quantities of data i.e. the network data and the non network sourced data to extract previously unknown interesting patterns. The pattern recognition method contemplates use of any data mining technique to identify so called normal and abnormal network operations. Generally the data mining can include without limitation anomaly detection detection of unusual data or errors association learning searching for relationships between data clustering discovering groups or structures in the data that is some way related or similar without using known structures in the data classification generalizing known structure to apply to new data regression attempt to find a function which models the data with low error summarization providing compact representation of the data etc. Additionally the validity of the overall patterns and correlations determined by the data mining can be continually checked by various statistical algorithms to see if these patterns and correlations are correctly predicting failures and these updates can further be used to refine the data mining. This data mining step can also be viewed as a training step.

The pattern recognition method includes developing a predictive analytics model based on the data mining step . The data mining can be viewed as gathering knowledge and the resulting predictive analytics model is applying that knowledge to determine or predict events. The pattern recognition method contemplates using any predictive analytics model such as without limitation regression models linear logistic multinomial logistic probit splines etc. time series models survival analysis decision learning machine learning techniques neural networks Hierarchical Temporal Memory etc. For example the pattern recognition method can include a self organizing map technique to determine out of normal operation for the network and associated network resources such as a component sub system system device facility etc. . Other embodiments are also contemplated.

The pattern recognition method includes performing predictive analytics on the network data and the non network sourced data using the predictive model to detect likely future failures step . Here after the pattern recognition method has established a sufficiently trained predictive analytics model based on the data mining the pattern recognition method can operate over time to provide proactive OAM in the network . The output of this step is a statistical likelihood of a failure in the network . For example the pattern recognition method can direct a network operator to a potential failure i.e. an infrastructure hotspot in the network in advance so the network operator can perform proactive maintenance before the failure instead of reactive maintenance after the failure. That is the pattern recognition method can provide a notification from the predictive analytics that a network resource in the network is likely to fail and the network operator can perform a proactive maintenance activity on the network resource. Further this step can be continually used to provide feedback in the pattern recognition method for better training to improve the pattern recognition.

The proactive OAM systems and methods provide novel techniques to adapt emerging big data or data analytics techniques to review historical trends and consequences in the network to identify possible future outcomes with a high degree of statistical probability. This is counter to the conventional OAM technique of real time monitoring to detect a definitive threshold crossing. In use the proactive OAM systems and methods are advantageous in network operations network optimization and service monetization. For network operation the proactive OAM systems and methods allow a network operator to monitor network health so as to identify infrastructure hotspots and possible future failure modes in advance. For network optimization the proactive OAM systems and methods allow the network operator to proactively manage bandwidth resources so as to optimize for efficiency and cost such as for example relying on less protection bandwidth based on an ability to prevent failures. For service monetization the proactive OAM systems and methods allow the network operator to apply dynamic pricing strategies based on dynamic traffic patterns and historical customer trends.

It will be appreciated that some exemplary embodiments described herein may include one or more generic or specialized processors one or more processors such as microprocessors digital signal processors customized processors and field programmable gate arrays FPGAs and unique stored program instructions including both software and firmware that control the one or more processors to implement in conjunction with certain non processor circuits some most or all of the functions of the methods and or systems described herein. Alternatively some or all functions may be implemented by a state machine that has no stored program instructions or in one or more application specific integrated circuits ASICs in which each function or some combinations of certain of the functions are implemented as custom logic. Of course a combination of the aforementioned approaches may be used. Moreover some exemplary embodiments may be implemented as a non transitory computer readable storage medium having computer readable code stored thereon for programming a computer server appliance device etc. each of which may include a processor to perform methods as described and claimed herein. Examples of such computer readable storage mediums include but are not limited to a hard disk an optical storage device a magnetic storage device a ROM Read Only Memory a PROM Programmable Read Only Memory an EPROM Erasable Programmable Read Only Memory an EEPROM Electrically Erasable Programmable Read Only Memory Flash memory and the like. When stored in the non transitory computer readable medium software can include instructions executable by a processor that in response to such execution cause a processor or any other circuitry to perform a set of operations steps methods processes algorithms etc.

Although the present disclosure has been illustrated and described herein with reference to preferred embodiments and specific examples thereof it will be readily apparent to those of ordinary skill in the art that other embodiments and examples may perform similar functions and or achieve like results. All such equivalent embodiments and examples are within the spirit and scope of the present disclosure are contemplated thereby and are intended to be covered by the following claims.

