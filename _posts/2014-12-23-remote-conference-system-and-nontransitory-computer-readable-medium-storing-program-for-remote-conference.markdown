---

title: Remote conference system and non-transitory computer readable medium storing program for remote conference
abstract: A communication device obtains video data. The video data includes a plurality of inter-frame coded image data and a plurality of intra-frame coded image data. The communication device displays a portion of a video layout region on a video display region of a display of the communication device. A plurality of captured images, reproduced from video data, is laid out in the video layout region. When a specific captured image is not included in the video display region, the communication device determines update frequency information. The update frequency information sets at least a portion of the plurality of inter-frame coded image data included in specific video data, corresponding to the specific captured image, as a non-target for transmission. The communication device transmits the update frequency information via a communication unit of the communication device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09420028&OS=09420028&RS=09420028
owner: Brother Kogyo Kabushiki Kaisha
number: 09420028
owner_city: Nagoya-shi, Aichi-ken
owner_country: JP
publication_date: 20141223
---
This application claims priority to Japanese Patent Application No. 2013 270726 filed on Dec. 27 2013 the content of which is herein incorporated by reference in its entirety.

Aspects relate to a non transitory storage medium that stores programs executable by a computer that controls a communication device used in a remote conference via a network a non transitory storage medium that stores programs for a server used in the remote conference and a remote conference system.

There has been known a technique relating to a remote conference. For example a known communication device is installed at each location for a television conference in a television conference system. In the television conference system each communication device is connected to the other communication devices to perform a television conference. Each communication device includes a monitor on which a plurality of windows is displayed. Upon receipt of moving image data from one or more other communication devices installed at other respective locations a communication device displays moving images of the respective locations in respective windows on the monitor. In the communication device for example when a size of a window in which a moving image is displayed is reduced a control command for decreasing a frame rate or resolution of moving image data is generated. In another example when a window is dismissed a control command for stopping transmission of moving image data is generated. Such a control command is transmitted to a communication device that sent the moving image data.

A remote conference may be performed using a plurality of communication devices connected to a network. Data of video and audio in a remote conference may be communicated between the plurality of the communication devices via the server connected to the network. Each communication device may display captured images corresponding to a plurality of pieces of video data transmitted from the other communication devices. The number of captured images to be displayed in each communication device may increase with an increase in number of communication devices to be used e.g. locations in a remote conference. In some cases the captured images of all the locations might not be displayed on a monitor at the same time in a communication device. In order to display one or more hidden captured images on the monitor a user of the communication device may input into the communication device an instruction to move one or more captured images through an operation for changing one or more captured images to be displayed e.g. scrolling swiping and or changing a tab . In response to the instruction the communication device may display the one or more hidden captured images. When the communication device receives such an instruction while receipt of video data corresponding to the one or more hidden captured images has been stopped the communication device starts receiving the corresponding video data in response to the instruction. Video data includes an intra frame coded image data and an inter frame coded image data. The intra frame coded image data may be decoded without reference to information of another frame. In contrast to this for example an inter frame coded image data may be decoded with reference to information of an intra frame coded image data. Therefore if the communication device receives an inter frame coded image data in response to the moving instruction the communication device might not decode video data until the communication device receives an intra frame coded image data. Owing to this a captured image corresponding to the video data might not be displayed until the communication device receives an intra frame coded image data whereby a hidden captured image might not be displayed smoothly in response to the changing operation in some cases.

Some embodiments provide for a remote conference system and a non transitory storage medium that stores programs to be used for a remote conference which may enable one or more hidden captured images to be displayed smoothly while restricting increase of an amount of video data to be communicated between communication devices.

An aspect of the present disclosure is a communication device. The communication device obtains a plurality of video data. Each of the plurality of video data including a plurality of inter frame coded image data and a plurality of intra frame coded image data. The communication device displays a portion of a video layout region on a video display region of a display of the communication device. A plurality of captured images from the plurality of video data being laid out in the video layout region. When a specific captured image is not included in the video display region the communication device determines update frequency information. The update frequency information set at least a portion of the plurality of inter frame coded image data included in specific video data corresponding to the specific captured image as a non target for transmission. The communication device transmits the update frequency information via a communication unit of the communication device.

Hereinafter an illustrative embodiment for implementing one or more aspects of the disclosure will be described with reference to the accompanying drawings. The disclosure is not limited to specific embodiments but various aspects may be adopted in the same technical idea. For example one or more aspects of the disclosure may be omitted or replaced with another one. The disclosure may include another aspect as well as the disclosure.

A remote conference system will be described referring to . As depicted in the remote conference system includes a server and a plurality of for example six communication devices and . Hereinafter a remote conference performed among parties using the communication devices and respectively will be described. In other embodiments for example a remote conference using the remote conference system may be performed among parties using five or less communication devices or using seven or more communication devices.

The server and the communication devices and are connected to a network . The network may be for example the Internet. A remote conference using the communication devices and may be performed via the server similar to a Web conference using a known remote conference system.

The communication device has a function of performing communication via the network . The communication device may be for example a smartphone a tablet terminal or a personal computer. In this illustrative embodiment the communication device may be a mobile device such as a smartphone or a tablet terminal. A detailed configuration of the communication device will be described later. The communication devices and may be a known communication device. For example one or more or all of the communication devices and may be a communication device that is the same as the communication device . In other embodiments for example the communication devices and may be a personal computer. At a remote conference the communication devices and are configured to execute each processing that the communication device executes refer to . In the illustrative embodiment a description will be made by taking the communication device as an example.

In the remote conference system for example the communication device transmits video data and audio data to the server . The video data transmitted from the communication device corresponds to an image captured using the communication device hereinafter referred to as captured image . The audio data transmitted from the communication device corresponds to audio collected using the communication device . The communication device also transmits video data and audio data to the server . The video data transmitted from the communication device corresponds to an image captured using the communication device . The audio data transmitted from the communication device corresponds to audio collected using the communication device . Similar to the communication device each of the communication devices and transmit to the server video data corresponding to an image captured using each of the communication devices and and audio data corresponding to audio collected using each of the communication devices and . The server transmits the video data and audio data which are received from the communication devices and to appropriate destination devices respectively. The destination device refers to each of the communication device and the communication devices and other than the sender device that transmits video data and audio data. For example the server transmits video data and audio data which are received from the communication device to each of the communication devices and . The server does not transmit the video data and the audio data which are received from the communication device to the communication device which is the sender device of the video data and the audio data. In other words in the remote conference system the video data and audio data transmitted from the communication device are delivered to each of the communication devices and via the server using a streaming method. The video data and audio data transmitted from each of the communication devices and are delivered to the communication device via the server using the streaming method.

Video data may be moving image data compressed using a predetermined compression method. The compression method may be for example the H.264 video compression method. The video data according to the illustrative embodiment includes an intra frame coded image data and an inter frame coded image data similar to known video data. A frame rate of video data may be for example 30 fps. The intra frame coded image data includes an I frame intra coded frame . The inter frame coded image data includes a P frame predicted frame and a B frame bi directional predicted frame . The I frame is an image coded without using inter frame prediction. The P frame is an image coded using forward prediction. The B frame is an image coded using one of forward prediction backward prediction and bi directional prediction. The I frame the P frame the B frame are compressed images already in practical use. Therefore a detailed description for the I frame the P frame the B frame will be omitted. The I frame P frame and B frame are also referred to irrespectively or correctively as compressed image .

Each of the communication devices and transmits its own identification ID information as sender device s ID information and a conference ID that identifies a remote conference in which each of the communication devices and participates along with video data and audio data. The server transmits the sender device s ID information and the conference ID to each destination device along with the video data and audio data received from the sender device. The ID information and conference ID are included in for example each header portion of the video data and the audio data. Each ID information is information for identifying particular communication devices from one another. For example the ID information of the communication device is information for identifying the communication device . The ID information of each of the communication devices and is information for identifying each of the communication devices and from one another. In the illustrative embodiment it is assumed that all the communication devices and participate in the same remote conference that is identified by a predetermined conference ID.

The communication device receives video data audio data the ID information and the conference ID transmitted from each of the communication devices and . In the communication device captured images are reproduced from the respective video data received from the communication devices and respectively. In other words the communication device generates captured images and corresponding to the respective video data. The communication device also reproduces a captured image from video data that it obtains. In other words the communication device generates a captured image corresponding to the received video data. The reproduction of a captured image may be performed for example by decoding a compressed image included in video data.

The captured image corresponds to video data transmitted from the communication device . The captured image corresponds to video data transmitted from the communication device . The captured image corresponds to video data transmitted from the communication device . The captured image corresponds to video data transmitted from the communication device . The captured image corresponds to video data transmitted from the communication device .

The generated captured images and and the captured image of the communication device are laid out in accordance with a layout setting. A predetermined program for remote conference includes the layout setting. The predetermined program for remote conference may be for example a program for receiving processing of refer to step S in . The layout setting may be for example information in which an entire area including a partial area where one or more captured images including the captured images and are laid out is patterned. In the communication device the layout of the captured images and and the captured image of the communication device may be determined arbitrarily in advance. In the communication device one of the options display and hide may be set to each captured image. For example when the option of hide is set to the captured image of the communication device the captured image of the communication device is hidden. In the communication device a remote conference screen which includes contents thereon in accordance with the layout setting and the setting of one of the options of display and hide is displayed refer to .

In the illustrative embodiment according to the layout setting for example the option of hide is set to the captured image of the communication device and the option of display is set to each of the captured images and . The captured images and are aligned in the horizontal direction refer to . The entire area in which the captured images and are arranged in accordance with the layout setting is referred to as video layout region A . The captured image is arranged in an area A of the video layout region A. The captured image is arranged in an area A of the video layout region A. The captured image is arranged in an area A of the video layout region A. The captured image is arranged in an area A of the video layout region A. The captured image is arranged in an area A of the video layout region A. The video layout region A includes one column by five rows. The area A is an area in the first column and first row of the video layout region A. The area A is an area in the first column and second row of the video layout region A. The area A is an area in the first column and third row of the video layout region A. The area A is an area in the first column and fourth row of the video layout region A. The area A is an area in the first column and fifth row of the video layout region A. In other embodiments for example the video layout region A may include a plurality of columns.

The communication device stores a status table therein refer to . The area A and the ID information of the communication device are stored in the status table in association with each other. The area A and the ID information of the communication device are stored in the status table in association with each other. The area A and the ID information of the communication device are stored in the status table in association with each other. The area A and the ID information of the communication device are stored in the status table in association with each other. The area A and the ID information of the communication device are stored in the status table in association with each other. In addition to this in the status table a total video play time and a total audio play time are associated with each pair of one of the areas A A A A and A of the video layout region A and a corresponding one of the ID information. The total video play time indicates a total display duration of each of the captured images and in the video display region B during a remote conference. In the communication device the duration for which each of the captured images and is displayed is measured and accumulated to obtain the total display duration.

The total audio play time indicates a total play duration of audio data transmitted from each of the communication devices and during a remote conference. Audio data is transmitted and received in a unit of a block having a play duration of a predetermined time via the server in the remote conference system . For example audio data is transmitted and received in unit of a block having a play duration of 20 milliseconds msec. . The total audio play time in each of the communication devices and is obtained based on audio data received by the communication device from each of the communication devices and . Audio data is transmitted to the server from each of the communication devices and at predetermined regular intervals.

In ID information indicates the ID information of the communication device . ID information indicates the ID information of the communication device . ID information indicates the ID information of the communication device . ID information indicates the ID information of the communication device . ID information indicates the ID information of the communication device . The details relating to the display of the captured images and that are laid out in accordance with the layout setting will be further described later.

In each of the communication devices and captured images are also reproduced from respective video data received from other ones of the communication devices and . In other words each of the communication devices and generates captured images corresponding to the respective video data. In each of the communication devices and a remote conference screen which includes contents thereon in accordance with the layout setting and the setting of one of the options of display and hide is displayed. The communication devices and are also configured to reproduce a captured image from video data obtained and display the generated captured image thereon. Further in each of the communication devices and audio is reproduced from audio data received from each of the communication devices and other than itself and the generated audio corresponding to each audio data is outputted.

In the illustrative embodiment similar to the setting for the communication device in the setting for the communication devices and the option of hide is set to own captured image generated by itself and the option of display is set to the captured images of the other communication devices. When a description is made from the viewpoint of a device that obtains predetermined data the sender device or sender of the predetermined data in the illustrative embodiment is also referred to as supplier device or supplier of the predetermined data.

As depicted in the server includes a central processing unit CPU a storage device a random access memory RAM a timer and a communication unit . The CPU the storage device the RAM the timer and the communication unit are connected to a bus .

The CPU is configured to execute calculation processing. The storage device may be implemented by a computer readable storage medium e.g. a hard disk. In other embodiments for example the storage device may be implemented by a flash memory and or a read only memory ROM . The storage device stores therein various programs for example an operating system OS and various applications. The applications stored in the storage device include programs for executing various processing refer to . The programs for executing the above processing are preinstalled in the storage device .

The pre installation of the execution programs is implemented by which a reading unit not depicted of the server reads the programs from a computer readable storage medium e.g. a semiconductor memory. In other embodiments for example when the server includes an optical drive not depicted such a pre installation may be implemented by which the optical drive reads the programs from an optical medium. In still other embodiments for example the pre installation may be implemented by which the server receives via the communication unit of the server the programs stored in a computer readable storage medium e.g. a hard disk of another server as transmission signals. The other server may be different from the server connected to the network . The computer readable storage medium may include a non transitory storage medium but not include a transitory storage medium. The non transitory storage medium may include any storage medium that is capable of storing information regardless of storage duration of information.

The RAM is a storage area to be used when the CPU executes various programs. The RAM stores in a predetermined storage area predetermined data and information used in various processing during execution of the various processing.

The CPU is configured to control the server for example by executing the OS and the programs for executing the processing depicted in and stored in the storage device whereby various processing are executed and various functions are implemented in the server .

The timer has for example a calendar function and a clock function. The timer is configured to measure elapsed time. In other embodiments for example the timer may be implemented by a clock function of the OS. The communication unit is configured to connect the server to the network and perform data communication via the network . The server is configured to receive video data audio data and a particular conference ID from each communication device that participates in a remote conference identified by the particular conference ID. The server is further configured to transmit the received video data and audio data to each destination device. For example the communication unit receives video data and audio data transmitted from each of the communication devices and and transmits the received video data and audio data to each destination device. In other words the video data and audio data transmitted from each of the communication devices and are transferred to each destination device via the communication unit . The server is hardwired to the network via the communication unit . In other embodiments for example the server may be wirelessly connected to the network via the communication unit .

The server is different from a known server in a point that the storage device of the server stores the programs for executing the processing depicted in . The server may be an information processing device having a communication function that is the same as the known server in terms of hardware configuration. In other embodiments for example the server may have a configuration that is the same as the known server.

As depicted in the communication device includes a CPU a storage device a RAM a display an operation device a camera an audio device a timer and a communication unit . The CPU the storage device the RAM the display the operation device the camera the audio device the timer and the communication unit are connected to a bus .

The CPU executes calculation processing. The storage device may be implemented by a computer readable storage medium e.g. a flash memory. In other embodiments for example the storage device may be implemented by a hard disk and or a ROM. The storage device stores various therein various programs for example an OS and various applications. The applications stored in the storage device include programs for executing various processing refer to . The programs for executing the above processing may be preinstalled in the storage device . In other embodiments for example the programs may be transmitted to the communication device from the server via the network as transmission signals when the communication device accesses the server for participating in a remote conference. In this case the programs are installed in the storage device or the RAM of the communication device upon participation of the remote conference.

The pre installation of the execution programs is implemented by which a reading unit not depicted of the communication device reads the programs from a computer readable storage medium e.g. a semiconductor memory. In other embodiments for example when the communication device includes an optical drive not depicted such a pre installation may be implemented by which the optical drive reads the programs from an optical medium. In still other embodiments for example the pre installation may be implemented by which the communication device receives via the communication unit of the communication device the programs stored in a computer readable storage medium e.g. a hard disk of another server as transmission signals. The other server may be different from the server connected to the network . The computer readable storage medium may include a non transitory storage medium but not include a transitory storage medium. The non transitory storage medium may include any storage medium that is capable of storing information regardless of storage duration of information.

The RAM is a storage area to be used when the CPU executes various programs. The RAM stores in a predetermined storage area predetermined data and information used in various processing during execution of the various processing. The RAM also stores the status table refer to therein.

The CPU is configured to control the communication device for example by executing the OS and the programs for executing the processing depicted in stored in the storage device whereby various processing are executed and various functions are implemented in the communication device .

The display is configured to display various information thereon. For example the display displays a remote conference screen including the captured images and refer to . The operation device is configured to receive an input e.g. various instructions with respect to the communication device . The operation device includes for example a physical button and a touch pad . The touch pad may be for example a capacitive pointing device that is configured to output a signal indicating a position of a coordinate corresponding to a position where a finger of a user touches. In other embodiments for example the touch pad may be a resistive pointing device or an ultrasonic pointing device. The display and the touch pad enclosed with a dashed line in constitute a touch panel.

A user of the communication device performs operations e.g. scrolling swiping flicking tapping dragging pinch in and or pinch out on the touch pad . For example the user of the communication device moves a finger touching the touch pad in a predetermined direction to perform such operations. In response to the user s operations predetermined signals are outputted from the touch pad . Operation information e.g. types of operations and movement distance corresponding to each operation is generated based on the predetermined signals. Processing to generate the operation information is employed in known smartphones or known tablet terminals as Application Programming Interface API and also employed in the communication device . In other embodiments for example the operation device may further include a keyboard and a mouse. When the communication device is a personal computer the operation device includes a keyboard and a mouse.

The display of the captured images and on the display will be described referring to . The display includes a display area. The video layout region A is an imaginary area that is defined beyond the display area of the display . The video display region B is a display area for remote conference that is defined within the display area of the display . In a case where an entire portion of the display area of the display is defined as the display area for remote conference the video display region B coincides with the display area of the display . In the illustrative embodiment it is assumed that the entire portion of the display area of the display is defined as the display area for remote conference. In a halftone area of the display indicates the display area of the display . The captured images and are laid out in the video layout region A. A width WA of the video layout region A in the horizontal direction is greater than a width WB of the video display region B. A portion of the video layout region A is displayed in the video display region B. In other words one or more but not all of the captured images and are displayed in the video display region B at one time. In an example depicted in particular two of the captured images and are displayed in the video display region B at one time.

For example in order to change the display contents on the display area of the display from the captured images and refer to an upper drawing in to the captured images and refer to a lower drawing in a user of the communication device performs a swiping operation to move a finger touching the touch pad from the right to the left. In response to this the video layout region A moves relative to the video display region B in the horizontal direction and thus the captured images and are displayed. In the communication device with reference to the horizontal direction particular areas of the video layout region A displayed in the video display region B are identified. For example in a case of the upper drawing in the areas A and A displayed in the video display region B are identified and information indicating the areas A and A is stored in the RAM . In a case of the lower drawing in the areas A and A displayed in the video display region B are identified and information indicating the areas A and A is stored in the RAM .

The camera is configured to capture an external image that presents in a predetermined direction with respect to the communication device e.g. in front of the communication device . For example when there is a user of the communication device in front of the communication device the camera captures an external image including the user. The audio device includes a speaker and a microphone . The speaker is configured to output audio. The microphone is configured to collect external audio. For example the microphone collects voice outputted by the user of the communication device . The audio device is configured to output audio corresponding to audio data from the speaker . The audio device is configured to generate waveform data through analog to digital conversion of audio collected by the microphone using a predetermined sampling frequency e.g. 11.025 kHz or 44.1 kHz . The communication device is configured to start capturing an external image using the camera and collecting external audio using the microphone upon start of a remote conference. In the communication device video data corresponding to a captured image and audio data corresponding to the generated waveform data are generated.

The timer has for example a calendar function and a clock function. The timer is configured to measure elapsed time. In other embodiments for example the timer may be implemented by a clock function of the OS. The communication unit is configured to connect the communication device to the network and perform data communication via the network . For example the communication unit of the communication device transmits video data and audio data which are generated during a remote conference to the server along with the ID information of the communication device and the conference ID identifying the remote conference in which the communication device participates. Then the server further transmits the received video data audio data and ID information of the communication device to each of the communication devices and that participate in the remote conference identified by the same conference ID. The communication unit of the communication unit receives video data audio data and the sender device s ID information transmitted from each of the communication devices and via the server . The communication device is wired or wirelessly connected to the network communication unit . For example when the communication device is a mobile device the communication device is wirelessly connected to the network via the communication unit . The communication unit is a communication module for performing wireless communication in compliance with a known communication standard for example a Wi Fi standard a 4G standard or a 3G standard.

The communication device is different from a known mobile device in a point that the storage device of the communication device stores the programs for executing the processing depicted in . The communication device may be a communication device that is the same as a known mobile device in terms of hardware configuration.

The various processing executed in the communication device during a remote conference will be described. In the remote conference system for example the server sends an electronic mail e mail to e mail addresses corresponding to the communication devices and before a predetermined time and date of a particular remote conference. Each e mail includes a Uniform Resource Locator URL of the particular remote conference to be held among the communication devices and . The URL is unique to each virtual conference room of a remote conference. In other words the URL includes a conference ID of a remote conference. The conference ID may be included as for example a query parameter of a URL.

The user of the communication device performs an appropriate operation on the communication device on or after the predetermined time and date of the particular remote conference. For example in the communication device the CPU accesses the server via the communication unit based on the URL including the conference ID of the particular remote conference and executes processing for establishing a session for the particular remote conference with the server . In other embodiments for example the CPU may allow the communication unit to transmit a login request including a predetermined user ID and a password to the server . In this case when a login is successful the CPU may transmit the conference ID from the communication unit to the server to establish a session for the particular remote conference with the server . Processing described below are executed while the session for the particular remote conference is established between the communication device and the server e.g. while the communication device is connected with a particular remote conference room for the particular remote conference .

The CPU allows the timer to start measuring time upon establishment of a connection of the communication device to the particular remote conference room. The CPU is configured to store in the RAM elapsed time from the start of measurement. In other embodiments for example the timer may be configured to start measuring time upon establishment of connections of all the communication devices and which are scheduled to participate in the same remote conference identified by the same conference ID to the particular remote conference room. Upon establishment of connections of all the communication devices and which are scheduled to participate in the same remote conference to the particular remote conference room the server notifies each of the communication devices and that all the communication devices and have connected to the particular remote conference room.

Update frequency transmitting processing will be described referring to . The update frequency transmitting processing is repeatedly executed at regular intervals until the communication device is disconnected from the particular conference room after establishing the connection thereto. The update frequency transmitting processing is executed at every predetermined interval e.g. 100 msec. Subsequent to starting the update frequency transmitting processing the CPU specifies a positional relationship between the video layout region A and the video display region B e.g. step S . For example the CPU identifies particular areas of the video layout region A positioned within the video display region B and particular areas of the video layout region A positioned outside the video display region B. In the case of the upper drawing in the CPU identifies the areas A and A as the particular areas of the video layout region A positioned within the video display region B and the areas A A and A as the particular areas of the video layout region A positioned out of the video display region B.

Subsequently the CPU updates each total video play time associated with a corresponding one of the particular areas of the video layout region A positioned within the video display region B in the status table stored in the RAM e.g. step S . For example it is assumed that the areas A and A are identified as the particular areas of the video layout region A positioned within the video display region B refer to the upper drawing in . In this case the CPU updates both the total video play time associated with the area A and the total video play time associated with the area A in the status table. As described above the update frequency transmitting processing is repeatedly executed at every predetermined interval. Therefore the CPU adds a predetermined amount of time e.g. 100 msec. which is the predetermined interval to each total video play time associated with a corresponding one of the areas A and A in the status table. The predetermined interval may be the time elapsed between a timing of the last execution of step S and a timing of this time execution of step S.

Subsequently the CPU determines update frequency information e.g. step S . The update frequency information is determined for each of the communication devices and that transmit video data. The determined update frequency information is stored with the ID information of each of the communication devices and . The update frequency information indicates which one or more of the compressed images of various types included in video data are determined as a non target for transmission. For example the update frequency information is defined as described in .

An update rule will be described referring to . In the illustrative embodiment for example the update rule defines update frequency levels 5 4 3 2 and 1 for the update frequency information. The update frequency level 5 is the highest level for the update frequency information. Subsequent to the update frequency level 5 the level becomes lower in the order of the update frequency levels 4 3 and 2 . The update frequency level 1 is the lowest level for the update frequency information.

At the update frequency level 5 for example an I frame a P frame and a B frame are all determined as a target for transmission. None of the I frame the P frame and the B frame is determined as a non target for transmission. Therefore for video data corresponding to the update frequency level 5 I frames P frames and B frames are all transmitted to the communication device via the server . Thus this rule enables a captured image to be updated in the communication device based on all of the I frames the P frames and the B frames. A minimum I frame transmission interval is defined as 0 msec. The minimum I frame transmission interval indicates the shortest interval at which the server transmits an I frame which is a target for transmission.

At the update frequency level 4 for example an I frame and a P frame are determined as a target for transmission and a B frame is determined as a non target for transmission. Therefore for video data corresponding to the update frequency level 4 I frames and P frames are transmitted to the communication device via the server and B frames are not transmitted to the communication device . Thus this rule enables a captured image to be updated in the communication device based on the I frames and the P frames. The minimum I frame transmission interval is defined as 0 msec.

At the update frequency level 3 for example an I frame is determined as a target for transmission and a P frame and a B frame are determined as a non target for transmission. The minimum I frame transmission interval is defined as 300 msec. Therefore for video data corresponding to the update frequency level 3 I frames are transmitted to the communication device via the server at intervals of 300 msec. or longer and P frames and B frames are not transmitted to the communication device . Thus this rule enables a captured image to be updated in the communication device based on the I frames transmitted from the server at intervals of 300 msec. or longer.

At the update frequency level 2 for example an I frame is determined as a target for transmission and a P frame and a B frame are determined as a non target for transmission. The minimum I frame transmission interval is defined as 2000 msec. Therefore for video data corresponding to the update frequency level 2 I frames are transmitted to the communication device via the server at intervals of 2000 msec. or longer and P frames and B frames are not transmitted to the communication device . This rule enables a captured image to be updated in the communication device based on I frames transmitted from the server at intervals of 2000 msec. or longer.

At the update frequency level 1 for example an I frame a P frame and a B frame are all determined as a non target for transmission. In this case transmission of video data corresponding to the update frequency level 1 to the communication device via the server is stopped. The illustrative embodiment will be described below using example cases according to the update frequency levels 5 4 3 2 and 1 depicted in .

Subsequent to determining update frequency information for each of the communication devices and in step S the CPU controls transmission of the update frequency setting and own ID information e.g. step S . More specifically in step S the CPU outputs to the communication unit an instruction to transmit the update frequency setting and the own ID information to the server . Thus the update frequency setting and the ID information of the communication device are transmitted to the server from the communication unit . The update frequency setting which is transmitted to the server includes the update frequency information determined for each of the communication devices and refer to . Each update frequency information is associated with a corresponding one of the ID information of the communication devices and refer to . The CPU generates the update frequency setting based on the update frequency information that is determined as described below and stored in the RAM with being associated with the ID information at the time of controlling the transmission in step S. The ID information of the communication device that is a sender may be included in for example a header portion of the update frequency setting. Subsequent to step S the CPU ends the update frequency transmitting processing.

Update frequency determining processing which is executed at the time of determining the update frequency information in step S in the update frequency transmitting processing depicted in will be described referring to . As described above the update frequency determining processing is executed for each of the communication devices and . In the illustrative embodiment there are five communication devices and besides the communication device . Therefore in the illustrative embodiment the update frequency determining processing is successively executed five times for determining the update frequency information in step S. The CPU determines the update frequency information determined through the update frequency determining processing executed for one of the communication devices and refer to step S S S S or S described below as the update frequency information of a target communication device.

The CPU judges whether the ID information of the target communication device targeted for the update frequency determining processing is associated with the one of the areas identified as the particular areas of the video layout region A positioned within the video display region B in step S of e.g. step S . A description will be further made referring to the upper drawing of and . In this case in step S of the areas A and A are identified. Therefore when the update frequency determining processing is executed for one of the communication device identified by the ID information associated with the area A and the communication device identified by the ID information associated with the area A among the communication devices and the CPU makes a positive judgment in step S e.g. YES in step S . When the update frequency determining processing is executed for one of the communication devices and identified by the ID information associated with the areas A A and A among the communication devices and the CPU makes a negative judgment in step S e.g. NO in step S . Hereinafter a communication device that is targeted for the update frequency determining processing among the communication devices and is referred to as communication device targeted for processing .

When the CPU makes a positive judgment in step S e.g. YES in step S the CPU designates update frequency information as update frequency level 5 e.g. step S . That is when video data transmitted from the communication device targeted for processing is displayed the update frequency information is designated as update frequency level 5 . The designated update frequency level 5 is stored in the RAM with being associated with the ID information of the communication device targeted for processing. When the CPU makes a negative judgment in step S e.g. NO in step S the CPU designates update frequency information as update frequency level 1 e.g. step S . The designated update frequency level 1 is stored in the RAM with being associated with the ID information of the communication device targeted for processing.

Subsequent to step S the CPU judges whether the particular area of the video layout region A associated with the ID information of the communication device targeted for processing is positioned within an area corresponding to a reference distance WC with reference to a reference edge in a direction opposite to a moving direction e.g. step S . In the example depicted in the upper drawing of when the communication device targeted for processing is the communication device the particular area of the video layout region A associated with the ID information of the communication device targeted for processing is the area A. When the communication device targeted for processing is the communication device the particular area of the video layout region A associated with the ID information of the communication device targeted for processing is the area A. When the communication device targeted for processing is the communication device the particular area of the video layout region A associated with the ID information of the communication device targeted for processing is the area A refer to .

In the moving direction of the captured images in response to a swiping operation for displaying one or more hidden captured images is the horizontal direction. In step S a reference direction may be the horizontal direction. The reference edge may be a trailing edge of both edges of the video display region B in the horizontal movement. For example in the example depicted in the upper drawing of the right edge of the video display region B in the horizontal direction may be the reference edge. In the example depicted in the lower drawing of the left edge of the video display region B in the horizontal direction may be the reference edge. The reference distance WC is a distance appropriate for a distance WD. The distance WD is a distance between edges on the same side e.g. the right edges or the left edges of adjacent two of the captured images in the horizontal direction. In the illustrative embodiment particular two of a plurality of captured images are displayed in the video display region B at the same time refer to . Therefore the reference distance WC is twice as long as the distance WD. In other embodiments for example the reference distance WC may be the same as the distance WD or three times or more as long as the distance WD.

When the particular area of the video layout region A associated with the ID information of the communication device targeted for processing is positioned within the area corresponding to the reference distance WC with reference to the reference edge e.g. YES in step S the CPU raises by one level the update frequency level designated for the update frequency information in step S and is stored in the RAM e.g. step S . Thus the update frequency information stored in the RAM is designated as update frequency level 2 . When the particular area of the video layout region A associated with the ID information of the communication device targeted for processing is not positioned within the area corresponding to the reference distance WC with reference to the reference edge e.g. NO in step S or subsequent to step S the CPU judges whether a ratio of the total video play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is greater than or equal to a first reference value e.g. step S . In step S the CPU accesses the status table stored in the RAM to judge the total video play time associated with the ID information. The CPU also judges an elapsed time which is continuously measured by the timer from the start of the particular remote conference upon the establishment of the connection of the communication device to the particular remote conference room as the duration of the ongoing remote conference. Subsequently the CPU judges whether a value obtained by dividing the total video play time by the duration of the ongoing remote conference is greater than or equal to the first reference value. For example the first reference value may be 0.5 50 . The first reference value is stored in the storage device with being associated with the programs for executing the update frequency determining processing.

When the ratio of the total video play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is greater than or equal to the first reference value e.g. YES in step S the CPU raises by one level the update frequency level designated for the update frequency information stored in the RAM e.g. step S . When step S has already been executed the update frequency information stored in the RAM is designated as the update frequency level 3 . When step S has not yet been executed the update frequency information stored in the RAM is designated as the update frequency level 2 .

When the ratio of the total video play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is smaller than the first reference value e.g. step S No or subsequent to step S the CPU judges whether a ratio of the total audio play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is greater than or equal to a second reference value e.g. step S . In step S the CPU accesses the status table stored in the RAM to judges the total audio play time associated with the ID information. The CPU also judges an elapsed time which is continuously measured by the timer from the start of the particular remote conference upon the establishment of the connection of the communication device to the particular remote conference as the duration of the ongoing remote conference. The CPU judges whether a value obtained by dividing the total audio play time by the duration of the ongoing remote conference is greater than or equal to the second reference value. For example the second reference value may be 0.2 20 . The second reference value is stored in the storage device with being associated with the programs for executing the update frequency determining processing.

When the ratio of the total audio play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is greater than or equal to the second reference value e.g. YES in step S the CPU raises by one level the update frequency level designated for the update frequency information stored in the RAM e.g. step S . When both steps S and S have already been executed the update frequency information stored in the RAM is designated as the update frequency level 4 . When one of steps S and S has already been executed the update frequency information stored in the RAM is designated as the update frequency level 3 .

When the ratio of the total audio play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is smaller than the second reference value e.g. NO in step S or subsequent to one of steps S and S the CPU ends the update frequency determining processing. When there is one or more communication devices that are not determined as a device targeted for processing the CPU executes the update frequency determining processing again. When the update frequency determining processing has been executed for all of the communication devices and the routine returns to step S of .

Video data transmitting processing will be described referring to . The video data transmitting processing is repeatedly executed at regular intervals until the communication device is disconnected from the particular conference room after establishing the connection thereto. The video data transmitting processing is repeatedly executed at intervals corresponding to the frame rate of video data. For example when the frame rate is 30 fps the video data transmitting processing is executed at intervals of 1 30 sec. Subsequent to starting the video data transmitting processing the CPU obtains a captured image captured using the camera e.g. step S . Subsequently the CPU generates a compressed image by encoding the captured image using a predetermined compression method e.g. the H.264 video compression method e.g. step S .

The CPU assigns image type information and the ID information of the communication device to video data including the generated compressed image e.g. step S . The image type information indicates a type of the generated compressed image. For example when the generated compressed image is an I frame the video data is assigned with the image type information indicating I frame. When the generated compressed image is a P frame the video data is assigned with the image type information indicating P frame. When the generated compressed image is a B frame the video data is assigned with the image type information indicating B frame.

The CPU controls transmission of the video data including the compressed image. The video data is assigned with the ID information of the communication device and the image type information e.g. step S . In step S the CPU outputs to the communication unit an instruction to transmit the video data. Thus the video data is transmitted from the communication unit to the server . Subsequent to step S the CPU ends the video data transmitting processing.

Audio Data transmitting processing will be described referring to . The audio data transmitting processing is repeatedly executed at regular intervals until the communication device is disconnected from the particular conference room after establishing the connection thereto. The audio data transmitting processing is repeatedly executed for example at predetermined encoding intervals e.g. at intervals of 20 msec. . The play duration of 20 msec. of audio data corresponds to the encoding intervals of 20 msec. Subsequent to starting the audio data transmitting processing the CPU obtains audio collected using the microphone e.g. step S . The audio obtained by the CPU in step S includes waveform data generated through the analog to digital conversion of audio collected by the microphone using the predetermined sampling frequency e.g. 11.025 kHz or 44.1 kHz . The CPU determines volume dB of the collected audio and judges whether the value representing the determined volume of the collected audio is greater than a threshold value e.g. step S . For example the volume may be determined by determination of a level of the waveform of the audio obtained in step S. The audio collected in step S includes a plurality of sampling points. Therefore for example an average level of a plurality of sampling points included in a predetermined time period may be determined as volume of audio. In other embodiments for example a maximum level of a plurality of sampling points included in the predetermined time period may be determined as volume of audio. The threshold value which is the reference to be used in step S is predetermined in consideration given to volume of user s voice such that the CPU judges that the user of the communication device outputs voice in a remote conference. The threshold value is stored in the storage device with being associated with the program for executing audio data transmitting processing. In other embodiments for example the threshold value may be changed in response to degree of background noises.

When the value representing the determined volume of audio is greater than the threshold value e.g. YES in step S the CPU generates compressed audio data by encoding the obtained audio using a predetermined compression method e.g. MPEG 4 AAC or G.711 e.g. step S . The audio data may be a packet that includes for example encoded data corresponding waveform data having a play duration of 20 msec. The CPU assigns the ID information of the communication device to the generated audio data e.g. step S . Subsequently the CPU controls transmission of the audio data assigned with the ID information e.g. step S . In step S the CPU outputs to the communication unit an instruction to transmit the audio data. Thus the audio data is transmitted from the communication unit to the server . When the value representing the determined volume of audio is smaller than or equal to the threshold value e.g. NO in step S or subsequent to step S the CPU ends the audio data transmitting processing.

Receiving processing will be described referring to . The receiving processing is repeatedly executed at regular intervals until the communication device is disconnected from the particular conference room after establishing the connection thereto. Subsequent to starting the receiving processing the CPU judges whether the predetermined data transmitted from the server has been received e.g. obtained via the communication unit e.g. step S . When the CPU judges that the predetermined data has not been received yet e.g. NO in step S the CPU repeatedly executes this judgment step.

When the CPU judges that the predetermined data has received e.g. YES in step S the CPU judges whether the received data is audio data e.g. step S . When the CPU judges that the received data is audio data e.g. YES in step S the CPU obtains the ID information of the communication device that is a sender of the audio data e.g. step S . For example when the received data is audio data transmitted from the communication device the CPU obtains the ID information of the communication device assigned to the audio data. When the received data is audio data transmitted from the communication device the CPU obtains the ID information of the communication device assigned to the audio data.

Subsequently the CPU accesses the status table stored in the RAM to update the total audio play time associated with the obtained ID information e.g. step S . As described above audio data transmitted and received in the remote conference system is data having a play duration of a predetermined certain length. Therefore the CPU adds the play time to the total audio play time stored with being associated with the ID information obtained in step S. In an example it is assumed that audio data has a play time of 20 msec. and the ID information of the communication device has been obtained in step S. In this case the CPU adds 0.02 sec to the total audio play time associated with the ID information of the communication device in the status table. In another example it is assumed that audio data has a play time of 20 msec. and the ID information of the communication device has been obtained in step S. In this case the CPU adds 0.02 sec to the total audio play time associated with the ID information of the communication device in the status table.

The CPU controls output of audio corresponding to the received audio data e.g. step S . In step S the CPU reproduces audio from the received audio data e.g. decodes the received audio data and outputs to the audio device an instruction to output the reproduced audio. In response to the output instruction the audio device outputs audio corresponding to the audio data through the speaker . When audio data transmitted from the communication device has been received while the display is in a state depicted in the upper drawing of audio including voice of a user of the communication device is outputted through the speaker . When audio data transmitted from the communication device has been received while the display is in a state depicted in the upper drawing of audio including voice of a user of the communication device is outputted through the speaker . In other words in the communication device audio corresponding to each audio data received from each of the communication devices and is outputted through the speaker regardless of whether the captured images and of the communication devices and are displayed or hidden. Subsequent to step S the routine returns to step S and the CPU executes step S and subsequent steps again.

When the received data is not audio data e.g. NO in step S the CPU judges whether the received data is video data e.g. step S . When the received data is not video data e.g. NO in step S the CPU executes processing appropriate for the received data as necessary. Subsequently the routine returns to step S and the CPU executes step S and subsequent steps again.

When the received data is audio data e.g. YES in step S the CPU obtains the ID information of the communication device that is a sender of the video data e.g. step S . For example when the received data is video data transmitted from the communication device the CPU obtains the ID information of the communication device assigned to the video data. When the received data is video data transmitted from the communication device the CPU obtains the ID information of the communication device .

The CPU determines a position of the display area for the received video data in the video layout region A e.g. step S . In one example it is assumed that audio data transmitted from the communication device has been received while the display is in the state depicted in the upper drawing of . In step S as a first step the CPU identifies the area A which is associated with the sender device s ID information refer to obtained along with the video data transmitted from the communication device in the video layout region A. As a second step the CPU identifies the areas A and A of the video layout region A positioned within the video display region B. Then the CPU determines whether a particular area is identified in both the first and second steps. In this case the area A is identified in both the first and second steps. Therefore the CPU determines that the area A is positioned within the video display region B.

In another example it is assumed that video data transmitted from the communication device has been received while the display is in the state depicted in the upper drawing of . In this case in step S as a first step the CPU identifies the area A in the video layout region A associated with the sender device s ID information refer to . As a second step the CPU identifies the areas A and A of the video layout region A positioned within the video display region B. Then the CPU determines whether a particular area is identified in both the first and second steps. In this case the area A is not identified in both the first and second steps. Therefore the CPU determines that the area A is positioned out of the video display region B.

Subsequently the CPU controls the display condition according to the layout setting e.g. step S . During this control the CPU executes processing based on the determination result made in step S. For example when the received data is video data transmitted from the communication device the CPU controls the display condition of the captured image based on the determination result that the received video data is positioned within the video display region B. The CPU reproduces video based on the video data transmitted from the communication device and obtains the captured image . Subsequently the CPU outputs to the display an instruction to output the captured image . In response to the output instruction the display displays the captured image newly obtained in the area A. Subsequent to step S the routine returns to step S and the CPU executes step S and subsequent steps.

When the determination result made in step S indicates that the received video data is positioned out of the video display region B the routine skips step S. For example when the received data is video data transmitted from communication device the CPU does not execute the control of the display condition of the captured image corresponding to video data transmitted from the communication device . Subsequent to step S the routine skips step S and returns to step S.

Processing executed in the server during the remote conference will be described. Each processing described below is executed for one or more of the communication devices and which are connected to the same conference room. In description of processing executed in server one or more or all of the communication devices and may refer to communication device or communication devices without reference numerals.

Transferring processing will be described referring to . The transferring processing is repeatedly executed until all of one or more of the communication devices and disconnect from the particular conference room after one of the one or more communication devices and connects to the particular conference room. Subsequent to starting the transferring processing the CPU judges whether the predetermined data transmitted from one of the communication devices and has been received e.g. obtained via the communication unit e.g. step S . When the CPU judges that the predetermined data has not been received e.g. NO in step S the CPU executes this judgment step repeatedly.

When the CPU judges that the predetermined data has been received e.g. YES in step S the CPU judges whether the received data is the update frequency setting e.g. step S . When the CPU judges that the received data is the update frequency setting e.g. YES in step S the CPU stores the update frequency setting e.g. step S . The update frequency setting is stored in the RAM with being associated with the ID information of the sender device that has sent the update frequency setting refer to . The ID information of the sender device is received by the communication unit along with the update frequency setting. The CPU obtains the ID information via the communication unit along with the update frequency setting.

In ID information target corresponds to ID information target included in the update frequency setting. In the illustrative embodiment each communication device obtains a captured image of own device from video data obtained in itself without the captured image passing through the server . Therefore the update frequency setting transmitted from each of the communication devices i.e. the update frequency setting of the sender device might not include the update frequency information for own device refer to when the communication device is a sender device . Therefore as depicted in there is no update frequency information for the ID information target stored with respect to the sender device s ID information. The update frequency setting refer to received from the communication device is the update frequency setting transmitted by the communication device in step S of . The update frequency settings received from the communication devices and are the update frequency settings transmitted from the communication devices and respectively in a step corresponding to step S of .

When the received data is not the update frequency setting e.g. NO in step S the CPU judges whether the received data is video data e.g. step S . When the received data is not video data e.g. NO in step S the routine proceeds to step S of . When the received data is video data e.g. YES in step S the CPU obtains the ID information and the image type information which are assigned to the video data e.g. step S . The video data received from the communication device is the video data transmitted from the communication device in step S of . The video data of the communication devices and received from the communication devices and are the video data transmitted from the communication devices and respectively in a step corresponding to step S of . The CPU stores the obtained ID information and compressed image information in the RAM .

The CPU judges whether the compressed image included in the video data is I frame e.g. step S . This judgment is made based on the image type information obtained in step S. When the CPU judges that the compressed image is I frame e.g. YES in step S the CPU obtains bandwidth provided for the sender device of the video data e.g. step S . The bandwidth is calculated by dividing a total data amount of all compressed image data received between after last time reception of I frame and before this time reception of I frame in one communication device by a time elapsed between after last time reception of I frame and before this time reception of I frame.

In order to calculate the bandwidth the CPU obtains the total data amount and the elapsed time. The total data amount is obtained for example as described below. Once the CPU obtains an I frame from a predetermined communication device every time the CPU obtains a compressed image from the predetermined communication device the CPU adds an amount of data of the received compressed image. The adding of the amount of data is continued until the CPU receives another I frame from the predetermined communication device. When the CPU newly receives an I frame from the predetermined communication device the CPU adds the amount of data of the newly received I frame to an accumulated value to obtain the total data amount. The CPU resets the accumulated value as the CPU obtains the total data amount. Subsequent to resetting the accumulated value the CPU starts adding a data mount of a received compressed image. The elapsed time is obtained based on a difference between a timing at which the CPU receives an I frame last time and a timing at which the CPU receives another I frame this time in accordance with the storing executed in step S. The CPU stores the bandwidth obtained in step S in the RAM with being associated with the ID information obtained in step S.

When the CPU judges that the compressed image is not I frame e.g. NO in step S or subsequent to step S the CPU judges whether steps S to S have already been executed for all the communication devices that are connected to the particular conference room other than the communication device identified by the ID information obtained in step S of e.g. step S . Steps S to S are a series of processing for transmitting video data selectively. The CPU judges for example whether the received video data refer to YES in step S of is video data to be transmitted for each destination device on communication device basis. When the CPU judges the received video data is video data to be transmitted for each destination device the CPU transmits the video data to one or more destination devices. Steps S to S are executed for all the communication devices that are connected to the particular conference room other than the communication device identified by the ID information that has been obtained in step S of . When the CPU judges that there is no communication device on which steps S to S have not been executed yet i.e. steps S to S have already been executed for all the communication devices e.g. YES in step S the routine returns to step S of and the CPU executes processing of step S and subsequent steps. When the CPU judges that there is one or more communication devices on which steps S to S have not been executed yet i.e. steps S to S have not been executed for all the communication devices e.g. NO in step S the CPU selects one of the one or more communication devices as a target to be processed e.g. step S . For example it is assumed that the received video data is video data transmitted from the communication device i.e. the CPU has obtained the ID information of the communication device in step S of . When steps S to S have not yet been executed for the communication devices and although steps S to S have already been executed for the communication devices and one of the communication devices and e.g. the communication device is selected as a target to be processed.

Subsequently the CPU executes a transfer determining processing e.g. step S . A detail of the transfer determining processing will be described later. Subsequent to the transfer determining processing the CPU judges whether the determination result stored in the RAM indicates that it is necessary to transfer the received video data hereinafter referred to as transfer necessary e.g. step S . When the CPU judges that the determination result indicates transfer necessary e.g. YES in step S the CPU controls transmission of the received video data e.g. step S . The communication device that is a target to be processed is determined as the destination of the video data. Subsequently the CPU stores the ID information of the sender device that has transmitted the video data the ID information of the destination device a transmission time and the image type information for the transmission in step S e.g. step S . The sender device s ID information the destination device s ID information the transmission time and the image type information are stored in a transmission table not depicted stored in the RAM for example.

Details of steps S and S will be described below assuming that the received video data is video data transmitted from the communication device the ID information of the communication device is obtained in step S of and the communication device is selected as a target to be processed in step S. In step S the CPU determines the communication device as a destination of the video data and outputs to the communication unit an instruction to transmit the video data received from the communication device . Thus the video data received from the communication device is transmitted to the communication device from the communication unit . In step S the CPU stores the ID information of the communication device the ID information of the communication device a transmission time and the image type information in the transmission table stored in the RAM .

When the CPU judges that the determination result indicates it is unnecessary to transfer the received video data hereinafter referred to as transfer unnecessary e.g. NO in step S or subsequent to step S the routine returns to step S and the CPU executes step S and subsequent steps.

In step S the CPU judges whether the received data is audio data. When the CPU judges that the received data is not audio data e.g. step NO in S the CPU executes processing appropriate for the received data. Subsequently the routine returns to step S of and the CPU executes step S and subsequent steps.

When the CPU judges that the received data is audio data e.g. YES in step S the CPU controls transmission of the audio data e.g. step S . The audio data transmitted from the communication device is the audio data transmitted by the communication device in step S of . The audio data transmitted from each of the communication devices and is the audio data transmitted by each of the communication devices and in a step corresponding to step S of . All of the one or more communication devices identified by the respective ID information other than the ID information of the communication device assigned to the audio data are determined as a destination of the audio data. For example it is assumed that the received data is audio data transmitted from the communication device . In this case the CPU determines the communication devices and identified by the respective ID information that are different from the ID information of the communication device assigned to the audio data as a destination of the video data. Subsequently the CPU outputs to the communication unit an instruction to transmit the audio data received from the communication device . Thus the audio data received from the communication device is transmitted to each of the communication devices and from the communication unit . Subsequent to step S the routine returns to step S of and the CPU executes step S and subsequent steps.

The transfer determining processing executed in step S refer to of the transferring processing in will be described referring to . In the description for the transfer determining processing and update frequency correcting processing refer to the video data that contributes to the positive judgment in step S of e.g. YES in step S is referred to as new video data .

Subsequent to starting the transfer determining processing the CPU executes the update frequency correcting processing e.g. step S . A detail of the update frequency correcting processing will be described later. The CPU obtains the update frequency information for ID information target which is associated to the ID information sender in the update frequency setting refer to e.g. step S .

The CPU judges whether the update frequency information obtained in step S indicates that the compressed image in the new video data is determined as a non target for transmission e.g. step S . The type of the compressed image in the new video data is identified based on the image type information obtained in step S of . When the CPU judges that the update frequency information indicates that the compressed image in the new video data is not determined as a non target for transmission e.g. NO in step S the CPU judges whether a value representing a time period elapsed between a timing of the last time transmission of an I frame and a timing of execution of step S i.e. the current time is greater than a value representing the minimum I frame transmission interval specified in the update frequency information obtained in step S e.g. step S .

For example step S is executed as described below. The CPU identifies the transmission time of the last time transmission of an I frame from the transmission table stored in the RAM in which various information has been stored in step S of . The ID information obtained in step S of as the ID information of the sender device of the video data and the ID information of the communication device selected in step S of as the ID information of the destination of the video data are associated with the last I frame of which transmission time has been identified. The CPU obtains the current time from the timer . In the identification of the transmission time of the last time transmission of the I frame the type of the compressed image is determined based on the image type information stored in the transmission table. The CPU obtains an elapsed time based on the last transmission time and the current time to determine the relationship between the elapsed time and the minimum I frame transmission interval. When the CPU judges that the value representing the elapsed time is greater than the value representing the minimum I frame transmission interval the CPU makes a positive judgment in step S e.g. YES in step S . When the value representing the elapsed time is smaller than or equal to the value representing the minimum I frame transmission interval the CPU makes a negative judgment in step S e.g. NO in step S . In other embodiments for example when the value representing the elapsed time is equal to the value representing the minimum I frame transmission interval the CPU may make a positive judgment in step S e.g. YES in step S .

When the CPU makes a positive judgment in step S e.g. YES in step S the CPU stores a determination result indicating transfer necessary in the RAM e.g. step S . When the compressed image in the new video data is a compressed image type that does not relate to the minimum I frame transmission interval the CPU makes a positive judgment in step S e.g. YES in step S and the CPU stores a determination result indicating transfer necessary in the RAM in step S. In the illustrative embodiment the minimum interval is the minimum I frame transmission interval. Therefore the compressed image type that does not relate to the minimum I frame transmission interval may be a P frame or a B frame. When the CPU makes a positive judgment in step S e.g. YES in step S or when the CPU makes a negative judgment in step S e.g. NO in step S the CPU stores a determination result indicating transfer unnecessary in the RAM e.g. step S .

Steps S to S will be described assuming that the new video data is video data received from the communication device the ID information of the communication device is obtained in step S of and the communication device is selected as a target to be processed in step S of . In the update frequency setting associated with the ID information of the communication device the update frequency information for the ID information of each of the communication devices and is as shown in . In step S the CPU obtains the update frequency information for the ID information associated with the ID information of the communication device sender based on the update frequency setting stored in the RAM . According to the update frequency setting depicted in in this case the CPU obtains the update frequency level 3 .

When the CPU judges that the compressed image in the new video data is I frame the CPU makes a negative judgment in step S e.g. NO in step S . When 300 msec. has elapsed from the transmission time of the last time transmission of an I frame e.g. YES in step S the CPU stores a determination result indicating transfer necessary in the RAM e.g. step S . When 300 msec. has not yet elapsed from the transmission time of the last time transmission of an I frame e.g. NO in step S the CPU stores a determination result indicating transfer unnecessary in the RAM e.g. step S . When the compressed image in the new video data is one of P frame and B frame the CPU makes a positive judgment in step S e.g. YES in step S and stores a determination result indicating transfer unnecessary in the RAM e.g. step S .

Subsequent to step S or S the CPU ends the transfer determining processing and the routine returns to step S of .

The update frequency correcting processing executed in step S of the transfer determining processing in will be described referring to . Subsequent to starting the update frequency correcting processing the CPU judges whether the bandwidth obtained in step S of is greater than or equal to a threshold value e.g. step S . For example the threshold value may be 1 Mbps. The threshold value is stored in the storage device with being associated with the programs for executing the update frequency determining processing. When the CPU judges that the bandwidth is greater than or equal to the threshold value e.g. YES in step S the CPU raises by one level the update frequency level designated for the update frequency information e.g. step S . The update frequency information whose level is to be raised is the update frequency information for the ID information target stored in step S of associated with the ID information sender of the communication device selected in step S of in the update frequency setting refer to .

For example it is assumed that the new video data is video data received from the communication device the ID information of the communication device is obtained in step S of and the communication device is selected as a target to be processed in step S of . Example update frequency information for the ID information of each of the communication devices and associated with the ID information of the communication device in the update frequency setting is as shown in . The CPU raises the update frequency level 1 designated for the target ID information associated with the ID information 30 of the communication device by one level to update the update frequency level to level 2 .

When the CPU judges that the bandwidth is smaller than the threshold value e.g. NO in step S or subsequent to step S the CPU ends the update frequency correcting processing and the routine returns to step S of . When the update frequency information of which level is a target to be raised in step S indicates the update frequency level 5 the CPU makes a positive judgment in step S e.g. YES in step S and then the routine skips step S and returns to step S of .

 1 In the communication device it is judged whether the ID information of the communication device which is a target for the update frequency determining processing is associated with a particular area determined as an area of the video layout region A positioned within the display area of the video display region B in step S of refer to step S in . When a positive judgment is made in step S the update frequency information is designated as the highest update frequency level 5 refer to step S . When a negative judgment is made in step S the update frequency information is designated as one of the update frequency levels 1 2 3 and 4 which are lower levels than the update frequency level 5 refer to step S S S or S . In the update frequency transmitting processing depicted in the update frequency setting refer to including the update frequency information designated to the respective communication devices and is transmitted to the server refer to step S in .

In the server a determination is made based on the update frequency setting refer to refer to step S or S in . One of the determination result indicating transfer necessary and the determination result indicating transfer unnecessary is stored refer to step S or step S . In the server when the determination result indicates transfer necessary e.g. YES in step S in video data is transmitted to the communication device determined as a target to be processed in step S of refer to step S in . When the determination result indicates transfer unnecessary e.g. NO in step S in transmission of video data is not performed e.g. NO in step S in .

Therefore this configuration may enable to determine compressed images of particular types as a non target for transmission in video data corresponding to a captured image that is not displayed within the video display region B of the display of the communication device . That is this configuration may disable the server to transmit to the communication device video data including the compressed images determined as a non target for transmission.

When the update frequency information indicating one of the update frequency levels 2 3 and 4 is designated to a hidden captured image in the communication device refer to NO in step S in refer to step S step S or step S in video data which corresponds to the hidden captured image and includes at least I frames is transmitted from the server to the communication device refer to NO in step S in and step S YES in step S in and step S . When a positive judgment is made in at least one of steps S S and S of the update frequency determining processing the update frequency information is designated as one of the update frequency levels 2 3 and 4 . Therefore for example when a swiping operation is performed in order to display a hidden captured image the video data including the compressed image that is a target for transmission is obtained refer to YES in step S in and thus the captured image that includes the compressed image and corresponds to the video data may be displayed in the communication device refer to step S in . Therefore this configuration may enable to display a hidden captured image smoothly while restricting increase of the amount of video data to be communicated.

 2 It is judged that whether a particular area of the video layout region A associated with the ID information of the communication device targeted for processing is positioned within an area corresponding to the reference distance WC refer to with reference to the reference edge in the direction opposite to the moving direction refer to step S in . When the particular area of the video layout region A associated with the ID information of the communication device targeted for processing is positioned within the area corresponding to the reference distance WC with reference to the reference edge refer to YES in step S the update frequency level designated for the update frequency information is raised by one level refer to step S . Therefore the update frequency level designated for the update frequency information for video data corresponding to the captured image that is not displayed within the video display region B with reference to the reference distance WC may be raised from the update frequency level 1 to the update frequency level 2 . Since the update frequency information is designated as the update frequency level 2 an I frame is determined as a target for transmission. Therefore when the hidden captured image is displayed the captured image may be displayed owing to receipt of I frames. In the illustrative embodiment both the moving direction and the direction opposite to the moving direction may be referred to as a direction corresponding to the moving direction. The direction corresponding to the moving direction may be for example the horizontal direction refer to .

 3 It is judged whether the ratio of the total video play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is greater than or equal to the first reference value refer to step S in . When the ratio is greater than or equal to the first reference value e.g. YES in step S the update frequency level designated for the update frequency information is raised by one level refer to step S . Therefore the update frequency information for video data corresponding to the captured image that is not displayed within the video display region B may be changed appropriate to the total video play time. For example when step S has not been executed the update frequency level designated for the update frequency information is changed from the update frequency level 1 to the update frequency level 2 . When step S has already been executed the update frequency level designated for the update frequency information is changed from the update frequency level 2 to the update frequency level 3 . At the update frequency level 2 or 3 an I frame determined as a target for transmission may enable the captured image to be displayed. Raising the update frequency level designated for the update frequency information from the update frequency level 2 to the update frequency level 3 may enable to shorten the minimum I frame transmission interval e.g. 1700 msec. shortened whereby the image switching interval of the captured image in display duration of one frame may be shortened. Thus reproduction quality may be increased.

 4 It is judged whether the ratio of the total audio play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is greater than or equal to the second reference value refer to step S in . When the ratio is greater than or equal to the second reference value e.g. YES in step S the update frequency level designated for the update frequency information is raised by one level refer to step S . Therefore the update frequency information for video data corresponding to the captured image that is not displayed within the video display region B may be changed appropriate to the total video play time. For example when both steps S and S have not been executed the update frequency level designated for the update frequency information is changed from the update frequency level 1 to the update frequency level 2 . When one of step S and step S has been executed the update frequency level designated for the update frequency information is changed from the update frequency level 2 to the update frequency level 3 . When both steps S and S have been executed the update frequency level designated for the update frequency information is changed from the update frequency level 3 to the update frequency level 4 . At the update frequency level 2 or 3 an I frame determined as a target for transmission may enable the captured image to be displayed. At the update frequency level 4 a P frame is also determined as a target for transmission. Therefore a P frame as well as an I frame may enable the captured image to be displayed. Raising the update frequency level designated for the update frequency information from the update frequency level 3 to the update frequency level 4 may enable to shorten the minimum I frame transmission interval e.g. 300 msec. shortened and to obtain P frames whereby the image switching interval of the captured image in display duration of one frame may be shortened. Thus reproduction quality may be further increased. The effects obtained due to the raising of the update frequency information from the update frequency level 2 to the update frequency level 3 are as described above.

One or more aspects of the disclosure according to the illustrative embodiment may be modified as described below. One or more aspects of the disclosure according to various modifications may be combined appropriately. Other embodiments that adopt one or more aspects described below may provide the same effects as the effects provided by the above described embodiment.

 1 In the above described illustrative embodiment the video layout region A is defined by the layout setting that defines that the areas A A A A and A are arranged along the horizontal direction and the captured images and are positioned in the areas A A A A and A respectively refer to . In other embodiments for example the layout setting may define the video layout area such that the areas A A A A and A are arranged along the vertical direction and the captured images and are positioned in the areas A A A A and A respectively arranged along the vertical direction. In this case elements corresponding to the widths WA and WB the reference distance WC and the distance WD with reference to the horizontal direction may be defined with reference to the vertical direction. The moving direction may include an upward direction and downward direction in the vertical direction. According to the drawing depicted in the vertical direction is a direction perpendicular to the horizontal direction indicated by a bi directional arrow.

 2 In the above described illustrative embodiment for the arrangement of the captured images and in accordance with the layout setting the areas A A A A and A are defined in the video layout region A refer to . In other embodiments for example the areas in which the captured images and are positioned respectively in the video layout region A may be identified using a coordinate system refer to . In this case a particular area of the video layout region A displayed within the video display region B may also be identified using the coordinate system. For example as depicted in whether or not a particular captured image corresponding to an ID information is displayed within the video display region B may be identified using an indication for example Image Displayed Yes No .

In values of X and Y indicate coordinates of a reference position in each area in which a corresponding one of the captured images and is positioned. For example the values of X and Y indicate coordinates of the position of a point corresponding to an upper left corner of the area in which a corresponding one of the captured images and is positioned. The width and height indicate a dimension in the lateral direction and a dimension in the longitudinal direction of the area in which a corresponding one of the captured images and is positioned. In the above described embodiment the areas A A A A and A i.e. the captured images and are elongated in the vertical direction refer to . In an example depicted in in contrast to the above described embodiment the areas in which the captured images are arranged respectively i.e. the captured images may be elongated in the horizontal direction.

The X 10 Y 30 width 160 and length 100 for the ID information of corresponds to the area A of . The X 180 Y 30 width 160 and height 100 for the ID information of corresponds to the area A of . The X 10 Y 30 width 350 and height 100 for the ID information of corresponds to the area A of . The X 520 Y 30 width 160 and height 100 for the ID information of corresponds to the area A of . The X 690 Y 30 width 160 and height 100 for the ID information of corresponds to the area A of .

 3 In the above described illustrative embodiment when a negative judgment is made in step S of the update frequency information is designated as the update frequency level 1 in step S. When a negative judgment is made in each of steps S S and S the update frequency level designated for the update frequency information is raised by one level. In other embodiments for example the update frequency information may be updated using scores. In this case for example the update frequency information and a score are associated with each other such that 0 points indicates the update frequency level 1 20 points indicates the update frequency level 2 40 points indicates the update frequency level 3 60 points indicates the update frequency level 4 and 80 points indicates the update frequency level 5 . The update frequency information may be designated in accordance with the score. For example when a negative judgment is made in step S in step S the score is set to 0 points and this score is stored in the RAM . When a positive judgment is made in step S in step S the CPU adds 20 points to the score. In this case the score of 20 points is stored in the RAM . When a positive judgment is made in step S in step S the CPU adds 20 points to the store stored in the RAM . When a positive judgment is made in step S in step S the CPU adds 20 points to the score stored in the RAM . Subsequently the CPU designates the update frequency information in accordance with the final score stored in the RAM . For example when the final score stored in the RAM is 60 points the CPU designates the update frequency information as the update frequency level 4 and determines the update frequency information as the update frequency level 4 in step S of .

In step S when the ratio of the total video play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is equal to the first reference value a positive judgment is made. In other embodiments for example in step S a judgment may be made based on whether the ratio of the total video play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is greater than the first reference value. In other words when the ratio is equal to the first reference value a negative judgment may be made in step S.

In step S when the ratio of the total audio play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is equal to the second reference value a positive judgment is made. In other embodiments for example in step S a judgment may be made based on whether the ratio of the total audio play time associated with the ID information of the communication device targeted for processing to the duration of the ongoing remote conference is greater than the second reference value. In other words when the ratio is equal to the second reference value a negative judgment may be made in step S.

The order in which judgments in steps S S and S are performed may be changed. In other embodiments for example the judgment performed in accordance with the condition of step S may be performed at the timing of step S executed in the above described illustrative embodiment. The judgment performed in accordance with the condition of step S may be performed at the timing of step S executed in the above described illustrative embodiment. The judgment performed in accordance with the condition of step S may be performed at the timing of step S executed in the above described illustrative embodiment.

 4 In the above described illustrative embodiment in step S of the audio data transmitting processing depicted in when the value representing the volume of the audio obtained in step S is equal to the threshold value a negative judgment is made. In other embodiments for example in step S a judgment may be made based on whether the value representing the volume of the audio obtained in step S is greater than or equal to the threshold value. In this case when the value representing the volume is equal to the threshold value a positive judgment may be made e.g. YES in step S .

 5 In the above described illustrative embodiment in step S refer to the bandwidth is obtained based on the interval of obtaining an I frame. In other embodiments for example the bandwidth may be obtained for example on a group of pictures GOP structure basis. In the above described illustrative embodiment the description has been made in the case where the bandwidth of video data is used. In other embodiments for example instead of or in addition to video data a bandwidth of other data communicated in the remote conference system e.g. audio data common material data or control data may be used.

 6 In the above described illustrative embodiment a judgment is made in step S of based on whether the update frequency information obtained in step S indicates the compressed image included in the new video data is determined as a non target for transmission. In other embodiments for example in step S a judgment may be made based on whether the update frequency information obtained in step S indicates the compressed image included in the new video data is determined as a target for transmission. In this case when the compressed image is determined as a target for transmission the CPU may make a positive judgment and the routine may proceed to step S. When the compressed image is determined as a non target for transmission the CPU may make a negative judgment and the routine proceed to step S.

 7 In the above described illustrative embodiment in step S of when the value representing the bandwidth obtained in step S of is equal to the threshold value a positive judgment is made. In other embodiments for example in step S a judgment may be made based on whether the value representing the bandwidth obtained in step S of is greater than the threshold value. In other words when the value representing the bandwidth is equal to the threshold value a negative judgment may be made in step S.

 8 In the above described illustrative embodiment the server transmits video data to each appropriate destination device. The sender device of the video data reproduces video from video data obtained therein and displays thereon a captured image of itself generated through the reproduction. In other embodiments for example the server may be configured to transmit the video data to the sender device. In this case the sender device may be configured to display a captured image corresponding to the received video data based on the own video data transmitted from the server . For example in the communication device the CPU may be configured to execute the update frequency determining processing for the device itself in step S of the update frequency transmitting processing depicted in as described above and determine the update frequency information for own device. The update frequency setting refer to transmitted in step S of includes the update frequency information associated with own ID information. In the server the CPU may be configured to determine the sender device that has transmitted the video data as a device targeted for processing in step S refer to and execute steps S to S for the sender device as described above.

 9 According to the above described illustrative embodiments in the remote conference system video data and audio data transmitted from the communication device are transmitted to each of the communication devices and via the server using the streaming method. Nevertheless in other embodiments for example video data and audio data transmitted from the communication device may be transmitted directly to each of the communication devices and by bypassing the server . In other words a remote conference system using a peer to peer P2P technology may be within the scope of the disclosure.

In a case where a remote conference system uses the P2P technology the CPU of the communication device may transmit the update frequency setting and own ID information via the communication unit in step S refer to . The update frequency setting and the ID information of the communication device may be associated with the ID information of each of the communication devices and which may be destination devices. In other words the update frequency setting and the ID information of the communication device may be transmitted directly to each of the communication devices and associated with the update frequency setting and the ID information of the communication device by bypassing the server . In each of the communication devices that receive the update frequency setting directly may be configured to execute processing corresponding to the transferring processing depicted in the transfer determining processing depicted in and the update frequency correcting processing depicted in instead of the server .

