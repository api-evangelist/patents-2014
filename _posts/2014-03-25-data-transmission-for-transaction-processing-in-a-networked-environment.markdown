---

title: Data transmission for transaction processing in a networked environment
abstract: Techniques are disclosed to transmit arbitrarily large data units for transaction processing in a networked environment. A request is received to store a data unit of a size exceeding an allocated memory address space of a transaction gateway component of the networked environment. A predefined store function, provided by a repository interface component, is invoked to store the data unit to a data repository component of the networked environment and without segmenting the data unit. A repository handle of the stored data unit is identified. A predefined load function, provided by the repository interface component, is invoked to load a portion of the stored data unit, based on the identified repository handle, where the portion is smaller than the stored data unit.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09473565&OS=09473565&RS=09473565
owner: INTERNATIONAL BUSINESS MACHINES CORPORATION
number: 09473565
owner_city: Armonk
owner_country: US
publication_date: 20140325
---
This application is a continuation of co pending U.S. patent application Ser. No. 13 841 665 filed Mar. 15 2013. The aforementioned related patent application is herein incorporated by reference in its entirety.

Embodiments disclosed herein relate to data transmission. More specifically embodiments disclosed herein relate to data transmission for transaction processing in a networked environment.

In computing transaction processing is a type of information handling in which operations are divided into individual indivisible units of work called transactions. Each transaction must succeed or fail as a complete unit and cannot remain in an intermediate state. Transaction processing is designed to maintain a computer system such as a database in a consistent state which is characterized by a notion that any interdependent operations in the system either all complete successfully or all cancel successfully. For example a typical banking transaction that involves moving money from a customer savings account to a customer bank account is a single transaction to the bank even though at least two separate operations are involved from a computing perspective. These operations include debiting of the savings account and crediting of the bank account. From this example the operations in the transaction must either both succeed or both fail to prevent an inconsistency in the bank database. Transaction processing allows multiple individual operations to be linked together automatically as a single indivisible transaction. The transaction processing system ensures that either all operations in a transaction are completed without error or that none of them are completed. If some of the operations are completed but errors occur when the others are attempted the transaction processing system rolls back all of the operations of the transaction including the successful ones thereby erasing all traces of the transaction and restoring the system to a previous consistent state. If all operations of a transaction are completed successfully the transaction is committed by the system and all changes to the database are made permanent.

Embodiments presented in this disclosure provide a computer implemented method to transmit arbitrarily large data units for transaction processing in a networked environment. The computer implemented method includes receiving a first request to store a first data unit of a size exceeding an allocated memory address space of a transaction gateway component of the networked environment. The computer implemented method also includes invoking a first predefined store function provided by a repository interface component to store the first data unit to a data repository component of the networked environment and without segmenting the first data unit. The computer implemented method also includes identifying a repository handle of the stored data unit. The computer implemented method also includes invoking a first predefined load function provided by the repository interface component to load a portion of the stored data unit based on the identified repository handle where the portion is smaller than the stored data unit.

Other embodiments presented in this disclosure provide a computer program product to transmit arbitrarily large data units for transaction processing in a networked environment. The computer program product includes a computer readable storage medium having program code embodied therewith. The program code is executable by one or more computer processors to receive a first request to store a first data unit of a size exceeding an allocated memory address space of a transaction gateway component of the networked environment. The program code is also executable to invoke a first predefined store function provided by a repository interface component to store the first data unit to a data repository component of the networked environment and without segmenting the first data unit. The program code is also executable to invoke a first predefined load function provided by the repository interface component to load a portion of the stored data unit based on the identified repository handle where the portion is smaller than the stored data unit.

Still other embodiments presented in this disclosure provide a system to transmit arbitrarily large data units for transaction processing in a networked environment. The system includes one or more computer processors and a memory containing a program which when executed by the one or more computer processors is configured to perform an operation that includes receiving a first request to store a first data unit of a size exceeding an allocated memory address space of a transaction gateway component of the networked environment. The operation also includes invoking a first predefined store function provided by a repository interface component to store the first data unit to a data repository component of the networked environment and without segmenting the first data unit. The operation also includes identifying a repository handle of the stored data unit. The operation also includes invoking a first predefined load function provided by the repository interface component to load a portion of the stored data unit based on the identified repository handle where the portion is smaller than the stored data unit.

Embodiments presented in this disclosure provide techniques to manage arbitrarily large data in transaction processing in a networked environment. Depending on the embodiment the arbitrarily large data may be in the form of a data unit which refers to any unit of data that may be transmitted according to the techniques disclosed herein. A data unit is also referred to herein as a data structure. Depending on the embodiment the data unit may contain a request itself or only the data accompanying a request. The data unit may include structured data or unstructured data. Further depending on the embodiment different types of transactions may be supported by the networked environment. One example of the networked environment is an enterprise information system EIS . In one embodiment an EIS provides a technology platform that allows organizations to integrate and coordinate business processes thereof. In some embodiments an EIS provides a unified system that is central to a given organization and that facilitates sharing of information across different functional levels and management hierarchies of the given organization. At least in some embodiments an EIS standardizes data for an organization thereby reducing an extent of information fragmentation resulting from having multiple information systems within the organization. Further an EIS may support provider type transactions where a distributed application e.g. a distributed client sends a request to the EIS and optionally receives a response from the EIS. Additionally or alternatively an EIS may support consumer type transactions where the EIS acts as a client that sends out a request to a distributed application e.g. a distributed server and optionally receives a response from the distributed application.

In some cases there may also be usage constraints associated with a given EIS. The usage constraints may relate to processing provider type and consumer type transactions involving data structures of a size beyond a predefined threshold size. Examples of data structures include messages file attachments etc. Data structures beyond the predefined threshold size such as X ray data magnetic resonance imaging MRI data medical records fingerprint data pictures in support of insurance claims video data etc. which may often even number in the zettabytes ZB may be too costly to transfer from distributed applications to the EIS and vice versa via predetermined communication protocols examples of which include Transmission Control Protocol Internet Protocol TCP IP IBM Cross System Coupling Facility XCF etc. For instance a given EIS may not necessarily support transaction processing for requests involving arbitrarily large data structures also referred to herein as large data . Further a given EIS may not necessarily support transaction processing involving arbitrarily large data structures for requests not pertaining to web services. Further still a given EIS may not necessarily provide any mechanism to retrieve merely a portion of the data structure for processing rather than the entire data structure.

By configuring a networked environment such as an EIS using the techniques disclosed herein the networked environment may support transaction processing for requests involving arbitrarily large data structures. In some embodiments the networked environment is configured to include an application programming interface API providing predefined load and store functions for transferring arbitrarily large data structures to and from a data repository also referred to herein as a repository. Doing so allows the networked environment to process transactions using repository handles to the data structures stored in the data repository where the repository handles may be forwarded among components within the networked environment thereby eliminating any need to forward the actual data structures within the networked environment.

In some embodiments the API further provides a second load function configured to load only a specified portion of a desired data structure stored in the data repository. The second load function may also be referred to herein as a predefined scan function. Loading only a specified portion of a desired data structure may ease memory constraints associated with transaction processing at least in some cases. Additionally or alternatively the API may provide a function configured to append data to a specified data structure stored in the data repository e.g. to support video streaming. The function is also referred to herein as a predefined append function. The API may also provide functions to clean up or remove a specified data structure from the data repository upon loading the specified data structure or via explicit calls to a predefined cleanup function also referred to herein as a destroy function. Such an API allows the networked environment to better support data integrity at least in some cases.

At least in some embodiments configuring a networked environment using the techniques disclosed herein may reduce network traffic by avoiding having to pass arbitrarily large data structures as a request or response is transmitted within the networked environment and via predetermined communication protocols. Input output I O load may also be reduced at least in some cases given that the data structures once stored are assigned repository handles that may then be forwarded within the networked environment where the repository handles are also referred to herein as handles. For instance the handles may be forwarded as part of control data associated with a request or a response. Further message queue processing may be reduced for provider type transactions at least in some cases.

At least in some embodiments predefined memory constraints for consumer type transactions may be overcome at least in some cases. One example of a predefined memory constraint is a two gigabyte 2 GB memory constraint for consumer type transactions for a given EIS. Further I O load may be further reduced in some cases due to portions of data structures being loaded only as needed. Further still the ability to consolidate data via the append function allows transactions to be processed more conveniently or efficiently at least in some cases. Depending on the embodiment other constraints may also be overcome such as Common Business Oriented Language COBOL and Programming Language One PL I compiler size constraints for EIS transactional applications or 31 bit memory constraints of a given EIS.

In some cases provider type transaction processing in a networked environment may require segmentation and message queue processing. In one embodiment segmentation and message queue processing involves dividing an arbitrarily large data structure into smaller segments of predefined size such as thirty two kilobytes 32 KB and subsequently assembling multiple smaller segments together to form a response to a request. On the other hand by configuring a networked environment using the techniques disclosed herein the networked environment may support provider type transaction processing without segmentation and without message queue processing at least in some cases.

Further in some cases consumer type transaction processing in a networked environment may require storing a message in a predefined memory area within the networked environment also referred to herein as control region memory. In one embodiment the control region memory refers to an allocated memory address space of a transaction gateway component of the networked environment. The control region memory may often have an associated size constraint pertaining to messages and data structures e.g. a constraint of two gigabytes 2 GB per address space where a message refers to a request or a response. Hence an arbitrarily large data structure exceeding the size constraint may require processing multiple requests and responses and further require the EIS and the distributed application to include predefined logic configured to generate or manage the multiple requests and responses. On the other hand by configuring a networked environment using the techniques disclosed herein the size constraint of control region memory may be overcome at least in some cases and the processing of multiple requests and responses may be avoided or simplified at least in some cases. In other embodiments even arbitrarily large data structures not exceeding the size constraint may be processed using the techniques disclosed herein to improve efficiency of transaction processing at least in some cases.

At least in some embodiments such networked environments may also better provide to external applications an abstraction creating an appearance that data units are not segmented within the networked environment regardless of whether the data units are actually segmented within the networked environment. Any segmenting of the data units is nevertheless performed in a manner transparent to the external applications. Accordingly from the perspective of the external applications the data units remain intact within the networked environment regardless of the size of the data units.

In one embodiment the API to load or store the data structure to or from the data repository may be provided by the repository interface component . As described above the API may provide various functions such as a function to load only a portion of the stored data structure . The repository interface component also provides a handle for the data structure to the transaction gateway component or to the transaction manager component . Accordingly the enterprise system may more efficiently process transactions involving arbitrarily large data structures at least in some cases. Further in some alternative embodiments the external application directly accesses the API provided by the repository interface component . In such embodiments the external application may load and store arbitrarily large data structures via the API and send and receive requests with handles to and from the transaction gateway component .

In one embodiment the transaction manager component is a message based transaction processor. In that case a transaction may include a message specifying a set of input data that triggers the execution of a desired application. The transaction may also include any results returned from executing the desired application. In one embodiment the transaction manager component may process input messages received from a variety of sources such as a terminal network other transaction managers and the Web. The transaction manager component may also process output messages created by application programs. Further the transaction manager component may provide an underlying queuing mechanism for handling these messages. Further still the transaction manager component may at least in some cases provide high volume high performance high capacity low cost transaction processing for various types of data sources such as hierarchical databases relational databases etc. In some embodiments the transaction manager is configured to interact with an end user or another application process a desired business function such as a bank account withdrawal and maintain state throughout such that the system properly records the business function to storage such as a database. The end user may be connected via Virtual Telecommunications Access Method VTAM TCP TP terminals such as IBM 3270 web interfaces etc. At least in some embodiments transaction processing is performed to maintain database integrity in a consistent state and by enforcing atomicity of transactions.

In the second approach the networked environment is configured with components and an API that allow the data structures to be processed separately from the rest of the networked environment. In one embodiment the transaction gateway component invokes a store function provided by the API to store the arbitrarily large data structure into the data repository where the data repository supports loading and storing of data structures. An example of a transaction gateway component is an enterprise gateway which may refer to a gateway that is on the same systems complex sysplex as the transaction manager component. Examples of the enterprise gateway include TCP IP gateways such as EIS transaction gateways and further include Hypertext Transfer Protocol HTTP gateways such as a Simple Object Access Protocol SOAP gateway for an EIS. Examples of the data repository include virtual storage access method VSAM data sets partitioned data set extended PDSE data sets databases and associated database management system DBMS etc.

Once stored the data structure under the second approach may be passed via a handle according to one embodiment. Accordingly the transaction gateway component obtains the handle of the stored data structure and passes the handle to other components of the networked environment as needed. The data structure may subsequently be loaded in the networked environment by invoking a load function provided by the API while passing the handle. If the response from the networked environment refers to a data structure the data structure may first be stored and subsequently loaded by the transaction gateway component of the networked environment. In embodiments where the transaction gateway component acts as a first entry point into the EIS having the transaction gateway component invoke load and store functions reduces network traffic within the EIS to a greater extent than having other components invoke the load and store functions.

At least in some embodiments the specific functions provided by the API may be tailored to suit the needs of a particular case. Table I provides a description of functions provided by the API according to one embodiment.

Storing an entire data structure in repository handle store pointer size properties Storing additional data to repository handle append pointer size handle properties Loading an entire data structure from repository bytes loadFull handle properties Loading a portion of a data structure bytes loadWindow handle index size properties Function to destroy and clean up a data structure status destroy handle properties 

In Table I pointer refers to a memory address to a desired data structure. Size refers to a desired size of data in bytes. Properties refers to repository access information a browse discard option and a retrieval option. In some embodiments the function to load an entire attachment provides an option to delete the data structure from the data repository upon loading the data structure. Handle refers to an object handle to a data structure stored in the data repository. Window size refers to a desired portion size of the data structure to load. Bytes is a variable containing the returned data. Status refers to information returned from invoking a function such as success failure information.

On the other hand upon receiving from the distributed client a request that specifies the data structure the transaction gateway component invokes a store function via the API library module to store the data structure into the data repository . Depending on the embodiment the store function is invoked for data structures of any size or alternatively only those data structures exceeding a specified minimum size. Further the transaction gateway component passes the request including a handle associated with the stored data structure to the transaction manager component thereby bypassing the message queue . In some embodiments the message queue is bypassed only for the data structure while the request itself is still divided into segments. Alternatively the message queue is bypassed for both the data structure and the request . The transaction manager component then processes the request loading the data structure from the data repository into memory via the API library module and by passing the handle.

At least in some embodiments the distributed client may directly access the API library module to load store send or receive arbitrarily large data structures to or from the transaction gateway component as represented by the request . Further still depending on the embodiment one or more of the API library modules may be the same type or of different types. Still further at least in some embodiments any requests beyond a threshold size may itself may be made into and or processed as a data structure according to the techniques disclosed herein. Because the message queue is bypassed for requests specifying data structures segmentation of the data structures is avoided thus improving transaction processing performance in some cases.

On the other hand when the enterprise system responds to the distributed client with a data structure or with a data structure exceeding the specified minimum size then the transaction manager component saves the data structure into the data repository by invoking a predefined store function provided by the API library module . The transaction manager component then sends a handle obtained from the data repository and pertaining to the stored data structure to the transaction gateway component . The transaction gateway component may then invoke a predefined load function provided by the API library module to load the data structure into memory. The transaction gateway component may then send to the distributed client a response with the loaded data structure . Further at least in some embodiments the distributed client may directly access the API library module to load store send or receive arbitrarily large data structures to or from the transaction gateway component as represented by the response . Because the message queue is bypassed for responses specifying data structures segmentation of the data structures is avoided thus improving transaction processing performance in some cases.

On the other hand when the enterprise system sends a request with the data structure then the transaction manager component saves the data structure into the data repository via the API library module and passes a handle to the transaction gateway component . The transaction gateway component may then load the data structure into memory via the API library module and by using the handle. At least in some embodiments the data structure is in part or in whole loaded into an area of memory other than control region memory and that is hence not subject to the size constraint. Further at least in some embodiments the distributed server may directly access the API library module to load store send or receive arbitrarily large data structures to or from the transaction gateway component as represented by the request . The transaction gateway component then sends the request and the loaded data structure to the distributed server . Doing so allows transactions to be processed even when the transactions involve data structures that exceed the size constraint of control region memory thereby effectively eliminating the size constraint for data structures. Accordingly the flexibility of transaction processing may be improved at least in some cases.

On the other hand when the distributed server responds to the enterprise system with the data structure the data structure is in part or in whole loaded into an area of memory other than control region memory and that is hence not subject to the size constraint. The transaction gateway component then saves the data structure into the data repository via the API library module . The transaction gateway component then sends a handle obtained from the data repository and pertaining to the stored data structure to the transaction manager component . The transaction manager component may then load the data structure into memory via the API library module and by using the handle. Further at least in some embodiments the distributed server may directly access the API library module to load store send or receive arbitrarily large data structures to or from the transaction gateway component as represented by the response .

In some embodiments the transaction manager component does not have any control region memory or any memory subject to the size constraint. In alternative embodiments the transaction manager component has an associated control region memory separate from the control region memory of the transaction gateway component . In such alternative embodiments the data structure is in part or in whole loaded into an area of memory of the transaction manager component other than control region memory. Accordingly transactions may be processed even when the transactions involve data structures that exceed the size constraint of the control region memory thereby effectively eliminating the size constraint for data structures. Consequently the flexibility of transaction processing may be improved at least in some cases.

Accordingly a total amount of the data structure that is transmitted between non repository components in the networked environment is reduced at least relative to transmitting the first data unit between non repository components in the networked environment without using the data repository component where the non repository components include the transaction gateway component and the transaction manager component of the networked environment. Stated differently the total amount of the first data unit that is transmitted between the transaction gateway component and the transaction manager component may be reduced at least relative to transmitting the first data unit between the transaction gateway component and the transaction manager component without using the data repository component. Accordingly invoking the first predefined load function based on the identified repository handle may cause the repository interface component to load the portion of the stored data unit to a transaction manager component of the networked environment. Doing so provides the transaction manager component with the portion of the first data unit without requiring the portion of the first data unit to be transmitted from the transaction gateway component to the transaction manager component. Consequently the amount of network traffic or impact on other network traffic associated with transmitting the data structure between the transaction gateway component and the transaction manager component may be reduced or eliminated if the transaction gateway component or the external application stores the data structure into the data repository component for subsequent retrieval by the transaction gateway component. The impact on other network traffic within the networked environment may be reduced especially in scenarios and networked environments where more bandwidth is available for storing and loading the data structure to and from the repository component than for transmitting the data structure between the transaction gateway component and the transaction manager component. Further by loading only a portion of the data structure when only the portion is desired to be retrieved the amount of network traffic or impact on other network traffic associated with transmitting the data structure within the networked environment may be further reduced at least in some cases because the remaining portion of the data structure that is not desired to be retrieved need not be retrieved or transmitted in the networked environment.

Embodiments disclosed herein provide techniques to manage arbitrarily large data structures for transaction processing in a networked environment. By configuring components of the networked environment to communicate with a repository interface component that provides predefined load and store functions based on repository handles instances of data structures being forwarded without the networked environment may be reduced thus improving transaction processing efficiency and flexibility at least in some cases.

The computer generally includes a processor connected via a bus to a memory a network interface device a storage an input device and an output device . The computer is generally under the control of an operating system. Examples of operating systems include IBM z OS UNIX versions of the Microsoft Windows operating system and distributions of the Linux operating system. More generally any operating system supporting the functions disclosed herein may be used. The processor is included to be representative of a single CPU multiple CPUs a single CPU having multiple processing cores and the like. Similarly the memory may be a random access memory. While the memory is shown as a single identity it should be understood that the memory may comprise a plurality of modules and that the memory may exist at multiple levels from high speed registers and caches to lower speed but larger DRAM chips. The network interface device may be any type of network communications device allowing the computer to communicate with other computers via the network .

The storage may be a persistent storage device. Although the storage is shown as a single unit the storage may be a combination of fixed and or removable storage devices such as fixed disc drives solid state drives floppy disc drives tape drives removable memory cards or optical storage. The memory and the storage may be part of one virtual address space spanning multiple primary and secondary storage devices.

The input device may be any device for providing input to the computer . For example a keyboard a mouse a touchpad voice commands or any combination thereof may be used. The output device may be any device for providing output to a user of the computer . For example the output device may be any display screen or set of speakers. Although shown separately from the input device the output device and input device may be combined. For example a display screen with an integrated touch screen may be used.

As shown the memory of the computer includes the repository interface component of the enterprise system of . The storage includes the data structure which may be arbitrarily large in size. As described above in one embodiment the repository interface component provides an API to load or store the data structure . Further depending on the embodiment one or more other components of the enterprise system described herein such as the transaction gateway component the transaction manager component the data repository and the message queue may execute on the computer or on one or more computers communicably connected to the computer via the network .

In the preceding reference is made to embodiments presented in this disclosure. However the scope of the present disclosure is not limited to specific described embodiments. Instead any combination of the following features and elements whether related to different embodiments or not is contemplated to implement and practice contemplated embodiments. Furthermore although embodiments disclosed herein may achieve advantages over other possible solutions or over the prior art whether or not a particular advantage is achieved by a given embodiment is not limiting of the scope of the present disclosure. Thus the preceding aspects features embodiments and advantages are merely illustrative and are not considered elements or limitations of the appended claims except where explicitly recited in a claim s . Likewise reference to the invention shall not be construed as a generalization of any inventive subject matter disclosed herein and shall not be considered to be an element or limitation of the appended claims except where explicitly recited in a claim s .

Aspects presented in this disclosure may be embodied as a system method or computer program product. Accordingly aspects disclosed herein may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects disclosed herein may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this disclosure a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects disclosed herein may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the computer of a user partly on the computer of the user as a stand alone software package partly on the computer of the user and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the computer of the user via any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects presented in this disclosure are described above with reference to flowchart illustrations or block diagrams of methods apparatus systems and computer program products according to embodiments disclosed herein. It will be understood that each block of the flowchart illustrations or block diagrams and combinations of blocks in the flowchart illustrations or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart or block diagram block or blocks.

Embodiments disclosed herein may be provided to end users through a cloud computing infrastructure. Cloud computing generally refers to the provision of scalable computing resources as a service over a network. More formally cloud computing may be defined as a computing capability that provides an abstraction between the computing resource and its underlying technical architecture e.g. servers storage networks enabling convenient on demand network access to a shared pool of configurable computing resources that can be rapidly provisioned and released with minimal management effort or service provider interaction. Thus cloud computing allows a user to access virtual computing resources e.g. storage data applications and even complete virtualized computing systems in the cloud without regard for the underlying physical systems or locations of those systems used to provide the computing resources.

Typically cloud computing resources are provided to a user on a pay per use basis where users are charged only for the computing resources actually used e.g. an amount of storage space consumed by a user or a number of virtualized systems instantiated by the user . A user can access any of the resources that reside in the cloud at any time and from anywhere across the Internet. In context of the present disclosure a user may access applications e.g. enterprise system or related data available in the cloud. For example the enterprise system could execute on one or more computing systems in the cloud and process transactions involving arbitrarily large data structures.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments disclosed herein. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . In some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. Each block of the block diagrams or flowchart illustration and combinations of blocks in the block diagrams or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

While the foregoing is directed to embodiments presented in this disclosure other and further embodiments may be devised without departing from the basic scope of contemplated embodiments and the scope thereof is determined by the claims that follow.

