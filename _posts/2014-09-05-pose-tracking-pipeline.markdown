---

title: Pose tracking pipeline
abstract: A method of tracking a subject includes receiving from a source a depth image of a scene including the subject. The depth image includes a depth for each of a plurality of pixels. The method further includes identifying pixels of the depth image that image the subject and deriving from the identified pixels of the depth image one or more machine readable data structures representing the subject as a model including a plurality of shapes.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09465980&OS=09465980&RS=09465980
owner: MICROSOFT TECHNOLOGY LICENSING, LLC
number: 09465980
owner_city: Redmond
owner_country: US
publication_date: 20140905
---
This application is a continuation of U.S. patent application Ser. No. 14 088 184 filed Nov. 22 2013 which is a continuation of U.S. patent application Ser. No. 13 871 974 filed Apr. 26 2013 now U.S. Pat. No. 8 610 665 which is a continuation of U.S. patent application Ser. No. 13 408 775 filed Feb. 29 2012 now U.S. Pat. No. 8 553 939 which is a continuation of U.S. patent application Ser. No. 12 603 437 filed Oct. 21 2009 now U.S. Pat. No. 8 295 546 which is a continuation in part of U.S. patent application Ser. No. 12 367 435 filed Feb. 6 2009 which claims priority to U.S. Provisional Patent Application No. 61 148 892 filed Jan. 30 2009. The above applications are hereby incorporated herein by reference in their entirety.

Many computer games and other computer vision applications utilize complicated controls to allow users to manipulate game characters or other aspects of an application. Such controls can be difficult to learn thus creating a barrier to entry for many games or other applications. Furthermore such controls may be very different from the actual game actions or other application actions for which they are used. For example a game control that causes a game character to swing a baseball bat may not at all resemble the actual motion of swinging a baseball bat.

This Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description. This Summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter. Furthermore the claimed subject matter is not limited to implementations that solve any or all disadvantages noted in any part of this disclosure.

A method of tracking a human subject is disclosed. The method includes receiving from a source a depth image of a scene including the subject. The depth image includes a depth for each of a plurality of pixels. The method further includes identifying pixels of the depth image that image the subject and deriving from the identified pixels of the depth image one or more machine readable data structures representing the subject as a model including a plurality of shapes.

The present disclosure is directed to target recognition analysis and tracking. In particular the use of a depth camera or other source for acquiring depth information for one or more targets is disclosed. Such depth information may then be used to efficiently and accurately model and track the one or more targets as described in detail below. The target recognition analysis and tracking described herein provides a robust platform in which one or more targets can be consistently tracked at a relatively fast frame rate even when the target s move into poses that have been considered difficult to analyze using other approaches e.g. when two or more targets partially overlap and or occlude one another when a portion of a target self occludes another portion of the same target when a target changes its topographical appearance e.g. a human touching his or her head etc. .

A target tracking system may be used to recognize analyze and or track one or more targets such as game player . shows a scenario in which game player is tracked using depth camera so that the movements of game player may be interpreted by gaming system as controls that can be used to affect the game being executed by gaming system . In other words game player may use his movements to control the game. The movements of game player may be interpreted as virtually any type of game control.

The example scenario illustrated in shows game player playing a boxing game that is being executed by gaming system . The gaming system uses HDTV to visually present a boxing opponent to game player . Furthermore the gaming system uses HDTV to visually present a player avatar that gaming player controls with his movements. As shown in game player can throw a punch in physical world space as an instruction for player avatar to throw a punch in game virtual space. Gaming system and depth camera can be used to recognize and analyze the punch of game player in physical space so that the punch can be interpreted as a game control that causes player avatar to throw a punch in game space. For example shows HDTV visually presenting player avatar throwing a punch that strikes boxing opponent responsive to game player throwing a punch in physical space.

Other movements by game player may be interpreted as other controls such as controls to bob weave shuffle block jab or throw a variety of different power punches. Furthermore some movements may be interpreted into controls that serve purposes other than controlling player avatar . For example the player may use movements to end pause or save a game select a level view high scores communicate with a friend etc.

In some embodiments a target may include a human and an object. In such embodiments for example a player of an electronic game may be holding an object such that the motions of the player and the object are utilized to adjust and or control parameters of the electronic game. For example the motion of a player holding a racket may be tracked and utilized for controlling an on screen racket in an electronic sports game. In another example the motion of a player holding an object may be tracked and utilized for controlling an on screen weapon in an electronic combat game.

Target tracking systems may be used to interpret target movements as operating system and or application controls that are outside the realm of gaming. Virtually any controllable aspect of an operating system and or application such as the boxing game shown in may be controlled by movements of a target such as game player . The illustrated boxing scenario is provided as an example but is not meant to be limiting in any way. To the contrary the illustrated scenario is intended to demonstrate a general concept which may be applied to a variety of different applications without departing from the scope of this disclosure.

The methods and processes described herein may be tied to a variety of different types of computing systems. show a nonlimiting example in the form of gaming system HDTV and depth camera . As another more general example schematically shows a computing system that may perform one or more of the target recognition tracking and analysis methods and processes described herein. Computing system may take a variety of different forms including but not limited to gaming consoles personal computing systems public computing systems human interactive robots military tracking and or targeting systems and character acquisition systems offering green screen or motion capture functionality among others.

Computing system may include a logic subsystem a data holding subsystem a display subsystem and or a capture device . The computing system may optionally include components not shown in and or some components shown in may be peripheral components that are not integrated into the computing system.

Logic subsystem may include one or more physical devices configured to execute one or more instructions. For example the logic subsystem may be configured to execute one or more instructions that are part of one or more programs routines objects components data structures or other logical constructs. Such instructions may be implemented to perform a task implement a data type transform the state of one or more devices or otherwise arrive at a desired result. The logic subsystem may include one or more processors that are configured to execute software instructions. Additionally or alternatively the logic subsystem may include one or more hardware or firmware logic machines configured to execute hardware or firmware instructions. The logic subsystem may optionally include individual components that are distributed throughout two or more devices which may be remotely located in some embodiments.

Data holding subsystem may include one or more physical devices configured to hold data and or instructions executable by the logic subsystem to implement the herein described methods and processes. When such methods and processes are implemented the state of data holding subsystem may be transformed e.g. to hold different data . Data holding subsystem may include removable media and or built in devices. Data holding subsystem may include optical memory devices semiconductor memory devices e.g. RAM EEPROM flash etc. and or magnetic memory devices among others. Data holding subsystem may include devices with one or more of the following characteristics volatile nonvolatile dynamic static read write read only random access sequential access location addressable file addressable and content addressable. In some embodiments logic subsystem and data holding subsystem may be integrated into one or more common devices such as an application specific integrated circuit or a system on a chip.

Display subsystem may be used to present a visual representation of data held by data holding subsystem . As the herein described methods and processes change the data held by the data holding subsystem and thus transform the state of the data holding subsystem the state of display subsystem may likewise be transformed to visually represent changes in the underlying data. As a nonlimiting example the target recognition tracking and analysis described herein may be reflected via display subsystem in the form of a game character that changes poses in game space responsive to the movements of a game player in physical space. Display subsystem may include one or more display devices utilizing virtually any type of technology. Such display devices may be combined with logic subsystem and or data holding subsystem in a shared enclosure or such display devices may be peripheral display devices as shown in .

Computing system further includes a capture device configured to obtain depth images of one or more targets. Capture device may be configured to capture video with depth information via any suitable technique e.g. time of flight structured light stereo image etc. . As such capture device may include a depth camera a video camera stereo cameras and or other suitable capture devices.

For example in time of flight analysis the capture device may emit infrared light to the target and may then use sensors to detect the backscattered light from the surface of the target. In some cases pulsed infrared light may be used wherein the time between an outgoing light pulse and a corresponding incoming light pulse may be measured and used to determine a physical distance from the capture device to a particular location on the target. In some cases the phase of the outgoing light wave may be compared to the phase of the incoming light wave to determine a phase shift and the phase shift may be used to determine a physical distance from the capture device to a particular location on the target.

In another example time of flight analysis may be used to indirectly determine a physical distance from the capture device to a particular location on the target by analyzing the intensity of the reflected beam of light over time via a technique such as shuttered light pulse imaging.

In another example structured light analysis may be utilized by capture device to capture depth information. In such an analysis patterned light i.e. light displayed as a known pattern such as grid pattern a stripe pattern a constellation of dots etc. may be projected onto the target. Upon striking the surface of the target the pattern may become deformed and this deformation of the pattern may be studied to determine a physical distance from the capture device to a particular location on the target.

In another example the capture device may include two or more physically separated cameras that view a target from different angles to obtain visual stereo data. In such cases the visual stereo data may be resolved to generate a depth image.

In other embodiments capture device may utilize other technologies to measure and or calculate depth values. Additionally capture device may organize the calculated depth information into Z layers i.e. layers perpendicular to a Z axis extending from the depth camera along its line of sight to the viewer.

In some embodiments two or more different cameras may be incorporated into an integrated capture device. For example a depth camera and a video camera e.g. RGB video camera may be incorporated into a common capture device. In some embodiments two or more separate capture devices may be cooperatively used. For example a depth camera and a separate video camera may be used. When a video camera is used it may be used to provide target tracking data confirmation data for error correction of target tracking image capture face recognition high precision tracking of fingers or other small features light sensing and or other functions.

It is to be understood that at least some target analysis and tracking operations may be executed by a logic machine of one or more capture devices. A capture device may include one or more onboard processing units configured to perform one or more target analysis and or tracking functions. A capture device may include firmware to facilitate updating such onboard processing logic.

Computing system may optionally include one or more input devices such as controller and controller . Input devices may be used to control operation of the computing system. In the context of a game input devices such as controller and or controller can be used to control aspects of a game not controlled via the target recognition tracking and analysis methods and procedures described herein. In some embodiments input devices such as controller and or controller may include one or more of accelerometers gyroscopes infrared target sensor systems etc. which may be used to measure movement of the controllers in physical space. In some embodiments the computing system may optionally include and or utilize input gloves keyboards mice track pads trackballs touch screens buttons switches dials and or other input devices. As will be appreciated target recognition tracking and analysis may be used to control or augment aspects of a game or other application conventionally controlled by an input device such as a game controller. In some embodiments the target tracking described herein can be used as a complete replacement to other forms of user input while in other embodiments such target tracking can be used to complement one or more other forms of user input.

Computing system may be configured to perform the target tracking methods described herein. However it should be understood that computing system is provided as a nonlimiting example of a device that may perform such target tracking. Other devices are within the scope of this disclosure.

Computing system or another suitable device may be configured to represent each target with a model. As described in more detail below information derived from such a model can be compared to information obtained from a capture device such as a depth camera so that the fundamental proportions or shape of the model as well as its current pose can be adjusted to more accurately represent the modeled target. The model may be represented by one or more polygonal meshes by a set of mathematical primitives and or via other suitable machine representations of the modeled target.

A model of a target can be variously configured without departing from the scope of this disclosure. In some examples a model may include one or more data structures that represent a target as a three dimensional model comprising rigid and or deformable shapes or body parts. Each body part may be characterized as a mathematical primitive examples of which include but are not limited to spheres anisotropically scaled spheres cylinders anisotropic cylinders smooth cylinders boxes beveled boxes prisms and the like.

For example body model of includes body parts bp through bp each of which represents a different portion of the modeled target. Each body part is a three dimensional shape. For example bp is a rectangular prism that represents the left hand of a modeled target and bp is an octagonal prism that represents the left upper arm of the modeled target. Body model is exemplary in that a body model may contain any number of body parts each of which may be any machine understandable representation of the corresponding part of the modeled target.

A model including two or more body parts may also include one or more joints. Each joint may allow one or more body parts to move relative to one or more other body parts. For example a model representing a human target may include a plurality of rigid and or deformable body parts wherein some body parts may represent a corresponding anatomical body part of the human target. Further each body part of the model may comprise one or more structural members i.e. bones or skeletal parts with joints located at the intersection of adjacent bones. It is to be understood that some bones may correspond to anatomical bones in a human target and or some bones may not have corresponding anatomical bones in the human target.

The bones and joints may collectively make up a skeletal model which may be a constituent element of the body model. In some embodiments a skeletal model may be used instead of another type of model such as model of . The skeletal model may include one or more skeletal members for each body part and a joint between adjacent skeletal members. Exemplary skeletal model and exemplary skeletal model are shown in respectively. shows a skeletal model as viewed from the front with joints j through j. shows a skeletal model as viewed from a skewed view also with joints j through j.

Skeletal model further includes roll joints j through j where each roll joint may be utilized to track axial roll angles. For example an axial roll angle may be used to define a rotational orientation of a limb relative to its parent limb and or the torso. For example if a skeletal model is illustrating an axial rotation of an arm roll joint j may be used to indicate the direction the associated wrist is pointing e.g. palm facing up . By examining an orientation of a limb relative to its parent limb and or the torso an axial roll angle may be determined. For example if examining a lower leg the orientation of the lower leg relative to the associated upper leg and hips may be examined in order to determine an axial roll angle.

A skeletal model may include more or fewer joints without departing from the spirit of this disclosure.

As described above some models may include a skeleton and or other body parts that serve as a machine representation of a modeled target. In some embodiments a model may alternatively or additionally include a wireframe mesh which may include hierarchies of rigid polygonal meshes one or more deformable meshes or any combination of the two.

The above described body part models and skeletal models are nonlimiting example types of models that may be used as machine representations of a modeled target. Other models are also within the scope of this disclosure. For example some models may include polygonal meshes patches non uniform rational B splines subdivision surfaces or other high order surfaces. A model may also include surface textures and or other information to more accurately represent clothing hair and or other aspects of a modeled target. A model may optionally include information pertaining to a current pose one or more past poses and or model physics. It is to be understood that a variety of different models that can be posed are compatible with the herein described target recognition analysis and tracking.

As mentioned above a model serves as a representation of a target such as game player in . As the target moves in physical space information from a capture device such as depth camera in can be used to adjust a pose and or the fundamental size shape of the model so that it more accurately represents the target.

The disclosed pipeline can be used to accurately and efficiently track one or more humans that are present in the field of view of a depth camera. The pipeline can model and track one or more humans in real time thus providing a responsive immersive and realistic experience for a human being tracked. Furthermore the pipeline is believed to be efficient so as to limit the computing resources used to execute the pipeline.

Pipeline includes six conceptual phases depth image acquisition background removal foreground pixel assignment model fitting model resolution and reporting .

Depth image acquisition may include receiving an observed depth image of the target from a source. In some embodiments the source may be a depth camera configured to obtain depth information about the target via a suitable technique such as time of flight analysis structured light analysis stereo vision analysis or other suitable techniques. The observed depth image may include a plurality of observed pixels where each observed pixel has an observed depth value. The observed depth value includes depth information of the target as viewed from the source.

The depth image may optionally be represented as a pixel matrix that includes for each pixel address a depth value indicating a world space depth from the plane of the depth camera or another suitable reference plane to a surface at that pixel address.

As shown at of depth image acquisition may optionally include downsampling the observed depth image to a lower processing resolution. Downsampling to a lower processing resolution may allow the observed depth image to be more easily utilized and or more quickly processed with less computing overhead.

As shown at of depth image acquisition may optionally include removing and or smoothing one or more high variance and or noisy depth values from the observed depth image. Such high variance and or noisy depth values in the observed depth image may result from a number of different sources such as random and or systematic errors occurring during the image capturing process defects and or aberrations resulting from the capture device etc. Since such high variance and or noisy depth values may be artifacts of the image capturing process including these values in any future analysis of the image may skew results and or slow calculations. Thus removal of such values may provide better data integrity and or speed for future calculations.

Background removal may include distinguishing targets that are to be tracked from non target background elements in the observed depth image. As used herein the term background is used to describe anything in the scene that is not part of the target s to be tracked. The background may include elements that are in front of i.e. closer to the depth camera than the target s to be tracked. Distinguishing foreground elements that are to be tracked from background elements that may be ignored can increase tracking efficiency and or simplify downstream processing.

Background removal may include assigning each data point e.g. pixel of the processed depth image a player index that identifies that data point as belonging to a particular target or to a non target background element. When such an approach is used pixels or other data points assigned a background index can be removed from consideration in one or more subsequent phases of pipeline .

As an example pixels corresponding to a first player can be assigned a player index equal to one pixels corresponding to a second player can be assigned a player index equal to two and pixels that do not correspond to a target player can be assigned a player index equal to zero. Such player indices can be saved in any suitable manner. In some embodiments a pixel matrix may include at each pixel address a player index indicating if a surface at that pixel address belongs to a background element a first player a second player etc. For example shows data structure including a player index equal to zero for wall pixel data structure including a player index equal to zero for door pixel and data structure including a player index equal to one for player pixel . While this example shows the player background indices as part of the same data structure that holds the depth values other arrangements are possible. In some embodiments depth information player background indices body part indices body part probability distributions and other information may be tracked in a common data structure such as a matrix addressable by pixel address. In other embodiments different masks may be used to track information through pipeline . The player index may be a discrete index or a fuzzy index indicating a probability that a pixel belongs to a particular target and or the background.

A variety of different background removal techniques may be used. Some background removal techniques may use information from one or more previous frames to assist and improve the quality of background removal. For example a depth history image can be derived from two or more frames of depth information where the depth value for each pixel is set to the deepest depth value that pixel experiences during the sample frames. A depth history image may be used to identify moving objects in the foreground of a scene e.g. a human game player from the nonmoving background elements. In a given frame the moving foreground pixels are likely to have depth values that are smaller than the corresponding depth values at the same pixel addresses in the depth history image. In a given frame the nonmoving background pixels are likely to have depth values that match the corresponding depth values in the depth history image.

As one nonlimiting example a connected island background removal may be used. Using a connected island approach an input depth stream can be used to generate a set of samples e.g. voxels that can be conceptually unprojected back into world space. Foreground objects are then isolated from background objects using information from previous frames. In particular the process can be used to determine whether one or more voxels in the grid are associated with a background by determining whether an object of the one or more objects in the grid is moving. This may be accomplished at least in part by determining whether a given voxel is close to or behind a reference plate that is a history of the minimum or maximum values observed for background objects. The output from this process can be used to assign each data point e.g. pixel a player index or a background index. Connected island background removal is described in U.S. patent application Ser. No. 12 575 363 filed Oct. 7 2009 the entirety of which is hereby incorporated herein by reference.

Additional or alternative background removal techniques can be used to assign each data point a player index or a background index or otherwise distinguish foreground targets from background elements. In some embodiments particular portions of a background may be identified. For example at of a floor in a scene may be identified as part of the background. In addition to being removed from consideration when processing foreground targets a found floor can be used as a reference surface that can be used to accurately position virtual objects in game space stop a flood fill that is part of generating a connected island and or reject an island if its center is too close to the floor plane.

A variety of different floor finding techniques may be used. In some embodiments a depth image can be analyzed in screen space row by row. For selected candidate rows of the screen space depth image e.g. rows near the bottom of the image a straight depth line can be interpolated through two candidate points that are believed to be located on a floor surface. Boundary lines can then be fit to endpoints of the straight depth lines. The boundary lines can be averaged and used to define a plane that is believed to correspond to the floor surface. Screen space floor detection of this kind is described in U.S. patent application Ser. No. 12 563 456 filed Sep. 21 2009 the entirety of which is hereby incorporated herein by reference.

In other embodiments a floor finding technique may use three points from a depth image to define a candidate floor surface. The three points used to define the candidate can be randomly selected from a lower portion of the depth image for example. If the normal of the candidate is substantially vertical in world space the candidate is considered and if the normal of the candidate is not substantially vertical the candidate can be rejected. A candidate with a substantially vertical normal can be scored by counting how many points from the depth image are located below the candidate and or what the average distance such points are below the candidate. If the number of points below the candidate exceeds a threshold and or the average distance of points below the candidate exceeds a threshold the candidate can be rejected. Different candidates are tested and the candidate with the best score is saved. The saved candidate may be blessed as the actual floor if a predetermined number of candidates with lower scores are tested against the saved candidate.

Additional or alternative background removal techniques can be used to assign each data point a player index or a background index or otherwise distinguish foreground targets from background elements. For example in pipeline includes bad body rejection . In some embodiments objects that are initially identified as foreground objects can be rejected because they do not resemble any known target. For example an object that is initially identified as a foreground object can be tested for basic criteria that are to be present in any objects to be tracked e.g. head and or torso identifiable bone lengths within predetermined tolerances etc. . If an object that is initially identified as being a candidate foreground object fails such testing it may be reclassified as a background element and or subjected to further testing. In this way moving objects that are not to be tracked such as a chair pushed into the scene can be classified as background elements because such elements do not resemble a human target.

After foreground pixels are distinguished from background pixels pipeline further classifies the pixels that are considered to correspond to the foreground objects that are to be tracked. In particular at foreground pixel assignment of each foreground pixel is analyzed to determine what part of a player target s body that foreground pixel is likely to belong.

A variety of different foreground pixel assignment techniques can be used to assess which part of a player target s body or a machine representation of the body a particular pixel is likely to belong. A pixel matrix or other data structure may include for each pixel address a body part index confidence value and or body part probability distribution indicating the part or parts to which a pixel is likely to belong. For example schematically shows data structure including a body part index equal to nine which corresponds to an upper right arm for player pixel . In the simplified version of the body part index is resolved to a single candidate body part i.e. body part nine . In practice the body part information may be a soft labeling that is represented as a histogram over possible body parts for each pixel. In other words a probability distribution of all likely body parts may be used in some embodiments as described in more detail below.

As one nonlimiting example machine learning can be used to assign each foreground pixel a body part index and or body part probability distribution. The machine learning approach analyzes a foreground object using information learned from analyzing a prior trained collection of known poses. This approach can be used to assign each foreground pixel a body part index or distribution without any prior context i.e. knowledge of the prior frame is not needed .

In some embodiments the machine learning foreground pixel assignment may utilize one or more decision trees to analyze each foreground pixel of interest in an observed depth image. Such analysis can find a best guess of the body part for that pixel and the confidence that the best guess is correct. In some embodiments the best guess may include a probability distribution over two or more possible body parts and the confidence may be represented by the relative probabilities of the different possible body parts.

At each node of the decision tree an observed depth value comparison between two pixels is made and depending on the result of the comparison a subsequent depth value comparison between two pixels is made at the child node of the decision tree. The result of such comparisons at each node determines the pixels that are to be compared at the next node. The terminal nodes of each decision tree result in a body part classification and associated confidence in the classification.

In some embodiments subsequent decision trees may be used to iteratively refine the best guess of the body part for each pixel and the confidence that the best guess is correct. For example once the pixels have been classified with the first classifier tree based on neighboring depth values a refining classification may be performed to classify each pixel by using a second decision tree that looks at the previous classified pixels and or depth values. A third pass may also be used to further refine the classification of the current pixel by looking at the previous classified pixels and or depth values. It is to be understood that virtually any number of iterations may be performed with fewer iterations resulting in less computational expense and more iterations potentially offering more accurate classifications and or confidences.

The decision trees may be constructed during a training mode in which a sample of known models in known poses are analyzed to determine the questions i.e. tests that can be asked at each node of the decision trees in order to produce accurate pixel classifications.

Turning back to after foreground pixels are labeled with body part information pipeline includes model fitting which finds one or more possible skeletons that serve as machine representations of the player target.

A variety of different model fitting techniques may be used. During model fitting a human target is modeled as a skeleton including a plurality of skeletal points each skeletal point having a three dimensional location in world space. The various skeletal points may correspond to actual joints of a human target terminal ends of a human target s extremities and or points without a direct anatomical link to the human target. Each skeletal point has at least three degrees of freedom e.g. world space x y z . As such the skeleton can be fully defined by 3 values where is equal to the total number of skeletal points included in the skeleton. A skeleton with 31 skeletal points can be defined by 93 values for example. As described with reference to above some skeletal points may account for axial roll angles.

The various model fitting approaches compatible with pipeline may use depth information background information body part information and or prior trained anatomical and kinetic information to deduce one or more skeleton s that closely model a human target.

As an example the body part information that is assessed for the foreground pixels may be used to find one or more candidate locations e.g. centroids for one or more skeletal bones. Furthermore a plurality of plausible skeletons may be assembled to include skeletal bones at different combinations of the plurality of candidate locations. The various plausible skeletons may then be scored and the scored proposals can be combined into a final estimate.

Clumps of foreground pixels may individually include body part probability distributions indicating that a particular body part is probable for that clump. In some cases two or more clumps that are spaced apart from one another may indicate that the same body part is probable. For example the clumps of pixels actually showing the right and left hands of a target may both be labeled with body part information indicating a high probability for a right hand body part. As such two or more centroid candidates may be calculated for each body part. Each centroid candidate for a parituclar body part may be represented in four dimensions x y z and probability w that the candidate belongs to that body part. In other words each centroid defines a location of a clump of neighboring foreground pixels individually having body part probability distributions indicating that that body part is probable for that clump of neighboring foreground pixels. Furthermore each centroid defines a single probability representing all individual body part probability distributions within the clump.

Two or more different centroid candidates can be considered in finding a skeleton that closely models a human target. The various candidate centroids can be scored against one another e.g. number of pixels in clump multiplied by average probability that pixels in the clump belong to a particular body part . The scores may be adjusted based on one or more constraints e.g. apply a penalty when a distance between the highest scoring clump for a body part in a previous frame exceeds a threshold distance to the highest scoring clump for the same body part in the current frame . The scored centroids may be used to construct one or more plausible skeletons from which a single skeleton can be derived.

Considering plural plausible skeletons employs a probabilistic principle of least commitment to deal with uncertainty. As such many possibilities are considered throughout the model fitting phase of the pipeline without making hard decisions until such decisions can no longer be avoided.

When the data is unambiguous the plurality of plausible skeletons will be very similar to each other. If there are situations in which there are numerous possibilities for one or more parts of the skeleton the sample set will be more diverse thus capturing the uncertainty.

The accuracy of the approximation can improve as the number of plausible skeletons n increases. However computational cost also increases as n increases. The model fitting phase of the pipeline can be restrained to focus on a relatively small number of samples e.g. n

As shown in model fitting may receive input from previous phases of pipeline . Model fitting may receive one or more raw depth images from depth image acquisition player background information from background removal and body part information from foreground pixel assignment .

With all available inputs foreground regions of the depth image may be segmented into a set of patches which are regions of roughly consistent depth. This effectively approximates the full depth image by a set of small planar regions. For a modest loss of fidelity this can reduce the bandwidth requirements from millions of pixel accesses to thousands of patch accesses.

Plausible skeletons may then be proposed from the previous foreground pixel assignments. The purpose of this phase is to convert pixel wise body part probability distributions into proposals for full skeletons e.g. 93 values for a 31 skeleton . In the spirit of the principle of least commitment all likely locations for a body part are considered until global information can be brought to bear. Therefore this phase may include two components a body part proposer which extracts candidate locations from foreground pixel assignment for each body part independently e.g. finding candidate centroids for each body part as introduced above and a skeleton generator which combines these candidates into complete skeletons.

As discussed above in at least some embodiments model fitting can be used to find a plurality of different plausible skeletons. A proposed skeleton can be scored using a variety of different metrics. In pipeline includes model resolution in which a single skeleton is derived from the plurality of plausible skeletons. A variety of different model resolution techniques may be used. In some embodiments two or more plausible skeletons may be scored against each other based on weight observed motion over time anticipated bone length foreground background crossing and or other factors. A proposed skeleton with a highest score may be selected or the best scoring portions of two or more different proposed skeletons from one or more different frames may be combined into a selected skeleton. Furthermore various constraints e.g. bone length joint angle collision testing etc. may be applied to one or more skeletons to shift the proposed skeleton s into a better matching pose.

Pipeline also includes reporting where the selected skeleton is reported for use by other applications. Reporting can be performed in any suitable manner. As a nonlimiting example an application programming interface API may be used to report the selected skeleton. Such an API may be configured to communicate the joint positions joint velocities joint accelerations confidences in positions velocities and or accelerations and or other information related to the selected skeleton for one or more targets. A content receiver e.g. a gaming application may then use the reported information as desired.

At the depth information believed to belong to the player target is analyzed to determine what part of a player target s body each pixel is likely to belong. Map schematically represents one or more data structures capturing the body part information e.g. as deduced during foreground pixel assignment of pipeline .

At a set of plausible skeletons are proposed where each skeleton is an attempt to model the human target as a machine representation. Skeleton set schematically represents one or more data structures defining the proposed skeletons e.g. as proposed during model fitting of pipeline . It is to be understood that the graphical depictions of skeletons in is nonlimiting. Skeletons with a different number and or configuration of skeletal points and skeletal bones may be used.

At a skeleton is selected based on the set of plausible skeletons. Skeleton schematically represents one or more data structures defining the selected skeleton e.g. as selected during model resolution of pipeline .

At the selected skeleton is reported e.g. as described with reference to model reporting of pipeline . As indicated at the reported skeleton may be used as an input by an operating system one or more applications or any other suitable receiver.

It is to be understood that the configurations and or approaches described herein are exemplary in nature and that these specific embodiments or examples are not to be considered in a limiting sense because numerous variations are possible. The specific routines or methods described herein may represent one or more of any number of processing strategies. As such various acts illustrated may be performed in the sequence illustrated in other sequences in parallel or in some cases omitted. Likewise the order of the above described processes may be changed.

The subject matter of the present disclosure includes all novel and nonobvious combinations and subcombinations of the various processes systems and configurations and other features functions acts and or properties disclosed herein as well as any and all equivalents thereof.

