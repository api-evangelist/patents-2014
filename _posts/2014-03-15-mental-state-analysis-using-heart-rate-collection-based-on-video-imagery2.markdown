---

title: Mental state analysis using heart rate collection based on video imagery
abstract: Video of one or more people is obtained and analyzed. Heart rate information is determined from the video and the heart rate information is used in mental state analysis. The heart rate information and resulting mental state analysis are correlated to stimuli, such as digital media which is consumed or with which a person interacts. The heart rate information is used to infer mental states. The mental state analysis, based on the heart rate information, can be used to optimize digital media or modify a digital game.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09642536&OS=09642536&RS=09642536
owner: Affectiva, Inc.
number: 09642536
owner_city: Boston
owner_country: US
publication_date: 20140315
---
This application claims the benefit of U.S. provisional patent applications Mental State Analysis Using Heart Rate Collection Based on Video Imagery Ser. No. 61 793 761 filed Mar. 15 2013 Mental State Analysis Using Blink Rate Ser. No. 61 789 038 filed Mar. 15 2013 Mental State Data Tagging for Data Collected from Multiple Sources Ser. No. 61 790 461 filed Mar. 15 2013 Mental State Well Being Monitoring Ser. No. 61 798 731 filed Mar. 15 2013 Personal Emotional Profile Generation Ser. No. 61 844 478 filed Jul. 10 2013 Heart Rate Variability Evaluation for Mental State Analysis Ser. No. 61 916 190 filed Dec. 14 2013 Mental State Analysis Using an Application Programming Interface Ser. No. 61 924 252 filed Jan. 7 2014 and Mental State Analysis for Norm Generation Ser. No. 61 927 481 filed Jan. 15 2014. This application is also a continuation in part of U.S. patent application Mental State Analysis Using Web Services Ser. No. 13 153 745 filed Jun. 6 2011 which claims the benefit of U.S. provisional patent applications Mental State Analysis Through Web Based Indexing Ser. No. 61 352 166 filed Jun. 7 2010 Measuring Affective Data for Web Enabled Applications Ser. No. 61 388 002 filed Sep. 30 2010 Sharing Affect Data Across a Social Network Ser. No. 61 414 451 filed Nov. 17 2010 Using Affect Within a Gaming Context Ser. No. 61 439 913 filed Feb. 6 2011 Recommendation and Visualization of Affect Responses to Videos Ser. No. 61 447 089 filed Feb. 27 2011 Video Ranking Based on Affect Ser. No. 61 447 464 filed Feb. 28 2011 and Baseline Face Analysis Ser. No. 61 467 209 filed Mar. 24 2011. The foregoing applications are each hereby incorporated by reference in their entirety.

This application relates generally to analysis of mental states and more particularly to mental state analysis using heart rate collection based on video imagery.

It is well known that an individual s emotions or mental state can cause physiological changes. Examples of such physiological changes include sweating changes in respiration facial movements fidgeting changes to blood pressure and changes to heart rate. Heart rate related indications of mental state can include a measure of absolute heart rate HR heart rate variability HRV and blood volume pulse BVP . An individual s heart rate can be measured in various ways including using a medical electrocardiograph EKG machine a chest strap with electrodes a pulse oximeter that clips on a finger a sphygmomanometer or by measuring a pressure point on an individual.

A person s mental state can be impacted by many types of external stimuli. One growingly common stimulus is interaction with a computer. People spend an ever increasing amount of time interacting with computers and consume a vast amount of computer delivered media. This interaction can be for many different reasons such as desire for educational content entertainment social media interaction document creation and gaming to name a few.

In some cases the human computer interaction can take the form of a person performing a task using a computer and a software tool running on the computer. Examples of such interactions can include filling out a tax form creating a document editing a video and doing one or more of the other activities that a modern computer can perform. The person might find certain activities interesting or even exciting and might be surprised at how easy it is to perform the activity or activities. The person can become excited happy or content as they perform the activities. On the other hand the person might find some activities difficult to perform and can become frustrated or even angry with the computer even though the computer is oblivious to their emotions. In other cases of human computer interaction the person can be consuming content or media such as news pictures music or video. A person s mental state can be useful in determining whether or not the person enjoys particular media content.

Currently tedious methods with limited usefulness are employed to determine users mental states. For example users can be surveyed in an attempt to determine their mental state in reaction to a stimulus such as a human computer interaction. Survey results are often unreliable because the surveys are often done well after the activity was performed survey participation rates can be low and many times people do not provide accurate and honest answers to the survey questions. In other cases people can self rate media to communicate personal preferences by entering a specific number of stars corresponding to a level of like or dislike. However these types of subjective evaluations are often neither a reliable nor practical way to evaluate personal response to media. Recommendations based on such methods are imprecise subjective unreliable and are often further subject to problems related to the small number of individuals willing to participate in the evaluations.

Heart rate and other types of analysis can be gleaned from facial video as someone observes various media presentations. The information on heart rates can be used to aid in mental state analysis. A method for mental state analysis is described which includes obtaining video of an individual as the individual is interacting with a computer either by performing various operations or by consuming a media presentation. The video is then analyzed to determine heart rate information on the individual including both heart rate and heart rate variability. A mental state of the individual is then inferred based on the heart rate information. A computer implemented method for mental state analysis is disclosed comprising obtaining video of an individual analyzing the video to determine heart rate information and inferring mental states of the individual based on the heart rate information.

The method can include analyzing a media presentation based on the mental states which were inferred. The analyzing of the media presentation may include evaluating advertisement effectiveness. The analyzing of the media presentation can also include optimizing the media presentation. The heart rate information may be correlated to a stimulus that the individual is encountering. The analyzing can include identifying a location of a face of the individual in a portion of the video. The method may further comprise establishing a region of interest including the face separating pixels in the region of interest into at least two channel values and combining to form raw traces transforming and decomposing the raw traces into at least one independent source signal and processing the at least one independent source signal to obtain the heart rate information.

In embodiments a computer program product embodied in a non transitory computer readable medium for mental state analysis comprises code for obtaining video of an individual code for analyzing the video to determine heart rate information and code for inferring mental states of the individual based on the heart rate information. In some embodiments a computer system for mental state analysis comprises a memory which stores instructions one or more processors attached to the memory wherein the one or more processors when executing the instructions which are stored are configured to obtain video of an individual analyze the video to determine heart rate information and infer mental states of the individual based on the heart rate information.

Various features aspects and advantages of various embodiments will become more apparent from the following further description.

As an individual interacts with a computer the individual s mental state can be impacted by the interaction which can in turn have an impact on the individual s facial expressions and heart rate as well as provoking other physiological reactions. Determining the individual s mental state can have value for a variety of reasons such as improving the program that the individual is using rating a media presentation or optimizing an advertisement. Traditional methods of monitoring an individual s mental state have limited effectiveness for a variety of reasons. For example surveys or rating systems are prone to non participation and inaccurate reporting and even though physiological information is often an accurate way to determine an individual s mental state traditional physiological monitoring devices are intrusive and not available at most computer workstations.

Many contemporary computer systems already include a webcam and even for systems without a webcam it is possible to easily and inexpensively add one to nearly any modern computer workstation. In many cases a webcam can unobtrusively monitor an individual but until recently it was not known how to determine heart rate information from a video produced by a webcam. Recent studies have shown however that it is possible to extract heart rate information from video of an individual. Examples of such work include Remote plethysmographic imaging using ambient light by Wim Verkruysse Lars O Svaasand and J Stuart Nelson published in Optics Express Vol. 16 No. 26 on Dec. 12 2008 and U.S. patent application publication US 2011 0251493 A1 published on Oct. 31 2011 entitled Method and System for Measurement of Physiological Parameters with Ming Zher Poh Daniel McDuff and Rosalind Picard as named inventors. These papers are hereby incorporated by reference in their entirety. The present disclosure describes using a video of an individual to determine heart rate information and then using the heart rate information to infer a mental state of that individual.

An individual can interact with a computer to perform some type of task on the computer or view a media presentation while being monitored by a webcam. The video from the webcam can then be analyzed to determine heart rate information. In one embodiment the video is separated into separate color channels and a trace is generated for each color channel based on the spatial average of the color channel for the face over time. Independent component analysis can then be used to generate independent source signals that correlate to heart rate information such as BVP. Standard signal processing techniques can then be used to extract heart rate information including heart rate variability arrhythmias heart murmurs beat strength and shape artery health or arterial obstructions. In some embodiments respiration rate information is also determined.

Once the heart rate information has been determined a mental state of the individual can be inferred. Mental states which can be inferred include confusion disappointment hesitation cognitive overload focusing engagement attention boredom exploration confidence trust delight disgust skepticism doubt satisfaction excitement laughter calmness happiness sadness anger stress sentimentality or curiosity. Various types of heart rate information can be used to infer a mental state. For example an elevated HR can indicate excitement a decrease in phasic HR can indicate attention and tonic HR can be used to indicate arousal. In some embodiments the heart rate information can be used in conjunction with facial movement data and or other biosensor data to infer a mental state.

The flow continues by analyzing the video to determine heart rate information . The analyzing can be performed using any type of algorithm but one algorithm that can be used is described in more detail in . In some embodiments the heart rate information includes a measure of heart rate HR . The heart rate can be an instantaneous heart rate or an average heart rate over a period of time. In some embodiments the heart rate information includes heart rate variability HRV . In some embodiments the analyzing correlates the heart rate information to a stimulus such as a scene of a movie a portion of an advertisement a specific task performed within a software application or any other type of stimulus generated by the individual s interaction with the computer by an external event or through some other context. The context can include viewing a concept viewing a product and interacting with a person or persons. In some cases a wearable apparatus can view and record another person s face. The video from that person s face can then be analyzed for heart rate information. In some embodiments two or more people can each have a wearable apparatus and video information can be collected analyzed and exchanged between the people or provided to another system for utilization. The analyzing can factor in a facial occlusion for part of an individual s face. This is accomplished in some embodiments by recognizing that the face is occluded and adjusting a region of interest for the frames where the face is partially occluded along with removing the frames where more than a predetermined portion of the face is occluded. In some embodiments the analyzing includes calculating blood volume pulse BVP . The BVP can be included in the heart rate information and or can be used to calculate the heart rate information depending on the embodiment.

The analyzing can include evaluating phasic and or tonic response of the heart rate information. A phasic response is a short term or high frequency response to a stimulus and a tonic response is a long term or low frequency response to a stimulus. In one embodiment a phasic response constitutes a heartbeat to heartbeat difference while in other embodiments a phasic response constitutes a difference over some number of seconds such as a period between about two and about 10 seconds. Other embodiments can use a different threshold for a phasic response. A tonic response can represent a change over a longer period of time for example a change observed during any period of time from 10 seconds to many minutes or longer. HR HRV and BVP can all have both phasic and tonic responses. In addition analyzing can include extracting a heart rate from evaluation of a face of the individual in the video and the heart rate may be an equivalent to a blood volume pulse value. The analyzing can use a green channel from the video.

The flow further comprises inferring an individual s mental states based on the heart rate information . The mental states can include one or more of frustration confusion disappointment hesitation cognitive overload focusing engagement attention boredom exploration confidence trust delight disgust skepticism doubt satisfaction excitement laughter calmness stress and curiosity. The inferring can include determining arousal determining attention and or determining valence . The method can include interpreting physiological arousal from the heart rate information. Various combinations of the absolute value relative value phasic response and or tonic response of HR HRV BVP and or other heart rate information can be used for the inferring. For example a phasic response of HR can be used to infer attention and a tonic response of HR can be used to infer arousal. A decrease in phasic HR can be used to infer a change of valence with a measure of tonic HR used to infer the direction of the change of valence. In some embodiments a time lag is factored into the inference as there can be a lag between the video and the stimulus as well as a lag in the individual s heart rate response to the stimulus. The time lag factoring can be used to help correlate the response to a specific stimulus. In some embodiments the flow further comprises aggregating the heart rate information for the individual with other people and or inferring mental states of the plurality of other people based on the heart rate information on the plurality of other people. Such aggregation can be useful in determining a mental state of the group of people or a group s response to a certain stimulus.

The flow further comprises analyzing a media presentation based on the mental states which were inferred . The media presentation can be any type of media presentation but can include one or more of an advertisement a movie a television show a web series a webisode a video a video clip an electronic game a concept presentation an e book an e magazine or an app. Some embodiments further comprise aggregating the mental states for the individual with other people. The analyzing can include comparing the mental state to an intended mental state to determine if the media presentation is effective. So if the media presentation is an advertisement the analyzing of the media presentation can include evaluating advertisement effectiveness . In some embodiments different versions of the media presentation are presented and the mental states of the individual or the group can be compared for the different versions. The media presentation can be changed in some embodiments based on the mental states. Such changes can include changing a length of the media presentation adding or deleting scenes choosing appropriate music for the soundtrack or other changes. Thus the analyzing of the media presentation can include optimizing the media presentation . The flow can further include learning about heart rate information as part of the analyzing. The learning can factor in one or more previous frames of data and can apply transformations either previously learned or learned on the fly to the traces for this analysis to promote the capture of signal fluctuations due to blood flow. One or more previous frames can be used as training data for an individual for people with similar skin pigmentation or for people in general. The learning can occur on the fly or can be stored for future use with a certain individual or group of people. The learning can be used for global independent component analysis and or other transformations. Further a set of videos can be processed in order to learn heart rate information analysis.

The flow can further comprise collecting facial data based on the video. The facial data can include facial movements which in at least some embodiments can be categorized using the facial action coding system FACS . The inferring of mental states can be based at least in part on the facial data thus the facial data can be used in combination with the heart rate information for the inferring of mental states. Various steps in the flow may be changed in order repeated omitted or the like without departing from the disclosed concepts. Various embodiments of the flow may be included in a computer program product embodied in a non transitory computer readable medium that includes code executable by one or more processors.

The webcam can have a line of sight to the user s face and can capture any one or more of video audio and still images of the individual . A webcam as the term is used herein can include a video camera a still camera a thermal imager a CCD device a phone camera a three dimensional camera a depth camera multiple webcams used to show different views of a person or any other type of image capture apparatus which can allow image data to be captured and used in an electronic system. The images of the person as taken by the webcam can be captured by a video capture unit . In some embodiments video is captured while in others one or more still images are captured at regular or irregular intervals. In some embodiments the one or more still images are used to create a video which can have a variable frame rate. The captured video or still images can be analyzed to determine one or both of facial movements and heart rate information . The facial movements can include information on facial expressions action units head gestures smiles smirks brow furrows squints lowered eyebrows raised eyebrows or attention. In some embodiments the webcam can also capture images of the setting which can assist in determining contextual information other physiological data gestures actions and or other movements. The analysis of the video can be used to infer a mental state of the user .

The flow can further comprise determining contextual information such as identifying the stimulus . In some embodiments the contextual information can include other information such as other individuals nearby who can be captured by the webcam environmental information identity information about the user or another type of contextual information. The electronic display can include a stimulus such as a media presentation or the user interface of a computer program. Thus the stimulus can pertain to a media presentation . The media presentation can include one of a group consisting of a movie a television show a web series a webisode a video a video clip an electronic game an e book or an e magazine. In other embodiments the stimulus can be based on a game device appliance vehicle sensor application robot or system with which the user is interacting using the display .

The heart rate information can be correlated to a stimulus that the individual is encountering and in at least some embodiments the inferring factors in the time lag between a stimulus and the heart rate information. This can allow conclusions to be formed about the user s interaction with the stimulus . In some embodiments the media presentation is optimized based on the correlation of the mental state to the stimulus. In some embodiments a game is changed in some way based on the mental state inferred from the heart rate information and or the facial movements. Thus the game can be modified based on the heart rate information. The game can be modified in many different ways. For example the game s difficulty can be changed or a player s avatar can be modified to match modify or disguise the player s mental state by adjusting the avatar s facial expressions or body actions. That is in embodiments the avatar performs an action such as smiling or frowning based on the user s mental state.

The flow can further comprise separating temporal pixel intensity traces in the regions of interest into at least two channel values and spatially and or temporally processing the separated pixels to form raw traces . While one embodiment establishes red green and blue as channel values other embodiments can base channels on another color gamut or other functions of the pixel intensity traces. The channels of the video can be analyzed on a frame by frame basis and spatially averaged to provide a single value for each frame in each channel. Some embodiments use a weighted average to emphasize certain areas of the face. One raw trace per channel can be created and can include a single value that varies over time. In some embodiments the raw traces can be processed for filtering or enhancement. Such processing can include various filters such as low pass high pass or band pass filters interpolation decimation or other signal processing techniques. In at least one embodiment the raw traces are detrended using a procedure based on a smoothness priors approach. Other types of analysis are alternatively possible such as a feature being extracted from a channel based on a discrete probability distribution of pixel intensities. A histogram of intensities can be generated with a histogram per channel. In some embodiments one bin can be considered equivalent to summing spatially. Analysis can include tracing fluctuations in reflected light from the skin of a person being viewed.

The flow can further comprise decomposing the raw traces into at least one independent source signal . The decomposition can be accomplished using independent component analysis ICA . Independent component analysis ICA is a technique for uncovering independent signals from a set of observations composed of linear mixtures of underlying sources. In this case the underlying source signal of interest can be BVP. During the cardiac cycle volumetric changes in the blood vessels modify the path length of the incident ambient light which in turn changes the amount of light reflected a measurement which can indicate the timing of cardiovascular events. By capturing a sequence of images of the facial region with a webcam the red green and blue RGB color sensors pick up a mixture of reflected plethysmographic signals along with other sources of fluctuations in light due to artifacts. Given that hemoglobin absorptivity differs across the visible and near infrared spectral range each color sensor records a mixture of the original source signals with slightly different weights. The ICA model assumes that the observed signals are linear mixtures of the sources where one of the sources is hemoglobin absorptivity or reflectivity. ICA can be used to decompose the raw traces into a source signal representing hemoglobin absorptivity correlating to BVP. Respiration rate information is also determined in some embodiments.

The flow further comprises processing at least one source signal to obtain the heart rate information . Heart rate HR can be determined by observing the intervals between peaks of the source signal finding the peaks having been discussed above. Thus the heart rate information can include heart rate and the heart rate can be determined based on changes in the amount of reflected light . Heart rate variability both phasic and tonic can be obtained using a power spectral density PSD estimation and or through other signal processing techniques. The analysis can include evaluation of phasic and tonic heart rate responses. In some embodiments the video includes a plurality of other people. Such embodiments can comprise identifying locations for faces of the plurality of other people and analyzing the video to determine heart rate information on the plurality of other people. Various steps in the flow may be changed in order repeated omitted or the like without departing from the disclosed concepts. Various embodiments of the flow may be included in a computer program product embodied in a non transitory computer readable medium that includes code executable by one or more processors. In other embodiments a supervised learning approach is adopted to the problem of detecting human heart rate. A statistical classifier can be trained by learning from a data set consisting of human blood volume pulse synchronized with face videos. The classifier will recognize a pulse by learning patterns of variability in the mean of the green channel that correspond to a beat in the blood volume pulse values. After training the classifier can process a sequence of frames and thereby report a heartbeat when it detects a pattern in the green channel similar to the pattern seen during training. The classifier can return a number that could be positive or negative. A larger number is returned as a result of a higher confidence by the classifier. In some embodiments progressive filtering can be used to enable shorter time spans in the heart rate analysis. In some cases each beat can be evaluated for a heart rate. In embodiments facial images can be compensated for media images that are reflected from the face due to screen lighting.

Mental states can be inferred based on physiological data including physiological data from the sensor which can be used to augment the heart rate information determined by analyzing video. Mental states can also be inferred at least in part based on facial expressions and head gestures observed by a webcam or based on a combination of data from the webcam and data from the sensor . The mental states can be analyzed based on arousal and valence. Arousal can range from being highly activated such as when someone is agitated to being entirely passive such as when someone is bored. Valence can range from being very positive such as when someone is happy to being very negative such as when someone is angry. Physiological data can include one or more of electrodermal activity EDA heart rate heart rate variability skin temperature respiration accelerometer readings and other types of analysis of a human being. It will be understood that both here and elsewhere in this document physiological information can be obtained either by biosensor or by facial observation via an image capturing device. Facial data can include facial actions and head gestures used to infer mental states. Further the data can include information on hand gestures or body language and body movements such as visible fidgets. In some embodiments these movements are captured by cameras while in other embodiments these movements are captured by sensors. Facial data can include the tilting of the head to the side leaning forward smiling and frowning among numerous other gestures or expressions.

In some embodiments electrodermal activity is collected continuously periodically or sporadically. The electrodermal activity can be analyzed to indicate arousal excitement boredom or other mental states based on observed changes in skin conductance. Skin temperature can be collected and recorded. In turn the skin temperature can be analyzed . Changes in skin temperature can indicate arousal excitement boredom or other mental states. Heart rate can be collected and recorded and can also be analyzed . A high heart rate can indicate excitement arousal or other mental states. Accelerometer data can be collected and used to track one two or three dimensions of motion. The accelerometer data can be recorded. The accelerometer data can be analyzed and can indicate a sleep pattern a state of high activity a state of lethargy or other states. The various data collected by the biosensor can be used along with the heart rate information determined by analyzing video captured by the webcam in the analysis of mental state.

The one or more processors can be configured to obtain video of the individual using the webcam or other camera analyze the video to determine heart rate information and infer mental states of the individual based at least in part and in some embodiments on the heart rate information. So the system can comprise a computer program product embodied in a non transitory computer readable medium for mental state analysis the computer program product comprising code for obtaining video of an individual code for analyzing the video to determine heart rate information and code for inferring mental states of the individual based on the heart rate information.

Some embodiments include an analysis server although some embodiments comprise performing the analysis of the video data inferring mental states and executing other aspects of methods described herein on the local machine . The local machine sends video data over the Internet or other computer communication link to the analysis server in some embodiments. In some embodiments the analysis server is provisioned as a web service. The analysis server includes one or more processors coupled to a memory to store instructions and or data. Some embodiments of the analysis server include a display . The one or more processors can be configured to receive video data from the local machine over the Internet . Thus the obtaining the video of the individual can comprise receiving the video from another computer and the obtaining the video of the individual can comprise receiving the video over the Internet. The transfer of video can be accomplished once an entire video is captured of a person for analysis. Alternatively video can be streamed as it is collected. The video can be analyzed for heart rate information on the fly as the video is collected or as it is streamed to analysis machine. The one or more processors can also be configured to analyze the video to determine heart rate information and infer mental states of the individual based on the heart rate information. In some embodiments the analysis server receives video of multiple individuals from multiple other computers and determine heart rate information for the multiple individuals. In some embodiments the heart rate information from the multiple individuals is aggregated to determine an aggregated mental state of the group including the multiple individuals.

Each of the above methods may be executed on one or more processors on one or more computer systems. Embodiments may include various forms of distributed computing client server computing and cloud based computing. Further it will be understood that the depicted steps or boxes contained in this disclosure s flow charts are solely illustrative and explanatory. The steps may be modified omitted repeated or re ordered without departing from the scope of this disclosure. Further each step may contain one or more sub steps. While the foregoing drawings and description set forth functional aspects of the disclosed systems no particular implementation or arrangement of software and or hardware should be inferred from these descriptions unless explicitly stated or otherwise clear from the context. All such arrangements of software and or hardware are intended to fall within the scope of this disclosure.

The block diagrams and flowchart illustrations depict methods apparatus systems and computer program products. The elements and combinations of elements in the block diagrams and flow diagrams show functions steps or groups of steps of the methods apparatus systems computer program products and or computer implemented methods. Any and all such functions generally referred to herein as a circuit module or system may be implemented by computer program instructions by special purpose hardware based computer systems by combinations of special purpose hardware and computer instructions by combinations of general purpose hardware and computer instructions and so on.

A programmable apparatus which executes any of the above mentioned computer program products or computer implemented methods may include one or more microprocessors microcontrollers embedded microcontrollers programmable digital signal processors programmable devices programmable gate arrays programmable array logic memory devices application specific integrated circuits or the like. Each may be suitably employed or configured to process computer program instructions execute computer logic store computer data and so on.

It will be understood that a computer may include a computer program product from a computer readable storage medium and that this medium may be internal or external removable and replaceable or fixed. In addition a computer may include a Basic Input Output System BIOS firmware an operating system a database or the like that may include interface with or support the software and hardware described herein.

Embodiments of the present invention are neither limited to conventional computer applications nor the programmable apparatus that run them. To illustrate the embodiments of the presently claimed invention could include an optical computer quantum computer analog computer or the like. A computer program may be loaded onto a computer to produce a particular machine that may perform any and all of the depicted functions. This particular machine provides a means for carrying out any and all of the depicted functions.

Any combination of one or more computer readable media may be utilized including but not limited to a non transitory computer readable medium for storage an electronic magnetic optical electromagnetic infrared or semiconductor computer readable storage medium or any suitable combination of the foregoing a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM Flash MRAM FeRAM or phase change memory an optical fiber a portable compact disc an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

It will be appreciated that computer program instructions may include computer executable code. A variety of languages for expressing computer program instructions may include without limitation C C Java JavaScript ActionScript assembly language Lisp Perl Tcl Python Ruby hardware description languages database programming languages functional programming languages imperative programming languages and so on. In embodiments computer program instructions may be stored compiled or interpreted to run on a computer a programmable data processing apparatus a heterogeneous combination of processors or processor architectures and so on. Without limitation embodiments of the present invention may take the form of web based computer software which includes client server software software as a service peer to peer software or the like.

In embodiments a computer may enable execution of computer program instructions including multiple programs or threads. The multiple programs or threads may be processed approximately simultaneously to enhance utilization of the processor and to facilitate substantially simultaneous functions. By way of implementation any and all methods program codes program instructions and the like described herein may be implemented in one or more threads which may in turn spawn other threads which may themselves have priorities associated with them. In some embodiments a computer may process these threads based on priority or other order.

Unless explicitly stated or otherwise clear from the context the verbs execute and process may be used interchangeably to indicate execute process interpret compile assemble link load or a combination of the foregoing. Therefore embodiments that execute or process computer program instructions computer executable code or the like may act upon the instructions or code in any and all of the ways described. Further the method steps shown are intended to include any suitable method of causing one or more parties or entities to perform the steps. The parties performing a step or portion of a step need not be located within a particular geographic location or country boundary. For instance if an entity located within the United States causes a method step or portion thereof to be performed outside of the United States then the method is considered to be performed in the United States by virtue of the causal entity.

While the invention has been disclosed in connection with preferred embodiments shown and described in detail various modifications and improvements thereon will become apparent to those skilled in the art. Accordingly the forgoing examples should not limit the spirit and scope of the present invention rather it should be understood in the broadest sense allowable by law.

