---

title: 3D pointing device with up-down-left-right mode switching and integrated swipe detector
abstract: A 3D pointing device for use with a content delivery system is provided. The pointing device can operate in one of at least one of two modes: a first 3D or scrolling mode, and a second non-3D mode that can also be referred to as an up-down-left-right (UDLR) mode. The pointing device can include one or more directional sensors, to provide orientation and movement information. For either of the at least two modes, an optical finger navigation module is provided that can detect movement of a user's finger or object across its screen, and provides a predetermined threshold that must be exceeded before movement information is generated from the OFN module. The pointing device can generate scroll and UDLR commands based on the information from the orientation and movement sensors, as well as the OFN module, or can provide the information from the orientation and movement sensors to a user interface that can generate the appropriate scrolling or UDLR commands for use by the content delivery system.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09571878&OS=09571878&RS=09571878
owner: HILLCREST LABORATORIES, INC.
number: 09571878
owner_city: Rockville
owner_country: US
publication_date: 20141114
---
This application is a continuation of U.S. patent application Ser. No. 13 628 505 filed on Sep. 27 2012 entitled 3D POINTING DEVICE WITH UP DOWN LEFT RIGHT MODE SWITCHING AND INTEGRATED SWIPE DETECTOR which is a continuation of International Application No. PCT US2011 061667 filed Dec. 28 2010 which is related to and claims priority from U.S. Provisional Patent Application Ser. No. 61 427 562 also entitled 3D POINTING DEVICE WITH UP DOWN LEFT RIGHT MODE SWITCHING to Daniel S. Simpkins and Joseph Tanen filed on Dec. 28 2010 and U.S. Provisional Patent Application Ser. No. 61 416 025 entitled UP DOWN LEFT RIGHT MODE SWITCHING to Daniel S. Simpkins filed on Nov. 22 2010 the disclosure of both of which are incorporated herein by reference.

The present invention describes mode switching techniques devices systems and software which can be used in three dimensional 3D pointing devices as well as in other types of devices.

Technologies associated with the communication of information have evolved rapidly over the last several decades. Television cellular telephony the Internet and optical communication techniques to name just a few modes of communications combine to inundate consumers with available information and entertainment options. Taking television as an example the last three decades have seen the introduction of cable television service satellite television service pay per view movies and video on demand both of the latter being made available by cable fiber optic and satellite service providers as well as over the internet e.g. Netflix . Whereas television viewers of the 1960s could typically receive perhaps four or five over the air TV channels on their television sets today s TV watchers have the opportunity to select from hundreds thousands and potentially millions of channels of shows and information. Video on demand technology currently used primarily in hotels and the like provides the potential for in home entertainment selection from among thousands of movie titles.

The technological ability to provide so much information and content to end users provides both opportunities and challenges to system designers and service providers. One challenge is that while end users typically prefer having more choices rather than fewer this preference is counterweighted by their desire that the selection process be both fast and simple. Unfortunately the development of the systems and interfaces by which end users access media items has resulted in selection processes which are neither fast nor simple. Consider again the example of television programs. When television was in its infancy determining which program to watch was a relatively simple process primarily due to the small number of choices. One would consult a printed guide that was formatted for example as series of columns and rows which showed the correspondence between 1 nearby television channels 2 programs being transmitted on those channels and 3 date and time. The television was tuned to the desired channel by adjusting a tuner knob and the viewer watched the selected program. Later remote control devices were introduced that permitted viewers to tune the television from a distance. This addition to the television user interface created the phenomenon known as channel surfing whereby a viewer could rapidly view short segments being broadcast on a number of channels to quickly learn what programs were available at any given time.

Despite the fact that the number of channels and amount of viewable content has dramatically increased the generally available user interface control device options and frameworks for televisions has not changed much over the last 30 years. Printed guides and their displayed counterparts on a guide channel are still the most prevalent mechanism for conveying programming information. The multiple button remote control an example of which is illustrated in with up down left and right arrows is still the most prevalent channel content navigation mechanism. The reaction of those who design and implement the TV user interface to the increase in available media content has been a straightforward extension of the existing selection procedures and interface objects. Thus the number of rows in the printed guides has been increased to accommodate more channels. The number of buttons on the remote control devices has been increased to support additional functionality and content handling. However this approach has significantly increased both the time required for a viewer to review the available information and the complexity of actions required to implement a selection. For example in a large grid guide supporting hundreds of channels a user may have to perform 50 or a 100 up down left right button presses to navigate the grid guide and make a content selection. Arguably the cumbersome nature of the existing interface has hampered commercial implementation of some services e.g. video on demand since consumers are resistant to new services that will add complexity to an interface that they view as already too slow and complex.

Some attempts have also been made to modernize the screen interface between end users and media systems. However these attempts typically suffer from among other drawbacks an inability to easily scale between large collections of media items and small collections of media items. For example interfaces which rely on lists of items may work well for small collections of media items but are tedious to browse for large collections of media items. Interfaces which rely on hierarchical navigation e.g. tree structures may be speedier to traverse than list interfaces for large collections of media items but are not readily adaptable to small collections of media items. Additionally users tend to lose interest in selection processes wherein the user has to move through three or more layers in a tree structure. For all of these cases current remote units make this selection process even more tedious by forcing the user to repeatedly depress the up and down buttons to navigate the list or hierarchies. When selection skipping controls are available such as page up and page down the user usually has to look at the remote to find these special buttons or be trained to know that they even exist. Accordingly organizing frameworks techniques and systems that simplify the control and screen interface between users and media systems as well as accelerate the selection process while at the same time permitting service providers to take advantage of the increases in available bandwidth to end user equipment by facilitating the supply of a large number of media items and new services to the user have been proposed in the Assignee s earlier U.S. patent application Ser. No. 10 768 432 filed on Jan. 30 2004 entitled A Control Framework with a Zoomable Graphical User Interface for Organizing Selecting and Launching Media Items the disclosure of which is incorporated here by reference.

Of particular interest for this specification are the remote devices usable to interact with such frameworks as well as other applications and systems. As mentioned in the above incorporated application various different types of remote devices can be used with such frameworks including for example trackballs mouse type pointing devices light pens etc. However another category of remote devices which can be used with such frameworks and other applications is 3D pointing devices. The phrase 3D pointing is used in this specification to refer to the ability of an input device to move in three or more dimensions in the air in front of e.g. a display screen and the corresponding ability of the user interface to translate those motions directly into user interface commands e.g. movement of a cursor on the display screen. The transfer of data between the 3D pointing device may be performed wirelessly or via a wire connecting the 3D pointing device to another device. Thus 3D pointing differs from e.g. conventional computer mouse pointing techniques which use a surface e.g. a desk surface or mouse pad as a proxy surface from which relative movement of the mouse is translated into cursor movement on the computer display screen. An example of a 3D pointing device can be found in Assignee s U.S. Pat. No. 7 158 118 to Matthew G. Liberty hereafter referred to as the 118 patent the disclosure of which is incorporated here by reference.

The 118 patent describes 3D pointing devices which include for example one or more rotational sensors and an accelerometer. The rotational sensor s are used as described in more detail below to detect an angular rate at which the 3D pointing device is being rotated by a user and this information is conveyed to a user interface wherein it can be used for example to control cursor movement. Such 3D pointing devices have been shown to free the user from the constraints of up down left right UDLR remote control devices by for example allowing them to directly quickly and randomly access any point or region on a displayed user interface or screen.

However despite the established benefits of 3D pointing an issue that may be presented with this new technology is how to handle legacy applications or systems that expect UDLR inputs to select user interface objects e.g. media selections on a television. Even though 3D pointing provides a superior user experience in many respects given the large number of devices and applications that have been designed to expect UDLR inputs 3D pointing by itself may not provide sufficient support for such legacy systems. Of perhaps more significant importance however is that code bases for set top boxes STB and television operation for example are so large that a substantial transition period needs to planned for wherein legacy UDLR style navigation has to co exist with the newer 3D pointing style navigation. A new device i.e. a new 3D pointer that implements both forms of control into one device and that can change mode of control between different applications or even different screens without compromising performance of either type would provide an easy elegant and simple transition path from the legacy UDLR type navigation to pointing type navigation.

It is therefore a general aspect of the invention to provide a 3d pointer device that will obviate or minimize problems of the type previously described.

According to a first aspect of the present invention a method for generating either a scroll command or an up down left right UDLR command using a single control element of a remote control device is provided the method comprising detecting movement of an object across a surface of said single control element of said remote control device determining a direction of said detected movement and a distance of said detected movement in said direction generating when in a scroll mode a scroll command based upon said direction and distance of said detected movement and generating when in a UDLR mode a UDLR command when said distance exceeds a predetermined distance threshold in said direction.

According to a second aspect of the present invention a method for generating either a scroll command or an up down left right UDLR command using a single control element of a remote control device is provided the method comprising detecting movement of an object across a surface of said single control element of said remote control device generating when in a scroll mode a scroll command responsive to said detected movement and generating when in an UDLR mode an UDLR command.

According to a third aspect of the present invention a method for generating either a scroll command or an up down left right UDLR command using a single control element of a remote control device is provided the method comprising receiving data from said single control element which indicates motion of an object in one of a plurality of different directions and generating either said scroll command or said UDLR command based upon said received data and a mode of operation of said remote control device.

According to a fourth aspect of the present invention a remote control device is provided comprising a housing at least one sensor disposed at least partially within said housing said at least one sensor configured to detect motion of said remote control device and to generate first data associated with said detected motion an optical finger navigation OFN module disposed on an upper surface of said housing configured to detect movement of an object across a surface of a lens and to generate second data associated with said detected movement a user input control element configured to switch said remote control device from a 3D pointing mode into a non 3D pointing mode and a processor configured to receive said first data and said second data and further configured to operate when in said 3D pointing mode to transmit information associated with said first data and to transmit a scroll command based on said second data and further configured to operate when in said non 3D pointing mode to transmit an up down left right UDLR command based on said second data.

According to a fifth aspect of the present invention a remote control device is provided comprising an optical finger navigation OFN module configured to detect movement of an object across a surface of said OFN module and to generate data associated with said detected movement and a processor configured to receive said data and to transmit a command based on said data wherein said processor is configured to operate either in a scroll mode or an up down left right UDLR mode such that when in said scroll mode said processor generates a scroll command based on said data and when in said UDLR mode said processor generates a UDLR command based on said data.

According to a sixth aspect of the present invention a system is provided comprising a user interface controlling device configured to generate and control a user interface based at least in part on received user inputs wherein said user interface controlling device is further configured to receive an input which in a first mode is interpreted as a scroll command and which in a second mode is interpreted as an up down left right UDLR command.

According to a seventh aspect of the present invention a system for controlling operation of a content providing apparatus is provided comprising a remote control device the remote control device including a housing at least two sensors disposed at least partially within said housing said first of the at least two sensors configured to detect motion of said remote control device in a first plane of motion and to generate first data associated with said detected motion in the first plane of motion and wherein said second of the at least two sensors is configured to detect motion of said remote control device in a second plane or motion and to generate second data associated with said detected motion in the second plane of motion an optical finger navigation OFN module disposed on a first surface of said housing configured to detect movement of an object across a surface of a lens and to generate third data associated with said detected movement and further wherein the detected motion includes information about a direction of the detected motion and still further wherein the detected motion includes information about the detected motion exceeding a predetermined threshold a user input control element configured to switch said remote control device from a 3D pointing mode into a non 3D pointing mode and a processor configured to receive said first data said second data and said third data and is further configured to operate when in said 3D pointing mode to transmit 3D pointing information associated with said first and second data and further configured to operate when in said non 3D pointing mode to transmit UDLR information associated with said third data and wherein the system further includes a user interface controlling device configured to generate and control a user interface based at least in part on received user inputs wherein said user interface controlling device is further configured to receive said 3D pointing information from the remote control device that is interpreted as a scroll command and which is further configured to receive said non 3d pointing information from the remote control device that is interpreted as an up down left right UDLR command.

According to an eighth aspect of the present invention a method for controlling a user interface that interfaces with a remote control device is provided comprising determining by the user interface whether the remote control device should be operating in a first mode or a second mode forwarding by the user interface a control signal to the remote control device to put the remote control device in either the first operating mode or the second operating mode and receiving by the user interface either a scroll command that corresponds to the first operating mode or an up down left right UDLR command that corresponds to the second operating mode.

According to a ninth aspect of the present invention a method for controlling a user interface using a 3D pointing device is provided comprising 

switching an operating mode of the 3D pointing device between a random access mode and a non random access mode.

According to a tenth aspect of the present invention a system that includes a 3D pointing device is provided comprising a processor configured to switch an operating mode of the 3D pointing device between a random access mode and a non random access mode.

The following detailed description of the invention refers to the accompanying drawings. The same reference numbers in different drawings identify the same or similar elements. Also the following detailed description does not limit the invention. Instead the scope of the invention is defined by the appended claims.

In order to provide some context for this discussion an exemplary aggregated media system in which the present invention can be implemented will first be described with respect to . Those skilled in the art will appreciate however that the present invention is not restricted to implementation in this type of media system and that more or fewer components can be included therein. Therein an input output I O bus connects the system components in the media system together. The I O bus represents any of a number of different of mechanisms and techniques for routing signals between the media system components. For example the I O bus may include an appropriate number of independent audio patch cables that route audio signals coaxial cables that route video signals two wire serial lines or infrared or radio frequency transceivers that route control signals optical fiber or any other routing mechanisms that route other types of signals.

In this exemplary embodiment the media system includes a television TV monitor a video cassette recorder VCR digital video disk DVD recorder playback device audio video tuner and compact disk player coupled to the I O bus . The VCR DVD and compact disk player may be single disk or single cassette devices or alternatively may be multiple disk or multiple cassette devices. They may be independent units or integrated together. In addition the media system includes a microphone speaker system video camera and a wireless I O control device . According to exemplary embodiments of the present invention the wireless I O control device is a 3D pointing device according to one of the exemplary embodiments described below. The wireless I O control device can communicate with the entertainment system using e.g. an IR or RF transmitter or transceiver. Alternatively the I O control device can be connected to the entertainment system via a wire.

The entertainment system also includes a system controller . According to one exemplary embodiment of the present invention the system controller operates to store and display entertainment system data available from a plurality of entertainment system data sources and to control a wide variety of features associated with each of the system components. As shown in system controller is coupled either directly or indirectly to each of the system components as necessary through I O bus . In one exemplary embodiment in addition to or in place of I O bus system controller is configured with a wireless communication transmitter or transceiver which is capable of communicating with the system components via IR signals or RF signals. Regardless of the control medium the system controller is configured to control the media components of the media system via a graphical user interface described below.

As further illustrated in media system may be configured to receive media items from various media sources and service providers. In this exemplary embodiment media system receives media input from and optionally sends information to any or all of the following sources cable broadcast e.g. via coaxial cable or optionally a fiber optic cable satellite broadcast e.g. via a satellite dish very high frequency VHF or ultra high frequency UHF radio frequency communication of the broadcast television networks e.g. via an aerial antenna telephone network and cable modem or another source of Internet content . Those skilled in the art will appreciate that the media components and media sources illustrated and described with respect to are purely exemplary and that media system may include more or fewer of both. For example other types of inputs to the system include AM FM radio and satellite radio.

More details regarding this exemplary entertainment system and frameworks associated therewith can be found in the above incorporated by reference U.S. Patent Application Publication No. 2004 0268393 entitled A Control Framework with a Zoomable Graphical User Interface for Organizing Selecting and Launching Media Items . Alternatively remote devices in accordance with the present invention can be used in conjunction with other systems for example computer systems including e.g. a display a processor and a memory system or with various other systems and applications.

As mentioned in the Background section remote devices which operate as 3D pointers are of particular interest for the present specification. Such devices enable the translation of movement e.g. gestures into commands to a user interface. An exemplary 3D pointing device is depicted in . Therein user movement of the 3D pointing can be defined for example in terms of a combination of x axis attitude roll y axis elevation pitch and or z axis heading yaw motion of the 3D pointing device . In addition some exemplary embodiments of the present invention can also measure linear movement of the 3D pointing device along the x y and z axes to generate cursor movement or other user interface commands. In the exemplary embodiment of the 3D pointing device includes two buttons and as well as a scroll wheel although other exemplary embodiments will include other physical configurations as will be specifically described under the heading Up Down Left Right Mode Switching below.

According to exemplary embodiments of the present invention it is anticipated that 3D pointing devices will be held by a user in front of a display and that motion of the 3D pointing device will be translated by the 3D pointing device into output which is usable to interact with the information displayed on display e.g. to move the cursor on the display . For example rotation of the 3D pointing device about the y axis can be sensed by the 3D pointing device and translated into an output usable by the system to move cursor along the yaxis of the display . Likewise rotation of the 3D pointing device about the z axis can be sensed by the 3D pointing device and translated into an output usable by the system to move cursor along the xaxis of the display . It will be appreciated that the output of 3D pointing device can be used to interact with the display in a number of ways other than or in addition to cursor movement for example it can control cursor fading volume or media transport play pause fast forward and rewind . Input commands may include operations in addition to cursor movement for example a zoom in or zoom out on a particular region of a display. A cursor may or may not be visible. Similarly rotation of the 3D pointing device sensed about the x axis of 3D pointing device can be used in addition to or as an alternative to y axis and or z axis rotation to provide input to a user interface.

According to one purely illustrative exemplary embodiment of the present invention two rotational sensors and and one accelerometer can be employed as sensors in 3D pointing device as shown in . Although this exemplary embodiment employs inertial sensors to sense motion it will be appreciated that the present invention is not so limited and examples of other types of sensors which can be used in conjunction with other exemplary embodiments are provided below. The rotational sensors and can for example be implemented using ADXRS150 or ADXRS401 sensors made by Analog Devices. It will be appreciated by those skilled in the art that other types of rotational sensors can be employed as rotational sensors and and that the ADXRS150 and ADXRS401 are purely used as an illustrative example.

Unlike traditional gyroscopes these exemplary rotational sensors use micro electromechanical systems MEMS technology to provide a resonating mass which is attached to a frame so that it can resonate only along one direction. The resonating mass is displaced when the body to which the sensor is affixed is rotated around the sensor s sensing axis. This displacement can be measured using the Coriolis acceleration effect to determine an angular velocity associated with rotation along the sensing axis. If the rotational sensors and have a single sensing axis as for example the ADXRS150s then they can be mounted in the 3D pointing device such that their sensing axes are aligned with the rotations to be measured. For this exemplary embodiment of the present invention this means that rotational sensor is mounted such that its sensing axis is parallel to the y axis and that rotational sensor is mounted such that its sensing axis is parallel to the z axis as shown in .

It will be appreciated that different sensor packages may be available which could lead to other exemplary implementations. For example the two 1 D rotational sensors and could be replaced by a single 2D rotational sensor package which provides outputs of rotational motion along e.g. the y and z axes. One exemplary 2 D rotational sensor is the InvenSense IDG 300 although it will be appreciated that other sensors sensor packages may also be used. The rotational sensors can be 1 D 2 D or 3 D sensors. The accelerometer can for example be a 3 axis linear accelerometer although a 2 axis linear accelerometer could be used by assuming that the device is measuring gravity and mathematically computing the remaining 3value. Additionally the accelerometer s and rotational sensor s could be packaged together into a single sensor package. Other variations of sensors and sensor packages may also be used in conjunction with these exemplary embodiments.

The exemplary embodiments are not limited to the industrial design illustrated in but can instead be deployed in any industrial form factor another example of which is illustrated as . In the exemplary embodiment of the 3D pointing device includes a ring shaped housing two buttons and as well as a scroll wheel and grip although other exemplary embodiments may include other physical configurations. The region which includes the two buttons and and scroll wheel is referred to herein as the control area which is disposed on an outer portion of the ring shaped housing . More details regarding this exemplary embodiment can be found in U.S. patent application Ser. No. 11 480 662 entitled 3D Pointing Devices filed on Jul. 3 2006 the disclosure of which is incorporated here by reference. As will be discussed in more detail below in the section related to UDLR mode switching according to some exemplary embodiments the scroll wheel can be replaced by a different control element e.g. an optical finger navigation OFN device.

Such 3D pointing devices have numerous applications including for example usage in the so called 10 foot interface between a sofa and a television in the typical living room as shown in . Therein as the 3D pointing device moves between different positions that movement is detected by one or more sensors within 3D pointing device and transmitted to the television or associated system component e.g. a set top box not shown . Movement of the 3D pointing device can for example be translated into movement of a cursor displayed on the television and which is used to interact with a user interface. Details of an exemplary user interface with which the user can interact via 3D pointing device can be found for example in the above incorporated U.S. patent application Ser. No. 10 768 432 as well as U.S. patent application Ser. No. 11 437 215 entitled Global Navigation Objects in User Interfaces filed on May 19 2006 the disclosure of which is incorporated here by reference.

One challenge faced in implementing exemplary 3D pointing devices in accordance with these exemplary embodiments is to employ components e.g. rotational sensors and which are not too costly while at the same time providing a high degree of correlation between movement of the 3D pointing devices a user s expectation regarding how the user interface will react to that particular movement of the 3D pointing device and actual user interface performance in response to that movement. For example if the 3D pointing device is not moving the user will likely expect that the cursor ought not to be drifting across the screen. Likewise if the user rotates the 3D pointing device purely around the y axis she or he would likely not expect to see the resulting cursor movement on display contain any significant x axis component. To achieve these and other aspects of exemplary embodiments of the present invention various measurements and calculations are performed e.g. by the 3D pointing devices which are used to adjust the outputs of one or more of the sensors and and or as part of the input used by a processor to determine an appropriate output for the user interface based on the outputs of the sensors and . These measurements and calculations are used to compensate for factors which fall broadly into two categories 1 factors which are intrinsic to the 3D pointing devices e.g. errors associated with the particular sensors and used in the 3D pointing devices or the way in which the sensors are mounted in the 3D pointing devices and 2 factors which are not intrinsic to the 3D pointing devices but are instead associated with the manner in which a user is using the 3D pointing devices e.g. linear acceleration tilt and tremor. Some exemplary techniques for handling these effects are described in the above incorporated by reference 118 patent. Additional techniques e.g. related to handling the bias or offset error contributions to sensed motion are described in Assignee s U.S. Patent Publication No. 2009 0033807 the disclosure of which is also incorporated here by reference.

Sometimes it may also be desirable to provide legacy support in the 3D pointing devices described above or others for devices applications and or software which were designed to receive UDLR inputs as for example selection inputs to a user interface. Exemplary embodiments of the present invention address this desire by providing for mode switching in 3D pointing devices between a 3D pointing mode and an UDLR mode or expressed even more generally between a random access mode and a non random access mode or a between a mode in which a particular control element on a 3D pointing device is operable in a UDLR mode and a non UDLR mode e.g. a scrolling mode.

According to one such exemplary embodiment when a 3D pointing device is interacting with a user interface controlling device e.g. a television a set top box a gaming console or any other such device or an application running on the user interface controlling device which supports 3D pointing inputs then the system i.e. the 3D pointing device and or the user interface controlling device operates in 3D pointing mode. On the other hand when a 3D pointing device is interacting with a user interface controlling device e.g. a television a set top box a gaming console or any other such device or an application running on the user interface controlling device which does not support 3D pointing inputs or which does support or need UDLR inputs then the system i.e. the 3D pointing device and or the user interface controlling device operates in a non 3D pointing mode e.g. an UDLR mode.

Such exemplary embodiments can be implemented in different ways. For example according to one exemplary embodiment the 3D pointing device can be modified to include a mode switching function. In this embodiment after actuating a mode switching control which can be an explicit button or other input on the 3D pointing device or some less explicit control such as a an UDLR gesture which is a pattern of movement by the user holding the 3D pointing device that is recognized by the 3D pointing device as a command to enter UDLR mode or b a series of non UDLR gestures which can be by way of example only a rocking motion of the hand followed by a rolling motion the 3D pointing device will interpret one or more subsequent inputs that it receives from a user either by way of motion of the device operation of a button or movement of the scroll wheel in the exemplary 3D pointing device described above as one of an up down left or right command and will transmit a corresponding UDLR signal or command toward the user interface controlling device. According to a further exemplary embodiment even if a mode switch occurs whether it s from a 3D pointing mode to an UDLR mode or visa versa motions from the original mode can still be interpreted while in the new mode. For example if the 3D pointing device was in a 3D pointing mode and then transitioned to an UDLR mode the 3D pointing device while in the UDLR mode can still interpret some or all of the set of 3D gestures.

According to another exemplary embodiment the user interface controlling device e.g. system controller in or application running on the user interface controlling device can interpret a specific input which it receives from the 3D pointing device as an up down left or right input command. In this exemplary embodiment it may not be necessary to make any changes to the 3D pointing device itself or to perform a mode switching in the 3D pointing device. That is in this particular exemplary embodiment determination of scroll versus UDLR mode is performed in the receiving device i.e. in system controller . In another exemplary embodiment the user interface or application running on the user interface controlling device itself effectuates the mode switch of the 3D pointing device between for example the UDLR and scrolling modes. In this case the operational mode of the 3D pointing device is controlled by the user interface without any explicit action by the user to make said selection. The change between operational modes of the 3D pointing device can occur for example if the entire application or user interface operates in a different operating mode than the 3D pointing device is current to operate in or if one or more portions sub applications of the user interface operates in a different mode that what the 3D pointing device is currently set to operate in.

To support these exemplary embodiments it may be desirable but not necessary to adapt an input control on a 3D pointing device to support UDLR mode switching. For example as shown in instead of the scroll wheel provided to the 3D pointing device of it may be desirable to provide a 3D pointing device with an optical pad which can detect the movement of for example a user s thumb across the optical pad in any desired direction. An example of such an optical pad is an optical finger navigation OFN device such as any of those described in U.S. Patent Publication No. 20090201594 the disclosure of which is incorporated herein by reference. OFN devices sometimes referred to as air lenses operate by illuminating an object e.g. a finger or fingerprint and tracking the object s motion across a surface. As the object moves across the surface motion is detected based on differences between at least two images recorded by an image sensor over a relatively short period of time. According to some embodiments movements of e.g. a finger across an optical pad or OFN device can be referred to as swipe or swiping. For example a left motion of a finger or object across an optical pad or OFN can be referred to as a left swipe and a right movement of the finger or object can be referred to as a right swipe. 

With this input control when in 3D pointing mode or from the point of view of the control element when in scrolling mode an input received via the optical pad can be considered to be for example a scrolling input. Thus either the 3D pointing device the user interface controlling device and or an application running on the user interface controlling device will interpret an input received via the optical control pad as a scrolling input and will scroll the user interface in the indicated direction when operating in 3D pointing mode or scroll mode. By way of contrast when operating in UDLR mode inputs received via optical control pad are interpreted by one or more of the 3D pointing device the user interface controlling device and or an application running on the user interface controlling device as an up down left or right input command. As mentioned above the selection of UDLR mode or non UDLR mode for the 3D pointing device user interface controlling device and or application can be made for example explicitly by the user or implicitly by the system based on e.g. the types of inputs that the application or user interface controlling device is designed to accept.

As a purely illustrative example if a user moves his or her thumb across the optical control pad from the bottom of the pad toward the top of the pad as shown in position A at bottom position B at top this input can be interpreted as a scroll up command when the system is operating in a 3D pointing or scrolling mode. By way of contrast when the system is operating in UDLR mode e.g. due to the execution of an application on the user interface controlling device which only recognizes UDLR commands or some mode switching command then this same input by the user on optical control pad can instead be interpreted as an up command and for example a highlighted region cursor or other focus effect could move up from one displayed interface element to the next highest interface element in an UDLR matrix of displayed elements in response to receipt of information generated based on this input. Correspondingly as shown in there is the scroll down scroll left and scroll right commands. In all of position A is the initial position and position B is the final position. According to a further exemplary embodiment each of can include an optical lens threshold threshold similar to that as discussed in greater detail below in regard to and threshold that would need to be crossed in order to interpret a scroll command i.e. an upper threshold needs to be crossed by the thumb for an upward scroll a lower threshold needs to be crossed by the thumb for a downward scroll and similarly for left and right scrolls .

According to one exemplary embodiment wherein the optical control pad is an OFN module hardware including a lens connected to an OFN driver software as generally shown in the operation can be as follows and is illustrated by a flow chart of method as shown in according to an exemplary embodiment. From idle in step the OFN module polls itself periodically to determine if an object e.g. a finger is covering its lens in decision step . If a finger covers the lens Yes path from decision step the OFN module asserts an interrupt signal toward the OFN driver step . Once this interrupt signal is received the OFN software driver periodically reads data from the OFN module step until the finger or other object is removed from the lens determined by decision step . This data indicates in which direction the finger moved while covering the lens . Once the finger or other object is removed detected in the polling loop No path from decision step the OFN module and OFN driver return to the interrupt driven mode i.e. to decision step .

If the OFN driver is in scroll mode or alternatively 3D pointing mode and based on a mode control input then all of the up or down motion read from the OFN module is reported by the OFN driver as scroll motion toward an application. Left and right motion is ignored according to this exemplary embodiment where horizontal scrolling is not supported but could according to another exemplary embodiment also be reported as scrolling motion if horizontal scrolling on a user interface was a supported navigation. The OFN module can be configured by the OFN driver to produce the desired output for scroll in terms of sensitivity acceleration hysteresis etc. . Thus for example the OFN module may have different hardware and or software configurations for scroll mode versus UDLR mode according to one exemplary embodiment e.g. different ballistics or quantization configurations. Alternatively such OFN configurations may be the same for scroll mode and UDLR mode.

If the OFN driver is instead in UDLR mode i.e. based on a mode control input then the OFN driver accumulates motion in all directions until an optical lens threshold threshold is exceeded in one of the four directions. This threshold can be conceptually envisioned as a virtual box surrounding a center point on the OFN lens. When the moved object exits the virtual box threshold on any side of the box then a corresponding UDLR output is generated. Thus for example once the threshold is exceeded the OFN driver sends according to one exemplary embodiment a keyboard press as an output indicating in which direction the finger was moved i.e. an up down left or right command which corresponds to the direction in which the finger was moved. Until the user removes his finger from the OFN module no other keystrokes are reported according to this exemplary embodiment. For example as seen in a user s thumb begins at position A then is moved from position A to position B. At position B the user s thumb has exceeded the upper part of threshold indicating an up command even though the user s thumb also moved from right to left but did not exceed either of the left or right sides of threshold . Using a device according to this exemplary embodiment it is expected that users will flick or swipe their fingers across the OFN lens in a manner which rapidly and easily surpasses the distance threshold to be interpreted as an UDLR command in the direction of the finger flick. According to further exemplary embodiments other pattern recognition methods can be used to detect the up down left and right movement patterns as well as more complex ones such as circles.

Thus according to one exemplary embodiment motion detected by the OFN module in conjunction with the OFN driver can be interpreted to transmit a message which is determined based on the direction of motion and the mode. As a purely illustrative exemplary embodiment the message sent can be formatted as illustrated in the Table below.

In the afore described exemplary embodiment only one UDLR command is generated per detected motion of an object across the OFN lens . However according to another embodiment it may be possible to detect and generate multiple UDLR commands per motion i.e. without requiring the user to lift his or her finger from the lens. Such an embodiment should consider however potential design challenges. For example if there is sufficient user interface delay associated with updating the displayed position of a cursor or focus condition this may cause accidental overshoot of a selection object target on the user interface which is being interacted with via UDLR commands e.g. displayed on a television since the user might interpret the delay as a failure to exceed the above described distance threshold and would instead send a second repetitive UDLR command.

According to a further exemplary embodiment the size of threshold is variable. Threshold can vary in size in accordance with a size setting determined by a user or the size of threshold can be set to a size of an interface screen of screen elements. Further according to further exemplary embodiments a sensitivity to the size of a user s finger can be varied such that OFN driver would recognize a first user s finger versus that of another. In addition a stylus or other type of pointer device can be used in place of a user s finger to indicate motion on lens . According to further exemplary embodiments if motion by a user s finger or other device in a first direction is determined by OFN driver the rate motion in the same direction can be determined in accordance with rate that the user s finger or device moves on the lens . For example referring to if at time ta user s finger is at position A and moves to position B from the difference in time between tto twill directly or substantially correlate to a rate of motion of the cursor as driven by OFN driver . The same rate of motion applies as those of skill in the art can appreciate to downward movements or leftward and rightward movements or swipes.

Changing a 3D pointing device between scroll mode and UDLR mode can be accomplished in any desired way. According to one exemplary embodiment the OFN driver changes between scroll and UDLR mode depending on whether 3D pointing is enabled or not respectively. That is if device has 3D pointing enabled then mode control input places the OFN driver into scroll mode. Alternatively if 3D pointing is disabled then mode control input places the OFN driver into UDLR mode. Enabling 3D pointing on device can for example involve pressing a button disposed on the device itself or any other desired mechanism can be used to switch modes. However other embodiments may not tie scroll UDLR mode switching to 3D pointing and any desired mechanism can be used to toggle mode control input .

An exemplary state machine for the OFN driver is presented in . The core operating sequence begins with READY state . From that state OFN driver polls the 3D pointer device periodically to see if a finger is covering lens . If a finger covers lens it informs OFN driver by asserting the interrupt signal INT . Once the INT signal is received OFN driver periodically reads data from 3D pointer device until the finger is removed by toggling between the ACCUM WAIT  state and ACCUM state . Once the finger is removed transition occurs and OFN driver returns to READY state unless the operation is being turned off in which case it returns to SHUTDOWN WAIT state .

encoderStop The system tells the OFN driver to stop producing outputs and to go into a low power mode.

ON OFF Responses from the system telling the driver that it has been granted an ON or OFF power level in response to the POWER request.

The Process function performs the high level functions of interpreting the OFN device data as either a scrolling input or UDLR input depending on the operational mode selected described in more detail below or as noise to be ignored. It will be appreciated by those skilled in the art that the state machine of is purely illustrative and that other logic can be used to implement the more general UDLR scroll mode switching described herein.

The illustrative OFN driver includes a mode switch that switches between a scroll mode and a UDLR mode. Depending on whether the system requests scrolling or not via the SL signal OFN driver either processes finger movements on the OFN lens as scrolling commands or as UDLR commands.

If OFN driver is in scroll mode all up or down motion read from OFN lens is reported as scroll motion. Left and right motion according to an exemplary embodiment is either ignored or used for horizontal scroll instead of vertical scroll. OFN module is configured by OFN driver in for example CONFIG  state for the various parameters appropriate for either scrolling or UDLR operation such as sensitivity acceleration hysteresis among others.

If OFN driver is in UDLR mode it accumulates motion in all directions until a threshold is exceeded in one of the 4 directions. According to a further exemplary embodiment there can be more directions such as in and out if desired. Once one of the thresholds is exceeded driver sends the appropriate command indicating which direction the finger was moved either Up Down Left or Right for the 4 direction case. In a further exemplary embodiment until the user removes his finger from OFN lens no other commands are reported. The exemplary embodiments of OFN driver described herein therefore offer several important advantages 

1. Guards against target overshoot by the user falsely interpreting user interface delay as inadequate motion 

2. Adjusts for the varying amounts of motion per stroke that each user assumes is required to move the cursor and

According to studies performed by the inventors the typical user operation was a single flick with the finger per UDLR command a very simple easy and deterministic method of operation since each flick equals a key press or command.

Although OFN technology has been described herein the optical control pad can take any desired form and can detect movement of e.g. a user s thumb using any desired technology. Moreover control pad need not be optical but could be touch sensitive or use any technology which can detect movement of a user s finger thereover to derive an input therefrom.

Having provided a description of UDLR mode switching in exemplary 3D pointing devices according to the afore described exemplary embodiments illustrates an exemplary hardware architecture associated with such 3D pointing devices. Therein a processor communicates with other elements of the 3D pointing device including a flash memory OFN boundary scan cells joint test action group JTAG light emitting diodes LEDs switch matrix infra red IR photo detector rotational sensor s accelerometer and transceiver . The flash memory device can be used by processor to store various programs and or data for use in operating the 3D pointing device e.g. bias estimates as described above. The OFN is an input component which enables a user to provide either UDLR or scroll input to the interface as described above. JTAG provides the programming and debugging interface to the processor. LEDs provide visual feedback to a user for example when a button is pressed. Switch matrix receives inputs e.g. indications that a button on the 3D pointing device has been depressed or released that are then passed on to processor . The optional IR photo detector can be provided to enable the exemplary 3D pointing device to learn IR codes from other remote controls. Rotational sensors provide readings to processor regarding e.g. the y axis and z axis rotation angular rate of the 3D pointing device as described above. Accelerometer provides readings to processor regarding the linear acceleration of the 3D pointing device which can be used e.g. to perform tilt compensation and to compensate for errors which linear acceleration introduces into the rotational readings generated by rotational sensor s . Transceiver is used to communicate information to and from 3D pointing device e.g. to the system controller or to a processor associated with a computer. The transceiver can be a wireless transceiver e.g. operating in accordance with the Bluetooth standards for short range wireless communication or an infrared transceiver. Alternatively 3D pointing device according to these exemplary embodiments can communicate with systems via a wireline connection.

The remote or 3D pointing device can take any desired form and UDLR mode switching according to exemplary embodiments is not limited thereto but can be provided in any device which interacts with applications that may operate in a UDLR mode or a non UDLR mode including e.g. a mobile phone.

Systems and methods for processing data according to exemplary embodiments of the present invention can be performed by one or more processors executing sequences of instructions contained in a memory device. Such instructions may be read into the memory device from other computer readable mediums such as secondary data storage device s . Execution of the sequences of instructions contained in the memory device causes the processor to operate for example as described above. In alternative embodiments hard wire circuitry may be used in place of or in combination with software instructions to implement the present invention. Such software may run on a processor which is housed within the device e.g. a 3D pointing device or other device which contains the sensors or the software may run on a processor or computer housed within another device e.g. a system controller a game console a personal computer etc. which is in communication with the device containing the sensors. In such a case data may be transferred via wireline or wirelessly between the device containing the sensors and the device containing the processor which runs the software which performs the bias estimation and compensation as described above. According to other exemplary embodiments some of the processing described above with respect to UDLR scroll mode switching may be performed in the device containing the sensors while the remainder of the processing is performed in a second device after receipt of the partially processed data from the device containing the sensors.

Although the foregoing exemplary embodiments relate to sensing packages including one or more rotational sensors and an accelerometer bias estimation techniques according to these exemplary embodiments are not limited to only these types of sensors. Instead bias estimation techniques as described herein can be applied to devices which include for example only accelerometer s optical and inertial sensors e.g. a rotational sensor a gyroscope or an accelerometer a magnetometer and an inertial sensor e.g. a rotational sensor a gyroscope or an accelerometer a magnetometer and an optical sensor or other sensor combinations. Additionally although exemplary embodiments described herein relate to bias estimation in the context of 3D pointing devices and applications such techniques are not so limited and may be employed in methods and devices associated with other applications e.g. mobile phones medical applications gaming cameras military applications etc.

Moreover the exemplary processing described herein may be performed in whole or in part either within the 3D pointing device itself or outside of the 3D pointing device. For example raw sensor data can be transmitted to a system processor e.g. within a set top box or a computer wherein it can then be processed to e.g. to update cursor position associated with a cursor displayed on a user interface screen.

The above described exemplary embodiments are intended to be illustrative in all respects rather than restrictive of the present invention. Thus the present invention is capable of many variations in detailed implementation that can be derived from the description contained herein by a person skilled in the art. For example although the foregoing exemplary embodiments describe among other things the use of inertial sensors to detect movement of a device other types of sensors e.g. ultrasound magnetic or optical can be used instead of or in addition to inertial sensors in conjunction with the afore described signal processing. All such variations and modifications are considered to be within the scope and spirit of the present invention as defined by the following claims. No element act or instruction used in the description of the present application should be construed as critical or essential to the invention unless explicitly described as such. Also as used herein the article a is intended to include one or more items.

