---

title: Techniques for managing ternary content-addressable memory (TCAM) resources in heterogeneous systems
abstract: Techniques for managing ternary content-addressable memory (TCAM) in a network device/system are provided. In one embodiment, the network device/system can include one or more TCAMs and can execute a TCAM manager for each TCAM. Each TCAM manager can manage allocation of resources of its associated TCAM, as well as manage access to the TCAM by one or more network applications running on the device/system. In this way, the TCAM managers can hide TCAM implementation differences (e.g., different sizes, different capabilities, etc.) from the network applications and thereby enable the applications to interact with the TCAMs in a uniform manner.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09577932&OS=09577932&RS=09577932
owner: Brocade Communications Systems, Inc.
number: 09577932
owner_city: San Jose
owner_country: US
publication_date: 20141031
---
The present application claims the benefit and priority under 35 U.S.C. 119 e of U.S. Provisional Application No. 61 938 805 filed Feb. 12 2014 entitled A UNIFIED METHOD FOR MANAGING TERNARY CONTENT ADDRESSABLE MEMORY ACROSS HETEROGENEOUS DEVICES. The entire contents of this provisional application are incorporated herein by reference for all purposes.

A ternary content addressable memory TCAM is a type of memory that is commonly incorporated in or packaged with packet processors used by network devices and systems. The packet processors leverage the TCAMs to perform fast lookups of patterns in sent received packets and to apply actions to the packets e.g. drop forward to address X etc. based on the lookups. Some network devices systems referred to herein as homogeneous devices systems make use of packet processors that all have the same type of TCAM. For instance in a homogeneous device system the included TCAMs may all be instances of the same TCAM module designed by the same chip vendor. Other network devices systems referred to herein as heterogeneous devices systems make use of packet processors that have different types of TCAMs. For instance in a heterogeneous device system such as e.g. a mixed stacking system the included TCAMs may correspond to different TCAM modules designed by different chip vendors or different TCAM modules designed by the same chip vendor .

One challenge with managing the different types of TCAMs in a heterogeneous network device system is that the TCAMs may support different memory sizes and or different capabilities. For example consider a stacking system comprising a mixture of high end stackable switches S1 S2 and low end stackable switches S3 S4 S5. Each of these switches includes a TCAM T1 T2 T3 T4 and T5 respectively. In this scenario TCAMs T1 and T2 which correspond to high end stackable switches S1 and S2 may be larger in size that TCAMs T3 T4 and T5 which correspond to low end stackable switches S3 S5 . Alternatively or in addition the capabilities of each TCAM e.g. accessibility method support for hardware priority etc. may differ. This makes it difficult for network applications running on the stacking system to manage and interact with the TCAMs in a uniform manner.

Techniques for managing TCAM resources in a network device system are provided. In one embodiment the network device system can include one or more TCAMs and can execute a TCAM manager for each TCAM. Each TCAM manager can manage allocation of resources of its associated TCAM as well as manage access to the TCAM by one or more network applications running on the device system. In this way the TCAM managers can hide TCAM implementation differences e.g. different sizes different capabilities etc. from the network applications and thereby enable the applications to interact with the TCAMs as if they were identical modules.

The following detailed description and accompanying drawings provide a better understanding of the nature and advantages of particular embodiments.

In the following description for purposes of explanation numerous examples and details are set forth in order to provide an understanding of various embodiments. It will be evident however to one skilled in the art that certain embodiments can be practiced without some of these details or can be practiced with modifications or equivalents thereof.

The present disclosure describes techniques for managing TCAM resources in a network device or system that comprises multiple TCAMs. According to one set of embodiments the network device system can execute a separate TCAM manager for each TCAM of the system. Each TCAM manager is a software component that runs on e.g. a management CPU of the device system and is configured to 1 manage allocation of resources i.e. table space within its associated TCAM and 2 manage access to the TCAM by various network applications security protocols routing protocols etc. running on the device system. By acting as an intermediary layer between the network applications and the TCAMs these TCAM managers can effectively abstract away the hardware implementation of each TCAM e.g. size capabilities etc. and present a uniform TCAM interaction interface to the network applications. This in turn allows the network applications to code their TCAM operations e.g. rule programming rule matching etc. in a unified manner without having to worry about the specific feature set supported by each different type of TCAM.

Embodiments of the present invention are particularly beneficial for heterogeneous network devices systems i.e. devices systems comprising different types of TCAMs such as mixed stacking systems or modular chassis systems. However the techniques described herein may also be applied to homogeneous network devices systems i.e. devices systems comprising a single type of TCAM . In this latter case these techniques can facilitate device system engineering and development for example if the TCAMs in the device system are later replaced within a newer TCAM module in a newer revision no changes will be needed to the application layer that interacts with the TCAMs since they are coded to interact with the generic TCAM managers rather than with an access interface that is specific to a particular TCAM module .

As shown stacking system includes a number of stackable switches N that are communicatively coupled via respective stacking ports N . Although stackable switches N are depicted as forming a ring topology other types of topologies e.g. linear star arbitrary mesh etc. are also possible. Each stackable switch N comprises a management CPU N that is responsible for handling the control plane and management functions of switch N . In addition each stackable switch N comprises a packet processor N that is responsible for handling some or all of the data plane functions of switch N .

To carry out its data plane functions each packet processor N includes a TCAM N which packet processor N leverages for various packet processing purposes. For instance each packet processor N can install rules i.e. entries in its corresponding TCAM for features such as e.g. L3 routing DHCP snooping IP source guard ICMP attack prevention static ACLs dynamic ACLs and so on. Each rule can define an IP subnet or host address as well as an action to take for a packet that matches the subnet host address. Each packet processor N can then process incoming packets e.g. packets that are received via data ports N and or stacking ports N by performing a lookup into its TCAM N for each packet and executing the associated action if a match is made. If no match is made for a given packet packet processor N can take a default action such as dropping the packet or trapping it to management CPU N .

For the purposes of this example it is assumed that TCAMs N are heterogeneous in other words at least one of TCAMs N has a size that is different from the other TCAMs or supports a capability that is not supported by the other TCAMs. For instance TCAM may have more table entries than TCAMs N and or support dynamic hardware based priority or other capabilities while TCAMs N do not. This may occur if e.g. the chipset of packet processor is designed by a different chip vendor than the chipsets of packet processors N or is a different model module designed by the same chip vendor .

As noted in the Background section one difficulty with managing a heterogeneous network system such as stacking system of is that due to the different potential hardware capabilities sizes of TCAMs N the network applications running on the system cannot interact with the TCAMs in a uniform manner. For example if a DHCP snooping application were running on management CPUs N the application would need to be aware of the various different sizes and capabilities of TCAMs N and would need to implement specialized code paths in order to account for these differences when accessing the TCAMs. While this approach may be workable for fixed devices systems it quickly become unpractical in modular systems like stacking system where devices and thus TCAMs can be added and removed from the system on demand.

To address the foregoing and other similar issues each management CPU N of stacking system is configured to execute a novel TCAM manager N one per TCAM N . As described in further detail below TCAM managers N can act as an intermediary or virtualization layer between the network applications of stacking system and TCAMs N thereby hiding the hardware differences of TCAMs N from the applications. For instance if TCAM supports dynamic hardware based priority for rules while TCAMs N do not TCAM managers N can present a single unified TCAM programming interface to the network applications. TCAM managers N can then internally determine how to install rules into their respective TCAMs based on the rule priorities and the hardware capabilities of each TCAM. In this way the network applications can interact with TCAMs N via TCAM managers N as if they are all the same type of TCAM module even though they are not.

Second feature group manager can via a number of rule managers keep track of mappings between the feature groups features and where the rules for those feature groups features are actually installed in the TCAM. For example if there two rules for feature installed at table indices and in the TCAM rule manager can maintain a mapping between feature and indices and . This allows TCAM manager to quickly find all of the rules for a given feature group or feature which can be useful if the rule needs to be deleted or modified. This also allows TCAM manager to share a single rule entry for multiple different ports that may be configured to use the same feature or feature group thereby saving TCAM space .

Index manager works in conjunction with feature group manager and manages the allocation of resources i.e. entries in the TCAM manager s corresponding TCAM. For instance index manager can divide the TCAM space into a number of partitions where each partition is allocated to a feature group determined by feature group manager . This allows TCAM manager to physically segregate the rules for different feature groups which has several benefits. For example TCAM manager can ensure that higher priority feature groups are allocated partitions that have a lower index range than lower priority feature groups thereby ensuring that the rules in the higher priority feature groups are matched first . Further by segregating different feature groups into different TCAM partitions TCAM manager can ensure that the addition or removal of rule s for one feature group will not affect the operation of features in other feature groups since the partitions of those other feature groups will not need to be touched modified.

Section 3 below provides additional details regarding the operation of feature group manager and index manager in a typical workflow.

At block index manager of TCAM manager can initially partition the space in the TCAM based on the feature groups created at block . For example if feature group manager created three feature groups index manager can divide the TCAM into three partitions and assign each feature group to a different partition. In a particular embodiment index manager can assign higher priority feature groups to partitions that have a lower TCAM index range and can assign lower priority feature groups to partitions that have a higher TCAM index range.

At block TCAM manager can expose a number of application programming interfaces APIs to network applications running on the network system for accessing programming the TCAM. As noted previously these APIs can be uniform in nature such that the various TCAM managers in the system will expose the same APIs regardless of the underlying hardware sizes capabilities of their corresponding TCAMs.

Then at block TCAM manager can process API invocations received from the network applications. These API invocations may correspond to e.g. programming a rule for a particular feature modifying a rule or deleting a rule. In the case of programming a rule TCAM manager can determine based on the partitions created by index manager which TCAM partition the rule should be placed in and can install the rule into the determined partition. In the case of modifying or deleting a rule TCAM manager can determine via an appropriate rule manager where i.e. at which hardware index the rule is currently installed. TCAM manager can then modify or delete the rule based on the determined hardware index. Significantly since the rules are partitioned by feature group the addition modification or deletion of a rule in one partition will generally not affect the operation of features in other partitions.

Finally at block index manager can dynamically grow shrink and or move TCAM partitions as needed in order to accommodate new rules. For instance in a scenario where one partition becomes full index manager can grow that partition by a certain number of entries and shrink a neighboring partition. Index manager can also move partitions if they cannot be shrunk. In a particular embodiment index manager can perform these operations using a copy before move paradigm thereby ensuring that there is no traffic loss due to missing TCAM entries while partitions are being modified.

As shown network switch router includes a management module a switch fabric module and a number of I O modules N . Management module represents the control plane of network switch router and includes one or more management CPUs for managing controlling the operation of the device. Each management CPU can be a general purpose processor such as a PowerPC Intel AMD or ARM based processor that operates under the control of software stored in an associated memory not shown .

Switch fabric module and I O modules N collectively represent the data or forwarding plane of network switch router . Switch fabric module is configured to interconnect the various other modules of network switch router . Each I O module N can include one or more input output ports N that are used by network switch router to send and receive data packets. As noted with respect to ports N can comprise stacking ports for communicating with other stackable switches in the same stacking system as well as data ports for communicating with host devices networks. Each I O module N can also include a packet processor N . Packet processor N is a hardware processing component e.g. an FPGA or ASIC that can make wire speed decisions on how to handle incoming or outgoing data packets. Although not shown each packet processor N can include a TCAM like TCAMs N of to facilitate its packet processing functions.

It should be appreciated that network switch router is illustrative and not intended to limit embodiments of the present invention. Many other configurations having more or fewer components than network switch router are possible.

The above description illustrates various embodiments of the present invention along with examples of how aspects of the present invention may be implemented. The above examples and embodiments should not be deemed to be the only embodiments and are presented to illustrate the flexibility and advantages of the present invention as defined by the following claims. For example although certain embodiments have been described with respect to particular process flows and steps it should be apparent to those skilled in the art that the scope of the present invention is not strictly limited to the described flows and steps. Steps described as sequential may be executed in parallel order of steps may be varied and steps may be modified combined added or omitted. As another example although certain embodiments have been described using a particular combination of hardware and software it should be recognized that other combinations of hardware and software are possible and that specific operations described as being implemented in software can also be implemented in hardware and vice versa.

The specification and drawings are accordingly to be regarded in an illustrative rather than restrictive sense. Other arrangements embodiments implementations and equivalents will be evident to those skilled in the art and may be employed without departing from the spirit and scope of the invention as set forth in the following claims.

