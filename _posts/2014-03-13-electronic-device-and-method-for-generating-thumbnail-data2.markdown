---

title: Electronic device and method for generating thumbnail data
abstract: An electronic device includes a first image sensor, a second image sensor, one or more image processing modules, and a display. The first image sensor generates first image data. The second image sensor generates second image data. The one or more image processing modules process one or more image data among the first image and the second image data. The display displays the one or more image data among the first image data or second image data processed by the one or more image processing modules. The thumbnail generation module generates thumbnail data using the one or more image data among the first image data and second image data processed by the one or more image processing modules. A method includes converting the plurality of image data into a format displayable on a display, and generating thumbnail data using the image data of the displayable format.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09635268&OS=09635268&RS=09635268
owner: Samsung Electronics Co., Ltd.
number: 09635268
owner_city: Suwon-si
owner_country: KR
publication_date: 20140313
---
The present application is related to and claims priority under 35 U.S.C. 119 a to a provisional application Ser. No. 61 780 635 filed in the United States Patent and Trademark Office on Mar. 13 2013 and an application No. 10 2014 0025000 filed in the Korean Intellectual Property Office on Mar. 3 2014 the contents of which are herein incorporated by reference.

Various embodiments of the present disclosure relate to a method for processing images and an electronic device thereof.

With the development of Information Telecommunication IT technologies and semiconductor technologies a variety of kinds of electronic devices are evolving into multimedia devices providing various multimedia services. For example a portable electronic device can provide various multimedia services such as a broadcasting service a wireless Internet service a music playing service and the like.

An electronic device can provide various services using one or more images acquired through image sensors. For example the electronic device can perform image processing such as level adjustment noise removal gamma correction color space conversion and the like for image data acquired through the image sensor using an Image Signal Processor ISP and provide various services.

However because the electronic device performs various image processing using one ISP there can be a problem of decreasing a processing speed for image data.

To address the above discussed deficiencies it is a primary object provide an apparatus and method for efficiently processing image data acquired through one or more image sensors in an electronic device.

An embodiment of the present disclosure can provide an apparatus and method for reducing a processing delay of image data acquired through one or more image sensors in an electronic device.

An embodiment of the present disclosure can provide an apparatus and method for efficiently generating thumbnail data about capture image data in an electronic device.

An embodiment of the present disclosure can provide an apparatus and method for generating thumbnail data about capture image data using a processor different from an image processing unit i.e. Image Signal Processor ISP in an electronic device.

An embodiment of the present disclosure can provide an apparatus and method for generating thumbnail data about capture image data using one or more data generated in an image processing unit i.e. ISP in a different processor of an electronic device.

An embodiment of the present disclosure can provide an apparatus and method for interlocking and storing thumbnail data generated using a processor different from an image processing unit i.e. ISP and capture image data in an electronic device.

An embodiment of the present disclosure can provide an apparatus and method for interlocking and storing capture image data and thumbnail data using metadata generated in an image processing unit i.e. ISP in a different processor of an electronic device.

According to an embodiment of the present disclosure an electronic device includes a first image sensor a second image sensor one or more image processing modules a display and a thumbnail generation unit. The first image sensor generates first image data. The second image sensor generates second image data. The one or more image processing modules process one or more image data among the first image and the second image data. The display unit displays the one or more image data among the first image data and second image data processed by the one or more image processing modules. The thumbnail generation module generates thumbnail data using the one or more image data among the first image data and second image data processed by the one or more image processing modules.

According to an embodiment of the present disclosure an electronic device includes one or more processors and a display unit. The one or more processors receive image data process the image data and generate a preview image. The display unit displays the preview image generated by the one or more processors. The one or more processors are configured to generate an image of a smaller size than the preview image using at least part of the preview image in response to a signal corresponding to a capture instruction.

According to an embodiment of the present disclosure an operation method of an electronic device is provided. The method includes the operations of generating a plurality of image data using a plurality of image sensors converting the plurality of image data into a format displayable on a display unit through one or more image processing modules and generating thumbnail data using the image data of the displayable format converted in the image processing modules in a other module separate from the image processing modules.

According to an embodiment of the present disclosure an operation method of an electronic device is provided. The method includes the operations of storing one or more image data converting one or more image data among the one or more image data into a preview image through one or more processors and in response to a signal indicating a capture instruction generating an image of a smaller size than the preview image using at least part of the preview image through the processor.

According to an embodiment of the present disclosure an electronic device includes one or more image sensors and an interface. The one or more image sensors generate image data. The interface processes the image data generated in the one or more image sensors. The interface transmits the image data to one or more modules. The one or more modules change a format of the image data based on an image data processing method of a corresponding module.

Before undertaking the DETAILED DESCRIPTION below it may be advantageous to set forth definitions of certain words and phrases used throughout this patent document the terms include and comprise as well as derivatives thereof mean inclusion without limitation the term or is inclusive meaning and or the phrases associated with and associated therewith as well as derivatives thereof may mean to include be included within interconnect with contain be contained within connect to or with couple to or with be communicable with cooperate with interleave juxtapose be proximate to be bound to or with have have a property of or the like and the term controller means any device system or part thereof that controls at least one operation such a device may be implemented in hardware firmware or software or some combination of at least two of the same. It should be noted that the functionality associated with any particular controller may be centralized or distributed whether locally or remotely. Definitions for certain words and phrases are provided throughout this patent document those of ordinary skill in the art should understand that in many if not most instances such definitions apply to prior as well as future uses of such defined words and phrases.

The expressions such as comprise include can include can comprise or the like usable in the present disclosure indicate the existence of disclosed corresponding function operation constituent element and the like and do not limit additional one or more functions operations constituent elements or the like. Also in the present disclosure it should be understood that terms of comprise include have etc. are to designate the existence of a feature disclosed in the specification a numeral a step an operation a constituent element a part or a combination thereof and do not previously exclude a possibility of existence or supplement of one or more other features numerals steps operations constituent elements parts or combinations thereof.

In the present disclosure the expressions of or and the like include any and all combinations of words arrayed together. For example A or B can include A or can include B or can include all of A and B.

In the present disclosure the expressions of first second and the like can modify various constituent elements of the present disclosure but do not limit the corresponding constituent elements. For example the expressions do not limit the order and or importance and the like of the corresponding constituent elements. The expressions can be used to distinguish one constituent element from another constituent element. For example a first user device and a second user device are all user devices and represent different user devices. For example a first constituent element can be named as a second constituent element without departing from the spirit and scope of the present disclosure. Likely even a second constituent element can be named as a first constituent element.

When it is mentioned that one constituent element is connected or accessed to another constituent element it should be understood that one constituent element can be directly connected or accessed to another constituent element or the third constituent element may exist in between the two constituent elements. In contrast when it is mentioned that one constituent element is directly connected or directly accessed to another constituent element it should be understood that the third constituent element does not exist in between the two constituent elements.

The terms used in the present disclosure are used for just describing specific embodiments and do not intend to limit the spirit and scope of the present disclosure. The expression of singular number includes the expression of plural number unless clearly intending otherwise in a context.

Unless defined otherwise all terms used herein including a technological or scientific term have the same meaning as being commonly understood by a person having ordinary knowledge in the art to which the present disclosure belongs. Terms as in defined in a general dictionary should be interpreted as having a meaning consistent with a contextual meaning of a related technology and are not interpreted as an ideal or excessively formal meaning unless defined clearly in the present disclosure.

An electronic device according to an embodiment of the present disclosure can be a device including a camera function. For example the electronic device can include at least one of a smart phone a tablet Personal Computer PC a mobile phone a video phone an electronic book reader a desktop PC a laptop PC a netbook computer a Personal Digital Assistant PDA a Portable Media Player PMP an MPEG Audio Layer 3 MP3 player a mobile medical instrument a camera and a wearable device e.g. a Head Mount Display HMD such as electronic glasses an electronic clothes an electronic bracelet an electronic necklace an electronic accessory an electronic tattoo or a smart watch .

According to some embodiments the electronic device can be smart electric home appliances with a camera function. For example the smart electric home appliances can include at least one of a television a Digital Versatile Disc DVD player an audio a refrigerator an air conditioner a cleaner an oven a microwave a washing machine an air cleaner a settop box a TV box for example Samsung HomeSyn AppleTV or Google TV a game console an electronic dictionary an electronic locking system a camcorder and an electronic frame.

According to some embodiments the electronic device can include at least one of various medical instruments e.g. Magnetic Resonance Angiography MRA Magnetic Resonance Imaging MRI Computerized Tomography CT a moving camera an ultrasound machine and the like a navigation device a Global Positioning System GPS receiver a vehicle infotainment device a vessel electronic equipment e.g. a vessel navigation device a gyrocompass and the like a flight electronic instrument a security instrument and an industrial or household robot.

According to some embodiments the electronic device can include at least one of part of furniture or building structure with a camera function an electronic board an electronic signature input device a projector and various metering instruments e.g. tap water electricity gas or radio wave metering instrument and the like . The electronic device according to the present disclosure can be one of the aforementioned various devices or a combination of two or more. Also it is obvious to those skilled in the art that the electronic device according to the present disclosure is limited to the aforementioned instruments.

Electronic devices according to various embodiments will be described below with reference to the accompanying drawings. The term of user used in the various embodiments can denote a person who uses an electronic device or a device e.g. a fuzzy electronic device which uses the electronic device.

Below embodiments of the present disclosure describe a technology for processing image data acquired through a plurality of image sensors in an electronic device.

Referring to the electronic device can include a bus a processor a memory an input output interface a display a communication interface an image processing module and an image sensor module .

The bus can be a circuit connecting the aforementioned constituent elements with each other and forwarding a communication signal e.g. a control message between the aforementioned constituent elements.

The processor can receive an instruction from the aforementioned other constituent elements e.g. the memory the input output interface the display the communication interface the image processing module or the image sensor module for example through the bus deciphers the received instruction and execute operation or data processing according to the deciphered instruction.

The memory can store an instruction or data which is received from the processor or the other constituent elements e.g. the input output interface the display the communication interface the image processing module the image sensor module or the like or is generated by the processor or the other constituent elements. The memory can include programming modules of a kernel a middleware an Application Programming Interface API an application or the like. The aforementioned respective programming modules can be composed of software firmware hardware or a combination of at least two or more of them.

The kernel can control or manage system resources e.g. the bus the processor the memory or the like used for executing operations or functions implemented in the remnant other programming modules for example the middleware the API or the application . Also the kernel can provide an interface of enabling the middleware the API or the application to access and control or manage an individual constituent element of an electronic device .

The middleware can perform a relay role of enabling the API or the application to communicate and exchange data with the kernel . Also in relation with work requests received from the application the middleware can perform a control e.g. scheduling or load balancing of the work request using a method of allotting priority order and the like capable of using a system resource e.g. the bus the processor the memory or the like of the electronic device to at least one application among the application for example.

The API which is an interface for enabling the application to control a function provided in the kernel or the middleware can include for example at least one interface or function e.g. an instruction for file control window control image processing character control or the like.

According to various embodiments the application can include a Short Message Service SMS Multimedia Message Service MMS application an electronic mail e mail application a calendar application an alarm application a health care application e.g. an application measuring momentum blood sugar or the like environment information application e.g. an application providing pressure humidity temperature information or the like or the like. Additionally or alternatively the application can be an application related with information exchange between the electronic device and an external electronic device e.g. an electronic device or an electronic device . The application related with the information exchange can include for example a notification forward application for forwarding specific information to the external electronic device or a device management application for managing the external electronic device.

For example the notification forward application can include a function of forwarding to the external electronic device e.g. the electronic device or the electronic device notification information generated in other applications e.g. the SMS MMS application the e mail application the health care application the environment information application or the like of the electronic device . Additionally or alternatively the notification forward application can receive the notification information from the external electronic device e.g. the electronic device or the electronic device and provide the received notification information to a user for example. The device management application can manage e.g. install delete or update a function e.g. turn on turn off of the external electronic device itself or some constituent parts thereof or adjustment of display brightness or resolution of at least a part of the external electronic device e.g. the electronic device or the electronic device communicating with the electronic device an application operating in the external electronic device or a service e.g. a call service or a message service provided in the external electronic device for example.

According to various embodiments the application can include an application designated according to an attribute e.g. kind of the external electronic device e.g. the electronic device or the electronic device . For example when the external electronic device is an MP3 player the application can include an application related with music playing. Similarly when the external electronic device is a mobile medical instrument the application can include an application related with health care. According to one embodiment the application can include at least one of an application designated to the electronic device and an application received from the external electronic device e.g. the server the electronic device or the electronic device .

The input output interface can forward an instruction or data which is inputted from a user through a sensor e.g. an acceleration sensor and a gyro sensor or an input device e.g. a keyboard or a touch screen for example to the processor the memory the communication interface or the image processing module through the bus . For example the input output interface can provide the processor with data about a user s touch inputted through the touch screen. Also the input output interface can output through an output device e.g. a speaker or a display an instruction or data received from the processor the memory the communication interface or the image processing module through the bus for example. For example the input output interface can output voice data which is processed through the processor to a user through the speaker.

The communication interface can connect communication between the electronic device and the external device e.g. the electronic device the electronic device or the server . For example the communication interface can support network communication e.g. the Internet a Local Area Network LAN a Wide Area Network WAN a telecommunication network a cellular network a satellite network a Plain Old Telephone System POTS or the like short range communication e.g. Wireless Fidelity WiFi Bluetooth BT or Near Field Communication NFC and wired communication e.g. a Universe Serial Bus USB a High Definition Multimedia Interface HDMI a Recommended Standard 232 RS 232 a POTS or the like . According to one embodiment a protocol e.g. short range communication protocol network communication protocol or wired communication protocol for communication between the electronic device and the external device can be supported in at least one of the API and the middleware . The electronic devices and each can be the same device e.g. same type device as the electronic device or be a different device e.g. different type device .

The image sensor module can provide image data acquired through subject taking to the image processing module . At this time the image sensor module can include at least one image sensor module functionally connected to the electronic device .

The image processing module can perform image processing for image data provided from the image sensor module or the external electronic devices and . For example the image processing module can perform one or more image processing among level adjustment for image data noise removal gamma correction and conversion into a format displayable on the display . The image processing module can control to store image processed image data in the memory or display the image data on the display . For instance the image processing module can transmit the image data e.g. YUV data displayed on the display and metadata about the corresponding image data to the memory . Here the image processing converting into the format displayable on the display can include color space conversion.

The image processing module can select and synthesize at least two image data among image data acquired through at least one image sensor module . For instance the image processing module can select and synthesize at least two image data using image acquisition time stamps corresponding to the image data or an image processing delay time and the image acquisition time stamps.

For another example when a capture event occurs the image processing module can generate thumbnail data about capture image data using image data e.g. a preview image stored in the memory and metadata about each image data. For instance the image processing module can generate thumbnail data about capture image data using a different module logically or physically separated from a module performing image processing for image data provided from the image sensor module . The thumbnail data can represent image data reducing an image to facilitate search of the corresponding image or such that a user can easily recognize the corresponding image.

Referring to the electronic device can include a processor a memory image sensors to N an input unit input interface and a display unit i.e. a display . Here the processor can include an Application Processor AP .

The processor can decipher an instruction received from one or more other constituent elements e.g. the memory the image sensors to N the display unit and the input unit included in the electronic device and execute operation or data processing according to the deciphered instruction. For example the processor can perform one or more image processing among level adjustment for image data provided from the image sensors to N noise removal gamma correction and conversion into a format displayable on the display unit . The processor can control to store image processed image data in the memory or display the image data on the display unit . For instance the processor can transmit the image data e.g. YUV data displayed on the display unit and metadata about the corresponding image data to the memory . Here the image processing converting into the format displayable on the display unit can include color space conversion.

The processor can execute one or more programs stored in the memory and control the electronic device to provide various multimedia services. For example the processor can execute the program stored in the memory and select and synthesize at least two image data among image data acquired through the image sensors to N. For instance the processor can select and synthesize at least two image data using image acquisition time stamps corresponding to the image data or an image processing delay time and the image acquisition time stamps.

For another example when a capture event occurs the processor can generate thumbnail data about capture image data using image processed image data e.g. a preview image stored in the memory and metadata about each image data. For instance the processor can generate thumbnail data about capture image data using a different module logically or physically separated from a module e.g. ISP performing image processing for image data provided from the image sensors to N.

The memory can store an instruction or data which is received from one or more constituent elements included in the electronic device or is generated by the one or more constituent elements. For example the memory can include an internal memory or an external memory. The internal memory can include at least one of for example a volatile memory e.g. a Dynamic Random Access Memory DRAM a Static Random Access Memory SRAM a Synchronous Dynamic Random Access Memory SDRAM and the like and a nonvolatile memory e.g. One Time Programmable Read Only Memory OTPROM a Programmable Read Only Memory PROM an Erasable PROM EPROM an Electrically Erasable Programmable ROM EEPROM a mask ROM a flash ROM a Not AND NAND flash memory a Not OR NOR flash memory and the like . The external memory can include a flash drive for example at least one of Compact Flash CF Secure Digital SD micro SD xD and a memory stick. The external memory can be functionally connected with the electronic device through various interfaces.

The image sensors to N can provide image data acquired through subject taking to the processor . At this time the image sensors to N can transmit the image data to the processor through a serial interface such as Mobile Industry Processor Interface MIPI and Mobile Display Digital Interface MDDI and a parallel interface such as a parallel bus. Here the first image sensor can be located in front of the electronic device and the Nth image sensor N can be located in rear of the electronic device .

The input unit can transmit an instruction or data inputted by a user to the processor or the memory . For example the input unit can include a touch input unit a pen sensor a key or an ultrasonic wave input device.

The display unit can provide status information of the electronic device a still picture a moving picture or data through a graphical user interface. For example the display unit can display one or more images provided from the processor . For another example the display unit can display at least one image selected based on an image acquisition time stamp or the image acquisition time stamp and an image processing delay time in the processor .

Though not illustrated the electronic device can further include a communication unit capable of connecting communication with other electronic devices or servers through voice communication or data communication. Here the communication unit can be divided into a plurality of communication sub modules supporting different communication networks.

In the aforementioned embodiment the electronic device can include a plurality of image sensors to N. At this time among the plurality of image sensors to N one or more image sensors can be selectively connected to the electronic device . For example among the plurality of image sensors to N the one or more image sensors can be selectively connected to the electronic device through a wired interface. For another example among the plurality of image sensors to N the one or more image sensors can be selectively connected with the electronic device through a wireless interface such as Bluetooth and a wireless LAN.

Referring to the processor can include an image processing unit i.e. Image Signal Processor ISP a display control unit an image generation control unit a thumbnail generation unit and a moving picture generation unit .

The image processing unit can perform one or more image processing among level adjustment for image data provided from respective image sensors to N noise removal gamma correction and color space conversion. The image processing unit can transmit the image processed image data to one or more of the memory and the display control unit . For example the image processing unit can transmit image data e.g. YUV data displayed on the display unit and metadata about the corresponding image data to the memory .

The display control unit can control to provide a graphical user interface through the display unit . For example the display control unit can control to display image data e.g. a preview image provided from the image processing unit or the memory on the display unit . For instance the display control unit can control to display image data provided from the image sensors to N through the image processing unit on the display unit together.

The image generation control unit can select and synthesize at least two image data among image data acquired through the image sensors to N. For example when a capture event occurs the image generation control unit can select and synthesize at least two image data using an image acquisition time stamp of image data stored in the memory or an image processing delay time and the image acquisition time stamp.

The thumbnail generation unit can generate thumbnail data using image processed image data e.g. a preview image stored in the memory or metadata about the respective image data. For example when a capture event occurs the thumbnail generation unit can generate thumbnail data using YUV data of image data stored in the memory and metadata about the corresponding image data. For instance in a case of synthesizing at least two image data acquired through the plurality of image sensors to N and generating capture image data the thumbnail generation unit can synchronize the image data based on a processing delay time of each image data and generate thumbnail data. At this time the thumbnail generation unit can interlock the capture image data and the thumbnail data using an image acquisition time stamp or frame identification information included in the metadata and store the interlock result in the memory .

The moving picture generation unit can encode image processed image data stored in the memory and generate moving picture data. For example the moving picture generation unit can include a video pre processor and a video encoder. The video pre processor can perform pre processing such as zoom rotation color space conversion and flip for the image processed image data stored in the memory and store the pre processing result in the memory . The video encoder encodes the image data pre processed by the video pre processor and stored in the memory according to a preset encoding method and generate the moving picture data.

Though not illustrated the processor can further include a time setting unit capable of setting an image acquisition time stamp to one or more image data provided from the image sensors to N. For example the time setting unit can record a time corresponding to each image data provided from the image sensors to N in metadata of the corresponding image data every frame unit. For another example when there are one or more image sensors selectively connectable to the electronic device among the image sensors to N the time setting unit can set an image acquisition time stamp to metadata of one or more image data provided from one or more image sensors connected to the electronic device . At this time image acquisition time stamps can be set to images acquired through one or more image sensors capable of being selectively connected to the electronic device by a separate module included in each image sensor.

In the aforementioned embodiment the processor can process image data provided from the image sensors to N through one image processing unit .

In another embodiment the processor can include a plurality of image processing units and process image data provided from the respective image sensors to N.

Referring to the electronic device can include a processor a memory image sensors to N external image processing units to N 1 an input unit and a display unit . Here the processor can include an AP.

The processor can decipher an instruction received from one or more other constituent elements e.g. the memory the first image sensor the external image processing units to N 1 the input unit and the display unit included in the electronic device and execute operation or data processing according to the deciphered instruction. For example the processor can perform one or more image processing among level adjustment for image data provided from the first image sensor noise removal gamma correction and conversion into a format displayable on the display unit . The processor can control to store image processed image data in the memory or display the image data on the display unit . For instance the processor can transmit the image data e.g. YUV data displayed on the display unit and metadata about the corresponding image data to the memory . For another instance the processor can control to convert images stored in the memory into the format displayable on the display unit through the external image processing units to N 1 and display the converted images on the display unit . Here the image processing converting into the format displayable on the display unit can include color space conversion.

The processor can execute one or more programs stored in the memory and control the electronic device to provide various multimedia services. For example the processor can execute the program stored in the memory and select and synthesize at least two image data among image data acquired through the image sensors to N. For instance the processor can select and synthesize at least two image data using image acquisition time stamps corresponding to the image data or an image processing delay time and the image acquisition time stamps.

For another example when a capture event occurs the processor can generate thumbnail data about capture image data using image processed image data e.g. a preview image stored in the memory and metadata about each image data. For instance the processor can generate thumbnail data about capture image data using a different module logically or physically separated from an internal module e.g. ISP of the processor performing image processing for image data provided from the first image sensor . At this time the different module can be logically or physically distinguished from the internal module processing an image within the processor or be distinguished physically from the processor .

The memory can store an instruction or data received from one or more constituent elements included in the electronic device or generated by the one or more constituent elements.

The image sensors to N can provide a collected image acquired through subject taking to the processor . At this time the image sensors to N can transmit the image to the processor or the external image processing units to N 1 through a serial interface such as MIPI and MDDI and a parallel interface such as a parallel bus. Here the first image sensor can be located in front of the electronic device and the Nth image sensor N can be located in rear of the electronic device .

The external image processing units to N 1 can control to perform image processing such as level adjustment for images provided from the image sensors to N noise removal and gamma correction and store the processing result in the memory through the processor . Here the external image processing units to N 1 can further include a time setting unit capable of setting an image acquisition time stamp to image data about the images provided from the image sensors to N. For example the time setting unit can record a time corresponding to each image data provided from the image sensors to N in metadata of corresponding image data every frame unit.

The input unit can transmit an instruction or data inputted by a user to the processor or the memory . For example the input unit can include a touch input unit a pen sensor a key or an ultrasonic wave input device.

The display unit can provide status information of the electronic device a still picture a moving picture or data through a graphical user interface. For example the display unit can display one or more image data provided from the processor . For another example the display unit can display at least one image data selected based on an image acquisition time stamp or the image acquisition time stamp and an image processing delay time in the processor .

Though not illustrated the electronic device can further include a communication unit capable of connecting communication with other electronic devices or servers through voice communication or data communication. Here the communication unit can be divided into a plurality of communication sub modules supporting different communication networks.

In the aforementioned embodiment the electronic device can include a plurality of image sensors to N. At this time among the plurality of image sensors to N one or more image sensors can be selectively connected to the electronic device . For example among the plurality of image sensors to N the one or more image sensors can be selectively connected to the electronic device through a wired interface. In this case the external image processing unit connected to the one or more image sensors selectively connectable to the electronic device can be mounted in the electronic device or be selectively connected to the electronic device together with the image sensor.

For another example among the plurality of image sensors to N the one or more image sensors can be selectively connected with the electronic device through a wireless interface such as Bluetooth and a wireless LAN. In this case the external image processing unit connected to the one or more image sensors selectively connectable to the electronic device can be connected to the electronic device or be selectively connected to the electronic device together with the image sensor.

Referring to the processor can include an image processing unit i.e. ISP an internal interface a format change unit a display control unit an image generation control unit a thumbnail generation unit and a moving picture generation unit .

The image processing unit can perform one or more image processing among level adjustment for image data provided from a first image sensor noise removal gamma correction and color space conversion. The image processing unit can transmit the image processed image data to one or more of the memory and the display control unit . For example the image processing unit can transmit image data e.g. YUV data displayed on the display unit and metadata about the corresponding image data to the memory .

The internal interface can transmit to the memory image data provided from respective external image processing units to N 1 . For example the internal interface can include one or more of MIFI and CAMIF.

The format change unit can change image data provided from the external image processing units to N 1 stored in the memory into a format of image data displayable on the display unit . For example the format change unit can color space convert the image data provided from the memory and transmit the image data to the display control unit . For instance the format change unit can control to store in the memory the image data provided from the external image processing units to N 1 changed into the format of the image data displayable on the display unit .

The display control unit can control to provide a graphical user interface through the display unit . For example the display control unit can control to display on the display unit images provided from one or more of the image processing unit and the format change unit . For instance the display control unit can control to display image data provided from the first image sensor provided through the image processing unit and image data of the Nth image sensor N provided through the format change unit on the display unit together.

The image generation control unit can select and synthesize at least two image data among image data acquired through the image sensors to N. For example when a capture event occurs the image generation control unit can select and synthesize at least two image data using an image acquisition time stamp of images stored in the memory or an image processing delay time and the image acquisition time stamp.

The thumbnail generation unit can generate thumbnail data using image processed image data stored in the memory or metadata about the respective image data. For example when a capture event occurs the thumbnail generation unit can generate thumbnail data using YUV data of each image data stored in the memory and metadata about the corresponding image data. For instance in a case of synthesizing at least two image data acquired through the plurality of image sensors to N and generating capture image data the thumbnail generation unit can synchronize the image data based on a processing delay time of each image data and generate thumbnail data. At this time the thumbnail generation unit can interlock the capture image data and the thumbnail data using an image acquisition time stamp or frame identification information included in the metadata and store the interlock result in the memory .

The moving picture generation unit can encode image processed image data stored in the memory and generate moving picture data. For example the moving picture generation unit can include a video pre processor and a video encoder. The video pre processor can perform pre processing such as zoom rotation color space conversion and flip for the image processed image data stored in the memory and store the pre processing result in the memory . The video encoder encodes the image data pre processed by the video pre processor and stored in the memory according to a preset encoding method and generate the moving picture data.

Though not illustrated the processor can further include a time setting unit capable of setting an image acquisition time stamp to image data provided from the first image sensor or the first image sensor and the external image processing units to N 1 . For example the time setting unit can record a time corresponding to image data provided from the first image sensor in metadata of the corresponding image data every frame unit. At this time image acquisition time stamps can be set to the image data acquired through the second image sensor to the Nth image sensor N by the external image processing unit connected to each image sensor.

In the aforementioned embodiment the processor can include the format change unit for changing the image data provided from the external image processing units to N 1 into the format of image data displayable on the display unit .

In another embodiment if the external image processing units to N 1 can change the image data into the format of image data displayable on the display unit the processor can be constructed to exclude the format change unit .

Referring to the electronic device can include a processor memories and image sensors to N external image processing units to N 1 a display unit and an input unit . Here the processor can include an AP.

The processor can decipher an instruction received from one or more other constituent elements included in the electronic device and execute operation or data processing according to the deciphered instruction. For example the processor can perform one or more image processing among level adjustment for image data provided from the first image sensor noise removal gamma correction and conversion into a format displayable on the display unit . The processor can control to store image processed image data in the first memory or display the image data on the display unit . For instance the processor can transmit the image data e.g. YUV data displayed on the display unit and metadata about the corresponding image data to the first memory . Here the image processing converting into the format displayable on the display unit can include color space conversion.

The processor can execute one or more programs stored in the first memory and control the electronic device to provide various multimedia services. For example the processor can execute the program stored in the memory and select and synthesize at least two image data among image data acquired through the image sensors to N. For instance the processor can select and synthesize at least two image data using image acquisition time stamps corresponding to the image data or an image processing delay time and the image acquisition time stamps.

For another example when a capture event occurs the processor can generate thumbnail data about capture image data using image processed image data e.g. a preview image stored in the first memory and metadata about each image data. For instance the processor can generate thumbnail data about capture image data using a different module separate from a module e.g. ISP performing image processing for image data provided from the first image sensor .

The first memory can store an instruction or data received from one or more constituent elements included in the electronic device or generated by the one or more constituent elements.

The image sensors to N can provide an image acquired through subject taking to the processor . At this time the image sensors to N can transmit the image to the processor or the external image processing units to N 1 through a serial interface such as MIPI and MDDI and a parallel interface such as a parallel bus. Here the first image sensor can be located in front of the electronic device and the Nimage sensor N can be located in rear of the electronic device .

The external image processing units to N 1 can control to perform image processing such as level adjustment for image data provided from the image sensors to N noise removal gamma correction and color space conversion and store the processing result in the first memory . Also the external image processing units to N 1 can control to set time information to the image data provided from the image sensors to N and store the image data setting the time information in the second memory . For instance the external image processing units to N 1 can set time information to metadata of corresponding image data.

The second memory can store non processed image data provided from the external image processing units to N 1 . For example the second memory can store raw image data provided from the external image processing units to N 1 . At this time the second memory can exist by each of the external image processing unit or N 1 .

The display unit can provide status information of the electronic device a still picture a moving picture or data through a graphical user interface. For example the display unit can display one or more image data provided from the processor . For another example the display unit can display at least two image data selected based on an image acquisition time stamp or the image acquisition time stamp and an image processing delay time in the processor .

The input unit can transmit an instruction or data inputted by a user to the processor or the first memory . For example the input unit can include a touch input unit a pen sensor a key or an ultrasonic wave input device.

Though not illustrated the electronic device can further include a communication unit capable of connecting communication with other electronic devices or servers through voice communication or data communication. Here the communication unit can be divided into a plurality of communication sub modules supporting different communication networks.

In the aforementioned embodiment the electronic device can include a plurality of image sensors to N. At this time among the plurality of image sensors to N one or more image sensors can be selectively connected to the electronic device . For example among the plurality of image sensors to N the one or more image sensors can be selectively connected to the electronic device through a wired interface. In this case the external image processing unit connected to the one or more image sensors selectively connectable to the electronic device can be mounted in the electronic device or be selectively connected to the electronic device together with the image sensor.

For another example among the plurality of image sensors to N the one or more image sensors can be selectively connected with the electronic device through a wireless interface such as Bluetooth and a wireless LAN. In this case the external image processing unit connected to the one or more image sensors selectively connectable to the electronic device can be connected to the electronic device or be selectively connected to the electronic device together with the image sensor.

Referring to the processor can include an image processing unit i.e. ISP an internal interface a display control unit an image generation control unit a moving picture generation unit and a thumbnail generation unit .

The image processing unit can perform one or more image processing among level adjustment for image data provided from a first image sensor noise removal gamma correction and color space conversion. The image processing unit can transmit the image processed image data to one or more of the first memory and the display control unit . For example the image processing unit can transmit image data e.g. YUV data displayed on the display unit and metadata about the corresponding image data to the first memory .

The internal interface can transmit to the first memory images provided from respective external image processing units to N 1 . For example the internal interface can include one or more of MIFI and CAMIF and RDI for transmitting an image converted into a format displayable on the display unit in the external image processing unit or N 1 .

The display control unit can control to provide a graphical user interface through the display unit . For example the display control unit can control to display on the display unit image data provided from one or more of the image processing unit and the first memory . For instance the display control unit can control to display image data of the first image sensor provided through the image processing unit and image data of the Nth image sensor N acquired from the first memory on the display unit together.

The image generation control unit can select and synthesize at least two image data among image data acquired through the image sensors to N. For example when a capture event occurs the image generation control unit can select and synthesize at least two image data using an image acquisition time stamp of image data stored in the first memory and the second memory or an image processing delay time and the image acquisition time stamp.

The moving picture generation unit can encode image processed image data stored in the first memory and the second memory and generate moving picture data. For example the moving picture generation unit can include a video pre processor and a video encoder. The video pre processor can perform pre processing such as zoom rotation color space conversion and flip for the image data stored in the first memory and the second memory and store the pre processing result in one or more of the first memory and the second memory . The video encoder can encode the image data pre processed by the video pre processor and stored in one or more of the first memory and the second memory according to a preset encoding method and generate the moving picture data.

The thumbnail generation unit can generate thumbnail data using image processed image data e.g. a preview image stored in the first memory or metadata about the respective image data. For example when a capture event occurs the thumbnail generation unit can generate thumbnail data using YUV data of each image data stored in the first memory and metadata about the corresponding image data. For instance in a case of synthesizing at least two image data acquired through the plurality of image sensors to N and generating capture image data the thumbnail generation unit can synchronize the image data based on a processing delay time of each image data and generate thumbnail data. At this time the thumbnail generation unit can interlock the capture image data and the thumbnail data using an image acquisition time stamp or frame identification information included in the metadata and store the interlock result in the first memory .

Though not illustrated the processor can further include a time setting unit capable of setting an image acquisition time stamp to image data provided from the first image sensor or the first image sensor and the external image processing units to N 1 . For example the time setting unit can record a time corresponding to image data provided from the first image sensor in metadata of the corresponding image data every frame unit. At this time image acquisition time stamps can be set to images acquired through the second image sensor to the Nth image sensor N by the external image processing unit connected to each image sensor. For another example the time setting unit can record a time corresponding to image data provided from the external image processing unit N 1 in metadata of the corresponding image data every frame unit. In this case the image generation control unit can select and synthesize at least two images for synthesizing based on an image acquisition time stamp of images stored in the first memory .

Referring to the external image processing unit can include an image processing control unit and a time setting unit .

The image processing control unit can perform one or more image processing among level adjustment for image data provided from the image sensor or N noise removal gamma correction and conversion into a format displayable on the display unit . For example the image processing control unit can color space convert image data of YUV422 provided from the image sensor to N into image data of YUV 420 so as to convert into a format displayable on the display unit .

The image processing control unit can convert one or more image data stored in the second memory into a format displayable on the display unit and transmit the converted image data to the image generation control unit . For example the image processing control unit can receive image data selected for image synthesis from the second memory according to control of the image generation control unit of convert the received image data into the format displayable on the display unit and transmit the converted image data to the image generation control unit . For another example when a capture event occurs the image processing control unit can convert one or more image data among images stored in the second memory into the format displayable on the display unit and transmit the converted image data to the image generation control unit .

The time setting unit can set an image acquisition time stamp to image data provided from the image sensor or N. For example the time setting unit can include a time insertion unit and a frame setting unit and record a time corresponding to the image data provided from the image sensor or N every frame unit.

In the aforementioned embodiment the external image processing unit can include the image processing control unit and the time setting unit . In another embodiment the time setting unit can be located outside the external image processing unit .

Referring to the first memory can be logically or physically divided into a plurality of blocks and to store data. For example image data provided from the image processing unit of the processor can be stored in the third block of the first memory .

The image data provided from the external image processing units to N 1 can be stored in the first block of the first memory . At this time the image data can be divided into Y data UV data and metadata and be stored in internal blocks and in the first block . Here the metadata can include one or more of a frame identifier of image data an image acquisition time stamp focus information and image setting information EXIF .

When a capture event occurs image data stored in the second memory can be stored in the third block of the first memory through the external image processing unit to N 1 .

In the aforementioned embodiment the electronic device can transmit image data generated through an image sensor to each module using a serial interface and a parallel interface. For example an electronic device can transmit the image data generated through the image sensor to each module using a MIPI interface constructed as in below.

Referring to a MIPI interface can include a plurality of lanes according to a format of data. For example the MIPI interface can be composed of a MIPI 4 Lane PHY a MIPI 2 Lane PHY and a MIPI 1 Lane PHY according to a transmission data capacity.

The MIPI interface can transmit image data to a corresponding module through a serial interface e.g. a Camera Serial Interface CSI corresponding to each lane . For example the MIPI 4 Lane PHY can transmit the image data to one or more modules through MIPI CSI 0 and the MIPI 2 Lane PHY can transmit the image data to one or more modules through a MIPI CSI 1 and the MIPI 1 Lane PHY can transmit the image data to one or more modules through a MIPI CSI 2.

The module receiving image data through the MIPI interface can process a format of the image data according to a characteristic of each module. For example a VPE module can perform image processing such as zoom rotation color space conversion and flip for the image data provided through the MIPI interface. A Joint Photographic Experts Group JPEG Decoding DCD module can support a hardware acceleration function necessary for decoding image data of a JPEG format provided through the MIPI interface. A VFE module can apply various effects such as color change to the image data provided through the MIPI interface. An offline JEPG module can support a hardware acceleration function necessary for encoding the image data of the JPEG format provided through the MIPI interface.

When transmitting the image data through the MIPI interface constructed as above an electronic device can use a division transmission method of dividing and transmitting image data due to the limitation of a memory and a transmission capacity of the MIPI interface. For example when transmitting image data of 11 Mega Bytes MB the electronic device can divide the image data of 11 MB into 8 MB data and 3 MB data and transmit the divided image data through the MIPI interface. For instance the electronic device can divide image data of 11 MB into 8 MB data and 3 MB data and store the divided image data as in and transmit the divided image data and through a PIPE method. The memory of the electronic device receiving the data and divided through the MIPI interface can collect the divided data and as one data and store the divided data and in a divided format. As in the electronic device can flexibly set the size e.g. the size of divided data of the memory and the number of division of data. For another example if the electronic device can transmit data of 11 MB at one time through the MIPI interface as in the electronic device can use a preset data capacity e.g. 3 MB among the 11 MB for a preview image and transmit raw image data using the remnant data capacity e.g. 8 MB . In this case the electronic device can transmit the raw image data at one time or divide and transmit the raw image data through the MIPI interface based on the size of the raw image data. For instance if raw image data is 7 MB the electronic device can transmit 3 MB for a preview image and 7 MB for the raw image data at one time through the MIPI interface. If raw image data is 15 MB the electronic device can fixedly use 3 MB for a preview image and divide the raw image data into 8 MB and 7 MB raw image data and transmit the 8 MB and 7 MB raw image data at one time through the MIPI interface over twice. When dividing and transmitting the raw image data the electronic device can combine the divided raw image data into one image using metadata.

According to an embodiment of the present disclosure an electronic device includes a first image sensor a second image sensor one or more image processing modules a display and a thumbnail generation unit. The first image sensor generates first image data. The second image sensor generates second image data. The one or more image processing modules process one or more image data among the first image and the second image data. The display unit displays the one or more image data among the first image data and second image data processed by the one or more image processing modules. The thumbnail generation module generates thumbnail data using the one or more image data among the first image data and second image data processed by the one or more image processing modules.

The one or more image processing modules comprise a first image processing module configured to process the first image data received from the first image sensor a second image processing module configured to process the second image data received from the second image sensor wherein the first image processing module is formed in an Application Processor AP .

The one or more image processing modules are configured to process the one or more image data among the first image data and the second image data and generate one or more preview data of a format displayable on the display and metadata about corresponding image data.

At a capture event the thumbnail generation module is configured to generate thumbnail data about capture image data using one or more among one or more preview data and metadata about corresponding image data generated in the one or more image processing modules.

The electronic device may further comprising a memory wherein the thumbnail generation module is configured to interlock the thumbnail data and the capture image data using an image acquisition time stamp comprised in the metadata or frame identification information and store the interlock result in the memory.

Referring to in step the electronic device can generate image data using a plurality of image sensors. For example the electronic device can generate the image data using a first image sensor located in front of the electronic device and a second image sensor located in rear of the electronic device.

When generating the image data in step the electronic device can convert the image data into a preview format displayable on a display unit. For instance the electronic device can convert the image data into the preview format displayable on the display unit using one or more image processing units i.e. ISPs . For example when referring to the electronic device can convert image data generated through the image sensors to N into a preview format e.g. YUV data displayable on the display unit using the image processing unit . At this time the image processing unit can generate metadata about the image data converted into the preview format displayable on the display unit together and store the image data and the metadata about the image data in the memory . For another example when referring to and the electronic device can convert image data generated through the first image sensor into the preview format e.g. YUV data displayable on the display unit using the image processing unit and convert image data generated through the second image sensor to the Nth image sensor N into the preview format displayable on the display unit using the external image processing units to N 1 . At this time the image processing unit and the external image processing units to N 1 can generate metadata about the image data converted into the preview format displayable on the display unit together and store the image data and the metadata about the image data in one or more memories among the first memory and the second memory . Here the metadata can include one or more of a frame IDentifier ID of the corresponding image data an image acquisition time stamp and image setting information EXIF .

When converting the image data into the preview format displayable on the display unit in step the electronic device can generate thumbnail data about capture image data using the data of the preview format. For instance the electronic device can generate the thumbnail data using a different module separate from the image processing unit. For example when referring to the thumbnail generation unit of the electronic device can generate thumbnail data about capture image data using image data of a preview format and metadata of the corresponding image data stored in the memory . For another example when referring to and the thumbnail generation unit of the electronic device can generate thumbnail data about capture image data using image data of a preview format and metadata of the corresponding image data stored in one or more memories among the first memory and the second memory .

Referring to in step the electronic device can generate image data using a plurality of image sensors. For example the electronic device can generate the image data using a first image sensor located in front of the electronic device and a second image sensor located in rear of the electronic device.

When generating the image data in step the electronic device can convert the image data into a preview format displayable on a display unit. For instance the electronic device can convert the image data into the preview format displayable on the display unit using one or more image processing units i.e. ISPs . At this time the electronic device can store in a memory image data converted into a preview format in one or more image processing units and metadata about the corresponding image data. Here the metadata can include one or more of a frame ID of the corresponding image data an image acquisition time stamp and image setting information EXIF .

When converting the image data into the preview format displayable on the display unit in step the electronic device can display the image data of the preview format on the display unit.

In step the electronic device can determine if a capture event takes place. For example the electronic device can determine if an input of a hardware button corresponding to the capture event is sensed. For another example the electronic device can determine if a selection of an icon corresponding to the capture event is sensed. For further example the electronic device can determine if a user s gesture corresponding to the capture event is sensed.

If the capture event does not take place in step the electronic device can return to step and generate image data using the plurality of image sensors.

If the capture event occurs in step in step the electronic device can generate thumbnail data about capture image data using the image data of the preview format. For example when a first image sensor of a low capacity is located in front of the electronic device and a second image sensor of a high capacity is located in rear thereof the electronic device can use low capacity image data generated through the first image sensor as preview image data displayable on the display unit. The electronic device can convert high capacity image data generated through the second image sensor into a preview format and generate preview image data. According to this when the capture event takes place by a time of a processing delay of the high capacity image data the electronic device can recognize and synthesize as capture image data the low capacity image data corresponding to the preview image data displayed on the display unit at a capture event occurrence time point and the high capacity image data including an image acquisition time stamp corresponding to the capture event occurrence time point. At the time of thumbnail data generation according to the capture event the electronic device can generate thumbnail data by synthesizing preview image data of the low capacity image data displayed on the display unit at the capture event occurrence time point and a preview image for the high capacity image data including the image acquisition time stamp corresponding to the capture event occurrence time stamp. For instance the electronic device can generate the thumbnail data using a different module separate from the image processing unit.

After generating the thumbnail data in step the electronic device can interlock the thumbnail data and the capture image data using metadata of the thumbnail data and store the interlock result. For example the electronic device can interlock the capture image data and the thumbnail data using the image acquisition time stamp or frame identification information included in the metadata used for generating the thumbnail data and store the interlock result in the memory.

According to an embodiment of the present disclosure an operation method of an electronic device is provided. The method includes the operations of generating a plurality of image data using a plurality of image sensors converting the plurality of image data into a format displayable on a display unit through one or more image processing modules and generating thumbnail data using the image data of the displayable format converted in the image processing modules in a other module separate from the image processing modules.

The method may further comprise generating the plurality of image data using the plurality of image sensors connected to the electronic device or connected with the electronic device through a wired interface or a wireless interface.

The method may further include displaying on the display one or more image data among the image data of the displayable format converted in the image processing modules.

The converting into the displayable format include converting first image data generated using a first image sensor among the plurality of image sensors into the format displayable on the display using a first image processing module formed in an Application Processor AP and converting second image data generated using a second image sensor among the plurality of image sensors into the format displayable on the display using a second image processing module formed separately from the AP.

The generating the thumbnail data include the operation of generating the thumbnail data using the image data of the displayable format converted in the first image processing module and the second image processing module in the other module comprised in the AP.

The converting into the displayable format include processing the one or more image data among the plurality of image data using the one or more image processing modules and generating one or more preview data of the format displayable on the display and metadata about corresponding image data.

The generating the thumbnail data include at a capture event generating thumbnail data about capture image data using one or more among the one or more preview data and the metadata about corresponding image data generated in the one or more image processing modules in the other module.

The method may further include interlocking the thumbnail data and the capture image data using an image acquisition time stamp comprised in the metadata or frame identification information and storing the interlock result in a memory.

According to an embodiment of the present disclosure an electronic device includes one or more image sensors and an interface. The one or more image sensors generate image data. The interface processes the image data generated in the one or more image sensors. The interface transmits the image data to one or more modules. The one or more modules change a format of the image data based on an image data processing method of a corresponding module.

The one or more modules comprise one or more of an Image Signal Processor ISP a Video Preprocessing VPE module a Video Front End VFE module and a preview image generation module.

When the format of the image data is changed based on the image data processing methods of the one or more modules the ISP generates metadata comprising information about the format change of the image data.

The metadata comprises one or more of frame identification information of the image data an image acquisition time stamp and image setting information Exchangeable Image File Format EXIF .

The ISP is configured to generate thumbnail data of the image data generated in the one or more image sensors using the metadata.

The interface is configured to divide the image data into a plurality of pieces based on a transmission capacity of the interface and transmit the divided image data to the one ore modules.

Referring to the electronic device can include one or more processors a SIM card a memory a communication module a sensor module an input module a display module an interface an audio module a camera module a power management module a battery an indicator or a motor .

The processor e.g. the processor can include one or more APs or one or more Communication Processors CPs . In it is illustrated that the AP and the CP are included within the processor but the AP and the CP can be included within different IC packages respectively. According to one embodiment the AP and the CP can be included within one IC package.

The AP can drive an operating system or application program and control a plurality of hardware or software constituent elements connected to the AP and can perform processing and operations of various data including multimedia data. The AP can be implemented for example as a System on Chip SoC . According to one embodiment the processor can further include a Graphics Processing Unit GPU not shown .

The CP can perform a function of managing a data link and converting a communication protocol in communication between the electronic device e.g. the electronic device and other electronic devices e.g. the electronic device the electronic device or the server connected to a network. The CP can be implemented for example as an SoC. According to one embodiment the CP can perform at least a part of a multimedia control function. The CP can perform discrimination and authentication of an electronic device within a communication network using a subscriber identity module e.g. the SIM card . Also the CP can provide services of a voice call a video call a text message packet data or the like to a user.

Also the CP can control data transmission reception of the communication module . In constituent elements such as the CP the power management module the memory or the like are illustrated as constituent elements separate from the AP but according to one embodiment the AP can be implemented to include at least some e.g. the CP of the aforementioned constituent elements.

According to one embodiment the AP or the CP can load to a volatile memory an instruction or data received from a nonvolatile memory connected to each or at least one of other constituent elements and process the loaded instruction or data. Also the AP or the CP can store data received from at least one of other constituent elements or generated by at least one of the other constituent elements in the nonvolatile memory.

The SIM card can be a card including the subscriber identity module and can be inserted into a slot provided in a specific location of the electronic device. The SIM card can include unique identification information e.g. an Integrated Circuit Card ID ICCID or subscriber information e.g. International Mobile Subscriber Identity IMSI .

The memory e.g. the memory can include an internal memory or an external memory . The internal memory can include at least one of for example a volatile memory e.g. a DRAM a SRAM a SDRAM and the like and a nonvolatile memory e.g. OTPROM a PROM an EPROM an EEPROM a mask ROM a flash ROM a NAND flash memory a NOR flash memory and the like . According to one embodiment the internal memory can be an SSD. The external memory can further include a flash drive for example CF SD micro SD Mini SD xD a memory stick or the like. The external memory can be functionally connected with the electronic device through various interfaces. According to one embodiment the electronic device can further include a storage device or storage media such as a hard disk.

The communication module e.g. the communication interface can include a wireless communication module or a Radio Frequency RF module . The wireless communication module can include for example WiFi BT GPS or NFC . For example the wireless communication module can provide a wireless communication function using a radio frequency. Additionally or alternatively the wireless communication module can include a network interface e.g. a LAN card a modem or the like for connecting the electronic device with a network e.g. the Internet a LAN a WAN a telecommunication network a cellular network a satellite network a POTS or the like .

The RF module can take charge of transmission reception of data for example transmission reception of an RF signal. The RF module can include though not illustrated a transceiver a Pluggable Authentication Module PAM a frequency filter a Low Noise Amplifier LNA or the like for example. Also the RF module can further include components for transmitting receiving electromagnetic wave on a free space in wireless communication for example a conductor a conductive line or the like.

The sensor module can measure a physical quantity sense an activation state of the electronic device and convert the measured or sensed information into an electrical signal. The sensor module can include for example at least one of a gesture sensor A a gyro sensor B a pressure sensor C a magnetic sensor D an accelerator sensor E a grip sensor F a proximity sensor G a color sensor H e.g. an RGB sensor a biological sensor I a temperature humidity sensor J a light sensor K and a Ultraviolet UV sensor M. Additionally or alternatively the sensor module can include for example an odor sensor not shown an Electromyography EMG sensor not shown an Electroencephalography EEG sensor not shown an Electrocardiograph ECG sensor not shown an Infrared IR sensor not shown an iris sensor not shown a fingerprint sensor not shown or the like. The sensor module can further include a control circuit for controlling at least one or more sensors belonging to therein.

The input module can include a touch panel a digital pen sensor a key or an ultrasonic wave input device . The touch panel can recognize a touch input for example in at least one method among a capacitive method a pressure sensitive method an infrared method and an ultrasonic wave method. Also the touch panel can further include a control circuit. In the capacitive method physical contact or proximity recognition is possible. The touch panel can further include a tactile layer. In this case the touch panel can provide a tactile response to a user.

The digital pen sensor can be implemented for example in the same or similar method as receiving a user s touch input or using a separate recognizing sheet. The key can include for example a physical button an optical key a keypad or a touch key. The ultrasonic wave input device which is a device capable of sensing a sound wave by a microphone e.g. microphone and confirming data in an electronic device enables wireless recognition through an input tool generating an ultrasonic wave signal. According to one embodiment the electronic device can receive a user input from an external device e.g. a network a computer or a server connected to this using the communication module .

The display module e.g. the display can include a panel a hologram or a projector . The panel can be for example a Liquid Crystal Display LCD an Active Matrix Organic Light Emitting Diode AMOLED or the like. The panel can be implemented for example to be flexible transparent or wearable. The panel can be constructed as one module with the touch panel . The hologram can represent a three dimensional image in the air using interference of light. The projector can project light to a screen and display a video. The screen can be located for example inside or outside the electronic device . According to one embodiment the display module can further include a control circuit for controlling the panel the hologram or the projector .

The interface can include for example an HDMI a USB an optical communication terminal or a D subminiature D sub . The interface can include for example the communication interface illustrated in . Additionally or alternatively the interface can include for example Mobile High definition Link MHL not shown Secure Digital Multi Media Card SD MMC not shown or Infrared Data Association IrDA not shown .

The audio module can convert sound and an electric signal interactively. At least some constituent elements of the audio module can be included for example in the input output interface illustrated in . The audio module can process for example sound information inputted or outputted through a speaker a receiver an earphone a microphone or the like.

The camera module is a device capable of taking a still picture and a moving picture. According to one embodiment the camera module can include one or more image sensors e.g. a front sensor or rear sensor a lens not shown an ISP not shown or a flash not shown e.g. an LED or a xenon lamp .

The power management module can manage power of the electronic device . Though not illustrated the power management module can include for example a Power Management Integrated Circuit PMIC a charging Integrated Circuit IC and a battery or fuel gauge.

The PMIC can be mounted for example within an integrated circuit or an SoC semiconductor. A charging method can be divided into wired and wireless. The charging IC can charge a battery and can prevent the inflow of overvoltage or overcurrent from an electric charger. According to one embodiment the charging IC can include a charging IC of at least one of a wired charging method and a wireless charging method. As the wireless charging method there are for example a magnetic resonance method a magnetic induction method an electromagnetic method and the like. The charging IC can be added with a supplementary circuit for wireless charging for example a coil loop a resonance circuit a rectifier circuit or the like.

The battery gauge can measure for example a level of the battery and a charging voltage current or temperature. The battery can store and generate electricity and can supply a power source to the electronic device using the stored or generated electricity. The battery can include for example a chargeable cell or a solar cell.

The indicator can display a specific state of the electronic device or a part thereof for example a booting state a message state a charging state or the like. The motor can convert an electrical signal into a mechanical vibration. Though not illustrated the electronic device can include a processing device e.g. a GPU for mobile TV support. The processing device for mobile TV support can process for example standard media data of Digital Multimedia Broadcasting DMB Digital Video Broadcasting DVB a media flow or the like.

The aforementioned constituent elements of an electronic device according to an embodiment of the present disclosure can be each composed of one or more components and a name of a corresponding constituent element can be different according to the kind of the electronic device. The electronic device according to the present disclosure can include at least one of the aforementioned constituent elements and can omit some constituent elements or further include additional other constituent elements. Also some of the constituent elements of the electronic device according to the present disclosure are combined and constructed as one entity thereby being able to identically perform the functions of the corresponding constituent elements before combination.

As described above embodiments of the present disclosure can improve an image processing speed of an image processing unit i.e. ISP by interlocking thumbnail data generated using a processor different from the image processing unit and capture data and storing the interlock result in an electronic device.

The embodiments of the present disclosure can improve a processing speed for thumbnail data by generating the thumbnail data using metadata generated in the image processing unit in a different processor of an electronic device. Here the metadata can include a frame identifier of image data an image acquisition time stamp focus information image setting information EXIF flash information and the like.

While the present disclosure has been shown and described with reference to certain preferred embodiments thereof it will be understood by those skilled in the art that operations of an electronic device can be changed merged or reused and various changes such as omission and the like can be made therein without departing from the spirit and scope of the present disclosure. Therefore the spirit and scope of the present disclosure should not be limited and defined to the described embodiments and should be defined by not only the appended claims but also equivalents to the appended claims.

