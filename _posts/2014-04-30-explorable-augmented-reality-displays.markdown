---

title: Explorable augmented reality displays
abstract: Concepts and technologies are disclosed herein for explorable augmented reality displays. An augmented reality service can receive a request for augmented reality display data. The request can be associated with a device. The augmented reality service can determine a location associated with the device and identify augmented reality data associated with the location. The augmented reality service can provide augmented reality display data to the device.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09501871&OS=09501871&RS=09501871
owner: AT&T Mobility II LLC
number: 09501871
owner_city: Atlanta
owner_country: US
publication_date: 20140430
---
Virtual reality and augmented reality are two computer technologies for viewing synthetic or partially synthetic environments. Virtual reality generally is used to refer to computer generated representations of various real world or fictitious environments. Virtual reality can be used to generate immersive synthetic environments that users can interact with and or navigate through as if in a real world environment though the virtual reality environment can be fictional. Some embodiments of virtual reality make use of immersive audio and or visual technologies to provide realistic experiences in the virtual environments.

Augmented reality can be used to refer to various types of computer assisted representations of the real world. In particular augmented reality displays sometimes use a photograph or video of a real world environment such as for example a photograph or video of an environment around a smartphone as captured by a camera or other imaging device associated with the smartphone. These images can be supplemented with computer generated information such as tags flags or the like which can be used to denote places of interest or other information within the images. The supplemented information can be provided in some embodiments as an image overlay that provides information about objects viewable in the image.

Because augmented reality displays are sometimes based upon a photograph image or video taken using a device camera the augmented reality displays generally only provide information about objects in a field of vision of the camera or other imaging device used to capture the photograph image or video. To obtain information about objects outside of the camera field of vision a user turns his or her body or at least the device housing the camera toward the objects thereby prompting download and display of augmented reality elements associated with the objects.

The present disclosure is directed to explorable augmented reality displays. The explorable augmented reality displays can be used to provide augmented reality elements relevant to objects within a field of vision of a camera or other image capture device as well as objects outside of a field of vision of the camera of other image capture device. In particular the explorable augmented reality displays can provide an augmented reality display that enables a user or other entity to explore an area around the user by panning the display to access a three hundred sixty degree view of the surroundings from an augmented reality perspective. As such while the actual image or video associated with the three hundred sixty degree view may be unavailable since cameras may be limited to about forty five to sixty degrees of view augmented reality objects for the full three hundred sixty degrees can be provided and explored thereby allowing users to see objects in the environment without turning their bodies and or devices in all three hundred sixty degrees.

As used herein explorable is used to refer to user interfaces that provide a navigable environment for providing information to users. In the context of an augmented reality display for example explorable can refer to rendering augmented reality objects outside of a field of view and allowing users to view those objects without turning their bodies or their devices toward directions in which real world objects associated with the augmented reality objects are located. Furthermore the augmented reality objects outside of the field of view can be downloaded with the objects within the field of view thereby allowing seamless viewing of the objects without having to request and download the objects from a server or service.

According to various embodiments of the concepts and technologies described herein an augmented reality service can be executed by a server computer or other computing device. The augmented reality service can be configured to receive a request for augmented reality data from a user or user device. The request can include or can prompt collection of location data and orientation data associated with a device used to generate the augmented reality views and or the request for augmented reality data. The location data can identify a geographic location of the device and can be obtained directly from the device or from one or more location devices in communication with the server computer. The orientation data can identify a facing direction a direction in which the camera is pointing associated with the device a compass bearing associated with the device a path or vector representing movement or a bearing of the device combinations thereof or the like.

The augmented reality service can determine based upon the location data and the orientation data objects or points of interest in a field of view or vision of the device associated with the request as well as objects or points of interest outside of the field of view or vision. The augmented reality service can query or otherwise perform lookup operations on augmented reality data and identify the relevant augmented reality data. The relevant augmented reality data can be packaged and provided to the device associated with the request as augmented reality display data.

The device associated with the request can execute an augmented reality display application that can obtain the augmented reality display data from the augmented reality service and generate user interface UI elements based upon the augmented reality display data. The user device also can generate and present an explorable augmented reality display that can provide augmented reality elements around a user or user device. Thus a user can access augmented reality data associated with a location or environment without turning his or her body in all three hundred sixty degrees within the environment. Concepts and technologies described herein also support position and or location correction. The position and or location correction can be used to enable augmented reality displays and or explorable augmented reality displays in environments in which exact location information may be difficult to obtain.

According to one aspect of the concepts and technologies described herein a method is disclosed. The method can include receiving at a processor executing an augmented reality service a request for augmented reality display data the request being associated with a device. The method also can include determining at the processor a location associated with the device identifying at the processor augmented reality data associated with the location and providing by the processor augmented reality display data to the device. The augmented reality display data can include the augmented reality data.

In some embodiments determining the location associated with the device can include receiving with the request for the augmented reality display data location data and orientation data associated with the device. The location data and the orientation data can be captured by the device. In some embodiments determining the location associated with the device can include accessing a location device to obtain location data associated with the device. Determining the location associated with the device can include determining a geographic location associated with the device and an orientation associated with the device. The orientation associated with the device can include a facing direction.

In some embodiments the method also can include determining at the processor if the location is to be updated and in response to a determination that the location is to be updated obtaining by the processor a location update from the device. The location update can be provided by the device by presenting a location correction display and receiving an update to the location via the location correction display.

In some embodiments the augmented reality display data can include augmented reality objects corresponding to objects in proximity to the device. The augmented reality display data can include data that when presented by the device in an explorable augmented reality display enables exploration of augmented reality objects outside of a field of view of the device. The augmented reality display data can be provided to the device for presentation in an explorable augmented reality display. In some embodiments the device can include a smartphone. The smartphone can execute an augmented reality display application that generates the request and the explorable augmented reality display.

According to another aspect of the concepts and technologies described herein a system is disclosed. The system can include a processor and a memory. The memory can store computer executable instructions that when executed by the processor cause the processor to perform operations. The operations can include receiving a request for augmented reality display data the request being associated with a device determining a location associated with the device identifying augmented reality data associated with the location and providing augmented reality display data to the device. The augmented reality display data can include the augmented reality data.

In some embodiments determining the location can include determining a geographic location at which the device is located and determining an orientation of the device. The orientation can include a facing direction. In some embodiments determining the location associated with the device can include receiving with the request for the augmented reality display data location data and orientation data associated with the device. In some embodiments the system can include computer executable instructions that when executed by the processor cause the processor to perform operations further including determining if the location is to be updated and in response to a determination that the location is to be updated obtaining a location update from the device. The augmented reality display data can be provided to the device for presentation in an explorable augmented reality display.

According to another aspect of the concepts and technologies described herein a computer storage medium is disclosed. The computer storage medium can have computer executable instructions stored thereon that when executed by a processor cause the processor to perform operations. The operations can include receiving a request for augmented reality display data the request being associated with a device determining a location associated with the device identifying augmented reality data associated with the location and providing augmented reality display data to the device. The augmented reality display data can include the augmented reality data.

In some embodiments determining the location can include determining a geographic location at which the device is located and determining an orientation of the device. The orientation can include a facing direction. In some embodiments determining the location associated with the device can include obtaining location data and orientation data associated with the device. The computer storage medium also can include computer executable instructions that when executed by the processor cause the processor to perform operations further including determining if the location is to be updated and in response to a determination that the location is to be updated obtaining a location update from the device. The augmented reality display data can be provided to the device for presentation in an explorable augmented reality display.

Other systems methods and or computer program products according to embodiments will be or become apparent to one with skill in the art upon review of the following drawings and detailed description. It is intended that all such additional systems methods and or computer program products be included within this description be within the scope of this disclosure.

The following detailed description is directed to explorable augmented reality displays The explorable augmented reality displays can be used to provide augmented reality elements relevant to objects within a field of vision of a camera or other image capture device as well as objects outside of a field of vision of the camera of other image capture device. Thus the concepts and technologies described herein can be used to provide a user with access to augmented reality information in an environment without requiring the user or device to turn in each direction of the environment. Thus augmented reality objects for three hundred sixty degrees around a device can be provided and explored.

According to various embodiments of the concepts and technologies described herein an augmented reality service can be executed by a server computer or other computing device. The augmented reality service can be configured to receive a request for augmented reality data from a user or user device. The augmented reality service can determine a location associated with the request. In some embodiments location data and or orientation data can be included with the request while in some other embodiments the augmented reality service can collect the location data and or orientation data from other devices systems or nodes. The location data can identify a geographic location of the device and the orientation data can identify a facing direction a direction in which the camera is pointing associated with the device a compass bearing associated with the device a path or vector representing movement or a bearing of the device combinations thereof or the like.

The augmented reality service can determine based upon the location data and the orientation data objects or points of interest in a field of view or vision of the device associated with the request as well as objects or points of interest outside of the field of view or vision. The augmented reality service can provide the relevant augmented reality data to the device associated as augmented reality display data. The device can obtain the augmented reality display data from the augmented reality service and generate user interface elements based upon the augmented reality display data. The device also can generate and present an explorable augmented reality display that can provide augmented reality elements around a user or user device. Thus a user can access augmented reality data associated with a location or environment without turning his or her body or the device in all three hundred sixty degrees within the environment. Concepts and technologies described herein also support position and or location correction. The position and or location correction can be used to enable augmented reality displays and or explorable augmented reality displays in environments in which exact location information may be difficult to obtain.

While the subject matter described herein is presented in the general context of program modules that execute in conjunction with the execution of an operating system and application programs on a computer system those skilled in the art will recognize that other implementations may be performed in combination with other types of program modules. Generally program modules include routines programs components data structures and other types of structures that perform particular tasks or implement particular abstract data types. Moreover those skilled in the art will appreciate that the subject matter described herein may be practiced with other computer system configurations including hand held devices multiprocessor systems microprocessor based or programmable consumer electronics minicomputers mainframe computers and the like.

Referring now to aspects of an operating environment for various embodiments of the concepts and technologies disclosed herein for explorable augmented reality displays will be described according to an illustrative embodiment. The operating environment shown in includes a user device operating in communication with and or as part of a communications network network .

According to various embodiments the functionality of the user device may be provided by one or more server computers desktop computers mobile telephones laptop computers set top boxes other computing systems and the like. It should be understood that the functionality of the user device can be provided by a single device by two or more similar devices and or by two or more dissimilar devices. For purposes of describing the concepts and technologies disclosed herein the user device is described herein as a smartphone. It should be understood that this embodiment is illustrative and should not be construed as being limiting in any way.

The user device can execute an operating system and one or more application programs such as for example an augmented reality display application . The operating system is a computer program for controlling the operation of the user device . The augmented reality display application is an executable program configured to execute on top of the operating system to provide the functionality described herein for providing explorable virtual reality displays.

In particular the augmented reality display application can be configured to generate and present an explorable augmented reality display and to support various interactions between a user or other entity and the explorable augmented reality display . In some embodiments the explorable augmented reality display can be presented to a user or other entity associated with the user device though this is not necessarily the case. In particular as generally is understood an augmented reality display can include a user interface overlay or other user interface elements that can be used to supplement a view of an environment. For example if the user device passes into or through an environment such as the location or environment location environment shown in an augmented reality display such as the explorable augmented reality display can be used to overlay a captured photograph or video with information about the location or environment. Thus an entity such as a user can view the explorable augmented reality display to learn information about the environment such as for example points of interest sites historical information businesses combinations thereof or the like.

The augmented reality display application can be configured to capture video or other imagery at or near the user device and to obtain augmented reality information that can be used to supplement the display of the imagery. In some embodiments the augmented reality display application can be configured to generate user interface UI elements and present the UI elements in the explorable augmented reality displays . Furthermore the augmented reality display application can be configured to support location and or position correction which are illustrated and described in more detail below particularly with reference to . These and other functions of the augmented reality display application will be further described below.

According to various embodiments the user device can communicate with an augmented reality service . According to various embodiments the augmented reality service can include a server application or module executed or hosted by a computing device such as a server computer . According to some embodiments the augmented reality service can be a callable service that can be configured to generate augmented reality display data and to provide the augmented reality display data to the user device . In some embodiments the augmented reality service can provide the augmented reality display data in response to a request or call from the user device such as for example an augmented reality display data request .

In particular the augmented reality service can receive an augmented reality display data request from the user device . The augmented reality service can determine a location and orientation associated with the user device in response to receiving the augmented reality display data request in some embodiments. In some other embodiments the augmented reality display data request can include an indication of the location and orientation of the user device . Thus for example the augmented reality display data request can include a geographic location that can be determined by the user device for example using a global positioning system GPS receiver and or other location determination hardware and or software. The augmented reality display data request also can indicate an orientation of the user device for example a direction to which the user device is facing. The direction can be determined for example based upon a bearing of the user device and or various sensors such as magnetometers accelerometers gyroscopes combinations thereof or the like.

In some other embodiments the augmented reality service can be configured to obtain location information associated with the user device . Thus for example the augmented reality service can communicate with a location device such as for example a location server a location beacon or other location determination hardware and or software to determine the location of the user device . In some embodiments the location device also can determine or obtain a bearing facing direction and or other orientation information associated with the user device . In some contemplated embodiments the location device can include a location server of a cellular network which can determine location using GPS triangulation SSID information of WiFi hotspots in a proximity of the user device combinations thereof or the like.

In some embodiments the functionality of the location device can be supplemented and or replaced by various application programming interfaces APIs . In particular the augmented reality service can access call and or receive information from various location services and or APIs associated with location services and or software. Contemplated examples include but are not limited to a location service or API provided by a member of the AT T family of products from AT T Inc. a member of the GOOGLE family of products from Google Inc a member of the APPLE family of products from Apple Company a member of the MICROSOFT family of products from Microsoft Corporation and or other location services and or APIs It should be understood that these examples are illustrative and therefore should not be construed as being limiting in any way.

According to various embodiments the augmented reality service can analyze the augmented reality display data request and a location and orientation associated with the user device to identify data to be provided to the user device for presentation in an explorable augmented reality display . In various embodiments the augmented reality service can access augmented reality data and identify relevant portions of the augmented reality data based upon the augmented reality display data request and or the location and orientation determined for the user device .

In various embodiments the augmented reality data can be stored in a data storage device such as a data store or the like. According to various embodiments the augmented reality data can be stored with data or other information that associates the augmented reality data with various locations. The augmented reality data can be stored in a table database or other data structure that can support querying and or other lookup operations. As such the augmented reality data can be searched according to various aspects of the augmented reality data and the augmented reality service can identify relevant augmented reality data based upon various aspects of the augmented reality data including but not limited to location user permissions preferences facing direction or the like. The augmented reality service can be configured to control storage of the augmented reality data in some embodiments though this is not necessarily the case.

The augmented reality service can therefore be configured to receive the augmented reality display data request determine a location and orientation associated with the requestor and or included in the augmented reality display data request and access the augmented reality data to identify augmented reality data relevant to the requestor. The augmented reality service can package the relevant data and transmit the relevant data to the user device or other requestor as the augmented reality display data . In some embodiments the orientation of the requestor is not obtained and instead the user device can determine what data to show first in the explorable augmented reality display based upon the orientation.

Upon receiving the augmented reality display data the user device can via execution of the augmented reality display application and or other application programs generate the explorable augmented reality display . As will be explained in more detail below the explorable augmented reality display can include an augmented reality display that shows tags or other UI elements for indicating points of interest businesses sites or the like. The explorable augmented reality display also can include tags or other UI elements that are outside a current view of the augmented reality display. Thus for example a user facing north can via manipulation of the explorable augmented reality display view tags or other UI elements associated with points of interest located to the south of the user. These aspects of the concepts and technologies described herein will be easier understood with reference to below.

Various embodiments of the concepts and technologies described herein can be used to allow users to view points of interest and or other information relevant to an environment using augmented reality without being required to turn their bodies and or facing direction of devices to capture video or photographs in all directions. Thus embodiments of the concepts and technologies described herein can improve a user experience when using augmented reality in various environments and or in low light conditions by obviating the need to turn around to see points of interest in the explorable augmented reality display . These and other aspects of the concepts and technologies described herein will be easier understood with reference to below.

Turning now to aspects of a method for providing augmented reality data to a device will be described in detail according to an illustrative embodiment. It should be understood that the operations of the methods disclosed herein are not necessarily presented in any particular order and that performance of some or all of the operations in an alternative order s is possible and is contemplated. The operations have been presented in the demonstrated order for ease of description and illustration. Operations may be added omitted and or performed simultaneously without departing from the scope of the concepts and technologies disclosed herein.

It also should be understood that the methods disclosed herein can be ended at any time and need not be performed in its entirety. Some or all operations of the methods and or substantially equivalent operations can be performed by execution of computer readable instructions included on a computer storage media as defined herein. The term computer readable instructions and variants thereof as used herein is used expansively to include routines applications application modules program modules programs components data structures algorithms and the like. Computer readable instructions can be implemented on various system configurations including single processor or multiprocessor systems minicomputers mainframe computers personal computers hand held computing devices microprocessor based programmable consumer electronics combinations thereof and the like.

Thus it should be appreciated that the logical operations described herein are implemented 1 as a sequence of computer implemented acts or program modules running on a computing system and or 2 as interconnected machine logic circuits or circuit modules within the computing system. The implementation is a matter of choice dependent on the performance and other requirements of the computing system. Accordingly the logical operations described herein are referred to variously as states operations structural devices acts or modules. These states operations structural devices acts and modules may be implemented in software in firmware in special purpose digital logic and any combination thereof. As used herein the phrase cause a processor to perform operations and variants thereof is used to refer to causing a processor of a computing system or device such as the user device or the server computer to perform one or more operations and or causing the processor to direct other components of the computing system or device to perform one or more of the operations.

For purposes of illustrating and describing the concepts of the present disclosure the method is described as being performed by the server computer via execution of one or more software modules such as for example the augmented reality service . It should be understood that additional and or alternative devices and or network nodes can provide the functionality described herein via execution of one or more modules applications and or other software including but not limited to the augmented reality service . Thus the illustrated embodiments are illustrative and should not be viewed as being limiting in any way.

The method begins at operation . At operation the server computer receives a request for augmented reality display data . In some embodiments the request received in operation can include an augmented reality display data request . The augmented reality display data request can be triggered for example by activation at the user device of an option to present an augmented reality display. In some embodiments the request is generated by starting an application by accessing a camera application by selecting an explicit option to present an augmented reality display combinations thereof or the like. In various embodiments of the concepts and technologies described herein the augmented reality display data request can be generated by the user device in response to detecting execution of an application to present an explorable augmented reality display . It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

From operation the method proceeds to operation . At operation the server computer determines a location associated with the request received in operation . In some embodiments as explained above the server computer can upon receiving the request in operation access one or more location devices to determine a location associated with the user device . In addition to providing location the location devices also can provide orientation information relating to the user device . The orientation information can reflect for example a compass bearing of the user device a direction path or vector of movement of the user device a facing direction associated with the user device combinations thereof or the like. Some or all of these orientation data can be obtained from the user device by the location device and or the server computer . In some embodiments as noted above the orientation data may not be obtained by the server computer and instead can be obtained at the device and used to customize an initial display of the explorable augmented reality display . It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

In some other embodiments the location data and or the orientation data can be included in the request received in operation . As used herein location data can refer to data that identifies a geographic location. The location data can include for example GPS coordinates or other data that identifies a location. As used herein orientation data can include for example a compass bearing direction or path of movement a movement vector a facing direction combinations thereof or the like. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

From operation the method proceeds to operation . At operation the server computer can determine if the location determined in operation is to be updated. In some embodiments the concepts and technologies described herein can be used to provide explorable augmented reality displays inside buildings and or elsewhere where an accurate geographic location may not be available. For example if the concepts and technologies described herein are used to generate the explorable augmented reality display within a museum or other indoor space GPS coordinates may be unavailable due to GPS shadow. Thus the concepts and technologies described herein support presenting a user interface for allowing a user to update a location. The server computer also can determine that location is to be updated for additional or alternative reasons and as such the above examples are illustrative and should not be construed as being limiting in any way.

According to various embodiments the user can update the location using a display generated by the augmented reality display application . As such the display used to update or correct location can be based upon the location of various tags or other augmented reality display UI elements. Thus for example if a user facing north knows that a first item ItemA is located to his or her north and that a second item ItemB is located to his or her south the user can indicate his or her present location relevant to ItemA and ItemB via manipulating representations on a display. One contemplated embodiment of the UI for updating a location is illustrated and described below with reference to . Because the location can be updated in additional and or alternative ways it should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

If the server computer determines at operation that the location is to be updated the method proceeds to operation . At operation the server computer can obtain a location update. In some embodiments as described above the server computer can instruct the user device to obtain a location update for example via a UI as illustrated and described herein. In other embodiments the server computer can contact one or more location devices such as location beacons within an environment or location to determine an updated location associated with the user device . Because the location can be updated in additional and or alternative ways it should be understood that these examples are illustrative and therefore should not be construed as being limiting in any way.

If the server computer determines at operation that the location is not to be updated the method proceeds to operation . The method also can proceed to operation from operation . At operation the server computer can identify augmented reality data associated with the location determined in operations and or . As explained above the server computer can access the augmented reality data via lookup operations and or other database or table operations to identify relevant and or associated augmented reality data . The augmented reality data can be determined to be associated with the location based upon various data associations and or analyses by the augmented reality service as generally is understood and therefore will not be further described herein.

From operation the method proceeds to operation . At operation the server computer provides augmented reality display data to the requestor associated with the request received in operation . In the context of operation can correspond to the server computer providing the augmented reality display data to the user device though this is not necessarily the case. Although not separately illustrated in it should be understood that operation can include the server computer packaging the augmented reality data identified in operation and providing the data to the user device or other requestor. As such the augmented reality display data can be provided to the user device as a single download thereby obviating the need to download augmented reality display data when the device is turned or otherwise manipulated to face an area outside of a previous field of vision. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

Turning now to aspects of a method for requesting and presenting an explorable augmented reality display at a device will be described in detail according to an illustrative embodiment. For purposes of illustrating and describing the concepts of the present disclosure the method is described as being performed by the user device via execution of one or more software modules such as for example the augmented reality display application . It should be understood that additional and or alternative devices and or network nodes can provide the functionality described herein via execution of one or more modules applications and or other software including but not limited to the augmented reality display application . Thus the illustrated embodiments are illustrative and should not be viewed as being limiting in any way.

The method begins at operation . At operation the user device determines a location. The user device also can determine its orientation in some embodiments though this is not necessarily the case. According to various embodiments the user device can periodically determine its location and or orientation. In some other embodiments the user device can determine its location and or orientation based upon a request to display an augmented reality display or an explorable augmented reality display . In the embodiment shown in the user device can be configured to determine its location and or orientation based upon a request for an explorable augmented reality display . The request can be an explicit request or an implicit request.

In particular the request can correspond to an explicit request such as a selection of a UI element to present an explorable augmented reality display . In some other embodiments the request can correspond to an implicit request such as for example activation of the augmented reality display application . Thus in operation the user device can detect a user request for an explorable augmented reality display and as a result can determine a location and or orientation. Because the location and or orientation can be determined in response to other triggers or events it should be understood that these examples are illustrative and therefore should not be construed as being limiting in any way.

From operation the method proceeds to operation . At operation the user device generates an augmented reality display data request . The augmented reality display data request can include data identifying the location and or orientation determined in operation and can request augmented reality display data . The user device can transmit the augmented reality display data request to the server computer or another device system or node. In the embodiment shown in the user device transmits the augmented reality display data request to the augmented reality service executed by the server computer . It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

The augmented reality display data request can request data relevant and or associated with the location and or orientation determined in operation . The augmented reality display data request therefore can be used to obtain augmented reality display data that can be presented by the user device in the explorable augmented reality display .

From operation the method proceeds to operation . At operation the user device obtains augmented reality display data . According to various embodiments of the concepts and technologies described herein the user device can receive the augmented reality display data as a response to the augmented reality display data request though this is not necessarily the case. In some other embodiments the user device can be configured to obtain the augmented reality display data by accessing a server or other device that can serve the relevant data. Because the augmented reality display data can be obtained in additional and or alternative ways it should be understood that these examples are illustrative and therefore should not be construed as being limiting in any way.

From operation the method proceeds to operation . At operation the user device generates UI elements. The UI elements generated in operation can correspond to various UI elements of the explorable augmented reality display . The user device can generate the UI elements based upon the augmented reality display data received in operation .

The UI elements generated in operation can include for example tags flags text photographs icons and or other UI elements for presentation within or as the explorable augmented reality display . In addition to generating UI elements such as overlay elements with tags flags or the like for a visible field of view within the explorable augmented reality display the user device also can generate UI elements that are outside of the visible field of view within the explorable augmented reality display .

In particular for example if the user device is facing north and is presenting within the explorable augmented reality display a field of view of about sixty degrees any points of interest or other objects located to the south of the user device would generally not be visible in the current view of the explorable augmented reality display . According to various embodiments of the concepts and technologies described herein however the user device can generate UI elements associated with the points of interest and or other objects located around the user device thereby enabling exploration within the explorable augmented reality display . Thus some embodiments of the concepts and technologies described herein include rendering UI elements around three hundred sixty degrees around the user device though this is not necessarily the case.

In particular various embodiments of the concepts and technologies described herein allow a user facing north to input a command to view objects located to his or her south or other direction outside of a current visible field of view without turning his or her body or device to face that direction. For example a user can select a UI control to explore in one or more directions enter a swipe command on a touch screen and or enter other types of input to view UI elements associated with portions of the location or environment outside of the visible field of view of the explorable augmented reality display . Thus for example a user facing north can swipe to the right in the explorable augmented reality display to view UI elements associated with points of interest or other objects located to the east south west north and or points between. Thus a user may not need to turn his or her body or device to these directions to determine points of interest or other objects in those directions. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

From operation the method proceeds to operation . At operation the user device can provide the explorable augmented reality display . Thus the user device can present the explorable augmented reality display on a display device or otherwise output the explorable augmented reality display . Operation also can include various manipulations within the explorable augmented reality display by the user and display of UI elements by the user device in response to these manipulations. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

From operation the method proceeds to operation . At operation the user device can determine if the location determined in operation is to be updated. In some embodiments operation can correspond to a user selection of a UI control for updating location. In some other embodiments operation can correspond to the user device determining based upon data received from the server computer and or based upon other information that the location is to be updated. In some embodiments the user selects an option to update location and in response thereto the user device can present a UI to update location. One example embodiment of the UI for updating location is illustrated and described below with reference to . It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

If the user device determines in operation that the location is to be updated the method can proceed to operation . In operation the user device can obtain updated location information. As noted above operation can correspond to presentation of a UI for updating location and or receiving data via that UI and receipt via the UI of updated location information. From operation the method can proceed to operation and the user device can obtain augmented reality display data associated with the updated location. Although not shown in it should be understood that the user device can be configured to generate a new augmented reality display data request after receiving updated location data. Such may be the case where the location is adjusted such that that the available augmented reality display data is insufficient to provide UI elements at the updated location. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

If the user device determines in operation that the location is not to be updated the method can proceed to operation . The method ends at operation .

The screen display A can include various menus and or menu options not shown in . The screen display A also can include camera view display or window camera display . The camera display can correspond to a current view of a location or environment as viewed through a camera or other capture device associated with the user device . Thus the camera display can correspond to a part of a viewable location or environment from the perspective of the user device and or a user associated with the user device.

It should be appreciated that the screen display A can be presented for example in response to receiving activation of the camera or other capture device at the user device activation of the augmented reality display application or the like. Because the screen display A illustrated in can be displayed at additional and or alternative times it should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

The camera display can include a UI control . Selection of the UI control can cause the user device to obtain augmented reality display data and or to present the augmented reality display data in an explorable augmented reality display . Because the camera display can include additional or alternative UI controls it should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

It can be appreciated from the above description of that selection of the UI control can cause the user device to generate an augmented reality display data request and or to obtain the augmented reality display data . Selection of the UI control also can cause the device to obtain or determine its location and or to capture orientation data as explained above. Because additional and or alternative actions can be taken in response to selection of the UI control it should be understood that these embodiments are illustrative and should not be construed as being limiting in any way.

The screen display A shown in also includes a viewing direction and viewing scope indicator viewing direction indicator . The viewing direction indicator can display information that indicates a pointing direction. The pointing direction can inform a user or other entity as to a direction in which the user is facing and or a scope of view included in the displayed view. As shown in the viewing direction indicator can include a viewing scope and direction cone view cone . The view cone can schematically illustrate a scope or amount for example in degrees of a three hundred sixty degree radius about the user or other entity that is visible in the screen display A. Thus a user or other entity can via reference to the viewing direction indicator and the view cone determine a direction in which the user or other entity is facing west in the illustrated embodiment and a relative scope of view that is visible to the user or other entity approximately fifteen degrees in the illustrated embodiment .

In some other embodiments a compass readout and or display can be included in the screen display A. Thus for example hash marks corresponding to degrees of a compass and or directions of a compass can be displayed on the screen display A in addition to or instead of the viewing direction indicator and or the view cone . Because a user s pointing direction and or a scope of view can be illustrated in various other ways it should be understood that the illustrated example is illustrative and therefore should not be construed as being limiting in any way. Additional iterations of the viewing direction indicator and or the viewing cone are illustrated and described below and therefore will be further understood with reference to .

Referring now to a UI diagram showing additional aspects of the concepts and technologies disclosed herein for providing explorable augmented reality displays using an augmented reality service are described in detail. In particular shows an illustrative screen display B generated by a device such as the user device . It should be appreciated that the UI diagram illustrated in is illustrative of one contemplated example of the UIs that can be generated and or displayed in accordance with the concepts and technologies disclosed herein and therefore should not be construed as being limited in any way.

The screen display B can include an explorable augmented reality display . The explorable augmented reality display can be used to present one or more explorable augmented reality displays to a user or other entity. It can be appreciated that the explorable augmented reality display can be presented in response to a user selecting the UI control shown in . Because the explorable augmented reality display can be displayed at additional and or alternative times it should be understood that this embodiment is illustrative and should not be construed as being limiting in any way.

The explorable augmented reality display can include a view of the location or environment as seen through the camera or other imaging device associated with the user device as explained above with reference to . The explorable augmented reality display also can include flags tags or other UI elements tags . The tags can provide information about items or objects within a current field of view of the camera or other imaging device. It should be understood that the camera or other imaging device can capture photographs or video depending upon preferences settings and or needs. The tags can provide information about items within a view. In some embodiments the tags can include labels for the items or objects as well as distance and or direction information if desired. In various other embodiments the tags can include data indicating if the item or object is free to see or access business hours associated with a business or institution other information or the like.

The explorable augmented reality display also can include a UI control for exploring within the explorable augmented reality display . Thus selection of the UI control can cause the user device to present augmented reality UI elements outside of the current field of view as explained above in detail. According to various embodiments the UI control can include a scroll bar cursors or arrows that can be tapped or otherwise manipulated and or a region of the display within which swipes or other gestures can be recognized as commands to explore the explorable augmented reality display . It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

Referring now to a UI diagram showing additional aspects of the concepts and technologies disclosed herein for providing explorable augmented reality displays using an augmented reality service are described in detail. In particular shows an illustrative screen display C generated by a device such as the user device . It should be appreciated that the UI diagram illustrated in is illustrative of one contemplated example of the UIs that can be generated and or displayed in accordance with the concepts and technologies disclosed herein and therefore should not be construed as being limited in any way.

The screen display C can include a manipulated view of the explorable augmented reality display shown in . The manipulated view can be presented in response to a user manipulating the UI control shown in . In particular as shown in the user can enter a swipe gesture along the UI control to present the manipulated view . Because the manipulated view can be displayed at additional and or alternative times it should be understood that this embodiment is illustrative and should not be construed as being limiting in any way.

The manipulated view can include a partial view of the environment or location as seen through the camera or other imaging device associated with the user device as explained above with reference to . As shown in an active view can effectively be panned off the visible portion of the screen and instead a void can be displayed on the screen display C. The void can correspond to a portion of the explorable augmented reality display that is outside of the field of view of the camera or other capture device. Thus the void can be blank or empty as shown in other than tags or other UI elements associated with the location corresponding to the void .

As can be seen in a new tag can be displayed on the manipulated view . The new tag can point off the visible screen and therefore can indicate to a user or other entity manipulating the explorable augmented reality display that a point of interest is located in the direction indicated in the new tag .

The new tag can provide information about items or objects outside of the current field of view of the camera or other imaging device. It should be understood that the camera or other imaging device can capture photographs or video depending upon preferences settings and or needs. In some embodiments the new tag also can include a label distance information direction information and or other information. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

In it can be appreciated that the viewing direction indicator can be updated as the user or other entity manipulates the screen display C. As shown in the viewing direction indicator also can include a current view scope and direction indicator current view cone in addition to or instead of the viewing direction indicator . The current view cone can indicate a direction and or scope of the environment that corresponds to the view depicted within the screen display C. Thus a user or other entity can via reference to the viewing direction indicator the view cone and the current view cone understand a relative movement between the view shown in the screen display A and a subsequent view such as the view shown in the screen display C. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

Referring now to a UI diagram showing additional aspects of the concepts and technologies disclosed herein for providing explorable augmented reality displays using an augmented reality service are described in detail. In particular shows an illustrative screen display D generated by a device such as the user device . It should be appreciated that the UI diagram illustrated in is illustrative of one contemplated example of the UIs that can be generated and or displayed in accordance with the concepts and technologies disclosed herein and therefore should not be construed as being limited in any way.

The screen display D can include another manipulated view of the explorable augmented reality display shown in and therefore can represent further manipulation of the manipulated view shown in . The manipulated view can be presented in response to a user further manipulating the UI control shown in . Because the manipulated view can be displayed at additional and or alternative times it should be understood that this embodiment is illustrative and should not be construed as being limiting in any way.

As can be seen in the manipulated view can omit a view of the environment or location as seen through the camera or other imaging device associated with the user device as these portions of the environment location can be outside of the portion of the virtual environment represented by the manipulated view . Thus it can be appreciated that the active view can effectively be panned off the visible portion of the screen and instead only the void can be displayed. Thus the void can be blank or empty as shown in other than the new tags or other UI elements associated with the location corresponding to the void .

As can be seen in the new tags can be displayed on the manipulated view . The new tags can point off the visible screen and therefore can indicate to a user or other entity that points of interest associated with the new tags are located in the direction indicated in the new tags . The new tags can provide information about items or objects outside of the current field of view of the camera or other imaging device. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

As shown in the current view cone has again been updated to show the current viewing direction and or scope depicted within the screen display D. Thus a user or other entity can via reference to the viewing direction indicator the view cone and the current view cone understand a relative movement between the view shown in the screen display A and or C and a subsequent view such as the view shown in the screen display D. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

Referring now to a UI diagram showing additional aspects of the concepts and technologies disclosed herein for providing explorable augmented reality displays using an augmented reality service are described in detail. In particular shows an illustrative screen display E generated by a device such as the user device . It should be appreciated that the UI diagram illustrated in is illustrative of one contemplated example of the UIs that can be generated and or displayed in accordance with the concepts and technologies disclosed herein and therefore should not be construed as being limited in any way.

The screen display E can include yet another manipulated view of the explorable augmented reality display shown in and therefore can represent further manipulation of the manipulated view shown in . The manipulated view can be presented in response to a user further manipulating the UI control shown in . Because the manipulated view can be displayed at additional and or alternative times it should be understood that this embodiment is illustrative and should not be construed as being limiting in any way.

As can be seen in the manipulated view can correspond to a point at which the new tags are centered within the void though this is not necessarily the case. The new tags can point to points within the void and therefore can indicate to a user or other entity that the points of interest associated with the new tags are located in a portion of the environment or location that corresponds to the void . It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

The manipulated view also can include a UI control for activating a live scan. Selection of the UI control can cause the user device to activate a camera or other imaging device so that a user can view an augmented display view corresponding to the void . Thus in some embodiments the user can turn his or her body and or the user device to point in the direction of the location environment that corresponds to the void and then select the UI control to view a captured image of the location environment in that direction. An example is shown in .

As shown in the current view cone has again been updated to show the current viewing direction and or scope depicted within the screen display E. Thus a user or other entity can via reference to the viewing direction indicator the view cone and the current view cone understand a relative movement between the view shown in the screen display A C and or D and a subsequent view such as the view shown in the screen display E. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

Turning now to a UI diagram showing additional aspects of the concepts and technologies disclosed herein for providing explorable augmented reality displays using an augmented reality service are described in detail. In particular shows an illustrative screen display F generated by a device such as the user device . It should be appreciated that the UI diagram illustrated in is illustrative of one contemplated example of the UIs that can be generated and or displayed in accordance with the concepts and technologies disclosed herein and therefore should not be construed as being limited in any way.

The screen display F can include another explorable augmented reality display . The explorable augmented reality display can be presented in response to a user selecting the UI control shown in . Because the explorable augmented reality display can be displayed at additional and or alternative times it should be understood that this embodiment is illustrative and should not be construed as being limiting in any way.

As can be seen in the explorable augmented reality display can provide the new tags shown in but can show these new tags as overlays on a video or photo of the real location or environment. Although the new tags are shown in their correct relationship relative to the sculptures shown in it is possible that UI elements such as tags flags or the like can be displayed at locations that do not match the real world elements to which they relate.

In particular if the augmented reality display application is used indoors or at other locations at which obtaining exact geolocation is difficult or impossible the tags or other UI elements may be displayed at locations that do not match the real world elements. This can be for example because the expected or estimated location of the user device may not accurately reflect the real location and as such tags that are estimated to be in front of the user device may in fact be behind the user device and or vice versa. As such embodiments of the concepts and technologies described herein support user interfaces and technologies for updating or correcting position for the explorable augmented reality displays and or for other reasons.

Thus the screen display F also includes a UI control for correcting a position or location of the user device relative to the location or environment. Upon selection of the UI control the user device can be configured to present a UI for adjusting location and or position or can take other actions to update location. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

As shown in the viewing direction indicator and the view cone have been updated to show the current viewing direction and or scope depicted within the screen display F. Thus a user or other entity can via reference to the viewing direction indicator and the view cone understand a relative movement and or facing direction change between the views shown in the screen displays A C D or E and a subsequent view and or pointing direction such as the view and pointing direction depicted in the screen display F. It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

Referring now to a UI diagram showing additional aspects of the concepts and technologies disclosed herein for providing explorable augmented reality displays using an augmented reality service are described in detail. In particular shows an illustrative screen display G generated by a device such as the user device . It should be appreciated that the UI diagram illustrated in is illustrative of one contemplated example of the UIs that can be generated and or displayed in accordance with the concepts and technologies disclosed herein and therefore should not be construed as being limited in any way.

The screen display G can include a location correction display . The location correction display can be used to correct a location or position of a user device or user relative to one or more augmented reality elements such as tags or the like. It should be appreciated that the location correction display can be presented in response to a user selecting the UI control shown in . Because the location correction display can be displayed at additional and or alternative times it should be understood that this embodiment is illustrative and should not be construed as being limiting in any way.

The location correction display can include a view of the location or environment in which the user or user device is located. In some embodiments the location correction display includes a plan view showing representations of the augmented reality tags or elements in the location or environment and an indicator of current location of the user device within that location or environment. As such the user or other entity can see a relationship between the augmented reality tags or elements and a location of the user or user device and can be given the opportunity to correct the position and or location of the user or user device .

As shown in the location correction display can include icons . The icons can correspond to relative positions of objects in the real world relative to the current estimated or known location of the user device that are included in the augmented reality display data upon which the explorable augmented reality display is based. It should be understood that the icons can be replaced and or supplemented with flags tags or the like and that the illustrated embodiment is merely illustrative of the concepts and technologies described herein. Also the location correction display can include an estimated or known location indicator which can correspond to a known or estimated location of the user device . Again it should be understood that this embodiment is illustrative and therefore should not be construed as being limiting in any way.

In some embodiments the user can adjust his or her location or position relative to the icons by knowing his or her location in the real world and adjusting the location of the estimated or known location indicator based upon that knowledge. For example the user or other entity may know that a real world object that corresponds to the icon labeled is actually located behind the user or other entity while in the location correction display the icon labeled is shown in front of the user or other entity. Thus the user or other entity can adjust the location of the estimated or known location indicator to correct this error as shown collectively in .

In particular shows a user or other entity tapping the estimated or known location indicator and dragging the estimated or known location indicator along a path to a new location . In the icons are shown in their corrected locations relative to the corrected location of the estimated or known location indicator . As shown in the location correction display also can include a UI control for accepting a location or position correction. In some embodiments selection of the UI control can accept the changes and also can communicate to the server computer the location correction as illustrated and described above with reference to operations and of . It should be understood that these examples are illustrative and therefore should not be construed as being limiting in any way.

It should be understood that the camera or other imaging device can capture photographs or video depending upon preferences settings and or needs. The tags can provide information about items within view. In some embodiments the tags can include labels for the items or objects as well as distance and or direction information if desired. In various other embodiments the tags can include data indicating if the item or object is free to see or access business hours associated with a business or institution other information or the like.

The location correction display also can include a UI control for exploring within the location correction display . Thus selection of the UI control can cause the user device to present UI elements outside of the current field of view as explained above in detail. According to various embodiments the UI control can include a scroll bar cursors or arrows that can be tapped or otherwise manipulated and or a region of the display within which swipes or other gestures can be recognized as commands to explore the location correction display . It should be understood that this example is illustrative and therefore should not be construed as being limiting in any way.

Turning now to additional details of the network are illustrated according to an illustrative embodiment. The network includes a cellular network a packet data network for example the Internet and a circuit switched network for example a publicly switched telephone network PSTN . The cellular network includes various components such as but not limited to base transceiver stations BTSs Node B s or e Node B s base station controllers BSCs radio network controllers RNCs mobile switching centers MSCs mobile management entities MMEs short message service centers SMSCs multimedia messaging service centers MMSCs home location registers HLRs home subscriber servers HSSs visitor location registers VLRs charging platforms billing platforms voicemail platforms GPRS core network components location service nodes an IP Multimedia Subsystem IMS and the like. The cellular network also includes radios and nodes for receiving and transmitting voice data and combinations thereof to and from radio transceivers networks the packet data network and the circuit switched network .

A mobile communications device such as for example a cellular telephone a user equipment a mobile terminal a PDA a laptop computer a handheld computer and combinations thereof can be operatively connected to the cellular network . The cellular network can be configured as a 2G GSM network and can provide data communications via GPRS and or EDGE. Additionally or alternatively the cellular network can be configured as a 3G UMTS network and can provide data communications via the HSPA protocol family for example HSDPA EUL also referred to as HSUPA and HSPA . The cellular network also is compatible with 4G mobile communications standards as well as evolved and future mobile standards.

The packet data network includes various devices for example servers computers databases and other devices in communication with another as is generally known. The packet data network devices are accessible via one or more network links. The servers often store various files that are provided to a requesting device such as for example a computer a terminal a smartphone or the like. Typically the requesting device includes software a browser for executing a web page in a format readable by the browser or other software. Other files and or data may be accessible via links in the retrieved files as is generally known. In some embodiments the packet data network includes or is in communication with the Internet. The circuit switched network includes various hardware and software for providing circuit switched communications. The circuit switched network may include or may be what is often referred to as a plain old telephone system POTS . The functionality of a circuit switched network or other circuit switched network are generally known and will not be described herein in detail.

The illustrated cellular network is shown in communication with the packet data network and a circuit switched network though it should be appreciated that this is not necessarily the case. One or more Internet capable devices for example a PC a laptop a portable device or another suitable device can communicate with one or more cellular networks and devices connected thereto through the packet data network . It also should be appreciated that the Internet capable device can communicate with the packet data network through the circuit switched network the cellular network and or via other networks not illustrated .

As illustrated a communications device for example a telephone facsimile machine modem computer or the like can be in communication with the circuit switched network and therethrough to the packet data network and or the cellular network . It should be appreciated that the communications device can be an Internet capable device and can be substantially similar to the Internet capable device . In the specification the network is used to refer broadly to any combination of the networks . It should be appreciated that substantially all of the functionality described with reference to the network can be performed by the cellular network the packet data network and or the circuit switched network alone or in combination with other networks network elements and the like.

The processing unit may be a standard central processor that performs arithmetic and logical operations a more specific purpose programmable logic controller PLC a programmable gate array or other type of processor known to those skilled in the art and suitable for controlling the operation of the server computer. As used herein the word processor and or the phrase processing unit when used with regard to any architecture or system can include multiple processors or processing units distributed across and or operating in parallel in a single machine or in multiple machines. Furthermore processors and or processing units can be used to support virtual processing environments. Processors and processing units also can include state machines application specific integrated circuits ASICs combinations thereof or the like. Because processors and or processing units are generally known the processors and processing units disclosed herein will not be described in further detail herein.

The memory communicates with the processing unit via the system bus . In some embodiments the memory is operatively connected to a memory controller not shown that enables communication with the processing unit via the system bus . The memory includes an operating system and one or more program modules . The operating system can include but is not limited to members of the WINDOWS WINDOWS CE and or WINDOWS MOBILE families of operating systems from MICROSOFT CORPORATION the LINUX family of operating systems the SYMBIAN family of operating systems from SYMBIAN LIMITED the BREW family of operating systems from QUALCOMM CORPORATION the MAC OS iOS and or LEOPARD families of operating systems from APPLE CORPORATION the FREEBSD family of operating systems the SOLARIS family of operating systems from ORACLE CORPORATION other operating systems and the like.

The program modules may include various software and or program modules described herein. In some embodiments for example the program modules include the augmented reality service and or the augmented reality display application not shown in . This and or other programs can be embodied in computer readable media containing instructions that when executed by the processing unit perform one or more of the methods described in detail above with respect to . According to some embodiments the program modules may be embodied in hardware software firmware or any combination thereof. Although not shown in it should be understood that the memory also can be configured to store the explorable augmented reality display the augmented reality display data the augmented reality data and or other data if desired.

By way of example and not limitation computer readable media may include any available computer storage media or communication media that can be accessed by the computer system . Communication media includes computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any delivery media. The term modulated data signal means a signal that has one or more of its characteristics changed or set in a manner as to encode information in the signal. By way of example and not limitation communication media includes wired media such as a wired network or direct wired connection and wireless media such as acoustic RF infrared and other wireless media. Combinations of the any of the above should also be included within the scope of computer readable media.

Computer storage media includes volatile and non volatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Computer storage media includes but is not limited to RAM ROM Erasable Programmable ROM EPROM Electrically Erasable Programmable ROM EEPROM flash memory or other solid state memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the computer system . In the claims the phrase computer storage medium and variations thereof does not include waves or signals per se and or communication media.

The user interface devices may include one or more devices with which a user accesses the computer system . The user interface devices may include but are not limited to computers servers personal digital assistants cellular phones or any suitable computing devices. The I O devices enable a user to interface with the program modules . In one embodiment the I O devices are operatively connected to an I O controller not shown that enables communication with the processing unit via the system bus . The I O devices may include one or more input devices such as but not limited to a keyboard a mouse or an electronic stylus. Further the I O devices may include one or more output devices such as but not limited to a display screen or a printer.

The network devices enable the computer system to communicate with other networks or remote systems via a network such as the network . Examples of the network devices include but are not limited to a modem a radio frequency RF or infrared IR transceiver a telephonic interface a bridge a router or a network card. The network may include a wireless network such as but not limited to a Wireless Local Area Network WLAN such as a WI FI network a Wireless Wide Area Network WWAN a Wireless Personal Area Network WPAN such as BLUETOOTH a Wireless Metropolitan Area Network WMAN such a WiMAX network or a cellular network. Alternatively the network may be a wired network such as but not limited to a Wide Area Network WAN such as the Internet a Local Area Network LAN such as the Ethernet a wired Personal Area Network PAN or a wired Metropolitan Area Network MAN .

Turning now to an illustrative mobile device and components thereof will be described. In some embodiments the user device described above with reference to can be configured as and or can have an architecture similar or identical to the mobile device described herein in . It should be understood however that the user device may or may not include the functionality described herein with reference to . While connections are not shown between the various components illustrated in it should be understood that some none or all of the components illustrated in can be configured to interact with one other to carry out various device functions. In some embodiments the components are arranged so as to communicate via one or more busses not shown . Thus it should be understood that and the following description are intended to provide a general understanding of a suitable environment in which various aspects of embodiments can be implemented and should not be construed as being limiting in any way.

As illustrated in the mobile device can include a display for displaying data. According to various embodiments the display can be configured to display various graphical user interface GUI elements for explorable augmented reality displays text images video virtual keypads and or keyboards messaging data notification messages metadata internet content device status time date calendar data device preferences map and location data combinations thereof and or the like. The mobile device also can include a processor and a memory or other data storage device memory . The processor can be configured to process data and or can execute computer executable instructions stored in the memory . The computer executable instructions executed by the processor can include for example an operating system one or more applications such as the augmented reality display application the augmented reality service other computer executable instructions stored in a memory or the like. In some embodiments the applications also can include a UI application not illustrated in .

The UI application can interface with the operating system such as the operating system shown in to facilitate user interaction with functionality and or data stored at the mobile device and or stored elsewhere. In some embodiments the operating system can include a member of the SYMBIAN OS family of operating systems from SYMBIAN LIMITED a member of the WINDOWS MOBILE OS and or WINDOWS PHONE OS families of operating systems from MICROSOFT CORPORATION a member of the PALM WEBOS family of operating systems from HEWLETT PACKARD CORPORATION a member of the BLACKBERRY OS family of operating systems from RESEARCH IN MOTION LIMITED a member of the IOS family of operating systems from APPLE INC. a member of the ANDROID OS family of operating systems from GOOGLE INC. and or other operating systems. These operating systems are merely illustrative of some contemplated operating systems that may be used in accordance with various embodiments of the concepts and technologies described herein and therefore should not be construed as being limiting in any way.

The UI application can be executed by the processor to aid a user in entering content capturing video or photographs providing augmented reality views correcting position and or location configuring settings manipulating address book content and or settings multimode interaction interacting with other applications and otherwise facilitating user interaction with the operating system the applications and or other types or instances of data that can be stored at the mobile device . The data can include for example the augmented reality data the augmented reality display data and or other applications or program modules. According to various embodiments the data can include for example presence applications visual voice mail applications messaging applications text to speech and speech to text applications add ons plug ins email applications music applications video applications camera applications location based service applications power conservation applications game applications productivity applications entertainment applications enterprise applications combinations thereof and the like. The applications the data and or portions thereof can be stored in the memory and or in a firmware and can be executed by the processor . The firmware also can store code for execution during device power up and power down operations. It can be appreciated that the firmware can be stored in a volatile or non volatile data storage device including but not limited to the memory and or a portion thereof.

The mobile device also can include an input output I O interface . The I O interface can be configured to support the input output of data such as location information selection of UI controls orientation information user information organization information presence status information user IDs passwords and application initiation start up requests. In some embodiments the I O interface can include a hardwire connection such as a universal serial bus USB port a mini USB port a micro USB port an audio jack a PS port an IEEE 1394 FIREWIRE port a serial port a parallel port an Ethernet RJ port an RJ port a proprietary port combinations thereof or the like. In some embodiments the mobile device can be configured to synchronize with another device to transfer content to and or from the mobile device . In some embodiments the mobile device can be configured to receive updates to one or more of the applications via the I O interface though this is not necessarily the case. In some embodiments the I O interface accepts I O devices such as keyboards keypads mice interface tethers printers plotters external storage touch multi touch screens touch pads trackballs joysticks microphones remote control devices displays projectors medical equipment e.g. stethoscopes heart monitors and other health metric monitors modems routers external power sources docking stations combinations thereof and the like. It should be appreciated that the I interface may be used for communications between the mobile device and a network device or local device.

The mobile device also can include a communications component . The communications component can be configured to interface with the processor to facilitate wired and or wireless communications with one or more networks such as the network described herein. In some embodiments other networks include networks that utilize non cellular wireless technologies such as WI FI or WIMAX. In some embodiments the communications component includes a multimode communications subsystem for facilitating communications via the cellular network and one or more other networks.

The communications component in some embodiments includes one or more transceivers. The one or more transceivers if included can be configured to communicate over the same and or different wireless technology standards with respect to one another. For example in some embodiments one or more of the transceivers of the communications component may be configured to communicate using GSM CDMAONE CDMA2000 LTE and various other 2G 2.5G 3G 4G and greater generation technology standards. Moreover the communications component may facilitate communications over various channel access methods which may or may not be used by the aforementioned standards including but not limited to TDMA FDMA W CDMA OFDM SDMA and the like.

In addition the communications component may facilitate data communications using GPRS EDGE the HSPA protocol family including HSDPA EUL or otherwise termed HSUPA HSPA and various other current and future wireless data access standards. In the illustrated embodiment the communications component can include a first transceiver TxRx A that can operate in a first communications mode e.g. GSM . The communications component also can include an Ntransceiver TxRx N that can operate in a second communications mode relative to the first transceiver A e.g. UMTS . While two transceivers A N hereinafter collectively and or generically referred to as transceivers are shown in it should be appreciated that less than two two and or more than two transceivers can be included in the communications component .

The communications component also can include an alternative transceiver Alt TxRx for supporting other types and or standards of communications. According to various contemplated embodiments the alternative transceiver can communicate using various communications technologies such as for example WI FI WIMAX BLUETOOTH infrared infrared data association IRDA near field communications NFC other RF technologies combinations thereof and the like. In some embodiments the communications component also can facilitate reception from terrestrial radio networks digital satellite radio networks internet based radio service networks combinations thereof and the like. The communications component can process data from a network such as the Internet an intranet a broadband network a WI FI hotspot an Internet service provider ISP a digital subscriber line DSL provider a broadband provider combinations thereof or the like.

The mobile device also can include one or more sensors . The sensors can include temperature sensors light sensors air quality sensors movement sensors orientation sensors noise sensors proximity sensors or the like. As such it should be understood that the sensors can include but are not limited to accelerometers magnetometers gyroscopes infrared sensors noise sensors microphones combinations thereof or the like. Additionally audio capabilities for the mobile device may be provided by an audio I O component . The audio I O component of the mobile device can include one or more speakers for the output of audio signals one or more microphones for the collection and or input of audio signals and or other audio input and or output devices.

The illustrated mobile device also can include a subscriber identity module SIM system . The SIM system can include a universal SIM USIM a universal integrated circuit card UICC and or other identity devices. The SIM system can include and or can be connected to or inserted into an interface such as a slot interface . In some embodiments the slot interface can be configured to accept insertion of other identity cards or modules for accessing various types of networks. Additionally or alternatively the slot interface can be configured to accept multiple subscriber identity cards. Because other devices and or modules for identifying users and or the mobile device are contemplated it should be understood that these embodiments are illustrative and should not be construed as being limiting in any way.

The mobile device also can include an image capture and processing system image system . The image system can be configured to capture or otherwise obtain photos videos and or other visual information. As such the image system can include cameras lenses charge coupled devices CCDs combinations thereof or the like. The mobile device may also include a video system . The video system can be configured to capture process record modify and or store video content. Photos and videos obtained using the image system and the video system respectively may be added as message content to an MMS message email message and sent to another mobile device. The video and or photo content also can be shared with other devices via various types of data transfers via wired and or wireless communication devices as described herein.

The mobile device also can include one or more location components . The location components can be configured to send and or receive signals to determine a geographic location of the mobile device . According to various embodiments the location components can send and or receive signals from global positioning system GPS devices assisted GPS A GPS devices WI FI WIMAX and or cellular network triangulation data combinations thereof and the like. The location component also can be configured to communicate with the communications component to retrieve triangulation data for determining a location of the mobile device . In some embodiments the location component can interface with cellular network nodes telephone lines satellites location transmitters and or beacons wireless network transmitters and receivers combinations thereof and the like. In some embodiments the location component can include and or can communicate with one or more of the sensors such as a compass an accelerometer and or a gyroscope to determine the orientation of the mobile device . Using the location component the mobile device can generate and or receive data to identify its geographic location or to transmit data used by other devices to determine the location of the mobile device . The location component may include multiple components for determining the location and or orientation of the mobile device .

The illustrated mobile device also can include a power source . The power source can include one or more batteries power supplies power cells and or other power subsystems including alternating current AC and or direct current DC power devices. The power source also can interface with an external power system or charging equipment via a power I O component . Because the mobile device can include additional and or alternative components the above embodiment should be understood as being illustrative of one possible operating environment for various embodiments of the concepts and technologies described herein. The described embodiment of the mobile device is illustrative and should not be construed as being limiting in any way.

Based on the foregoing it should be appreciated that systems and methods for explorable augmented reality displays have been disclosed herein. Although the subject matter presented herein has been described in language specific to computer structural features methodological and transformative acts specific computing machinery and computer readable media it is to be understood that the concepts and technologies disclosed herein are not necessarily limited to the specific features acts or media described herein. Rather the specific features acts and mediums are disclosed as example forms of implementing the concepts and technologies disclosed herein.

The subject matter described above is provided by way of illustration only and should not be construed as limiting. Various modifications and changes may be made to the subject matter described herein without following the example embodiments and applications illustrated and described and without departing from the true spirit and scope of the embodiments of the concepts and technologies disclosed herein.

