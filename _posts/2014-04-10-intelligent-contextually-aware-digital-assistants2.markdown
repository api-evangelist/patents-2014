---

title: Intelligent contextually aware digital assistants
abstract: One embodiment of the present invention provides a system for providing context-based web services for a user. During operation, the system receives a sentence as input from a user. The system performs natural language processing on the sentence to determine one or more parameters. The system retrieves data from a foreground knowledge graph containing contextual data for the user and from a background knowledge graph containing background information corresponding to the parameters. The system determines a set of arguments based on the parameters and/or data from the foreground knowledge graph and/or data from the background knowledge graph. The system then selects an action module based on results of the natural language processing and/or the set of arguments. The system passes the arguments to the action module. The action module then uses the arguments to respond to a question or interact with web services to perform an action for the user.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09542648&OS=09542648&RS=09542648
owner: PALO ALTO RESEARCH CENTER INCORPORATED
number: 09542648
owner_city: Palo Alto
owner_country: US
publication_date: 20140410
---
The present disclosure relates to digital assistants. More specifically this disclosure relates to a method and system for an intelligent contextually aware digital assistant that can perform actions based on the user s current and background context.

In the rapidly evolving digital world users are confronted with masses of information. At the same time computing is moving away from the desktop and into a world where the cloud stores users information and users access their information from a plurality of devices. Similarly speech interfaces are beginning to unchain users from interacting with specific devices. Users seeking assistance with managing their daily activities and handling the masses of information have increasingly sophisticated choices available through multiple devices. Digital assistants such as Siri provide services including helping users to search the Internet. However current digital assistants are limited in their ability to perform more sophisticated operations for the user.

One embodiment of the present invention provides a system for providing context based web services for a user. During operation the system receives a sentence as input from a user. Next the system performs natural language processing on the sentence to determine one or more parameters. The system retrieves data from a foreground knowledge graph that contains contextual data for the user and from a background knowledge graph that contains background information corresponding to the one or more parameters. The system determines a set of arguments based on the one or more parameters and or data from the foreground knowledge graph and or data from the background knowledge graph. The system then selects an action module based on results of the natural language processing and or the set of arguments. The system passes the determined set of arguments to the selected action module. The selected action module then uses the determined set of arguments to respond to a question or interact with web services to perform an action for the user.

In a variation on this embodiment performing an action for the user further includes completing an online sales transaction.

In a variation on this embodiment performing natural language processing to determine one or more parameters further includes determining a sentence structure of the sentence. The system then determines whether there is an entry in a database corresponding to the sentence structure. Responsive to determining that there is an entry in the database corresponding to the sentence structure the system retrieves information from the entry in the database and extracts parameters from the sentence based on information retrieved from the database entry.

In a variation on this embodiment performing natural language processing on the sentence to determine one or more parameters further includes determining a sentence structure of the sentence. The system then determines whether there is an entry in a database corresponding to the sentence structure. Responsive to determining that there is no entry in the database corresponding to the sentence structure the system engages in a dialogue to elicit one or more parameters. The system determines mapping of the one or more parameters to properties on an object and stores information that includes the mapping and the one or more parameters in a database.

In a variation on this embodiment changes in the contextual data of the foreground knowledge graph triggers performing an action based on the user s context.

In a variation on this embodiment the system adds contextual data to the foreground knowledge graph based on detected user activity and or user communications. The system disambiguates another input sentence that requires information from the background knowledge graph based on the contextual data from the foreground knowledge graph. The system then performs another action for the user based at least on a portion of the contextual data added to the foreground knowledge graph and the information from the background knowledge graph.

In a variation on this embodiment one or more modules perform parameterized queries and modifications on the foreground knowledge graph and background knowledge graph.

The following description is presented to enable any person skilled in the art to make and use the embodiments and is provided in the context of a particular application and its requirements. Various modifications to the disclosed embodiments will be readily apparent to those skilled in the art and the general principles defined herein may be applied to other embodiments and applications without departing from the spirit and scope of the present disclosure. Thus the present invention is not limited to the embodiments shown but is to be accorded the widest scope consistent with the principles and features disclosed herein.

Embodiments of the present invention solve the problem of assisting users with managing information and activities by providing an agent based interface to a system that replies to queries from a user and can perform actions on behalf of the user. The user interfaces with an intelligent contextually aware personal digital assistant that uses natural language processing to understand the user s sentences and respond to questions or perform actions for the user.

The digital assistant is a software agent that runs in the cloud and is accessible from a variety of devices. It is able to both take action on the web based on commands given to it in natural language by the user and also to detect and respond to contextual situations in the user s digital and physical environments. For example the agent can automatically complete a sales transaction for the user book a trip or organize an itinerary.

The agent has access to information modeling the user s current context in a foreground knowledge graph and background information in a background knowledge graph. The system can respond to user input based on information from the knowledge graphs. The user s current context may include for example the people that the user has been communicating with the activities the user has been involved with the places that the user visits and the user s social circle of friends and acquaintances. The system has a deep understanding of the user s state based on a context graph system. This includes a deep semantic understanding of activities and other contextual data.

The system may also have access to background information stored in a graph. Background information includes data such as facts and common knowledge. The system may combine information from the background knowledge graph with the user s current context to respond to the user s questions or commands. Further the system may also allow in place learning of responses and expansion of the background semantic knowledge graph via knowledge acquisition.

User may interact with digital assistant through any number of devices such as a cell phone a cell phone or a tablet . User may also interact with digital assistant in other ways such as through a vehicle s Internet access. Digital assistant may transparently follow the user as he she moves around between devices. Digital assistant may appear on a car display on a phone or a tablet when the user is interacting with each device. The front end for digital assistant may run as a web application on the device the user is currently interacting with. Note that there may be multiple digital assistants running at the same time with different front ends sharing information from a database stored in storage .

As illustrated in system includes a visual interface displayed as an agent . Agent communicates with the user and receives user input . A parameterized natural language reply system agent behavior system controls behavior and communication for agent . Note that a front end for agent can be implemented with a combination of JavaScript and Unity3D C .

A preprocessing mechanism performs functions that include natural language processing parameter extraction disambiguation and query assembly. Preprocessing mechanism includes extraction parameter natural language modules and disambiguation and query assembly . Extraction parameter represents one or more parameters extracted from the user input. Natural language modules facilitate communication with the user using natural language. Disambiguation and query assembly disambiguates sentence parameters and objects in a foreground knowledge graph and a background knowledge graph and generates queries for the knowledge graphs. For example system may disambiguate questions that require information from background knowledge graph based on contextual data from foreground knowledge graph . Disambiguation may also involve determining additional arguments from the knowledge graphs for the action modules. In some implementations preprocessing mechanism may select an action module and interact with the knowledge graphs to determine arguments that can be passed to the selected action module.

World action modules represent one or more programmatic modules that interact with web services to perform actions for the user. A module labeled book me a ticket to . . . provides booking services and is one example of such an action module. Answer question is a module that responds to questions from user .

There may be many different modules to perform a variety of actions in the world. For example there may be modules for setting appointments purchasing items and sending text messages. Some implementations may include one module for performing each action. There may be any number of modules to perform actions. For example some implementations may include up to 40 or 50 modules to perform actions.

Web service application programming interfaces APIs allow the modules to perform their actions with web services. The selected action modules may use the arguments to interact with web service APIs . Web services are applications that make services available to other software over the web. Web services can be a web based interface for applications to communicate with each other. For example web services may include an Outlook calendar or an online travel booking service such as Expedia.

System includes two knowledge graphs that digital assistant may obtain data from. The two knowledge graphs are foreground knowledge graph and background knowledge graph . Some implementations may combine the foreground knowledge and background knowledge into a single graph. System may generate background knowledge graph using semantic content extraction or crowd sourced information. Background knowledge graph contains mined information that is generally publicly available. Background knowledge graph may contain both general knowledge and domain specific knowledge extracted from a body of content relating to a particular subject. System may expand background knowledge graph via knowledge acquisition. System may use machine learning or a deep language parser to parse information for background knowledge graph . World action modules and or other action modules may access information from background knowledge graph to perform actions.

Foreground knowledge graph contains information such as the user s current context including user s location user s identity associated people places and activities. System may maintain foreground knowledge graph on a private per user basis and can have multiple foreground knowledge graphs. Foreground knowledge graph may include one or more nodes representing objects e.g. a person with associated properties e.g. height of the person . Foreground knowledge graph may also be called a context graph or semantic graph. In one implementation foreground knowledge graph can be an in memory graph based model that stores facts and assertions about user state behavior and actions.

System may form foreground knowledge graph from the user s contextual information. For example system may derive context data from an accelerometer and update foreground knowledge graph . One may then query the user s contextual information. For example system may respond to a user s contextual query such as what was I doing last Tuesday at 8 30 AM 

System may access data from foreground knowledge graph and background knowledge graph . In one example foreground knowledge graph may contain contextual data indicating that the user has a preference for a particular Chinese restaurant. That is the user may visit the Chinese restaurant very frequently. However foreground knowledge graph does not have background information about Chinese restaurants. Instead background knowledge graph stores pre existing shared information indicating that the restaurant is part of a chain and that there is another similar restaurant. System may mine such information from publicly available sources such as Yelp. As another example system may access background knowledge graph to obtain data that may include topics objects or entities and other information extracted from service manuals.

System may store contextual information associated with different points in time. In some implementations system may store multiple versions of foreground knowledge graph with different versions corresponding to different points in time. System may store the differences between the different versions. System may then query knowledge graph to answer questions pertaining to different times such as what was I doing on last Tuesday 

Knowledge enters the system along two paths shown symbolically in on the left and right sides. On the right side events stream into a module labeled activity detection where system parses the events into high level modifications to foreground knowledge graph . Communications analysis may also analyze communications to add data to foreground knowledge graph . On the left side general and domain specific knowledge passes though semantic meaning extraction modules . Content analysis analyzes content such as search result documents to add knowledge to background knowledge graph .

System converts general and domain specific knowledge into modifications to background knowledge graph . A module may initiate a modification sequence based on a web search related to a particular subject. For example the web search may be Perform in depth research on Barack Obama. System would then use a search provider to assemble a document set on the subject subsequently running it through the content analysis and semantic meaning extraction systems and inserting the knowledge into background knowledge graph .

Note that system is organized around a system of data driven modules. Modules are a computing technique which allows routines to call each other in an unstructured manner without a standard call stack. Instead of the standard call return paradigm routines can invoke each other with control passing directly to the invoked routine. Different modules are provided for separate agent functions. World action modules and the other modules are examples of such modules. In some implementations one or more modules perform parameterized queries and modifications on the foreground knowledge graph and background knowledge graph .

System may include modules for performing actions in the world such as booking tickets or inserting calendar events. Such modules utilize the parameterization system to extract parameters from the incoming natural language input.

In some implementations system may map suitable responses into agent actions which are streamed in the form of JSON behave messages to agent . The output actions may be stored in a shared database and can be defined at the time system runs a question learning routine.

One example of an action is digital assistant annunciating a parameterized sentence. System may run the sentence through a text speech translator. System processes the output from this and the original text with a viseme extractor which yields a set of mouth positions for the character to mouth the sentence while the audio is played. A flexible schedulable animation system allows for the playing of the audio in synch with the mouthing. This system also allows for the interleaving of other animations such as look interested lean forwards etc. which are represented as tags in the output sentence. System does not send the tags to the viseme extractor but extracts and plays the tags in parallel with the mouthing animation by an engine.

System may also include a dependency system which allows registering for changes in a context graph e.g. foreground knowledge graph to trigger action recommendations. The recommendable items are actions that the digital assistant can perform. In some implementations modules implemented as JSON scripts perform the actions for digital assistant . When changes in the context graph trigger a script system fills parameters for the script with information from the user s context. This information may include recent background knowledge queries or actions. System then executes the script which may result in an animated avatar behavior annunciation etc. For example the appearance of a user in a machine vision system may cause changes to the context graph that establishes user presence. The changes to the context graph may then trigger a hello how are you script. Note that there are output triggered scripts as well as input modules.

The disclosure below describes processes illustrated in and . illustrates a process system may execute in response to an input sentence. System may execute the operations of to retrieve data from the knowledge graphs in response to receiving user input. illustrates a process system may execute to perform an action with web services in response to a user request. Note that some implementation variations may perform operations from both and . For example an implementation of the present invention may execute operations as part of or instead of executing operations to retrieve and store data in response to receiving user input.

System may query a database of previous questions to determine whether there is an entry in the database to facilitate parameter extraction operation . In one implementation system may use the sentence structure as a key for a set of data structures with data describing how to extract parameters from sentences. One can train system to store entries in the database that include instructions on how to extract parameters for particular sentence structures. For example one can train system to store data indicating how to extract parameters from a question such as how tall is Barack Obama System can then extract parameters from subsequent questions such as how tall is Abraham Lincoln 

If system finds an entry in the database then system uses the stored information to extract parameters from the sentence operation . System may extract information appropriate for different sentence structures. For example system may determine that a sentence is a ticket booking sentence or a question and answer sentence and extract the parameters of the sentence accordingly. System may extract a subject verb and an object. Systems may also extract a destination location from a sentence or a target recipient. For example system may extract parameters Barack Obama and height. In another example the sentence might be a booking ticket sentence where the user requests that digital assistant books a plane ticket to Munich. System may extract parameters from the sentence such as ticket and Munich. System may pass the parameters as arguments to the action modules.

System e.g. an action module may ascertain objects or topics or entities in a knowledge graph that correspond to one or more parameters operation . For example system may ascertain an object in a knowledge graph that correspond to the subject Barack Obama. System may perform operation as part of disambiguation. System may include a database of mined information that facilitates ascertaining objects in a knowledge graph that correspond to particular subjects. This database may include common misspellings of a subject as well as related subject information.

System e.g. an action module may access tables that provide mappings from a parameter to properties of an object in a knowledge graph operation . For example the parameter may be height and the object may be a person e.g. Barack Obama and a property of the object may be height in meters. The value of the property may be 6 feet 1 inch which is the height of Barack Obama. As another example the action module may access knowledge graphs to learn that Munich is a city accessible by rail. The action module may access either foreground knowledge graph or background knowledge graph to gather information. In some implementations the mapping tables may be stored in a database. In some implementations the mapping tables can also be knowledge graph objects.

When system retrieves information e.g. from background knowledge graph system may store the information as current context associated with foreground knowledge graph operation . System may store a link or other reference in foreground knowledge graph to information in background knowledge graph . Subsequent related queries to foreground knowledge graph may then be directed to the information in background knowledge graph . For example system may subsequently respond efficiently to a question such as where did he live in 2003 

If system has never encountered the sentence before e.g. system did not find an entry in the database then system may engage in a dialogue with the user to elicit parameters from the sentence operation . System then determines mappings from parameters of the sentence to properties of objects operation . System may allow the user to choose properties from a property browser. In some implementations system may store data associating a module or other subprogram with a particular sentence structure to facilitate responding to the sentence structure. System may store some or all of the information in a database that is shared between all the instances of digital assistant operation .

During operation system initially receives an input sentence from a user operation . System may perform natural language processing on the sentence operation . System may process the sentence using preprocessing mechanism . System may determine a set of parameters for the sentence operation . For example an input sentence may be associated with a particular sentence structure and the input sentence may refer to a parameter height of a person.

In some implementations preprocessing mechanism may access and interact with foreground knowledge graph and background knowledge graph to determine a set of arguments operation . For example system may determine that height in a sentence for a particular sentence structure maps to a height in meters property associated with an object in a knowledge graph. The node may represent a person object which can also be associated with other properties such as birthday weight address and other information about the person. Preprocessing mechanism may access the knowledge graph to obtain the object data.

System may select an action module operation . In some implementations preprocessing mechanism may select the action module. For example preprocessing mechanism may select the action module based on the arguments and or results from the natural language processing. Preprocessing mechanism may pass arguments to the selected action module operation . The arguments can be information that preprocessing mechanism retrieves from knowledge graphs. For example system may call world action modules and or other action modules and pass the arguments to world action modules and or other action modules.

The selected action module may use the arguments to interact with web service APIs to perform an action operation . World action modules and or other action modules may execute actions using the arguments and web search APIs . For example module may purchase plane tickets to Munich for the user. As another example a module may send a communication e.g. text message or email that indicates the user s current location and or activity. Yet another module may purchase a book for the user from an online bookstore.

In some implementations digital assistant may provide the user with additional options relating to the action and request that the user choose from one of the additional options. For example digital assistant may provide the user with options such as such as coach business or first class tickets and the exact time of departure or arrival.

Note that in some implementations the selected action module may also gather arguments or other information from the knowledge graphs. For example the selected action module may obtain data from the knowledge graphs about a person including the location of the person e.g. that the person is far away from a train station address citizenship and other information. The selected action module may use the additional information to perform an action such as completing a transaction.

The data structures and code described in this detailed description are typically stored on a computer readable storage medium which may be any device or medium that can store code and or data for use by a computer system. The computer readable storage medium includes but is not limited to volatile memory non volatile memory magnetic and optical storage devices such as disk drives magnetic tape CDs compact discs DVDs digital versatile discs or digital video discs or other media capable of storing computer readable media now known or later developed.

The methods and processes described in the detailed description section can be embodied as code and or data which can be stored in a computer readable storage medium as described above. When a computer system reads and executes the code and or data stored on the computer readable storage medium the computer system performs the methods and processes embodied as data structures and code and stored within the computer readable storage medium.

Furthermore methods and processes described herein can be included in hardware modules or apparatus. These modules or apparatus may include but are not limited to an application specific integrated circuit ASIC chip a field programmable gate array FPGA a dedicated or shared processor that executes a particular software module or a piece of code at a particular time and or other programmable logic devices now known or later developed. When the hardware modules or apparatus are activated they perform the methods and processes included within them.

The foregoing descriptions of various embodiments have been presented only for purposes of illustration and description. They are not intended to be exhaustive or to limit the present invention to the forms disclosed. Accordingly many modifications and variations will be apparent to practitioners skilled in the art. Additionally the above disclosure is not intended to limit the present invention.

