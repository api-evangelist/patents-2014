---

title: Electronic device and method for processing image
abstract: An electronic device includes a first image sensor generating first image data, a second image sensor generating second image data, at least one processor processing the first image data and the second image data, and a display displaying at least one image of the first image data and the second image data processed by the at least one processor, wherein the electronic device is configured to set each time stamp on the first image data and the second image data and the display is configured to display at least one image data on the basis of the time stamps. An operating method of an electronic device includes generating first image data and second image data by using a first image sensor and a second image sensor, respectively, and displaying at least one image data on a display on the basis of the time stamp.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09363433&OS=09363433&RS=09363433
owner: Samsung Electronics Co., Ltd.
number: 09363433
owner_city: Suwon-si
owner_country: KR
publication_date: 20140313
---
The present application is related to and claims priority under 35 U.S.C. 119 to a provisional application Ser. No. 61 780 619 filed in the United States Patent and Trademark Office on Mar. 13 2013 and an application No. 10 2013 0139907 filed in the Korean Intellectual Property Office on Nov. 18 2013 the contents of which are incorporated herein by reference.

Various embodiments of the present disclosure relates generally to a method and an electronic device for processing an image.

With the developments of information and communication technology and semiconductor technology various electronic devices become multimedia devices providing various multimedia services. For example a portable electronic device may provide various multimedia services such as broadcasting services wireless Internet service and music playback service.

An electronic device may provide various services through at least one image obtained from image sensors.

If including a plurality of image sensors an electronic device may not display images obtained through the plurality of image sensors on a display unit at the same time due to different processing times of the images.

To address the above discussed deficiencies it is a primary object to provide a device and method for efficiently processing images obtained through a plurality of image sensors in an electronic device.

Another object of the present disclosure is to provide a device and method for reducing processing delay of images obtained through a plurality of image sensors in an electronic device.

Another object of the present disclosure is to provide a device and method for processing images obtained through a plurality of image sensors in an electronic device by using image processing units disposed inside or outside of a processor.

Another object of the present disclosure is to provide a device and method for converting at least one image obtained through at least one image sensor into an image in a format displayable on a display unit by using at least one image processor disposed outside a processor in an electronic device.

Another object of the present disclosure is to provide a device and method for setting a time stamp for images obtained through a plurality of image sensors in an electronic device.

Another object of the present disclosure is to provide a device and method for selecting a plurality of images for synthesis by using a time stamp set for images obtained through a plurality of image sensors in an electronic device.

Another object of the present disclosure is to provide a device and method for selecting a plurality of images for synthesis by using a time stamp and an image processing delay time set for images obtained through a plurality of image sensors in an electronic device.

According to an aspect of the present disclosure an electronic device includes a first image sensor generating first image data a second image sensor generating second image data at least one processor processing at least one image data of the first image data and the second image data and a display unit displaying at least one image of the first image data and the second image data processed by the at least one processor wherein the electronic device sets a time stamp on the first image data and the second image data and the display unit displays at least one image data on the basis of the time stamp.

According to an aspect of the present disclosure an electronic device includes a first image sensor generating first image data a second image sensor generating second image data an application processor processing the first image data and an image processing processor processing the second image data wherein the image processing processor converts the second image data into a format displayable on a display unit.

According to an aspect of the present disclosure an electronic device includes a storage device storing first image data having a first time stamp added and second image data having a second time stamp added at least one processor processing at least one image data of the first image data and the second image data and a display unit displaying at least one image of the first image data and the second data processed by the at least one processor wherein the display unit displays at least one image data on the basis of the time stamp.

According to an aspect of the present disclosure an electronic device includes a first image sensor generating first image data a second image sensor generating second image data at least one processor processing at least one of the first image data and the second image data and a storage device storing time stamps corresponding to the first image data and the second image data wherein the electronic device compares time stamps of the image data.

According to an aspect of the present disclosure an operating method of an electronic device includes generating a plurality of image data by using a plurality of image sensors setting a time stamp corresponding to each of the plurality of image data and displaying at least one image data on a display unit on the basis of the time stamp.

According to an aspect of the present disclosure an operating method of an electronic device includes generating first image data and second image data by using a first image sensor and a second image sensor and processing the first image data by using an application processor and processing the second image data by using an image processing processor wherein the processing of the second image data includes converting the second image data into a format displayable on a display unit.

According to an aspect of the present disclosure an operating method of an electronic device includes storing first image data including a first time stamp added and second image data including a second time stamp added and displaying at least one image data on a display unit on the basis of the time stamp.

According to an aspect of the present disclosure an operating method of an electronic device includes generating first image data and second image data by using a first image sensor and a second image sensor storing a first image data including a first time stamp added and a second image data including a second time stamp added and displaying at least one image data on a display unit on the basis of the time stamp.

Before undertaking the DETAILED DESCRIPTION below it may be advantageous to set forth definitions of certain words and phrases used throughout this patent document the terms include and comprise as well as derivatives thereof mean inclusion without limitation the term or is inclusive meaning and or the phrases associated with and associated therewith as well as derivatives thereof may mean to include be included within interconnect with contain be contained within connect to or with couple to or with be communicable with cooperate with interleave juxtapose be proximate to be bound to or with have have a property of or the like and the term controller means any device system or part thereof that controls at least one operation such a device may be implemented in hardware firmware or software or some combination of at least two of the same. It should be noted that the functionality associated with any particular controller may be centralized or distributed whether locally or remotely. Definitions for certain words and phrases are provided throughout this patent document those of ordinary skill in the art should understand that in many if not most instances such definitions apply to prior as well as future uses of such defined words and phrases.

Various embodiments of the present disclosure describe a device and method for efficiently processing images obtained through a plurality of image sensors in an electronic device.

An electronic device according to an embodiment of the present disclosure may be one or a combination of various devices such as smart phones tablet PCs mobile phones video phones e book readers desktop PCs laptop PCs netbook computers PDAs PMPs MP3 players mobile medical equipment jewelry electronics accessory cameras wearable devices electronic watches wrist watches refrigerators air conditioners vacuum cleaners artificial intelligence robots TVs DVD players audios ovens microwaves washing machines microwave bracelets electronic necklaces air purifiers electronic picture frames medical devices e.g. MRAs MRIs CTs camcorders or ultrasound devices navigation devices GPS receivers EDRs FDRs set top boxes TV boxes for example SamSung HomeSync Apple TVTM or Google TVTM Electronic dictionaries automotive infotainment devices marine electronic equipment for example marine navigation systems and gyro compasses Avionics security devices and electronic garments electronic keys camcorders game consoles HMDs flat panel display devices the electronic albums part of furniture or buildings structures including an electronic device electronic boards electronic signature input devices or projectors all of which include a plurality of sensors. It is apparent to those skilled in the art that the electronic device is not limited to the above mentioned devices.

Referring to the electronic device includes a processor a memory image sensors to N a display unit and a user input unit . Here the processor can include an application program processor AP.

The processor interprets a command received from at least another component for example the memory the image sensors to N the display unit and the user input unit included in the electronic device and then and performs operations and data processing in response to the interpreted command. For example the processor can perform at least one image processing on images provided from the image sensors to N for example level adjustment noise reduction gamma correction and format conversion for displaying an image on the display unit . The processor can store the processed images in the memory or display them on the display unit . At this point the processor can transmit the images displayed on the display unit to the memory so as to temporarily store them in the memory . Here the image processing that is the format conversion for displaying an image on the display unit can include color space conversion.

The processor can allow the electronic device to provide various multimedia services by executing at least one program stored in the memory . The processor can select at least two from among images obtained through the image sensors to N and synthesize them by executing a program stored in the memory . For example the processor can set a time stamp corresponding to images obtained through at least one among the image sensors to N. As another example if a capture event occurs the processor can select and synthesize at least two images for synthesis on the basis of a time stamp of images obtained through each of the image sensors to N. As another example if a capture event occurs the processor can select and synthesize at least two images for synthesis on the basis of a processing delay time and a time stamp for images obtained through each of the image sensors to N.

The memory can store commands or data received or generated from at least one component included in the electronic device . For example the memory can include programming modules for example a kernel a middleware an application programming interface API and an application. Here the programming module can include an operating system OS controlling resources relating to the electronic device or various applications running on OS. At this point each programming module can be configured with software firmware hardware or a combination thereof. The OS can include Android iOS Windows Symbian Tizen or bada.

The image sensors to N can provide collected images obtained through capturing a subject to the processor . At this point the image sensors to N can transmit an image to the processor through a serial interface such as MIPI and MDDI or a parallel interface such as parallel bus. Here the first image sensor can be disposed at the front of the electronic device and the Nth image sensor N can be disposed at the rear of the electronic device .

The display unit can provide a graphic user interface such as state information characters entered by a user a moving image or a still image of the electronic device . For example the display unit can display at least one image provided from the processor . As another example the display unit can display at least two images selected by the processor based on a time stamp or a time stamp and an image processing delay time.

The user input unit can transmit commands or data generated by a user selection to the processor or the memory . For example the user input unit can include a touch input unit a pen sensor a key or an ultrasonic input device.

Although not shown in the drawings the electronic device can further include a communication unit for communicating with another electronic device or a server through voice communication or data communication. Here the communication unit can include a plurality of communication sub modules supporting different communication networks. For example the communication network is not limited thereto but can support a short range communication protocol for example Wifi BT NFC or a network communication for example Internet LAN WAN telecommunication network cellular network satellite network or POTS .

According to the above mentioned embodiment the electronic device includes the image sensors to N. At this point at least one image sensor among the image sensors to N can be selectively mounted on the electronic device . For example at least one image sensor among the image sensors to N can be selectively mounted on the electronic device through a wired interface. As another example at least one image sensor among the image sensors to N can be selectively connected to the electronic device through a wireless interface such as Bluetooth and wireless LAN.

Referring to the processor includes an image processing unit a display control unit and an image generation control unit .

The image processing unit can perform at least one image processing on image data provided from each of the image sensors to N for example level adjustment noise reduction gamma correction and color space conversion. The image processing unit can transmit the processed image to at least one of the memory and the display control unit . At this point the image processing unit can transmit the images displayed on the display unit to the memory so as to temporarily store them in the memory .

The display control unit can provide a graphic user interface through the display unit . For example the display control unit can display images provided from the image processing unit or the memory on the display unit . At this point the display control unit can display images provided from the image sensors to N through the image processing unit on the display unit simultaneously.

The image generation control unit can select at least two images from among images obtained through the image sensors to N and synthesize them. For example if a capture event occurs the image generation control unit can select and synthesize at least two images for synthesis on the basis of a time stamp of images stored in the memory . For example if different sizes of images obtained through the low pixel first image sensor and the high pixel Nth image sensor N are synthesized the image generation control unit can select at least one first image including a time stamp prior to a capture event occurrence time from among images obtained through the first image sensor . At this point the image generation control unit can select at least one first image from among images including a time stamp prior to a capture event occurrence time by using a processing delay difference on an image of the first image sensor and an image of the Nth image sensor N. The image generation control unit can select at least one second image obtained at a time closest to the capture event occurrence time according to the time stamp of images obtained through the Nth image sensor N and then can synthesize the second image with the first image. At this point the image generation control unit can transmit first and second images stored in the memory to the control unit so as to display a synthesized image on the display unit .

Although not shown in the drawings the processor can further include a time setting unit for setting a time stamp for at least one image data provided from the image sensors to N. For example the time setting unit can record a time corresponding to each image data provided from the image sensors to N by each frame unit. As another example if there is at least one image sensor that is selectively mounted on the electronic device among the image sensors to N the time setting unit can set a time stamp on at least one image data provided from the at least one image sensor mounted on the electronic device . At this point an image obtained through at least one image sensor that is selectively mounted on the electronic device can be set with a time stamp by an additional module included in each image sensor.

According to the above mentioned embodiment the processor can process images provided from the image sensors to N through the image processing unit .

According to another embodiment the processor can process images provided from the image sensors to N through a plurality of image processing units in the processor .

Referring to the electronic device includes a processor a memory image sensors to N external image processing units to N 1 a user input unit and a display unit . Here the processor can include an application program processor AP.

The processor interprets a command received from at least another component for example the memory the first image sensor the external image processing units to N 1 the user input unit and the display unit included in the electronic device and then and performs operations and data processing in response to the interpreted command. For example the processor can perform at least one image processing on images provided from the first image sensor for example level adjustment noise reduction gamma correction and format conversion for displaying an image on the display unit . The processor can store the processed images in the memory or display them on the display unit . At this point the processor can transmit the images displayed on the display unit to the memory so as to temporarily store them in the memory . As another example the processor can convert images stored in the memory into images in a format for displaying the images on the display unit through the external image processing units to N 1 and then display the converted images on the display unit . Here the image processing that is the format conversion for displaying an image on the display unit can include color space conversion.

The processor can allow the electronic device to provide various multimedia services by executing at least one program stored in the memory . The processor can select at least two images from among images obtained through the image sensors to N and synthesize them by executing a program stored in the memory . For example the processor can set a time stamp on image data provided from the first image sensor or the first image sensor and the external image processing units to N 1 . As another example if a capture event occurs the processor can select and synthesize at least two images for synthesis on the basis of a time stamp of images obtained through each of the image sensors to N. As another example if a capture event occurs the processor can select and synthesize at least two images for synthesis on the basis of a processing delay time and a time stamp for images obtained through each of the image sensors to N.

The memory can store commands or data received or generated from at least one component included in the electronic device .

The image sensors to N can provide collected images obtained through capturing a subject to the processor . At this point the image sensors to N can transmit an image to the processor or the external image processing units to N 1 through a serial interface such as MIPI and MDDI or a parallel interface such as parallel bus. Here the first image sensor can be disposed at the front of the electronic device and the Nth image sensor N can be disposed at the rear of the electronic device .

The external image processing units to N 1 can perform image processing on an image provided from the image sensors to N for example level adjustment noise reduction and gamma correction.

The user input unit can transmit commands or data generated by a user selection to the processor or the memory . For example the user input unit can include a touch input unit a pen sensor a key or an ultrasonic input device.

The display unit can provide a graphic user interface such as state information characters entered by a user a moving image or a still image of the electronic device . For example the display unit can display at least one image provided from the processor . As another example the display unit can display at least two images selected by the processor based on a time stamp or a time stamp and an image processing delay time.

Although not shown in the drawings the electronic device can further include a communication unit for communicating with another electronic device or a server through voice communication or data communication. Here the communication unit can include a plurality of communication sub modules supporting different communication networks.

According to the above mentioned embodiment the electronic device includes the image sensors to N. At this point at least one image sensor among the image sensors to N can be selectively mounted on the electronic device . For example at least one image sensor among the image sensors to N can be selectively mounted on the electronic device through a wired interface. In this case an external image processing unit connected to at least one image sensor that is selectively mounted on the electronic device can be mounted on the electronic device or can be selectively mounted on the electronic device in addition to an Nth image sensor.

As another example at least one image sensor among the image sensors to N can be selectively connected to the electronic device through a wireless interface such as Bluetooth and wireless LAN. In this case an external image processing unit connected to at least one image sensor that is selectively connected to the electronic device can be mounted on the electronic device or can be selectively mounted on the electronic device in addition to an Nth image sensor.

Referring to the processor includes an image processing unit an internal interface a display control unit a format conversion unit and an image generation control unit .

The image processing unit can perform at least one image processing on image data provided from the first image sensor for example level adjustment noise reduction gamma correction and color space conversion. The image processing unit can transmit the processed image to at least one of the memory and the display control unit . At this point the image processing unit can transmit the images displayed on the display unit to the memory so as to temporarily store them in the memory .

The internal interface can transmit images provided from each of the external image processing units to N 1 to the memory . For example the internal interface can include at least one of MIFI and CAMIF.

The display control unit can provide a graphic user interface through the display unit . For example the display control unit can display images provided from the image processing unit or the memory on the display unit . At this point the display control unit can display an image provided from the first image sensor through the image processing unit and an image provided from the Nth image sensor N through the memory on the display unit simultaneously. For example the display control unit can display an image converted into a data format for displaying the image on the display unit through the format conversion unit and an image provided from the first image sensor through the image processing unit simultaneously.

The format conversion unit can convert an image provided from the memory into a data format displayable on the display unit . For example the format conversion unit can perform color space conversion on an image provided from the memory and transmit the converted image to the display control unit .

The image generation control unit can select at least two images from among images obtained through the image sensors to N and synthesize them. For example if a capture event occurs the image generation control unit can select and synthesize at least two images for synthesis on the basis of a time stamp of images stored in the memory . If different sizes of images obtained through the low pixel first image sensor and the high pixel Nth image sensor N are synthesized the image generation control unit can select at least one first image including a time stamp prior to a capture event occurrence time from among images obtained through the first image sensor . At this point the image generation control unit can select at least one first image from among images including a time stamp prior to a capture event occurrence time by using a processing delay difference on an image of the first image sensor and an image of the Nth image sensor N. The image generation control unit can select at least one second image obtained at a time closest to the capture event occurrence time according to the time stamp of images obtained through the Nth image sensor N and then can synthesize the second image with the first image. At this point the image generation control unit can transmit first and second images stored in the memory to the control unit so as to display a synthesized image on the display unit .

Although not shown in the drawings the processor can further include a time setting unit for setting a time stamp on image data provided from the first image sensor or the first image sensor and the external image processing units to N 1 . For example the time setting unit can record a time corresponding to each image data provided from the first image sensor by each frame unit. At this point an image obtained through the second image sensor to the Nth image sensor N can be set with a time stamp through an external image processing unit connected to each image sensor.

Referring to the electronic device includes a processor memories and image sensors to N external image processing units to N 1 a display unit and a user input unit . Here the processor can include an application program processor AP.

The processor can interpret a command received from at least another component included in the electronic device and performs operations or data processing in response to the interpreted command. For example the processor can perform at least one image processing on images provided from the first image sensor for example level adjustment noise reduction gamma correction and format conversion for displaying an image on the display unit . The processor can store the processed images in the first memory or display them on the display unit . At this point the processor can transmit the images displayed on the display unit to the first memory so as to temporarily store them in the first memory . As another example the processor can convert images stored in the first memory into images in a format for displaying the images on the display unit through the external image processing units to N 1 and then display the converted images on the display unit . Here the image processing that is the format conversion for displaying an image on the display unit can include color space conversion.

The processor can allow the electronic device to provide various multimedia services by executing at least one program stored in the first memory . The processor can select at least two images from among images obtained through the image sensors to N and synthesize them by executing a program stored in the memory . For example the processor can set a time stamp on image data provided from the first image sensor or the first image sensor and the external image processing units to N 1 . As another example if a capture event occurs the processor can select and synthesize at least two images for synthesis on the basis of a time stamp of images obtained through each of the image sensors to N. As another example if a capture event occurs the processor can select and synthesize at least two images for synthesis on the basis of a processing delay time and a time stamp for images obtained through each of the image sensors and N.

The first memory can store commands or data received or generated from at least one component included in the electronic device .

The image sensors to N can provide collected images obtained through capturing a subject to the processor . At this point the image sensors to N can transmit an image to the processor or the external image processing units to N 1 through a serial interface such as MIPI and MDDI or a parallel interface such as parallel bus. Here the first image sensor can be disposed at the front of the electronic device and the Nth image sensor N can be disposed at the rear of the electronic device .

The external image processing units to N 1 can perform image processing on an image provided from the image sensors to N for example level adjustment noise reduction gamma correction and color space conversion and store the processed image in the first memory . Additionally the external image processing units to N 1 can set time information in an image provided from the image sensors to N and store the image in the second memory .

The second memory can store an unprocessed image provided from the external image processing units to N 1 . For example the second memory can store raw image data provided from the external image processing units to N 1 . At this point the second memory can exist at each of the external image processing units and N 1 .

The display unit can provide a graphic user interface such as state information characters entered by a user a moving image or a still image of the electronic device . For example the display unit can display at least one image provided from the processor . As another example the display unit can display at least two images selected by the processor based on a time stamp or a time stamp and an image processing delay time.

The user input unit can transmit commands or data generated by a user selection to the processor or the first memory . For example the user input unit can include a touch input unit a pen sensor a key or an ultrasonic input device.

Although not shown in the drawings the electronic device can further include a communication unit for communicating with another electronic device or a server through voice communication or data communication. Here the communication unit can include a plurality of communication sub modules supporting different communication networks.

According to the above mentioned embodiment the electronic device includes the image sensors to N. At this point at least one image sensor among the image sensors to N can be selectively mounted on the electronic device . For example at least one image sensor among the image sensors to N can be selectively mounted on the electronic device through a wired interface. In this case an external image processing unit connected to at least one image sensor that is selectively mounted on the electronic device can be mounted on the electronic device or can be selectively mounted on the electronic device in addition to an Nth image sensor.

As another example at least one image sensor among the image sensors to N can be selectively connected to the electronic device through a wireless interface such as Bluetooth and wireless LAN. In this case an external image processing unit connected to at least one image sensor that is selectively connected to the electronic device can be mounted on the electronic device or can be selectively connected to the electronic device in addition to an Nth image sensor.

Referring to the processor includes an image processing unit an internal interface a display control unit and an image generation control unit .

The image processing unit can perform at least one image processing on image data provided from the first image sensor for example level adjustment noise reduction gamma correction and color space conversion. The image processing unit can transmit the processed image to at least one of the first memory and the display control unit . At this point the image processing unit can transmit the images displayed on the display unit to the first memory so as to temporarily store them in the first memory .

The internal interface can transmit images provided from each of the external image processing units to N 1 to the first memory . For example the internal interface can include at least one of MIFI and CAMIF and a raw data dumping interface RDI for transmitting an image converted for displaying an image on the display unit from the external image processing units to N 1 .

The display control unit can provide a graphic user interface through the display unit . For example the display control unit can display images provided from the image processing unit or the first memory on the display unit . At this point the display control unit can display an image provided from the first image sensor through the image processing unit and an image provided from the Nth image sensor N through the first memory on the display unit simultaneously.

The image generation control unit can select at least two images from among images obtained through the image sensors to N and synthesize them. For example if a capture event occurs the image generation control unit can select and synthesize at least two images for synthesis on the basis of a time stamp of images stored in the first memory and the second memory . If images obtained through the low pixel first image sensor and the high pixel Nth image sensor N are synthesized the image generation control unit can select at least one first image including a time stamp prior to a capture event occurrence time from among images stored in the first memory and obtained through the first image sensor . At this point the image generation control unit can select at least one first image from among images including a time stamp prior to a capture event occurrence time by using a processing delay difference on an image of the first image sensor and an image of the Nth image sensor N. The image generation control unit can select a second image obtained at a time closest to the capture event occurrence time according to the time stamp of images stored in the second memory and obtained through the Nth image sensor N and then can synthesize the second image with the first image. As another embodiment if images obtained through the low pixel first image sensor and the high pixel Nth image sensor N are synthesized the image generation control unit can select at least one second image obtained at a time closest to a capture event occurrence time according to a time stamp of images stored in the second memory and obtained through the Nth image sensor N. The second image stored in the second memory selected from the image generation control unit can be stored in the first memory through the processor . The image generation control unit can select a first image obtained at a time closest to a time at which the second image starts to be transmitted to the processor or at a time closest to a time at which the second image starts to be stored in the first memory according to the time stamp of images stored in the first memory and obtained through the first image sensor and then can synthesize the selected first image with the second image. At this point the image generation control unit can transmit first and second images stored in the first memory to the control unit so as to display a synthesized image on the display unit .

Although not shown in the drawings the processor can further include a time setting unit for setting a time stamp on image data provided from the first image sensor or the first image sensor and the external image processing units to N 1 . For example the time setting unit can record a time corresponding to each image data provided from the first image sensor by each frame unit. At this point an image obtained through the second image sensor to the Nth image sensor N can be set with a time stamp through an external image processing unit connected to each image sensor. As another example the time setting unit can record a time corresponding to image data provided from the external image sensor N 1 by each frame unit. For example the image generation control unit can select and synthesize at least two images for synthesis on the basis of a time stamp of images stored in the first memory .

Referring to the external image processing unit includes an image processing control unit and a time setting unit .

The image processing control unit can perform at least one image processing on image data provided from the image sensors to N for example level adjustment noise reduction gamma correction and format conversion for displaying an image on the display unit . For example the image processing control unit can convert image data of YUV422 provided from the image sensors to N into image data of YUV420 through color space conversion so as to convert an image into a format displayable on the display unit .

The image processing control unit can convert at least one image data stored in the second memory into a format displayable on the display unit and then can transmit the converted image into the image generation control unit . For example the image processing control unit can receive selected image data for image synthesis from the second memory according to a control of the image generation control unit of and then can convert the received image data into a format displayable on the display unit to transmit it to the image generation control unit . As another example when a capture event occurs the image processing control unit can convert at least one image data among images stored in the second memory into a format displayable on the display unit and then can transmit the converted image data into the image generation control unit .

The time setting unit can set a time stamp in image data provided from the image sensors to N. For example the time setting unit can include a time insertion unit and a frame setting unit and can record a time corresponding to each image data provided from the image sensors to N by each frame unit.

According to the above mentioned embodiment the external image processing unit can include an image processing control unit and a time setting unit . According to another embodiment the time setting unit can be disposed outside an external image processing unit.

Referring to the first memory includes a plurality of blocks and logically or physically and stores data therein. For example image data provided from the image processing unit of the processor can be stored in the third block of the first memory .

Image data provided from the external image processing units to N 1 in the first block of the first memory . At this point the image data can be classified into Y data UV data and metadata and can be stored in the internal blocks and of the first block . Here the metadata can include at least one of a frame identifier of image data a time stamp focus information and image setting information EXIF.

If a capture event occurs image data stored in the second memory can be stored in the third block of the first memory through the external image processing units to N 1 .

As mentioned above the electronic device can convert images obtained through the image sensor N into a format for displaying the images on the display unit through the external image processing unit N 1 and then can store the converted images in the first memory so that delay due to an additional format conversion can be reduced.

Referring to the electronic device can display images obtained through a plurality of image sensors on a display unit in operation . At this point the electronic device can store at least one image displayed on a display unit in at least one memory. For example referring to the electronic device performs image processing on an image obtained through the first image sensor through the image processing unit of the processor and stores it in the third block of the first memory by each frame unit. The electronic device performs image processing on an image obtained through the Nth image sensor N through the external image processing unit N 1 and stores it in the first block of the first memory by each frame unit. At this point the processor can set a time stamp on an image inputted to the image processing unit or an image outputted from the image processing unit and can set a time stamp on an image provided from the external image processing unit N 1 . As another example referring to the electronic device performs image processing on an image obtained through the first image sensor through the image processing unit of the processor and stores it in the first memory by each frame unit. At this point the processor can set a time stamp in an image inputted to the image processing unit or an image outputted from the image processing unit . The electronic device can store an image obtained through the Nth image sensor N in the second memory by each frame unit before performing image processing through the image processing control unit of the external image processing unit N 1 . At this point the external image processing unit N 1 can set a time stamp in an image stored in the second memory by using the time setting unit . Here an image stored in the memory or can include metadata having at least one of a frame identifier a time stamp focus information and image setting information EXIF.

The electronic device can select a plurality of images for synthesis on the basis of a time stamp of images stored in a memory in operation . For example if a capture event occurs the electronic device can select a first image whose time stamp is closest to a capture event occurrence time among images stored in the first block of the first memory . Moreover the electronic device can select a second image whose time stamp is closest to a capture event occurrence time from among images stored in the third block of the first memory . The electronic device can synthesize a first image selected from the first memory and a second image as one image. As another example if a capture event occurs the electronic device can select a first image whose time stamp is closest to a capture event occurrence time from among images stored in the first memory . Additionally the electronic device can select a second image whose time stamp is closest to a capture event occurrence time from among images stored in the second memory . The electronic device can synthesize a first image selected from the first memory and a second image as one image.

An electronic device including a plurality of image sensors can have different processing delays on an image obtained through each image sensor by at least one difference in the number of pixels in each image sensor the sensitivity of an Nth image sensor the size of an image obtained through an Nth image sensor or an image processing speed. Accordingly the electronic device can synchronize images for synthesis as shown in .

Referring to the electronic device can set a time stamp on images obtained through a plurality of image sensors in operation . For example referring to the processor of the electronic device can set a time stamp on an image inputted to the image processing unit or an image outputted from the image processing unit and can set a time stamp on an image provided from the external image processing unit N 1 . At another example referring to the processor of the electronic device can set a time stamp on an image inputted to the image processing unit or an image outputted from the image processing unit . Additionally the external image processing unit N 1 of the electronic device can set a time stamp on an image provided from the Nth image sensor N by using the time setting unit .

The electronic device can display images obtained through image sensors on a display unit in operation . At this point the electronic device can store at least one image displayed on a display unit in at least one memory. For example when a time stamp is set in an image inputted to the image processing unit through the processor the electronic device can perform image processing on an image where a time stamp is set through the image processing unit of the processor and can store the image in the third block of the first memory . As another example when a time stamp is set in an image outputted from the image processing unit through the processor the electronic device can store an image whose time stamp is set in the third block of the first memory . As another example when a time stamp is set in an image outputted from the external image processing unit N 1 through the processor the electronic device can store an image whose time stamp is set in the first block of the first memory . As another example when a time stamp is set in an image outputted from the external image processing unit N through the time setting unit the electronic device can store an image whose time stamp is set in the second memory . At this point referring to the electronic device can store an image in the memory or by a frame unit. Here an image stored in the memory or can include metadata having at least one of a frame identifier a time stamp focus information and image setting information EXIF.

The electronic device can confirm whether a capture event occurs in operation . For example the electronic device can confirm whether a hardware button input corresponding to the capture event is detected. As another example the electronic device can confirm whether an icon corresponding to the capture event is detected. As another example the electronic device can confirm whether a user gesture corresponding to the capture event is detected.

If the capture event does not occur the electronic device can set a time stamp on images obtained through a plurality of image sensors in operation .

If the capture event occurs the electronic device can select at least one image for synthesis including a time stamp prior closest to a capture event occurrence time from among images obtained through a first image sensor stored in a memory in operation . For example referring to the electronic device can select one first image including a time stamp prior closest to a capture event occurrence time as an image for synthesis from among images obtained through the first image sensor and sequentially stored in the first memory . At this point the electronic device can select one first image from among images including a time stamp prior to the capture event occurrence time in consideration of a difference between a processing delay on an image obtained through the first image sensor and a processing delay on an image obtained through the Nth image sensor N.

Additionally if the capture event occurs the electronic device can select one image for synthesis including a time stamp closest to a capture event occurrence time from among images obtained through the Nth image sensor stored in a memory in operation . For example referring to the electronic device can select one second image including a time stamp closest to a capture event occurrence time as an image for synthesis from among images obtained through the Nth image sensor N and sequentially stored in the first memory or the second memory .

If images are selected for synthesis in operation and operation the electronic device can synthesize a first image selected from images provided from a first image sensor with a second image selected from images provided from an Nth image sensor as one image in operation .

Referring to the electronic device can set a time stamp on images obtained through a plurality of image sensors in operation . For example referring to the processor of the electronic device can set a time stamp on an image inputted to the image processing unit or an image outputted from the image processing unit . Additionally the external image processing unit N 1 of the electronic device can set a time stamp on an image provided from the Nth image sensor N by using the time setting unit .

The electronic device can display images obtained through image sensors on a display unit in operation . At this point the electronic device can store at least one image displayed on a display unit in at least one memory. For example referring to when a time stamp is set in an image inputted to the image processing unit through the processor the electronic device can perform image processing on an image where a time stamp is set through the image processing unit of the processor and can store the image in the third block of the first memory . As another example referring to when a time stamp is set in an image outputted from the image processing unit through the processor the electronic device can store an image whose time stamp is set in the third block of the first memory . As another example referring to when a time stamp is set in an image provided from the Nth image sensor N through the time setting unit the electronic device can store an image whose time stamp is set in the second memory . At this point as shown in the electronic device can store an image in the memory or by a frame unit in operations and . Here an image stored in the memory or can include metadata having at least one of a frame identifier a time stamp focus information and image setting information EXIF.

The electronic device can confirm whether a capture event occurs in operation . For example the electronic device can confirm whether a hardware button input corresponding to the capture event is detected. As another example the electronic device can confirm whether an icon corresponding to the capture event is detected. As another example the electronic device can confirm whether a user gesture corresponding to the capture event is detected.

If the capture event does not occur the electronic device can set a time stamp on images obtained through a plurality of image sensors in operation .

Additionally if the capture event occurs the electronic device can select one image for synthesis including a time stamp closest to a capture event occurrence time from among images obtained through the Nth image sensor stored in a memory in operation . For example referring to the electronic device can select one second image including a time stamp closest to a capture event occurrence time as an image for synthesis from among images obtained through the Nth image sensor N and sequentially stored in the second memory .

The electronic device can select a second image for synthesis from among images obtained through the Nth image sensor and stored in a memory in order to synthesize one image including a time stamp closest to the processing time of a processor in operation . For example the electronic device can select one first image including a time stamp closest to a time at which the second image selected from the external image processing unit N 1 starts to be transmitted to the processor in order for synthesis in operation . As another example the electronic device can select one first image including a time stamp closest to a time at which the second image selected from the external image processing unit N 1 starts to be stored in the first memory through the processor in order for synthesis in operation .

If images are selected for synthesis the electronic device can synthesize a first image selected from images provided from a first image sensor with a second image selected from images provided from an Nth image sensor as one image in operation .

As mentioned above the electronic device converts at least one image obtained through at least one sensor into a format displayable on a display unit through an image processing unit inside or outside a processor and then provides the converted image to the processor so that a time delay due to an image processing time can be reduced.

By selecting a plurality of images for synthesis through a time stamp set in images obtained from image sensors the acquisition times of images to be synthesized can be synchronized.

While the disclosure has been shown and described with reference to certain preferred embodiments thereof it will be understood by those skilled in the art that various changes in form and details can be made therein without departing from the spirit and scope of the disclosure as defined by the appended claims. Therefore the scope of the disclosure is defined not by the detailed description of the disclosure but by the appended claims and all differences within the scope will be construed as being included in the present disclosure.

