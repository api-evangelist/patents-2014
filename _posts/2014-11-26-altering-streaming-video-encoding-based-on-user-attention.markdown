---

title: Altering streaming video encoding based on user attention
abstract: Disclosed are various embodiments for adjusting the encoding of a video signal into a video stream based on user attention. A video signal is encoded into a video stream. A temporary lapse of attention by a user of the interactive application is predicted. The encoding of the video signal into the video stream is adjusted from an initial state to a conservation state in response to predicting the temporary lapse of attention by the user. The conservation state is configured to conserve one or more resources used for the video stream relative to the initial state.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09253494&OS=09253494&RS=09253494
owner: Amazon Technologies, Inc.
number: 09253494
owner_city: Seattle
owner_country: US
publication_date: 20141126
---
This application is a divisional of and claims priority to co pending U.S. Patent Application entitled ALTERING STREAMING VIDEO ENCODING BASED ON USER ATTENTION filed on Dec. 1 2010 and assigned application Ser. No. 12 957 450 which is incorporated herein by reference in its entirety.

A video signal is typically encoded by one or more video encoders in order to generate a video stream capable of being sent over a data communications network. Such encoding is useful to reduce the bitrate associated with the video signal thereby allowing the video stream to fit within the bandwidth constraints of the network. Data reduction is also helpful in some systems to permit forward error correction data to be transmitted in the video stream. However video encoders may be resource intensive sometimes requiring significant processing and or memory resources in order to achieve acceptable video quality.

The present disclosure relates to adjusting the encoding of a video signal into a video stream based on user attention or anticipated user attention. Given that a video stream may use significant encoding resources and or network bandwidth resources it may be desirable to reduce such resource consumption when a user is not paying attention to the video stream. In some cases it may be desirable to reduce such resource consumption even when a user is not paying attention merely to a portion of a screen rendered from the video stream.

Various embodiments of the present disclosure adjust the encoding of a video signal generated by an interactive application into a video stream based on the attention of the user. As a non limiting example a user who is playing a game may leave the room temporarily or otherwise might not pay attention to a video stream that is encoded from a video signal generated by the game. Accordingly a video encoder that encodes the video signal into the video stream may be adjusted to stop encoding or to reduce resource consumption during a temporary lapse of attention by the user to the video stream.

As another non limiting example an event occurring in a portion of a game screen may draw the attention of the user and induce a saccade. A saccade is a rapid movement of the eyes as they jump from fixation on one point to another. When a person shifts visual focus to something that is moving the person perceives a smooth visual experience. However the actual physiology involved differs from the perception. In reality the eye unfocuses the muscles controlling the eye aim the eye to focus on another object and the eye refocuses on the other object.

During this time which may last approximately between 30 and 50 milliseconds the visual field is edited out by the brain and the brain fills in the gap. If something unusual occurs in the visual field during the saccade the user does not perceive it due to this saccadic masking phenomenon. Accordingly a video encoder that encodes the video signal of the game may be adjusted to reduce resource consumption while the user is experiencing saccadic masking. In the following discussion a general description of the system and its components is provided followed by a discussion of the operation of the same.

With reference to shown is a networked environment according to various embodiments. The networked environment includes one or more computing devices in data communication with one or more clients by way of a network . The network includes for example the Internet intranets extranets wide area networks WANs local area networks LANs wired networks wireless networks or other suitable networks etc. or any combination of two or more such networks.

The computing device may comprise for example a server computer or any other system providing computing capability. Alternatively a plurality of computing devices may be employed that are arranged for example in one or more server banks or computer banks or other arrangements. For example a plurality of networked computing devices together may comprise a cloud computing resource a grid computing resource and or any other distributed computing arrangement. Such computing devices may be located in a single installation or may be distributed among many different geographical locations. For purposes of convenience the computing device is referred to herein in the singular. Even though the computing device is referred to in the singular it is understood that a plurality of computing devices may be employed in the various arrangements as described above.

Various applications and or other functionality may be executed in the computing device according to various embodiments. Also various data is stored in a data store that is accessible to the computing device . The data store may be representative of a plurality of data stores as can be appreciated. The data stored in the data store for example is associated with the operation of the various applications and or functional entities described below.

The components executed on the computing device for example include a server application an encoding adjustment application a plurality of applications . . . N a plurality of video encoders . . . N a plurality of wrappers . . . N and other applications services processes systems engines or functionality not discussed in detail herein. The server application is executed to launch applications which may be executed within wrappers that provide a virtualized environment. Although the principles of the present disclosure are illustrated with reference to applications that are executed in remote servers it is understood that the principles are applicable to any video stream that depicts saccade inducing events or may be susceptible to user inattention. Non limiting examples of such video streams may include movies television programs televised sports programs etc. Although games are discussed herein as particular examples of applications it is understood that the applications may correspond to many different types of interactive applications other than merely games in various embodiments.

The server application is executed to obtain input data from the clients and provide the input data to the respective wrapper . The server application is also executed to send video data that is captured from the application to the clients as a video stream. The server application may communicate with the client over various protocols such as for example hypertext transfer protocol HTTP simple object access protocol SOAP representational state transfer REST real time transport protocol RTP real time streaming protocol RTSP real time messaging protocol RTMP user datagram protocol UDP transmission control protocol TCP and or other protocols for communicating data over the network . The server application is configured to maintain application state information associated with the executing applications .

The application is an interactive application such as for example a game. The application may be a single player game a multiple player game or include both single player and multiple player modes. As non limiting examples the application may correspond to a first person shooter game an action game an adventure game a party game a role playing game a simulation game a strategy game a vehicle simulation game and or other types of games. The application may be a game originally designed for execution in a general purpose computing device or in a specialized video game device such as for example a video game console a handheld game device an arcade game device etc. The application may expect to access one or more resources of the device on which it is executed. Such resources may correspond to display devices input devices or other devices. In some cases the application may request exclusive access to one or more of the resources whereby no other applications may have access to the particular resources.

The video encoder is able to encode a video signal generated by the application into a video stream for transmission over the network to clients . The video stream may include an audio signal generated by the application as well. To this end the video encoder may include various types of video and audio encoders such as for example Moving Pictures Experts Group MPEG encoders H.264 encoders Flash video encoders etc. Such encoders may be selected according to factors such as for example data reduction encoding quality latency etc.

The video encoder may introduce various encoding artifacts into the video stream that were not present in the video signal. Such encoding artifacts may comprise macroblocking pixelation mosquito noise and or other forms of encoding artifacts. The presence and severity of the encoding artifacts may depend on various factors such as the content of the video signal the maximum bitrate of the video stream the data reduction approach employed by the particular video encoder etc.

In general it may be the case that video encoders that are configured to use lesser processing resources may produce video streams of lower quality at a specified bitrate when compared to video encoders that are configured to use greater processing resources and produce video streams at the same specified bitrate. Further it may generally be the case that video streams that are encoded at a lower bitrate have a lower quality than video streams that are encoded at a higher bitrate. Therefore reducing consumption of resources such as processing resources and network bandwidth resources may result in lower quality video streams.

The encoding adjustment application is executed to detect periods of user inattention and to make adjustments to the corresponding video encoder to conserve one or more resources consumed by the video stream. For example the encoding adjustment application may configure the video encoder to stop encoding a video stream while a user is not paying attention to the rendered video stream. Alternatively the encoding adjustment application may configure the video encoder to encode the video stream using a lesser quality encoding to conserve resources while a user is not paying attention to the rendered video stream.

In addition the encoding adjustment application may be executed to detect whether a rapid change is present in one or more frames of the video signal that is to be encoded. Such a rapid change may be predicted to draw the attention of the user to a region of the video frame where the rapid change is occurring thereby inducing a saccade. In one embodiment the encoding adjustment application may compare frames of the video signal to previous frames of the video signal to ascertain whether a rapid change is present. In another embodiment the encoding adjustment application may be able to correlate frames of the video signal to a profile of the application that indicates whether a rapid change is anticipated. In yet another embodiment the encoding adjustment application may obtain event indications from the application that notify the encoding adjustment application that a rapid change is anticipated.

The encoding adjustment application may configure the video encoder to use lesser resources in encoding the video stream when a saccade inducing event is present in the video signal. Because the attention of the user is drawn to the region of rapid change other areas of the video signal may be encoded to use less data less processing time etc. for the duration of the saccade inducing event. Such an event may last for example two to three frames 30 to 50 milliseconds or some other duration. In one embodiment the entire video frame may be encoded with a lesser quality encoding for at least a portion of the duration of the saccade inducing event to take advantage of the saccade masking phenomenon.

In addition to reconfiguring the video encoder the encoding adjustment application may be capable of reconfiguring the application to conserve resources used in generating the video signal. For example the encoding adjustment application may configure the application to generate a video signal with a lower resolution fewer colors fewer rendered polygons etc. In various embodiments the encoding adjustment application may interface with one or more graphics libraries used by the application e.g. DirectX etc. to accomplish such an adjustment. Such an adjustment of the source video signal may also result in using fewer resources in encoding the source video signal.

The wrapper corresponds to an application that provides a virtualized environment for execution of the application . In particular the wrapper may be configured to virtualize one or more of the resources that the application expects to access. Such resources may include a keyboard a mouse a joystick a video device a sound device etc. In this way the wrapper is able to provide input commands to the application as if the wrapper emulates a keyboard a mouse or another type of input device.

Different types of wrappers may be provided for different applications or classes of applications . As non limiting examples different wrappers may be provided for applications using different application programming interfaces APIs such as OpenGL DirectX the Graphics Device Interface GDI and so on. Where the application is configured for execution in a specialized video game device or another type of computing device the wrapper may include an emulation application that emulates the device. The wrapper may be configured to deliver the video signal generated by the application to the video encoder for encoding.

The application state information that is maintained by the server application includes various data relating to application sessions that are currently active. For example the application state information may track the users that are currently participating in the application session scores and status information associated with the users security permissions associated with the application session e.g. who can or cannot join and so on. In some embodiments some or all of the application state information may be discarded when an application session ends.

The data stored in the data store includes for example applications video encoders wrappers saved state data user data saccadic event profiles encoding adjustment configuration data and potentially other data. The applications correspond to a library of video games or other applications that are available to be launched as applications . The applications may correspond to executable code within the computing device . Alternatively the applications may correspond to code that is executable within another type of device but is not executable within the computing device . Such applications may be referred to as binaries read only memory images ROMs and other terms. A particular application may be executed as multiple instances of the applications for multiple application sessions.

The video encoders correspond to the various types of video encoders that may be employed in the computing device . Some video encoders may correspond to specific formats such as for example H.264 MPEG 4 MPEG 2 3D video streams and or other formats. The wrappers correspond to the executable code that implements the various types of wrappers . The wrappers are executable in the computing device and may be executed as multiple instances of the wrappers for multiple application sessions.

The saved state data corresponds to application states that have been saved by the applications . Because the applications are executed in a virtualized environment the applications may write state information to a virtual location which is then mapped for storage in the data store as the saved state data . The saved state data may correspond to data saved normally by the application or may correspond to a memory image of the application that may be resumed at any time. The user data includes various data related to the users of the applications such as for example security credentials application preferences billing information a listing of other users that are permitted to join application sessions started by the user and so on.

The saccadic event profiles include data that assists the encoding adjustment application in detecting saccade inducing events in video signals. To this end the saccadic event profiles may include fingerprints that may be applied to frames of a video signal in order to detect the occurrence of a saccade inducing event. As a non limiting example an explosion in a certain application may be understood to cause a saccade. Such an explosion may be associated with a characteristic fireball graphic. A fingerprint of this graphic may be stored in the saccadic event profiles . The fingerprint may be later used by the encoding adjustment application to detect the saccadic event based on the presence of the characteristic graphic in a video frame.

Additionally an application may provide metadata regarding the game play represented in the video signal by way of an application programming interface API . Such metadata may describe the occurrence of an event in a video signal that may predicted to induce a saccade in the user e.g. explosions sudden appearances of enemies sudden changes in lighting or contrast and so on. The saccadic event profiles may describe indications of certain such events as saccade inducing events.

The encoding adjustment configuration data includes various configurations that may be applied to video encoders and or applications . The encoding adjustment configuration data may include initial configurations and conservation configurations that are used to conserve resources associated with the video stream and or video signal. As a non limiting example an initial configuration may specify that a video signal is to be encoded with an H.264 video encoder with a 1024 768 pixel resolution at 60 frames per second with 16 bit color and at a 2.0 Megabit per second bitrate. As another non limiting example a conservation configuration may specify that a portion of the video signal is to be encoded to be encoded with an H.264 video encoder with a 1024 768 pixel resolution at 24 frames per second with 8 bit color and at a 256 Kilobit per second bitrate. The resolution of a portion of the video signal may also change in the conservation configuration though the portion of the video signal may be rendered with the same size relative to the rest of the video signal.

The client is representative of a plurality of client devices that may be coupled to the network . The clients may be geographically diverse. The client may comprise for example a processor based system such as a computer system. Such a computer system may be embodied in the form of a desktop computer a laptop computer personal digital assistants cellular telephones smartphones set top boxes music players web pads tablet computer systems game consoles electronic book readers or other devices with like capability.

The client may include a display . The display may comprise for example one or more devices such as cathode ray tubes CRTs liquid crystal display LCD screens gas plasma based flat panel displays LCD projectors or other types of display devices etc. The client may include one or more input devices . The input devices may comprise for example devices such as keyboards mice joysticks accelerometers light guns game controllers touch pads touch sticks push buttons optical sensors microphones haptic devices webcams and or any other devices that can provide user input.

The client may be configured to execute various applications such as a client application and or other applications. The client application is executed to allow a user to launch join play and otherwise interact with an application executed in the computing device . To this end the client application is configured to capture input provided by the user through one or more of the input devices and send this input over the network to the computing device as input data .

The client application is also configured to obtain video data over the network from the computing device and render a screen on the display . To this end the client application may include one or more video and audio players to play out a video stream generated by a video encoder . In one embodiment the client application comprises a plug in within a browser application. The client may be configured to execute applications beyond the client application such as for example browser applications email applications instant message applications and or other applications.

Next a general description of the operation of the various components of the networked environment is provided. To begin a user at a client sends a request to launch an application to the server application . The server application obtains the corresponding application and wrapper from the data store . The server application then launches the application in the corresponding wrapper . The server application tracks the status of the application session within the application state information .

The wrapper provides a virtualized environment for the application that virtualizes one or more resources of the computing device . Such resources may include exclusive resources i.e. resources for which the application requests exclusive access. For example the application may request full screen access from a video device which is an exclusive resource because normally only one application can have full screen access. Furthermore the wrapper may virtualize input devices such as for example keyboards mice etc. which may not actually be present in the computing device . In various embodiments the wrapper may correspond to a virtual machine and or the wrapper may be executed within a virtual machine.

The user at the client enters input commands for the application by use of the input devices of the client . As a non limiting example the user may depress a left mouse button. Accordingly the client application functions to encode the input command into a format that may be transmitted over the network within the input data . The server application receives the input command and passes it to the wrapper . The wrapper then provides a left mouse button depression to the application by way of a virtualized mouse. In some embodiments different input commands may be presented to the application from those that were generated by a client . As a non limiting example if a user sends a mouse down command and the client application loses focus the wrapper may be configured to send a mouse down command followed by a mouse up command. In various embodiments the input commands may be relayed to the wrapper as soon as possible or the input commands may be queued by the wrapper and relayed to the application sequentially from the queue according to another approach.

Various embodiments enable input generated through one type of input device in a client to be transformed by the wrapper into input commands provided to the application through an entirely different type of virtual input device. As a non limiting example input generated by an accelerometer in the client may be translated by the wrapper into input provided through a virtual mouse. Thus completely different kinds of input devices may be used in the application that may not have been contemplated when the application was implemented.

Moreover because the client is decoupled from the hardware requirements of the application the application may be used in a diverse variety of clients that are capable of streaming video with acceptable bandwidth and latency over a network . For example the application may be used on a client that is a smartphone. Thus the client need not include expensive graphics hardware to perform the complex three dimensional rendering that may be necessary to execute the application . By contrast the hardware of the computing device may be upgraded as needed to meet the hardware requirements of the latest and most computationally intensive applications . In various embodiments the video stream encoded by the video encoder may be scaled according to the bitrate and or other characteristics of the connection between the computing device and the client over the network .

The graphical output of the application is captured by the wrapper and encoded into a video stream. Additionally the audio output of the application may be captured and multiplexed into the video stream. The video stream is transmitted by the server application to the client over the network as the video data . The client application obtains the video data and plays it out on the display in a screen .

Turning now to shown are examples of user interfaces rendered by the client application executed in the client in the networked environment . In particular depicts a screen rendered on the display from a video stream. The screen in shows a sprite that is being controlled by the user. In some embodiments it may be assumed by the encoding adjustment application that the user is paying attention to the sprite based on receipt of an input command controlling the sprite .

In a saccadic event occurs which corresponds to an explosion in the game environment. The encoding adjustment application may then determine that the attention of the user is directed to the saccadic event . When the user moves from paying attention to the sprite to the saccadic event a saccade may occur in the user. Although the attention of the user moves from a sprite to a saccadic event it is understood that the attention of the user may move from another saccadic event to the saccadic event . Further the attention of the user may move from an undetermined location on the screen to the saccadic event .

During and relative to a predicted saccade the encoding adjustment application may configure the video encoder to conserve resources associated with encoding the video stream where the user is not likely to perceive quality problems. Such resources may include processor time and or memory consumed by the video encoder and or bandwidth on the network consumed by the resulting video stream.

Although the operation of the encoding adjustment application is described in relation to a video signal generated by an application it is understood that principles of the present disclosure may be applied to any other encoding of video signals into video streams. For example explosions changes in contrast appearance of characters etc. may occur in television programs movies and so on. Accordingly various embodiments of the present disclosure may be able to recognize saccadic events in television programs movies etc. Moreover various embodiments of the present disclosure may be able to detect user inattention regarding a video stream of television programs movies etc.

Referring next to shown is a flowchart that provides one example of the operation of a portion of the encoding adjustment application according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the encoding adjustment application as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the computing device according to one or more embodiments.

Beginning with box the encoding adjustment application detects an event occurring in a region of a video signal. Specifically the region may correspond to a region in one or more frames of the video signal. The encoding adjustment application may detect the event by identifying a rapid change in color luminosity and or other video characteristics relative to previous frames of the video signal. Alternatively the encoding adjustment application may identify a graphical event in the video signal according to a fingerprint stored in the saccadic event profiles . In some embodiments the encoding adjustment application may receive an indication from the corresponding application that an event is occurring.

In box the encoding adjustment application determines whether the event detected in box is predicted to cause a saccade. Where the encoding adjustment application obtains the indication that the event is occurring from the application the encoding adjustment application may correlate the indication with a saccadic event by using data stored in the saccadic event profiles . Where the encoding adjustment application detects a rapid change between frames the encoding adjustment application may refer to one or more thresholds stored in the saccadic event profiles to determine whether the rapid change is likely to attract the attention of the user and induce a saccade.

If the encoding adjustment application determines that the event is not predicted to cause a saccade the encoding adjustment application maintains the currently configured encoding of the video signal in box . In other words the event may not be significant enough or may not be distinct enough from other action occurring in the video signal to attract the attention of the user to the event. It may also be the case that the user may be predicted to have become accustomed to the specific type of event due to location on the display frequency of repetition recent repetition and or other factors. If the user is accustomed to the event or if another event had just occurred in or near the same location a saccade may be unlikely. Thereafter the portion of the encoding adjustment application ends.

Otherwise if the encoding adjustment application determines that the event is predicted to cause a saccade the encoding adjustment application proceeds to box . In box the encoding adjustment application adjusts the encoding of the video signal in the other regions of the video frames to conserve resource usage. The encoding adjustment application may configure the video encoder to move from an initial state with an initial encoder configuration to a conservation state with a conservation encoder configuration.

Such configurations may be loaded from the encoding adjustment configuration data . Such a conservation encoder configuration may result in lower memory usage lower processor usage lower network bandwidth usage and or other reductions in resource consumption associated with the video stream. In some embodiments the entire video signal may be encoded in a lower quality during the time period of the saccade to take advantage of saccadic masking while the eye is re aimed from one position on the screen to another.

Next in box the encoding adjustment application determines whether the saccade is completed. In other words the encoding adjustment application determines whether the user is predicted to be focused on the region of the screen that contains the saccade inducing event. If the user is focused on that area the user may then look at another area of the screen at any time. If the saccade has not completed the encoding adjustment application returns to box and maintains the adjusted encoding configuration of the video signal that conserves resources.

If the saccade has completed the encoding adjustment application continues to box and returns the encoding of the video signal to the previously configured encoding. Because the user may look at some other area of the screen the encoding configuration of the video encoder may be readjusted to use the initial higher quality encoding configuration. Thereafter the portion of the encoding adjustment application ends.

Moving on to shown is a flowchart that provides one example of the operation of another portion of the encoding adjustment application according to various embodiments. It is understood that the flowchart of provides merely an example of the many different types of functional arrangements that may be employed to implement the operation of the portion of the encoding adjustment application as described herein. As an alternative the flowchart of may be viewed as depicting an example of steps of a method implemented in the computing device according to one or more embodiments.

Beginning with box the encoding adjustment application detects user inattention. As a non limiting example the user may be talking on telephone in another room or otherwise not paying attention to the screen . Accordingly the user is not moving a mouse not typing on the keyboard etc. Therefore no input data is obtained by the server application when the user is not paying attention to the screen . When a predetermined time period elapses the encoding adjustment application may regard the user as idle and not paying attention. As another non limiting example if the user minimizes the client application the client application may be configured to send an indication of user inattention to the server application .

In box the encoding adjustment application determines whether another user participating in the game session is paying attention. If another user is paying attention the video stream encoding continues unaffected and the portion of the encoding adjustment application ends. However if no other users are paying attention the encoding adjustment application proceeds to box .

In box the encoding adjustment application stops the encoding of the video signal into the video stream. In other embodiments the encoding adjustment application may instead configure the video encoder to encode the video signal into a lower quality video stream. In either case processing resources and or network resources may be conserved. Where the encoding is stopped completely the video encoder may be terminated thereby freeing up memory of the computing device . However the application may continue to execute in the computing device and generate the video signal even though the corresponding video encoder has been terminated.

In box the encoding adjustment application determines whether the user has resumed paying attention to the screen . The user may have actuated an input device thereby causing input data to be sent to the server application . Alternatively the user may have restored a client application that had been minimized thereby causing the client application to send an indication of visibility to the computing device .

If the user has resumed paying attention the encoding adjustment application continues to box and restarts the encoding of the video signal into the video stream. In another embodiment the encoding adjustment application may reconfigure the video encoder to use an initial configuration after employing a conservation configuration while the user was inattentive. If the video encoder had been terminated a new instance of the video encoder may be launched and configured to perform the encoding of the video signal into the video stream. Thereafter the portion of the encoding adjustment application ends.

Otherwise if the user does not resume paying attention the encoding may remain stopped or may continue according to the conservation configuration. If the encoding continues according to the conservation configuration it may be stopped entirely after the expiration of a timeout period. Additionally the application and or the wrapper may be stopped by the server after the expiration of a timeout period. Thereafter the portion of the encoding adjustment application ends.

With reference to shown is a schematic block diagram of the computing device according to an embodiment of the present disclosure. The computing device includes at least one processor circuit for example having a processor a memory and one or more graphics devices all of which are coupled to a local interface . To this end the computing device may comprise for example at least one server computer or like device. The local interface may comprise for example a data bus with an accompanying address control bus or other bus structure as can be appreciated. The graphics devices may correspond to high performance graphics hardware including one or more graphics processors . Non limiting examples of commercially available graphics processors include the NVIDIA Tesla series. The graphics devices are configured to render graphics corresponding to the applications executed in the computing device .

Stored in the memory are both data and several components that are executable by the processor . In particular stored in the memory and executable by the processor are the server application the encoding adjustment application the applications the video encoders the wrappers and potentially other applications. Also stored in the memory may be a data store and other data. In addition an operating system may be stored in the memory and executable by the processor .

It is understood that there may be other applications that are stored in the memory and are executable by the processors as can be appreciated. Where any component discussed herein is implemented in the form of software any one of a number of programming languages may be employed such as for example C C C Objective C Java JavaScript Perl PHP Visual Basic Python Ruby Delphi Flash or other programming languages.

A number of software components are stored in the memory and are executable by the processor . In this respect the term executable means a program file that is in a form that can ultimately be run by the processor . Examples of executable programs may be for example a compiled program that can be translated into machine code in a format that can be loaded into a random access portion of the memory and run by the processor source code that may be expressed in proper format such as object code that is capable of being loaded into a random access portion of the memory and executed by the processor or source code that may be interpreted by another executable program to generate instructions in a random access portion of the memory to be executed by the processor etc. An executable program may be stored in any portion or component of the memory including for example random access memory RAM read only memory ROM hard drive solid state drive USB flash drive memory card optical disc such as compact disc CD or digital versatile disc DVD floppy disk magnetic tape or other memory components.

The memory is defined herein as including both volatile and nonvolatile memory and data storage components. Volatile components are those that do not retain data values upon loss of power. Nonvolatile components are those that retain data upon a loss of power. Thus the memory may comprise for example random access memory RAM read only memory ROM hard disk drives solid state drives USB flash drives memory cards accessed via a memory card reader floppy disks accessed via an associated floppy disk drive optical discs accessed via an optical disc drive magnetic tapes accessed via an appropriate tape drive and or other memory components or a combination of any two or more of these memory components. In addition the RAM may comprise for example static random access memory SRAM dynamic random access memory DRAM or magnetic random access memory MRAM and other such devices. The ROM may comprise for example a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other like memory device.

Also the processor may represent multiple processors and the memory may represent multiple memories that operate in parallel processing circuits respectively. In such a case the local interface may be an appropriate network that facilitates communication between any two of the multiple processors between any processor and any of the memories or between any two of the memories etc. The local interface may comprise additional systems designed to coordinate this communication including for example performing load balancing. The processor may be of electrical or of some other available construction.

Although the server application the encoding adjustment application the applications the video encoders the wrappers and other various systems described herein may be embodied in software or code executed by general purpose hardware as discussed above as an alternative the same may also be embodied in dedicated hardware or a combination of software general purpose hardware and dedicated hardware. If embodied in dedicated hardware each can be implemented as a circuit or state machine that employs any one of or a combination of a number of technologies. These technologies may include but are not limited to discrete logic circuits having logic gates for implementing various logic functions upon an application of one or more data signals application specific integrated circuits having appropriate logic gates or other components etc. Such technologies are generally well known by those skilled in the art and consequently are not described in detail herein.

The flowcharts of show the functionality and operation of an implementation of portions of the encoding adjustment application . If embodied in software each block may represent a module segment or portion of code that comprises program instructions to implement the specified logical function s . The program instructions may be embodied in the form of source code that comprises human readable statements written in a programming language or machine code that comprises numerical instructions recognizable by a suitable execution system such as a processor in a computer system or other system. The machine code may be converted from the source code etc. If embodied in hardware each block may represent a circuit or a number of interconnected circuits to implement the specified logical function s .

Although the flowcharts of show a specific order of execution it is understood that the order of execution may differ from that which is depicted. For example the order of execution of two or more blocks may be scrambled relative to the order shown. Also two or more blocks shown in succession in may be executed concurrently or with partial concurrence. Further in some embodiments one or more of the blocks shown in may be skipped or omitted. In addition any number of counters state variables warning semaphores or messages might be added to the logical flow described herein for purposes of enhanced utility accounting performance measurement or providing troubleshooting aids etc. It is understood that all such variations are within the scope of the present disclosure.

Also any logic or application described herein including the server application the encoding adjustment application the applications the video encoders and the wrappers that comprises software or code can be embodied in any non transitory computer readable medium for use by or in connection with an instruction execution system such as for example a processor in a computer system or other system. In this sense the logic may comprise for example statements including instructions and declarations that can be fetched from the computer readable medium and executed by the instruction execution system. In the context of the present disclosure a computer readable medium can be any medium that can contain store or maintain the logic or application described herein for use by or in connection with the instruction execution system.

The computer readable medium can comprise any one of many physical media such as for example magnetic optical or semiconductor media. More specific examples of a suitable computer readable medium would include but are not limited to magnetic tapes magnetic floppy diskettes magnetic hard drives memory cards solid state drives USB flash drives or optical discs. Also the computer readable medium may be a random access memory RAM including for example static random access memory SRAM and dynamic random access memory DRAM or magnetic random access memory MRAM . In addition the computer readable medium may be a read only memory ROM a programmable read only memory PROM an erasable programmable read only memory EPROM an electrically erasable programmable read only memory EEPROM or other type of memory device.

It should be emphasized that the above described embodiments of the present disclosure are merely possible examples of implementations set forth for a clear understanding of the principles of the disclosure. Many variations and modifications may be made to the above described embodiment s without departing substantially from the spirit and principles of the disclosure. All such modifications and variations are intended to be included herein within the scope of this disclosure and protected by the following claims.

