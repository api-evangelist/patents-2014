---

title: Failure management in a distributed strict queue
abstract: Methods and systems for implementing failure management in a distributed strict queue are disclosed. A plurality of messages are distributed to a plurality of queue servers based on strict order parameters for the messages. Messages that share a value for the strict order parameter are distributed to the same queue server. The messages are enqueued at the queue servers. Messages that share a value for the strict order parameter are enqueued in a strict order based on the time of receipt at the queue server. One or more queue clients are configured to attempt message processing for the enqueued messages. Log data is received from the one or more queue clients at the queue servers. The log data is descriptive of the attempted message processing.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09584593&OS=09584593&RS=09584593
owner: Amazon Technologies, Inc.
number: 09584593
owner_city: Reno
owner_country: US
publication_date: 20140627
---
Many companies and other organizations operate distributed systems that interconnect numerous computing systems and other computing resources to support their operations such as with the computing systems being co located e.g. as part of a local network or instead located in multiple distinct geographical locations e.g. connected via one or more private or public intermediate networks . For example data centers housing significant numbers of interconnected computing systems have become commonplace such as private data centers that are operated by and on behalf of a single organization and public data centers that are operated by entities as businesses to provide computing resources to customers. As the scale and scope of typical distributed systems has increased the tasks of provisioning administering and managing the computing resources have become increasingly complicated.

For example a queuing service may be implemented using a distributed system in a manner that prioritizes high availability and redundancy. However prior approaches for implementing a distributed queuing service may present messages out of their intended order. Additionally prior approaches for implementing a distributed queuing service may present a message more than the number of intended times e.g. once . The presentation of messages out of their intended order and the presentation of messages more than once may pose problems for applications that require strict queue behavior.

While embodiments are described herein by way of example for several embodiments and illustrative drawings those skilled in the art will recognize that embodiments are not limited to the embodiments or drawings described. It should be understood that the drawings and detailed description thereto are not intended to limit embodiments to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope as defined by the appended claims. The headings used herein are for organizational purposes only and are not meant to be used to limit the scope of the description or the claims. As used throughout this application the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to. 

Various embodiments of methods and systems for implementing strict queue ordering in a distributed system are described. In a distributed strict queue system with multiple queue servers each queue server may be assigned a portion of a range of values for a strict order parameter. Based on the value of its strict order parameter an incoming message may be forwarded to the appropriate queue server for the value of the strict order parameter and the queue server may assign a sequence identifier to the message. The message may then be presented in the intended order with respect to other messages with the same value for the strict order parameter. Additionally each message may be delivered to a queue consumer once and only once in the distributed strict queue system.

In one embodiment the queue system may batch messages in a manner that preserves the strict order guarantee and the guaranteed once delivery. In one embodiment the queue system may select and or provision queue clients based on system parameters performance metrics and or cost considerations. In one embodiment the queue system may control queue clients using control messages. For example control messages may be used to update a client configuration or client software. In one embodiment queue clients may generate log data for attempted message processing and the queue system may perform various failure management functions using the log data. In one embodiment the queue system may use a network proxy for network traffic involving the queue clients in this manner the queue system may restrict network interactions for any of the client or otherwise isolate any of the clients. In one embodiment the queue system may use geographical awareness techniques to improve the performance cost and or risk in the system. In one embodiment a multi tiered processing algorithm may use the strict queues to generate a final result following transformation summarization and aggregation phases.

In one embodiment the strict queue s may include messages associated with different values for a strict order parameter. Messages with the same value for the strict order parameter may be enqueued in the correct order relative to each other. However for messages with different values for the strict order parameter the queue service may use a best effort ordering technique that is not guaranteed to present messages with different values for the strict order parameter in the correct order. The best effort ordering may result in some messages with different values for the strict order parameter being processed by queue clients in a different order than the messages were received by the queue service . Accordingly the strict queue s may be strict for messages with the same value for the strict order parameter and non strict for messages with different values for the strict order parameter.

It is contemplated that the distributed strict queue system may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. For example although three queue producers A B and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue producers may be used. Additionally although three queue servers A B and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue servers may be used. Furthermore although three queue consumers A B and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue consumers may be used.

The distributed strict queue system may comprise one or more computing devices any of which may be implemented by the example computing device illustrated in . In various embodiments portions of the functionality of the distributed strict queue system including the queue producers A N queue servers A N and or queue consumers A N may be provided by the same computing device or by any suitable number of different computing devices. If any of the components of the distributed strict queue system are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions.

In some embodiments the queue servers A N and queue consumers A N may be implemented as virtual compute instances or as physical compute instances. The virtual compute instances and or physical compute instances may be offered to clients provisioned and maintained by a provider network that manages computational resources memory resources storage resources and network resources. A virtual compute instance may comprise one or more servers with a specified computational capacity which may be specified by indicating the type and number of CPUs the main memory size and so on and a specified software stack e.g. a particular version of an operating system which may in turn run on top of a hypervisor . One or more virtual compute instances may be implemented by the example computing device illustrated in .

In one embodiment a suitable component of the distributed strict queue system may select and or provision the queue servers A N and or queue consumers A N. For example the queue servers A N and or queue consumers A N may be provisioned from a suitable pool of available computing instances. In one embodiment additional computing instances may be added to the queue servers A N and or queue consumers A N as needed. In one embodiment computing instances may be returned to the pool of available computing instances from the queue servers A N and or queue consumers A N if the computing instances are not needed at a particular point in time.

In one embodiment the functionality of the distributed strict queue system may be provided to clients using a provider network. For example the functionality of the distributed strict queue system may be presented to clients as a web accessible service. A network set up by an entity such as a company or a public sector organization to provide one or more services such as various types of cloud based computing or storage accessible via the Internet and or other networks to a distributed set of clients may be termed a provider network. A provider network may include numerous data centers hosting various resource pools such as collections of physical and or virtualized computer servers storage devices networking equipment and the like that are used to implement and distribute the infrastructure and services offered by the provider. The resources may in some embodiments be offered to clients in units called instances such as virtual or physical compute instances or storage instances. A virtual compute instance may for example comprise one or more servers with a specified computational capacity which may be specified by indicating the type and number of CPUs the main memory size and so on and a specified software stack e.g. a particular version of an operating system which may in turn run on top of a hypervisor . A number of different types of computing devices may be used singly or in combination to implement the resources of the provider network in different embodiments including general purpose or special purpose computer servers storage devices network devices and the like.

In one embodiment operators of provider networks may implement a flexible set of resource reservation control and access interfaces for their clients. For example a provider network may implement a programmatic resource reservation interface e.g. via a web site or a set of web pages that allows clients to learn about select purchase access to and or reserve resources. In one embodiment queue resources may be reserved on behalf of clients using a client accessible service that implements the distributed strict queue system . According to one such embodiment a distributed strict queue system in such an environment may receive specifications for the various messages to be enqueued e.g. a description of one or more tasks and an indication of a source of input data to be used by the task s . In response the distributed strict queue system may enqueue and execute the task s using one or more resources of a selected resource pool of the provider network. In one embodiment the resource pool may be automatically selected based on the anticipated computational needs of the various tasks. In one embodiment the resource pool may be selected based on a specific resource request or reservation submitted by the client.

In one embodiment the client may use one or more suitable interfaces such as one or more web pages an application programming interface API or a command line interface CLI to provide the various messages to be enqueued and otherwise configure the distributed strict queue system . In one embodiment the client may be able to view the current status of the messages using the interface s . In one embodiment additional information about messages in the distributed strict queue system may be available via the interface s such as program output error logs exception logs and so on.

In one embodiment the messages A N may be received by one or more designated instances of the queue servers A N. As shown in for example the messages A N may be received by substantially any of the queue servers such as queue server A and queue server B for example. Based on the value of the strict order parameter associated with a message the queue server that initially receives the message from the corresponding queue producer may forward the message to a particular queue server that is associated with that value of the strict order parameter.

In one embodiment a range of values for the strict order parameter may be divided among the queue servers A N such that a particular one of the queue servers may be responsible for handling messages identified by each value of the strict order parameter. The range of values may include any collection of values and the values may include integers alphanumeric values binary values etc. In one embodiment each value of the strict order parameter may be assigned to one and only one of the queue servers A N. In one embodiment any of the queue servers A N may be responsible for one or more values of the strict order parameter.

The value of the strict order parameter for a message or a basis for the value may be generated by the corresponding queue producer. For example the value of the strict order parameter may be a string a binary value or an integer. In one embodiment a stable hash function may be applied by the initial recipient queue servers to the values of the strict order parameter as expressed in incoming messages. In this manner the various initial values for the strict order parameter may be standardized to a particular length and or data type within a known range for more efficient handling by the queue service . As used herein the term strict order parameter may refer to the original strict order parameter or the value thereof associated with a message or to the result of a hash function that uses the original strict order parameter as input. In one embodiment a message may be forwarded to an appropriate queue server i.e. a destination server based on the hash value.

In one embodiment each of the queue servers A N that is configured to receive incoming messages from the queue producers A N may include functionality for destination server determination. For example the queue server A may include a module A that implements the destination server determination functionality and the queue server B may include a module B that implements the destination server determination functionality. Using the destination server determination module A or B the corresponding queue server may compare the value of the strict order parameter of an incoming message to the range of values assigned to the various queue servers. The destination server determination module A or B may implement the destination server determination functionality using any suitable technique such as the use of a lookup function that maps an input value representing a strict order parameter to an output value representing a queue server. The destination server determination module A or B may determine the identity of the queue server to which the message should be forwarded i.e. the destination queue server based on the value of the strict order parameter for the message. The queue server A may forward one or more messages B to the queue server B based on one or more values of the strict order parameter and the queue server B may forward one or more messages A to the queue server A based on one or more values of the strict order parameter.

The value of the strict order parameter for the message may be within the range of values assigned to the destination queue server. The output of the destination server determination functionality may be stored for later reference using a module for storage of the destination server state. For example the queue server A may include a module A that implements the destination server state functionality and the queue server B may include a module B that implements the destination server state functionality. In one embodiment the destination server state A or B may represent a whole or partial list of active servers within the queue service .

In one embodiment the destination server determination modules A and B and or the states A and B may change if one or more new queue servers become active in the distributed strict queue system if one or more queue servers stop being active or are removed from the distributed strict queue system or if the range of values of the strict order parameter is otherwise reassigned to the queue servers. For example the range of strict order parameters may be rebalanced if a set of messages with a particular value for the strict order parameter begins placing excessive demands on the resources of the particular queue server assigned to that value of the strict order parameter. In such circumstances the load for the particular queue server may be reduced by reassigning one or more values of the strict order parameter to another queue server. As another example if the load provided by a set of messages with a particular value for the strict order parameter decreases sufficiently the responsible queue server may be assigned additional values of the strict order parameter so that it may optimize its resource usage. In one embodiment queue servers may be added to the distributed strict queue system or removed from the distributed strict queue system as needed to handle the current load and or anticipated load.

As shown in one or more components may be configured to serve as an interface between the queue producers A N and the queue servers A N. Each of the component s may be referred to as a forwarding server. Although one forwarding server is shown for purposes of example and illustration it is contemplated that different quantities and combinations of forwarding servers may be used. The forwarding server s may be implemented by the example computing device illustrated in . In one embodiment each forwarding server may be provisioned from among the queue servers A N. The one or more forwarding servers may be used to receive messages from the queue producers A N and forward each message to the appropriate queue server based on the value of the strict order parameter for the message. For example the one or more forwarding servers may forward one or more messages A to the queue server A based on one or more values of the strict order parameter one or more messages B to the queue server B based on one or more values of the strict order parameter and one or more messages N to the queue server N based on one or more values of the strict order parameter. As discussed above with reference to each forwarding server may include a module C for destination server determination and a module C for destination server state storage. The forwarding server s may be used with the distributed strict queue system on any suitable basis e.g. a queue by queue or account by account basis.

If the queue producer for a message does not supply a value for the strict order parameter then a value may be generated by another entity within the distributed strict queue system such as the queue server or forwarding server that initially receives the message from the queue producer. The value for the strict order parameter may be generated using any suitable technique including uniform random selection from a range of possible values e.g. within the same range of values assigned to the various queue servers A N or round robin selection from a range of possible values. The ranges of values may be a parameter of the distributed strict queue system or configurable per strict queue.

The queue server A may include a sequence identification functionality A. In one embodiment each incoming message within the range of strict order parameters assigned to the queue server A may undergo sequence identification using the sequence identification functionality A. The sequence identification functionality A may employ any suitable technique to assign each incoming message a place in a message sequence for the corresponding value of the strict order parameter. For example the sequence identification functionality A may generate a message sequence for the first value based on the messages received over time. The message sequence may indicate an ordering of the messages based on the time of receipt at the queue server A. The time of receipt may be based on the time of receipt of the first byte received the time of receipt of the last byte received or any time in between. Accordingly the message sequence for the first value may place the earlier message A before the later message N.

The sequence identification functionality A may assign a sequence identifier to each message. Each sequence identifier may indicate a respective position in the message sequence for the message where the respective position is based on the time of receipt e.g. the time of receipt of the first byte received the time of receipt of the last byte received or any time in between . In one embodiment the sequence identifier may include a timestamp e.g. indicating the time of receipt and or an ordinal number indicating the relative position of the message in a sequence associated with a particular value of the strict order parameter. In one embodiment the sequence identification functionality A may remember the last sequence identifier for a particular value of the strict order parameter as long as the particular value is active in the distributed strict queue system and associated with new messages provided to the queue server A. If the particular value of the strict order parameter has not been associated with a new message since the last message was delivered to a queue customer then the message sequence for that particular value may be discarded. The message sequence may be restarted e.g. from the beginning value if the one or more queue providers resume sending messages with the particular value of the strict order parameter to the queue server A.

After the sequence identifier has been added to an incoming message the queue server A may enqueue the message in a logical queue A. In one embodiment a logical queue may be managed by a single queue server e.g. server A and may contain only those messages associated with a particular value for the strict order parameter. The logical queue A may be strictly ordered for messages with a particular value of the strict order parameter. By referencing the sequence identifiers for messages having a particular value of the strict order parameter the messages may be added to the logical queue A in the order in which the messages were received by the queue server A that is designated to handle the particular value. As a result the logical queue A may include the messages for a particular value of the strict order parameter in a strict order relative to each other. For example the earlier message with a sequence identifier with the first value A and the later message with a sequence identifier with the first value N may be enqueued in the correct order relative to each other.

As shown in the queue server A may receive messages having different values for the strict order parameter. Although the queue server functionality is illustrated with reference to queue server A it is contemplated that the same or similar functionality may be implemented by any of the queue servers A N in the distributed strict queue system . At least two of the values of the strict order parameter may be assigned to the queue server A e.g. within a range of values assigned to the queue server A. Accordingly the queue server A may receive a set of messages from one or more of the queue producers A N where the set of messages includes both messages with a first value for the strict order parameter and messages with a second value for the strict order parameter. The messages may be received at different points in time. For example the messages may include an earlier message A and a later message N with the first value and the messages may also include an earlier message A and a later message N with the second value. Any suitable number of messages may be received by the queue server A. As discussed above the messages may be forwarded to the queue server A from another one of the queue servers or from a forwarding server based on the strict order parameters within the messages.

The queue server A may include a sequence identification functionality A. In one embodiment each incoming message within the range of strict order parameters assigned to the queue server A may undergo sequence identification using the sequence identification functionality A. The sequence identification functionality A may employ any suitable technique to assign each incoming message a place in a message sequence for the corresponding value for the strict order parameter. For example the sequence identification functionality A may generate a message sequence for the first value based on the messages A N with the first value received over time and the sequence identification functionality A may generate a message sequence for the second value based on the messages with the second value A N received over time. Each message sequence and may indicate an ordering of the messages based on the time of receipt at the queue server A. The time of receipt may be based on the receipt of the first byte of the message or the receipt of the last byte of the message. Accordingly the message sequence for the first value may place the earlier message A before the later message N and the message sequence for the second value may place the earlier message A before the later message N.

As discussed above the sequence identification functionality A may assign a sequence identifier to each message. Each sequence identifier may indicate a respective position in the message sequence for the message where the respective position is based on the time of receipt e.g. of the first byte or last byte . In one embodiment the sequence identifier may include a timestamp e.g. indicating the time of receipt and or an ordinal number indicating the relative position of the message in a sequence associated with a particular value of the strict order parameter.

After the sequence identifier has been added to an incoming message the queue server A may enqueue the message in a logical queue A for the first value of the strict order parameter or in a logical queue A for the second value of the strict order parameter. In one embodiment each logical queue A and A may be managed by a single queue server e.g. server A and may contain only those messages associated with a particular value for the strict order parameter. The logical queue A may be strictly ordered for messages with the first value of the strict order parameter and the logical queue A may be strictly ordered for messages with the second value of the strict order parameter. By referencing the sequence identifiers for messages having particular values of the strict order parameter the messages may be added to the appropriate logical queue A or A in the order in which the messages were received by the queue server A that is designated to handle the particular values. As a result the logical queue A may include the messages for the first value of the strict order parameter in a strict order relative to each other and the logical queue A may include the messages for the second value of the strict order parameter in a strict order relative to each other. For example the earlier message with a sequence identifier with the first value A and the later message with a sequence identifier with the first value N may be enqueued in the correct order relative to each other. Additionally the earlier message with a sequence identifier with the second value A and the later message with a sequence identifier with the second value N may be enqueued in the correct order relative to each other

In one embodiment the strict queue s may include a plurality of logical queues such as logical queues A and A. Each of the logical queues may be managed by a single queue server and may correspond to a particular value for the strict order parameter. Messages with the same value for the strict order parameter may be enqueued in the correct order relative to each other. However for messages with different values for the strict order parameter the queue service may use a best effort ordering technique that is not guaranteed to present messages with different values for the strict order parameter in the correct order. The best effort ordering may result in some messages with different values for the strict order parameter being placed in the queue s in a different order than the messages were received by the queue service . Accordingly the strict queue s may be strict for messages with the same value for the strict order parameter and non strict for messages with different values for the strict order parameter.

When a message is received by the primary server A and stamped with a sequence identifier the stamped message may be forwarded to the one or more backup servers e.g. secondary server B and tertiary server N . The replicated message A may be sent from the primary server A to the secondary server B and the replicated message B may be sent from the secondary server B to the tertiary server N. The tertiary server N may then send a confirmation of receipt N to the secondary server B and the secondary server B may then send a confirmation of receipt B to the primary server A. In one embodiment the primary server A may place the message in the logical queue A and or confirm the enqueuing of the message to the message source only after receiving the confirmation of receipt B from the secondary server B.

Similarly as shown in the example of when preparing to deliver a message to a consumer the primary server A may send updates A and B to the secondary server B and tertiary server N before delivering the message. The updates A and B may indicate that the primary server A is preparing to deliver the message. In one embodiment the message may be delivered to the consumer only after the one or more backup servers have confirmed receipt of the update s sent by the primary server e.g. with confirmations of receipt B and N. In one embodiment the delivery of a message to a consumer may include a preparation step in which the one or more backup servers are notified of the impending delivery a locking step to flag the message in the queue as locked after the message has been delivered and a deletion step to delete the message from the queue after the consumer has confirmed successful processing of the message. Updates A and B may be sent from the primary server to the one or more backup servers before each step and the step may be completed only after the one or more backup servers have confirmed receipt of the updates with receipt confirmations B and N. For example the primary server A may delete the message from the queue A only after receiving confirmation of processing from the consumer sending updates A and B to the secondary server B and tertiary server N and receiving confirmations B and N of receipt of the updates. In this manner the distributed strict queue system may provide guaranteed once delivery for messages i.e. a guarantee that each message is delivered once and only once using one or more backup servers in case the primary server A fails at some point during the delivery process.

In one embodiment in a similar manner as discussed above with reference to a queue consumer may be directed to an appropriate queue server based on one or more values of the strict order parameter assigned to the queue consumer. As shown in one or more components may be configured to serve as an interface between the queue consumers A N and the queue servers A N. Each of the component s may be referred to as a forwarding server. Although one forwarding server is shown for purposes of example and illustration it is contemplated that different quantities and combinations of forwarding servers may be used. The forwarding server s may be implemented by the example computing device illustrated in . The one or more forwarding servers may be used to receive requests from the queue consumers A N and forward each request to the appropriate queue server based on the one or more values of the strict order parameter associated with the requesting queue consumer. After a forwarding server determines a corresponding queue server for a particular queue consumer the queue server may push messages to the queue consumer or the queue consumer may pull messages from the queue server.

Each forwarding server may include a module for performing server determination a module for storing queue server state information and a module for storing queue consumer state information. In one embodiment one or more values of the strict order parameter may be assigned to each of the queue consumers using any suitable technique including uniform random selection from a range of possible values e.g. within the same range of values assigned to the various queue servers A N or round robin selection from a range of possible values. The value s of the strict order parameter associated with a particular queue consumer may be stored in the queue consumer state information . Using the server determination module the forwarding server s may compare the value s of the strict order parameter associated with a queue consumer to the ranges of values assigned to the various queue servers. The server determination module may implement the server determination functionality using any suitable technique such as the use of a lookup function that maps a value or range of values of the strict order parameter to a queue server. The server determination module may determine the identity of a queue server that should provide messages to a queue consumer based on one or more values or range of values of the strict order parameter associated with the queue consumer. The output of the server determination functionality may be stored for later reference using a module for storage of queue server state information.

After performing the server lookup process to determine the queue server responsible for a particular value or range of values of the strict order parameter the server determination module or any other suitable component of the forwarding server may forward a request e.g. a request from a queue consumer for messages to that queue server. If the logical queue corresponding to the value of the strict order parameter contains any messages that are available to the queue consumer then the queue server may return the next message in the logical queue to the queue consumer. If the logical queue corresponding to the value of the strict order parameter is empty then the association between the queue consumer and the value of the strict order parameter may be removed and the server determination module or any other suitable component of the forwarding server may restart the server lookup process.

If no queue server has messages among the queue servers that are responsible for the value s of the strict order parameter assigned to the queue consumer then the forwarding server may assign one or more new values or a range of values of the strict order parameter to the queue consumer and restart the lookup process. Alternatively the forwarding server may send a message to the queue consumer indicating that the queue consumer is not currently responsible for processing any messages. In response to such a message from the forwarding server the queue consumer may enter a sleep state in which its interaction with the distributed strict queue system is reduced.

By allowing queue servers to give preferential treatment to particular queue consumers based on the strict order parameter the efficiency and reliability of failover operations may be enhanced. Additionally the performance characteristics of a consumer may be enhanced by allowing the consumer to process messages for particular values of the strict order parameter particularly if the messages tend to require the same input data or other resources. The range of values of the strict order parameter assigned to various consumers may be rebalanced to optimize resource usage e.g. using load balancing techniques.

A range of strict order parameters may be divided among a plurality of queue servers. Each strict order parameter may be assigned to one and only one of the queue servers. As shown in the message may be forwarded to the assigned queue server based on the value of the strict order parameter or the hash thereof . The destination queue server may be determined using a functionality to determine the destination queue server based on the value of the strict order parameter for the message. The destination queue server may be a primary server for a range of values of the strict order parameter that includes the value in the current message. In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with the received message.

As shown in a sequence identifier may be assigned to the message at the queue server responsible for all of the messages with the strict order parameter. The sequence identifier may indicate a respective position in a message sequence for the strict order parameter. The respective position may be based on the time of receipt. The time of receipt may be based on the receipt of the first or last byte of the message at the destination queue server.

As shown in the message may be enqueued based on the sequence identifier. The message may be placed in a queue in a strict order with respect to other messages with the same value for the strict order parameter. In some cases however the message may be out of order with respect to messages with other values for the strict order parameter. In this manner the distributed strict queue system may ensure that messages with the same strict order parameter i.e. with the same values thereof are strictly ordered in a queue while messages with different strict order parameters i.e. with different values thereof are not necessarily in the correct order i.e. weakly ordered or non strictly ordered . In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with updates regarding the enqueuing of the message.

The queue client may comprise one or more computing devices any of which may be implemented by the example computing device illustrated in . In various embodiments portions of the functionality of the queue client may be provided by the same computing device or by any suitable number of different computing devices. If any of the components of the queue client are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions. In some embodiments the queue client may be implemented as one or more virtual compute instances and or physical compute instances. It is contemplated that the queue client may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown.

The queue service may maintain one or more logical queues such as logical queue A and logical queue B. Each logical queue may use a first in first out FIFO data structure to store one or more messages associated with a particular value for a strict order parameter. For example the logical queue A may store message A and message B through message N having one value for the strict order parameter and the logical queue B may store message A and message B through message N having another value for the strict order parameter. The messages may represent tasks or requests to be executed or otherwise implemented using appropriate computing resources. For example a message may describe or reference one or more instructions to be executed or interpreted using source data from one or more indicated data sources and or storing results in one or more indicated data destinations.

In one embodiment the queue service may include functionality to estimate a time i.e. a duration of time to process one of the messages. Processing a message may include performing or implementing the one or more tasks described in the message. For messages with the same value for the strict order parameter the processing stage may have a strictness guarantee such that the queue service is expected to perform the processing of the messages in a particular predetermined order. The queue service may also include functionality to estimate a time i.e. a duration of time to pre process one of the messages. Pre processing a message may include any part of the message computation for which strict ordering between different messages is not required. For example pre processing a message may sometimes include performing one or more tasks to prepare the message for processing such as fetching or otherwise loading the data described in the message as input for the processing stage. When pre processing a message includes fetching data the elements of input data may be acquired from any appropriate source s such as local storage locations remote storage locations and or other servers in a distributed system.

In one embodiment the pre processing and processing time estimates may be configured at the queue level such that the same estimates may generally be applied to all the messages in the queue by default but the queue level estimates may be overridden for particular messages in a queue. In one embodiment each message may have its own respective time estimates. Therefore the queue service may store the pre processing and processing time estimates per queue A and or per message B. Any suitable techniques may be used to determine the estimates. In one embodiment the time estimates may be determined based on a user specified configuration per message and or per queue. In one embodiment information usable to determine the estimates may be supplied by the queue producer using any suitable interface presented by the queue service . For example a message size parameter may be supplied by the queue producer on a message by message basis. The message size parameter may be an integer for which smaller values tend to indicate a shorter processing time and for which larger values tend to indicate a longer processing time. In one embodiment the queue service may be configured to programmatically estimate the pre processing and or processing times based on analysis of performance of the queue client over time. For example the queue service may programmatically determine a relationship between the message size parameter and processing time for various processed messages and the queue service may programmatically determine a relationship between the message size parameter and pre processing time for various processed messages. In this manner the queue service may generate better estimates for the pre processing and or processing times of subsequent messages based on the determined relationships between the message size parameter and the pre processing and or processing times for prior messages.

The queue client may receive a sequence of messages from the queue service and process the messages. In one embodiment the queue client may pull messages from the queue service . The client may pull messages from one or more of the logical queues A and B by sending one or more requests for one or more additional messages to the queue service or by otherwise initiating the pulling of messages from the queue service. In one embodiment the queue service may push messages to the queue client . Messages may be pushed to the queue client periodically based on an analysis of the queue client s health by the queue service . The queue client may send to the queue service an indication of the client s health at appropriate points in time. For example the queue client may send a health indication upon receipt of a message from the queue service . In general the health indication for a queue client may comprise any data usable by the queue service to determine whether to send additional messages to the queue client how many messages to send to the queue client and or how many logical queues to assign to the queue client. For example the health indication may tend to indicate the load at the client. Based on one or more of the health indications received over time the queue service may perform a rebalancing of the assignment of logical queues to the queue client and one or more additional queue clients. The queue service may also determine that a particular queue client is unnecessary if the other queue clients are able to handle the strict queue load consequently the queue service may reassign any logical queues to the other clients and may instruct the queue client considered unnecessary to enter a sleep state thereby reducing the queue client s traffic with the queue service

The queue client may also receive the time estimates for pre processing and processing each message. The time estimates for each message may be received along with the message on a message by message basis i.e. in a bundle along with the body of the message. In one embodiment relevant per queue time estimates A or relevant per message time estimates B may be sent by the queue service for each individual message.

Based on the pre processing and processing time estimates the queue client may implement a pipeline for pre processing and processing the messages . Using the pipeline the queue client may begin pre processing one message while continuing to process an earlier message. In other words the queue client may concurrently process one message and pre process another message. In one embodiment the queue client may include functionality for message pre processing and functionality for message processing . The message processor may be configured to perform the tasks described in the message e.g. by executing or interpreting instructions and or invoking functions or services included in the body of the message. In one embodiment the message pre processor may be configured to perform any tasks that may be used to prepare a message for processing such as fetching or otherwise loading the data described in the message as input for the processing stage. In general however the pre processing stage may include any computation for which a strict order guarantee is not required. For consecutive messages with different values for the strict order parameter both pre processing and processing may be performed concurrently. For consecutive messages with the same value for the strict order parameter the pre processing of the second message may sometimes be performed concurrently with the processing of the first message.

The queue client may include a scheduler component . In one embodiment the scheduler may schedule the receipt and or pre processing of the next message based on the estimated time to process the current message and estimated time to pre process the next message. For example if the estimated time to process the current message is 2.0 seconds and the estimated time to pre process the next message is 0.3 seconds then the scheduler may cause the queue client to begin pre processing the next message after the current message has been processing for 1.7 seconds. As a result the next message may be fully pre processed and ready for processing near the time when the processing of the current message is complete. Using the pipeline in this manner the queue client may perform all or part of the pre processing for a particular message by the time the client is ready to initiate the processing of the message. In one embodiment however the pre processing of the next message may be initiated at substantially any point in time during the processing of the current message even if the pre processing is likely to finish before the processing of the current message or after the processing of the current message.

When a message is first received by the queue client from the queue service the scheduler may receive and analyze the message. At different stages during the pre processing and processing of the message the queue service may use different flags to indicate the status of the message. For example the message may be flagged as prepared when sent to the queue client and as locked when processing begins. The message may be deleted from the queue or flagged for deletion when the queue service is informed by the queue client that processing is complete.

In one embodiment the queue client may include a heartbeat indicator functionality . Using the heartbeat indicator functionality the queue client may send one or more heartbeat indications at appropriate intervals. In one embodiment the health indications discussed above may be communicated using the same or similar modules. In one embodiment the heartbeat indication s may include data usable by the queue service to determine the load at the queue client . Using the heartbeat indication s for multiple queue clients the queue service may decide to put one or more of the clients to sleep if the heartbeats indicate that there are too many active clients for the current load represented by the queue s .

As shown in the queue client may initiate pre processing of the second message during the processing of the first message. The pre processing may comprise fetching data described in the second message or any other computation associated with the second message that is not required to be performed in a strict order with respect to the processing of the first message. The pre processing of the second message may be scheduled to begin based on the estimated time to process the first message and the estimated time to pre process the second message. In one embodiment the pre processing of the second message may be scheduled to be completed by the end of the processing of the first message based on the estimated time to process the first message and the estimated time to pre process the second message. In one embodiment the operation shown in may be performed during the processing of the first message based on analysis of the strict order parameters for the first and second messages.

As shown in the queue client may initiate processing of the second message. In one embodiment the processing of the second message may use any of the results generated from the pre processing of the second message. The processing of the second message may be initiated after the processing of the first message is completed. In this manner the queue client may implement a pipeline for pre processing and processing consecutive messages in a queue. The queue client may also send a status of the processing of any of the messages to the queue service e.g. after the processing of the message is complete.

It is contemplated that the queue service may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. The queue service may be implemented using one or more computing devices any of which may be implemented by the example computing device illustrated in . In some embodiments the queue service may be implemented as one or more virtual compute instances and or physical compute instances. In various embodiments portions of the functionality shown in may be provided by the same computing device or by any suitable number of different computing devices. If any of the components shown in are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions.

The queue service may maintain one or more logical queues such as logical queue A and logical queue B. Although two logical queues A and B are shown for purposes of example and illustration it is contemplated that different quantities of logical queues may be used. Each logical queue may use a first in first out FIFO data structure to store one or more messages associated with a particular value for a strict order parameter. For example the logical queue A may store a series of ordered messages such as messages A and B through N having one value for the strict order parameter and the logical queue B may store another series of ordered messages such as messages A and B through N having another value for the strict order parameter. The messages may represent tasks or requests to be executed or otherwise implemented using appropriate computing resources. For example a message may describe or reference one or more instructions to be executed or interpreted using source data from one or more indicated data sources and or storing results in one or more indicated data destinations.

In one embodiment the queue service may include functionality to generate batches of messages. The batch generation functionality may generate a batch that includes multiple messages. In one embodiment a message batch may include messages having a particular value for the strict order parameter. For example as shown in the batch generation functionality may generate a message batch A. The batch A may include a plurality of messages such as messages A and B through N taken from the logical queue A and having one value for the strict order parameter. Similarly the batch generation functionality may generate a message batch B. The batch B may include a plurality of messages such as messages A and B through N taken from the logical queue B and having another value for the strict order parameter. The batch generation functionality may generate the batches A and B such that the strictness guarantee is met for particular values for the strict order parameter. Accordingly messages within a batch that share a particular value for the strict order parameter may be strictly ordered e.g. based on the time of receipt at the queue server as discussed above with respect to . Additionally a batch may be locked on the originating queue server once the batch has been delivered to a queue client as a result the same batch may not be provided to another queue client unless the batch is unlocked e.g. due to a processing failure or timeout on the first queue client. In general the queue service may implement the same or similar behavior for batches as for individual messages.

In one embodiment a batch may be generated by the queue service in response to a request from a queue client for one or more messages. In one embodiment a batch may be generated by the queue service prior to receiving such a request from a queue client. In one embodiment the batches A and B may be generated by retrieving the constituent messages from the logical queues A and B and sending the batched messages to a queue client. As discussed above with respect to the messages included in the batch may remain in the one or more logical queues A and B but the status of the queued messages may be changed so that they are not delivered to another queue client while the recipient queue client is attempting to process the messages.

A batch may be generated in order to optimize the use of network resources processing resources memory resources or any suitable combination thereof. In one embodiment a batch may be generated in order to minimize the use of network bandwidth between the queue server s and queue client s . In one embodiment a batch may be generated in order to minimize the number of calls made over the network between the queue server s and queue client s . Accordingly the batch generation functionality may generate batches of a particular size e.g. batches having a particular number of messages batches having a total size in bytes within a particular range or batches having a combined message size parameter within a particular range. In one embodiment the queue service may delay sending messages to a queue client until a batch of sufficient size is ready in the interim the queue service may report to a queue client that no messages are available in the queue. In one embodiment the size of a batch may be determined using machine learning techniques. For example the queue service may send batches of varying sizes to the queue client analyze the performance of the client for the different sizes e.g. using performance metrics gathered by the queue client and or one or more queue servers and determine an optimal batch size for the client or class of clients. In one embodiment the individual messages in the batch may be compressed to further optimize the use of network resources. In one embodiment the batch may be compressed based on data derived from messages having one or more values for the strict order parameter for the messages in the batch.

In one embodiment a queue producer may send messages in batch form to the queue service . Because a batch from the queue producer may include messages having different values for the strict order parameter the queue service may divide such a batch into its constituent messages prior to forwarding the messages to one or more destination servers and placing the messages in one or more logical queues based on their individual values for the strict order parameter. As discussed above the messages may then be rebatched for delivery to one or more queue clients. As discussed above with respect to the queue service may confirm receipt of messages from a queue producer after all the messages have been delivered to the primary server and replicated to any secondary and or tertiary servers. Messages having different values for the strict order parameter may be delivered to different primary servers. In one embodiment to avoid a distributed commit problem involving different primary servers the queue service may reject batches from queue producers having multiple values for the strict order parameter.

In one embodiment the queue client may pull messages from the queue service . The client may pull messages from the queue service by sending one or more requests for one or more additional messages to the queue service or by otherwise initiating the pulling of messages from the queue service. In one embodiment the queue service may push messages to a queue client. The messages and or may be included as part of a batch. The queue client may send to the queue service an indication of the client s health at appropriate points in time. In one embodiment messages either single or batched may be pushed to the queue client periodically based on an analysis of the queue client s health by the queue service .

The queue client may receive the messages from the queue service in their intended order for each value of the strict order parameter and execute instructions in the messages or otherwise implement the messages. In one embodiment the queue service may deliver each message only once. The queue client may include a message processor that implements the instructions in the messages potentially by invoking the functionality of one or more backend systems. The queue client may also include a batch separator functionality that is configured to separate a batch into its constituent messages. In one embodiment the batch separator may provide the individual messages to the message processor in an order that meets the strict order guarantee.

As discussed above with respect to the queue client may send status updates for the processing of individual messages. In one embodiment the queue client may also include a functionality for batch processing verification . The batch processing verification functionality may send a batch processing response to the queue service . The response may indicate that the entire batch succeeded that the entire batch failed or that the batch partially succeeded and partially failed. In one embodiment the queue client may generate the response with the number of batched messages that were processed successfully and or the number of batched messages that were processed unsuccessfully. In one embodiment the queue client may generate the response with the number of batched messages that were processed successfully for particular values for the strict order parameter and or the number of batched messages that were processed unsuccessfully for particular values for the strict order parameter. The queue service may remove the successfully processed messages from one or more logical queues and mark the unsuccessfully processed messages for reprocessing. In one embodiment if the queue service does not receive the response or any intermediate results e.g. if the queue client dies or times out then the queue service may determine that the entire batch was processed unsuccessfully and mark the individual messages in the batch for reprocessing.

In one embodiment the queue service may attempt to retry the message processing for one or more messages in a batch potentially using log results for the failed message processing to recover from a partial failure. In one embodiment a message retry workflow may dictate how batch processing failures are handled by the queue service . For example the message retry workflow may pause the delivery of messages to queue clients for particular values for the strict order parameter. The message retry workflow may be specified by a user for failures in the processing of batched messages. The message retry workflow may vary for different values for the strict order parameter. Additional aspects of the message retry workflow are discussed below with respect to and .

The queue client may be implemented using any combination of the features described herein with respect to queue consumers and or queue clients such as the queue consumers A N. It is contemplated that the queue client may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. Although one queue client is shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue clients may be used. The queue client may be implemented using one or more computing devices any of which may be implemented by the example computing device illustrated in . In some embodiments the queue client may be implemented as one or more virtual compute instances and or physical compute instances. In various embodiments portions of the functionality shown in may be provided by the same computing device or by any suitable number of different computing devices. If any of the components shown in are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions.

In one embodiment a control operation involving the queue client may be delayed until the processing of a batch is complete by the queue client. In general the control operation may include any operation involving the queue client that is prompted by a control message sent by the queue service to the queue client. Control messages are discussed below with respect to . The control operation may include for example a deprovisioning of the queue client a rebalancing of the range of values for the strict order parameter etc. A batch sent to one queue client may include a particular value for the strict order parameter that the queue service seeks to rebalance e.g. by assigning the value to a different queue client. In such circumstances the queue service may wait until the first queue client has either successfully processed the entire batch or encountered a failure that causes the queue client to stop processing the remainder of the batch. Only after the attempted processing is complete may the queue service transfer the value for the strict order parameter to a different queue client.

A range of strict order parameters may be divided among a plurality of queue servers. Each strict order parameter may be assigned to one and only one of the queue servers. As shown in the message may be forwarded to the assigned queue server based on the value of the strict order parameter or the hash thereof . The destination queue server may be determined using a functionality to determine the destination queue server based on the value of the strict order parameter for the message. The destination queue server may be a primary server for a range of values of the strict order parameter that includes the value in the current message. In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with the received message.

As shown in the message may be enqueued based on the time of receipt. The time of receipt may be based on the receipt of the first or last byte of the message at the destination queue server. The message may be placed in a queue in a strict order with respect to other messages with the same value for the strict order parameter. In some cases however the message may be out of order with respect to messages with other values for the strict order parameter. In this manner the distributed strict queue system may ensure that messages with the same strict order parameter i.e. with the same values thereof are strictly ordered in a queue while messages with different strict order parameters i.e. with different values thereof are not necessarily in the correct order i.e. weakly ordered or non strictly ordered . In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with updates regarding the enqueuing of the message. One or more queue clients may be configured to dequeue and process the messages.

As shown in a batch may be generated to include the message and one or more additional messages. Messages within the batch may be strictly ordered based on the strict order parameter. In other words messages with a first value for the strict order parameter may be ordered correctly within the batch and messages with a second value for the strict order parameter may be ordered correctly within the batch. The batch may be generated either before a queue client requests messages or after e.g. in response to a request for messages from the queue client. The batch may be generated to optimize a use of network resources e.g. network bandwidth and or a quantity of calls made over the network.

As shown in the batch may be sent to a queue client. As discussed above for each value for the strict order parameter in the batch the messages for that value may be batched in the correct order. In other words messages with a first value for the strict order parameter may be ordered correctly within the batch and messages with a second value for the strict order parameter may be ordered correctly within the batch. The batch may be processed as a unit such that the processing of the entire batch may be considered to fail if the processing of any of the individual messages fails. In one embodiment the individual messages in the batch may be compressed to further optimize the use of network resources. In one embodiment the batch may be compressed based on data derived from messages having one or more values for the strict order parameter for the messages in the batch.

It is contemplated that the queue service and queue clients A N may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. For example although two queue clients A and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue clients may be used. The queue service and queue clients A N may be implemented using one or more computing devices any of which may be implemented by the example computing device illustrated in . In some embodiments the queue service and or queue clients A N may be implemented as one or more virtual compute instances and or physical compute instances. In various embodiments portions of the functionality shown in may be provided by the same computing device or by any suitable number of different computing devices. If any of the components shown in are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions.

The queue service may maintain one or more logical queues such as logical queue A and logical queue N. Although two logical queues A and N are shown for purposes of example and illustration it is contemplated that different quantities of logical queues may be used. Each logical queue may use a first in first out FIFO data structure to store one or more messages associated with a particular value for a strict order parameter. For example the logical queue A may store a series of ordered messages having one value for the strict order parameter and the logical queue N may store another series of ordered messages having another value for the strict order parameter. The messages may represent tasks or requests to be executed or otherwise implemented using appropriate computing resources. For example a message may describe or reference one or more instructions to be executed or interpreted using source data from one or more indicated data sources and or storing results in one or more indicated data destinations. Accordingly each of the queue clients A N may include a message processor that implements the instructions in the messages potentially by invoking the functionality of one or more backend systems.

In one embodiment a queue client may pull messages from the queue service . The client may pull messages from one or more of the logical queues A N sending one or more requests for one or more additional messages to the queue service or by otherwise initiating the pulling of messages from the queue service. In one embodiment the queue service may push messages to a queue client. The queue client may send to the queue service an indication of the client s health at appropriate points in time. In one embodiment messages may be pushed to the queue client periodically based on an analysis of the queue client s health by the queue service .

In one embodiment the queue service may include a functionality for client selection . The client selection functionality may select from a pool of potential queue clients one or more queue clients to process messages from one or more of the logical queue A N. The client selection functionality may use any suitable basis for selecting the queue client s . In various embodiments the client selection functionality may select a queue client based on performance optimization e.g. using system parameters and or performance metrics for clients cost optimization or any combination thereof. The client selection functionality may select a queue client to process a particular value or range of values for the strict order parameter. In one embodiment the queue client may be selected to process messages e.g. having a particular value or range of values for the strict order parameter if the message processing throughput for the messages would not exceed the available message processing throughput at the queue client. The message processing throughput may be determined based on the number of messages the average size of the messages e.g. based on the message size parameter the average time to process one of the messages and or any other suitable basis.

In one embodiment the queue clients may be selected based at least in part on system parameters of the clients. The system parameters may describe aspects of the hardware configuration and or software configuration of the corresponding client. For example the system parameters may describe any suitable aspect s of hardware and or software on the queue clients A N including processor resources memory including cache resources persistent storage resources network resources system software resources application software resources etc. In general the system parameters may describe the message processing capability of a computing instance on which a queue client is implemented. In various embodiments the system parameters may be used for client selection either before or after potential clients have been provisioned or begun processing messages.

In one embodiment the queue clients may be selected based at least in part on performance metrics for the clients. The performance metrics may describe aspects of the performance of the corresponding client. For example the performance metrics may describe any suitable aspect s of hardware and or software on the queue clients A N including processor metrics memory including cache metrics storage metrics network metrics etc. The performance may include real time metrics and or aggregated metrics. In general the performance metrics may describe the message processing capability of a queue client. In one embodiment the performance metrics may indicate a message processing performance e.g. as determined in processing one or more messages on the corresponding client. In one embodiment metrics may be associated with a value for the strict order parameter for the processed message. In one embodiment metrics may be associated with timestamps. In one embodiment metrics may be sent to the queue service at multiple stages such as pre processing processing and completion of processing for a single message. Using the metrics provided for message processing including pre processing and completion of processing the queue service may build a profile of the capabilities of an individual queue client. Accordingly the performance metrics may be used for client selection after one or more clients have already begun processing messages and generating performance metrics for the message processing. In some circumstances the performance metrics may be used for client selection after one or more clients have already processed messages but been terminated or quiesced the performance metrics may indicate the performance of message processing prior to the termination.

In one embodiment any of the queue clients A N may supply the system parameters and or performance metrics to the queue service . As shown in for example queue client A may determine and send system parameters A and performance metrics A as client metadata A. Similarly queue client N may determine and send system parameters N and performance metrics N as client metadata N. Alternatively the queue service may ascertain aspects of the client metadata such as the system parameters from a table or registry describing potential clients. The queue service may store the system parameters A N and performance metrics A N as the client parameters and metrics .

A particular queue client may be selected to process either an individual message or a particular value or range of values for the strict order parameter. The queue client may be matched to suitable message s based on the message processing capability of the client along with any data or metadata of the message s . In one embodiment a queue producer may provide along with one or more message data or metadata indicative of a minimum configuration for a queue client. In one embodiment the queue clients may be selected based at least in part on a message size parameter for individual messages. In one embodiment a message size parameter may be supplied by the queue producer on a message by message basis. The message size parameter may be an integer for which smaller values tend to indicate a shorter processing time and for which larger values tend to indicate a longer processing time. The queue service may determine a correlation between particular performance metrics for a queue client and the message size of messages provided to that queue client. Clients with greater computational resources may be assigned larger messages while clients with lesser computational resources may be assigned smaller messages. For values of the strict order parameter that tend to have large message sizes the queue service may assign those values to queue clients with sufficient resources to process the largest messages. If large messages occur only rarely for a particular value for the strict order parameter then the queue service may temporarily transfer responsibility for the corresponding value for the strict order parameter away from a less capable client and toward a more capable queue client when a large message is encountered.

In one embodiment the queue clients may be selected based at least in part on cost optimization. For example the software licensing costs for particular queue clients may be considered. Accordingly the queue service may maintain data describing client costs . The client costs may include costs of provisioning and or operating queue clients e.g. energy costs for particular classes of hosts. The client costs may include the costs of software licenses e.g. for software used in processing messages as well as system software and other support software. By optimizing for cost including software licensing cost the queue service may prefer to run fewer queue clients if each queue client requires a separate license. In such circumstances the queue service may select a fewer number of queue clients that have greater computational resources in order to provide sufficient processing power while minimizing the licensing cost. In other circumstances e.g. where one license covers multiple host machines the queue service may select a greater number of queue clients that have lesser computational resources. The queue service may also optimize the selection of queue clients based on the license requirements and or purchasing model. For example if a software license costs a particular amount over a particular interval of time then the queue service may have a preference for running clients in blocks of time that do not exceed the particular interval of time. In one embodiment the queue service may be aware of the cost of software licenses the number of available licenses the licensing scheme for particular licenses e.g. per time interval per host per core per site etc. and other preferences for licensing e.g. the queue service may prefer to revoke a license from a queue client on a temporary basis without terminating the queue client for the sake of faster reprovisioning . In one embodiment any number of computing instances for queue servers may be selected for use with the distributed strict queue system on a similar basis as described above with respect to selecting queue clients. In one embodiment any number of computing instances for network proxies may be selected for use with the distributed strict queue system on a similar basis as described above with respect to selecting queue clients.

In one embodiment the performance metrics A may be collected and or updated during the processing of the messages by the queue client A. The updated performance metrics A may be sent to the queue service for analysis e.g. by the client selection functionality . If the updated performance metrics A indicate that the queue client A does not have sufficient resources e.g. computational resources memory resources storage resources network resources etc. to process the messages efficiently then the client selection functionality may reduce the workload for the queue client A or terminate the queue client A. For example the queue service may rebalance the range of values for the strict order parameter to reduce the workload for the queue client A and increase the workload for one or more other queue clients. On the other hand if the updated performance metrics A indicate that the queue client A has more than sufficient resources e.g. computational resources memory resources storage resources network resources etc. to process the messages efficiently then the client selection functionality may increase the workload for the queue client A. For example the queue service may rebalance the range of values for the strict order parameter to increase the workload for the queue client A and terminate or decrease the workload for one or more other queue clients.

In a similar manner as the client selection discussed above the client provisioning and deprovisioning functionality may select from a pool of potential host machines one or more host machines to process messages from one or more of the logical queue A N. The client provisioning and deprovisioning functionality may use any suitable basis for selecting the queue client s . In various embodiments the client provisioning and deprovisioning functionality may select a queue client based on performance optimization e.g. using system parameters and or performance metrics for clients cost optimization or any combination thereof. In various embodiments the client provisioning and deprovisioning functionality may utilize the client selection functionality or implement a similar functionality. Typically queue clients may be provisioned to scale up the collective computational resources for processing messages and queue clients may be deprovisioned to scale down the collective computational resources for processing messages.

As shown in the queue service may provision a queue client A. In one embodiment the queue service may send one or more provisioning requests to an instance provider . In one embodiment the instance provider may select a computing instance A for use in implementing the queue client A. The instance provider may select the instance A from a pool of available instances based on information received from the queue service e.g. information generated using the client provisioning and deprovisioning functionality . In one embodiment the instance provider may select the instance A based on the hardware parameters of its host class its location with respect to one or more geographic or logical zones its cost of provisioning and or operation and any other suitable criteria. The selected instance A may be a physical computing instance or a virtual computing instance. The instance provider may also prepare the queue client A for processing queue messages by installing appropriate client software or otherwise configuring the queue client A. The provisioning request may include information usable by the client A to configure itself. In one embodiment the instance provider may obtain a state of the instance A including a health of the instance and or any relevant performance metrics at any suitable time e.g. after the selection and provisioning of the instance.

As shown in the queue service may deprovision a queue client A. In one embodiment the queue service may send one or more deprovisioning requests to an instance provider . In one embodiment the instance provider may perform any steps needed to deprovision or disable the computing instance A and or software of the queue client A. For example the instance provider may prepare the queue client A to discontinue processing queue messages terminate the queue client A or otherwise configure the queue client A. Additionally the instance provider may return the computing instance A used to implement the queue client A to a pool of available instances

In one embodiment one or more queue clients may be provisioned in anticipation of a need for additional computational resources. For example an atypically large quantity of messages or a quantity of messages having a larger size may be anticipated at a particular time based on past history. Accordingly the queue service or another component may track spikes in queue size and apply machine learning techniques to predict when additional queue clients may be needed in the future. At or before the time when the spike is expected to occur the queue service may provision one or more additional queue clients to handle the heavier load. In other words the additional queue client s may be provisioned prior to the actual receipt by the queue service of at least some of the spike in messages.

In one embodiment one or more queue clients may be deprovisioned to minimize software licensing costs for the queue clients. While the queue client s are deprovisioned the software licensing costs may be reduced or eliminated for the particular clients. For example the software licensing costs may be payable per interval of time e.g. per hour. While the queue client s are deprovisioned the queue service may accumulate messages in the one or more logical queues A N. Once a sufficient quantity of messages or messages of sufficient size have accumulated to warrant paying the software licensing cost for an interval of time the queue service may provision one or more queue clients to handle the accumulated load of messages.

A range of strict order parameters may be divided among a plurality of queue servers. Each strict order parameter may be assigned to one and only one of the queue servers. As shown in the message may be forwarded to the assigned queue server based on the value of the strict order parameter or the hash thereof . The destination queue server may be determined using a functionality to determine the destination queue server based on the value of the strict order parameter for the message. The destination queue server may be a primary server for a range of values of the strict order parameter that includes the value in the current message. In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with the received message.

As shown in the message may be enqueued based on the time of receipt. The time of receipt may be based on the receipt of the first or last byte of the message at the destination queue server. The message may be placed in a queue in a strict order with respect to other messages with the same value for the strict order parameter. In some cases however the message may be out of order with respect to messages with other values for the strict order parameter. In this manner the distributed strict queue system may ensure that messages with the same strict order parameter i.e. with the same values thereof are strictly ordered in a queue while messages with different strict order parameters i.e. with different values thereof are not necessarily in the correct order i.e. weakly ordered or non strictly ordered . In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with updates regarding the enqueuing of the message. Queue clients may be configured to dequeue and process the messages.

As shown in the message processing capabilities of queue clients may be determined. The message processing capabilities may be based on one or more system parameters and or one or more performance metrics. The system parameters may describe aspects of the hardware configuration and or software configuration of the corresponding client. The performance metrics may describe aspects of the performance of the corresponding client. The performance metrics may indicate a message processing performance e.g. as determined in processing one or more messages on the corresponding client.

As shown in the message processing throughput may be determined for individual values for the strict order parameter. In one embodiment the message processing throughput may be based at least in part on the average number of messages produced over a period of time for a particular value for the strict order parameter. In one embodiment the message processing throughput may be based at least in part on the average processing time for messages having a particular value for the strict order parameter. In one embodiment the message processing throughput may be based at least in part on the average size of messages for a particular value for the strict order parameter.

As shown in one or more queue clients may be selected to process individual messages in the queue s or to process particular values or ranges of values for the strict order parameter. In one embodiment the queue clients may be selected based at least in part on the message processing capabilities e.g. the system parameters and or performance metrics. When a client is selected to process particular values or ranges of values for the strict order parameter the message processing throughput of the values or ranges may not exceed an available throughput at the selected client. In one embodiment the queue clients may be selected to process particular messages based at least in part on any data or metadata in one or more messages such as a message size parameter for individual messages. For example clients with greater computational resources may be assigned larger messages while clients with lesser computational resources may be assigned smaller messages. In one embodiment the queue clients may be selected based at least in part on cost optimization. For example the software licensing cost for particular queue clients may be considered. In one embodiment one or more software licenses may be reserved for particular queue clients e.g. when the clients are provisioned.

It is contemplated that the queue service and queue client A may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. For example although one queue client A is shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue clients may be used. The queue service and queue client A may be implemented using one or more computing devices any of which may be implemented by the example computing device illustrated in . In some embodiments the queue service and or queue client A may be implemented as one or more virtual compute instances and or physical compute instances. In various embodiments portions of the functionality shown in may be provided by the same computing device or by any suitable number of different computing devices. If any of the components shown in are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions.

The queue service may maintain one or more logical queues such as logical queue A and logical queue N. Although two logical queues A and N are shown for purposes of example and illustration it is contemplated that different quantities of logical queues may be used. Each logical queue may use a first in first out FIFO data structure to store one or more messages associated with a particular value for a strict order parameter. For example the logical queue A may store a series of ordered messages having one value for the strict order parameter and the logical queue N may store another series of ordered messages having another value for the strict order parameter. The messages may represent tasks or requests to be executed or otherwise implemented using appropriate computing resources. For example a message may describe or reference one or more instructions to be executed or interpreted using source data from one or more indicated data sources and or storing results in one or more indicated data destinations. Accordingly each of the queue clients may include client software configured to process messages such as client software A for queue client A. The client software A may implement the instructions in the messages potentially by invoking the functionality of one or more backend systems.

In one embodiment a queue client may pull messages from the queue service . The client may pull messages from one or more of the logical queues A N sending one or more requests for one or more additional messages to the queue service or by otherwise initiating the pulling of messages from the queue service. In one embodiment the queue service may push messages to a queue client. The queue client may send to the queue service an indication of the client s health at appropriate points in time. In one embodiment messages may be pushed to the queue client periodically based on an analysis of the queue client s health by the queue service .

Each of the queue clients may include a configuration that may impact the processing of messages such as client configuration A for queue client A. The client configuration A may include a configuration of system software on the queue client A including one or more tunable parameters of the system software. For example the client configuration A may indicate a heap size for a virtual machine the client software A may run within the virtual machine. In one embodiment the client configuration A may include a hardware configuration. In general the client configuration A may control any suitable aspect s of hardware and or software on the queue client A including processor usage cache usage transient memory usage persistent storage usage network usage system software usage application software usage etc. Additionally the client software A may have its own configuration including one or more tunable parameters. For example the parameters of the client software A may affect the way in which the client software A processes messages emits metrics emits logs communicates with the queue service etc.

In one embodiment the queue service may include a functionality for control message generation . The control message generation functionality may generate one or more control messages a control message when executed or implemented by a queue client may modify the client configuration and or configuration of the client software. As shown in the queue service may generate and send a control message to the queue client A. The control message may be sent once to any set of one or more queue clients selected by the queue service . The control message may include one or more commands to be executed or implemented by the queue client A e.g. terminal level commands or other system level commands. The execution of such commands may result in a change in one or more system parameters or any other change in the client configuration A at the queue client A. Alternatively the control message may include one or more commands to be executed or implemented by the client software A. The execution of such commands may result in a change in one or more parameters of the client software A at the queue client A. The control message may trigger the queue client A to download executable program code from another component. For example the control message may trigger the queue client A to update the client software A by downloading a new version of the software or an update to the software from another component. In one embodiment the control message may cause a modification in how messages are processed by the queue client A. The control messages may be sent using the same data channel as the regular queue messages or using out of band communications techniques.

In one embodiment client configurations may be modified differently for different value or ranges of values for the strict order parameter. In one embodiment client configurations may be modified based on a user preference or user specification. In one embodiment any suitable information in a queue message as specified by a user may be used to modify one or more client configurations. For example messages with a message size parameter lower than a particular threshold may be assigned to lightweight clients. Similarly messages with a message size parameter exceeding a particular threshold may be assigned to clients having sufficient resources to process such messages the assignment of the strict order parameter may be transferred from one machine to another on a temporary basis to process a larger message. As another example if values or ranges of values for the strict order parameter are assigned to particular clients due to heavier processing requirements for the values then the configurations of those clients may vary from the configurations of other clients in order to permit efficient processing of messages.

In one embodiment the client software registry may be updated using information sent from the one or more queue clients A N. For example as shown in queue client A may send a client software description A to the queue service and queue client N may send a client software description N to the queue service . The client software descriptions A and N may identify any relevant aspect of the client software installed on the corresponding queue client such as the name version and or other indication of functionality of the client software. Based on the client software descriptions A and N the client software registration functionality may update the client software registry for the queue clients A N. Additionally the client software registration functionality may update the client software registry for particular queue clients based on a standard configuration that the queue clients are known to have e.g. when the queue clients are provisioned from a hardware pool based on known characteristics of the provisioned machines.

In one embodiment the queue clients A N may also send data describing their respective configurations A N to the queue service . For example queue client A may send a client configuration description A to the queue service and queue client N may send a client configuration description N to the queue service . The queue service may store aspects of the client configuration descriptions A N e.g. using the client software registration functionality or an equivalent functionality. Based on the client software descriptions A N and or the client configuration descriptions A N the queue service may determine how to maintain or modify the client software A N and or client configurations A N.

The queue service may send one or more control messages to other queue clients such as queue client N to modify the client software on the other queue client s to a different version. In this manner the queue service may selectively modify the client software of different queue clients in different ways. For example the queue service may perform rolling deployments of client software to different queue clients. In one embodiment queue clients that are responsible for different ranges of values for the strict order parameter may have their client software updated in a different manner e.g. with different versions of client software or different types of client software.

In one embodiment the queue service may send one or more messages potentially including control messages to initiate the software testing on one or more clients. As shown in for example the queue service may send one or more messages A to initiate the testing of the updated client software B on the queue client A. Similarly the queue service may send one or more messages N to initiate the testing of the other client software N on the queue client N. The tests may be conducted by the corresponding queue clients by executing or implementing queue messages to perform various tasks. In one embodiment each of the tested queue clients may send metrics logs and or other results such as test results A and N to the queue service . Using the test results A and N the client software testing functionality may determine any differences between the client software B and the client software N with respect to their functionality performance and or results.

In one embodiment the same or similar messages may be provided to two or more versions or types of client software in order to determine the differences. In one embodiment any of the tested clients may be isolated from a network during the testing e.g. using the I O fencing techniques discussed below with respect to . In one embodiment dummy messages may be provided to the tested client software. A dummy message may include one or more steps tasks or operations to be performed potentially by the queue client invoking one or more backend systems. Dummy messages are discussed in greater detail below with respect to .

In one embodiment an I O fenced client processing real messages may be compared to another client with a different version or type of client software. A message may be processed using a first client running a first version or type of client software. Traffic between one or more external components and the first client may be captured in the processing of the message. The same message may be processed using a second client running a second version or type of client software. To simulate interactions with the external component s I O fencing with I O mimicry may be implemented for the second client e.g. using a network proxy layer. Accordingly the captured traffic from the first client e.g. any responses from the external component s may be replayed for the second client so that the second client can process the message properly. Results and or metrics may be compared for the first client and the second client to evaluate the modified client software.

In one embodiment real i.e. not dummy messages may be sent to a queue client for processing using modified client software. The attempted processing of the messages may be evaluated using any suitable metrics and or logs. In one embodiment the queue client A may be responsible for a particular range of values for the strict order parameter and its client software B may be configured and or updated based on that range. Similarly the queue client N may be responsible for a different range of values for the strict order parameter and its client software N may be configured and or updated differently based on that range. In one embodiment a particular range of values for the strict order parameter may be assigned to a queue client as part of the software testing e.g. to test the operation of a particular version and or type of client software as it processes messages within the assigned range of values for the strict order parameter. In one embodiment if the tested client software performs in a satisfactory manner it may be deployed to other queue clients that are collectively responsible for a larger range of values for the strict order parameter. Accordingly the queue service may modify the client software for a limited set of queue clients test the client software for the limited set of clients and roll out the modified software for additional clients potentially for additional tests if the tests succeed.

In one embodiment the client software testing functionality may perform different actions for software testing in various circumstances. For example the queue service may update client software to a new version and test the updated software with dummy messages. If the dummy message testing succeeds the queue service may perform additional tests to compare the updated software with another version of the software e.g. an earlier version on one or more other clients for a particular percentage e.g. 1 of calls. If the additional testing succeeds for a particular interval of time e.g. 24 hours then the queue service may perform further tests for a particular percentage e.g. 2 of calls for a particular interval of time e.g. 12 hours . The queue service may then gradually shift traffic to the updated software.

Various actions may be taken by the queue service if the testing fails for one or more queue clients. For example software testing for all or part of a fleet may be suspended if a failure threshold is exceeded. As another example the queue service may send a control message to revert software modifications e.g. to restore a previously installed version of client software on one or more clients. As yet another example the queue service may stop the rollout of a configuration or of client software. In one embodiment the queue service may inform a user e.g. an administrator of the queue service and or a customer of the queue service of failed software tests including relevant details of the failure s and or summaries of multiple failures. Elements of the failure report may be based on logs collected during the software testing.

A range of strict order parameters may be divided among a plurality of queue servers. Each strict order parameter may be assigned to one and only one of the queue servers. As shown in the message may be forwarded to the assigned queue server based on the value of the strict order parameter or the hash thereof . The destination queue server may be determined using a functionality to determine the destination queue server based on the value of the strict order parameter for the message. The destination queue server may be a primary server for a range of values of the strict order parameter that includes the value in the current message. In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with the received message.

As shown in the message may be enqueued based on the time of receipt. The time of receipt may be based on the receipt of the first or last byte of the message at the destination queue server. The message may be placed in a queue in a strict order with respect to other messages with the same value for the strict order parameter. In some cases however the message may be out of order with respect to messages with other values for the strict order parameter. In this manner the distributed strict queue system may ensure that messages with the same strict order parameter i.e. with the same values thereof are strictly ordered in a queue while messages with different strict order parameters i.e. with different values thereof are not necessarily in the correct order i.e. weakly ordered or non strictly ordered . In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with updates regarding the enqueuing of the message. One or more queue clients may be configured to dequeue and process the messages.

As shown in a control message may be sent from the queue server s to one or more queue clients. When executed or otherwise implemented at a queue client the control message may cause modification of a configuration at the queue client. Accordingly as shown in the queue client s may modify their configuration s based on the control messages. In one embodiment the modification may include a change in one or more parameters of client software at the queue client s . In one embodiment the modification may include a change in one or more system parameters of at the queue client s . The queue client s may be configured to process the messages based on the modified configuration s .

It is contemplated that the queue service and queue clients A N may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. For example although two queue clients A and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue clients may be used. The queue service and queue clients A N may be implemented using one or more computing devices any of which may be implemented by the example computing device illustrated in . In some embodiments the queue service and or queue clients A N may be implemented as one or more virtual compute instances and or physical compute instances. In various embodiments portions of the functionality shown in may be provided by the same computing device or by any suitable number of different computing devices. If any of the components shown in are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions.

The queue service may maintain one or more logical queues such as logical queue A and logical queue N. Although two logical queues A and N are shown for purposes of example and illustration it is contemplated that different quantities of logical queues may be used. Each logical queue may use a first in first out FIFO data structure to store one or more messages associated with a particular value for a strict order parameter. For example the logical queue A may store a series of ordered messages having one value for the strict order parameter and the logical queue N may store another series of ordered messages having another value for the strict order parameter. The messages may represent tasks or requests to be executed or otherwise implemented using appropriate computing resources. For example a message may describe or reference one or more instructions to be executed or interpreted using source data from one or more indicated data sources and or storing results in one or more indicated data destinations. Accordingly each of the queue clients A N may include a message processor such as message processor A for queue client A and message processor N for queue client N. The message processors A N may implement the instructions in the messages potentially by invoking the functionality of one or more backend systems.

In one embodiment a queue client may pull messages from the queue service . The client may pull messages from one or more of the logical queues A N sending one or more requests for one or more additional messages to the queue service or by otherwise initiating the pulling of messages from the queue service. In one embodiment the queue service may push messages to a queue client. The queue client may send to the queue service an indication of the client s health at appropriate points in time. In one embodiment messages may be pushed to the queue client periodically based on an analysis of the queue client s health by the queue service .

In one embodiment each of the queue clients A N may include a log data generation functionality such as log data generator A for queue client A and log data generator N for queue client N. The log data generator A may generate log data A and the log data generator N may generate log data N. Each log data generator may generate log data that describes aspects of the message processing on the local queue client. For example the log data may indicate the success or failure of the attempted processing of each individual message along with one or more identifiers of the message including a message identifier and optionally the value of the strict order parameter for the message. In one embodiment the log data may indicate a response such as message processing completed but failed for a particular message. In one embodiment the log data may include status updates for the processing of a particular message. In some embodiments the log data may also include an indication of any operations taken to execute a message an indication of inputs or other parameters used in such operations and or an indication of the output or results of such operations etc. Each queue client A N may send its log data A N to the queue service . Elements of the log data may be sent at any suitable time. For example individual elements of the log data may be sent shortly after they are generated by the log data generator.

The queue service may include a functionality for log data storage . In various embodiments the log data storage may be implemented using any suitable combination of persistent storage resources and transient storage resources and the storage resources may be located either on host or off host with respect to any of the queue servers in the queue service . The log data storage may use any suitable techniques and data structures for organizing and storing the elements of log data. In one embodiment elements of log data related to the processing of a particular message may be associated with the value for the strict order parameter for that message. Accordingly the log data storage may store log data with various values for the strict order parameter such as log data A with a first value for the strict order parameter to log data N with an Nth value for the strict order parameter. In various embodiments the log data for a particular value for the strict order parameter may be stored separately from or mixed with the log data for other values for the strict order parameter. As will be discussed below the log data A N may be used by the queue service to implement various failure management tasks.

In some embodiments the log data A N may be compressed. The log data may be compressed across multiple messages using one or more compression dictionaries specific to one or more values for the strict order parameter one or more queue clients one or more queue servers or any other suitable dimension. In some embodiments the log data A N may be searchable e.g. to find patterns for common types of failure. The search may present such incidents as known error cases. A user may view the known error cases in a manner independent of any particular message. In one embodiment the user may also view a message that is exemplary of a type of known error case. In one embodiment a user may be alerted when specific types of error cases are found in the log data e.g. with automated searching or pattern matching . In one embodiment user input may be solicited for failure management when specific types of error cases are found in the log data e.g. with automated searching or pattern matching .

The queue service may analyze one or more message processing failures and take appropriate action to mitigate future message processing failures. In one embodiment the queue service may analyze the failed message processing at one or more queue clients and determine that a particular type of message is responsible for the failures. In one embodiment the queue service may analyze multiple message processing failures occurring over a period of time and decide to suspend operations e.g. at one or more queue clients for a particular message type or a particular range of values for the strict order parameter. In one embodiment the queue service may cancel the processing of particular messages and or pull particular messages from their queue s upon detecting a failure of those messages and or a failure of messages with the same value for the strict order parameter.

If the attempted processing of a message fails at one of the queue clients the queue service may determine the failure. In some circumstances the queue service may determine the failure by determining that the queue client has timed out or otherwise failed. In some circumstances the queue client may send log data or another indication of the failure. For example as shown in the queue client A may send log data indicating a message processing failure. The log data may indicate among other data the message identifier and or the value for the strict order parameter for each message for which the attempted message processing failed. The log data may be stored using the log data storage . The message retry workflow may attempt to recover from the failure of the message processing. For example the message retry workflow may attempt to retry the failed processing of the message a particular number of times using one or more queue clients potentially including the same client that previously failed. As another example the message retry workflow may attempt to retry the failed processing of the message using one or more other queue clients. Accordingly the message retry workflow may implement a message processing retry by providing to the queue client N one or more messages whose processing previously failed with the queue client A. In one embodiment the message processing retry may involve transferring responsibility for one or more values for the strict order parameter from the queue client A to the queue client N at least temporarily. Using the message processor N the queue client N may then attempt to process the one or more messages whose processing previously failed with the queue client A.

The message processing retry may include sending all or part of the log data for the failed message s to the queue client N. The log data sent to the retry client N may associate each message to be retried with a message identifier and or the value for the strict order parameter for the message. In one embodiment the log data or other metadata sent to the retry client N may indicate that processing has previously failed for a particular message. In one embodiment the log data or other metadata sent to the retry client N may include the number of times that the attempted processing has failed for a particular message. In one embodiment the log data sent to the retry client N may include an estimated reason that the attempted processing failed for a particular message. In one embodiment the log data or other metadata sent to the retry client N may include the partial results of the attempted processing for a particular message is the processing failed before it was complete. In one embodiment the log data sent to the retry client N may include an indication of processing steps that were performed successfully before the message processing failed. Accordingly the retry client N may verify that such steps were indeed successfully completed before continuing the processing of a message with one or more additional steps. In this manner the log data may be used for efficient and automated recovery from message processing failure.

The dummy message A may be provided to a queue client such as queue client A by the queue service in order to verify the health of the recipient queue client i.e. the expected functioning of the recipient queue client for message processing. The dummy message A may be provided to the client A in the same manner or a similar manner as normal messages are provided to the client e.g. by permitting the client to dequeue the dummy message from a logical queue. In one embodiment the dummy message may be provided to the queue client A in response to the queue client A failing to process one or more messages successfully. The queue client A may attempt to process the dummy message A and generate results A of the attempted processing. The queue client may send the dummy message results A to the queue service . The results A may typically indicate the success or failure of the attempted processing of the dummy message A. The queue service may take any suitable steps in response to the dummy message results A. For example if queue service suspends the queue client s ability to access one or more logical queue after a message processing failure the queue service may restore the client s access to the logical queue s after the client successfully processes the dummy message A. As another example if the queue client A fails to successfully process one or more dummy messages in a particular number of attempts the queue service may blacklist the queue client A e.g. restrict the client from receiving any additional messages from one or more logical queues. A user may be informed of the blacklist and potentially of the reasons for the blacklist. The blacklist may be temporary.

In one embodiment the dummy messages A N may be sent to the queue clients A N if the queue service has determined that multiple queue clients have recently failed. If the attempted processing fails for multiple dummy messages at multiple clients e.g. meeting or surpassing some predefined failure threshold the queue service may take any suitable actions. For example the queue service may determine that a large scale event is occurring such as a network outage or failure of a backend system and suspend at least some operations such as providing messages to queue clients until the large scale event appears to be over. In one embodiment the queue service may suspend operations on a subset of queue clients. In one embodiment the queue service may terminate and or restart one or more queue clients after the large scale event has ended.

A range of strict order parameters may be divided among a plurality of queue servers. Each strict order parameter may be assigned to one and only one of the queue servers. As shown in the message may be forwarded to the assigned queue server based on the value of the strict order parameter or the hash thereof . The destination queue server may be determined using a functionality to determine the destination queue server based on the value of the strict order parameter for the message. The destination queue server may be a primary server for a range of values of the strict order parameter that includes the value in the current message. In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with the received message.

As shown in the message may be enqueued based on the time of receipt. The time of receipt may be based on the receipt of the first or last byte of the message at the destination queue server. The message may be placed in a queue in a strict order with respect to other messages with the same value for the strict order parameter. In some cases however the message may be out of order with respect to messages with other values for the strict order parameter. In this manner the distributed strict queue system may ensure that messages with the same strict order parameter i.e. with the same values thereof are strictly ordered in a queue while messages with different strict order parameters i.e. with different values thereof are not necessarily in the correct order i.e. weakly ordered or non strictly ordered . In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with updates regarding the enqueuing of the message. One or more queue clients may be configured to dequeue and process the messages.

As shown in log data may be received from the one or more queue clients at individual ones of the queue servers. The log data may be descriptive of the attempted message processing. In one embodiment the log data may indicate the message identifiers and or respective values for the strict order parameter for the messages for which message processing was attempted. Various steps may be taken for failure management if the queue system determines that the attempted message processing failed for one or more messages. In one embodiment the failure management may be based on a specification for an automated workflow as received from a user. For example a message and log data for the message may be resent to an additional queue client the additional queue client may retry the message processing for the message based at least in part on the log data for the message. If the queue system determines that the attempted message processing failed at a particular queue client for a number of messages exceeding a failure threshold the queue system may discontinue sending additional ones of the messages to the particular queue client based on the log data.

If the queue system determines that the attempted message processing failed one or more times at a particular queue client the queue system may send a dummy message to the queue client. The queue client may attempt message processing for the dummy message where a successful message processing for the dummy message verifies a proper functioning of the queue client. If the queue system determines that the attempted message processing failed one or more times at a particular queue client the queue system may send a dummy message to the queue client determine that the attempted message processing for the dummy message failed at the queue client and discontinue sending additional messages to the queue client based on the additional log data. In one embodiment the queue system may send a dummy message to multiple queue clients that are configured to attempt message processing for the dummy message. If the queue system determines that the attempted message processing for the dummy message failed for at least some the queue client the queue system may determine that a large scale event is affecting proper functioning of the queue clients based on the additional log data.

It is contemplated that the queue service and queue clients A N may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. For example although two queue clients A and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue clients may be used. The queue service and queue clients A N may be implemented using one or more computing devices any of which may be implemented by the example computing device illustrated in . In some embodiments the queue service and or queue clients A N may be implemented as one or more virtual compute instances and or physical compute instances. In various embodiments portions of the functionality shown in may be provided by the same computing device or by any suitable number of different computing devices. If any of the components shown in are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions.

The queue service may maintain one or more logical queues such as logical queue A and logical queue N. Although two logical queues A and N are shown for purposes of example and illustration it is contemplated that different quantities of logical queues may be used. Each logical queue may use a first in first out FIFO data structure to store one or more messages associated with a particular value for a strict order parameter. For example the logical queue A may store a series of ordered messages having one value for the strict order parameter and the logical queue N may store another series of ordered messages having another value for the strict order parameter. The messages may represent tasks or requests to be executed or otherwise implemented using appropriate computing resources. For example a message may describe or reference one or more instructions to be executed or interpreted using source data from one or more indicated data sources and or storing results in one or more indicated data destinations. Accordingly each of the queue clients A N may include a message processor such as message processor A for queue client A and message processor N for queue client N. The message processors A N may implement the instructions in the messages potentially by invoking the functionality of one or more backend systems.

In one embodiment a queue client may pull messages from the queue service . The client may pull messages from one or more of the logical queues A N sending one or more requests for one or more additional messages to the queue service or by otherwise initiating the pulling of messages from the queue service. In one embodiment the queue service may push messages to a queue client. The queue client may send to the queue service an indication of the client s health at appropriate points in time. In one embodiment messages may be pushed to the queue client periodically based on an analysis of the queue client s health by the queue service .

In one embodiment the queue service may implement one or more network proxies such as network proxy . The network proxy may act as an intermediary for requests from some components seeking to contact other components over a network. In one embodiment the network proxy may act as an intermediary for network interactions between one or more of the queue clients A N and one or more external components . The external components generally include servers and or services other than the queue servers and queue clients. The external components may include for example one or more backend systems or services that are invoked by the queue clients A N to process messages from one or more logical queues A N. The network proxy may be implemented using any suitable software and or hardware resources. In one embodiment the network proxy may be implemented using one or more queue servers and or any other suitable component s of the queue service running appropriate software. In one embodiment the network proxy may be implemented using one or more hardware components that are external to the queue servers.

In one embodiment input output for a set of queue clients A N may be managed by the queue service using the network proxy . Accordingly outbound traffic A and inbound traffic A for the queue client A may be routed through the network proxy and outbound traffic N and inbound traffic N for the queue client N may be routed through the network proxy . The network proxy may contact one or more external components on behalf of the clients A N by sending and or receiving traffic . The traffic may thus include elements of the outbound traffic A inbound traffic A outbound traffic N and or inbound traffic N. In one embodiment the network proxy may provide SSL Secure Sockets Layer termination. In providing SSL termination the network proxy may handle incoming SSL connections e.g. by decrypting an incoming request and passing the unencrypted request to one or more queue servers and or queue clients.

By funneling the outbound traffic A inbound traffic A outbound traffic N and or inbound traffic N through the network proxy the queue service may generate and store a wire log describing aspects of the traffic. The wire log may be persisted independently of any of the queue clients. Accordingly the queue service may include a functionality for wire log generation. The wire log generator may generate log data that describes aspects of the network traffic including aspects of outbound traffic A inbound traffic A outbound traffic N and or inbound traffic N. The wire log data may indicate the sender recipient and timestamp for each network interaction. In some embodiments the wire log data may include an indication of any functions invoked in the external component s parameters or responses passed from queue clients A N to the external component s parameters or responses passed from the external component s to the queue clients A N and or any other data that describes aspects of message processing.

In one embodiment elements of the network traffic may be deliberately omitted from the wire log e.g. as configured by a user. For example the wire log may keep HTTP bodies but omit HTTP headers for HTTP traffic. The omitted data may be represented in the wire log by a byte count and or hash of the omitted data in a manner that may be parsed by the queue service . In one embodiment a level of logging may be configured e.g. by a user and or customer. The level of logging may be based at least in part on suitable parameters such as the external component endpoint the size of the data and wire log persistence only in cases of failure. In one embodiment data fields in the wire log may be blacklisted or otherwise obscured e.g. by a user and or customer. For example sensitive data in the network traffic may be stripped from the wire log by parsing the traffic to identify the sensitive data in specific locations.

In one embodiment the queue service may parse network interactions between the queue clients and the external component s to determine a message identifier and or value for the strict order parameter associated with a particular interaction. Accordingly the queue service may have a sufficient understanding of application protocols to determine the message identifiers and or values for the strict order parameter in the network traffic. In one embodiment the queue clients may be configured to include the message identifiers and or values for the strict order parameter in elements of outbound traffic. The wire log may associate the message identifiers and or values for the strict order parameter with particular interactions.

In various embodiments the wire log generator may store wire log data using any suitable combination of persistent storage resources and transient storage resources and the storage resources may be located either on host or off host with respect to any of the queue servers in the queue service . The wire log data storage may use any suitable techniques and data structures for organizing and storing the elements of log data. In one embodiment elements of wire log data related to the processing of a particular message may indicate the message identifier and or value for the strict order parameter for that message. Accordingly the wire log generator may store log data with various values for the strict order parameter such as wire log data A with a first value for the strict order parameter to wire log data N with an Nth value for the strict order parameter. In various embodiments the wire log data for a particular value for the strict order parameter may be stored separately from or mixed with the wire log data for other values for the strict order parameter.

In some embodiments the wire log data A N may be compressed. The wire log data may be compressed across multiple messages using data specific to one or more values for the strict order parameter one or more queue clients one or more queue servers or any other suitable dimension. In some embodiments the log data A N may be searchable e.g. to find patterns for common types of failure. The search may present such incidents as known error cases. A user may view the known error cases in a manner independent of any particular message. In one embodiment the user may also view a message that is exemplary of a type of known error case. In one embodiment a user may be alerted when specific types of error cases are found in the log data e.g. with automated searching or pattern matching . In one embodiment user input may be solicited for failure management when specific types of error cases are found in the log data e.g. with automated searching or pattern matching .

In one embodiment a queue client may be I O fenced in order to mitigate the effects of malfunctions at the client. In one embodiment a queue client may be I O fenced after its number of failed attempts at message processing exceeds some failure threshold. In one embodiment a queue client may be I O fenced in order to expedite the transfer of responsibility for one or more messages and potentially one or more values for the strict order parameter from the I O fenced queue client to another queue client. To permit the client software on the I O fenced queue client to function properly the queue service may mimic interactions between the I O fenced queue client and one or more external components . For example the queue service may provide responses to function calls initiated by the I O fenced queue client to the one or more external components .

If the attempted processing of a message fails at one of the queue clients the failure may be indicated in the wire log data A N. For example as shown in the queue client A may send one or more indications of message processing failure to the queue service . The wire log data associated with the failed message s may indicate among other data the message identifier and or value for the strict order parameter for each message for which the attempted message processing failed. Based on the wire log data A N the message retry workflow may attempt to recover from the failure of the message processing. For example the message retry workflow may attempt to retry the failed processing of the message a particular number of times using one or more queue clients potentially including the same client that previously failed. As another example the message retry workflow may attempt to retry the failed processing of the message using one or more other queue clients. Accordingly the message retry workflow may implement a message processing retry by providing to the queue client N one or more messages whose processing previously failed with the queue client A. In one embodiment the message processing retry may involve transferring responsibility for one or more values for the strict order parameter from the queue client A to the queue client N at least temporarily. Using the message processor N the queue client N may then attempt to process the one or more messages whose processing previously failed with the queue client A.

The message processing retry may include sending all or part of the wire log data for the failed message s to the queue client N. The wire log data sent to the retry client N may associate each message to be retried with the message identifier and or value for the strict order parameter for the message. In one embodiment the wire log data or other metadata sent to the retry client N may indicate that processing has previously failed for a particular message. In one embodiment the wire log data or other metadata sent to the retry client N may include the number of times that the attempted processing has failed for a particular message. In one embodiment the wire log data sent to the retry client N may include an estimated reason that the attempted processing failed for a particular message. In one embodiment the wire log data or other metadata sent to the retry client N may include the partial results of the attempted processing for a particular message is the processing failed before it was complete. In one embodiment the wire log data sent to the retry client N may include an indication of processing steps that were performed successfully before the message processing failed. Accordingly the retry client N may verify that such steps were indeed successfully completed before continuing the processing of a message with one or more additional steps. In this manner the wire log data may be used for efficient and automated recovery from message processing failure.

A range of strict order parameters may be divided among a plurality of queue servers. Each strict order parameter may be assigned to one and only one of the queue servers. As shown in the message may be forwarded to the assigned queue server based on the value of the strict order parameter or the hash thereof . The destination queue server may be determined using a functionality to determine the destination queue server based on the value of the strict order parameter for the message. The destination queue server may be a primary server for a range of values of the strict order parameter that includes the value in the current message. In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with the received message.

As shown in the message may be enqueued based on the time of receipt. The time of receipt may be based on the receipt of the first or last byte of the message at the destination queue server. The message may be placed in a queue in a strict order with respect to other messages with the same value for the strict order parameter. In some cases however the message may be out of order with respect to messages with other values for the strict order parameter. In this manner the distributed strict queue system may ensure that messages with the same strict order parameter i.e. with the same values thereof are strictly ordered in a queue while messages with different strict order parameters i.e. with different values thereof are not necessarily in the correct order i.e. weakly ordered or non strictly ordered . In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with updates regarding the enqueuing of the message. One or more queue clients may be configured to dequeue and process the messages.

As shown in network interactions between the one or more queue clients and one or more external components may be configured such that the interactions are routed through a network proxy. The network proxy may be implemented using one or more queue servers running appropriate software and or one or more other hardware components. Under some circumstances the network proxy may prevent one or more queue clients from sending network traffic. In one embodiment the queue clients are prevented from sending the network traffic in response to failed message processing at the queue clients.

As shown in a wire log may be generated and stored the wire log includes data descriptive of the network interactions. The wire log may indicate respective message identifiers and or values for the strict order parameter for the messages for which the message processing was attempted. The wire log may include data descriptive of failed message processing for one or more messages. Message processing may be retried using one or more additional queue clients for failed message processing.

In one embodiment the strict queue s may include messages associated with different values for a strict order parameter. Messages with the same value for the strict order parameter may be enqueued in the correct order relative to each other. However for messages with different values for the strict order parameter the queue service may use a best effort ordering technique that is not guaranteed to present messages with different values for the strict order parameter in the correct order. The best effort ordering may result in some messages with different values for the strict order parameter being processed by queue clients in a different order than the messages were received by the queue service . Accordingly the strict queue s may be strict for messages with the same value for the strict order parameter and non strict for messages with different values for the strict order parameter.

It is contemplated that the distributed strict queue system may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. For example although three queue producers A B and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue producers may be used. Additionally although three queue servers A B and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue servers may be used. Furthermore although three queue clients A B and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue consumers may be used.

The distributed strict queue system may comprise one or more computing devices any of which may be implemented by the example computing device illustrated in . In various embodiments portions of the functionality of the distributed strict queue system including the queue producers A N queue servers A N and or queue clients A N may be provided by the same computing device or by any suitable number of different computing devices. If any of the components of the distributed strict queue system are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions.

In some embodiments the queue servers A N and queue clients A N may be implemented as virtual compute instances or as physical compute instances. The virtual compute instances and or physical compute instances may be offered to clients provisioned and maintained by a provider network that manages computational resources memory resources storage resources and network resources. A virtual compute instance may comprise one or more servers with a specified computational capacity which may be specified by indicating the type and number of CPUs the main memory size and so on and a specified software stack e.g. a particular version of an operating system which may in turn run on top of a hypervisor . One or more virtual compute instances may be implemented by the example computing device illustrated in .

In one embodiment the queue service may include a functionality for geographic awareness . Using the geographic awareness functionality the queue service may select the geographic location of one or more components e.g. one or more queue servers A N and or one or more queue clients A N to optimize the performance of the distributed strict queue system . As will be discussed in greater detail below the distributed strict queue system may be optimized for any combination of performance e.g. network latency cost risk mitigation and or any other suitable criteria. For example the geographic awareness functionality may optimize the distributed strict queue system to improve latency with respect to particular interactions e.g. interactions between queue producers and queue servers interactions between queue servers and queue clients and or interactions between queue clients and external components. As used herein the term optimize generally means improve rather than make optimal. The geographic awareness functionality may be implemented using any suitable component s including one or more management components one or more queue servers A N and or one or more network proxy components etc.

In one embodiment each of the queue servers A N and or queue clients A N may determine its own geographical location. In one embodiment the geographic awareness functionality may determine the geographical location for any the queue servers A N and or queue clients A N either independently or by receiving the locations from the corresponding server s and or client s . In one embodiment the geographic awareness functionality may determine the geographical location for compute instances that potentially may be provisioned as queue servers A N and or queue clients A N.

In one embodiment the geographic awareness functionality may be implemented in connection with one or more proxy servers such as network proxy . When the queue producers A N initiate interactions with the queue service such as by sending queue messages to the queue service the network proxy may intercept the interactions. In one embodiment the network proxy may be situated in an edge location e.g. for further optimization of latency. Using aspects of the geographic awareness functionality the network proxy may select a suitable queue server to receive a particular message from a queue producer. A particular queue server may be selected from a pool of available queue servers A N e.g. to reduce latency between the queue service and the queue producer providing the message s . In one embodiment the network proxy may coordinate with an instance provider to provision any of the queue servers A N. The geographical location at which the queue server is provisioned may be selected to optimize for performance cost and or risk. For example the geographical location at which the queue server is provisioned may be selected to reduce latency between the queue service and the queue producer providing the message s . Once the queue server has been selected and optionally provisioned the proxy server may forward the message s to the selected queue server.

Messages may be routed to selected queue servers using any suitable technique. In one embodiment a dynamic routing system such as Amazon Route may be used to route interactions e.g. messages from queue producers to queue servers by translating names to network addresses. In one embodiment one or more values for the strict order parameter may be assigned to the selected queue server. The one or more values for the strict order parameter may be assigned to the selected queue server based on the geographical location of the queue server. If the order parameter space is location sensitive e.g. such that values for the strict order parameter vary according to the geographical location of queue producers then queue servers may be assigned values for the strict order parameter and then selected based on those values.

In one embodiment the queue servers A N and or queue clients A N may be selected based at least in part on performance optimization. Accordingly the geographic awareness functionality may include a functionality for performance measurement . Using the performance measurement functionality the queue service may determine any suitable metrics describing the performance of queue servers A N and or queue clients A N potentially including processor metrics memory metrics and or network metrics. For example the queue service may determine the network latency between various components in the distributed strict queue system between various geographical locations for potential components and or between components and geographical locations. Using the performance measurement functionality the queue service may determine the network latency between queue producers and the queue servers or potential locations thereof between queue servers or potential locations thereof and queue clients or potential locations thereof and or between the queue clients or potential locations thereof and external components e.g. components outside the distributed strict queue system that the queue clients may call to assist in the processing of messages . As another example the queue service may determine the message processing latency for a set of messages and or components. The message processing latency may be a difference between the time at which a message is sent by a queue producer and the time at which a result or response is received by the queue producer.

In one embodiment the queue servers A N and or queue clients A N may be selected based at least in part on risk optimization. Accordingly the geographic awareness functionality may include a functionality for risk measurement . The risk measurement functionality may determine and maintain risk profiles for various components and configurations in the distributed strict queue system . Risk optimization may include a preference for avoiding the concentration of resources. For example to reduce risk queue servers and or queue clients may be selected so that all of the hosts are not located in the same data center or even in the same geographical zone. Additionally the queue servers A N and or queue clients A N may be selected based at least in part on a state of a network in the distributed strict queue system. For example network congestion or other conditions that may affect performance e.g. latency may influence the selection of the servers and or clients.

As will be described in greater detail below components such as queue servers A N and or queue clients A N may be provisioned or deprovisioned in order to optimize e.g. improve the performance cost and or risk in the distributed strict queue system . In one embodiment the queue servers A N and or queue clients A N may be provisioned or deprovisioned using the geographic awareness functionality . Accordingly the geographic awareness functionality or another suitable component may include a functionality for provisioning and deprovisioning . The provisioning and deprovisioning functionality may select and or provision any of the queue servers A N and or queue clients A N. For example the queue servers A N and or queue clients A N may be provisioned from a suitable pool of available computing instances. In one embodiment additional computing instances may be added to the queue servers A N and or queue clients A N as needed. In one embodiment computing instances may be returned to the pool of available computing instances from the queue servers A N and or queue clients A N if the computing instances are not needed at a particular point in time. The queue service may provision queue servers A N and or queue clients A N by reserving computing instances from a pool of available computing instances e.g. by reserving computing instances whose host class has particular system parameters and installing and or configuring the software of the computing instances. The queue service may deprovision queue servers A N and or queue clients A N by terminating the computing instance and returning it to the pool of available computing instances.

For example as shown in a queue server C may originally receive messages from one or more queue producers A N. The queue server C may be physically located in a first geographical zone A. Using the geographic awareness functionality the queue service may deprovision the queue server C and provision a queue server D to replace the functionality of the deprovisioned server C. The queue server D may be physically located in a second geographical zone B. The geographical zones A and B may represent any areas including noncontiguous areas defined by political or geographical boundaries including hemispheres continents nations states administrative regions metropolitan areas etc. The geographical zones A and B may also represent any areas defined by technical boundaries such as hosts racks of hosts or data centers. To relocate the functionality of the queue server C one or more values for the strict order parameter may be transferred from the queue server C to the queue server D. After the relocation the queue server D may receive the messages from the one or more queue producers A N that were originally directed to the queue server C e.g. messages having values for the strict order parameter that were within the range of values transferred from queue server C to queue server D.

In one embodiment the functionality of one or more queue servers may be moved from one geographical location to another geographical location based on the timing of message receipt. For example messages having a particular value for the strict order parameter may be generated at a particular local time e.g. noon on a daily basis across a variety of time zones. As the spike in message generation migrates from time zone to time zone queue producers in the various time zones may be directed to queue servers newly provisioned or otherwise selected in a nearby geographical location. Queue servers may be migrated again and again according to hourly cycles daily cycles weekly cycles monthly cycles etc. In this manner the performance cost and or risk of the distributed strict queue system may be optimized repeatedly and or continuously.

In one embodiment the queue server s may be relocated based on network latencies or other performance metrics that are currently being experienced. In one embodiment the queue server s may be relocated based on network latencies or other performance metrics that are predicted to occur. Network latency or other performance metrics may be predicted using any suitable basis such as the use of historical data and or machine learning.

For example as shown in a queue client C may originally receive messages from one or more queue servers A N. The queue client C may be physically located in a first geographical zone A. Using the geographic awareness functionality the queue service may deprovision the queue client C and provision a queue client D to replace the functionality of the deprovisioned client C. The queue client D may be physically located in a second geographical zone B. The geographical zones A and B may represent any areas including noncontiguous areas defined by political or geographical boundaries including hemispheres continents nations states administrative regions metropolitan areas etc. The geographical zones A and B may also represent any areas defined by technical boundaries such as hosts racks of hosts or data centers. To relocate the functionality of the queue client C one or more values for the strict order parameter may be transferred from the queue client C to the queue client D. After the relocation the queue client D may receive the messages from the one or more queue servers A N that were originally directed to the queue client C e.g. messages having values for the strict order parameter that were within the range of values transferred from queue client C to queue client D.

In one embodiment the functionality of one or more queue clients may be moved from one geographical location to another geographical location based on the timing of message receipt. For example messages having a particular value for the strict order parameter may be generated at a particular local time e.g. noon on a daily basis across a variety of time zones. As the spike in message generation migrates from time zone to time zone queue servers in the various time zones may provide messages to queue clients newly provisioned or otherwise selected in a nearby geographical location. Queue clients may be migrated again and again according to hourly cycles daily cycles weekly cycles monthly cycles etc. In this manner the performance cost and or risk of the distributed strict queue system may be optimized repeatedly and or continuously.

In one embodiment the queue client s may be relocated based on network latencies or other performance metrics that are currently being experienced. In one embodiment the queue client s may be relocated based on network latencies or other performance metrics that are predicted to occur. Network latency or other performance metrics may be predicted using any suitable basis such as the use of historical data and or machine learning.

As shown in a plurality of queue servers may be selected to receive the messages from the queue producers. Each queue server may be selected from a pool of available queue servers. The queue servers may be selected to optimize or otherwise improve the performance cost and or risk in the distributed strict queue system. For example network latency may be optimized or reduced by selecting particular queue servers in particular geographical locations e.g. a queue server with the same geographical zone as a queue producer. The interactions between the queue servers and the queue producers may include receiving messages at the queue servers from the queue producers.

As shown in each message may be forwarded to the selected queue server. A range of strict order parameters may be divided among the queue servers. Each strict order parameter may be assigned to one and only one of the queue servers. In one embodiment a range of one or more values for the strict order parameter may be assigned to a queue server when the queue server is selected to receive the messages from the queue producer s . The messages may then be delivered to the selected queue server based on the strict order parameter.

As shown in each message may be enqueued based on the time of receipt. The time of receipt may be based on the receipt of the first or last byte of the message at the destination queue server. The message may be placed in a queue in a strict order with respect to other messages with the same value for the strict order parameter. In some cases however the message may be out of order with respect to messages with other values for the strict order parameter. In this manner the distributed strict queue system may ensure that messages with the same strict order parameter i.e. with the same values thereof are strictly ordered in a queue while messages with different strict order parameters i.e. with different values thereof are not necessarily in the correct order i.e. weakly ordered or non strictly ordered . In one embodiment the primary server may update one or more backup servers e.g. a secondary server and a tertiary server with updates regarding the enqueuing of the message. One or more queue clients may be configured to dequeue and process the messages.

It is contemplated that the queue service and queue clients A N may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. For example although two queue clients A and N are shown for purposes of example and illustration it is contemplated that different quantities and combinations of queue clients may be used. The queue service and queue clients A N may be implemented using one or more computing devices any of which may be implemented by the example computing device illustrated in . In some embodiments the queue service and or queue clients A N may be implemented as one or more virtual compute instances and or physical compute instances. In various embodiments portions of the functionality shown in may be provided by the same computing device or by any suitable number of different computing devices. If any of the components shown in are implemented using different computing devices then the components and their respective computing devices may be communicatively coupled e.g. via a network. Each of the illustrated components may represent any combination of software and hardware usable to perform their respective functions.

The queue service may maintain one or more logical queues such as logical queue A and logical queue N. Although two logical queues A and N are shown for purposes of example and illustration it is contemplated that different quantities of logical queues may be used. Each logical queue may use a first in first out FIFO data structure to store one or more messages associated with a particular value for a strict order parameter. For example the logical queue A may store a series of ordered messages having one value for the strict order parameter and the logical queue N may store another series of ordered messages having another value for the strict order parameter. The messages may represent tasks or requests to be executed or otherwise implemented using appropriate computing resources. For example a message may describe or reference one or more instructions to be executed or interpreted using source data from one or more indicated data sources and or storing results in one or more indicated data destinations. Accordingly each of the queue clients A N may include a message processor such as message processor A for queue client A and message processor N for queue client N. The message processors A N may implement the instructions in the messages potentially by invoking the functionality of one or more backend systems.

In one embodiment the queue service may implement a strict client preference for one or more the queue clients A N. Based on the strict client preference a particular queue client may know with certainty that it is receiving all messages for its assigned range of values of the strict order parameter. To implement the strict client preference the queue service may be configured not to forget the assignment of the strict order parameter range to a particular queue client even if there are no messages within the range in the logical queues A N. In other words the assignment of a slice of the strict order parameter space may be locked to the queue client.

In one embodiment the queue client A may obtain messages A from the logical queue A using a strict client preference. In one embodiment the queue client N may obtain messages N from the logical queue N using a strict client preference. In one embodiment a queue client may pull messages from the queue service . The client may pull messages from one or more of the logical queues A N sending one or more requests for one or more additional messages to the queue service or by otherwise initiating the pulling of messages from the queue service. In one embodiment the queue service may push messages to a queue client. The queue client may send to the queue service an indication of the client s health at appropriate points in time. In one embodiment messages may be pushed to the queue client periodically based on an analysis of the queue client s health by the queue service .

In one embodiment each of the queue clients A N may store local state data such as stored local state A for queue client A and stored local state N for queue client N. The stored local state may indicate aspects of the message processing on the local queue client. The stored local state may include results of message processing for one or more messages such as aggregate metrics counts of items etc. The stored local state may be carried over from one message to the next. Elements of the stored local state may be associated with a value for the strict order parameter. In one embodiment elements of the stored local state may be removed or allowed to expire from the stored local state when the processing of a corresponding set of messages has successfully completed. The queue clients A N may use any suitable storage technologies such as transient memory cache memory or persistent memory to store the local state. In one embodiment the queue clients A N may store the local state using local i.e. on host memory resources for the corresponding queue client.

When the queue service transfers an assignment of the strict order parameter space the queue service may also transfer at least a portion of the stored local state from the donor client to the recipient client. For example as shown in the queue service may transfer an assignment of one or more values for the strict order parameter from queue client A to queue client N. The transferred assignment may correspond to a value for the strict order parameter associated with logical queue A. To implement the transfer the queue service may obtain local state data A that represents all or part of the stored local state A e.g. the portions of the stored local state A that relate to message processing for the transferred value for the strict order parameter . In one embodiment the queue service may obtain the local state data A by sending a control message to the queue client A to request the local state data A. The queue client A may also send any other control messages to the queue client A to terminate the client s responsibility for the transferred value for the strict order parameter. The queue service may then send the local state data A to the queue client N that is assuming responsibility for the transferred value for the strict order parameter. Using a strict client preference the queue client N may resume processing messages from the logical queue A that was previously linked to the queue client A with a strict client preference.

In one embodiment the multi tiered processing may be implemented using three or more sets of queues. Each set of queues potentially including multiple queues may provide messages to a corresponding set of queue clients potentially including multiple clients that generate messages for the set of queues at the next level. In one embodiment the number of queues and or queue clients are each level may be greater than the corresponding number at the next level. Accordingly intermediate results may cascade down through the multiple queues until a final result is generated. The final result may reflect the contributions of the original messages.

The multi tiered processing controller may coordinate aspects of the multi tiered processing. In one embodiment multi tiered processing controller may configure any of the sets of queues e.g. the first set of queues A the second set of queues B and or the third set of queues C . In one embodiment the multi tiered processing controller may provision or configure any of the sets of queue clients e.g. the first layer of queue clients A the second layer of queue clients B and or the third layer of queue clients C . The multi tiered processing controller may also monitor the health of the queue clients and take any suitable actions to mitigate client problems such as by rebalancing the range of strict order parameters across a layer or otherwise transferring an assignment of a strict order parameter from client to client.

In one embodiment the queue service may implement the multi tiered processing using queues and clients at three or more layers. As shown in a first set of one or more queues A may include a plurality of original messages A. The original messages may be produced by any suitable set of queue producers and enqueued using the queue service . A first layer of one or more queue clients typically multiple clients A may dequeue the original messages A apply transformation logic A to the original messages and place the transformed messages B in a second set of one or more queues B. As used herein transformation generally includes modification of the data structure of the input extraction of data from the input and or other modification of data in the input. Each of the queue clients in the first layer A may generate a single transformed message based on one or more original messages. In one embodiment the transformation logic A may be configured to extract data from the original messages A and generate a data structure that includes the extracted data. The data structure may be similar to a data structure used for a final result of the multi tiered processing. In one embodiment the transformation logic A may assign values for the strict order parameter to the transformed messages. In one embodiment aspects of the transformation logic A such as the assignment of values for the strict order parameter and or the generation of appropriate data structures may instead be performed by queue producers. Accordingly in one embodiment the first layer of queue clients A may be optional.

In one embodiment a second layer of one or more queue clients typically multiple clients B may dequeue the transformed messages B apply summarization logic B to the transformed messages and place the summarized messages C in a third set of one or more queues C. As used herein summarization of input generally includes representing the input using a smaller quantity or size of data. Each of the queue clients in the second layer B may generate a single summarized message based on a plurality of transformed messages. In one embodiment the summarization logic B may be configured to generate a data structure that includes a summarization of the data extracted by the first layer of queue clients A. The data structure may be similar to a data structure used for a final result of the multi tiered processing.

In one embodiment a third layer of one or more queue clients typically multiple clients C may dequeue the summarized messages C apply aggregation logic C to the summarized messages and produce one or more aggregated messages. As used herein aggregation of input generally includes combining aspects of the input into a single output or a smaller quantity of output items than input items. Each of the queue clients in the third layer C may generate a single aggregated message based on a plurality of summarized messages. In one embodiment the aggregation logic C may be configured to generate a data structure that includes an aggregation of the data extracted by the first layer of queue clients A and summarized by the second layer of queue clients B. The data structure may be similar to a data structure used for a final result of the multi tiered processing.

If the third layer includes only one queue client then the aggregated message that it produces may represent the final result . If not then additional layers of queue clients may implement the aggregation logic C until a single aggregated message representing the final result is generated by a single queue client in a final layer. For example as shown in the third layer C may place aggregated messages D into a fourth set of queues D and a fourth layer of one or more queue clients D may apply the same aggregation logic C to the aggregated messages to produce one or more further aggregated messages. The final result may ultimately be based on cascading tiers of aggregation using the aggregation logic C.

In one embodiment queue clients at multiple layers may run on the same computing instance at the same time. In one embodiment queue clients at multiple layers may run on the same computing instance at different times. Any suitable number of queue servers queue clients network proxies and or multi tiered processing coordinators may run on the same computing instance. The amount of hardware reuse may be determined dynamically e.g. based on metrics and or parameters described herein with respect to queue client selection in addition to similar metrics and or parameters for queue servers.

As intermediate results are generated through the summarization and aggregation the number of queue clients at each successive layer may be fewer than the number of queue clients at the previous layer. Accordingly the multi tiered processing algorithm may represent a cascade from more queue clients and corresponding queues to fewer queue clients and corresponding queues . At each successive layer the messages may be segregated based on the number of clients at the next layer. In one embodiment each client in the second layer and beyond may receive messages from a set of queues based on one or more values for the strict order parameter and based on a strict client preference. The amount of data may be reduced in each successive layer from the second layer to the final layer. In one embodiment the value for the strict order parameter assigned to a summarized message or aggregated message may be based on the contents of the message. For example the value may be an alphanumeric string or a random hash of the message. In one embodiment the values for the strict order parameter may be shorter at each successive layer and the range of values may be reduced in each successive layer from the second layer to the final layer.

In one embodiment the queue service may isolate among queue clients for individual values or ranges of values for the strict order parameter. In processing sensitive information for a particular customer a client may be isolated from clients processing messages for other customers e.g. at a network level. Accordingly the queue service may provision different queue clients to process messages for different values for the strict order parameter e.g. representing different customers. In one embodiment each value for the strict order parameter may be isolated and may be sent to one and only one client.

The multi tiered processing algorithm described herein may represent an improvement on the MapReduce algorithm. The first and second layers may broadly correspond to the Map phase of MapReduce. However in contrast to the MapReduce algorithm a shuffle phase between the Map and Reduce phases may be avoided using the multi tiered processing algorithm described herein. The third layer and any additional layers may broadly correspond to the Reduce phase of MapReduce. In the multi tiered processing scheme described herein the first layer may be referred to as a Map phase the second layer as a Reduce phase and the third layer as a Collect phase. Using these three or more layers of queue clients the queue service may implement multi tiered processing that is more efficient than a corresponding MapReduce solution.

The following example may illustrate the use of the multi tiered processing implemented by the queue service . In this example the original messages in the firsts set of queues may represent a real time or near real time stream of messages from a social media hub over an interval of time. Some of the original messages may contain hashtags or other items of interest. The multi tiered processing algorithm may be used to determine the top N hashtags over the interval of time. Each client in the first layer may read one or more messages from one of the first queues extract any hashtag s from the message s and generate a transformed message including the hashtag. Each transformed message may correspond to a single one of the original messages however not every one of the original messages may produce a transformed message. The first client may assign a value for the order parameter to the transformed message the value may be based on the content e.g. the hashtag such as a string representing the hashtag.

In this example each client in the second layer may read a plurality of transformed messages from one or more of the second set of queues. Each client in the second layer may collect the transformed messages into local memory and maintain a list of the top N hashtags it has seen over the interval of time. After the interval of time has ended each client in the second layer may generate a summarized message representing the top N hashtags over the interval of time. In one embodiment the summarized message may represent the most seen hashtag s and a count of the number of times each hashtag has been seen by the client over the interval of time.

In this example each client in the third layer may receive a plurality of summarized messages and aggregate the top N hashtags into an aggregated data structure representing the top N hashtags for all the summarized messages viewed by the client at the third layer. Similarly each client in any subsequent layer may receive a plurality of aggregated messages and aggregate the top N hashtags into another aggregated data structure representing the top N hashtags for all the aggregated messages viewed by the client at the third layer. In one embodiment the aggregated message may represent the most seen hashtag s and a count of the number of times each hashtag has been seen by the client over the interval of time. At each layer from the second through the next to final layer a queue client may perform its logic based on only a subset of the original messages e.g. to generate the top N hashtags over a subset of the original messages. After the data structures cascade down to the final layer the final result may be a data structure representing the top N hashtags for all or substantially all the original messages.

At the second layer third layer or any subsequent layer the queue service may monitor the performance of the queue clients. If the queue service determines that any of the clients does not have sufficient resources to process messages for its range of values for the strict order parameter the queue service may split the order parameter space at that layer and assign one or more values to other queue clients. If a single value for the order parameter space must be assigned to two or more clients so that one client is not overloaded then the value for the order parameter may be modified e.g. by concatenating a random number within the range of the number of clients for the value to the original value. If any of the queue clients experiences a failure or is otherwise terminated the queue service may transfer the saved local state to another client at the same layer along with a transferred assignment of one or more values for the strict order parameter.

As shown in the plurality of transformed messages may be dequeued from the second set of queues using a second layer of queue clients. The plurality of transformed messages may be segregated among the second layer of queue clients. Each queue client in the second layer of queue clients may be configured to summarize a subset of the transformed messages into a respective summarized message. As shown in the summarized messages may be enqueued into a third set of queues using the second layer of queue clients. Each of the summarized messages may comprise a respective value for a strict order parameter and a range of values for the strict order parameter is reduced from the current layer of queue clients to the next layer of queue clients.

As shown in the plurality of summarized messages may be dequeued from the third set of queues using a third layer of queue clients. The plurality of summarized messages may be segregated among the third layer of queue clients. Each queue client in the third layer of queue clients may be configured to aggregate a subset of the summarized messages into a respective aggregated message. In one embodiment the third layer of queue clients may enqueue the aggregated messages into a fourth set of queues and additional layers of queue clients may further aggregate the aggregated messages using any suitable number of layers and queues. Each of the aggregated messages may comprise a respective value for a strict order parameter and a range of values for the strict order parameter is reduced from the current layer of queue clients to the next layer of queue clients.

As shown in a final result may be generated based on the aggregated messages. The final result may be indicative of respective contributions from the plurality of original messages. In one embodiment a final aggregated message may represent the final result.

As shown in the plurality of transformed messages may be dequeued from the second set of queues using a second layer of queue clients. The plurality of transformed messages may be segregated among the second layer of queue clients. Each queue client in the second layer of queue clients may be configured to summarize a subset of the transformed messages into a respective summarized message. As shown in the summarized messages may be enqueued into a third set of queues using the second layer of queue clients. Each of the summarized messages may comprise a respective value for a strict order parameter and a range of values for the strict order parameter is reduced from the current layer of queue clients to the next layer of queue clients.

As shown in the plurality of summarized messages may be dequeued from the third set of queues using a third layer of queue clients. The plurality of summarized messages may be segregated among the third layer of queue clients. Each queue client in the third layer of queue clients may be configured to aggregate a subset of the summarized messages into a respective aggregated message. As shown in it may be determined e.g. by the multi tiered processing coordinator whether a final result has been generated. For example the final result may be generated if the current layer of one or more queue clients has produced a single aggregated message. If a final result has been generated then the method may end. If a final result has not been generated then as shown in the plurality of aggregated messages may be dequeued from the previous set of queues using a next layer of queue clients. The plurality of aggregated messages may be segregated among the next layer of queue clients. Each queue client in the next layer of queue clients may be configured to aggregate a subset of the aggregated messages into a respective aggregated message. As shown in the aggregated message s may be enqueued into an additional set of one or more queues. Each of the aggregated messages may comprise a respective value for a strict order parameter and a range of values for the strict order parameter is reduced from the current layer of queue clients to the next layer of queue clients.

In at least some embodiments a computer system that implements a portion or all of one or more of the technologies described herein may include a general purpose computer system that includes or is configured to access one or more computer readable media. illustrates such a general purpose computing device . In the illustrated embodiment computing device includes one or more processors e.g. processors A and B through N coupled to a system memory via an input output I O interface . Computing device further includes a network interface coupled to I O interface .

In various embodiments computing device may be a uniprocessor system including one processor or a multiprocessor system including several processors e.g. two four eight or another suitable number . Processors may include any suitable processors capable of executing instructions. For example in various embodiments processors may be general purpose or embedded processors implementing any of a variety of instruction set architectures ISAs such as the x86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA.

System memory may be configured to store program instructions and data accessible by processor s . In various embodiments system memory may be implemented using any suitable memory technology such as static random access memory SRAM synchronous dynamic RAM SDRAM nonvolatile Flash type memory or any other type of memory. In the illustrated embodiment program instructions and data implementing one or more desired functions such as those methods techniques and data described above are shown stored within system memory as code i.e. program instructions and data .

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripheral devices in the device including network interface or other peripheral interfaces. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor .

Network interface may be configured to allow data to be exchanged between computing device and other devices attached to a network or networks such as other computer systems or devices as illustrated in for example. In various embodiments network interface may support communication via any suitable wired or wireless general data networks such as types of Ethernet network for example. Additionally network interface may support communication via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs or via any other suitable type of network and or protocol.

In some embodiments system memory may be one embodiment of a computer readable i.e. computer accessible medium configured to store program instructions and data as described above for implementing embodiments of the corresponding methods and apparatus. However in other embodiments program instructions and or data may be received sent or stored upon different types of computer readable media. Generally speaking a computer readable medium may include non transitory storage media or memory media such as magnetic or optical media e.g. disk or DVD CD coupled to computing device via I O interface . A non transitory computer readable storage medium may also include any volatile or non volatile media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM etc that may be included in some embodiments of computing device as system memory or another type of memory. Further a computer readable medium may include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as a network and or a wireless link such as may be implemented via network interface . Portions or all of multiple computing devices such as that illustrated in may be used to implement the described functionality in various embodiments for example software components running on a variety of different devices and servers may collaborate to provide the functionality. In some embodiments portions of the described functionality may be implemented using storage devices network devices or special purpose computer systems in addition to or instead of being implemented using general purpose computer systems. The term computing device as used herein refers to at least all these types of devices and is not limited to these types of devices.

Various embodiments may further include receiving sending or storing instructions and or data implemented in accordance with the foregoing description upon a computer readable medium. Generally speaking a computer readable medium may include storage media or memory media such as magnetic or optical media e.g. disk or DVD CD ROM volatile or non volatile media such as RAM e.g. SDRAM DDR RDRAM SRAM etc. ROM etc. In some embodiments a computer readable medium may also include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as network and or a wireless link.

The various methods as illustrated in the Figures and described herein represent exemplary embodiments of methods. The methods may be implemented in software hardware or a combination thereof. In various of the methods the order of the steps may be changed and various elements may be added reordered combined omitted modified etc. Various of the steps may be performed automatically e.g. without being directly prompted by user input and or programmatically e.g. according to program instructions .

Various modifications and changes may be made as would be obvious to a person skilled in the art having the benefit of this disclosure. It is intended to embrace all such modifications and changes and accordingly the above description is to be regarded in an illustrative rather than a restrictive sense.

