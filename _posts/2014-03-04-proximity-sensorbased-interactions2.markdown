---

title: Proximity sensor-based interactions
abstract: An application programming interface is provided that allows applications to request and receive distance measurements from multiple proximity sensors arranged on a computing device such as a smart phone or tablet. Users can input ranges of values to the applications by moving objects such as hands and fingers towards and away one or more of the multiple proximity sensors. Applications can use the ranges of values provided by the proximity sensors to allow for more nuanced and precise user interfaces than what is typically available using the binary output associated with a capacitive display. The values provided by the proximity sensors can be combined with values from one or more other sensors such as accelerometers to provide additional user interface options.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09652044&OS=09652044&RS=09652044
owner: MICROSOFT TECHNOLOGY LICENSING, LLC
number: 09652044
owner_city: Redmond
owner_country: US
publication_date: 20140304
---
Modern computing devices such as smart phones laptops game systems and tablet computers often include a proximity sensor. A proximity sensor may be capable of detecting the presence of a nearby object as well as an approximate distance between the sensor and the nearby object. Proximity sensors may be implemented using a variety of technologies including lasers sonar and ultrasound for example.

While proximity sensors are often capable of measuring the distance between the sensor and a nearby object the proximity sensors found in most computing devices are often limited by the operating system or programming interface to only determining whether or not an object is close to the proximity sensor. Applications that use the proximity sensor in this way include applications that disable a display when it is determined that the computing device is against an ear or applications that increase a ring volume of the computing device when it is determined that the device may be in a pocket for example.

An application programming interface is provided that allows applications to request and receive distance measurements from multiple proximity sensors arranged on a computing device such as a smart phone or tablet. Users can input ranges of values to the applications by moving objects such as hands and fingers towards and away one or more of the multiple proximity sensors. Applications can use the ranges of values provided by the proximity sensors to allow for more nuanced and precise user interfaces than what is typically available using the binary output associated with a capacitive display. The values provided by the proximity sensors can be combined with values from one or more other sensors such as accelerometers to provide additional user interface options.

In an implementation a first value is received from a first proximity sensor by an application of a computing device. The first value represents a first distance between a first object and the first proximity sensor. A second value is received from a second proximity sensor by the application of the computing device. The second value represents a second distance between a second object and the second proximity sensor. One or more operations are performed based on both the first value and the second value by the application of the computing device.

In an implementation a first sequence of input values is received from a first proximity sensor and a second proximity sensor by a computing device. Each input value in the first sequence of input values represents either a distance between a first object and the first proximity sensor or a distance between a second object and the second proximity sensor. The first sequence is associated with one or more operations by the computing device. A second sequence of input values is received from the first proximity sensor and the second proximity sensor by the computing device. That the second sequence matches the first sequence is determined by the computing device. In response to the determination one or more operations associated with the first sequence is performed by the computing device.

In an implementation a first sequence of input values is received from a first proximity sensor by a computing device. Each input value in the first sequence of input values represents a distance between a first object and the first proximity sensor. The first sequence is associated with one or more operations by the computing device. A second sequence of input values is received from the first proximity sensor by the computing device. That the second sequence matches the first sequence is determined by the computing device. In response to the determination one or more operations associated with the first sequence is performed by the computing device.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the detailed description. This summary is not intended to identify key features or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

The computing device also comprises proximity sensors and collectively referred to herein as proximity sensors . Each proximity sensor may be capable of determining a distance between the proximity sensor and a nearby object. The proximity sensors may be implemented using a variety of techniques including lasers sonar and ultrasound for example. Depending on the implementation an application or operating system associated with the computing device may query a proximity sensor for a measurement of a distance between the proximity sensor and a closest object. The proximity sensor may return the measured distance. Depending on the type and capabilities of the proximity sensor the distance may be provided in a variety of formats and or resolutions including feet inches centimeters millimeters micrometers nanometers etc.

For example is an illustration of a user or users interacting with the proximity sensors. In the example shown an object and an object i.e. hands are in front of the proximity sensors and respectively. The proximity sensor measures a distance between the object and the proximity sensor and provides the measured distance to one or more applications associated with the computing device . Similarly the proximity sensor measures a distance between the object and the proximity sensor and provides the measured distance to the one or more applications. As the user or users move either the objects and or the computing device the proximity sensors and may update the values of the distances and or provided to the one or more applications.

In addition to the distance a proximity sensor may be used to measure a velocity of an object that is in front of the proximity sensor . For example the proximity sensor may determine the velocity of the object by comparing a current measured distance and time with a previously measured distance at a previous time. The measured velocity may be provided to the one or more applications.

As may be appreciated the proximity sensors may be used to provide a variety of user interface implementations to the operating system and or applications executing on the computing device . In particular the proximity sensors may be used in applications and or interfaces where a range of input values may be useful as opposed to the binary on off type of input values associated with capacitive displays. In addition many of the user interface implementations described herein may be provided using existing proximity sensors of current mobile devices without the addition of new or expensive sensors.

One such implementation is for videogame applications. Currently most videogame applications use the capacitive display to receive user input through displayed buttons. These capacitive displays typically cannot distinguish between a hard press of a displayed button and a soft press of a displayed button. To facilitate a greater range of user input a videogame application may use the proximity sensors to receive user input. The distance provided by the proximity sensors may be used to as an indicator of the relative strength of the user input.

For example a racing videogame application may map the proximity sensor to a gas pedal of a racecar and may map the proximity sensor to a brake pedal . When a hand or finger of a user is detected near the proximity sensor the videogame may actuate the gas pedal of the racecar with a force that is inversely proportional to the distance between the finger and the proximity sensor . Accordingly the smaller the distance between the proximity sensor and the finger the faster the racecar will accelerate. The brake pedal associated with the proximity sensor may operate similarly.

In another example a fighting videogame application may map the proximity sensor to a punch and may map the proximity sensor to a kick . When a user moves his hand or finger with respect to a proximity sensor the application may make a character punch or kick with a velocity that is proportional to the velocity detected by the associated proximity sensor .

In another example a board game videogame application may map each of the proximity sensors to a player of the board game. For example where a computing device has four proximity sensors each user may use his assigned proximity sensor to control the velocity of a virtual dice roll where the velocity measured by the proximity sensor is translated into a velocity of the virtual dice roll in the board game. In another example the board game may be a hungry hungry hippos type game where the velocity measured by a proximity sensor is used to control the speed and reach of a corresponding hippo.

In addition the proximity sensors may be used in conjunction with other sensors of the computing device such as an accelerometer a global positioning system a gyroscope and the capacitive display . Other sensors may be used. For example continuing the fighting videogame application above the application may use the proximity sensors to measure the velocity of the user s finger as it approaches the computing device but may not register the punch or kick selection until the accelerometer or display indicates that the computing device has been touched by the user. After determining that the computing device has been touched the application may cause the punch or kick to be performed with a force proportional to the determined velocity.

In another example the accelerometer may be used to distinguish between movements of the computing device and movements of hands and or fingers with respect to the proximity sensors . If movement of the computing device is detected by the accelerometer then any changes of distances measured by the proximity sensors may be disregarded or adjusted to account for the movement. For example a user may have been inadvertently jostled or may be riding on a train or bus which may result in an inadvertent change in distance between one or more of the proximity sensors .

In another example application the proximity sensors may be used to record a sequence of distance changes. For example a user may move both hands towards and away from each of the proximity sensors and the sequence may be recorded. The sequences may include changes in distances as well as changes in velocity. The user may associate one or more actions or operations with the recorded sequence such as unlocking the computing device opening an application or calling a contact for example. At a later time when the user repeats the sequence the computing device may perform the one or more operations.

As may be appreciated the proximity sensors described herein can be used in any application where multiple degrees of input sensitivity may be incorporated. For example in a painting or drawing application the measured velocities or distances can be used to adjust an amount or pressure applied by an on screen pencil or brush. In a mapping application the measured distance or velocity can be used to control a zoom level or speed. In an email or text viewing application the measured distance or velocity can be used to control a scroll speed. Other applications can be supported.

Returning to as illustrated the proximity sensors and are located at approximately opposite locations in the housing of the computing device next to the button and the speaker respectively. Where only two proximity sensors are used such an arrangement may allow for easy use of the multiple proximity sensors when the computing device is held in either of the two possible landscape orientations. However other proximity sensor configurations are contemplated and illustrated for example with respect to the computing devices and illustrated in respectively.

As shown in for the computing device the proximity sensors and are placed on opposite sides of the button and the microphone on the lower portion of the housing . In this configuration the proximity sensors may be well placed for use when the computing device is held in one of the two possible portrait orientations. For the other possible portrait orientation the proximity sensors and would be placed at the top of the housing on either side of the speaker .

In contrast as shown in for the computing device the proximity sensors and have been placed in the upper right hand corner and lower right corner of the housing . In this configuration the proximity sensors may be well placed for use when the computing device is held in one of the two possible landscape orientations. For the other possible landscape orientation the proximity sensors and may be placed the opposite sides of the housing .

In another implementation rather than two proximity sensors and three or more proximity sensors may be used to allow for a greater number of orientations to be supported. For example shows the computing device with four proximity sensors i.e. proximity sensor and . In such a configuration some or all of the proximity sensors may be used allowing the computing device to be held in any of the four orientations. The computing device may selectively activate or deactivate one or more of the proximity sensors depending on the orientation of the computing device . Alternatively each of the proximity sensors may be used allowing up to four independent proximity based inputs.

For example in some implementations an application may detect the orientation of the computing device using a gyroscope accelerometer or other orientation detection means. If the computing device is held in the portrait mode with the proximity sensors and closest to the user then the proximity sensors and may be activated and the proximity sensors and may be deactivated. If the computing device is held in the portrait mode with the proximity sensors and closest to the user then the proximity sensors and may be activated and the proximity sensors and may be deactivated. If the computing device is held in the landscape mode with the proximity sensors and closest to the user then the proximity sensors and may be activated and the proximity sensors and may be deactivated. If the computing device is held in the landscape mode with the proximity sensors and closest to the user then the proximity sensors and may be activated and the proximity sensors and may be deactivated.

In another implementation the computing device may selectively activate or deactivate proximity sensors based on user settings. The user may select the proximity sensors to use for all application on the computing device or may select proximity sensors for each application separately. For example a user may select proximity sensors and when using a fighting videogame application and proximity sensors and when using a racing videogame application.

In another example the proximity sensors may be activated dynamically based on the distance values measured by the proximity sensors when a particular application is started or after prompting a user. The proximity sensors with the smallest measured distances may then be activated. For example when a user starts an application on the computing device the user may be prompted to select one or more proximity sensors by placing a finger over the desired proximity sensors . When the application requests a distance measurement from each of the proximity sensors the proximity sensors that the user has selected by placing a finger over them will measure a very close or small distance. The application may activate proximity sensors with the smallest measured distances.

While only up to four proximity sensors are shown in the is it for illustrative purposes only there is no limit to the number of proximity sensors that may be supported. Moreover the placements and locations of the proximity sensors are not limited to those shown in the drawings. Other placements are contemplated including placements on the rear and sides of the computing devices and behind the display .

The application may include any type of application that may interact with a proximity sensor . The applications may include videogame applications media creating applications mapping applications web browsers and other types of applications. Applications typically associated with the operating system such as launchers keyboards lock screens and dialers may also be supported. There is no limit to the number of applications that may be part of the environment .

The proximity sensor API may be an application programming interface that allows the application to access or use the proximity sensors . In some implementations the proximity sensor API may be a set of functions that allow the application to determine a distance of the nearest object to each proximity sensor as well as a velocity of the nearest object. Alternatively the application may calculate the velocity of the object using a sequence of distance measurements. The API may allow the application to interact with a variety of proximity sensor types using a common set of functions.

The input sequence engine may record or store a representation of a sequence of inputs from the proximity sensors . The input sequences may include values such as distances and or velocities measured by one or more of the proximity sensors over some period of time. Each input sequence may be associated with one or more operations such as unlocking the computing device calling a contact or launching a particular application . Each input sequence may be stored by the input sequence engine in an input sequence storage . When an input sequence is received that matches one of the stored input sequences the one or more operations associated with the matching input sequence may be performed by the input sequence engine .

In some implementations each input sequence may be associated with a particular length of time. When the user wants to create a new input sequence the input sequence engine may use the proximity sensor API to record the distances and or velocities measured by one or more of the proximity sensors over the length of time as the user interacts with one or more of the proximity sensors . The interactions may include the user moving his hands or fingers towards and away from the proximity sensors at varying velocities. After the length of time has expired the input sequence engine may ask the user to repeat the interactions associated with the input sequence in order to verify that they were correctly recorded.

If verified the input sequence engine may ask the user to select one or more operations to associate with the input sequence. The input sequence and indicators of the selected one or more operations may be stored by the input sequence engine in the input sequence storage .

Alternatively the input sequences may be limited to some number of distance changes rather than limited to a particular length of time. For example the input sequence may include two three four or five distance changes with respect to one or more of the proximity sensors . In some implementations the input sequence engine may ask the user to select a desired sequence length and then successively prompt the user to position his hand or finger at each desired distance in the sequence.

Where multiple proximity sensors are used the input sequence engine may allow the user to change between proximity sensors during the sequence or to use multiple proximity sensors simultaneously during the sequence. Thus an example sequence may be the user holding one finger above the proximity sensor at a distance of 2 cm the user holding fingers above both the proximity sensors and at a distance of 4 cm the user holding one finger above the proximity sensor at a distance of 2 cm and the user holding a finger above the proximity sensor at a distance of 2 cm while also holding a finger above the proximity sensor at a distance of 4 cm.

The application and or the input sequence engine may also use other sensor data . The other sensor data may include data from other sensors associated with the computing device including but not limited to an accelerometer global positioning system a gyroscope thermometer barometer altimeter accelerometer and a capacitive touch screen. Other types of sensor data may be supported.

With respect to the application the sensor data may be used alongside the distance and or velocity data from the proximity sensors . For example in implementations with multiple proximity sensors some or all of the proximity sensors may be enabled or disabled based on a detected orientation.

The accelerometer data of the other sensor data may also be used to distinguish user movement towards the proximity sensors that is caused by movement of the computing device from actual movement by the user towards the proximity sensors or to determine when the user has touched the computing device .

With respect to the input sequence engine the other sensor data may be included in the recorded input sequences. For example the user may shake or more the computing device as part of the input sequence or may move the computing device towards his finger rather than move his finger towards a proximity sensor . The other sensor data may be stored by the input sequence engine with the input sequences in the input sequence storage .

A first proximity sensor and a second proximity sensor are selected at . The first and second proximity sensors may be selected from a plurality of proximity sensors of the computing device by the application . In some implementations the sensors may be selected based on an orientation of the computing device so that the selected proximity sensors are the closest or most accessible proximity sensors given the orientation. Alternatively the proximity sensors may be selected by a user or may be selected based on configuration information associated with the application .

A first value is received from the first proximity sensor at . The first value may be received by the application through the proximity sensor API . The first value may represent a first distance between a first object and the first proximity sensor. The first object may be a finger or hand of a user of the computing device . Alternatively or additionally the first value may be a velocity of the first object as it moves towards the first proximity sensor.

A second value is received from the second proximity sensor at . The second value may be received by the application through the proximity sensor API . The second value may represent a second distance between a second object and the second proximity sensor. The second proximity sensor may be a different proximity sensor than the first proximity sensor.

Depending on the implementation a third value is optionally received from a sensor other than the first and the second proximity sensors at . The third sensor may not be a proximity sensor. The third value may be other sensor data and may be received by the application from a sensor such as an accelerometer global positioning system a gyroscope or a capacitive display. Other sensors may be used.

One or more operations are performed based on both the first value and the second value at . The one of more operation may be performed by the application . Where the application is a videogame application the operations may include performing one or more character actions with a force or velocity proportional to the first value and the second value. Other operations may be supported. Where the third value is received the operation may be performed using the first second and third values.

A first sequence of input values is received at . The first sequence of input values may be received by the input sequence engine from a first proximity sensor and a second proximity sensor . Each input value in the first sequence of input values may represent either a distance between a first object and the first proximity sensor or a distance between a second object and the second proximity sensor.

The first sequence of input values is associated with one or more operations at . The first sequence of input values may be associated with one or more operations by the input sequence engine . The one or more operations may include opening a contact sending a message to a contact calling a contact unlocking the computed device turning on the computing device turning off the computing device opening an application turning or turning of Wi Fi and putting the computing device in airplane mode for example. The one or more operations may be selected by a user or administrator depending on the implementation. For example after entering the first sequence of input values the user may select the desired one or more operations from a drop down menu or other user interface element. The first sequence of input values and the associated one or more operations may be stored in the input sequence storage .

A second sequence of input values is received at . The second sequence of input values may be received by the input sequence engine from the first proximity sensor and the second proximity sensor .

A determination of whether the second sequence matches the first input sequence is made at . The determination may be made by the input sequence engine . If the first sequence matches the second sequence then the method may continue at . Otherwise the method may continue at .

The one or more operations are performed at . The one or more operations associated with the first input sequence may be retrieved from the input sequence storage and performed by the input sequence engine .

An error is generated at . If the first input sequence does not match the second input sequence then an error may be generated by the input sequence engine and the one or more operations associated first input sequence are not performed. For example a message that the input sequence was not recognized may be displayed to the user or a sound associated with an error may be played. Alternatively the one or more operations associated first input sequence is not performed and no error message or sound may be generated.

A determination of whether a computing device is in a landscape orientation or a portrait orientation is made at . The determination may be made by the application using sensor data provided by the accelerometer or gyroscope for example. Other methods or techniques for determining an orientation of a computing device may be used. If the computing device is determined to be in a landscape orientation then the method may continue at . If the computing device is determined to be in a portrait orientation then the method may continue at .

The proximity sensors are configured based on a landscape orientation at . The proximity sensors may be configured by the application . In some implementations in the landscape orientation the proximity sensors that are well suited for the landscape orientation may be selected for use by the application . Thus looking at the computing device of either the proximity sensors and or the proximity sensors and may be selected and activated.

The proximity sensors are configured based on a portrait orientation at . The proximity sensors may be configured by the application . In some implementations in the portrait orientation the proximity sensors that are well suited for the portrait orientation may be selected for use by the application . Thus continuing to look at the computing device of either the proximity sensors and or the proximity sensors and may be selected and activated.

A value is received from each proximity sensor at . The values may be received by the application from each of the proximity sensors through the proximity sensor API . Each value may represent the distance between a proximity sensor and the closest object.

Proximity sensor s associated with the smallest received value s are determined at . The smallest received values may be determined by the application . As part of the proximity sensor configuration process a user may have been prompted to select one or more proximity sensors to use during the application . In some implementations the application may have prompted the user to select the proximity sensors by placing his finger or another object close to or in front of the sensors that he would like to select. Thus the proximity sensors with the smallest values may be the proximity sensors that were selected by the user.

The proximity sensor s with the smallest received value s are selected at . The proximity sensors may be selected by the application and may be used to provide input to the application by the user. Any non selected proximity sensors may be deactivated for example.

Numerous other general purpose or special purpose computing system environments or configurations may be used. Examples of well known computing systems environments and or configurations that may be suitable for use include but are not limited to personal computers PCs server computers handheld or laptop devices multiprocessor systems microprocessor based systems network PCs minicomputers mainframe computers embedded systems distributed computing environments that include any of the above systems or devices and the like.

Computer executable instructions such as program modules being executed by a computer may be used. Generally program modules include routines programs objects components data structures etc. that perform particular tasks or implement particular abstract data types. Distributed computing environments may be used where tasks are performed by remote processing devices that are linked through a communications network or other data transmission medium. In a distributed computing environment program modules and other data may be located in both local and remote computer storage media including memory storage devices.

With reference to an exemplary system for implementing aspects described herein includes a computing device such as computing device . Computing device depicts the components of a basic computer system providing the execution platform for certain software based functionality in accordance with various embodiments. Computing device can be an environment upon which a client side library cluster wide service and or distributed execution engine or their components from various embodiments is instantiated. Computing device can include for example a desktop computer system laptop computer system or server computer system. Similarly computing device can be implemented as a handheld device e.g. cellphone smart phone tablet etc. . Computing device typically includes at least some form of computer readable media. Computer readable media can be a number of different types of available media that can be accessed by computing device and can include but is not limited to computer storage media.

In its most basic configuration computing device typically includes at least one processing unit and memory . Depending on the exact configuration and type of computing device memory may be volatile such as random access memory RAM non volatile such as read only memory ROM flash memory etc. or some combination of the two. This most basic configuration is illustrated in by dashed line .

Computing device may have additional features functionality. For example computing device may include additional storage removable and or non removable including but not limited to hard disks and SD cards. Such additional storage is illustrated in by removable storage and non removable storage .

Computing device typically includes a variety of computer readable media. Computer readable media can be any available media that can be accessed by device and includes both volatile and non volatile media removable and non removable media.

Computer storage media include volatile and non volatile and removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data. Memory removable storage and non removable storage are all examples of computer storage media. Computer storage media include but are not limited to RAM ROM electrically erasable program read only memory EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media may be part of computing device .

Computing device may contain communications connection s that allow the device to communicate with other devices and or networks. The connections may include Wi Fi cellular Bluetooth CDMA GSM etc. Computing device may also have input device s such as a keyboard capacitive display pen voice input device touch input device etc. Output device s such as a capacitive display speakers etc. may also be included. Computing device may also receive data from one or more sensors . The sensor s such accelerometers global positioning systems proximity sensors gyroscopes etc. All these devices and sensors are well known in the art and need not be discussed at length here.

It should be understood that the various techniques described herein may be implemented in connection with hardware or software or where appropriate with a combination of both. Thus the methods and apparatus of the presently disclosed subject matter or certain aspects or portions thereof may take the form of program code i.e. instructions embodied in tangible media such as floppy diskettes CD ROMs hard drives or any other machine readable storage medium where when the program code is loaded into and executed by a machine such as a computer the machine becomes an apparatus for practicing the presently disclosed subject matter.

Although exemplary implementations may refer to utilizing aspects of the presently disclosed subject matter in the context of one or more stand alone computer systems the subject matter is not so limited but rather may be implemented in connection with any computing environment such as a network or distributed computing environment. Still further aspects of the presently disclosed subject matter may be implemented in or across a plurality of processing chips or devices and storage may similarly be effected across a plurality of devices. Such devices might include personal computers network servers and handheld devices for example.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing the claims.

