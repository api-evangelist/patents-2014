---

title: Method and system for automated incident response
abstract: Methods, systems, and apparatus, including computer programs encoded on computer storage media, for implementing a response to one or more security incidents in a computing network. One of the methods includes identifying a security incident based on detecting one or more indicators of compromise associated with the security incident, comparing the security incident with a predefined ontology that maps the security incident to one or more courses of action, selecting a response strategy that includes one or more of the courses of action, and implementing the response strategy as an automated response.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09386041&OS=09386041&RS=09386041
owner: Accenture Global Services Limited
number: 09386041
owner_city: Dublin
owner_country: IE
publication_date: 20140829
---
In general one innovative aspect of the subject matter described in this specification can be embodied in methods for implementing a response to one or more security incidents in a computing network including identifying a security incident based on detecting one or more indicators of compromise associated with the security incident comparing the security incident with a predefined ontology that maps the security incident to one or more courses of action selecting a response strategy that includes one or more of the courses of action and implementing the response strategy as an automated response.

Other embodiments of this aspect include corresponding systems and include corresponding apparatus and computer programs recorded on one or more computer storage devices each configured to perform the actions of the methods. A system of one or more computers can be configured to perform particular operations or actions by virtue of having software firmware hardware or a combination of them installed on the system that in operation causes or cause the system to perform the actions. One or more computer programs can be configured to perform particular operations or actions by virtue of including instructions that when executed by data processing apparatus cause the apparatus to perform the actions.

These and other embodiments may each optionally include one or more of the following features. For instance the predefined ontology can be a runbook ontology that includes a representation of a structure that specifies details for controlling the computing network. One or more indicators of compromise can indicate a security threat to the computing network. The indicators of compromise may be previously prioritized based at least in part on potential effectiveness in preventing or mitigating the security threat. The indicators of compromise can include one or more of a process name a process identifier a process hash a file an object an application a service an Internet Protocol address a registry key or a user account. The one or more courses of action can include workflow steps to be performed in response to the incident and implementing the response strategy may include performing the workflow steps. The one or more courses of action can include infrastructure changes to be implemented in the computing network in response to the incident and implementing the response strategy may include implementing the infrastructure changes. Implementing the response strategy as an automated response can include coordinating operations of one or more third party services. Implementing the response strategy as an automated response can include gathering data by a host agent and providing the data to a forensics repository. A notification may be communicated about the selected response strategy that includes a message that the response strategy has been implemented. The notification about the selected response strategy can include a description of the security incident and a decision prompt. An indication can be received that the response strategy is to be performed and the response strategy may be implemented in response to receiving the indication. The notification about the selected response strategy can include a list of possible courses of action to be performed and receiving the indication may include receiving a selection of one of the courses of action.

Particular embodiments of the subject matter described in this specification may be implemented so as to realize one or more of the following advantages. Computer networks can defend against evolving cyber attacks. Indicators of compromise can be operationalized to prevent the spread of a threat internally. Threat actors can be profiled and possible motivations against an organization can be determined. Responses to threats can be automated and systems and processes for providing mitigations can be coordinated. Organizations can share information related to potential threats.

The details of one or more embodiments of the subject matter described in this specification are set forth in the accompanying drawings and the description below. Other potential features aspects and advantages of the subject matter will become apparent from the description the drawings and the claims.

This specification describes systems methods and computer programs for analyzing threat indicators implementing deception networks and automating incident responses in a computer network security environment. In general analyzing threat indicators may include aggregating threat activity identified within a computer network and applying analytics to gain actionable insights into security threats. Predictive analytics may be used to determine threat indicators which can be used to improve an organization s security posture. In general deception networks can combine network agility deep packet inspection and honeypots to identify indicators of network compromise to contextualize internal threat intelligence and to automatically apply mitigations using infrastructure orchestration. In general incident responses may include incident discovery and incident remediation processes.

Active defense techniques for network security may include orchestrating incident response and threat management systems incorporating deception network capabilities and leveraging software defined networking SDN . Predetermined courses of action may be established based on the processes within a security organization. Process changes may be implemented automatically or semi automatically through orchestration. To investigate threat activity and or to engage an adversary deception networks decoy resources anti reconnaissance and resource shifting may be used. For example an adversary can be deceived by generating false network topologies and baiting the adversary into a honeypot e.g. a computer data and or network site that appear as part of a network and that appear to include information of value but is sandboxed and monitored . A sandboxed environment for example can provide a contained set of resources that permits actions by a security threat with minimal or no permanent effect to the environment and or to an organization s network. Information gathered from observation of the adversary s behavior for example may be used to proactively mitigate threats to an organization. Security response and mitigation capabilities can be embedded into an agile and adaptive infrastructure. By leveraging application and network virtualization capabilities for example an organization can meet the adversary s tactics.

The threat intelligence component can receive information from one or more intelligence feeds . For example the intelligence feeds may include feeds from commercial government and or peers sources. A peer source for example may be associated with a similar type of organization e.g. a similar type of business such as a business in a similar sector or industry as an organization that hosts maintains or operates the system . As another example a peer source may be associated with a system that includes one or more components e.g. operating systems databases applications services and or servers that are similar to components of the organization s network. A peer source may also be another organization that hosts maintains or operates a system similar in structure to system e.g. one with one or more similar components such as for instance network components of the same or similar make or model or running a same or similar version of operating software or operating a same or similar version of application software . In some implementations a service may receive security threat information from multiple peer sources and provide aggregated intelligence feeds in return to each of the sources. For example one or more of the intelligence feeds can be provided by a peer exchange service which receives threat information from multiple peers e.g. including the system and which aggregates and provides the information in return to each of the peers thus facilitating the sharing of security threat information among peer organizations.

Each of the intelligence feeds and internal intelligence from the system may include information associated with one or more security threats. Upon receiving feed information for example the threat intelligence component can identify key indicators and observables associated with each of the threats. Indicators and observables may include for example names identifiers and or hashes of processes objects files applications or services Internet Protocol IP addresses of devices registry keys to be accessed or modified user accounts or other suitable indicators and observables of a security threat. In some implementations security threat information from multiple feeds may be consolidated and or normalized. For example a consolidated view of multiple feeds may include a list of indicators and observables upon which action may be taken.

Insights based on the security threat information can be provided by the threat intelligence component to the security information and analytics component and or to the defense component . For example insights can include information associated with key indicators and observables for previously occurring security threats such as information that indicates that suspicious activity has been observed in association with a particular executable that has been used by particular instances of malware and by particular threat actors. In some implementations insights provided to the defense component may include information associated with an incident response plan and one or more mitigating controls. For example based on one or more indicators of compromise identified by the intelligence component an appropriate plan of action may be generated selected and implemented to respond to a corresponding security threat.

In general the security information and analytics component may be supported by security information and event management SIEM analytics and visualization capabilities. The security information and analytics component can monitor one or more internal data sources and can map threat indicators to predefined courses of action to take in response to various security threats. For example the security information and analytics component can receive information from internal network data sources e.g. including information technology data sources operational technology data sources and or physical data sources and can provide monitoring of patterns and anomalies indicative of threat activity within an organization as informed by the insights provided by the threat intelligence component . Based on the insights for example the security and information analytics component can modify its threat monitoring process. For example when the security and information analytics component detects a known pattern of events e.g. related to the insights such as the existence of a file an activity on an IP address or another indicator or observable action it can record an incident can trigger one or more requests for responses and can provide the response requests to the defense component . Response requests may include incident activity information for example which may include information related to appropriate handling of a security threat or security breach such as removal of a file reporting of an IP address upgrading of software or another appropriate course of action.

In general the defense component may be supported by orchestration services e.g. including security orchestration services and or infrastructure orchestration services which can set policies and can automate threat management workflows. The security orchestration services for example can maintain an ontology regarding actions to be performed in response to particular security threats or breaches whereas the infrastructure orchestration services can maintain information related to mitigations e.g. infrastructure changes by a software defined networking controller to be performed. Based on insights from the threat intelligence component and or incident activity information from the security information and analytics component for example the defense component can provide automated or semi automated infrastructure changes and service management ticketing to mitigate the impact of identified threats or breaches. The defense component for example can perform particular actions in response to particular indicators such as blocking an IP address blocking a process executed by an endpoint reporting to data loss leak prevention DLP when a particular document is opened redirecting traffic or another appropriate action. To mitigate a phishing attack for example the defense component can cause a predefined course of action to be executed including using the orchestration services to determine whether a uniform resource locator URL included in an e mail is malicious and if so to block access to the URL and to generate a workflow request to remove the malicious e mail from a recipient s mailbox. As another example to mitigate a distributed denial of service DDoS attack the defense component can use the orchestration services to modify software defined networking SDN settings to reroute network traffic associated with the attack.

In some implementations one or more automated incident response components e.g. discussed in further detail in association with may be distributed among one or more of the security information and analytics component the defense component and or the orchestration services . In the present example the automated incident response components include a response selector a notification provider and a response implementer . The response selector for example can select an appropriate strategy for responding to an identified incident e.g. a security threat or breach based on comparing the incident to a predefined ontology. The notification provider for example can optionally provide information associated with the identified incident to an operator to facilitate a semi automated response. The response implementer for example can implement the selected response strategy by implementing one or more steps indicated by the predefined ontology. Operations performed by each of the components and may be performed by a single computing device or may be distributed to multiple devices.

In some implementations the defense component may use a deception network e.g. discussed in further detail in association with to mitigate a security threat and or to gather additional intelligence related to the threat. Based on information gathered by the deception network for example information associated with one or more threat indicators can be provided to the threat intelligence component and or information associated with one or more targets e.g. suspicious processes files traffic sources or other aspects to be monitored may be provided to the security information and analytics component . As another example the security information and analytics component may receive response strategy information from the security orchestration services . Insight related to internal threat intelligence e.g. indicators and observables determined from the data sources and or deception networks can be provided to the threat intelligence component for external communication e.g. via the peer exchange .

The example system includes multiple computing devices e.g. personal computing devices servers server clusters in communication over a wired and or wireless network. In the present example the system includes a threat intelligence server a management and process orchestration server a software defined networking controller and an indicator analytics server . Each of the devices and can include one or more processors configured to execute instructions stored by computer readable media for performing various device operations such as input output communication data processing and or data maintenance. An example computer device is described below with reference to . The devices and for example can communicate over a local area network a wireless network a wide area network a mobile telecommunications network the Internet or any other suitable network or any suitable combination thereof.

Referring to the example flow of data during stage A threat intelligence information is received by the threat intelligence server . For example a peer organization can share e.g. via the peer exchange shown in information associated with an IP block of addresses targeting a particular type of resource e.g. a database server . As another example internal threat intelligence information can be provided by monitoring capabilities of a security information and event management system e.g. included in the security information and analytics component shown in .

During stage B threat intelligence information is contextualized and stored. For example the threat intelligence server can contextualize and store information associated with external and or internal security threats to provide an understanding of a threat environment. For example contextualizing and storing information may include matching threat information identified from internal security threats to threat information identified from external security threats to supplement the information from each source. In the present example one or more threat indicators e.g. an IP block of addresses may be associated with a particular security threat e.g. a secure shell SSH brute force attack .

During stage C applicable threat intelligence information is provided to the management and process orchestration server . For example the information can be provided as a list of key indicators and observables. As another example the management and process orchestration server can receive threat intelligence information through an application programming interface API .

During stage D the management and process orchestration server identifies applicable actions for identified security threats and executes courses of action. For example the management and process orchestration server can maintain information associated with predefined courses of action e.g. a playbook for various types of security threats. When the management and process information orchestration server identifies an occurrence of a security threat e.g. via one or more data sources shown in as matching a known threat indicator it can execute a course of action to mitigate the particular threat. In the present example the management and process orchestration server can receive information indicating that a production environment e.g. a network endpoint running a database server is in communication with a device associated with an IP address that is a known threat indicator and can automatically execute an appropriate course of action to mitigate the threat. For example the management and process orchestration server can change the infrastructure of the system automatically and or can manipulate security controls to interfere with an attacker.

During stage E process mitigation controls are provided to protect one or more endpoints. For example the management and process orchestration server may determine that the production environment is at risk and may provide instructions to the production environment to perform one or more actions such as removing files terminating processes blocking communications or other appropriate actions. In some implementations a snapshot may be taken for use in threat analysis and or for use in rebuilding a session. For example a snapshot of a current session of the production environment can be taken and can be used to recreate the session in a honeypot environment .

During stage F flow change information is provided to direct network topology changes. For example the management and process orchestration server can provide instructions for the software defined networking SDN controller to redirect network traffic intended for the production environment e.g. traffic from an attacker s IP address to the honeypot environment . The software defined networking controller for example can facilitate on the fly changing of network topology from a centralized point such that an attacker may be unaware of the change and may perceive that communication with the production environment persists while traffic is actually being diverted to the honeypot environment .

In some implementations other software defined networking SDN techniques may be used to passively and or actively engage an adversary. For example the software defined networking controller may implement a white noise generator to report all IP addresses as being open thus potentially confusing an attacker and causing the attacker to question reconnaissance efforts. As another example the controller may implement an IP black hole silencing the system. As another example fake topologies may be generated to reduce the effectiveness of reconnaissance efforts. As another example targeted deep packet inspection data manipulation network intrusion prevention and or breach containment techniques may be implemented.

During stage G the software defined networking SDN controller provides flow changes to a software defined networking SDN switch . The software defined networking switch for example can implement policy changes related to network traffic flow.

During stage H the software defined networking switch redirects flow to the honeypot environment . The honeypot environment for example can use process tracing techniques to identify and provide information associated with an attack as the attack is being performed. In some implementations events may be generated for actions performed by the system. For example if an attacker logs in and installs a package the honeypot environment can identify where the user logs in from associated process identifiers commands performed by the system files manipulated by the installation registry keys that are modified and other relevant information.

During stage I information is provided by the honeypot environment to the indicator analytics server . For example information related to an attacker s tactics techniques and procedures TTP can be harvested and sent to the indicator analytics server for analysis.

During stage J the indicator analytics server generates threat intelligence. For example based on observable threat indicators identified by the honeypot environment the indicator analytics server can identify one or more indicators that are potentially actionable and that can be used to determine insights for defense against threats to the system .

During stage K generated threat intelligence is provided to the threat intelligence server . The threat intelligence server for example can determine whether any internally identified indicators are actionable and can use external threat intelligence information to contextualize the information. For example internal and external threat intelligence information can be used to map threat actors to malware to processes.

The cycle shown in stages A to K may continue iteratively for example thus improving an organization s security controls in response to ongoing security threats. Updated threat information for example can be provided to the management and process orchestration server where it can be used to generate another predetermined course of action and or to block future attacks. For example the threat information can be used to direct network topology changes e.g. further stages E F and G based on the observed honeypot activity.

A compromise can be identified . For example the management and process orchestration server can identify a compromise to the system via network traffic analysis. Alternatively external threat intelligence can provide information that when validated against other network services indicates a compromise. The compromise may be for example a process compromise e.g. a malicious running process on a system an object compromise e.g. an executable or other file a suspicious network connection or another sort of compromise to the system .

Data can be retrieved from one or more relevant sources. For example relevant data can be retrieved by the management and process orchestration server from endpoint management systems security information and event management SIEM systems packet capture PCAP monitoring systems or other suitable sources. Relevant data can be structured or unstructured for example. The data can be analyzed by the indicator analytics server for example to generate one or more indicators of compromise. In some implementations the data can be persisted e.g. in a Hadoop cluster for future reference.

The status of a compromised environment can be identified . For example endpoint management software can be used to take a snapshot of a system e.g. the honeypot environment and or the production environment under attack. The snapshot for example may provide one or more potential indicators of compromise based on a list of currently running processes recently e.g. within a predetermined timeframe such as a minute ten seconds a second or another suitable timeframe ended processes and or recently modified objects in a similar timeframe.

Indicator matches can be identified . For example security threat information provided by the threat intelligence server can be accessed by the management and process orchestration server and can be used for identifying matches from the list of running and or recently ended processes and or modified objects. Processes and or modified objects that match for example may be identified as threat indicators and may be initially assigned low credibility scores.

One or more performed actions can be identified . Actions for example may include process spawning file access or modification registry value access or modification analysis of installed files or other sorts of actions. To identify the actions for example data from an endpoint management system may be filtered and the actions initiated by each process may be sorted into a dataset. In some implementations identifying performed actions may be an iterative process with halting conditions to identify the scope of the compromise.

The credibility of each process action can be determined . In general each process can initiate a finite number of actions and each action may be associated with a particular credibility score in regard to the process. For example for a particular process an action of modifying a registry value may have a low credibility value whereas modifying a file may have a high credibility value.

A composite credibility can be determined for each process based on the actions. For example the indicator analytics server can access a model that combines the credibility scores for the process actions to generate a composite credibility score e.g. ranging from zero to one for each process. In some implementations the model may include interaction terms between the actions to a second or third interaction degree. For example if a process performs two or more actions in conjunction e.g. concurrently or in series the process may receive a score adjustment e.g. an increase or decrease . In some implementations the model may include a time decay function between actions to deemphasize unrelated actions. In some implementations a composite credibility score may be determined by a machine learning algorithm e.g. a general linear model a cumulative sum algorithm or another suitable algorithm.

One or more components for profiling can be determined . For example based on the composite credibility scores a determination can be made of which processes and or objects to profile for generating indicators of compromise or threat indicators . In some implementations the determination can be based on a threshold value for a composite credibility score. When a particular composite credibility score meets the threshold for example the indicator analytics server can automatically determine which indicators to provide to the threat intelligence server . As another example indicator selection may be a semi automated process.

Indicators of compromise can be determined for each component. Indicators of compromise or actual security threat indicators may be prioritized for example based at least in part on potential effectiveness in preventing or mitigating an associated threat. For example a process associated with a security threat may communicate with a particular IP address and may edit a particular registry key. In the present example indicators of compromise associated with the threat may be the process name and the IP address since these attributes may be used to prevent the threat from occurring whereas the registry key may not. Determining indicators of compromise may be an automated or semi automated process. In general some low impact indicators may be generated automatically while indicators for critical systems may require human oversight.

Indicators of compromise can be provided for orchestration. For example the indicators of compromise can be provided by the threat intelligence server to the management and process orchestration server . Based on the indicators of compromise for example the management and process orchestration server may coordinate human response and or automate response to implement mitigations against future security threats.

A security incident can be identified . Referring to for example the security information and analytics component can identify a security incident e.g. a security threat or security breach to an organization s network based on information from one or more of the data sources . For example a distributed denial of service DDoS attack on one or more network servers may be identified by an endpoint management system based on detecting a known pattern of events associated with the type of attack.

The security incident can be compared with a predefined ontology. For example the security information and analytics component and or the security orchestration services can maintain an incident response ontology e.g. a runbook that maps security threats to courses of action and the system can use one or more of the automated incident response components to compare an identified incident to the ontology. Information related to mitigations e.g. changes to a software defined networking topology to be performed in response to a security threat or breach during an incident response process for example can be maintained by the infrastructure orchestration services .

Based on one or more indicators of compromise associated with a particular security incident e.g. a DDoS attack for example the incident can be identified and an appropriate response strategy e.g. rerouting network traffic can be selected e.g. by the response selector . Response strategies for example may be based on strategy information received from the security orchestration services and or may be influenced by insight information received from the threat intelligence component . For example if a particular pattern is observed within a security incident a response strategy may be influenced by the insight information to determine an appropriate course of action e.g. repairing damage caused by a security breach . Upon selecting the response strategy for example the security information and analytics component can provide information e.g. incident activity information related to the identified security incident e.g. a security threat or breach to the defense component . In some implementations the incident activity information may include information for mitigating a security incident including workflow steps to perform and or infrastructure changes to implement in response to the incident. In the present example the incident activity information may include instructions for rerouting some network traffic e.g. traffic originating from a particular IP block or all traffic intended for the server under attack to a honeypot or to an IP black hole. As another example the incident activity information may include information related to incident activity e.g. a type of threat or breach and affected system components and processes and response handling may be determined by the defense component and the orchestration services .

In some implementations one or more notifications may optionally be sent . For example the defense component and or the security information and analytics component can use the notification provider to provide information associated with an identified incident e.g. a security threat or security breach and appropriate responses to the incident to an operator to facilitate a semi automated response that may include automated and human workflow processes e.g. discussed in further detail in association with . An incident response for example may include instructions for mitigating a security threat or security breach while performing a system recovery. A semi automated process for implementing the incident response for example may include various checkpoints for which a human operator may be prompted to make a decision and further automated processes e.g. scripts may be launched in response to receiving an indication of the decision. As another example upon automatically performing actions for mitigating a security threat or security breach the defense component can log the actions and notification of the actions performed can be provided to the operator through a reporting interface.

The response strategy can be implemented . For example the defense component can use the response implementer to implement a selected response strategy via the orchestration services e.g. including security orchestration services and or infrastructure orchestration services . In general implementing a response strategy may include implementing steps of an incident response ontology refining an understanding of a scope of a security incident e.g. by changing an infrastructure to observe and gather information about a security incident such as by routing network traffic to perform packet capture restricting networking and or communications capabilities of computing devices systems under threat e.g. to prevent a spread of an identified threat eradicating threats and or restoring affected devices systems. In some implementations the defense component may automate incident responses. For example the defense component can use the infrastructure orchestration services to coordinate operations of various other services e.g. third party services and to automatically implement a response strategy maintained by the security orchestration services . In the present example a software defined networking SDN controller e.g. the controller shown in can be used to redirect network traffic in response to the DDoS attack. As another example a software defined networking topology can be modified to limit e.g. by restricting particular ports the computing devices and or systems with which a compromised computing device may communicate. Thus the compromised computing device may continue to function but not operate in such a way that it can spread an identified threat.

In some implementations capture of host based forensics may be automated. When a system breach is detected or has occurred for example priority may be placed on restoring the system and performing host based forensics may be deferred. By automating a forensics process for example capture of forensics information can be performed in the background and in parallel with restoring the system. In general an incident response process includes investigating an incident and includes determining and following a response process based on the incident. Automating a host based forensics step in an incident response ontology may include for example implementing a step in an incident response ontology gathering data by a host agent and sending the data to a forensics repository and proceeding to a next step in the incident response ontology. For example the security orchestration services can implement a step in an incident response ontology by making a request to the infrastructure orchestration services to perform a particular operation e.g. a request to gather data from an computing device on a network and the infrastructure orchestration services can make a corresponding request to a host agent. Upon gathering the data e.g. by logging the hostname of the device by taking a snapshot of the device and by capturing a memory dump and log files for example the data can be provided by the host agent to a forensics repository for further analysis processing. Next the host agent can send an acknowledgement to the infrastructure orchestration services for example which can in turn send an acknowledgement to the security orchestration services which can then proceed to the next step in the ontology.

During stage for example a component e.g. the security information and analytics component of the computing system can continually monitor for indicators of compromise e.g. indicators of security threats or security breaches such as suspicious processes files traffic sources or other aspects based on information provided by the data sources . During stage for example an indicator of compromise associated with a security incident e.g. a threat or breach can be detected as having occurred within the computing system and a corresponding notification can be provided e.g. by the notification provider to the operator . In the present example the indicator of compromise may indicate that a particular computing device of the computing system e.g. a node on a network is running a process that has been identified as malicious.

In some implementations the notification may include one or more possible actions that may be performed e.g. by the response implementer to mitigate the security incident. Each possible action for example can correspond to an incident response e.g. a script for mitigating the security incident. In the present example the notification can include a description of the security incident and a list of possible actions which may be performed by the response implementer including an action of removing the malicious process from the affected computing device and restoring the device and an action of blocking outgoing network traffic from the affected device.

During stage for example the operator can select one or more of the possible actions and information associated with the actions can be provided to the computing system . In some implementations instructions for implementing the incident response e.g. scripts can be provided to the computing system by a computing device of the operator . In some implementations instructions for implementing the incident response may be hosted by the computing system and the action s may include information that identifies the appropriate instructions. In the present example the operator provides instructions for removing the malicious process and restoring the affected device.

During stage the computing system can perform the incident response e.g. execute a script corresponding to the selected action s and can provide a further notification that pertains to the security incident which can include results of the performed actions e.g. the response scripts a status of the affected computing device and a list of possible actions that may be performed based on the device s current status. In the present example the further notification indicates that a script for removing the malicious process was executed but additional suspicious files were detected on the affected device. The further notification in the present example may also indicate that an action of isolating the suspicious files and an action of blocking outgoing network traffic from the affected device may be performed. Based on the notification for example the operator can select at stage the option to perform the action of blocking outgoing network traffic from the device and information associated with the action s can be provided to the computing system . In the present example the computing system can perform the corresponding incident response action at stage and can provide a further notification pertaining to the security incident e.g. a notification that traffic was successfully blocked . Thus the semi automated example process may be iterative with performed actions potentially triggering further possible actions based on a changing state of an affected device or network. The operator for example can direct an incident response process at a high level while the computing system performs low level repeatable tasks.

Embodiments of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry in tangibly embodied computer software or firmware in computer hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs i.e. one or more modules of computer program instructions encoded on a tangible non transitory program carrier for execution by or to control the operation of data processing apparatus. Alternatively or in addition the program instructions can be encoded on an artificially generated propagated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. The computer storage medium can be a machine readable storage device a machine readable storage substrate a random or serial access memory device or a combination of one or more of them.

The term data processing apparatus refers to data processing hardware and encompasses all kinds of apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can also be or further include special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit . The apparatus can optionally include in addition to hardware code that creates an execution environment for computer programs e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them.

A computer program which may also be referred to or described as a program software a software application a module a software module a script or code can be written in any form of programming language including compiled or interpreted languages or declarative or procedural languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program may but need not correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code. A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable computers executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Computers suitable for the execution of a computer program include by way of example general or special purpose microprocessors or both or any other kind of central processing unit. Generally a central processing unit will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a central processing unit for performing or executing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Moreover a computer can be embedded in another device e.g. a mobile telephone a personal digital assistant PDA a mobile audio or video player a game console a Global Positioning System GPS receiver or a portable storage device e.g. a universal serial bus USB flash drive to name just a few.

Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user embodiments of the subject matter described in this specification can be implemented on a computer having a display device e.g. a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input. In addition a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user for example by sending web pages to a web browser on a user s device in response to requests received from the web browser.

Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification or any combination of one or more such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN e.g. the Internet.

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other. In some embodiments a server transmits data e.g. an HTML page to a user device e.g. for purposes of displaying data to and receiving user input from a user interacting with the user device which acts as a client. Data generated at the user device e.g. a result of the user interaction can be received from the user device at the server.

An example of one such type of computer is shown in which shows a schematic diagram of a generic computer system . The system can be used for the operations described in association with any of the computer implement methods described previously according to one implementation. The system includes a processor a memory a storage device and an input output device . Each of the components and are interconnected using a system bus . The processor is capable of processing instructions for execution within the system . In one implementation the processor is a single threaded processor. In another implementation the processor is a multi threaded processor. The processor is capable of processing instructions stored in the memory or on the storage device to display graphical information for a user interface on the input output device .

The memory stores information within the system . In one implementation the memory is a computer readable medium. In one implementation the memory is a volatile memory unit. In another implementation the memory is a non volatile memory unit.

The storage device is capable of providing mass storage for the system . In one implementation the storage device is a computer readable medium. In various different implementations the storage device may be a floppy disk device a hard disk device an optical disk device or a tape device.

The input output device provides input output operations for the system . In one implementation the input output device includes a keyboard and or pointing device. In another implementation the input output device includes a display unit for displaying graphical user interfaces.

While this specification contains many specific implementation details these should not be construed as limitations on the scope of any invention or on the scope of what may be claimed but rather as descriptions of features that may be specific to particular embodiments of particular inventions. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a subcombination or variation of a subcombination.

Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multitasking and parallel processing may be advantageous. Moreover the separation of various system modules and components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

Particular embodiments of the subject matter have been described. Other embodiments are within the scope of the following claims. For example the actions recited in the claims can be performed in a different order and still achieve desirable results. As one example the processes depicted in the accompanying figures do not necessarily require the particular order shown or sequential order to achieve desirable results. In some cases multitasking and parallel processing may be advantageous.

