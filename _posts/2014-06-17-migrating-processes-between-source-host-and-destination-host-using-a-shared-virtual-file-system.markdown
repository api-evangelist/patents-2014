---

title: Migrating processes between source host and destination host using a shared virtual file system
abstract: A process can be scheduled between first and second hosts that using a virtual file system that is shared between the hosts can be used. The process, running on a first hypervisor of the first host, can be scheduled to run on a second hypervisor of the second host. A file can be created that includes the data content of the process address space for the file. The file can be mapped address space of the virtual file system. Data from the physical memory of the first host can be transferred to physical memory of the second host using page fault routines.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09529618&OS=09529618&RS=09529618
owner: International Business Machines Corporation
number: 09529618
owner_city: Armonk
owner_country: US
publication_date: 20140617
---
This disclosure relates to scheduling a process to operate on different hosts. In particular it relates to scheduling a process running on a first host to run on a second hosts and to move process data stored in memory of the first host to the second host.

Symmetric multiprocessing SMP architectures allow two or more processors or processor cores to share a single shared memory. SMP can also allow processors to share access to input output I O devices and to be controlled by a single OS instance. In certain embodiments each processor can be treated equally. SMP systems can therefore be useful for providing processes with access to a pool of shared hardware including processors memory and I O devices. The different hardware components can be connected through a system bus network crossbar switch or similar interconnection mechanism.

Non uniform memory access NUMA memory can be used with multiprocessing where the memory access time depends on the memory location relative to a processor. Under NUMA access times to different portions of main memory can be different depending upon the physical hardware that stores the desired data. For instance a processor located on a first host may be able to access local memory faster than memory stored on another host.

A method and system for scheduling a process between first and second hosts that using a virtual file system that is shared between the hosts can be used. The method and system can relate to scheduling the process running on a first hypervisor of the first host to run on a second hypervisor of the second host identifying a process address space for the process creating a file that includes the data content of the process address space mapping the file to address space of the virtual file system generating in response to the process running on the second hypervisor requesting access to the file a page fault determining that the memory access request is for data that is stored in physical memory of the first host and transferring in response to the determining the data from the physical memory of the first host to physical memory of the second host.

The above summary is not intended to describe each illustrated embodiment or every implementation of the present disclosure.

While the invention is amenable to various modifications and alternative forms specifics thereof have been shown by way of example in the drawings and will be described in detail. It should be understood however that the intention is not to limit the invention to the particular embodiments described. On the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope of the invention.

Aspects of the present disclosure relate to scheduling processes to run on different hosts more particular aspects relate to managing memory transfer for a process that is scheduled to run on a new host. While the present disclosure is not necessarily limited to such applications various aspects of the disclosure may be appreciated through a discussion of various examples using this context.

Embodiments of the present disclosure are directed toward a system that provides distributed shared memory DSM between two or more hosts. The system can be configured to schedule processes between the hosts e.g. to allow for load balancing while providing a memory management solution for handling memory of a process that is migrated from one source host to another target host.

Certain embodiments are directed toward moving process data stored in memory of a source host to a target host as the memory is accessed by the migrated process. In this manner the memory can be moved as necessary e.g. as opposed to moving all memory in a single bulk operation . For instance a virtual file system can have use an address space that is shared between the source and target host. The system can create a file that maps to the address space of the process. This file can then be mapped into the address space of the virtual file system e.g. as physical memory of a virtual machine and virtual memory of the new host . The page table of the virtual machine on the target host will indicate that the contents of the file are not locally in local memory. Accordingly when the migrated process attempts to access the file at the target host an exception can be generated for requested data which resides in the memory of the source host. The system can then be configured to retrieve the requested data from the source host using distributed shared memory DSM .

In particular embodiments an exception of the file system can result in the calling of a page fault handling routine of the file system. The page fault routine can interface with a DSM module which can determine that the requested page resides in the physical memory of the source host. For instance the DSM module can maintain and consult a list that identifies pages that reside on the source host. The DSM module can then establish a connection with a DSM module of source host and request the desired page. The DSM module of the source host can provide the requested page. The received page can then be mapped in to process address space and the lists of the DSM modules can be updated accordingly.

Embodiments are discussed herein with respect to a Linux operating system kernel however aspects of the present disclosure are not necessarily so limited and various aspects of the disclosure can be used in combination with other operating systems. The Linux kernel can implement a Virtual File System VFS that facilitates separation of actual file system code from the rest of the kernel. The kernel can maintain files using index nodes Modes and directory entries dentries .

According to various embodiments the file created from the process address space can be mapped into the address space of the file system using a system command such as mmap . When a file is mapped into memory using mmap the Linux kernel can create entries in the page tables to allow for detection of when portions of the mapped memory are accessed read or written . Attempting to access portions that are not located in local physical memory can result in page faults. A kernel routine can then be called to load the requested portions into physical memory. Consistent with embodiments this can include the use of a DSM module configured to interface the kernel module and to retrieve data from memory located on a source host. The local page tables can then be updated.

Various aspects of the present disclosure are directed toward the mapping of the file in a manner that does not use anonymous memory memory mapping with no backing file or device . Initially an anonymous mapping only allocates virtual memory. Anonymous mappings may be created using the MAP ANONYMOUS flag within mmap .

Consistent with embodiments of the present disclosure the standard code for the page fault routine and tables of the kernel can be used. For instance the page tables can remain unmodified in that they do not contain extra information or bits to indicate whether or not a page is stored at a remote host. This can be useful for allowing the system to remain compatible with changes and additional development of the Linux kernel.

As discussed herein the address space of a process can include a number of memory segments including but not necessarily limited to the program s executable code and static data the heap the stack shared libraries loaded when the program was created shared memory segments and files that have been mapped into the address space e.g. using mmap .

Turning now to the figures depicts a block diagram of a system configured to schedule applications between multiple hosts consistent with embodiments of the present disclosure. The system includes two or more hosts which are communicatively connected by common infrastructure . As discussed herein the hosts can include computer hardware such as processors memory input output I O devices storage devices and others. The common infrastructure can include various interconnection solutions including but not limited to local area networks LANs crossbar switches fibre channel over Ethernet or similar solutions.

Each host can be configured to support the execution of a variety of different processes . These processes can include but are not necessarily limited to application level programs and virtual machines or guests . The hosts can be configured to each support a file system virtual address space that is shared between the hosts. Consistent with embodiments the virtual file system is executed on kernels or hypervisors as a single file system having one shared address space. For instance the virtual file system can be a virtual machine that runs as a Symmetric multiprocessing SMP or non uniform memory access NUMA aware operating system on both hypervisors operating in parallel.

Consistent with embodiments the system can be configured to schedule one or more of the processes running on the virtual file system between the available hosts. This scheduling may result in the transfer or migration of a process from one host to another as shown by migrated process . The scheduling decision can be carried out by an administrator module in order to achieve a variety of different goals. For instance the processes can be scheduled to run on a single host when possible to allow the other hosts to be placed into a power savings mode. In other instances the processes can be scheduled to provide load balancing between the hosts e.g. balancing one or more of processor load memory usage power usage and I O bandwidth .

In a NUMA environment a process running on one host may have access to physical memory located on another host however access times for physical memory of a remote host can be longer than access times for physical memory of a local host the host on which the process running . When a process is migrated the system can be configured to handle data transfer between the hosts to allow data stored at a remote host e.g. data corresponding to the address space of the process to be moved to the local host. Embodiments of the present disclosure provide a mechanism to transfer data from a remote host using an on demand technique where the data is transferred in response to a memory access request initiated by the migrated process.

Consistent with certain embodiments the hypervisors can be configured with a page fault routine or module that is called when a data access is for a memory location that is not in local memory. The page fault routine can access a page fault table to determine the location of a page corresponding to the requested memory. As discussed herein a page fault generated for a migrated process can be directed to a distributed shared memory DSM module . The DSM module can access list that is used to determine whether the requested page is local or on a remote host. If the requested page is on a remote host the DSM module can establish a connection with a remote DSM module for a host that has the requested page stored in its physical memory. The remote DSM module can retrieve and provide the requested page while updating a corresponding list to indicate that the requested page is no longer local to the corresponding host .

Aspects of the present disclosure are directed toward a system in which the DSM modules are configured for use with standard components of the kernels . For instance the kernels can be Linux kernels that use standard kernel level application programming interfaces APIs to interface with the DSM modules. In certain embodiments this is facilitated by intelligently mapping the process address space of the migrated application so that accesses to the process address space trigger a page fault within code of the virtual file system .

According to embodiments the migration of a process includes the creation of a file that contains the data of the address space for the migrated process. This file can then be mapped into the virtual file system such that memory accesses to the process address space trigger a page fault within the virtual file system . In certain embodiments this allows for little or no overhead to be used for processes that do not use the distributed shared memory. In embodiments this can be useful for maintaining compatibility with future development of the Linux kernel e.g. where the page fault API remains substantially unchanged in the updates . Embodiments also allow for the memory to be moved without augmenting existing page tables e.g. without adding additional bits to indicate that the page is located on a remote host .

Firmware and hypervisors can run on corresponding and respective hardware components from blocks and . Hypervisors can provide an interface between the hardware and other processes and file systems such as operating systems . The hypervisors can also support page fault routines page tables virtual file system DSM modules and DSM lists .

According to certain embodiments the hypervisors can be respective Linux kernels A and B. Kernels A and B can support a shared kernel C which runs on kernels A and B in parallel. A virtualized file system can be associated with this shared kernel. For instance each of kernels A and B can coordinate a common address space for the virtual file system by maintaining logical consistency between respective instances. Accordingly the operating systems appear as a single operating system to user level applications.

The file can then be mapped into the address space of virtual file system and the calling process per block . For instance the mapping can be implemented within Linux using the mmap system call. The mapping can be carried out on each host with a respective instance of the virtual file system. The mapping creates a link between the mapping on each host and the shared memory on the first host. Thus when the migrated process first attempts to access a portion file on the second host e.g. with a memory read request per block the file system will determine that a page fault should be generated per block . Otherwise the page corresponding to the request can be accessed locally per block .

The generated page fault per block can be handled by a DSM module. The DSM module can determine the location of the requested page using a list that identifies whether the location is local or remote per blocks . If the location is local then the page corresponding to the request can be accessed locally per block . If the location is not local then the DSM module can send a request for the page to the first host per block . The first host using a respective DSM module can then provide the page to the DSM module of the second host per block . According to embodiments the second host can then load the received page into its local memory per block . The mappings of each host can be updated accordingly per block .

According to certain embodiments it may be desirable to proactively move some or all of process address space for a migrated process to the target host e.g. as opposed to waiting for the migrated process to access the process address space . As part of the migration the address space can be accessed to cause the system to proactively retrieve remotely stored data. For instance the opening process e.g. qemu can issue read request for portions of the address space before starting the migrated instance of the process on the target host.

Consistent with certain embodiments interrupts that relate to a migrated process can be handled in a similar manner. If the interrupt is determined to be local to the file system it can be directly injected into the local target system or added to the interrupt list. If the interrupt is determined to be remote then it can be added to the remote source system and handed from there.

The computer system may contain one or more general purpose programmable central processing units CPUs A and B herein generically referred to as the processor . In embodiments the computer system may contain multiple processors however in certain embodiments the computer system may alternatively be a single CPU system. Each processor executes instructions stored in the memory and may include one or more levels of on board cache.

In embodiments the memory may include a random access semiconductor memory storage device and or storage medium either volatile or non volatile for storing and or encoding data and programs. In certain embodiments the memory represents the entire virtual memory of the computer system and may also include the virtual memory of other computer systems coupled to the computer system or connected via a network. The memory can be conceptually viewed as a single monolithic entity but in other embodiments the memory is a more complex arrangement such as a hierarchy of caches and other memory devices. For example memory may exist in multiple levels of caches and these caches may be further divided by function so that one cache holds instructions while another holds non instruction data which is used by the processor or processors. Memory may be further distributed and associated with different CPUs or sets of CPUs as is known in any of various so called non uniform memory access NUMA computer architectures.

The memory may store all or a portion of the various programs modules and data structures for processing data transfers as discussed herein. For instance the memory can store a DSM tool or module and or virtual OS . Consistent with certain embodiments these tools can be implemented as part of one or more database systems. These programs and data structures are illustrated as being included within the memory in the computer system however in other embodiments some or all of them may be on different computer systems and may be accessed remotely e.g. via a network. The computer system may use virtual addressing mechanisms that allow the programs of the computer system to behave as if they only have access to a large single storage entity instead of access to multiple smaller storage entities. Thus while the DSM tool and the Virtual OS are illustrated as being included within the memory these components are not necessarily all completely contained in the same storage device at the same time. Further although the DSM tool and the Virtual OS are illustrated as being separate entities in other embodiments some of them portions of some of them or all of them may be packaged together e.g. as part of the same monitor thread .

In embodiments the DSM tool and the Virtual OS may include instructions or statements that execute on the processor or instructions or statements that are interpreted by instructions or statements that execute on the processor to carry out the functions as described herein. In certain embodiments the DSM tool and the Virtual OS can be implemented in hardware via semiconductor devices chips logical gates circuits circuit cards and or other physical hardware devices in lieu of or in addition to a processor based system. In embodiments the DSM tool and the Virtual OS may include data in addition to instructions or statements.

The computer system may include a bus interface unit to handle communications among the processor the memory a display system and the I O bus interface unit . The I O bus interface unit may be coupled with the I O bus for transferring data to and from the various I O units. The I O bus interface unit communicates with multiple I O interface units and which are also known as I O processors IOPs or I O adapters IOAs through the I O bus . The display system may include a display controller a display memory or both. The display controller may provide video audio or both types of data to a display device . The display memory may be a dedicated memory for buffering video data. The display system may be coupled with a display device such as a standalone display screen computer monitor television or a tablet or handheld device display. In one embodiment the display device may include one or more speakers for rendering audio. Alternatively one or more speakers for rendering audio may be coupled with an I O interface unit. In alternate embodiments one or more of the functions provided by the display system may be on board an integrated circuit that also includes the processor . In addition one or more of the functions provided by the bus interface unit may be on board an integrated circuit that also includes the processor .

The I O interface units support communication with a variety of storage and I O devices. For example the terminal interface unit supports the attachment of one or more user I O devices which may include user output devices such as a video display device speaker and or television set and user input devices such as a keyboard mouse keypad touchpad trackball buttons light pen or other pointing device . A user may manipulate the user input devices using a user interface in order to provide input data and commands to the user I O device and the computer system and may receive output data via the user output devices. For example a user interface may be presented via the user I O device such as displayed on a display device played via a speaker or printed via a printer.

The storage interface supports the attachment of one or more disk drives or direct access storage devices which are typically rotating magnetic disk drive storage devices although they could alternatively be other storage devices including arrays of disk drives configured to appear as a single large storage device to a host computer or solid state drives such as flash memory . In some embodiments the storage device may be implemented via any type of secondary storage device. The contents of the memory or any portion thereof may be stored to and retrieved from the storage device as needed. The I O device interface provides an interface to any of various other I O devices or devices of other types such as printers or fax machines. The network interface provides one or more communication paths from the computer system to other digital devices and computer systems these communication paths may include e.g. one or more networks .

Although the computer system shown in illustrates a particular bus structure providing a direct communication path among the processors the memory the bus interface the display system and the I O bus interface unit in alternative embodiments the computer system may include different buses or communication paths which may be arranged in any of various forms such as point to point links in hierarchical star or web configurations multiple hierarchical buses parallel and redundant paths or any other appropriate type of configuration. Furthermore while the I O bus interface unit and the I O bus are shown as single respective units the computer system may in fact contain multiple I O bus interface units and or multiple I O buses . While multiple I O interface units are shown which separate the I O bus from various communications paths running to the various I O devices in other embodiments some or all of the I O devices are connected directly to one or more system I O buses.

In various embodiments the computer system is a multi user mainframe computer system a single user system or a server computer or similar device that has little or no direct user interface but receives requests from other computer systems clients . In other embodiments the computer system may be implemented as a desktop computer portable computer laptop or notebook computer tablet computer pocket computer telephone smart phone or any other suitable type of electronic device.

As will be appreciated by one skilled in the art aspects of the present invention may be embodied as a system method or computer program product. Accordingly aspects of the present invention may take the form of an entirely hardware embodiment an entirely software embodiment including firmware resident software micro code etc. or an embodiment combining software and hardware aspects that may all generally be referred to herein as a circuit module or system. Furthermore aspects of the present invention may take the form of a computer program product embodied in one or more computer readable medium s having computer readable program code embodied thereon.

Any combination of one or more computer readable medium s may be utilized. The computer readable medium may be a computer readable signal medium or a computer readable storage medium. A computer readable storage medium may be for example but not limited to an electronic magnetic optical electromagnetic infrared or semiconductor system apparatus or device or any suitable combination of the foregoing. More specific examples a non exhaustive list of the computer readable storage medium would include the following an electrical connection having one or more wires a portable computer diskette a hard disk a random access memory RAM a read only memory ROM an erasable programmable read only memory EPROM or Flash memory an optical fiber a portable compact disc read only memory CD ROM an optical storage device a magnetic storage device or any suitable combination of the foregoing. In the context of this document a computer readable storage medium may be any tangible medium that can contain or store a program for use by or in connection with an instruction execution system apparatus or device.

A computer readable signal medium may include a propagated data signal with computer readable program code embodied therein for example in baseband or as part of a carrier wave. Such a propagated signal may take any of a variety of forms including but not limited to electro magnetic optical or any suitable combination thereof. A computer readable signal medium may be any computer readable medium that is not a computer readable storage medium and that can communicate propagate or transport a program for use by or in connection with an instruction execution system apparatus or device.

Program code embodied on a computer readable medium may be transmitted using any appropriate medium including but not limited to wireless wireline optical fiber cable RF etc. or any suitable combination of the foregoing.

Computer program code for carrying out operations for aspects of the present invention may be written in any combination of one or more programming languages including an object oriented programming language such as Java Smalltalk C or the like and conventional procedural programming languages such as the C programming language or similar programming languages. The program code may execute entirely on the user s computer partly on the user s computer as a stand alone software package partly on the user s computer and partly on a remote computer or entirely on the remote computer or server. In the latter scenario the remote computer may be connected to the user s computer through any type of network including a local area network LAN or a wide area network WAN or the connection may be made to an external computer for example through the Internet using an Internet Service Provider .

Aspects of the present invention are described below with reference to flowchart illustrations and or block diagrams of methods apparatus systems and computer program products according to embodiments of the invention. It will be understood that each block of the flowchart illustrations and or block diagrams and combinations of blocks in the flowchart illustrations and or block diagrams can be implemented by computer program instructions. These computer program instructions may be provided to a processor of a general purpose computer special purpose computer or other programmable data processing apparatus to produce a machine such that the instructions which execute via the processor of the computer or other programmable data processing apparatus create means for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

These computer program instructions may also be stored in a computer readable medium that can direct a computer other programmable data processing apparatus or other devices to function in a particular manner such that the instructions stored in the computer readable medium produce an article of manufacture including instructions which implement the function act specified in the flowchart and or block diagram block or blocks.

The computer program instructions may also be loaded onto a computer other programmable data processing apparatus or other devices to cause a series of operational steps to be performed on the computer other programmable apparatus or other devices to produce a computer implemented process such that the instructions which execute on the computer or other programmable apparatus provide processes for implementing the functions acts specified in the flowchart and or block diagram block or blocks.

The flowchart and block diagrams in the Figures illustrate the architecture functionality and operation of possible implementations of systems methods and computer program products according to various embodiments of the present invention. In this regard each block in the flowchart or block diagrams may represent a module segment or portion of code which comprises one or more executable instructions for implementing the specified logical function s . It should also be noted that in some alternative implementations the functions noted in the block may occur out of the order noted in the figures. For example two blocks shown in succession may in fact be executed substantially concurrently or the blocks may sometimes be executed in the reverse order depending upon the functionality involved. It will also be noted that each block of the block diagrams and or flowchart illustration and combinations of blocks in the block diagrams and or flowchart illustration can be implemented by special purpose hardware based systems that perform the specified functions or acts or combinations of special purpose hardware and computer instructions.

Although the present disclosure has been described in terms of specific embodiments it is anticipated that alterations and modifications thereof will become apparent to those skilled in the art. Therefore it is intended that the following claims be interpreted as covering all such alterations and modifications as fall within the true spirit and scope of the disclosure.

