---

title: Methods and systems for removal of rolling shutter effects
abstract: Methods and systems for rolling shutter removal are described. A computing device may be configured to determine, in a frame of a video, distinguishable features. The frame may include sets of pixels captured asynchronously. The computing device may be configured to determine for a pixel representing a feature in the frame, a corresponding pixel representing the feature in a consecutive frame; and determine, for a set of pixels including the pixel in the frame, a projective transform that may represent motion of the camera. The computing device may be configured to determine, for the set of pixels in the frame, a mixture transform based on a combination of the projective transform and respective projective transforms determined for other sets of pixels. Accordingly, the computing device may be configured to estimate a motion path of the camera to account for distortion associated with the asynchronous capturing of the sets of pixels.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09357129&OS=09357129&RS=09357129
owner: Google Inc.
number: 09357129
owner_city: Mountain View
owner_country: US
publication_date: 20140926
---
This application is a continuation of U.S. patent application Ser. No. 13 611 023 filed Sep. 12 2012 and entitled METHODS AND SYSTEMS FOR REMOVAL OF ROLLING SHUTTER EFFECTS the entirety if which is incorporated herein by reference.

Video stabilization techniques may be used to improve recorded videos. With video cameras camera shake can cause visible frame to frame jitter in a recorded video. For example a handheld recorded video may be perceptibly shakier than a video recorded using a tripod mounted camera or other stabilization equipment such as camera dollies or steady cams due to motion of the operator holding the camera during recording. However recording videos using handheld video recording may enable more opportunities for filming.

Video stabilization techniques may be used to create a stable version of a casually shot video e.g. a video recorded on a device with little or no stabilization equipment . Video stabilization techniques generally attempt to render the recorded video as if the video would have been recorded from a smooth or stable camera path.

The present application discloses methods and systems for removal of rolling shutter effects from a video. In one aspect a method is described. The method may comprise determining by a computing device in a frame of a video captured by a camera features with a distinguishable geometric characteristic. The frame includes a plurality of rows of pixels captured sequentially in time. The method also may comprise determining for a pixel representing a feature of the features in the frame a corresponding pixel representing the feature in a consecutive frame in the video. The method further may comprise determining for a set of rows of pixels including the pixel in the frame a projective transform based on i a first position of the camera at which the set of rows of pixels is captured and ii a second position of the camera at which a corresponding set of rows of pixels including the corresponding pixel in the consecutive frame is captured. The projective transform may represent motion of the camera from the first position to the second position. The method also may comprise determining for the set of rows of pixels in the frame a mixture transform based on a combination of the projective transform and respective projective transforms determined for other sets of rows of pixels including the features in the frame. The method further may comprise estimating by the computing device a motion path of the camera based on the mixture transform and respective mixture transforms determined for the other sets of rows of pixels to account for distortion associated with the sequential capturing of the plurality of rows of pixels in the frame.

In another aspect a non transitory computer readable medium having stored thereon instructions executable by a computing device to cause the computing device to perform functions is described. The functions may comprise determining in a frame of a video captured by a camera features with a distinguishable geometric characteristic. The frame may include a plurality of sets of pixels captured sequentially in time. The functions also may comprise determining for a pixel representing a feature of the features in the frame a corresponding pixel representing the feature in a consecutive frame in the video. The functions further may comprise determining for a set of pixels including the pixel in the frame a projective transform based on i a first position of the camera at which the set of pixels is captured and ii a second position of the camera at which a corresponding set of pixels including the corresponding pixel in the consecutive frame is captured. The projective transform may represent motion of the camera from the first position to the second position. The functions also may comprise determining for the set of pixels in the frame a mixture transform based on a combination of the projective transform and respective projective transforms determined for other sets of pixels including the features in the frame. The functions further may comprise estimating a motion path of the camera based on the mixture transform and respective mixture transforms determined for the other sets of pixels to account for distortion associated with the sequential capturing of the plurality of sets of pixels in the frame.

In still another aspect a system is described. The system may comprise a feature extraction module configured to determine in a frame of a video captured by a camera features with a distinguishable geometric characteristic. The frame may include a plurality of sets of pixels captured sequentially in time. The feature extraction module also may be configured to determine for a pixel representing a feature of the features in the frame a corresponding pixel representing the feature in a consecutive frame in the video. The system also may comprise a transformation module in communication with the feature extraction module and configured to determine for a set of pixels including the pixel in the frame a projective transform based on i a first position of the camera at which the set of pixels is captured and ii a second position of the camera at which a corresponding set of pixels including the corresponding pixel in the consecutive frame is captured. The projective transform may represent motion of the camera from the first position to the second position. The transformation module also may be configured to determine for the set of pixels in the frame a mixture transform based on a combination of the projective transform and respective projective transforms determined for other sets of pixels including the features in the frame. The system further may comprise a camera path estimation module in communication with the feature extraction module and the transformation module and configured to estimate a motion path of the camera based on the mixture transform and respective mixture transforms determined for the other sets of pixels to account for distortion associated with the sequential capturing of the plurality of sets of pixels in the frame.

The foregoing summary is illustrative only and is not intended to be in any way limiting. In addition to the illustrative aspects embodiments and features described above further aspects embodiments and features will become apparent by reference to the figures and the following detailed description.

The following detailed description describes various features and functions of the disclosed systems and methods with reference to the accompanying figures. In the figures similar symbols identify similar components unless context dictates otherwise. The illustrative system and method embodiments described herein are not meant to be limiting. It may be readily understood that certain aspects of the disclosed systems and methods can be arranged and combined in a wide variety of different configurations all of which are contemplated herein.

Rolling shutter is a method of image or video acquisition in which a frame is recorded not from a snapshot of a single point in time but rather by scanning across the frame either vertically or horizontally. Thus not all parts of the image may be recorded at the same time even though the frame may be displayed at the same time during playback. This is in contrast with global shutter in which the frame as a whole may be exposed for a given time window. In examples rolling shutter may produce predictable distortions of fast moving objects or fast moving camera or when an imaging sensor of the camera captures rapid flashes of light.

Rolling shutter may be implemented by rolling moving a shutter of the camera across an exposable image area instead of exposing the image area as a whole at the same time. The shutter could be either mechanical or electronic. Rolling shutter methods may cause the imaging sensor to continue to gather photons during an image or video acquisition process thus increasing sensitivity. Rolling shutter however can cause such effects as wobble skew smear and partial exposure.

Wobble may occur in hand held camera shots and may be worse when the camera is vibrating due to being attached to a moving vehicle for instance. The rolling shutter may cause an image to wobble compress and stretch different parts of the frame .

Skew may be described as a kind or one manifestation of wobble. The image may bend diagonally in one direction or another as the camera or subject moves from one side to another exposing different parts of the image at different times.

Smear can be noticed when photographing or recording a video of a moving object like a fan or a propeller for example. The smear of each blade may be caused by the propeller rotating at the same or near the same speed of capturing the frame by the camera. As an example viewed perpendicular to a propeller spinning clockwise the blades on the left side can appear thinner than usual while the blades on the right side can appear thicker and can even appear as if the blades are not connected at the center of the propeller.

If a camera flash occurs in the shot quick nature of the flash may be present for some not all rows of pixels in a given frame and thus can cause partial exposure. As an example a top third of the image may be brightly lit by the flash while a bottom two thirds of the image may be dark and unlit.

Magnitude of distortion occurring may depend on speed of capturing of rows or sets of pixels i.e. readout speed. Higher readout speeds may cause less distortion. In some examples readout speed may be determined a priori for the camera or may be calibrated from a video sequence recorded by the camera. A computing device may be configured to process the video with the a priori knowledge of camera characteristics to compensate for and remove rolling shutter effects. However a priori knowledge of the camera characteristics or calibration results may not be available and a calibration free rolling shutter effects removal method may be implemented by the computing device.

Referring now to the Figures illustrates a block diagram of an example calibration free rolling shutter effects removal system . The system includes a feature extraction module a transformation module in communication with the feature extraction module a camera path estimation module in communication with the feature extraction module and the transformation module and the video stabilization module in communication with the feature extraction module and the camera path estimation module . The system may be configured to receive a video recorded by a camera and to perform calibration free rolling shutter effects removal and video stabilization processes on the video.

For example the feature extraction module may be configured to receive a video including a sequence of frames and captured by the camera and the feature extraction module may be configured to determine in a frame of the video features with a distinguishable geometric characteristic. The distinguishable geometric characteristic for example may include a corner formed by two converging lines depicted in the frame. In another example the distinguishable geometric characteristic may include a location at an intersection of two lines depicted in the frame. Other examples of the distinguishable geometric characteristic are possible.

In an example the frame may include a plurality of sets e.g. row or columns of pixels captured asynchronously e.g. sequentially in time using an example rolling shutter method. The feature extraction module also may be configured to for a pixel representing a feature of the features in the frame a corresponding pixel representing the feature in a consecutive frame in the video.

The transformation module may be configured to determine for a set of pixels including the pixel in the frame a projective transform based on i a first position of the camera at which the set of pixels is captured and ii a second position of the camera at which a corresponding set of pixels including the corresponding pixel in the consecutive frame is captured. The projective transform may describe or represent motion of the camera from the first position to the second position. The transformation module also may be configured to determine respective projective transforms for other sets of pixels including the features in the frame. Further the transformation module may be configured to determine for the set of pixels in the frame a mixture transform based on a combination of the projective transform and the respective projective transforms determined for the other sets of pixels including the features in the frame. The transformation module further may be configured to determine respective mixture transforms for the other sets of pixels including the features in the frame.

The camera path estimation module may be configured to estimate a motion path of the camera based on the mixture transform and the respective mixture transforms determined for the other sets of pixels to account for distortion associated with the asynchronous or sequential capturing of the plurality of sets of pixels in the frame. As an example the camera path estimation module may be configured to track the features in the plurality of frames of the video. Motion models of varying degrees of freedom e.g. translation similarity affine perspective transforms and mixture transforms as described above may be fit to the tracked features to estimate the motion path of the camera between two frames and mixture transforms may account for rolling shutter distortion. The motion models can be transformed to a common coordinate system and concatenated to yield an estimated camera path over all frames of the video.

The video stabilization module may be configured to unwarp or remove the rolling shutter distortions from the video based on the estimated motion path of the camera. Further in some examples the video stabilization module may be configured to stabilize the video by performing post processing techniques. The video stabilization module may be configured to estimate a new steady smooth camera path and to recast the video from a viewpoint of the new smooth camera path. The steady or smooth camera path may dampen high frequency jitter and remove low frequency distortions that occur during handheld panning shots or videos recorded by a moving camera for example.

Components of the system may be configured to work in an interconnected fashion with each other and or with other components coupled to respective systems. One or more of the described functions or components of the system may be divided up into additional functional or physical components or combined into fewer functional or physical components. In some further examples additional functional and or physical components may be added to the examples illustrated by . Still further any of the feature extraction module the transformation module the camera path estimation module and or the video stabilization module may include or be provided in the form of a processor e.g. a micro processor a digital signal processor DSP etc. configured to execute program code including one or more instructions for implementing logical functions described herein. The system may further include any type of computer readable medium non transitory medium or memory for example such as a storage device including a disk or hard drive to store the program code. In other examples the system may be included within other systems.

The computing device may be configured to perform motion estimation by first matching features having a distinguishable geometric characteristic across frame pairs to obtain potential matches. Further the computing device may be configured to perform outlier rejection to remove pixels with locally inconsistent motion and retain features with similar moving features in a local neighborhood. At block the computing device may be configured to fit homography mixtures e.g. mixture transforms as described with respect to to the potential matches obtaining a parametric model for motion and rolling shutter distortion between frames. At block the computing device also may be configured to estimate four degrees of freedom similarities that account for instability e.g. vibration or shake of an original camera path. At block the computing device may be configured to determine a modified smooth camera path and a crop window transform to stabilize the camera path over time. At block the computing device may be configured to use the estimated homography mixtures to unwarp the rolling shutter distortions and the crop window transform is applied to stabilize the video.

Turning to individual entities illustrated in each client A N may be used by a user to request video hosting services. For example a user can use the client A to send a request for uploading a video for sharing or playing a video. The clients A N can be any type of computer device such as a personal computer e.g. desktop notebook tablet laptop computer as well as devices such as a mobile telephone personal digital assistant or IP enabled video player. The clients A N may include a processor a display device or output to a display device and a local storage such as a hard drive or flash memory device to which the clients A N store data used by the user in performing tasks and a network interface for coupling to the video hosting service via the network .

The clients A N may include video players A N e.g. the Flash player from Adobe Systems Inc. or a proprietary one for playing a video stream. The video players A N may be standalone applications or a plug in to other applications such as a network or Internet browser. Where the client A N is a general purpose device e.g. a desktop computer mobile phone the players A N may be implemented as software executed by the computer. Where the clients A N are dedicated devices e.g. dedicated video players the players A N may be implemented in hardware or a combination of hardware and software. The players A N may include user interface controls and corresponding application programming interfaces for selecting a video feed starting stopping and rewinding a video feed. Also the players A N can include in a user interface a video display format selection configured to indicate a video display format e.g. a standard definition TV or a high definition TV . Other types of user interface controls e.g. buttons keyboard controls can be used as well to control the playback and video format selection functionality of the players A N.

The network enables communications between the clients A N and the video hosting service . In one example the network is the Internet and uses standardized internetworking communications technologies and protocols known now or subsequently developed that enable the clients A N to communicate with the video hosting service . In another example the network may be a wireless cellular network that enables wireless communication between the clients A N and the video hosting service .

The video hosting service comprises a calibration free rolling shutter effects removal system a video server an ingest server and a video database . The video server may be configured to serve videos from the video database in response to user video hosting service requests. The ingest server may be configured to receive user uploaded videos and store the videos in the video database . The video database may be configured to store user uploaded videos and videos processed by the calibration free rolling shutter effects removal system . In one example the video database stores a large video corpus.

The calibration free rolling shutter effects removal system may include a feature extraction module a transformation module a camera path estimation module and a video stabilization module . The system may be configured to receive user uploaded videos from the ingest server and to perform video stabilization of the videos.

The video hosting service may be configured to receive a video from a client of the clients A N and receive a single command by a single action of a user of the client requesting a stabilized video that is free of rolling shutter effects. Based on the single command the calibration free rolling shutter effects removal system coupled to the video hosting service may be configured to process the video to remove rolling shutter effects and stabilize the video. A stabilized modified video that is free of rolling shutter effects may then be provided to the user.

The method may include one or more operations functions or actions as illustrated by one or more of blocks . Although the blocks are illustrated in a sequential order these blocks may in some instances be performed in parallel and or in a different order than those described herein. Also the various blocks may be combined into fewer blocks divided into additional blocks and or removed based upon the desired implementation

In addition for the method and other processes and methods disclosed herein the flowchart shows functionality and operation of one possible implementation of present embodiments. In this regard each block may represent a module a segment or a portion of program code which includes one or more instructions executable by a processor for implementing specific logical functions or steps in the process. The program code may be stored on any type of computer readable medium or memory for example such as a storage device including a disk or hard drive. The computer readable medium may include a non transitory computer readable medium for example such as computer readable media that stores data for short periods of time like register memory processor cache and Random Access Memory RAM . The computer readable medium may also include non transitory media or memory such as secondary or persistent long term storage like read only memory ROM optical or magnetic disks compact disc read only memory CD ROM for example. The computer readable media may also be any other volatile or non volatile storage systems. The computer readable medium may be considered a computer readable storage medium a tangible storage device or other article of manufacture for example.

In addition for the method and other processes and methods disclosed herein each block in may represent circuitry that is wired to perform the specific logical functions in the process.

At block the method includes determining in a frame of a video captured by a camera features with a distinguishable geometric characteristic and the frame may include a plurality of sets of pixels captured sequentially in time. A camera may have recorded a video for example and the video may have been uploaded to and received at a computing device such as a computer laptop mobile phone etc. or a server. The video may include a sequence of frames. Each frame may include a plurality of sets of pixels. The sets of pixels may be rows or columns of pixels for example. For illustration of the method rows of pixels will be used herein to represent the sets of pixels as an example and without loss of generality. The frames may have been acquired by the camera with a rolling shutter method. i.e. the rows of pixels may have been captured sequentially in time asynchronously .

The computing device may be configured to determine features or locations that can be tracked in frames of the video. For example the computing device may be configured to identify features in a frame of the video that have a distinguishable geometric characteristic. As an example the computing device may be configured to determine corners at pixel locations i.e. a location where two lines depicted in the frame converge e.g. the location where two sides of a building intersect where both eigenvalues of a second moment matrix of pixel intensities are above a pre defined threshold. The threshold may be chosen with respect to a maximum eigenvalue across all pixels effectively imposing a frame global threshold. Corners are used as an example for illustration only and features with other geometric characteristics can be used.

Further the computing device may be configured to perform outlier rejection locally within the bins. As an example features that deviate from a mean translation in a bin more than 2 pixels may be rejected.

To prevent aliasing several grids across different resolutions and offsets can be used. In an example for a grid of size X N cells having square bins of size

Referring back to at block the method includes determining for a pixel representing a feature of the features in the frame a corresponding pixel representing the feature in a consecutive frame in the video. The computing device may be configured to match the features or pixels representing the features across frames of the video. In an example the computing device may be configured to track the features using tracking software such as pyramidical Lucas Kanade feature tracking software. The features may be tracked from frame to frame using any number of methods. For example if the video is a sequence of images F F . . . F video frame pairs may be represented by F F and feature pairs between video frames may be extracted e.g. for each feature or pixel x in frame F a corresponding feature or pixel y is found in a consecutive frame F .

At block the method includes determining for a set of pixels including the pixel in the frame a projective transform based on i a first position of the camera at which the set of pixels is captured and ii a second position of the camera at which a corresponding set of pixels including the corresponding pixel in the consecutive frame is captured and the projective transform may represent motion of the camera from the first position to the second position. For each frame pair F F the computing device may have determined matching feature or pixel locations as described at block and may be configured to determine the projective transform to represent motion of the camera between the frame pair.

In an example case of global shutter capturing method each row of a frame Fmay be imaged at the same time T. Therefore x y are related by x PX y PX where Pand Prepresent corresponding projection matrices. Each projection matrix may be decomposed into an intrinsic camera matrix Kand a camera center s origin tand orientation Rat frame i i.e. P K R t . In an example case of pure rotation t t 1 0 the projection matrices are invertible and both frames are related by the relationship Equation 1 where His a 3 3 projective transform or homography. A similar linear relationship for x and y holds in case of non zero translation if a scene being recorded is approximately in one plane or at infinity.

In an example case of rolling shutter capturing method Pand Pare not frame global but vary across rows of pixels for example. In this case a camera position can be determined at times T s and T s when image or frame rows of pixels sand sincluding x and y are captured or readout.

Without loss of generality the camera may be configured to begin capturing frame i at T 0 and readout time of each row can be determined from T 

Equation 1 can be rewritten as Equation 3 substituting KRwith an unknown projective transform or homography H. As described above in the rolling shutter capturing method the projective transform may depend on row indices sand sresulting in Equation 4 Equation 4 in not limited to a case of zero translation but may also hold if the scene being recorded is approximately in one plane or at infinity.

Equation 4 can be simplified by making an assumption that all pixels within a vicinity of row scan be mapped to row s i.e. relationship in equation 4 may depend on the row index s. The assumption may hold for arbitrary translations and small changes in scale perspective and rotation suited for small inter frame motion of the camera center while recording the video. The simplification can be expressed as follows with Equation 5 

In an example Hcan be estimated for each row of pixels in the frame. However to improve computational efficiency the frame can be divided into multiple blocks such as block and each block including multiple sets or rows of pixels. In addition to computational efficiency for estimating an N degrees of freedom transform N 2 features may be required where each feature may give a constraint for x and y using blocks of rows may ensure determining the N 2 features. A representative projective transform can be determined for each block. As an example the frame can be divided into m 10 blocks resulting in 10 unknown projective transforms H k 1 . . . m to be estimated per frame.

Referring back to at block the method includes determining for the set of pixels in the frame a mixture transform based on a combination of the projective transform and respective projective transforms determined for other sets of pixels including the features in the frame. To model distortions resulting from the asynchronous capturing of rows of pixels and to avoid discontinuity across blocks a mixture transform can be determined for each row based on combining the projective transform of the block and respective projective transforms similarly determined for other blocks in the frame. For example the mixture transform can include a weighted combination of the projective transform and the respective projective transforms.

In an example to determine a mixture transform of a row of pixels or a block of rows of pixels a respective weight associated with the projective transform of the row of pixels may be based on a mean of the Gaussian distribution. Weights assigned to other rows of pixels or blocks may be based on spatial proximity or distance between a given row of the other rows of pixels and the row of pixels. For example a smaller weight can be assigned to a respective row of pixels that is spatially farther in the frame from the row of pixels than another row of pixels that is spatially closer to the row of pixels.

In an example the mixture transform Hcan be fit to a set of normalized matches x y 0 1 x 0 1 by generalizing a normalized direct linear transform DLT to mixture models. For a given match x y x x 1 y y 1 expressed as three dimensional 3D vectors with the projective space equality after transformation holds up to scale 

Aggregating all linear constraints Afor each feature match x y yields a homogenous linear system which can be solved for under a constraint h 1 using Singular Value Decomposition SVD of A. Alternatively equation 9 can be transformed into a homogenous system by explicitly setting bottom right element of each transform to 1 i.e. h 3 3 1 k.

Using Gaussian weights w x may ensure smoothness across rows of pixels or blocks of rows of pixels. Further to ensure that adjacent transforms hdo not differ significantly a regularizer h h 1 can be added to the homogenous system described by equation 9 where 1.5 for example.

To further improve robustness with respect to outliers h can be solved for using iterative least squares method. A geometric error e yHx can be evaluated after each iteration and may be used to scale Ain equation 9 by an inverse error

The mixture transform may account for translation affine and perspective degrees of freedom. In an example not all degrees of freedom may be described in the mixture transform since not all degrees of freedom may vary across rows of pixels or blocks of rows of pixels.

Therefore to improve computational efficiency two reduced mixture models of 6 2k and 4 4k degrees of freedom respectively can be used instead of a full 2 9k mixture model as described in equation 9 . For example the reduced mixture model can be expressed by using 

In equation 11 A is a frame global 2 2 affine matrix w w w a frame constant perspective part and tis a block varying translation expression. Similarly a and d in are frame global scale parameters. This reduced model may increase computational efficiency and stability of solving for the mixture transform.

Referring back to at block the method includes estimating a motion path of the camera based on the mixture transform and respective mixture transforms determined for the other sets of pixels to account for distortion associated with the sequential capturing of the plurality of sets of pixels in the frame. The mixture transform determined by the computing device may be considered as a motion model between the frame and the consecutive frame and the motion model may include multiple degrees of freedom and accounts for rolling shutter distortions such as wobble and skew. Respective motion models of each pair of consecutive frames of the video can be determined similarly and can be transformed to a common coordinate system and concatenated to yield an estimated camera path over all frames of the video.

Further the computing device may be configured to stabilize the video by determining a smooth or optimal modified camera path P t . For example the smooth or optimal camera path P t can be partitioned into three segments where only one may be present at each time t a constant path representing a static camera i.e. 

A steady or smooth camera path motion can be estimated by performing an L1 optimization with imposed constraints. An example constraint may include constraining a crop window associated with the crop window transform B t to fit within frames of the video. The optimization for example may determine a stable camera path P t by minimizing an objective function 

The computed crop transform Bcan be decomposed into B RS with Sbeing a 4 degree of freedom similarities S translation scale and rotation and Ra residual. If perfect stabilization can be achieved Ris zero i.e. the crop transform compensates for any camera shake or motion. However due to the additional constraint that the crop window associated with Bfits within frames of the video Rmay not be zero.

To account for distortion resulting from rolling shutter capturing Smay be replaced with mixture transform Hdetermined for each pair of frames as described at block of the method yielding a per frame rectification rolling shutter distortion removal and stabilization warp circumflex over B RH. When the stabilization warp circumflex over B is applied to frames of the video the video is stabilized and rolling shutter distortions are removed.

To address potential error accumulation over time using circumflex over B adaptively spaced key frames can be used to minimize potential distortion. In an example for a frame interval F F. . . F the camera motion path can be determined by the computing device with respect to Fas homographies or transforms H H. . . H. Hl 1 . . . k can be selected with least non rigid distortion as next key frame. To this end each Hmay be scored using 4 rigidity measures skew change in aspect ratio obtained by applying QR decomposition to H modulus of perspective and average feature residual after registration. Considering variance of each measure across frames rigidity may be defined using a normal distribution around mean zero respectively mean one for aspect ratio . Lastly assuming independence of the four measures Hmay be determined at the frame l 1 . . . k of highest probability i.e. highest rigidity.

Depending on the desired configuration the system memory can be of any type including but not limited to volatile memory such as RAM non volatile memory such as ROM flash memory etc. or any combination thereof. System memory may include one or more applications and program data . Application may include optimal and dynamic crop algorithm that is arranged to provide inputs to the electronic circuits in accordance with the present disclosure. Program Data may include content information that could be directed to any number of types of data. In some example embodiments application can be arranged to operate with program data on an operating system.

Computing device can have additional features or functionality and additional interfaces to facilitate communications between the basic configuration and any devices and interfaces. For example data storage devices can be provided including removable storage devices non removable storage devices or a combination thereof. Examples of removable storage and non removable storage devices include magnetic disk devices such as flexible disk drives and hard disk drives HDD optical disk drives such as compact disk CD drives or digital versatile disk DVD drives solid state drives SSD and tape drives to name a few. Computer storage media can include volatile and nonvolatile non transitory removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data.

System memory and storage devices are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by the computing device . Any such computer storage media can be part of the computing device .

Computing device can also include output interfaces that may include a graphics processing unit which can be configured to communicate to various external devices such as display devices or speakers via one or more A V ports or a communication interface . The communication interface may include a network controller which can be arranged to facilitate communications with one or more other computing devices and one or more sensors over a network communication via one or more communication ports . The one or more sensors are shown external to the computing device but may also be internal to the device. The communication connection is one example of a communication media. Communication media may be embodied by computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. A modulated data signal can be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media can include wired media such as a wired network or direct wired connection and wireless media such as acoustic radio frequency RF infrared IR and other wireless media.

In some embodiments the disclosed methods may be implemented as computer program instructions encoded on a computer readable storage media in a machine readable format or on other non transitory media or articles of manufacture. is a schematic illustrating a conceptual partial view of an example computer program product that includes a computer program for executing a computer process on a computing device arranged according to at least some embodiments presented herein. In one embodiment the example computer program product is provided using a signal bearing medium . The signal bearing medium may include one or more program instructions that when executed by one or more processors may provide functionality or portions of the functionality described above with respect to . Thus for example referring to the embodiments shown in one or more features of blocks may be undertaken by one or more instructions associated with the signal bearing medium . In addition the program instructions in describe example instructions as well.

In some examples the signal bearing medium may encompass a computer readable medium such as but not limited to a hard disk drive a Compact Disc CD a Digital Video Disk DVD a digital tape memory etc. In some implementations the signal bearing medium may encompass a computer recordable medium such as but not limited to memory read write R W CDs R W DVDs etc. In some implementations the signal bearing medium may encompass a communications medium such as but not limited to a digital and or an analog communication medium e.g. a fiber optic cable a waveguide a wired communications link a wireless communication link etc. . Thus for example the signal bearing medium may be conveyed by a wireless form of the communications medium e.g. a wireless communications medium conforming to the IEEE 802.11 standard or other transmission protocol .

The one or more programming instructions may be for example computer executable and or logic implemented instructions. In some examples a computing device such as the computing device of may be configured to provide various operations functions or actions in response to the programming instructions conveyed to the computing device by one or more of the computer readable medium the computer recordable medium and or the communications medium . It should be understood that arrangements described herein are for purposes of example only. As such those skilled in the art will appreciate that other arrangements and other elements e.g. machines interfaces functions orders and groupings of functions etc. can be used instead and some elements may be omitted altogether according to the desired results. Further many of the elements that are described are functional entities that may be implemented as discrete or distributed components or in conjunction with other components in any suitable combination and location.

While various aspects and embodiments have been disclosed herein other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting with the true scope being indicated by the following claims along with the full scope of equivalents to which such claims are entitled. It is also to be understood that the terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting.

