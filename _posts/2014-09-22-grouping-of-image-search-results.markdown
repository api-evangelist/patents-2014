---

title: Grouping of image search results
abstract: This specification relates to presenting image search results. In general, one aspect of the subject matter described in this specification can be embodied in methods that include the actions of receiving an image query, the image query being a query for image search results; receiving ranked image search results responsive to the image query, the image search results each including an identification of a corresponding image resource; generating a similarity matrix for images identified by the image search results; generating a hierarchical grouping of the images using the similarity matrix; identifying a canonical image for each group in the hierarchical grouping using a ranking measure; and presenting a visual representation of the image search results based on the hierarchical grouping and the identified canonical images.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09116921&OS=09116921&RS=09116921
owner: Google Inc.
number: 09116921
owner_city: Mountain View
owner_country: US
publication_date: 20140922
---
This application is a continuation of and claims the benefit under 35 U.S.C. 120 of U.S. patent application Ser. No. 13 617 976 now U.S. Pat. No. 8 843 478 filed on Sep. 14 2012 titled Grouping of Image Search Results which is a continuation of and claims the benefit of U.S. patent application Ser. No. 12 876 077 now U.S. Pat. No. 8 352 465 filed on Sep. 3 2010 titled Grouping of Image Search Results which claims the benefit under 35 U.S.C. 119 e of U.S. Provisional Application Ser. No. 61 239 723 filed on Sep. 3 2009 entitled Grouping of Image Search Results and U.S. Provisional Application Ser. No. 61 261 719 filed on Nov. 16 2009 entitled Grouping of Image Search Results the entirety of which are hereby incorporated by reference.

Conventional information retrieval systems for example Internet search engines aim to identify resources e.g. web pages images text documents multimedia context that are relevant to a user s needs and to present information about the resources in a manner that is most useful to the user. Internet search engines return a set of search results in response to a user submitted query. The search results identify resources responsive to a user s query. The identified resources can include varying types of content including documents text images video and audio.

In some information retrieval systems a user can perform an image search. Typically an image search is a search for image content responsive to an input query. An image can include a static graphic representative of some content for example photographs drawings computer generated graphics advertisements web content book content. An image can also include a collection of image frames for example of a movie or a slideshow.

Image search results can be presented to a user in a number of ways. For example image search results can be presented as a collection of thumbnail images representing image resources responsive to the query and sorted e.g. in a list a diagram a map a file or other data sorting structure. In some implementations the image search results are displayed hierarchically according to relevancy. Hierarchically displayed image search results typically present search results with a higher relevancy to a particular query more prominently than search results with lower relevancy to the same query.

In general the systems and methods described in this specification provide techniques to identify a representative image result e.g. a canonical image for each of a number of clusters of images responsive to a given query. One or more image clusters can be presented in a hierarchical manner with respect to the identified representative images.

For example a search system can use signals and ranking mechanisms to hierarchically cluster images for a group of search results. The system can provide clusters of image search results where each cluster of images includes a representation of a canonical image representing a highly relevant search result. Clusters of image search results can be nested such that a member of one cluster of images can be the canonical image for another cluster of images at a different hierarchical level.

The system can provide a interface for presenting and interacting with one or more images of hierarchical clusters of images. Image clusters can be represented by displayed canonical images for the respective clusters. Users can select particular image clusters to view images within that clusters. The images within a cluster can include one or more canonical images representative of a further cluster of images representing a cluster at another hierarchical level.

In general one aspect of the subject matter described in this specification can be embodied in methods that include the actions of receiving an image query the image query being a query for images receiving ranked image search results responsive to the image query the image search results each including an identification of a corresponding image resource generating a similarity matrix for images identified by the image search results generating a hierarchical grouping of the images using the similarity matrix identifying a canonical image for each group in the hierarchical grouping using a ranking measure and presenting a visual representation of the image search results based on the hierarchical grouping and the identified canonical images. Other embodiments of this aspect include corresponding systems apparatus and computer program products.

These and other embodiments can optionally include one or more of the following features. Identifying a canonical image for each group includes identifying for each group an image an image having a highest image search rank and selecting the image having the highest image search rank as the canonical image for that group. Identifying a canonical image for each group includes identifying an image of the group as having a highest ranking according to the ranking measure and selecting the image having the highest ranking as the canonical image for that group. Selecting the image having the highest ranking includes calculating an image ranking for each image in the group including calculating a similarity between each image using one or more similarity metrics and comparing the image ranking for each image to identify an image having the highest image ranking. Presenting a visual representation of the image search results includes using a representation of one or more canonical images to represent one or more groups of images in the visual representation of the image search results.

The visual representation includes one or more first canonical images having a first size representing higher level image clusters and one or more second canonical images having a second smaller size associated with each first canonical image. Generating the hierarchical groups of images includes using hierarchical agglomerative clustering to group the image search results in a dendrogram structure and where the canonical image for each group corresponds to each cluster in the dendrogram. Generating the hierarchical grouping further includes generating a first number of clusters using the images in the similarity matrix identifying canonical images for each cluster of the first number of clusters and generating a second number of clusters using the identified canonical images for the first number of clusters.

In general one aspect of the subject matter described in this specification can be embodied in methods that include the actions of receiving an image query receiving ranked image search results responsive to the image query the image search results including an identification of corresponding image resources generating a similarity matrix for images identified by the image search results generating a hierarchical grouping of the images using the similarity matrix and identifying a canonical image for each group in the hierarchical grouping using a ranking measure. Other embodiments of this aspect include corresponding systems apparatus and computer program products.

These and other embodiments can optionally include one or more of the following features. The method further includes presenting an array of images representing a plurality of groupings of images from the hierarchical grouping and receiving a selection of an image from the array of images and presenting a hierarchical grouping of images associated with the selected image form the array of images. Presenting an array of images further includes identifying a first plurality of image grouping having a greatest strength and identifying a second plurality of image groupings having a highest similarity relative to the first plurality of image groupings. Presenting the hierarchical grouping of images further includes presenting in a first region a representation of the array of images and presenting in a second region a representation of the hierarchical grouping of images coupled to the representation of the array of images.

Particular embodiments of the subject matter described in this specification can be implemented so as to realize one or more of the following advantages. Representations of canonical images e.g. thumbnails can be used to graphically describe a cluster of image search results without requiring a user to review all available image search results. As an result the user can quickly peruse the canonical images within the image search results to determine whether the image cluster includes images having user desired content. In some implementations the system displays more relevant image results larger than other image results to allow more screen space for image search results. Presentation of canonical images provides an overview of a range of image search results. This allows a user to explore image search results reflecting a general information space efficiently.

The details of one or more implementations are set forth in the accompanying drawings and the description below. Other features and advantages will be apparent from the description and drawings as well as from the claims.

The system receives an image query. An image query is a search query for particular image content responsive to the query. For example a user can send the system a query that describes a particular image or type of image. The system can send the received image query to an image search engine that identifies search results.

The image query provides information about one or more images associated with a topic a website a webpage an offline database an online database a transaction a document a photograph a drawing or other content. The image query includes one or more query terms identifying requested image content. The query terms can identify one or more search strings e.g. red rose bouquet apple bakery logo image features e.g. color texture dimension file type e.g. bitmap jpeg tiff or any combination of the above. Alternatively in some other implementations the query itself is an image.

The system receives ranked image search results responsive to the image query. The image search results identify corresponding image resources relevant to the received image query. For example a search system can include a ranking engine that ranks image search results responsive to a received query according to one or more criteria. The system then uses the ranked search results as an input to group images into an organized and highly relevant hierarchical structure.

The system generates a hierarchical grouping of the images identified in the search results. For example the system uses clustering techniques to perform a first level grouping of the images e.g. an initial clustering of images identified from the image search results . The first level grouping of images can include clustering data using one or more hierarchical data clustering techniques for example according to a similarity between images identified in the search results. In some implementations the system uses additional external inputs when generating hierarchical image clusters. For example the system can use data from the user s profile to bias image search results when generating the hierarchical image clusters. One or more canonical images are selected for each group of images in the hierarchy. Techniques for selecting canonical images are described in greater detail below.

The system presents one or more of the image search results according to the hierarchical clustering. Additionally the system augments the presentation of image search results according to user interaction. The image search results can be displayed in a particular hierarchy determined by one or more data clustering techniques. The displaying can include canonical images representing groups or clusters of images at different levels of the hierarchy. Example data clustering techniques are shown below with reference to .

In some implementations the system presents each cluster of image search results with a selected canonical image at the forefront e.g. center of a circular area and additional images in the background e.g. surrounding a circular area . Alternatively in some other implementations the system presents clusters according to a single canonical image which can be expanded in response to user input to display other images in the next hierarchical level. The displayed image search results can be augmented in response to the user input for example to display different image search results e.g. associated with a particular cluster or hierarchical level or display image search results at different sizes. Augmenting the display can include animating changes moving image search results scaling image search results and redrawing image search results corresponding to the user input.

In some implementations only a system selected portion of the represented images are initially presented within the search results. The system can display thumbnail images reduced images or geometric representations of images if for example real estate within the GUI is scarce. The system can also provide software controls for navigating through additional images. In some examples a user can choose to zoom pan rotate deemphasize switch shrink copy or otherwise manipulate images within the presented search results.

The system presents the image search results in graphical or diagram forms including but not limited to a tree structure a fan structure a spherical structure a dendrogram structure or some arbitrarily shaped structure indicating a hierarchical flow. In some implementations the presented visual representation of the image search results are combined with search results sponsored links advertisements software controls publisher content images video content audio content and other content.

The system computes a similarity matrix. A similarity matrix generally includes an N N matrix of image results where each entry in the matrix is a similarity value associating two images. In particular the images are the images identified by the search results. The similarity value represents a score identifying the similarity between a pair of images. Similarity can be calculated for example using color texture shape or other image based signals. In some implementations image metadata is used in calculating similarity. For example metadata identifying a location where or time when the image was captured external information including text associated with the image e.g. on a webpage or automatically extracted metadata such as facial identification.

In some implementations the system computes the similarity metrics according to one or more similarity metrics for the images identified by the search results. The similarity metrics can be based on features of the images. A number of different possible image features can be used including intensity color edges texture wavelet based techniques or other aspects of the images. For example regarding intensity the system can divide each image into small patches e.g. rectangles circles and an intensity histogram can be computed for each patch. Each intensity histogram can be considered to be a feature for the image.

Similarly as an example of a color based feature the system can compute a color histogram for each patch or different patches within each image. The color histogram can be calculated using any known color space such as the RGB red green blue color space YIQ luma Y and chrominance IQ or another color space. Histograms can also be used to represent edge and texture information. For example histograms can be computed based on patches of edge information or texture information in an image.

For wavelet based techniques a wavelet transform may be computed for each patch and used as an image feature for example. The similarity metrics can alternatively be based on text features metadata user data ranking data link data and other retrievable content.

The similarity metrics can pertain to a combination of similarity signals including content based e.g. color local features facial similarity text etc. user behavior based e.g. co click information and text based e.g. computing the similarity between two sets of text annotations . Additionally text metadata associated with the images can be used for example file names labels or other text data associated with the images . When using local features the system typically computes the similarity based on the total number of matches normalized by the average number of local features. The similarity matrix or other structure can then be generated for the particular one or more similarity metrics using values calculated for each pair of images.

The similarity matrix can be computed for each unique pair of images in the image search results. For example the system can construct a similarity matrix by comparing images within a set of images to one another on a feature by feature basis. Thus each image has a similarity value relative to each other image of the search results.

Overall higher scores are given to more similar images and lower or negative scores are given for dissimilar images. The system can for example use ranked image search results returned in response to a user query to generate a similarity matrix. The similarity matrix can be symmetric or asymmetric.

The system generates a hierarchical cluster of image search results using the similarity matrix and according to a particular clustering technique. In particular the similarity value for each pair of images can be treated as a distance measure. The system can then cluster the images according to a particular threshold distance. The threshold can for example provide a minimum number of clusters or a minimum acceptable similarity value to select an image for membership to a specific cluster. Example clustering techniques are described in greater detail below. In some implementations similar groups of images are further grouped or categorized together to increasingly larger clusters which allows a user to gradually navigate through the layers of the hierarchy to an image of interest.

In some alternative implementations the system generates a hierarchical cluster of images using the similarity matrix and one or more additional image similarity measures. The additional image measures can for example include color texture shape or other image based signals. Additionally non image signals can be used to provide a similarity measure including for example text hyperlinks and user click data.

After generating a hierarchical clustering of images using the similarity matrix the system identifies a canonical image for each cluster. For example the system identifies which image within each image cluster to promote or designate as the representative image for that particular cluster. The selection of a canonical image for each image cluster provides a visual summary of the semantic content of a collection of images. The visual summary also provides a mechanism to navigate a large number of images quickly.

In some implementations one or more additional clustering iterations are performed. In particular additional clustering can be performed using only the canonical images. This provides a refined and reduced set of image results for display.

The canonical image can be selected using a combination of one or more ranking mechanisms mathematical techniques or graphical techniques. The system can calculate the canonical images for each image cluster using an image ranking score for example the ranking score provided from the search system or an alternative ranking system e.g. a ranking derived based on links to and from the image a VisualRank score image tagging information image similarity graphs or other measures.

One example ranking mechanism includes promoting the highest ranked image from a set of image search results as the canonical image for a particular image cluster. For example for a cluster of images x y and z each image is assigned a ranking score within a set of search results as a whole e.g. x 3 y 7 z 54 . The system can use a ranking mechanism to select image x as the canonical image of the cluster based on it having the highest rank within that cluster.

In some implementations the system computes an image similarity graph using image search results to determine a particular relevancy score for an image. The determined score can be used to select a canonical image for one or more of the image clusters. In general image similarity graphs depict a graphical representation of images and their respective similarities. An image similarity graph is generated based on common features between images. The image similarity graph can provide a global ranking of images. The global ranking of images can be combined with other non visual signals to determine the relevancy score. For example text based signals e.g. hyperlinks metadata can be combined with visual features and graph analysis techniques to determine relevancy scores for a set of images. The canonical image can be selected based on the image of a cluster having a highest relevancy score with respect to the images in the cluster.

In some implementations the system calculates and uses a calculated VisualRank to select the canonical image for an image cluster. VisualRank provides an image ranking based on visual hyperlinks among the images. VisualRank estimates a probability of each image in the search results being visited by users following the visual hyperlinks which represent the visual similarity of images. The VisualRank score depends both on initial placement of the images and the collective visual similarities. Thus if a user is viewing an image other visually similar images may also be of interest. For example if image u has a visual hyperlink to image v then there is some probability that the user will jump from u to v. Additionally images that are visited often are important and if an image is important and links to another image it suggests that the other image is also important.

The similarity measure used in VisualRank uses local descriptors. In contrast to global features e.g. color histograms and shape analysis local descriptors contain more image information and are relatively stable under different transformations. Local descriptors generally describe elementary characteristics such as shape color texture or the motion among others. Examples of local descriptors include Harris corners Scale Invariant Feature Transform Shape Context and Spin Images. Images with more matched local descriptors are more likely to be visited by users following the resulting probabilistic visual hyperlinks and therefore are more visually similar.

For a set of images the VisualRank can be calculated by 1 generating local descriptors for the group of image search results 2 constructing a collection of hash tables and indexing each local descriptor into each of the hash tables 3 aggregating images with identical hash keys across all hash tables for each local descriptor and 4 regrouping matched features by the images that can be associated with the local descriptor. Typically image pairs are considered matched if the images share more than three matched descriptors. The similarity value between two images is computed according to the total number of matches normalized by their average number of local features. The highest similarity value represents the canonical image for an image cluster. Calculating VisualRank for a set of images is described in greater detail in Y. Jing and S. Baluja VisualRank Applying PageRank to Large Scale Image Search IEEE Transactions on Pattern Analysis and Machine Intelligence November 2008.

In some implementations the system uses additional signals to identify a canonical image for a particular image cluster. The additional signals can include quality scores image features and other content based features. For example content based features include the intensity of an image edge based features of an image metadata within an image and text within an image. Other techniques of generating hierarchical image clusters and subsequently selecting respective canonical images can be used.

In some other implementations ranking scores are calculated by analyzing image signals to determine a visual theme. For example a number of images which contain a company logo can be retrieved in an online search query for the phrase company logo. In some of these images the logo is the main focus of the image whereas in others it occupies only a small portion. The repetition of the logo in a large fraction of the images returned in the search query is a strong image signal that can be used to infer a common visual theme throughout the image set. The ranking scores can then be used to select canonical images for clusters.

In some implementations the system injects standard image ranking results into the image similarity graph computation to bias an end result. For example the system can use current web rankings of image content along with VisualRank to bias the new rankings such that highly ranked images are more likely to be placed near the top when the next ranking is performed. The biased or modified rankings can then be used to select canonical images for clusters.

In some implementations the system implements a distance measuring scheme to provide the basis for determining a similarity calculation. For example the system can implement a symmetric or asymmetric distance measuring techniques. Example distance measuring techniques to determine similarity include but not limited to the Euclidean distance the Manhattan distance the maximum norm distance the Mahalanobis distance or the Hamming distance.

Similarity calculations can influence the graphical shape of a clustering diagram as some elements can be closer to one another when they are more similar and farther apart when the elements are less similar. Similarity calculations can also provide insight into selecting and presenting relevant image content to a user and or search engine website. For example search engines use combinations of similarity calculations to determine representative images to display within news articles advertisements and other content on a webpage.

The clustering diagram is a dendrogram structure having a tree like shape. The clustering diagram illustrates an example arrangement of clusters generated by a hierarchical data clustering technique for example as described above. In some implementations the system uses a combination of data clustering techniques to generate a grouping or clustering of image data. The system can implement one or more data clustering techniques including but not limited to hierarchical agglomerative clustering HAC k medoids clustering affinity propagation clustering step wise clustering fuzzy clustering quality threshold clustering and graph theoretic means clustering.

The example clustering diagram depicts a top row of nodes that represent data e.g. particular objects or image search results . The clustering diagram also includes a number of rows and that represent both data nodes and clusters to which nodes can belong e.g. image search results and clusters of image search results . For example in row a cluster a b is shown as well as individual nodes c e f g and h. More or fewer data nodes can be included in rows . In addition any number of external data nodes may be imported into the clustering diagram for example to form data clusters.

In the clustering diagram the data nodes and data clusters are linked using arrows e.g. arrow . The arrows between the data and the clusters generally represent a degree of similarity in that the more nodes added to a cluster the less overall similarity there is in the cluster e.g. images a and b can be very similar and clustered together but once a less similar image c is added to the cluster the overall similarity incrementally decreases depending on the degree of similarity between images in the cluster .

In operation the system builds the clustering diagram from a number of individual data nodes. At each iteration e.g. row of the dendrogram a larger cluster is assembled using one or more of the above data clustering techniques and a similarity matrix associating the images identified by the image search results. The system builds a dendrogram or other structure given a set of data nodes and a similarity matrix defining the similarity relationships between the nodes. For example an initial number of data clusters can be specified by the system and membership of the images in the initial clusters is based on a similarity score in the similarity matrix. The similarity matrix and other system data can then be used to convert a particular dendrogram or other structure to a hierarchical display.

In some implementations the system uses an agglomerative e.g. bottom up data clustering technique by representing each element as a separate image cluster and merging the separate image clusters into successively larger groups. For example the system can employ a Hierarchical Agglomerative Clustering HAC technique to generate the dendrogram diagram . The arrows shown in the dendrogram diagram indicate an agglomerative clustering technique because the arrows depict a flow of combining the data and additional data into larger image clusters as the diagram grows downward. In contrast the system can use a divisive e.g. top down clustering technique that can begin with an entire set of items and proceed to divide the items into successively smaller clusters.

In some implementations the system employs composite content based image retrieval CBIR systems in addition to ranking systems and data clustering techniques. Composite CBIR systems allow flexible query interfaces and a diverse collection of signal sources for web image retrieval. For example visual filters can be used to re rank image search results. These visual filters are generally learned from the top 1 000 search results using probabilistic graphical models PGMs to capture the higher order relationship among the visual features.

As shown in the clustering diagram depicts row with two individual images namely a and b . For the initial clustering the system uses specified similarity metrics e.g. a similarity image graph a similarity threshold for the metric e.g. a distance threshold and an associated specified number of image clusters e.g. a minimum set of image clusters . For example the system retrieves or calculates similarity metrics and similarity thresholds for purposes of clustering related images.

After an initial clustering is performed the images e.g. data nodes a and b in row can be merged using the similarity i.e. the distance between the images . For example the images a and b are shown merged in line . The images a and b can also be merged with other data in row or data in another subsequent row. In some implementations the system applies logic to ensure a minimum number of image clusters are used in the calculations and merging actions. Providing a minimum number of image clusters can ensure the calculations do not immediately reduce all images into a single cluster for example.

The clustering technique generated image clusters shown in rows . Particularly the system performs a first merge of image clusters to generate row for example where the images a and b are combined and images c d e f g and h are introduced. The system then generates row by merging images a b and c and separately merging images e with f and g with h . The system also introduces a new image d in row . A similar process is performed to merge images a b c and d into cluster a b c d and images e f g and h into cluster e f g h . In a similar fashion using any number of similarity thresholds and merges the system can generate the cluster a b c d e f g h in row . In some implementations a single similarity threshold can be used to generate the dendrogram in its entirety. In some implementations the system continues clustering image clusters into fewer clusters according to decreasing threshold similarity values until the dendrogram structure is created.

In some implementations the system uses binary system data e.g. data used to build a dendrogram and domain knowledge to generate a particular clustering precision. For example the system defines a set of minimum similarity thresholds ranging from zero to one where one is exactly similar and zero is completely dissimilar. The system uses the similarity thresholds to cut the dendrogram into clusters. The cut operation provides a particular precision of clustering. In some implementations the similarity threshold correlates to the distance between two images. That is the two closest images that meet the minimum similarity threshold are generally merged. As an example the dendrogram depicts a scenario where the system determined the similarity threshold to be 0.1.

In some implementations the system computes an image similarity graph using image search results. The image similarity graph can provide pair wise image similarities where each edge of the graph represents the similarity of the two images. These similarities can be combined with other non visual signals. For example text based signals e.g. hyperlinks metadata can be combined with visual features and graph analysis techniques to retrieve representative images.

Upon completing a particular level of image clustering the system determines a final hierarchy by combining the dendrogram structures generated for each similarity threshold value into one dendrogram tree not shown . The system can use the final hierarchy for each image cluster to select one image per image cluster with the highest image rank according to a particular ranking scheme e.g. search rank or VisualRank as the canonical image for the respective image cluster. For example the image in each cluster with the highest ranking can be selected as the representative canonical image for each image cluster. Thus the end result is a single canonical image representing a cluster of one or more peripheral images.

The canonical images and can be provided in a visual presentation where each image and is linked to a particular group of images based on the clustering. For example as shown in the canonical image is linked to the images c d and itself. In addition the image b is linked in a lower level of the dendrogram to the image a . In a similar fashion the canonical image g is linked to the images e h and itself. In addition the image e is linked to the image f in a lower level of the dendrogram.

In general a data clustering technique can be used to generate values indicating similarity between particular features computed for two images. The data clustering techniques provide a mechanism to arrange groups of images in a hierarchical way. The hierarchy can be used to provide the user with a navigable structure to descend to a desired level of the hierarchy of image search results. The tables below provide example pseudocode for various data clustering techniques namely a hierarchical agglomerative clustering HAC technique Table I a step wise clustering technique Table II a k medoids clustering technique Table III and an affinity propagation clustering technique Table IV .

An example implementation of HAC is shown in pseudo code in Table I below. In Table I the VisualRank is computed one or more dendrograms are assembled using for example the HAC technique a hierarchy is determined using the dendrograms output from the HAC technique and the canonical image is selected using the determined hierarchy. In this example the canonical image for a set of images is tabulated in the variable canonical image. In some implementations the VisualRank is computed at a later time in the technique. For example the system can compute the VisualRank after assembling a dendrogram or other hierarchical structure but before selecting a canonical image for a particular image cluster.

The HAC technique can be used to generate a hierarchy from individual images by progressively merging image clusters. The hierarchy level associated with an image can indicate specific similarities between the image and other images. For example the system generates distance matrices and threshold values to determine similarities between images. As shown in the system can employ the HAC technique to cluster image search results in a dendrogram structure.

HAC techniques generally include determining minimum maximum and mean distances between images in each pair of clusters for purposes of creating distance matrices and or dendrograms and other mapping structures. Each new merged image cluster occurs at a greater distance between clusters than the previous merged image cluster. In some implementations the system determines a stopping point for the HAC technique. For example the system determines when a maximum distance between image clusters is reached e.g. distance criterion or when a minimum image cluster threshold is met e.g. cluster minimum .

Other clustering techniques can be employed by the system to generate a set of images having similar relevancy to one another. For example Table II below illustrates a step wise clustering technique used to generate a collection of images after a first round of clustering has been performed. Once the clustering is performed the system can compute a VisualRank on a set of images for example to select a canonical image for each cluster. The system can also continue to perform clustering after canonical images have been selected for example to further narrow image search results based on different similarity thresholds. In this example the system identifies similarity thresholds or cuts at three points e.g. 0.1 0.3 and 0.8 . The cuts provide a further narrowing of the search results to a specific degree of relevancy. In Table II the final canonical image for each group is tabulated in the variable corpus. 

An example implementation of the k medoids technique is shown in pseudo code in Table III below. The HAC technique shown in Table I above is replaced with the k medoids technique. The k medoids technique partitions images into groups and attempts to minimize squared error i.e. the distance between points labeled to be in a group and a point designated as the center of that group . The k medoids technique includes arbitrarily selecting k images as medoid points out of n data points where n k associating each image to a most similar medoid randomly selecting a non medoid image I and computing the total cost S of swapping the initial medoid image to I . If S 

An example implementation of the affinity propagation technique is shown in pseudo code in Table IV below. The HAC technique shown in Table I above is replaced with the affinity propagation technique. The affinity propagation technique receives input measures of similarity between pairs of images and contemporaneously considers all data points as potential exemplars. Particularly real valued messages can be exchanged between image data points until a high quality set of canonical images and corresponding image clusters are determined. Additional details on affinity propagation can be found in Frey and Dueck Clustering by Passing Messages Between Data Points Science vol. 315 pp 972 976 2007 .

The techniques described above are provided as examples for clustering images in a relevant manner and determining a canonical image for each particular image cluster. Accordingly other methods and techniques can be implemented and or combined to cluster images and determine canonical images for each cluster.

In some implementations the system performs an image clustering process in an iterative manner such that each iteration of clustering refines the set of images. Any number of iterations can be performed to determine and present an appropriate image clustering diagram for a user. For example the system can cluster images using the HAC technique the affinity propagation technique the k medoids technique or other technique in combination or separately.

The system can then use the VisualRank or other ranking mechanism to find the canonical image from each cluster. Upon determining relevant canonical images the system can remove all non canonical images and repeat the clustering process using the same technique or another technique. Performing iterative clustering provides the advantage of improving the visual performance of the presentation content provided to the user such that the user is presented with highly relevant images.

As shown in a graphical user interface includes five top level e.g. parent image clusters and . The screenshot can be generated by the system if for example the system receives image search results responsive to an image query for the phrase Lincoln Memorial. Although depicts five top level image clusters any number of image clusters can be displayed within the GUI . The image clusters shown in screenshot are circular in shape. However image clusters can take any shape that depicts a particular hierarchy including dendrograms polygons lines spheres flowcharts file trees and other 2 D or 3 D shapes.

The GUIs represented in depict relationships between images using shape structure distance connection lines e.g. spokes or lack of connection lines. The various connection lines represent the relative cluster organization of the images in the hierarchy.

The image clusters each contain a number of peripheral image clusters centered on a canonical image. For example the image cluster includes three peripheral image clusters and all related to the Lincoln Memorial in this example e.g. generated in response to an image search query associated with Lincoln Memorial . The peripheral image clusters can include child images or child image clusters. For example the image cluster includes child images and connected to a canonical image i.e. the canonical image for the image cluster . In some implementations peripheral image clusters do not include child images and thus the peripheral image cluster includes one image which represents the canonical image for that particular image cluster.

The child images are each members of image cluster represented by canonical image . Each of the child images are canonical images for their respective clusters. As shown in image cluster child images can be mapped in a similar shape to a parent image cluster. Alternatively child images can be mapped in a different shape. In some implementations child images are placed nearer or farther away from other child images or parent image clusters based on a ranking score or similarity threshold value.

In some implementations child images are also attached to child image clusters e.g. grandchildren to a top level parent image cluster . The grandchild images and or grandchild image clusters represent an additional hierarchical layer of image results. Each grandchild image cluster is represented by a particular canonical image. Further hierarchal levels can be presented as the user zooms into the displayed images results.

In operation a user enters an image search query into a query field . For example the user entered an image query into query field for the phrase Lincoln Memorial. The system sends the image query to an image search engine and receives a collection of search results responsive to the query. The system performs a number of calculations arranges and or clusters the search results according to those calculations and then selects one image for each image cluster as the canonical image. For example in the image cluster the system determined that an image within the child image cluster provided the most representative image for the top level image cluster .

Accordingly the system promoted the image as the canonical image for the image cluster and the image cluster . In a similar fashion the system selects canonical images for the image clusters and . In some implementations the system selects one canonical image for each cluster within a set of search results. In some implementations the system selects a canonical image for the entire set of presented search results in addition to selecting a canonical image for each individual image cluster. For example the system can select a canonical image for all presented search results and further can optionally place the selected canonical image in a center location .

Referring to the GUI also includes a navigation control . The user can activate the navigation control to traverse the search results within the GUI and to configure viewing options. For example the user can use the navigation control to rotate images and to move or pan around the search results within the screenshot . In some implementations the navigation control is used to enable zooming options. For example a zoom box can be toggled on or off using a selectable option within the navigation control .

The zoom box displays a thumbnail image of a set of search results. In general the zoom box provides a map used to determine a location within the search results for example the depth e.g. zoom level within the search results hierarchy. For example the zoom box depicts an overview of how far a user has navigated throughout a set of search results. Thus the user can view the zoom in or zoom out status for the set of search results. A user can zoom in and out of search results by selecting images clusters and or connection lines. In the example shown in the user has not selected any images e.g. image search results within the screenshot . Thus the zoom box depicts a thumbnail view of all available search results.

Other tools can be integrated into the navigation control . For example the navigation control can include cropping tools email tools print tools mirroring tools rotational tools cluster shape building tools and other tools. A user can choose to deemphasize shrink or otherwise manipulate images within a set of presented search results.

The images displayed in are user selectable. For example a user can select an image in to instruct the system to retrieve an associated resource represented in the selected image. The resource may be a link a file an advertisement or other resource. The user can also select an image in to adjust the view of the image within a screen e.g. zoom in or zoom out on the image . For example a user can select image to view an enlarged e.g. zoomed image. When the user selects the image the system enlarges the image and can also enlarge connected images or peripheral images within the same image cluster for example.

In some implementations selecting an image and subsequently enlarging e.g. zooming one image cluster may reduce the amount of GUI space provided for other image clusters. Thus the user can easily view the zoomed image cluster while the unselected search results are shrunken panned or removed from the viewing window. In some implementations when a zoom operation is performed the canonical image for each image cluster does not expand as much as the child images. Consequently the system can display larger child and grandchild images since the canonical image does not expand proportionally with the child and grandchild images.

In some implementations the images displayed in can be navigated using a scroll wheel or navigation buttons without actually selecting or clicking an image. For example users can zoom in based on the center of the image cluster being displayed or based on a particular cursor position when for example the user is using a scroll wheel on a joystick mouse or keyboard device. The user can also select on one or more image or cluster and be presented with a link or link location for more information about the image or cluster.

In general a user can select a portion of a thumbnail image within a set of search results. In the depicted example the user selected the image within the cluster shown in graphical user interface . Selecting image enables the system to zoom and center image within the graphical user interface . Accordingly the graphical user interface depicts a zoomed version of the image cluster including the image as the canonical image for the entire cluster .

In some implementations additional images are shown enlarged within the graphical user interface . For example the image clusters and all include nested image clusters that also include images. After a user selects an image to zoom in on the system zooms in on the surrounding image clusters as well. For example the graphical user interface represents the child images as dots at the ends of connection lines. After the user zooms a nearby image the dots become images e.g. thumbnail representations of the image resources as illustrated in graphical user interface .

The zoom action also provides more detail to other images within the graphical user interface . For example each image within the image cluster includes additional dots which represent another layer of images. Similar to the zoom process described above the user can select another image within an image cluster to view more details of the image search results. When at a deepest level of the hierarchy the search results represent individual image search results without connections to deeper clusters of image search results.

In general zooming in or out of image clusters within the search results does not modify the predetermined canonical image selections. For example once the system determines to display any or all of the search results the canonical images have already been specified and remain constant until a user changes a search term or other search setting. Therefore the image remains the canonical image overall for the depicted search results shown in . Other canonical images within other displayed image clusters are displayed with their respective image clusters.

The zoom box depicts the new zoomed in location displayed in the graphical user interface . For example a thumbnail view of the image cluster is shown selected in the zoom box . The user can for example use control to navigate and adjust the GUI. The user can also navigate by moving a rectangle control within the zoom box . The zoom box also provides the user with information as to what is shown relative to a larger structure. For example the content shown in the rectangle control corresponds to the viewing screen and also provides a user with spatial context as to where the viewing screen content is located relative to a larger cluster display.

The zoom box depicts the new zoomed in location displayed in the graphical user interface . For example a thumbnail view of the image cluster is shown selected in the zoom box .

The zoom box depicts the new zoomed in location displayed in the graphical user interface . For example a thumbnail view of the image cluster is shown selected in the zoom box .

In some implementations the user can select one or more controls within control to zoom out rotate images pan around within the graphical user interface or otherwise manipulate the search result view. For example if the selected image does not satisfy the user s image search query the user can zoom out to find another image search result.

The image cluster diagram includes five top level e.g. parent image clusters and . The image cluster diagram also includes children arranged radially around the inner edge of a circle and a canonical image for each image cluster. A user can select any one of the images or clusters shown in the cluster diagram . For example the user can select an image in the image cluster to zoom in and view more detailed data of each of the children within a particular cluster. In some implementations the user can select an image within image cluster diagram and the system can retrieve information from the image such as a link a file an advertisement or other content.

In some implementations as the zoom in occurs each child image cluster includes a single image that also includes grandchild images. For example the user selects the image cluster within the image cluster . The system receives the selection and displays the zoomed image cluster with the canonical image in the center and several child clusters arranged radially around the canonical image . In the depicted example the image cluster also includes a grandchild image cluster . The grandchild image cluster includes an image cluster as the canonical image of the child cluster and a great grandchild image cluster . The great grandchild image cluster is shown promoted as the canonical image of the grandchild image cluster and finally to the canonical image of the parent image cluster .

In a similar fashion the grandchild clusters are arranged around additional image clusters. Here the user selects an image within the image cluster . The user selected image in this example is not the canonical image of the image cluster . The user selected image represents the canonical image for the image cluster . The system displays the image cluster with the user selected image as the canonical image. As shown in the image cluster upon receiving an image selection from the image cluster the system performed a zoom in operation to present the user with refined search result options within the image cluster where the image is represented in a child cluster as image

As shown in an image search session is depicted showing a graphical user interface . In this example a user entered an image query for the term dog into image query control . The image query control provides search suggestions in a dropdown box to guide the user while entering search query terms. The system receives the user s search query performs the search query and returns image query results. Here the image query results include various images and drawings related to the term dog. 

In addition the image clusters are shown with a system selected canonical image at the top of the graphical user interface and clusters of images with respective canonical images displayed according to relevancy from top to bottom. Under each canonical image the blocked clusters each including at least one medium image e.g. image and up to six smaller child images e.g. images and . Each of the child images e.g. images and can represent a canonical image of a grandchild cluster.

A user can select an image or an image cluster within the graphical user interface . depicts a selection box around an image cluster indicating that the user selected the image cluster . Upon selecting the image cluster the system displays a graphical user interface with the image cluster beginning to expand e.g. pop up from a small display to a larger display. For example the user selects the image cluster and the image cluster expands and overlays a portion of the graphical user interface .

Images within the image cluster can expand proportionally with a user selected image. For example if the user selects a child image within the image cluster the child image may expand more than the original canonical image. In some implementations if the user selects an image other than the canonical image the system swaps the user selected image and the canonical image in the display. In some implementations when a user selects a child level cluster all of the grandchildren images are expanded. In some implementations great grandchildren images are expandable.

In some implementations a user performs a mouse over action to view further detail about an image cluster or a specific image. For example if the user places the cursor over the image cluster the system can provide an expanded view of the cluster. As shown in an expanded view is enlarged as an overlay on the graphical user interface .

The graphical user interface implementations in the foregoing description are generally presented in an interactive browser. The depicted are example representations of graphical user interface implementations and are not intended to be limiting. Many variations of the layout and functionality of graphical user interfaces are possible. Accordingly the scope of protection is not limited by the description set out above. Similarly the foregoing description does not represent an exhaustive list of all possible implementations consistent with this disclosure or of all possible variations of the implementations described. Other implementations are within the scope of the following claims.

The array of image clusters are arranged in representative clusters where similar clusters both semantically and visually are placed near each other. In some implementations a greedy algorithm is used to identify the clusters to present.

In particular the array of image clusters includes a first row of clusters a second row of clusters and a third row of clusters . The first row of clusters represents the top four clusters sorted according to strength. The strength of a cluster is a function of cluster size and original rank. For example as described above image search results are clustered using for example a similarity matrix.

The image search results are clustered into a hierarchical grouping of clusters e.g. using hierarchical agglomerative clustering . In some other implementations one or more different clustering techniques are used including K means spectral clustering and affinity propagation. Each cluster has a size indicating the number of images in the cluster and the images within the cluster have a ranking value associated with the received search results. This combination can be used to identify the top clusters.

In some implementations the top four image clusters are based on the highest image rank received for top level canonical images of the hierarchy of image clusters. For example if there are twelve top level canonical images the four highest ranking ones are selected as the top row of the array. Canonical images representing clusters similar to those four can then be selected for the next rows as described below. In some other implementations other ranking measures can be used to identify the top clusters for example image quality measures ranks associated with source resources e.g. web pages including the images or other signals.

The second row of cluster in the array of image clusters includes clusters that are visually similar to the clusters in the first row of clusters above them. Thus in the array of image clusters the fifth cluster i.e. the first cluster in the second row of clusters is most similar to the first cluster of the first row of images as well as the second cluster in the second row of cluster . For example the first cluster in the first row of clusters includes a cluster of nighttime images of the Eiffel tower the first cluster in the second row of clusters includes visually similar images to both the first cluster and the next cluster in the second row of clusters .

Similar clusters can be identified using the similarity matrix based on the images in the respective clusters. In some other implementations the similarity between two image clusters is determined using different techniques for example by measuring the distance between the clusters e.g. L2 distance or smoothed graph distance .

The third row of clusters similarly includes clusters visually similar to the clusters in the second row of clusters above them as well as similar to adjacent clusters. The process can iteratively be repeated to generate a specified number of image clusters e.g. 20 clusters . Alternative techniques for arranging the image clusters in the array of image clusters include multidimensional scaling and local linear embedding.

Each of the clusters in the array of image clusters is selectable by the user in order to explore the cluster. In some implementations one or more of the clusters in the array of image clusters is labeled with a descriptor for images in the cluster. shows a graphical user interface presenting hierarchical image search results associated with a selected image cluster of the array of image clusters of . In particular the graphical user interface includes an array of image clusters . The array of image clusters can correspond to the array of image clusters . However as shown in the selected image cluster is no longer presented in the array of image clusters .

The selected image cluster is displayed in as a hierarchical grouping of image clusters connected to the presented array of image clusters . The hierarchical grouping of image clusters is similar to those described above and includes a canonical image the cluster at the presented level of the hierarchical grouping of clusters as well as several spokes to canonical images represented different hierarchical levels.

As described above each of the images in the hierarchical grouping of image clusters can be selected in order display images associated with that hierarchical level. The user can interact with the presented images to navigate to another level of the hierarchy e.g. by selecting a canonical representation of a child cluster from the presented parent cluster within the hierarchy .

Thus in the array of image clusters is shown connected to a hierarchical cluster of images for the selected cluster from the array of image clusters smaller than the hierarchical cluster of images . The hierarchical cluster of images is in turn connected to a hierarchical cluster of images representing a child cluster of the hierarchical cluster of images selected by a user. Thus each selection of an image shown in a hierarchical cluster of images generates a new graphical representation of that child cluster represented in the parent cluster by a canonical image.

The term computer readable medium refers to any medium that participates in providing instructions to a processor for execution. The computer readable medium further includes an operating system e.g. Mac OS Windows Linux etc. a network communication module image clustering module canonical image module and other applications .

The operating system can be multi user multiprocessing multitasking multithreading real time and the like. The operating system performs basic tasks including but not limited to recognizing input from input devices sending output to display devices keeping track of files and directories on computer readable mediums e.g. memory or a storage device controlling peripheral devices e.g. disk drives printers etc. and managing traffic on the one or more buses . The network communications module includes various components for establishing and maintaining network connections e.g. software for implementing communication protocols such as TCP IP HTTP Ethernet etc. .

The image clustering module provides various software components for performing the various functions for clustering image search results including generating a similarity matrix and clustering according to specified clustering criteria as described with respect to . The canonical image module provides various software components for performing the various functions for determining a canonical image for each cluster of images as described with respect to .

Embodiments of the subject matter and the operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. Embodiments of the subject matter described in this specification can be implemented as one or more computer programs i.e. one or more modules of computer program instructions encoded on a computer storage media for execution by or to control the operation of data processing apparatus. Alternatively or in addition the program instructions can be encoded on an artificially generated propagated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus for execution by a data processing apparatus. The computer storage medium can be or be included in a computer readable storage device a computer readable storage substrate a random or serial access memory array or device or a combination of one or more of them.

The operations described in this specification can be implemented as operations performed by a data processing apparatus on data stored on one or more computer readable storage devices or received from other sources.

The term data processing apparatus encompasses all kinds of apparatus devices and machines for processing data including by way of example a programmable processor a computer a system on a chip or combinations of them. The apparatus can include special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit . The apparatus can also include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system a cross platform runtime environment e.g. a virtual machine or a combination of one or more of them. The apparatus and execution environment can realize various different computing model infrastructures such as web services distributed computing and grid computing infrastructures.

A computer program also known as a program software software application script or code can be written in any form of programming language including compiled or interpreted languages declarative or procedural languages and it can be deployed in any form including as a stand alone program or as a module component subroutine object or other unit suitable for use in a computing environment. A computer program may but need not correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing or executing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Moreover a computer can be embedded in another device e.g. a mobile telephone a personal digital assistant PDA a mobile audio or video player a game console a Global Positioning System GPS receiver or a portable storage device e.g. a universal serial bus USB flash drive to name just a few. Devices suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user embodiments of the subject matter described in this specification can be implemented on a computer having a display device e.g. a CRT cathode ray tube or LCD liquid crystal display monitor for displaying information to the user and a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide for interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input. In addition a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user for example by sending web pages to a web browser on a user s client device in response to requests received from the web browser.

Embodiments of the subject matter described in this specification can be implemented in a computing system that includes a back end component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a front end component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification or any combination of one or more such back end middleware or front end components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN an inter network e.g. the Internet and peer to peer networks e.g. ad hoc peer to peer networks .

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other. In some embodiments a server transmits data e.g. an HTML page to a client device e.g. for purposes of displaying data to and receiving user input from a user interacting with the client device . Data generated at the client device e.g. a result of the user interaction can be received from the client device at the server.

While this specification contains many specific implementation details these should not be construed as limitations on the scope of the invention or of what may be claimed but rather as descriptions of features specific to particular embodiments of the invention. Certain features that are described in this specification in the context of separate embodiments can also be implemented in combination in a single embodiment. Conversely various features that are described in the context of a single embodiment can also be implemented in multiple embodiments separately or in any suitable subcombination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a subcombination or variation of a subcombination.

Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multitasking and parallel processing may be advantageous. Moreover the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

Thus particular embodiments of the invention have been described. Other embodiments are within the scope of the following claims. In some cases the actions recited in the claims can be performed in a different order and still achieve desirable results. In addition the processes depicted in the accompanying figures do not necessarily require the particular order shown or sequential order to achieve desirable results. In certain implementations multitasking and parallel processing may be advantageous.

