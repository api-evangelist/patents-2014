---

title: Application hosting in a distributed application execution system
abstract: In an application execution system having a plurality of application servers, each application server stores a plurality of applications, and has computational resources for executing applications in response to received requests. Each application server also includes instructions for loading a respective application into volatile storage and executing the application in response to a request from a client, and for returning a result. A generic application instance may be cloned, creating a pool of generic application instance clones that can be loaded with code for a requested application to produce an application instance. The application instance can then be stored in a cache to be used for a future application request.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09658881&OS=09658881&RS=09658881
owner: Google Inc.
number: 09658881
owner_city: Mountain View
owner_country: US
publication_date: 20140825
---
This application is a continuation of U.S. patent application Ser. No. 13 466 061 filed May 7 2012 entitled Application Hosting in a Distributed Application Execution System which is continuation of U.S. patent application Ser. No. 13 212 142 filed Aug. 17 2011 entitled Application Server Scalability Through Runtime Restrictions Enforcement in a Distributed Application Execution System which is a continuation of U.S. patent application Ser. No. 12 331 351 filed Dec. 9 2008 entitled Application Server Scalability Through Runtime Restrictions Enforcement in a Distributed Application Execution System now U.S. Pat. No. 8 005 950. U.S. patent application Ser. No. 13 466 061 U.S. patent application Ser. No. 13 212 142 and U.S. patent application Ser. No. 12 331 351 are incorporated herein by reference in their entireties.

This application is related to U.S. patent application Ser. No. 12 060 798 filed Apr. 1 2008 entitled Efficient Hosting in a Distributed Application Execution System now U.S. Pat. No. 7 877 482 which is incorporated by reference herein in its entirety.

The disclosed embodiments relate generally to methods and systems sometimes called application servers for hosting and executing large numbers of heterogeneous applications.

In general increases in an application s popularity could present a variety of scalability problems that negatively impact a user s experience. For example users could experience slower response times slower page loading and increased time outs on page requests. These scalability problems are typically alleviated by allocating additional capacity to the application such as more storage more memory more CPUs and more machines in general.

Allocating or installing more computing capacity may be a reasonable solution when increases in an application s popularity are experienced over a prolonged period of time or when usage of the application is predictable. Similarly when an application experiences a decrease in usage removing computing capacity previously allocated to the application may be a reasonable solution especially when the decrease is experienced over a prolonged period of time or when the decrease is predictable. However the popularity of an application is often unpredictable due to a variety of factors e.g. time of day current events advertising trends and fluctuates to a large extent which creates load spikes and dips in the application execution or hosting system.

Predefined allocations of computing resources are inefficient solutions for handling temporary load spikes and dips. Increasing or installing more computing resources to handle a load spike is inefficient since the additional pre allocated resources go unused when the spike disappears e.g. when the spike in demand subsides or the application s popularity dips . Similarly decreasing computing resources allocated to an application when its popularity declines is also inefficient since future usage spikes will require the re allocation of previously removed resources back to the application.

To complicate matters further application systems may host a large number of heterogeneous applications each with its own set of fluctuating resource requirements. Pre allocation of resources for the reasons discussed above is often an inefficient solution for ensuring consistent positive user experiences among heterogeneous applications hosted on an application system.

In an application execution system having a plurality of application servers and an application master in an application execution system the application master stores a plurality of applications including a respective application in a library for distribution among the application servers adds a first instance of the respective application from the library to a respective application server for execution and obtains usage information of one or more applications added to the application servers. In accordance with the usage information the application master performs one of a predefined set of actions that includes adding a second instance of the respective application to the plurality of application servers and removing the first instance of the respective application from the respective application server.

In some embodiments the application execution system include a front end server which receives application execution requests from clients and returns results to the requesting clients. The front end server receives from the application master an application distribution map which may include resource usage information that can be used to route requests received from client s . More information regarding the application distribution map is provided in U.S. patent application Ser. No. 12 060 798 filed Apr. 1 2008 entitled Efficient Hosting in a Distributed Application Execution System which is incorporated by reference herein in its entirety.

The application execution system include a plurality of application servers e.g. through . As described in more detail below with reference to each of the application servers includes non volatile storage for storing a plurality of applications in a local library volatile storage and computational resources for executing applications in response to requests received by the application execution system . The application servers may include a runtime manager which as further discussed below with reference to enforces resource limits and restrictions for various resources consumed by an application during execution. In some embodiments the application execution system includes a quota system which in conjunction with the runtime manager implements a plurality of application restriction limits as further discussed below.

The application execution system also includes an application master that distributes applications from a main library having a plurality of applications among the application servers . In the embodiment shown in the main library is stored in the application master . Alternately the main library may be stored remotely from the application master such as in a datastore . In some embodiments each application of the plurality of applications in the main library is a web application that is responsive to HTTP requests. However the present invention can also be used in non web based environments in which case the applications need not be web based applications.

In some embodiments the application execution system also includes a datastore accessible to at least the application master and the front end server for sharing information about the location of applications among the application servers and resource usage or loading information with respect to the application servers .

Optionally the distributed system includes additional resources which may be located either internally or externally to the system for use when executing applications in the application execution system . For example an application executed by the application execution system may access information in one or more of the additional resources in order to process a request received from a respective client . These additional resources may include one or more of other applications and data provided by web services e.g. web feed data from sources such as blog entries headlines podcasts etc. .

The application server may remove one or more applications from volatile memory before performing operation when there is insufficient volatile memory to process the request. Alternatively the application server may automatically remove applications from volatile memory when the amount of available volatile storage is below a predefined threshold.

In some embodiments after returning the result to the request the application server can either remove the respective application from volatile storage or retain the respective application in volatile storage for responding to future requests by determining whether predefined criteria has been met . In some embodiments the predefined criteria used by the application server include usage level criteria which may include the number of requests for the application processed per period of time. The predefined criteria may also include caching criteria which may include the number of respective application instances in volatile storage available for handling new requests and the number of respective application instances handling active requests and therefore not available for handling new requests. Cached application instances are discussed in more detail below with reference to . The predefined criteria may also include error criteria which may be based on the number of errors encountered during execution of the application and the type of errors encountered. For example the application server may remove the respective application from volatile storage if severe errors are encountered during N e.g. 5 10 or 20 consecutive executions of the application.

For applications that fail to meet the predefined criteria No the application server removes the respective applications from volatile storage upon returning the result to the request . In some embodiments the application server may remove the respective applications from volatile storage according to a predefined order for removal. For example the application server may remove the least recently used application.

In some embodiments when determining which application instance to remove from volatile storage the application servers may take into account the service quality levels of the applications for which instances are stored in volatile memory. The service quality level of each application may be based on the level of service requested or paid for. Various forms of preferences for retention of application instances in volatile memory may be given to applications with high service quality levels compared to applications with lower service quality levels. For example lower service quality level application instances may be evicted before higher service quality level application instances whenever a predefined condition is true. The predefined condition may relate to numbers or ratios of lower and higher service quality level application instances loaded in volatile memory. Alternately scores may be computed to determine which application instances to unload from volatile memory and computation of the scores may take into account the service quality levels of the applications.

For applications that meet the predefined criteria Yes the application server retains the respective applications in volatile storage for responding to future requests for the application . In some embodiments the application server retains more than one application instance of the respective application in volatile storage in accordance with predefined caching criteria. In some embodiments the application server limits the number of application instances in volatile storage. For example the application server may limit the total number of application instances in volatile memory to ensure that there is sufficient volatile memory for other processing tasks. Alternatively the application server may limit the number of instances of a respective application to ensure that other requested applications have access to sufficient volatile memory to service their requests.

In some embodiments the application server may terminate execution of the respective application prior to returning the result if the respective application violates any of a plurality of execution restrictions. These execution restrictions may include application resource limits for limiting an application s consumption of system resources during runtime e.g. a response time limit an average response time limit over multiple executions of an application a volatile memory usage limit that limits the amount of volatile memory used by each execution of an application . In some embodiments the same application resource limits are applied to all applications e.g. the volatile memory usage limit is the same for all applications . Alternatively the application resource limits may vary between applications. For example the application execution system may terminate execution of the application if the application s run time or execution time exceeds the response time limit. Optionally in embodiments where the average response time for an application is frequently or periodically updated the application execution system may terminate execution of the application if the application s average response time exceeds the average response time limit e.g. 0.5 seconds . For example multiple instances e.g. all instances being executed of the same application may all be terminated if for some reason the average response time of the application extends beyond the applicable resource limit. The application execution system may also restrict the number of requests processed per period of time for an application the number of CPU cycles per period of time the stack size associated with the execution of an application and other resource usage data as further discussed with reference to Resource Usage Data .

The execution restrictions may also prohibit certain actions performed by applications using one or more predefined application programming interfaces APIs . These execution restrictions may restrict the use of non volatile storage of the application server by an application during execution by preventing the application code from reading or accessing data stored in non volatile storage. In addition the execution restrictions may govern the storage of state information by requiring state information to be retained after returning the result to either be sent to the client for storage or retained in a datastore accessible by all application servers in the application execution system. Other execution restrictions may include restrictions on opening network connections creating new processes by an application including the creation of threads by the application making system calls by an application and other system function calls. In some embodiments to maintain scalability of the application execution system with respect to number of applications that can be executed and number of requests that can be processed per period of time the execution restrictions include a restriction requiring all applications to execute within a secure execution environment. In these embodiments external access to memory locations within the application servers is prohibited. The application execution system may also monitor and enforce restrictions on the frequency of certain actions performed by the applications that impact system performance by monitoring the frequency of calls made by an application to APIs associated with these restricted actions e.g. number of times per period of time that the application calls the API s for accessing a datastore number of times per period of time that the application calls the API s for accessing an external web service .

As previously discussed with reference to in some embodiments the application execution system includes a quota system . The monitoring and enforcement of certain execution restrictions described above may involve the quota system which maintains aggregate quota information for each application. When an application needs to consume a system resource the application execution system may consult the quota system to ensure that the application has not exceeded quota or threshold limits. For example the system may include a restriction on the number of times per day the application can access the datastore e.g. 2 000 000 calls per day using the associated API e.g. the Datastore Interface . Before the application can call the Datastore Interface the system checks the number of calls to the Datastore Interface made by a respective application on all application servers to ensure that the application is still within its quota limit e.g. 2 000 000 calls per day .

In the application server loads the code for App into a generic instance in response to a request received for App . The App instance may be referred to as live or alive since it contains code that is readily executable by the application server. The App instance is loaded into a cache e.g. Live Process Cache . The cache may contain other instances of App as well as instances of other requested applications e.g. App . . . AppN . These application instances in the Live Process Cache are either busy or available although other transitional states could be used in addition in other embodiments. A busy application instance is one that is processing a current request and therefore cannot process another incoming request until it finishes processing the current request. The available instances are ready to process any received request for the respective application.

Resource usage data which allows the system to monitor the amount of system resources consumed by an application may include any combination of the following per period of time number of CPU megacycles number of HTTP requests amount of bandwidth consumed by incoming requests for the application bandwidth in and amount of bandwidth consumed by transmission of outgoing results to requests for the application bandwidth out . In addition resource usage data may also monitor the frequency of certain activities such as accessing a datastore accessing internal or external application resources e.g. web services web feeds news feeds and sending email from the application. These monitored activities are further discussed above with reference to .

Response time data includes data indicating the amount of time it takes the application to issue a response to serve a request. Violations data may include data indicating the frequency of restriction violations associated with the application e.g. number of response time violations over a period of time type of violated restriction s aggregate number of violations .

In some embodiments the application master interface module includes procedures for adding or removing applications from the non volatile storage of the application server. The application master interface module may also include procedures for sending usage information on application resources and server resources to the application master. In some embodiments the front end interface module includes procedures for handling application requests forwarded from the front end . More information regarding the application master and the front end is provided in U.S. patent application Ser. No. 12 060 798 filed Apr. 1 2008 entitled Efficient Hosting in a Distributed Application Execution System which is incorporated by reference herein in its entirety.

Procedure s Live Process Cache Monitor Control for managing application instances in the live process cache may include procedures Load and Remove Application Instance Module for loading and removing application instances into the live process cache in accordance with application usage and available volatile memory as previously discussed with reference to procedures Execute Application Instance Module for executing application instances when processing application requests. The Execute Application Instance Module may also include procedures Resource Limit Enforcement for limiting resource consumption of a particular application. For example an application that consumes more resources than a limit or threshold may be terminated Terminate App Instance as previously described with reference to . The resource limit may be a predefined amount or the threshold may vary depending on factors such as the number of requests for the application. For example applications that receive higher numbers of requests may have a higher threshold before the application instance is terminated. Alternatively the threshold may also depend on the amount of processing resources e.g. one or more of CPU time wall clock time i.e. total elapsed real time memory communication bandwidth and number of system function calls made consumed by the application. The threshold s may be applied per execution of an application or to a running average of resources used over multiple executions of the application. An application instance that consumes resources above a corresponding threshold may be terminated.

The procedures Live Process Cache Monitor Control may also include application programming interfaces APIs that enable and restrict activities that applications may engage in during execution. The APIs may include any combination of the following a Datastore Interface for interfacing with a datastore e.g. the datastore a Cache Memory Interface for interfacing with shared Cache Memory and an External Resources Interface for interfacing with external resources e.g. other applications other websites web services . In embodiments having the Cache Memory and the Cache Memory Interface an application instance can store data e.g. data copied from a datastore for high speed access by all instances of the same application. The application must not rely upon retention of data by the Cache Memory for example the data stored in the Cache Memory for a respective application may be deleted whenever there are no longer any active instances of the application. The Datastore and Cache Memory mechanisms for sharing information between instances of the same application are accessibly only through the APIs provided by the application execution system which facilitates enforcement of application restrictions associated with both durable and temporary storage of data that can be shared between application instances.

The live process cache monitor control module may also include procedures for monitoring the status of application instances Monitor Application Instance Status Module . For example the status of the application instances may be busy available or any transitional state in between see .

Each of the above identified elements in may be stored in one or more of the previously mentioned memory devices and corresponds to a set of instructions for performing a function described above. The above identified modules or programs i.e. sets of instructions need not be implemented as separate software programs procedures or modules and thus various subsets of these modules may be combined or otherwise re arranged in various embodiments. In some embodiments Memory may store a subset of the modules and data structures identified above. Furthermore Memory may store additional modules and data structures not described above.

The application servers send application usage information to the application master and the application master monitors the application servers to generate usage information for each of the applications in the library for a predefined period of time. From the generated usage information the application master can evaluate usage of each application e.g. frequency of usage resources used etc. and can also evaluate the loading of each application server. In some embodiments the usage information e.g. CPU usage information and information about the amount of storage available at a respective application server e.g. server storage data used by the application master to determine the load on an application server are stored in a data structure described below with reference to . Information about the CPU usage of a respective application e.g. CPU usage used by the application master to determine the usage level of the application is stored in a data structure described below with reference to .

As described in more detail below the application master evaluates the usage information according to pre defined criteria and takes appropriate action by increasing or decreasing the number of application servers to which each application has been distributed to ensure that sufficient resources are available to service client requests for execution of the applications. In some embodiments the application distribution process by the application master as applied to each application in the library includes evaluating usage level thresholds for the application based on the number of active application servers to which the application has been distributed. For example minimum and maximum thresholds are determined which indicate a suitable range of application usage over a predefined period of time for the number of application servers on which the application is stored. If the usage level is below the minimum usage threshold Yes the application master removes the application from a selected set of the application servers . Upon receiving application removal instructions from the application master the selected application servers remove the application from their non volatile storage .

If the usage level is above the maximum threshold Yes the application master distributes additional copies of the application from the main library to a selected set of the application servers. The selected application servers store the application in their local libraries in non volatile memory. In some embodiments while performing operations and the application master manages the load on a respective application server in accordance with predefined load distribution criteria by distributing applications to and removing applications from the non volatile storage of the respective application server. More generally the application master takes into account the current application execution loads on the application servers when determining the applications servers to send additional applications and the applications servers from which to remove applications.

Occasionally application server s may need to be removed or taken offline from a cluster for repairs routine maintenance and other reasons. In these situations the application master may transfer load handled by the application server s to be removed and redistribute this load across remaining active application servers. The process of transferring load to the active servers may be rate limited so that application servers can be safely removed after a period of time without disrupting the system.

In some embodiments the removing of previously distributed applications from the non volatile storage of the application servers and the distributing of applications from the library to the application servers are rate limited with respect to how many applications are removed and distributed per predefined period of time. A rate limit e.g. a limit of N applications per unit of time may be applied to each application server individually or to a cluster or other group of application servers. In some embodiments the rate limit is set small enough so that changes in the load pattern of an application server occur slowly rather than all at once which allows the application master to make other changes to account for the load. The load increase that will be caused by adding a new application to a server is unknown. It may cause a large increase in load on the server or it may have no effect. By rate limiting how many applications are added or removed from an application server the system is given more time to adjust to changes in loads caused by the additions or removals.

distribution data identifying application servers that have a copy of the application in their local libraries and

application resource data which includes information about the resources consumed by the application.

information identifying the application servers that contain the respective application e.g. Application Server IDs and

optionally dates and times showing when the respective application was distributed to the identified application servers Distribution Date Time .

In some embodiments the application resource data for a particular application includes one or more of the following fields CPU usage information indicating an amount of CPU usage over a predefined period of time or per execution or other statistics e.g. minimum maximum average mean standard deviation relating to CPU usage by the application frequency of requests indicating a number of executions of the application per predefined period of time or other statistics relating to the frequency of requests for the application and memory usage indicating the amount of memory used during execution of the application or other statistics relating to memory usage by the application. It is noted that the fields of the data structure described above are examples of information stored by the application master. In other embodiments the application master may store a subset of these fields and may optionally store additional information about the applications in the master library . Furthermore the information represented here as being stored in data structure may be organized in other ways for example divided over multiple data structures in other embodiments of the invention.

a unique identifier e.g. network ID for the application server for example an identifier that indicates or that can be used to find the server s location on the network 

local library data identifying the specific applications installed on the application server s local library and

The local library data includes information e.g. application identifiers identifying the applications installed on the application server. Optionally local library data includes additional information such as distribution date information or version information for the listed applications. The information in the local library data for a respective application server is received from that application server and may be stored at the application server either as a distinct data structure or together with the local application library itself or in combination with other information retained by the application server.

The resource data may include information on the CPU load of the application server e.g. statistics such as average mean minimum maximum standard deviation etc. over a predefined period of time memory load of the application server e.g. statistics of volatile memory usage over a redefined period from which the application master can determine the amount of memory used and available on the application server and server storage data e.g. non volatile storage available storage used etc. from which the application master can determine the amount of non volatile storage available on the application server. It is noted that the fields of the data structure described above are examples of information stored by the application master. In other embodiments the application master may store a subset of these fields and may optionally store additional information about the application servers in the application execution system . Furthermore the information represented here as being stored in data structure may be organized in other ways for example divided over multiple data structures in other embodiments of the invention.

The data structure stores a respective record for each application to which the front end may need to route application execution requests. This record may be called an application distribution map. In some embodiments the record for a respective application includes the following information an identifier of the application and distribution data for the application. The distribution data includes a list of identifiers or other information identifying the application servers that have a copy of the application in their local libraries. Optionally the distribution data includes resource information associated with respective application at each of the identified application servers such as one or more of CPU load information memory load information and the number of loaded instances of the application at the respective application server the loading of application instances in volatile memory is described in more detail below . It is noted that the fields of the data structure described above are examples of information stored by the application master. In other embodiments the application master may store a subset of these fields and may optionally store additional information about the distribution of applications in the application execution system . Furthermore the information represented here as being stored in data structure may be organized in other ways for example divided over multiple data structures in other embodiments of the invention. Two examples of additional information that may optionally be included in the resource data or for a particular application server are the number of application execution requests that have been sent to the application server over a defined period of time e.g. an hour and or the number of outstanding or queued requests that are pending at the application server. The resource data or stored by the front end for a respective application server may comprise averages or running averages of resource usage by the applications being executed by the respective application server.

The front end server receives the application distribution map from the application master . As noted above the application distribution map optionally includes resource usage information that can be used to route requests received from client s . For example upon receiving a request from a client to execute a specified application the front end server accesses the corresponding record of application distribution map for the specified application to determine the application servers that have copies of the application. In some embodiments the front end server routes such requests using a round robin methodology e.g. in round robin order within the list of application servers in the record for the application or a random assignment methodology e.g. randomly or pseudo randomly among the application servers listed in record .

In some other embodiments the front end server routes requests based on current and historical load information that the front end server has observed directly. Two load metrics that the front end server can observe directly are the number of application execution requests that the front end server has recently sent to each application server and the number of currently outstanding application execution requests at each application server e.g. the number of recent application execution requests sent to each application server which have yet to return results or a signal of completion . It is noted that the number of pending application execution requests also called currently outstanding application execution requests is a latency metric and thus measures performance from the perspective of the system s users. Using this information which may be observed and stored by the front end server the front end server may route application requests. For example the front end server may route a request to the application server that A has a copy of the requested application and B the least number of outstanding requests. In another example the front end server may route a request to the application server that A has a copy of the requested application and B the least number of outstanding requests for the requested application.

Alternately the front end server accesses resource information associated with the application servers that have copies of the application and uses that information to route the request. For example the front end server may select an application server have the lowest load e.g. CPU load memory load or a predefined combination thereof or a load below a predefined threshold. Alternately the front end server may take into account the number of instances of the application already loaded in the volatile memory of each of the listed application servers and may favor sending the request to an application server having one or more loaded instances of the application so long as predefined the server also meets predefined load criteria e.g. a load level below a threshold a load lower than other application servers having one or more loaded instances of the application or the like .

an operating system that includes procedures for handling various basic system services and for performing hardware dependent tasks 

a network communication module that is used for connecting the application master to other computers via the one or more communication network interfaces wired or wireless and one or more communication networks such as the Internet other wide area networks local area networks metropolitan area networks and the like 

an application distribution removal module that is used for distributing applications from the main library to the application servers for storage in non volatile storage of the application servers the application distribution removal module also includes instructions for removing previously distributed applications from the non volatile storage of respective application servers in accordance with usage information as discussed above with reference to 

a usage information module that includes procedures for monitoring the application servers to generate usage information 

data which includes the main library data application specific data application server data and the application distribution map .

The procedures in the usage information module include an Application Resource Information Module to retrieve application resource information e.g. application specific data stored in data structure and a server resource information module to retrieve resource information concerning the application servers e.g. application server data stored in data structure . In some embodiments the usage information module also includes one or more procedures Analysis Module for analyzing the retrieved application resource and server resource information to generate usage statistics.

Each of the above identified elements may be stored in one or more of the previously mentioned memory devices and corresponds to a set of instructions for performing a function described above. The above identified modules or programs i.e. sets of instructions need not be implemented as separate software programs procedures or modules and thus various subsets of these modules may be combined or otherwise re arranged in various embodiments. In some embodiments memory may store a subset of the modules and data structures identified above. Furthermore memory may store additional modules and data structures not described above.

an operating system that includes procedures for handling various basic system services and for performing hardware dependent tasks 

a network communication module that is used for connecting the front end to other computers via the one or more communication network interfaces wired or wireless and one or more communication networks such as the Internet other wide area networks local area networks metropolitan area networks and the like 

response and request modules for handling incoming client requests for applications. In some embodiments the response and request modules include procedures for receiving incoming requests Incoming HTTP Request and for forwarding the HTTP Request to application servers that host the requested application Forward HTTP Request . The response and request modules may also include procedures for serving responses from the application servers to the clients Server HTTP Response .

data which includes user data and the application distribution map . In some embodiments the user data include client specific information passed to the front end by the client e.g. parameters embedded in the HTTP request . The application distribution map includes information used by the front end to route application processing requests to application servers. This is described in more detail above with reference to .

Each of the above identified elements may be stored in one or more of the previously mentioned memory devices and corresponds to a set of instructions for performing a function described above. The above identified modules or programs i.e. sets of instructions need not be implemented as separate software programs procedures or modules and thus various subsets of these modules may be combined or otherwise re arranged in various embodiments. In some embodiments memory may store a subset of the modules and data structures identified above. Furthermore memory may store additional modules and data structures not described above.

an operating system that includes procedures for handling various basic system services and for performing hardware dependent tasks 

a network communication module that is used for connecting the application server to other computers via the one or more communication network interfaces wired or wireless and one or more communication networks such as the Internet other wide area networks local area networks metropolitan area networks and the like 

an application server module that is used for processing application requests. In some embodiments the application server module includes an application master interface module for interfacing with the application master a front end interface module for interfacing with the front end a data store interface module for interfacing with the data store a live process cache monitor and control for managing application instances in the live process cache . The application server module may also store a security module for executing untrusted processes Run Untrusted Process Module and trusted processes Run Trusted Process Module . Some of the procedures included in the application server module are further described below.

a local application library for storing the applications distributed to the application server by the application master 

application instances in volatile memory e.g. in a live process cache for servicing application requests. In some embodiments there is at least one application instance for an application in volatile memory.

data which includes local application library data described above with reference to server resource data described above with reference to and application resource data described above with reference to . When needed data includes user data which may include data received from a requesting user e.g. user name passwords user preferences profiling information and or data produced or retrieved for the requesting user by the application server. In addition data may include live process cache data described above with reference to .

In some embodiments both application resource data and server resource data are sent by the application server to the application master which allows the application master to monitor the application servers and generate usage statistics e.g. see .

In some embodiments the application master interface module includes procedures for adding or removing applications from the non volatile storage of the application server Install Remove Applications . The application master interface module may also include procedures for sending usage information on application resources Return Application Resource Information Module and server resources Return Application Server Resource Information Module to the application master. In some embodiments the front end interface module includes procedures for handling application requests Handle HTTP Request Module forwarded from the front end .

In some embodiments the application server module also includes procedures Live Process Cache Monitor Control for monitoring and controlling the live process cache. These procedures include procedures Load and Remove Application Instance Module for loading and removing application instances into the live process cache in accordance with application usage and available volatile memory. There are also procedures Execute Application Instance Module for executing application instances when processing application requests.

The Execute Application Instance Module may also include procedures Resource Limit Enforcement for limiting resource consumption of a particular application. For example an application that consumes more resources than a limit or threshold will be terminated Terminate App Instance . The resource limit may be a predefined amount or the threshold may vary depending on factors such as the number of requests for the application. For example applications that receive higher numbers of requests may have a higher threshold before the application instance is terminated. Alternatively the threshold may also depend on the amount of processing resources e.g. one or more of CPU time wall clock time i.e. total elapsed real time memory communication bandwidth and number of system function calls made consumed by the application. The threshold s may be applied per execution of an application or to a running average of resources used over multiple executions of the application. An application instance that consumes resources above a corresponding threshold may be terminated.

The live process cache monitor control module may also include procedures for monitoring the status of application instances Monitor Application Instance Status Module . For example the status of the application instances may be busy available or any transitional state in between see .

Each of the above identified elements in may be stored in one or more of the previously mentioned memory devices and corresponds to a set of instructions for performing a function described above. The above identified modules or programs i.e. sets of instructions need not be implemented as separate software programs procedures or modules and thus various subsets of these modules may be combined or otherwise re arranged in various embodiments. In some embodiments memory may store a subset of the modules and data structures identified above. Furthermore memory may store additional modules and data structures not described above.

Although show an application master a front end server and an application server these figures are intended more as functional descriptions of the various features which may be present in a set of servers than as a structural schematic of the embodiments described herein. In practice and as recognized by those of ordinary skill in the art items shown separately could be combined and some items could be separated. For example some items shown separately in could be implemented on single servers and single items could be implemented by one or more servers. The actual number of servers used to implement each such subsystem and how features are allocated among them will vary from one implementation to another and may depend in part on the amount of data traffic that the system must handle during peak usage periods as well as during average usage periods.

The foregoing description for purpose of explanation has been described with reference to specific embodiments. However the illustrative discussions above are not intended to be exhaustive or to limit the invention to the precise forms disclosed. Many modifications and variations are possible in view of the above teachings. The embodiments were chosen and described in order to best explain the principles of the invention and its practical applications to thereby enable others skilled in the art to best utilize the invention and various embodiments with various modifications as are suited to the particular use contemplated.

