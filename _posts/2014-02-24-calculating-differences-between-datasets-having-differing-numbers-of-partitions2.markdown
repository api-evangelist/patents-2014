---

title: Calculating differences between datasets having differing numbers of partitions
abstract: Two massive databases, having differing numbers of partitions within a MapReduce process, may be compared within a map-stage of the MapReduce process without the need for a reduce stage of the MapReduce process. Custom input functions may be used to coordinate the reading of data from the partitions. By taking advantage of the fact that the database are divided and sorted in a consistent manner, the input functions may coordinate the matching of records from the two databases for use within a MapReduce process. By taking advantage of the consistent grouping and sorting of the data within the partitions, the map stage of the MapReduce process may generate includes the desired final data (e.g., the differences between the two databases) without the need to transfer partitioned intermediate results between the map stage and a reduce stage of the MapReduce process.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09563697&OS=09563697&RS=09563697
owner: Amazon Technologies, Inc.
number: 09563697
owner_city: Reno
owner_country: US
publication_date: 20140224
---
Many companies and other organizations operate computer networks that interconnect numerous computing systems to support their operations such as with the computing systems being co located or instead located in multiple distinct geographical locations e.g. connected via one or more private or public intermediate networks . For example data centers housing significant numbers of interconnected computing systems have become commonplace such as private data centers that are operated by and on behalf of a single organization and public data centers that are operated by entities as businesses to provide computing resources to customers. Some public data center operators provide network access power and secure installation facilities for hardware owned by various customers while other public data center operators provide full service facilities that also include hardware resources made available for use by their customers. As the scale and scope of typical data centers has increased the tasks of provisioning administering and managing the physical computing resources have become increasingly complicated.

Examples of such large scale systems include online merchants internet service providers online businesses such as photo processing services corporate networks cloud computing services web based hosting services etc. These entities may maintain computing resources in the form of large numbers of computing devices e.g. thousands of hosts which are hosted in geographically separate locations and which are configured to process large quantities e.g. millions of transactions daily or even hourly. Such large scale systems may collect vast amounts of data that require processing.

One conventional approach to process data is the MapReduce model for distributed parallel computing. In a MapReduce system a large set of data may be split into smaller chunks and the smaller chunks may be distributed to multiple compute nodes for an initial map stage of processing. Multiple nodes may also carry out a second reduce stage of processing based on the results of the map stage. The results from the map stage may be shuffled to other nodes to use as input for the reduce stage. In other words the intermediate results may be reorganized and grouped differently for the reduce stage and may be transferred across a network to the reduce nodes. The use of network resources in this manner may be expensive and the shuffle operation may be time consuming.

Within a MapReduce implementation most computations involve applying a user specified map operation to each logical record in the input in order to compute a set of intermediate key value pairs and then applying a user specified reduce operation to all the values that shared the same key. Thus the MapReduce computation takes a set of input key value pairs and produces a set of output key value pairs. The user of the MapReduce library expresses the computation as two functions a map function and reduce function. The user written map function receives a pair of input key values pairs and produces a set of intermediate key value pairs. The reduce function also written by the user receives and merges together the intermediate values

Although Java code is commonly used with MapReduce virtually any programming language may be used to implement the map and reduce functions.

While embodiments are described herein by way of example for several embodiments and illustrative drawings those skilled in the art will recognize that embodiments are not limited to the embodiments or drawings described. It should be understood that the drawings and detailed description thereto are not intended to limit embodiments to the particular form disclosed but on the contrary the intention is to cover all modifications equivalents and alternatives falling within the spirit and scope as defined by the appended examples. The headings used herein are for organizational purposes only and are not meant to be used to limit the scope of the description or the examples. As used throughout this application the word may is used in a permissive sense i.e. meaning having the potential to rather than the mandatory sense i.e. meaning must . Similarly the words include including and includes mean including but not limited to. 

Various embodiments of methods and systems for performing MapReduce comparison of massive databases having differing numbers of partitions are described. A MapReduce process may be used to determine differences between two databases even when those database are split into differing numbers of partitions without the need for a reduce stage of the overall MapReduce process. According to some embodiments custom input functions may be used to coordinate the reading of data from the various partitions. By taking advantage of the fact that the databases are divided and sorted in a consistent manner the input functions may coordinate the matching of records from the two databases for use within the MapReduce process. Furthermore by taking advantage of the consistent grouping and sorting of the partitions the use of network resources may be minimized or eliminated altogether since in some embodiments the output from the map stage of the MapReduce process includes the desired results data e.g. differences between the two database thereby obviating the need to transfer partitioned intermediate results between the map stage and the reduce stage.

A typical MapReduce program includes a map function or method or procedure that may perform various forms of processing such as filtering or sorting and a reduce function that may perform secondary operations such as summations aggregations etc. . A system utilizing a MapReduce process such as a MapReduce infrastructure or framework may utilize multiple servers hosts and or worker nodes executing the various tasks in parallel.

During the map stage of a MapReduce process a master node may divide the input data into data subsets and distribute them to individual worker nodes. In some embodiments a worker node may also sub divide the data and utilize additional worker nodes thus creating a multi level processing structure. The worker nodes process the data subsets and pass the resulting output data to the master node or the previous worker node .

Thus a MapReduce process may allow for distributed processing of the map and reduce operations. Provided that each map operation is independent of the others all map functions can be executed in parallel. Similarly the reduce stage may also be performed in parallel.

When using a MapReduce process to calculate differences between two datasets a map stage within the overall MapReduce program may compare an earlier dataset with a later dataset. In some embodiments the datasets may represent two versions of the same data. For instance the later dataset may include additions deletions and changes to the data as compared to the earlier dataset. Each dataset may include sets of records and each record may include a key value pair. Furthermore each dataset may be sorted by the keys in the same way. In other words both datasets are sorted in the same manner using the same keys. The two datasets may each be split into multiple partitions such as to enable parallel processing by multiple computers e.g. worker nodes . For example the input datasets may be split into logical partitions sometimes called input splits based on the total size e.g. in terms of bytes of the input files. However in many embodiments record boundaries may be respected and used to determine the actual division between two partitions or splits.

In some embodiments such a comparison may be performed within the map stage of a MapReduce process without the need for any reduce stage. For instance comparing two massive databases e.g. datasets may be performed within the map stage of a map side join within a MapReduce process according to some embodiments. By imposing partitioning and sorting restrictions on the input datasets as will be discussed in more detail below corresponding partitions from each dataset may be compared by iterating through them simultaneously and presenting the map tasks of the MapReduce process with pairs of records e.g. one from each dataset . The map tasks of the MapReduce process then generate the output data representing the differences between the two databases. After the differences between the two databases have been determined e.g. as the output of the map stage a reduce stage may be used to apply additional summary aggregation or other analysis to the difference data obtained during the map stage in some embodiments.

Comparing two massive databases as described herein may take advantage of certain properties of the MapReduce process. For example the partitioning scheme such as a hash function of the MapReduce process may be consistent across runs. Thus the partitions from a previous run e.g. a previous version of the database may be utilized in a subsequent run without repartitioning the previous version of the database . Additionally the output from the MapReduce process may generally be sorted internally in a consistent manner and such sorting may be used to aid in determining differences e.g. added or deleted records between the two databases as described herein.

Using the distributed computation system a set of before partitions such as before partitions A C may be compared to a set of after partitions such as after Partitions A F by the worker nodes to produce a set of difference data . For example in one embodiment before partitions may represent multiple partitions of before dataset and after partitions may represent multiple partitions of after dataset . Before dataset and after dataset may represent two different databases or may represent two different versions of the same database according to different embodiments. For instance in one embodiment before dataset and after dataset may represent two different versions of a database that is updated daily and the two versions are being compared to determine any differences that may have occurred between two different days.

Before dataset may be split into one or more of partitions such as before partitions A B and C. Similarly after dataset may be split into one or more partitions such as after partitions A B C D E and F. As shown in the two databases may be split into differing numbers of partitions. For example the database may have grown too large to be processed efficiently with the same number of partitions used previously according to some embodiments. Thus one database may be split into a greater number of partitions than the other. In some embodiments one of the databases may be split into a number of partitions that is an even multiple of the other. In other words as shown in according to one embodiment after dataset may be split into twice the number of partitions as before dataset . In other embodiments however other multiple or even uneven multiples may be used.

Also while described herein mainly in regard to a later version of a database being split into more partitions than a previous version of the database is some embodiments a later version of a database may be split into fewer e.g. half as many partition than a previous version e.g. when the database is shrinking rather than growing over time . In other embodiments the two databases being compared may not be different versions of the same database but instead may be any two databases with comparable data.

While described herein mainly in terms of comparing an earlier and a later dataset in general the techniques described herein may be applied to virtually any sort of MapReduce based processing of any two dataset that include the same keyspace and that are sorted and partitioned in the same manner according to various embodiments. Additionally virtually any sort of data may be used for the keys and or values described herein. For example in some embodiments the keys may be numeric e.g. IDs hash values etc. while in other embodiments the keys may be textual or string data. Similarly the values associated with the keys may be numeric textual or a combination of each. Furthermore in some embodiments the keys and or values may be data structures including multiple fields of differing data types.

The datasets may be split into partitions on any suitable basis. For example partition boundaries may be based on the boundaries between individual records individual lines of data etc. An individual partition may include elements of input data such as related items or families of items intended to be processed together by a single worker node. Although a particular number of partitions are illustrated in for purposes of example it is contemplated that any suitable number of partitions of input data may be processed using the distributed computation system .

In general one or more of the before partitions and two or more of the after partitions may be assigned to each of the worker nodes . The worker node may then compare the partitions to determine differences between the two databases. Thus a worker node may be assigned before partitions and after partitions that correspond to each other. For example a single before partition may include records for a certain set of keys and two after partitions may also include records for the same or at least similar set of keys. Thus the set of keys in one before partition may overlap the keys in two or more after partitions according to some embodiments. In other words any after partition that includes a key that is also in a particular before partition will only include keys that are also in that particular before partition or keys that were added to the dataset which would have been hashed to that before partition had they existed in the before dataset . A worker node may be assigned a single partition from the dataset that was split into fewer partitions as well as multiple partitions from the dataset that was split into a greater number of partitions.

The assignment of individual partitions to individual worker nodes as shown in is presented for purposes of example and illustration it is contemplated that any suitable assignment of individual partitions to individual worker nodes may be used with the distributed computation system .

In one embodiment the master node s may provide individual partition s to individual worker nodes e.g. by performing aspects of the partitioning of the datasets and or aspects of the assignment of individual partitions to individual worker nodes. In one embodiment the master node s may send data indicative of partition assignments to individual worker nodes and each worker node may acquire its partitions using any suitable technique. For example a worker node may read a portion of the data from one or more files or storage locations in one or more storage devices that are accessible to the worker nodes e.g. over a network. Alternatively the master node s may directly send the relevant partition s to individual worker nodes using a network. In various embodiments the partition s to be processed using a particular worker node may be loaded into memory at the particular worker node either partially or entirely before the processing of the partition s is initiated.

Each of the worker nodes may perform any suitable processing tasks to generate the difference data . As shown in the worker nodes may implement a map stage of an overall MapReduce process to compare the partitions and generate difference data indicating any differences between the partitions. In one embodiment the processing tasks implemented using the worker nodes may be provided by the master node s e.g. by sending program code to the worker nodes or instructing the worker nodes to load the program code from one or more storage locations. At least a portion of the processing tasks performed by the worker nodes may be performed concurrently i.e. in parallel relative to each other. In some embodiments each of the worker nodes may perform similar tasks and or implement similar algorithms to process its partition s of the input data. As a result of the processing of the partitions each of the worker nodes may produce difference data . As they are produced by the worker nodes the difference data may be stored in one or more storage locations on one or more storage devices that are accessible to the worker nodes. The difference data may also be referred to as final output data. In one embodiment the difference data may be further processed

As will be described in greater detail below the distributed computation system may implement a MapReduce system in which the use of network resources is minimized during the processing of the worker nodes . The computation performed by each of the worker nodes may include multiple stages of computation such as a map stage and a reduce stage .

In one embodiment the map stage may include any computation s to generate intermediate output such as difference data based on the input partitions. Contrary to conventional MapReduce implementations the intermediate output may represent the final desired output e.g. the difference data without the need for a reduce stage . Accordingly the distributed computation system may avoid the time and expense of re partitioning and network data transfer associated with a conventional shuffle from the map stage to the reduce stage.

It is contemplated that the distributed computation system may include additional components not shown fewer components than shown or different combinations configurations or quantities of the components shown. It is contemplated that any suitable number of worker nodes may be used in conjunction with the distributed computation system . Although one master node is illustrated for purposes of example it is contemplated that any suitable number of master nodes may be used in conjunction with the distributed computation system . In some embodiments any of the worker node s and or master node s may be implemented as virtual compute instances or as physical compute instances. One or more virtual compute instances may be implemented by the example computing device illustrated in . The distributed computation system may include one or more computing devices any of which may also be implemented by the example computing device illustrated in . In various embodiments the functionality of the different components of the distributed computation system may be provided by the same computing device or by different computing devices. If any of the various components are implemented using different computing devices then the respective computing devices may be communicatively coupled e.g. via one or more networks. Each component of the distributed computation system may represent any combination of software and hardware usable to perform their respective functions as discussed as follows.

In one embodiment the distributed computation system may manage the allocation of network accessible resources. Networks set up by an entity such as a company or a public sector organization to provide one or more services such as various types of cloud based computing or storage accessible via the Internet and or other networks to a distributed set of clients may be termed provider networks. A provider network may include numerous data centers hosting various resource pools such as collections of physical and or virtualized computer servers storage devices networking equipment and the like that are used to implement and distribute the infrastructure and services offered by the provider. The resources may in some embodiments be offered to clients in units called instances such as virtual or physical compute instances or storage instances. A virtual compute instance may for example comprise one or more servers with a specified computational capacity which may be specified by indicating the type and number of CPUs the main memory size and so on and a specified software stack e.g. a particular version of an operating system which may in turn run on top of a hypervisor . A number of different types of computing devices may be used singly or in combination to implement the resources of the provider network in different embodiments including general purpose or special purpose computer servers storage devices network devices and the like.

In one embodiment operators of provider networks may implement a flexible set of resource reservation control and access interfaces for their clients. For example a provider network may implement a programmatic resource reservation interface e.g. via a web site or a set of web pages that allows clients to learn about select purchase access to and or reserve resource instances. In one embodiment resources may be reserved on behalf of clients using a client accessible service that implements the distributed computation system . According to one such embodiment the distributed computation system in such an environment may receive a specification of one or more tasks to be performed for a client along with a set of input data or an indication of a source of input data to be used by the task s . In response the distributed computation system may determine an execution plan for implementing the task s using one or more resources of a selected resource pool of the provider network. In one embodiment the resource pool may be automatically selected based on the anticipated computational needs of the various tasks. In one embodiment the resource pool may be selected based on a specific resource request or reservation submitted by the client. The distributed computation system may schedule an execution of the task s using the selected resources.

In one embodiment the client may use one or more suitable interfaces such as one or more web pages an application programming interface API or a command line interface CLI to specify the task s to be implemented the input data set the computing resources to be used and or a time at which the task s should be initiated. In one embodiment the client may be able to view the current execution status of the task s using the interface s . In one embodiment additional information about executed tasks may be available via the interface s such as program output error logs exception logs and so on.

As shown in block a current dataset may be divided into a plurality of current partitions. For example after dataset may be divided e.g. split into a plurality of partitions or splits such as before partitions A B and C. In some embodiments master node may be configured to split the datasets into multiple partitions and may utilize a splitter function to perform the division of the datasets into partitions.

A previous partition of a previous dataset and two or more corresponding current partitions may be provided to a worker node for processing as shown in block . For example in one embodiment before partition A and after partitions A and B may be provided to worker node for processing. According to one embodiment one of the datasets e.g. the current dataset may be divided into more partitions e.g. twice three times four times as many etc. as the other database e.g. the previous database . For instance both datasets may represent different versions of the same database and the database may have grown in size between the two versions and therefore the current version may be divided into more partitions such as to achieve improved efficiency within the distributed MapReduce computation system.

It should be noted however that either of the two datasets may be the larger of the two and may therefore be divided into the larger number of partitions. For example the database may have shrunk in size between the two versions and the later or current dataset may be divided into a smaller number e.g. one half one third etc. of partitions as compared to the earlier or previous dataset.

In general within a distributed MapReduce computation system any sort of processing may be performed on records of the two datasets. For example one or more worker nodes s may be configured to perform a comparison of the two datasets may distributing the partitions of the datasets to individual ones of the work nodes and having each worker node compare records from the different partitions to determine any differences between the two datasets.

As shown in block and an input function of the distributed MapReduce computation system may iterate through records of the previous partition and of the corresponding current partitions. According to one embodiment the input function may open and read files containing the records of the partitions and may iterate through the records determining which records from the multiple current partitions. For instance the dataset may be partitioned according to partitioning schemes which ensure that the record within the partitions are grouped and or sorted consistently according to some embodiments. Thus the input function may be configured to determine according to the partitioning scheme and or based upon the sort order which current partition includes a record corresponding to a record included in one of the previous partitions.

Records from the two datasets may correspond according to different manners or mechanisms in different embodiments. For example in one embodiment each record may include and may be sorted by a key and two records having the same key may correspond. Additionally the records may be sorted by a key and the input function may be configured to utilize the key to determine not only which current partition should contain a record corresponding to a record in a previous partition but also whether any records were added or deleted between the two datasets.

The input function may at each iteration of the records i.e. at each current record provide information regarding a record of the previous partition and information regarding a matching record of one of the corresponding current partitions to the map function of the distributed MapReduce computation system as shown in block . For example each record may include a key and a value pair and the input function may provide the key and the two values e.g. one from each dataset to the map function for processing e.g. comparison . The exact manner and format of how the input function may provide the information regarding the records may vary from embodiment to embodiment and in general any suitable method and or format may be used to convey whatever information regarding the records is required by the map function.

Subsequently the map function of the distributed MapReduce computation system may perform a computation on the information regarding the records as shown in blocks and . For instance in one embodiment the map function may compare the information regarding the records to determine if any difference exists between the two records and may generate difference data such as difference data indicating or describing any determined difference. In other embodiments the map function may perform different or other processing or computations on the information regarding the records.

As shown in master node may split one of the datasets e.g. after dataset into a greater number of partitions than the other dataset. For example after dataset may be split into six partitions while before dataset may be split into three partitions. Datasets may be split into different numbers of partitions for any of various reasons such as to achieve greater efficiency after the dataset has grown over time. Worker nodes such as worker nodes A B and C may be assigned to process e.g. compare the data in the partitions. Since one dataset may be split into a greater number of partitions than the other each worker node may receive one partitions from one dataset and two or more partitions from the other dataset. For example as shown in after dataset may be split into six partitions while before dataset may be split into three partitions. Thus worker node A may be assigned one partition from before dataset e.g. before partitions A and two partitions from after dataset e.g. after partitions A and B .

A system to compare two databases using a MapReduce based process may take advantage of certain features of the MapReduce process. For example in some embodiments the partitioning of the datasets may be consistent across different runs of the system and therefore the system may be able to use partitions that were actually created during a previous run of the system. For instance in one embodiment before dataset may have been divided into before partitions during a previous execution such as when before dataset was compared to another previous version of the database not shown in . Additionally consistent partitioning schemes may be utilized to ensure that partitions boundaries match between the partitioning of before dataset and after dataset . For example a similar hashing function may be used to partition both datasets but may be used to create differing numbers of partitions. Thus records included in a single before partition may be included in multiple after partitions according to some embodiments. In other words the set of keys for records in the before partition may overlap the set of keys for records in multiple after partitions. While every key in the before partition may not be present in the after partitions if a key is present in the after dataset it will be present in one of the partitions corresponding to the before partition e.g. as defined deterministically by the partitioning scheme .

Partitioning schemes e.g. hashing functions may be selected to ensure that no partition in after dataset includes records with keys that are included in multiple before partitions according to one embodiment. In other words partitioning schemes may be selected that ensure that multiple partitions of the dataset with the greater number of partitions always align e.g. according to the partitioning scheme a single partition of the dataset with fewer partitions. As noted previously a master node may include a split or splitter function configured to determine how to divide the datasets into partitions. In some embodiments the splitter function may be configured to split a dataset into one or more partitions each of which may include multiple records for a set of keys according to a particular partitioning scheme e.g. a hash function . The same or different splitter functions utilizing the same similar or different partitioning schemes may be used to divide different datasets according to different embodiments. For example in one embodiment one splitter function may be used to divide before dataset while another may be used to divide after dataset . While generally described herein as a separate function or module in some embodiments a splitter function may be part of or utilized by an input function or module or class as will be described in more detail below.

In some embodiments two datasets may be compared when the datasets are split into different numbers of partitions. For instance if a comparison is made between a current version of a database and a previous version of the database the database may have grown in size so that additional partitions are needed for performance and or memory reasons. For example either additional records may have been added to the database or the data in existing records may have grown in size. Similarly in some embodiments the current dataset may be smaller than the previous dataset and therefore the later dataset may be split into a smaller number of partitions.

In some embodiments both the previous and current datasets may be split into partitions when performing the comparison and therefore a larger number of partitions may be generated for both dataset. However in some embodiments the partitions used previously e.g. the last time a comparison was performed for the later dataset may be reused and compared to the partitions of the current dataset even though the current dataset may be split into a larger number of partitions than the other dataset .

Thus when performing a comparison using the MapReduce methodology the two datasets may be split into partitions but the one dataset may be split into fewer partitions than the other dataset. In some embodiments whenever a dataset needs to be split into a different number of partitions than previously the MapReduce process may be configured to split the larger dataset into a number of partitions that is a multiple of e.g. two three four times the number of partitions of the smaller dataset.

For example is a block diagram that illustrates a logical view of the partitioning of two datasets into differing number of partitions in a consistent and deterministic manner. For instance in some embodiments the MapReduce process may be configured to utilize a hash function e.g. on the keys of a dataset to split the dataset into a number of partitions such as by hashing into a number of hash buckets equal to the number of final partitions. As shown in before dataset may be split using a hash function using 8 buckets e.g. buckets 0 7 . As illustrated by key hashes of before dataset . While shown in using an interleaved arrangement of buckets other embodiments may use different patters or arrangements of hash buckets.

After dataset may be divided into partitions according to the same or a similar hash function but using a different number of buckets. Thus as shown in key hashes of after dataset may be hashed using 16 buckets only 10 of which are shown e.g. buckets 0 10 . As is apparent in each of the buckets of before dataset corresponds to two buckets of after dataset . For example bucket 0 of before dataset corresponds to bucket 0 and bucket 8 of after dataset . It should be noted that the numbering and arrangement of buckets in is merely one example and that other embodiments may utilize different numbers arrangements and or correspondence of buckets between two datasets.

According to the partitioning schemes illustrated in if a key of before dataset is partitioned e.g. hashed into bucket 0 the corresponding key will be partitioned e.g. hashed into either bucket 0 or bucket 1 of after dataset . In some embodiments the correspondence between buckets may be deterministic according to the partitioning scheme e.g. hash function used. Thus by using a consistent partitioning scheme such as a hash function to partition both datasets the MapReduce process may be configured to easily determine which partitions e.g. buckets in one dataset correspond to partitions of the other dataset. In other embodiments other manners of determining the correspondence between partitions e.g. other than deterministically based on the partitioning scheme may be utilized. In general any method of determining which partitions of one dataset correspond to partitions in another dataset may be used with the methods and features described herein.

As noted above in some embodiments the MapReduce process may split one dataset into a number of partitions that is a multiple of e.g. two three four times the number of partitions of the other dataset. In other embodiments however the number of partitions in one database may not be an even multiple of the other. In some embodiments the two datasets may each be split into an arbitrary number of partitions.

Thus individual worker nodes may be assigned multiple partitions for comparison. As shown in worker node A may be assigned to compare before partition A to after partitions A and B while worker node B may be assigned to compare before partition B to after partitions C and D. Similarly worker node C may be assigned to compare before partition C to after partitions E and F. The particular arrangement of partitions assignments illustrated in is for example and ease of explanation only. In other embodiments other and differing partition assignments may be used. For example in one embodiment a worker node may be assigned multiple before partitions for comparison to corresponding after partitions. Thus a single worker node may be assigned to compare before partitions A and B to after partitions A B C and D according to one embodiment.

Input function may match up records from the before partition and after partitions based on the keys and the particular order used to the sort the records within the partition. For example each record may include a key and value as shown in and input function may read a record from before partition A that includes key and may read a record from after partition A that also include key . Thus key and value from before partition A may represent a key value pair and key and value A from after partition A may represent another key value pair. Input function may then build input data to include the key and values or the key value pairs from the two records and pass input data to map function for processing or other computation e.g. comparison .

When reading records from the partitions input function may have to keep track of the current key and or current records from each partition and utilize the consistent nature of the partitioning and the sorting within the partitions e.g. according to the keys to match up corresponding records from the different partitions. When comparing two databases using a MapReduce process the sorting order of records within partitions may be used to aid in the determination of differences between the databases. If two partitions include similar records sorted according to the same key data iterating through those records in both partitions may allow the comparison code to determine when a record has been deleted or added to the database.

When comparing two versions of a database looking for differences between the two versions iterating through the records in sorted order may reveal that a record has been deleted between the two versions of the database. When iterating through the records if the current record for a previous version of the database occurs before according to the sort order the current record in the later version of the database it may be determined that a record was deleted according to some embodiments. Similarly if the current record for a previous version of the database occurs after according to the sort order the current record in the later version of the database it may be determined that a record was added in some embodiments. If the two current records are equal according to the sort order then the details of the records may be compared to determine if any difference exists between them.

For example in one embodiment input function may open three files each containing one of the partitions illustrated in and may iterate e.g. step through the records of the partitions in parallel using the key order to only advance the iteration in one of the after partitions e.g. the after partition with the record that matches the record from the before partition . For example input function may read the first record from before partition A e.g. key value read the first record from after partition A and read the first record from after partition B. Input function may then determine that the record from after partition A precedes in terms of the sort order the record from after partition B. Input function may then use the record from after partition A to compare with the record from before partition A advance the iteration in both before partition A and after partition A but without advancing the iteration in partition B. Input function may then proceed to iterate through the records of before partition A and after partition A until all the records of after partition A have been used after which input function may begin to use record from after partition B.

At each iteration input function may build an input data including the values from the corresponding records and pass input data to map function for comparison. For example if a record for the key exists in both datasets such as in before partition A and in after partition A input function may include the value for the key from each partition in input data . For instance at the first iteration of the example data illustrated in input function may include key as well as value and value A in input data according to one embodiment. If however one of the datasets does not include a record for a particular key included in the other dataset e.g. an addition or deletion occurred then input function may include they key an a value for the key from one partition in input data but may also include a special indicator that the other partition does not include a record corresponding to the key. For example when processing key input function may include key and value from before partition A in input data but may include a special value indicating that no after partition includes a record with key .

Map function may compare the information regarding the two records to determine if any difference exists between the two records and may output information e.g. a record to difference data indicating any determined difference.

The map function may then compare the two values for the key to determine any differences between the values for that key between the two datasets. For example as shown in decision block if there is a value associated with the key in the earlier dataset but there is not a value associated with the key in the later dataset the map function may determine that the record s related to that key was deleted from the data between the earlier and later datasets as shown in block .

Similarly if there is not a value associated with the key in the earlier dataset but there is a value associated with the key in the later dataset as illustrated by the positive output of decision block the map function may determine that the record s related to that key was added to the data between the earlier and later datasets as shown in block .

Furthermore if there is a value associated with the key in both datasets but the values are different between the two datasets as illustrated by the positive output of decision block the map function may determine that the record related to that key was modified between the two datasets as shown in block . Finally if there is a value associated with the key in both the earlier and later datasets and the values are the same the map function may determine that there is no difference between the records related to the key between the earlier and later datasets as shown by block . In some embodiments the map function may include information in the generated difference data indicating that no differences were determined between the two datasets for particular records or keys. In other embodiments however the map function may not generate any difference data regarding records or keys for which no differences were determined.

After determining that difference exists between the records associated with the current key and after determining the nature of the difference e.g. an addition a deletion or a modification the map function may generate difference data e.g. MapReduce intermediate data indicating the difference discovered between the records of the two datasets as shown in block . In some embodiments the map function may generate a new key value record including the current key and information regarding the detected difference. For instance the map function may generate difference data indicating whether the difference was an addition a deletion or a modification. Additionally the map function may generate difference data including some or all of the actual data that was changed as shown in block . In other embodiments the intermediate data generated by the map function may include some or all of the information from one or both of the values associated with the key from the two datasets. As noted above in some embodiments the map function may also include information in the generated difference data regarding records or keys for which no difference was determined.

In some embodiments the data generated by the map function may be the only output from the overall MapReduce process. In other words differences may be calculated between two datasets within a MapReduce framework using only a map stage without a subsequent reduce stage. In other embodiments however the intermediate data may be used as input to one or more reduce functions in the reduce stage of the MapReduce methodology as called by the MapReduce framework such as to apply additional processing of the generated difference data e.g. summations aggregations etc. .

Returning now to input function may represent a custom version of an input function configured to override or be used in place of a default or generic input function from the MapReduce framework used to execute the MapReduce process. Additionally while only a single input function is illustrated in in some embodiments multiple input functions may be used. For example one input function may be configured to read before partitions while another may be configured to read after partitions . Thus a different version of input function may be utilized to coordinate the reading of records from the multiple after partitions and match up records to the single before partition. As noted above a splitter function may be used to divide up datasets into partitions. In some embodiments an input function may perform the same function as a splitter function since both features require similar knowledge regarding the record layout and other data format of the input data.

In some embodiments the custom MapReduce framework may be generated to allow the input data to the input function and or the map function to be strongly typed as opposed to requiring the use of source code reflection to determine and cast the input variables. For example a generic MapReduce source code system may require a programmer to use Java reflection to determine the actual type of a variable e.g. an input to a method or function but the custom MapReduce framework may be configured to allow the programmer to use strongly typed variables.

Thus rather than determining the type of an input variable via a class parameter which may be used to instantiate the format via reflection internally as in the following code snippet 

In some embodiments the type of an input variable such as to input function may be created via real e.g. standard object instantiation as in the following source code snippet 

In some embodiments providing the ability to utilize strong typing within a MapReduce framework may allow the use of generic type arguments or value parameters which may not be usable within a generic MapReduce system requiring the use of reflection to determine types and formats.

Similarly the values supplied to the map function may also be strongly typed. For example instead of requiring the programmer to perform casting within the map function to obtain component values e.g. from the record information being processed and then refer to those components by index as in the following example code snippet 

The values supplied to the map function may be written as objects of a generic subclass and accessed within the map function using strongly typed variables as in the following example code snippet 

For ease of description the above discussion assumes that every key found in before partition A is also found in either after partition A or after partition B. However as shown in that may not be the case. For instance key is found in before partition A but is not found in either after partition. When trying to match a record from one dataset that includes a key not found in a record in the other dataset input function may construct input data in such a way as to indicate that fact to map function . For example in one embodiment input function may construct an input data that includes key and value from before partition A but that does not include a corresponding value from an after partition. Thus input data may include a before value but not an after value. Alternatively if a record of an after partition includes a key not found in the before partition input data may include an after value but not a before value.

Map function may then compare the records using the data in the input data . For example map function may be configured to determine three types of differences such as an addition different a deletion difference and a modification difference. When comparing the records shown in map function may for example determine that a deletion difference exists regarding key since key exists in before partition A but does not exists in either after partition. Map function may also determine that an addition difference exists regarding key since key exists in after partition B but does not exist in before partition A.

While illustrates three partitions namely one before partition and two after partitions the relative numbers of partitions may vary from embodiment to embodiment. For example in one embodiment a first dataset may be divided into a number of partitions and a second dataset may be divided into three times that number of partitions. In some embodiments it may be more efficient to have the relative number of partitions between the two dataset be related by an even multiple e.g. one dataset has twice three times four times etc. the number of partitions of the other dataset . It is contemplated that the techniques described herein may be used with virtually any relative number of partitions.

While illustrates a single input function responsible for reading all three or more partitions in some embodiments additional input functions may be utilized. illustrates one embodiments of a system in which worker node includes additional input functions e.g. inputFormat functions A B and C to read the partitions. According to some embodiments custom inputFormat functions may be used to describe the input specification of data being processed within the MapReduce system. Additionally a custom inputFormat function may read the records of the input file for processing by the map function. For instance an inputFormat function may be responsible for determine the record boundaries within a partition and presenting a record oriented view of the partition to map function. An inputFormat function may be implemented within a sub class of a default input function provided by a generic MapReduce implementation according to some embodiments.

In some embodiments inputFormat function A B and or C may represent a function configured to override or otherwise replace a default or generic inputFormat function of a MapReduce framework. As described above regarding worker node may be assigned three partitions before partition A after partition A and after partition B for processing e.g. comparison . Worker node may utilize input function to load individual records from the partitions for comparison. In turn input function may utilize inputFormat functions A C to read the individual partitions. Thus when iterating through the records of the partitions inputFormat function A may read before partition A while inputFormat functions B and C may read after partitions A and B respectively. In some embodiments inputFormat functions B and C may coordinate the reading of records to ensure that the corresponding records are passed to map function for comparison. In one embodiment input function may be configured to coordinate the reading of records by the individual inputFormat functions.

Similarly map function may also utilize multiple comparison functions or in general other processing functions to compare the records from the two datasets. For example in one embodiment map function may include or access custom functions written to verify and or generate output data for different types of comparisons. As noted above in some embodiments three different types of differences may be discovered between records of the two datasets addition deletion and modification differences. Thus map function may be configured to utilize additional comparison functions such as addition function deletion function and or modification function .

In some embodiments input function may call map function with the information from the two records e.g. one record from each dataset and map function may then determine the nature of any difference between the two records and call one of the other comparison functions possibly passing along the records as input . In other embodiments however worker node may include multiple specialized processing e.g. comparison functions such as addition function deletion function and or modification function instead of or in addition to map function . Thus input function may determine the nature of any possible difference between the two records and call one of the appropriate processing functions e.g. addition function deletion function and or modification function directly.

For example in one embodiment input function may be configured to determine whether for a particular key a record exists in both datasets. If a record only exists in one of the datasets for a particular key then input function may determine that the difference between the two datasets is either an addition or a deletion and therefore may call an appropriate processing function e.g. addition function or deletion function respectively . If however a record exists in both datasets input function may call modification function passing the record information as input. Modification function may then compare the two records to determine if any difference exists between them.

While illustrates addition function deletion function and modification function within map function in other embodiments worker node may include addition function deletion function and modification function instead of map function .

In some embodiments any specialized processing functions e.g. addition function deletion function and or modification function may be configured to generate and or output information regarding any determined differences as difference data . In other embodiments however specialized processing functions may return the difference information to map function and map function may then add the difference information to difference data e.g. as MapReduce intermediate data .

In at least some embodiments a computer system that implements a portion or all of one or more of the technologies described herein such as the distributed computation system may include a general purpose computer system that includes or is configured to access one or more computer readable media.

In at least some embodiments a computer system that implements a portion or all of one or more of the technologies described herein may include a general purpose computer system that includes or is configured to access one or more computer readable media. illustrates such a general purpose computing device . In the illustrated embodiment computing device includes one or more processors coupled to a system memory via an input output I O interface . Computing device further includes a network interface coupled to I O interface .

In various embodiments computing device may be a uniprocessor system including one processor or a multiprocessor system including several processors and through e.g. two four eight or another suitable number referred to collectively as processors . Processors may include any suitable processors capable of executing instructions. For example in various embodiments processors may be general purpose or embedded processors implementing any of a variety of instruction set architectures ISAs such as the x86 PowerPC SPARC or MIPS ISAs or any other suitable ISA. In multiprocessor systems each of processors may commonly but not necessarily implement the same ISA.

System memory may be configured to store program instructions and data accessible by processor s . In various embodiments system memory may be implemented using any suitable memory technology such as static random access memory SRAM synchronous dynamic RAM SDRAM nonvolatile Flash type memory or any other type of memory. In the illustrated embodiment program instructions and data implementing one or more desired functions such as those methods techniques and data described above are shown stored within system memory as code i.e. program instructions and data .

In one embodiment I O interface may be configured to coordinate I O traffic between processor system memory and any peripheral devices in the device including network interface or other peripheral interfaces. In some embodiments I O interface may perform any necessary protocol timing or other data transformations to convert data signals from one component e.g. system memory into a format suitable for use by another component e.g. processor . In some embodiments I O interface may include support for devices attached through various types of peripheral buses such as a variant of the Peripheral Component Interconnect PCI bus standard or the Universal Serial Bus USB standard for example. In some embodiments the function of I O interface may be split into two or more separate components such as a north bridge and a south bridge for example. Also in some embodiments some or all of the functionality of I O interface such as an interface to system memory may be incorporated directly into processor .

Network interface may be configured to allow data to be exchanged between computing device and other devices attached to a network or networks such as other computer systems or devices for example. In various embodiments network interface may support communication via any suitable wired or wireless general data networks such as types of Ethernet network for example. Additionally network interface may support communication via telecommunications telephony networks such as analog voice networks or digital fiber communications networks via storage area networks such as Fibre Channel SANs or via any other suitable type of network and or protocol.

In some embodiments system memory may be one embodiment of a computer readable i.e. computer accessible medium configured to store program instructions and data as described above for implementing embodiments of the corresponding methods and apparatus. However in other embodiments program instructions and or data may be received sent or stored upon different types of computer readable media. Generally speaking a computer readable medium may include non transitory storage media or memory media such as magnetic or optical media e.g. disk or DVD CD coupled to computing device via I O interface . A non transitory computer readable storage medium may also include any volatile or non volatile media such as RAM e.g. SDRAM DDR SDRAM RDRAM SRAM etc. ROM etc. that may be included in some embodiments of computing device as system memory or another type of memory.

Further a computer readable medium may include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as a network and or a wireless link such as may be implemented via network interface . Portions or all of multiple computing devices such as that illustrated in may be used to implement the described functionality in various embodiments for example software components running on a variety of different devices and servers may collaborate to provide the functionality. In some embodiments portions of the described functionality may be implemented using storage devices network devices or special purpose computer systems in addition to or instead of being implemented using general purpose computer systems. The term computing device as used herein refers to at least all these types of devices and is not limited to these types of devices.

Various embodiments may further include receiving sending or storing instructions and or data implemented in accordance with the foregoing description upon a computer readable medium. Generally speaking a computer readable medium may include storage media or memory media such as magnetic or optical media e.g. disk or DVD CD ROM volatile or non volatile media such as RAM e.g. SDRAM DDR RDRAM SRAM etc. ROM etc. In some embodiments a computer readable medium may also include transmission media or signals such as electrical electromagnetic or digital signals conveyed via a communication medium such as network and or a wireless link.

The various methods as illustrated in the Figures and described herein represent exemplary embodiments of methods. The methods may be implemented in software hardware or a combination thereof. In various of the methods the order of the steps may be changed and various elements may be added reordered combined omitted modified etc. Various of the steps may be performed automatically e.g. without being directly prompted by user input and or programmatically e.g. according to program instructions .

Various modifications and changes may be made as would be obvious to a person skilled in the art having the benefit of this disclosure. It is intended to embrace all such modifications and changes and accordingly the above description is to be regarded in an illustrative rather than a restrictive sense.

