---

title: Data processing system and data processing method
abstract: A data processing system includes multiple data processing apparatuses; a peripheral apparatus; memory that is shared by the data processing apparatuses and the peripheral apparatus; peripheral memory provided corresponding to the peripheral apparatus; and a memory managing unit that secures in any one among the memory and the peripheral memory, an area for a thread that is based on thread information, the area being secured based on the thread information that is read out from a heap area that sequentially stores the thread information that is executed at any one among the data processing apparatuses and the peripheral apparatus.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09405470&OS=09405470&RS=09405470
owner: FUJITSU LIMITED
number: 09405470
owner_city: Kawasaki
owner_country: JP
publication_date: 20140204
---
This application is a continuation application of International Application PCT JP2011 067990 filed on Aug. 5 2011 and designating the U.S. the entire contents of which are incorporated herein by reference.

The embodiment discussed herein is related to a data processing system that manages memory and a data processing method.

Conventionally the memory architecture of mobile terminals such as mobile telephones includes various types of memory such as graphics RAM used by a graphics processing unit GPU buffer memory used by a digital signal processor DSP and video RAM of a liquid crystal display LCD controller in addition to random access memory RAM which is primarily accessed by a central processing unit CPU .

As a method of accessing such types of memory for example a technique has been disclosed that performs management related to accessing memory by a thread that is run to access memory by application software hereinafter app for example refer to Japanese Laid Open Patent Publication No. 2008 108089 . A process that is executed by a CPU is managed in units of threads.

Nonetheless with the technique above when configuration is such that a thread that manages memory access can be executed by an arbitrary CPU an exclusive control process has to be added to prevent contention that occurs consequent to concurrent access. Consequently a problem of increased overhead arises.

According to an aspect of an embodiment a data processing system includes multiple data processing apparatuses a peripheral apparatus memory that is shared by the data processing apparatuses and the peripheral apparatus peripheral memory provided corresponding to the peripheral apparatus and a memory managing unit that secures in any one among the memory and the peripheral memory an area for a thread that is based on thread information the area being secured based on the thread information that is read out from a heap area that sequentially stores the thread information that is executed at any one among the data processing apparatuses and the peripheral apparatus.

The object and advantages of the invention will be realized and attained by means of the elements and combinations particularly pointed out in the claims.

It is to be understood that both the foregoing general description and the following detailed description are exemplary and explanatory and are not restrictive of the invention.

An embodiment of a data processing system and a data processing method will be described in detail with reference to the accompanying drawings. A multi core processor system having multiple CPUs will be taken as an example of the data processing system of the embodiment. A multi core processor is a processor that is equipped with multiple cores. As long as multiple cores are provided the cores may be provided as a single processor equipped with multiple cores or as a group of single core processors in parallel. For the sake of simplicity in the present embodiment description will be given taking a group of single core processors in parallel as an example.

The CPU 0 executes a high priority thread 0 and the CPU 1 executes a low priority thread 1 and a memory management thread . The CPUs 0 and 1 execute dummy device drivers 0 and 1 upon executing a memory allocation request such as a malloc function by the threads 0 and 1.

The dummy device drivers have an application programming interface API which is identical to that of general device drivers for peripheral devices. With respect to the dummy device drivers a thread can perform the same operations as with a general device driver. The dummy device drivers upon receiving a memory allocation request store the memory allocation request to which thread information is appended to a management request dispatch table that is stored in the main memory . The thread information is information that includes the thread name and the priority level of the thread.

The memory management thread sequentially reads from the management request dispatch table the memory allocation requests and according to the thread information of the memory allocation requests allocates an area of the main memory or of the GPU memory .

In the example depicted in the memory management thread first secures in the main memory an area for the thread 0 and subsequently secures in the GPU memory an area for the thread 1. In this manner the multi core processor system stores to the management request dispatch table the memory allocation requests from threads under execution at multiple CPUs sequentially reads out the memory allocation requests and allocates memory of the main memory and peripheral apparatus memory for the memory allocation requests. Thus the multi core processor system can secure memory without the occurrence of contention resulting from concurrent access. With reference to the operation depicted in and performed by the multi core processor system will be described.

The multi core processor system includes a display an interface I F and a keyboard as input output apparatuses for the user and other devices. The components are respectively connected by the bus . The main memory depicted in may be the RAM or a portion of the RAM . Further the main memory is memory shared and accessed by the CPU 0 the CPU 1 the GPU the DSP etc.

In this example the CPUs 0 and 1 govern overall control of the multi core processor system . The CPUs 0 and 1 represent all of the single core processors connected in parallel. The multi core processor system may include 3 or more CPUs. The CPUs 0 to n respectively have dedicated cache memory.

The ROM stores programs such as a boot program. The RAM is used as a work area of the CPUs 0 and 1. The flash ROM is flash ROM for which the read out speed is high and is for example NOR flash memory. The flash ROM stores system software such an operating system OS and apps. For example when an OS is updated the multi core processor system receives the new OS via the I F and updates the old OS stored in the flash ROM with the new OS.

The flash ROM controller under the control of the CPUs 0 and 1 controls the reading and writing of data with respect to the flash ROM . The flash ROM is flash ROM intended for storage and portability and is for example NAND flash memory. The flash ROM stores data written thereto under the control of the flash ROM controller . Examples of the data include image data and video data obtained via the I F by the user of the multi core processor system as well as a program that executes the data processing method of the present embodiment. A memory card an SD card and the like may be employed as the flash ROM for example.

The display displays for example data such as text images functional information etc. in addition to a cursor icons and or tool boxes. A thin film transistor TFT liquid crystal display a plasma display etc. may be employed as the display .

The I F is connected to a network such as a local area network LAN a wide area network WAN and the Internet via a communication line. The I F administers an internal interface with the network and controls the input and output of data with respect to external apparatuses. A modem a LAN adapter and the like may be employed as the I F .

The keyboard includes for example keys for inputting letters numerals and various instructions and performs the input of data. Alternatively a touch panel type input pad or numeric keypad etc. may be adopted.

Thus although the multi core processor system has shared memory architecture from the perspective of the CPUs the multi core processor system has distributed memory architecture that has multiple memory masters such as the GPU and the DSP . Furthermore the main memory the GPU memory and the DSP memory are handled as shared space that can be accessed by the masters respectively forming a complicated nested structure.

The kernel the DSP dummy device driver and the GPU dummy device driver are respectively executed by the CPUs 0 and 1. For example the CPU 0 executes a kernel 0 a DSP dummy device driver 0 and a GPU dummy device driver 0. The CPU 1 executes a kernel 1 a DSP dummy device driver 1 and a GPU dummy device driver 1. Although the scheduler may be run by any one among the CPU 0 and the CPU 1 in the present embodiment the CPU 0 which is the master CPU in the multi core processor system is assumed to execute the scheduler . The memory management thread is executed by any one among the CPU 0 and the CPU 1.

The kernel has a function of serving as a core of the OS. For example when an app is invoked the kernel expands program code in the main memory . The scheduler has a function of assigning to CPUs threads that are to be executed in the multi core processor system and a function of selecting threads that are to be executed next. For example the scheduler assigns the thread 0 to the CPU 0 and assigns the thread 1 to the CPU 1.

The DSP dummy device driver and the GPU dummy device driver are the dummy device drivers for the device drivers of the GPU and the DSP respectively.

The main memory managing unit the DSP memory managing unit and the GPU memory managing unit have a function of managing the main memory the DSP memory and the GPU memory respectively. For example the main memory managing unit the DSP memory managing unit and the GPU memory managing unit store physical memory addresses and physical address ranges that can be allocated. For instance the main memory managing unit updates the utilization state according to allocation requests and release requests for the main memory . The DSP memory managing unit and the GPU memory managing unit update the utilization states of the DSP memory and the GPU memory respectively.

Functions of the multi core processor system will be described. is a block diagram of an example of functions of the multi core processor system. The multi core processor system includes a storage unit a determining unit an assigning unit an upper level memory managing unit a memory managing unit an updating unit a reading unit a selecting unit a securing unit and a notifying unit . These functions the storage unit to the notifying unit forming a control unit are implemented by executing on the CPUs 0 and 1 programs stored in a storage apparatus. The storage apparatus is for example the ROM the RAM the flash ROM the flash ROM depicted in and the like.

The storage unit is a function of the dummy device driver . The determining unit and the assigning unit are functions of the scheduler and the upper level memory managing unit is a function of the memory management thread . The memory managing unit is a function of the main memory managing unit to the GPU memory managing unit . The updating unit the reading unit and the selecting unit are included in the upper level memory managing unit and the securing unit and the notifying unit are included in the memory managing unit . In although the determining unit and the assigning unit are depicted as functions of the CPU 0 and the upper level memory managing unit is depicted as a function of the CPU 1 the determining unit and the assigning unit may be functions of the CPU 1 and the upper level memory managing unit may be a function of the CPU 0.

The multi core processor system has access to the management request dispatch table a memory utilization table and a thread operation history table .

The management request dispatch table resides in a heap area which is dynamically securable memory and stores thread information and memory management requests executed by the CPU 0 the CPU 1 the GPU and the DSP . The management request dispatch table will be described in detail with reference to . The memory utilization table stores the availability state of the main memory and peripheral memory. The memory utilization table will be described in detail with reference to . The thread operation history table stores information indicating the CPU at which a thread has been run. The thread operation history table will be described in detail with reference to .

The storage unit has a function of storing in sequence and to a heap area thread information executed by multiple data processing apparatuses or peripheral apparatuses. For example the storage unit stores thread information executed by the CPU 0 the CPU 1 the GPU and the DSP to the management request dispatch table . Storage of the thread information in sequence is sequential storage of the thread information.

The determining unit has a function of determining whether the loads of multiple data processing apparatuses are in a balanced state. For example the determining unit determines whether the loads of the CPU 0 and the CPU 1 are in a balanced state. As a method of making such determination for example the determining unit uses a load determining function of the OS calculates for each CPU the amount of time that a thread occupies the CPU and based on the loads of the CPUs determines whether the loads are in a balanced state. If the loads of the CPUs are equal or can be approximated to be equal based on a threshold the determining unit determines the loads to be in a balanced state and if the loads of the CPUs are greater than or equal to the threshold the determining unit determines that the loads are not in a balanced state. The result of the determination is stored to a memory area such as in the RAM and the flash ROM .

The assigning unit has a function of assigning execution of the upper level memory managing unit and the memory managing unit to the data apparatus having the smallest load among the data processing apparatuses when the CPU loads have been determined by the determining unit to not be in a balanced state. For example when the loads of the CPU 0 and the CPU 1 are not in a balanced state the assigning unit assigns the memory management thread to the CPU 0 1 having the smaller load.

If the determining unit determines that the loads area in a balanced state the assigning unit may assign the execution of the upper level memory managing unit and the memory managing unit to a data processing apparatus to which the execution has been assigned in the past or to a peripheral apparatus. For example if the loads of the CPU 0 and the CPU 1 are in a balanced state the assigning unit refers to the thread operation history table and assigns the execution to the CPU 0 1 to which the execution has been assigned in the past.

The upper level memory managing unit has a function of managing the utilization state of the main memory and peripheral memory. For example the upper level memory managing unit sends an inquiry for the utilization state of memory to the memory managing unit and receives notification of the utilization state from the memory managing unit .

The memory managing unit has a function of managing memory. The memory managing unit resides respectively in the main memory the GPU memory and the DSP memory . With respect to the memory the memory managing unit performs logical physical conversions secures releases and re secures areas and performs reading and writing.

The updating unit has a function of updating the memory utilization table based on the received the utilization state. For example the updating unit stores to the memory utilization table the utilization state notified by the memory managing unit .

The reading unit has a function of reading thread information from the heap area. For example the reading unit reads the thread information from the management request dispatch table . The results of the reading are stored to a memory area such as in the RAM and the flash ROM .

The selecting unit has a function of selecting based on the thread information read from the heap area the memory or peripheral memory to secure an area thereon for a memory allocation request from a thread based on the thread information. The selecting unit may make the selection for the memory allocation request based on priority level information that is based on the thread information. For example if the priority level is high the selecting unit selects the high speed main memory . If the priority level is low the selecting unit selects the DSP memory which has a slower speed than the main memory .

The selecting unit may select peripheral memory for the memory allocation request when the thread based on the thread information is a thread executed by a peripheral apparatus. The result of the selection is stored to a memory area such as in the RAM and the flash ROM .

The securing unit has a function of securing an area in the memory selected by the selecting unit . For example the securing unit secures an area in the main memory when the main memory has been selected. The source of the request is notified of the secured area.

The notifying unit has a function of notifying the upper level memory managing unit of the utilization state of memory. For example the notifying unit that is a function of the main memory managing unit notifies the upper level memory managing unit of the utilization state of the main memory . Similarly the notifying unit that is a function of the DSP memory managing unit notifies the upper level memory managing unit of the utilization state of the DSP memory . Further the notifying unit that is a function of the GPU memory managing unit notifies the upper level memory managing unit of the utilization state of the GPU memory .

In the present embodiment the management request dispatch table stores management requests for 3 memories including the main memory the GPU memory and the DSP memory . Management requests for the main memory are stored to the management request dispatch table  M management requests for the GPU memory are stored to the management request dispatch table  G and management requests for the DSP memory are stored to the management request dispatch table  D. Hereinafter although description will be given for the management request dispatch table  M the management request dispatch table  G and the management request dispatch table  D have similar contents and therefore description thereof is omitted.

The management request dispatch table  M depicted in stores records  M 1 to  M n where n is a natural number. The management request dispatch table  M has 2 fields respectively for request source thread IDs and the requested memory sizes. The request source thread ID field stores the ID of the thread that has issued the memory allocation request. The requested memory size field stores the number of bytes indicated in the memory allocation request. For example record  M 1 stores the memory allocation request of 32 bytes from the thread 0.

The management request dispatch table  M resides in the heap area which is dynamically securable memory and has a structure in which the records are connected by pointers. For example record  M 1 has a pointer to record  M 2. Similarly record  M 2 has a pointer to record  M 3 and record  M 3 has a pointer to record  M 4. Further record  M n has a pointer to record  M 1.

Although the management request dispatch table depicted in depicts memory allocation requests as memory management requests requests for re securing memory and for releasing memory may be included as other memory management requests. Further requests for reading and writing with respect to memory may be included as memory management requests. In this case fields retained by 1 record of the management request dispatch table are the request source thread ID field and parameters of the requests. Examples of a parameters of a request include parameters of the realloc function when the request is for the re securing of memory parameters of a free function when the request is for the release of memory an assigned address and a requested memory size and an address to be released.

The memory utilization table has 2 fields for memory types and available capacities. The memory type field stores identification information for identifying the memory. The available capacity field stores the available capacity of the memory.

For example record indicates that the available capacity of the main memory which has the fastest access speed among the memory group is 50 Mbytes . Record indicates that the available capacity of the GPU memory which has the next fastest access speed is 10 Mbytes . Record indicates that the available capacity of the DSP memory which has a slow access speed is 20 Mbytes .

For example the thread operation history table depicted in indicates that the memory management thread and the thread 1 have been run 2 times on the CPU 1 and the thread 0 has been run 1 time on the CPU 0.

The multi core processor system uses the function depicted in and the stored contents depicted in to assign threads and secure memory. depict examples of a thread assigning method and depict examples of a memory securing method.

In the example depicted in the scheduler refers to the thread operation history table and since the memory management thread has been operated by the CPU 1 twice in the past assigns the memory management thread to the CPU 1. Thread assignment to the same CPU increases as a result of assigning the threads based on the past operation history.

Examples of a memory securing method will be described with reference to . The thread 0 depicted in is assumed to be a menu program uses the GPU and has an intermediate priority level. The thread 1 is assumed to be a multimedia program uses the DSP and has a high priority level. The thread 3 is assumed to be a communication program and has a low priority level.

Next if the CPU 0 executes the thread 0 and the CPU 1 executes the high priority thread 1 the memory management thread performs the memory allocation request from the thread having the lower priority. In the case of after performing the memory allocation request of the thread 0 the memory management thread performs the memory allocation request of the thread 1.

First the memory management thread executes the GPU memory managing unit secures in the GPU memory for which the access speed is slow an area for the thread 0. Next the memory management thread executes the main memory managing unit and secures in the main memory for which the access speed is high an area for the thread 1.

In this case first the memory management thread performs the memory allocation request of the thread 2 subsequently performs the memory allocation request of the thread 0 and finally performs the memory allocation request of the thread 1. First the memory management thread executes the DSP memory managing unit and secures in the DSP memory for which the access speed is slow an area for the thread 2. Next the memory management thread executes the GPU memory managing unit and secures in the GPU memory for which the access speed is intermediate an area for the thread 0. Finally the memory management thread executes the main memory managing unit and secures in the main memory for which the access speed is high an area for the thread 1.

In the state depicted in consequent to the running of a new thread that uses the GPU the multi core processor system may release the area for the thread 0. In this case the thread using the GPU initializes the GPU and the GPU memory .

The CPU 0 determines whether the memory management thread has been periodically executed step S . If periodically executed step S YES the CPU 0 sends to the memory managing unit of each device an inquiry for the utilization state and the availability state step S . The CPU 0 after receiving an inquiry as a memory management unit of the devices notifies the memory management thread of the utilization state and the availability state step S . The CPU 0 having received notification of the utilization state and the availability state updates the memory utilization table based on the notification step S and ends the process of the memory management thread .

If the memory management thread has not been periodically executed step S NO the CPU 0 reads out a record from the management request dispatch table step S . Multiple records may be stored in the management request dispatch table . If multiple memory allocation requests are present the CPU 0 may sequentially read out the records starting from that of a memory allocation request from a thread having a low priority level.

If the CPU 0 cannot secure memory for a high priority thread consequent to securing memory for the high priority thread after securing memory for a thread having a low priority level the CPU 0 swaps out the memory for the low priority thread with the flash ROM or the flash ROM . Thus by rearranging the secured areas the multi core processor system can prevent fragmentation of the memory areas. If memory is secured for the threads in descending order of thread priority level secured areas cannot be moved from low priority threads to high priority threads increasing the risk of fragmentation of the memory areas.

After reading the record the CPU 0 determines whether a memory allocation request is present in the record step S . If a memory allocation request is present step S YES the CPU 0 executes a memory selecting process step S . The memory selecting process will be described with reference to .

After execution of the memory selecting process or if no memory allocation request is present step S NO the CPU 0 executes the memory managing unit of a given device step S . As an execution process of the memory managing unit of the given device for example if the memory management request is a memory allocation request the CPU 0 secures a memory area in given memory. The given memory is the memory selected at step S or step S. For example in a case where the main memory has been selected the main memory is the given memory.

The CPU 0 moves the read managing request to a process completion table step S updates the thread operation history table load information and the memory utilization table step S and ends the process of the memory management thread . The process completion table stores completed memory management requests correlated with returned values. The dummy device driver refers to the returned value for the memory management request in the process completion table and sends a response for the memory management request to the app that called the dummy device driver .

The CPU 0 determines whether the CPU loads are in a balanced state step S . If the CPU loads are in a balanced state step S YES the CPU 0 assigns the given thread to a CPU to which the given thread has been assigned in the past step S . If the CPU loads are not in a balanced state step S NO the CPU 0 assigns the given thread to a CPU having a low load step S . After the operation at steps S and S the CPU 0 ends the assignment destination CPU selecting process for the given thread.

If the memory management thread has been called by a user thread step S user thread the CPU 0 determines whether the user thread has a high priority step S . If the user thread has a low priority or an intermediate priority step S low priority intermediate priority the CPU 0 refers to the thread operation history table and determines whether an area is available in the peripheral memory step S .

If no area is available step S NO or if the user thread has a high priority step S high priority the CPU 0 selects the main memory from among the main memory and peripheral memory step S . After making the selection the CPU 0 ends the memory selecting process. If an area is available step S YES or if the memory management thread has been called by a device driver step S device driver the CPU 0 selects the peripheral memory from among the main memory and the peripheral memory step S . After making the selection the CPU 0 ends the memory selecting process.

The server is a management server of a group of servers servers to having a cloud . The client is a notebook personal computer PC . The client is a desktop PC and the client is a mobile telephone. The client may be a smartphone or a personal handyphone system PHS telephone in addition to a mobile telephone. The client is a tablet terminal.

In the server the server the servers to and the clients to for example execute the data processing system according to the present embodiment as the data processing apparatuses described in the embodiment. For example the server is assumed to have the fastest memory and the servers to are assumed to have low speed memory. In this case the data processing system can execute the data processing method of the present embodiment by using the memory of the server as the main memory and the memory of the servers to as the memory of the peripheral apparatuses.

As described the data processing system and the data processing method enable memory management requests from threads under execution by multiple data processing apparatuses to be stored to shared memory management requests to be read out sequentially and areas of the main memory and peripheral apparatus memory to be secured. As a result memory can be managed such that contention consequent to concurrent access by multiple data processing apparatuses in the data processing system does not occur. For example since the data processing apparatus reads from the shared memory in a sequential manner the memory management requests are not called at the same timing and therefore access contention does not occur.

The data processing system may assign the memory management thread that manages memory to the data processing apparatus having the smallest load among the data processing apparatuses if the data processing apparatus loads are not in a balanced state. As a result data processing system can distribute the load of memory managing process without causing access contention. In a conventional example of a data processing system if multiple memories are attempted to be managed by an arbitrary data processing apparatus exclusive control process is necessary causing overhead to increase. Further in a conventional example of a data processing system if multiple memories are attempted to be managed by a singular data processing apparatus the distribution of load becomes uneven.

The data processing system may assign the memory managing thread to a data processing apparatus to which the memory managing thread has been assigned in the past if the load of the data processing apparatuses are in a balanced state. As a result the data processing apparatus to which the memory managing thread is assigned can use in the cache memory the existing cache for the tread and thereby perform the process faster.

For example the memory management thread has memory management routines as programs and an allocation table of the secured memory areas as data. If memory management routines remain in the instruction cache the memory management thread can immediately execute the process. Further if the allocation table remains in the data cache the memory management thread can immediately manage the table.

The data processing system may secure an area in any one among the main memory and peripheral memory based on the priority level information of a thread that has issued a memory allocation request. The data processing system may secure an area in memory for which the memory access speed is high if the thread that issued the memory allocation request has a high priority. As a result for a thread requiring high speed processing the data processing system uses memory that can accommodate high speed access enabling high speed processing.

The data processing system may secure an area in peripheral memory if the thread that issued the memory allocation request has an intermediate or a low priority and the peripheral memory has an available area. Peripheral memory consumes less power than the main memory to the extent to which peripheral memory is slower than the main memory. Therefore when high speed processing need not be performed the data processing system can reduce power consumption and improve power efficiency by securing an area in peripheral memory which has low power consumption.

The data processing system may secure an area in peripheral memory if the thread that issued the memory allocation request manages a peripheral apparatus. As a result the data processing system can execute a thread corresponding to a peripheral apparatus even if the thread is a thread that uses the peripheral apparatus.

The data processing system may collect the utilization states of memory and of peripheral memory. As a result the data processing system can confirm the available capacity of each peripheral memory and thereby secure an area from available memory for which the access speed is slow.

The data processing method described in the present embodiment may be implemented by executing a prepared program on a computer such as a personal computer and a workstation. The program is stored on a non transitory computer readable recording medium such as a hard disk a flexible disk a CD ROM an MO and a DVD read out from the computer readable medium and executed by the computer. The program may be distributed through a network such as the Internet.

According to one aspect of the embodiment multiple memories can be managed without contention occurring consequent to concurrent memory access.

All examples and conditional language provided herein are intended for pedagogical purposes of aiding the reader in understanding the invention and the concepts contributed by the inventor to further the art and are not to be construed as limitations to such specifically recited examples and conditions nor does the organization of such examples in the specification relate to a showing of the superiority and inferiority of the invention. Although one or more embodiments of the present invention have been described in detail it should be understood that the various changes substitutions and alterations could be made hereto without departing from the spirit and scope of the invention.

