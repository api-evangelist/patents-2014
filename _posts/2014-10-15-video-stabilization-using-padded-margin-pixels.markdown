---

title: Video stabilization using padded margin pixels
abstract: One or more techniques and/or systems are provided for video stabilization and/or for image frame generation. For example, a user may instruct a video application hosted on a smart phone to capture a video at a target resolution of 1080 pixels. A padded input having a padded resolution that is larger than the target resolution may be obtained from a capture device, such as a camera of the smart phone. The padded input may be provided to a video stabilization component to obtain a target image frame having the target resolution. In this way, the video stabilization component may perform cropping using padded margin pixels (e.g., additional pixels of the padded input beyond the 1080 pixels of the target resolution) so that image upscaling after cropping (e.g., to account for global warping, etc.) may be mitigated to reduce blur that may otherwise result from image upscaling.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09398217&OS=09398217&RS=09398217
owner: Microsoft Technology Licensing, LLC
number: 09398217
owner_city: Redmond
owner_country: US
publication_date: 20141015
---
Many computing devices may have image capture capabilities. In an example a user may capture vacation photos using a digital camera and the user may transfer the vacation photos to a laptop for sharing with other users through a social network. In another example the user may capture a video of a daughter s soccer game using a mobile device such as a smart phone.

This summary is provided to introduce a selection of concepts in a simplified form that are further described below in the detailed description. This summary is not intended to identify key factors or essential features of the claimed subject matter nor is it intended to be used to limit the scope of the claimed subject matter.

Among other things one or more systems and or techniques for video stabilization and or for image frame generation are provided herein. In an example of video stabilization a capture device is negotiated with to obtain a padded input. The padded input comprises padded margin pixels. The padded input has a padded resolution that is larger than a target resolution. The padded input is provided to a video stabilization component to obtain a target image frame having the target resolution.

In an example of image frame generation a capture device is negotiated with to obtain a padded input. The padded input comprises padded margin pixels. An image frame is obtained for combination with the padded input. The padded margin pixels are utilized to compensate for one or more missing pixels between the image frame and the padded input to create a combined image frame.

To the accomplishment of the foregoing and related ends the following description and annexed drawings set forth certain illustrative aspects and implementations. These are indicative of but a few of the various ways in which one or more aspects may be employed. Other aspects advantages and novel features of the disclosure will become apparent from the following detailed description when considered in conjunction with the annexed drawings.

The claimed subject matter is now described with reference to the drawings wherein like reference numerals are generally used to refer to like elements throughout. In the following description for purposes of explanation numerous specific details are set forth to provide an understanding of the claimed subject matter. It may be evident however that the claimed subject matter may be practiced without these specific details. In other instances structures and devices are illustrated in block diagram form in order to facilitate describing the claimed subject matter.

One or more systems and or techniques for video stabilization and or image frame generation are provided herein. While capturing video using a capture device hand jitter of the user and or other factors such as user motion may result in undesirable video quality. Thus a video stabilization component may crop an image frame into a smaller cropped frame that is warped in a manner that improves video stabilization e.g. warped according to a forward facing view of a scene as opposed to a tilted view of the scene resulting from hand jitter and then may expand the smaller cropped frame into an upscaled full size frame that may suffer from blur or other visual issues due to the upscaling. Accordingly as provided herein a capture device may be negotiated with to obtain a padded input having a padded resolution that is larger than a target resolution e.g. the user may request a target video resolution of 1920 1080 and thus the capture device may be invoked to capture padded input frames at a padded resolution of 2112 1188 in order to obtain a 10 padding of padded margin pixels e.g. 10 more pixels than the 1920 1080 resolution . The padded input may be provided to a video stabilization component so that the video stabilization component may create a target image frame having the target resolution e.g. the video stabilization component may crop 10 of the pixels of the padded input to create a target image frame having the 1920 1080 target resolution without performing upscaling . Because the video stabilization component may utilize the padded margin pixels during processing minimal to no upscaling may be performed in order to reduce blur. In this way video capture functionality of the capture device such as a smart phone camera may be improved so that the user may create stabilized videos that are less blurry. The amount of padded input may be determined based upon available resources of a device such as the smart phone associated with the capture device which may improve processing efficiency e.g. 10 padded margin pixels as opposed to 30 padded margin pixels may be obtained so that the smart phone is not computationally overburdened during image stabilization that may otherwise occur when trying to process 30 more pixels .

An embodiment of video stabilization is illustrated by an exemplary method of . At the method starts. In an example a computing device may be associated with a capture device e.g. image processing circuitry of a digital camera a smart phone comprising a camera a wearable device such as glasses or a watch comprising a camera etc. . The capture device may be capable of capturing video such as image frames of a video. The capture device may be associated with a video stabilization component that may be configured to stabilize videos in order to compensate for hand jitter or other motion by the user while capturing video. The user may set a target resolution at which the video is to be captured such as a 1080p resolution. However the capture device may be capable of capturing video such as image frames that have a larger resolution than the target resolution. As provided herein the capture device may be instructed to capture padded input having a padded resolution larger than the target resolution. The padded input comprises padded margin pixels. The padded input may be provided to the video stabilization component for image stabilization to create a target image having the target resolution. Because the padded input has more pixels than the target resolution the video stabilization component may reduce or eliminate the amount of image upscaling performed after cropping because the padded input has extra pixels such as the padded margin pixels that can be cropped without reducing the padded input below the target resolution.

At the capture device may be negotiated with to obtain a padded input. For example a user or application may set a video capture resolution parameter to a target resolution of 1920 1080. A padded pixel percentage parameter e.g. a padding value of about 15 a padding value less than or equal to about 20 etc. may be selected so that the capture device may obtain the padded input according to the padded pixel percentage parameter e.g. a 2112 1188 padded input corresponding to a 10 padded pixel percentage parameter . In an example the padded pixel percentage parameter may be selected and or generated based upon at least one of a cropping metric used by the video stabilization component a field of view FOV of a sensor of the capture device an amount of padding to be used by the video stabilization component a set of available resolutions for the capture device the target resolution or an analysis of available computer resources of the computing device e.g. processor load and bandwidth memory etc. so that the padded pixel percentage parameter corresponds to an amount of image frame data that is reasonable for the computing device to process. In an example where the padded pixel percentage parameter is selected based upon the cropping metric the video stabilization component may crop 15 for example of an image during stabilization where obtaining 15 more pixel data may allow the video stabilization component to crop the padded input with reduced image upscaling otherwise used to compensate for cropped pixels.

In an example negotiation to obtain the padded input may be based upon whether the padded input will cover a larger field of view FOV than non padded input which may be based upon capabilities of one or more sensors of the capture device. For example a first set of sensors may have an increased resolution as compared to a second set of sensors but may correspond to the same FOV. The first set of sensors may for example correspond to 2112 1188 input for a particular region or FOV whereas the second set of sensors may correspond to 1920 1080 input for the same region. The 2112 1188 input is thus a more dense sampling for the same FOV. Alternatively the first set of sensors may have the same or different sampling density as compared to the second set of sensors but may nevertheless yield a padded input that has a larger FOV as compared to the first set of sensors. Padded input may also be a function of capture capability of one or more sensors. For example where a set of sensors can accommodate or support a 10 larger FOV at a target or desired resolution then cropping scenarios up to 10 may be covered whereas a 15 cropping scenario for example would not be available for video stabilization.

The padded input may comprise padded margin pixels. The padded input may have a padded resolution that is larger than the target resolution at which the target image frame is to be generated by the video stabilization component. For example the user may attempt to capture a video comprising target image frames at a target resolution of 1920 1080. The capture device may be instructed to capture the padded input at a padded resolution of 2112 1188 based upon the 10 padded pixel percentage parameter. In this way the padded input has the padded resolution of 2112 1188 with 10 padded margin pixels as compared to the target resolution 1920 1080 pixels e.g. the capture device is capturing image frames that are larger than what will be provided to the user so that the video stabilization component has more pixels to use during cropping which may result in less upscaling and blur during image stabilization .

At the padded input may be provided to the video stabilization component to obtain the target image frame having the target resolution. For example the video stabilization component may be instructed to utilize one or more padded margin pixels during image stabilization to generate the target image frame e.g. the video stabilization component may take the padded margin pixels into consideration when performing cropping or other functionality during image stabilization . The video stabilization component may utilize the one or more padded margin pixels in place of image upscaling functionality e.g. instead of upscaling non padded images to achieve the target resolution after cropping the video stabilization component may use padded margin pixels to fill cropped regions to generate the target image frame. Mitigating image upscaling after cropping may reduce image blur softness or other visual issues that may have resulted from image upscaling by the video stabilization component.

In an example where the padded pixel percentage parameter was derived from the cropping metric an instruction may be provided to the video stabilization component regarding how to crop the padded input. In an example responsive to the padded pixel percentage parameter e.g. 15 matching the cropping metric e.g. 15 the video stabilization component may be instructed to crop a portion of the padded input that corresponds to the padded pixel percentage parameter to create the target image frame e.g. the video stabilization component may crop 15 of the padded input to create the target image frame at the target resolution . Responsive to the padded pixel percentage parameter e.g. 20 being larger than the cropping metric e.g. 15 the video stabilization component may be instructed to crop a portion of the padded input corresponding to the cropping metric to create an intermediary image frame. The video stabilization component may be instructed to downsize the intermediary image frame to create the target image frame at the target resolution. Responsive to the padded pixel percentage e.g. 10 being smaller than the cropping metric e.g. 15 the video stabilization component may be instructed to crop a portion of the padded input corresponding to the cropping metric. An aperture setting may be set to indicate that a region of the target image frame e.g. 5 is invalid.

The padded input may be used for various other implementations such as for creating a panorama for creating a globally aligned image frame and or for creating a naturally padded input for use by video encoding functionality. In an example of creating a globally aligned image frame an image frame which is to be globally aligned with the padded input may be obtained. The padded margin pixels may be used to compensate for one or more missing pixels between the image frame and the padded input to create the globally aligned image frame. In an example of creating a panorama an image frame which is to be used with the padded input for generating the panorama may be obtained. The padded margin pixels may be used to compensate for one or more missing pixels between the image frame and the padded input to create the panorama. In an example of creating a naturally padded input a natural padding parameter used by video encoding functionality may be identified. The padded margin pixels may be utilized to create a naturally padded input for use by the video encoding functionality based upon the natural padding parameter e.g. as opposed to using padding comprised of black green or other stock colored pixels . At the method ends.

An embodiment of image frame generation is illustrated by an exemplary method of . At the method starts. At a capture device may be negotiated with to obtain a padded input. For example a user of a smart phone may set a target resolution of a video capture application to be 1920 1080. The capture device such as a camera associated with smart phone may be capable of capturing imagery larger than 1920 1080. Accordingly the capture device may be instructed to capture the padded input at a padded resolution of 2112 1188. The padded input comprises padded margin pixels e.g. padded margin pixels may correspond to a portion of the 2112 1188 pixels that surround the 1920 1080 pixels .

At an image frame that is to be combined with the padded input may be obtained. For example the image frame and the padded input may be combined e.g. stitched together to create a panorama or may be combined e.g. aligned to create a globally aligned image frame. In an example the image frame may have a resolution that is the same as the target resolution. In another example the image frame may have a resolution that is the same of the padded resolution. In another example the image frame may have a resolution that is different than both the target resolution and the padded resolution. At the padded margin pixels may be utilized to compensate for one or more missing pixels between the image frame and the padded input to create a combined image frame such as the panorama or the globally aligned image frame. At the method ends.

The video stabilization management component may provide the padded resolution to the capture device such as through the device driver interface . The capture device may capture padded input according to the padded resolution . The padded input may have the padded resolution of 2112 1188 that is larger than the target resolution of 1920 1080. In this way the padded input comprises padded margin pixels e.g. 10 of the 2112 1188 may be padded margin pixels based upon the padded resolution being 10 larger than the target resolution .

The video stabilization management component may provide the padded input to the video stabilization component . The video stabilization component may perform various image stabilization functions such as cropping to create a target image frame having the target resolution. For example the video stabilization management component may instruct the video stabilization component to crop one or more padded margin pixels during image stabilization which may mitigate the need to perform image upscaling after cropping to obtain the target image frame at the target resolution e.g. up to 10 of the 2112 1188 padded resolution may be cropped without going below the target resolution of 1920 1080 . Reducing or eliminating image upscaling may mitigate image blur that would have otherwise resulted from the image upscaling.

According to an aspect of the instant disclosure a method for video stabilization is provided. The method includes negotiating with a capture device to obtain a padded input. The padded input comprises padded margin pixels. The padded input has a padded resolution larger than a target resolution. The method includes providing the padded input to a video stabilization component to obtain a target image frame having the target resolution.

According to an aspect of the instant disclosure a system for video stabilization is provided. The system includes a video stabilization management component. The video stabilization management component is configured to negotiate with a capture device to obtain a padded input. The padded input comprises padded margin pixels. The padded input has a padded resolution larger than a target resolution. The video stabilization management component is configured to provide the padded input to a video stabilization component to obtain a target image frame having the target resolution.

According to an aspect of the instant disclosure a method for image frame generation is provided. The method includes negotiating with a capture device to obtain a padded input. The padded input comprises padded margin pixels. The method includes obtaining an image frame to be combined with the padded input. The method includes utilizing the padded margin pixels to compensate for one or more missing pixels between the image frame and the padded input to create a combined image frame.

According to an aspect of the instant disclosure a means for video stabilization is provided. A capture device is negotiated with to obtain a padded input by the means for video stabilization. The padded input comprises padded margin pixels. The padded input has a padded resolution larger than a target resolution. The padded input is provided to a video stabilization component to obtain a target image frame having the target resolution by the means for video stabilization.

According to an aspect of the instant disclosure a means for image frame generation is provided. A capture device is negotiated with to obtain a padded input by the means for image frame generation. The padded input comprises padded margin pixels. An image frame is obtained for combination with the padded input by the means for image frame generation. The padded margin pixels are utilized to compensate for one or more missing pixels between the image frame and the padded input to create a combined image frame by the means for image frame generation.

Still another embodiment involves a computer readable medium comprising processor executable instructions configured to implement one or more of the techniques presented herein. An example embodiment of a computer readable medium or a computer readable device is illustrated in wherein the implementation comprises a computer readable medium such as a CD R DVD R flash drive a platter of a hard disk drive etc. on which is encoded computer readable data . This computer readable data such as binary data comprising at least one of a zero or a one in turn comprises a set of computer instructions configured to operate according to one or more of the principles set forth herein. In some embodiments the processor executable computer instructions are configured to perform a method such as at least some of the exemplary method of and or at least some of the exemplary method of for example. In some embodiments the processor executable instructions are configured to implement a system such as at least some of the exemplary system of at least some of the exemplary system of at least some of the exemplary system of and or at least some of the exemplary system of for example. Many such computer readable media are devised by those of ordinary skill in the art that are configured to operate in accordance with the techniques presented herein.

Although the subject matter has been described in language specific to structural features and or methodological acts it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the specific features or acts described above. Rather the specific features and acts described above are disclosed as example forms of implementing at least some of the claims.

As used in this application the terms component module system interface and or the like are generally intended to refer to a computer related entity either hardware a combination of hardware and software software or software in execution. For example a component may be but is not limited to being a process running on a processor a processor an object an executable a thread of execution a program and or a computer. By way of illustration both an application running on a controller and the controller can be a component. One or more components may reside within a process and or thread of execution and a component may be localized on one computer and or distributed between two or more computers.

Furthermore the claimed subject matter may be implemented as a method apparatus or article of manufacture using standard programming and or engineering techniques to produce software firmware hardware or any combination thereof to control a computer to implement the disclosed subject matter. The term article of manufacture as used herein is intended to encompass a computer program accessible from any computer readable device carrier or media. Of course many modifications may be made to this configuration without departing from the scope or spirit of the claimed subject matter.

Although not required embodiments are described in the general context of computer readable instructions being executed by one or more computing devices. Computer readable instructions may be distributed via computer readable media discussed below . Computer readable instructions may be implemented as program modules such as functions objects Application Programming Interfaces APIs data structures and the like that perform particular tasks or implement particular abstract data types. Typically the functionality of the computer readable instructions may be combined or distributed as desired in various environments.

In other embodiments device may include additional features and or functionality. For example device may also include additional storage e.g. removable and or non removable including but not limited to magnetic storage optical storage and the like. Such additional storage is illustrated in by storage . In one embodiment computer readable instructions to implement one or more embodiments provided herein may be in storage . Storage may also store other computer readable instructions to implement an operating system an application program and the like. Computer readable instructions may be loaded in memory for execution by processing unit for example.

The term computer readable media as used herein includes computer storage media. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions or other data. Memory and storage are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM Digital Versatile Disks DVDs or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by device . Computer storage media does not however include propagated signals. Rather computer storage media excludes propagated signals. Any such computer storage media may be part of device .

Device may also include communication connection s that allows device to communicate with other devices. Communication connection s may include but is not limited to a modem a Network Interface Card NIC an integrated network interface a radio frequency transmitter receiver an infrared port a USB connection or other interfaces for connecting computing device to other computing devices. Communication connection s may include a wired connection or a wireless connection. Communication connection s may transmit and or receive communication media.

The term computer readable media may include communication media. Communication media typically embodies computer readable instructions or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. The term modulated data signal may include a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.

Device may include input device s such as keyboard mouse pen voice input device touch input device infrared cameras video input devices and or any other input device. Output device s such as one or more displays speakers printers and or any other output device may also be included in device . Input device s and output device s may be connected to device via a wired connection wireless connection or any combination thereof. In one embodiment an input device or an output device from another computing device may be used as input device s or output device s for computing device .

Components of computing device may be connected by various interconnects such as a bus. Such interconnects may include a Peripheral Component Interconnect PCI such as PCI Express a Universal Serial Bus USB firewire IEEE 1394 an optical bus structure and the like. In another embodiment components of computing device may be interconnected by a network. For example memory may be comprised of multiple physical memory units located in different physical locations interconnected by a network.

Those skilled in the art will realize that storage devices utilized to store computer readable instructions may be distributed across a network. For example a computing device accessible via a network may store computer readable instructions to implement one or more embodiments provided herein. Computing device may access computing device and download a part or all of the computer readable instructions for execution. Alternatively computing device may download pieces of the computer readable instructions as needed or some instructions may be executed at computing device and some at computing device .

Various operations of embodiments are provided herein. In one embodiment one or more of the operations described may constitute computer readable instructions stored on one or more computer readable media which if executed by a computing device will cause the computing device to perform the operations described. The order in which some or all of the operations are described should not be construed as to imply that these operations are necessarily order dependent. Alternative ordering will be appreciated by one skilled in the art having the benefit of this description. Further it will be understood that not all operations are necessarily present in each embodiment provided herein. Also it will be understood that not all operations are necessary in some embodiments.

Further unless specified otherwise first second and or the like are not intended to imply a temporal aspect a spatial aspect an ordering etc. Rather such terms are merely used as identifiers names etc. for features elements items etc. For example a first object and a second object generally correspond to object A and object B or two different or two identical objects or the same object.

Moreover exemplary is used herein to mean serving as an example instance illustration etc. and not necessarily as advantageous. As used herein or is intended to mean an inclusive or rather than an exclusive or . In addition a and an as used in this application are generally be construed to mean one or more unless specified otherwise or clear from context to be directed to a singular form. Also at least one of A and B and or the like generally means A or B and or both A and B. Furthermore to the extent that includes having has with and or variants thereof are used in either the detailed description or the claims such terms are intended to be inclusive in a manner similar to the term comprising .

Also although the disclosure has been shown and described with respect to one or more implementations equivalent alterations and modifications will occur to others skilled in the art based upon a reading and understanding of this specification and the annexed drawings. The disclosure includes all such modifications and alterations and is limited only by the scope of the following claims. In particular regard to the various functions performed by the above described components e.g. elements resources etc. the terms used to describe such components are intended to correspond unless otherwise indicated to any component which performs the specified function of the described component e.g. that is functionally equivalent even though not structurally equivalent to the disclosed structure. In addition while a particular feature of the disclosure may have been disclosed with respect to only one of several implementations such feature may be combined with one or more other features of the other implementations as may be desired and advantageous for any given or particular application.

