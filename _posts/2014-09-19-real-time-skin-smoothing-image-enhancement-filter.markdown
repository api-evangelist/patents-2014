---

title: Real time skin smoothing image enhancement filter
abstract: System, apparatus, method, and computer readable media for on-the-fly captured image data enhancement. An image or video stream is enhanced with a filter in concurrence with generation of the stream by a camera module. In one exemplary embodiment, HD image frames are filtered at a rate of 30 fps, or more, to enhance human skin tones with an edge-preserving smoothing filter. In embodiments, the smoothing filter is applied to an image representation of reduced resolution, reducing computational overhead of the filter. The filtered image is then upsampled and blended with a map that identifies edges to maintain an edge quality comparable to a smoothing filter applied at full resolution. A device platform including a camera module and comporting with the exemplary architecture may provide enhanced video camera functionality even at low image processing bandwidth.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09390478&OS=09390478&RS=09390478
owner: Intel Corporation
number: 09390478
owner_city: Santa Clara
owner_country: US
publication_date: 20140919
---
A digital camera is a component often included in commercial electronic media device platforms. Digital cameras are now available in wearable form factors e.g. video capture earpieces video capture headsets video capture eyeglasses etc. as well as embedded within smartphones tablet computers and notebook computers etc.

The introduction of streaming video from mobile digital cameras has ushered in an era with unprecedented volumes of video data shared between mobile devices. Consider an application where the user wears a pair of glasses fitted with a video camera. The camera captures video streams depicting the activities of the user throughout the day. Much of that data will capture human subjects. Since the introduction of digital image processing decades ago many users have become accustomed to reducing wrinkles freckles and various blemishes from human subjects for a more visually appealing image or video. There are several commercial image processing software packages with which users can remove wrinkles freckles etc. and adjust skin tone. However these image processing software packages typically require so much user interaction and time that their use is intractable for the large amounts of image data now being generated.

Automated skin smoothing image enhancement techniques have not kept pace with the need particularly in the low cost and low power market sector that includes wearable computing platforms and mobile communication handsets. There has been considerable research on fast and automated methods for skin smoothing. One currently popular technique is an edge preserving filtering called a bilateral filter. However a bilateral filter has a high computational cost complexity necessitating a powerful CPU and GPU to process high resolution images e.g. full HD in real time e.g. at 30 frames per second . Since sharing images between mobile devices has become popular a powerful CPU and GPU is not always available. Hence many of the platforms responsible for generating the vast majority of a user s archival image data are thus far ill equipped to perform sophisticated image processing.

Automated image data enhancement that can implemented by ultra light low cost and low power platforms in real time with a video stream captured at potentially high frame rates e.g. 30 frames second or more is therefore highly advantageous.

One or more embodiments are described with reference to the enclosed figures. While specific configurations and arrangements are depicted and discussed in detail it should be understood that this is done for illustrative purposes only. Persons skilled in the relevant art will recognize that other configurations and arrangements are possible without departing from the spirit and scope of the description. It will be apparent to those skilled in the relevant art that techniques and or arrangements described herein may be employed in a variety of other systems and applications beyond what is described in detail herein.

Reference is made in the following detailed description to the accompanying drawings which form a part hereof and illustrate exemplary embodiments. Further it is to be understood that other embodiments may be utilized and structural and or logical changes may be made without departing from the scope of claimed subject matter. Therefore the following detailed description is not to be taken in a limiting sense and the scope of claimed subject matter is defined solely by the appended claims and their equivalents.

In the following description numerous details are set forth however it will be apparent to one skilled in the art that embodiments may be practiced without these specific details. Well known methods and devices are shown in block diagram form rather than in detail to avoid obscuring more significant aspects. References throughout this specification to an embodiment or one embodiment mean that a particular feature structure function or characteristic described in connection with the embodiment is included in at least one embodiment. Thus the appearances of the phrase in an embodiment or in one embodiment in various places throughout this specification are not necessarily referring to the same embodiment. Furthermore the particular features structures functions or characteristics described in the context of an embodiment may be combined in any suitable manner in one or more embodiments. For example a first embodiment may be combined with a second embodiment anywhere the particular features structures functions or characteristics associated with the two embodiments are not mutually exclusive.

As used in the description of the exemplary embodiments and the appended claims the singular forms a an and the are intended to include the plural forms as well unless the context clearly indicates otherwise. It will also be understood that the term and or as used herein refers to and encompasses any and all possible combinations of one or more of the associated listed items.

As used throughout the description and in the claims a list of items joined by the term at least one of or one or more of can mean any combination of the listed terms. For example the phrase at least one of A B or C can mean A B C A and B A and C B and C or A B and C.

The terms coupled and connected along with their derivatives may be used herein to describe functional or structural relationships between components. It should be understood that these terms are not intended as synonyms for each other. Rather in particular embodiments connected may be used to indicate that two or more elements are in direct physical optical or electrical contact with each other. Coupled may be used to indicated that two or more elements are in either direct or indirect with other intervening elements between them physical optical or electrical contact with each other and or that the two or more elements co operate or interact with each other e.g. as in a cause an effect relationship .

Some portions of the detailed descriptions provide herein are presented in terms of algorithms and symbolic representations of operations on data bits within a computer memory. Unless specifically stated otherwise as apparent from the following discussion it is appreciated that throughout the description discussions utilizing terms such as calculating computing determining estimating storing collecting displaying receiving consolidating generating updating or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s circuitry including registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or display devices.

While the following description sets forth embodiments that may be manifested in architectures such system on a chip SoC architectures for example. Implementation of the techniques and or arrangements described herein are not restricted to particular architectures and or computing systems and may be implemented by any architecture and or computing system for similar purposes. Various architectures employing for example multiple integrated circuit IC chips and or packages and or various computing devices and or consumer electronic CE devices such as set top boxes smartphones etc. may implement the techniques and or arrangements described herein. Further while the following description may set forth numerous specific details such as logic implementations types and interrelationships of system components logic partitioning integration choices etc. claimed subject matter may be practiced without such specific details. Furthermore some material such as for example control structures and full software instruction sequences may not be shown in detail in order not to obscure the material disclosed herein.

Certain portions of the material disclosed herein may be implemented in hardware for example as logic circuitry in an image processor. Certain other portions may be implemented in hardware firmware software or any combination thereof. At least some of the material disclosed herein may also be implemented as instructions stored on a machine readable medium which may be read and executed by one or more processors graphics processors and or central processors . A machine readable medium may include any medium and or mechanism for storing or transmitting information in a form readable by a machine e.g. a computing device . For example a machine readable medium may include read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices electrical optical acoustical or other similarly non transitory tangible media.

One or more system apparatus method and computer readable media is described below for real time image enhancement. In real time image enhancement an image data video stream is enhanced frame by frame concurrently with frame by frame generation of the stream. The enhancement algorithm is operable at the frame level and may be performed on every consecutive image frame or on a subset of frames such as key frames. The rate requirement for real time image enhancement is a function of a frame rate associated with the CM. As described below a device platform including a CM and comporting with the exemplary architecture may provide video camera functionality with real time image enhancement within the power and processing bandwidth constraints typical of current mobile handsets.

As is discussed further herein RT skin smoothing image enhancement filter is to perform a filtering of input image data . While the filtering algorithm may be any known in the image processing art to reduce computational load associated with the filtering algorithm the algorithm is implemented at some resolution less than the input image resolution. Resultant loss of fidelity in the filtered image data is mitigated through a blending operation that modulates weighting of the filtered image data such that edges represented in the input image data are preserved around spatial regions that have been filtered. Regions to be filtered may be detected based on some skin tone detection criteria that may be a user defined configuration and or received from a system driver and or set to a default etc. RT skin smoothing image enhancement filter generates blended pixel values as output image data . In the exemplary embodiment output image data is also in YUV color space. As described further herein output image data is a blend of input image data and filtered input image pixel values. The blending is based on a pixel level blending coefficient which is determined from the pixel scores. For example where a pixel has a higher score the output pixel value will be a blend more heavily weighting the filtered pixel value than the input pixel value while a pixel with a lower score will be output as a blend more heavily weighting the input pixel value. The blending may be applied to each pixel value of input image data to generate output image data maintaining the input image resolution. Downstream of system output image data may be stored to memory. Output image data may be further post processed and or presented on a display. For example the output image data may receive a further image enhancement and or be encoded into compressed representation of the image frame e.g. in compliance with MPEG 4 H.264 AVC codecs or the like .

Method begins with receiving input image data at operation . In the exemplary embodiment the input image data received at operation is the input image data described above. The input image data received at operation includes pixel values representing an image frame at an input image resolution such as but not limited to 1920 1080. illustrates an input image including a plurality of pixels. A first pixel is inside of a skin tone region while a second pixel is outside of skin tone regions . General areas may include any areas that are not skin tone areas such as background e.g. general area and clothing e.g. general area or the like. Skin tone regions may include any areas that qualify as skin toned based on skin tone detection scores as discussed further below.

At operation individual pixel values within the image frame are scored based on filtering criteria. The pixel scores determined at scoring operation are ultimately indicative of blending coefficients or blending weights subsequently employed in method . With each pixel within a frame receiving a score the pixel scores are collectively indicative of a blending coefficient map within the image frame represented by input image data . In embodiments each pixel score determined at operation is indicative of a probability that the pixel satisfies a filtering criteria that may for example be based on a luma and or chroma component target or center value U V . In one exemplary embodiment the filtering criteria is color based skin tone test with each pixel receiving a skin tone detection score indicative of the probability that the pixel is a skin tone. Where a skin tone detection score is provided for each pixel of input image data the skin tone detection scores determined at operation collectively represent a skin map spatially correlated within the image frame represented by input image data .

In advantageous embodiments the skin tone detection score is a continuous value between 0 and 1 inclusive that is proportional to a probability the individual pixel is a skin tone. As one example a score of 0 may indicate a first e.g. very low likelihood the pixel is a skin tone pixel while a score of 1 may indicate a second e.g. very high likelihood the pixel is a skin tone pixel. Skin tone detection score may of course be provided over any other range such as 0 to 10 0 to 100 etc. With pixel scores ranging between 0 and 1 the pixel score generated at operation may be directly employed in a subsequent blending function. Alternatively an intermediate mapping may be performed to convert the pixel scores determined at operation into suitable blending coefficient values. The intermediate mapping may be with any predetermined default or user definable mapping function.

In embodiments the skin tone detection score is determined based on a comparison with a center of skin color U V . A center of skin color may be received from an outside source e.g. a memory a driver or another system component . The center of skin color may include any data e.g. U Vin the YUV color space indicating a center of skin color such that a pixel having a matching color is likely to be a skin tone pixel. For example center of skin color may vary between predetermined default values based on the skin tones associated with expected subjects of an input image frame.

The skin tone probability for an input pixel value may be calculated based on a pre learned skin tone model. There are many pixel based models for assessing a probability that a pixel is a skin tone and embodiments herein may employ any such technique at operation . These techniques are distinguished from facial recognition techniques and have the advantage of appropriately scoring non facial skin regions. As one example a skin tone model may entail a statistically defined distribution of a skin color as a cluster in the 3D YUV domain such that the center of the cluster is considered the exact skin tone value e.g. the center of the cluster may be center of skin color U V . If a pixel matches the center of the cluster the probability likelihood the pixel is a skin tone pixel may be at a maximum. The likelihood decreases as the pixel value moves further away from the center within the cluster. The likelihood may be further defined to be zero outside of the cluster. Any technique may be used to determine whether an input pixel value is within the cluster and to determine its skin tone detection score based on proximity to the center of the cluster. In one exemplary embodiment intersections of the cluster s projections onto three planes e.g. the UV plane or VU plane the YV plane or VY plane and the YU or UY plane are utilized to detect whether an input pixel is within the cluster. As one example the likelihood the pixel is a skin tone pixel in the UV plane may be determined based on a function modeling the distance relationship between the input pixel and the transformed projected center of the cluster . The function may calculate a likelihood that increases from zero to one as a pixel moves toward center of skin color e.g. U V .

In further embodiments operation additionally entails inputting the map of pixel scores into a spatial smoothing filter which reduces noise in the pixel scoring. The scoring map output by the detection algorithm e.g. skin tone detection algorithm is an input to the smoothing filter. Any spatial smoothing filter known to be suitable for this purpose may be utilized at operation with examples including but not limited to low pass convolution filters employing a smoothing mask such as a Gaussian mask. illustrates a simplified skin map that could be constructed after operation . For clarity depicts only maximum and minimum pixel scores generated at operation . In pixels having a highest probability of skin tone are represented as white e.g. skin detection score of 1 while black represents pixels having a lowest probability of skin tone e.g. skin detection score of 0 . Although not illustrated for the sake of clarity any number of gray levels between the binary levels illustrated in may be further generated at operation .

Method continues at operation . In some embodiments performance of operation and subsequent operations may be predicated upon at least a threshold number of pixels having at least a threshold pixel score indicative of the presence of skin tone within the image frame represented by the input image data. Where the threshold criteria e.g. minimum skin tone detection score are not satisfied method may be terminated at operation with the unfiltered input image data stored to memory. Hence in the absence of sufficient skin tone automated skin smoothing method may be bypassed.

In response to satisfying the threshold criteria e.g. sufficient skin regions were detected the input image data is downsampled at operation to change the pixel grid i.e. change the image size to contain fewer pixels . Downsampling of the input image data to a lower resolution representation of the image frame has the advantage of reducing the image processing requirements of smoothing operations subsequently performed in method . Many image minifying algorithms are known e.g. Bresenham nearest neighbor bicubic interpolation etc. and relative to other operations in method image size reduction algorithms are generally fast and not highly complex computationally. There are therefore many known downsampling filters suitable for real time scaling e.g. 30 FPS of the input image data e.g. Full HD with a given image and or applications processor. In exemplary embodiments downsampling operation employs pixel replication and or nearest neighbor sampling to advantageously reduce the image resolution by at least a factor of 2 and ideally a factor of 4 or more.

Method then continues with operation where the downsampled image generated at operation is enhanced with a skin smoothing filter. At operation pixel values of the downsampled image are smoothed based on values of the downsampled image pixels neighboring an input pixel. In embodiments an edge preserving smoothing filter is employed to smoothen the downsampled image removing texture while avoiding edges that may cause visible artifacts. In one advantageous embodiment a bitlateral filter is employed at operation . The bilateral filter has the advantage of preserving edges but relative to other operations in real time skin smoothing method the filter is computationally costly complex to implement. In the basic form the bilateral filter is a non linear filter employing both a spatial and a range kernel to replace the intensity value at each pixel in an image with a weighted average of intensity values from nearby pixels 

Notably image and or application processors of many mobile devices hosting camera modules e.g. current handsets are incapable of real time filtering a Full HD image frame even with a recursive bilateral filter algorithm. However 30 FPS filtering becomes possible for the downsampled images output by operation . Depending on the computational power of a platform s processor as well the frame rate and resolution of input image data the downsampling factor may be varied as needed e.g. between 2 and 4 to ensure real time smoothing at operation . illustrates a downsampled and smoothed image that might be constructed from image data available following operation in accordance with one exemplary embodiment.

Skin smoothing method continues at operation where the filtered low resolution image data is upsampled upsized back to the input image resolution. The magnification operation effectively increases size dimensionality of the output of smoothing filtering operation . Upsampling to higher pixel count has significant computational complexity cost and so the choice of upscaling algorithm may impact the overall rate of method . In advantageous embodiments a bilinear interpolation of pixel values is performed at operation . Bilinear interpolation has the advantage of being computationally simple enough for an image and or applications processor in most mobile devices e.g. handsets to upsample even a 4 downsampled image back to 1920 1080 in real time e.g. at 30 fps .

Skin smoothing method continues at operation where the input image data received at operation is blended with the upsampled filtered image data generated at operation . The blending of the two sets of image data is a function of the pixel scores determined at operation . Noting that even an edge preserving smoothing filter blurs edges the use of the skin map generated at operation improves retention of desirable edges e.g. nose face contours eyebrows etc. that might otherwise be distorted blurred or lost particularly when filtered at the reduce image size. As illustrated in skin map B contains sharp edge information between skin and non skin regions. In the exemplary embodiment this edge information can be directly incorporated into the blending operation by modulating of the weighting of the input image data relative to the filtered image data for the individual as a function of each pixel skin tone detection score.

In exemplary embodiments the blending at operation entails interpolating between a value e.g. at least one of luma or chroma component of a pixel in the input image data and a corresponding value of that pixel in the filtered image data based on the skin tone detection score for the pixel. In advantageous embodiments the interpolation is linear with the blended pixel value being a weighted sum of the value of the pixel in the input image data and the value of the pixel in the filtered image data. The skin tone detection score weights the two pixel values complementarily. For example where a pixel has a higher score indicating a greater probability the pixel is a skin tone the output pixel value will be a blend more heavily weighting the filtered pixel value than the input pixel value while a pixel with a lower score indicating a lower probability the pixel is a skin tone will be output as a blend more heavily weighting the input pixel value. illustrates an exemplary blended output image frame with blemishes present in input image frame smoothed out.

Returning to one iteration of method performed on a given input image frame completes at operation where the blended image data is stored to a memory for example as the enhanced skin smoothed output image data . The blended image data may be further output to at least one of a display device or an encoder.

As further shown in RT skin smoothing image enhancement filter further includes a detection module coupled to receive input image data . The detection module includes logic to determine a skin tone detection score for individual pixels of the image data. In the exemplary embodiment detection module is to determine a skin tone detection score e.g. between 0 and 1 that is proportional to a probability that an individual pixel comprises a skin tone using any of the technique described above. In further embodiments detection module further includes logic to denoise the skin tone detection scores for example with a spatial smoothing filter. The skin tone detection scores may be output in the form of skin tone probability map .

As further depicted in downsampling module is also coupled to receive input image data . Downsampling module includes logic to downsample image data to a representation of the image frame having a reduced resolution lower than the input image resolution for example using any of the techniques described above. A filter module is coupled to receive the lower resolution downsampled image data which is output by downsampling module . Filtering module includes logic to smooth the downsampled image data for example using any of the smoothing techniques described above. In one advantageous embodiment filtering module includes logic to recursively bilaterally filter individual pixel values in the downsampled image.

As further illustrated in RT skin smoothing image enhancement filter further includes an image upsampling module coupled to receive the filtered downsample image data output by filtering module . Upsampling module includes logic to upsample the filtered downsampled image data back to the input image resolution using any of the techniques described above. Blending module is then coupled to receive input image data high resolution upsampled filter image data output by upsampling module and skin tone probability map . Blending module includes logic to blend input image data with the upsampled filtered image data as a function of skin tone probability map . In advantageous embodiments blending module is to linearly interpolate between a luma and or chroma value of a pixel in the input image data and a luma and or chroma value of the corresponding pixel in the filtered image data based on the skin tone detection score for the pixel. For example a weighted sum of the luma or chroma value of the pixel in the input image data and the luma or chroma value of the pixel in the filtered image data may be determined to weight the two luma or chroma values complementarily by the skin tone detection score.

Platform includes CM . In the exemplary embodiment CM further includes a camera sensor . Sensor may be a HD FHD QXGA WQXGA or QSXGA format digital image device for example. Camera sensor may provide a color resolution of 10 bits or more per pixel is operable to capture continuous video frames progressively. Sensor may have a pixel frequency of 170 MHz or more. Camera sensor may include an RGB Bayer color filter an analog amplifier an A D converter other components to convert incident light into a digital signal corresponding to raw image data. Sensor may be controlled to operate a rolling shutter or electronic focal plane shutter process where pixels are read out progressively in a line sequential fashion for a frame. In exemplary video embodiments sensor outputs multiple consecutively exposed frames. CM outputs raw data associated with the consecutively exposed frames in conformance with any known streaming protocol such as a MIPI. Streamed raw video data is input to ISP . ISP is to receive and analyze frames of raw video data during the horizontal and or vertical blanking periods associated with CM . During raw image data processing ISP may perform one or more of color space conversion noise reduction pixel linearization and shading compensation for example.

Pre processed video data output by ISP may be buffered in a FIFO manner queued as YUV input image data ready for skin smoothing image enhancement. In exemplary embodiments DSP and or applications processor APU implements one or more of the skin smoothing image enhancement modules depicted in . DSP may for example include one or more fixed function or semi programmable logic circuits to perform one or more stages of the skin smoothing method described above. For example a fixed function module may be utilized to implement one or more of a spatially image filtering image minification image magnification bilateral smoothing or blending. Subsystem drivers within a kernel space of an operating system OS instantiated by APU may control various image processing parameters such as a skin tone detection score mapping a center skin tone a minification factor or a bilateral filter kernel. Access to the skin smoothing image enhancement control parameters may be provided through an application layer executing in a user space of the OS.

Embodiments employing fixed function logic are well suited to implementing skin smoothing method at pace with a high exposure frame rate at minimal power. In alternative embodiments however any known programmable processor including a core of APU an execution unit of a graphics processor or other similar vector processor is utilized to implement the logic of RT skin smoothing image enhancement filter . For such embodiments DSP need not implement fixed function circuitry relevant to RT skin smoothing image enhancement filter as denoted by dashed lines in . APU is then solely responsible for generating blended output image data from input image data received from ISP . Such software based implementations are advantageously more flexible than fixed function logic circuitry. In one exemplary embodiment the skin smoothing image enhancement filtering algorithms are instantiated through the user space of APU . APU executes these algorithms at a rate sufficient to perform the skin smoothing method in real time with frame generation. APU may be programmed with instructions stored on a computer readable media to cause the processor to perform any of the operations of skin smoothing method .

As further illustrated in blended output image data is output to storage display transmission pipeline . In one exemplary storage pipeline embodiment output image data is written to electronic memory e.g. DDR etc. which may be separate or a part of a main memory accessible to APU . Alternatively or in addition storage display transmission pipeline is to transmit summary frame data off video capture device .

System includes a device platform that may implement all or a subset of the various RT skin smoothing image enhancement methods and any of the RT skin smoothing image enhancement systems described above in the context of . In various exemplary embodiments video processor executes RT skin smoothing image enhancement. Video processor includes logic circuitry implementing RT skin smoothing image enhancement system to smooth skin toned regions of images synchronously with video frame data streamed from CM for example as described elsewhere herein. In some embodiments one or more computer readable media may store instructions which when executed by CPU and or video processor cause the processor s to execute one or more RT skin smoothing image enhancement algorithm such as any of those described in detail above. One or more image data frame exposed by CM may then be stored in memory as enhanced image data.

In embodiments device platform is coupled to a human interface device HID . Platform may collect raw image data with CM which is processed and output to HID . A navigation controller including one or more navigation features may be used to interact with for example device platform and or HID . In embodiments HID may include any television type monitor or display coupled to platform via radio and or network . HID may include for example a computer display screen touch screen display video monitor television like device and or a television.

Under the control of one or more software applications device platform may display user interface on HID . Movements of the navigation features of controller may be replicated on a display e.g. HID by movements of a pointer cursor focus ring or other visual indicators displayed on the display. For example under the control of software applications the navigation features located on navigation controller may be mapped to virtual navigation features displayed on user interface .

In embodiments device platform may include any combination of CM chipset processors memory storage applications and or radio . Chipset may provide intercommunication among processors memory video processor applications or radio .

One or more of processors may be implemented as one or more Complex Instruction Set Computer CISC or Reduced Instruction Set Computer RISC processors x86 instruction set compatible processors multi core or any other microprocessor or central processing unit CPU .

Memory may be implemented as a volatile memory device such as but not limited to a Random Access Memory RAM Dynamic Random Access Memory DRAM or Static RAM SRAM . Memory may also be implemented as a non volatile storage device such as but not limited to flash memory battery backed up SDRAM synchronous DRAM magnetic memory phase change memory and the like.

Radio may include one or more radios capable of transmitting and receiving signals using various suitable wireless communications techniques. Such techniques may involve communications across one or more wireless networks. Example wireless networks include but are not limited to wireless local area networks WLANs wireless personal area networks WPANs wireless metropolitan area network WMANs cellular networks and satellite networks. In communicating across such networks radio may operate in accordance with one or more applicable standards in any version.

In embodiments system may be implemented as a wireless system a wired system or a combination of both. When implemented as a wireless system system may include components and interfaces suitable for communicating over a wireless shared media such as one or more antennas transmitters receivers transceivers amplifiers filters control logic and so forth. An example of wireless shared media may include portions of a wireless spectrum such as the RF spectrum and so forth. When implemented as a wired system system may include components and interfaces suitable for communicating over wired communications media such as input output I O adapters physical connectors to connect the I O adapter with a corresponding wired communications medium a network interface card NIC disc controller video controller audio controller and the like. Examples of wired communications media may include a wire cable metal leads printed circuit board PCB backplane switch fabric semiconductor material twisted pair wire co axial cable fiber optics and so forth.

The RT skin smoothing image enhancement systems and associated skin smoothing processes as described herein may be implemented in various hardware architectures cell designs or IP cores. 

As described above system may be embodied in varying physical styles or form factors. further illustrates embodiments of a mobile handset device in which system may be embodied. In embodiments for example device may be implemented as a mobile computing handset device having wireless capabilities. As shown in mobile handset device may include a housing with a front and back . Device includes a display an input output I O device and an integrated antenna . Device also may include navigation features . Display may include any suitable display unit for displaying information appropriate for a mobile computing device. I O device may include any suitable I O device for entering information into a mobile computing device. Examples for I O device may include an alphanumeric keyboard a numeric keypad a touch pad input keys buttons switches microphones speakers voice recognition device and software and so forth. Information also may be entered into device by way of microphone not shown or may be digitized by a voice recognition device. Embodiments are not limited in this context. Integrated into at least the back is camera e.g. including a lens an aperture and an imaging sensor and a flash both of which may be components of a CM through which streaming video is exposed and output to the video summarization system as described elsewhere herein.

As exemplified above embodiments described herein may be implemented using hardware elements software elements or a combination of both. Examples of hardware elements or modules include processors microprocessors circuitry circuit elements e.g. transistors resistors capacitors inductors and so forth integrated circuits application specific integrated circuits ASIC programmable logic devices PLD digital signal processors DSP field programmable gate array FPGA logic gates registers semiconductor device chips microchips chip sets and so forth. Examples of software elements or modules include applications computer programs application programs system programs machine programs operating system software middleware firmware routines subroutines functions methods procedures software interfaces application programming interfaces API instruction sets computing code computer code code segments computer code segments data words values symbols or any combination thereof. Determining whether an embodiment is implemented using hardware elements and or software elements may vary in accordance with any number of factors considered for the choice of design such as but not limited to desired computational rate power levels heat tolerances processing cycle budget input data rates output data rates memory resources data bus speeds and other design or performance constraints.

One or more aspects of at least one embodiment may be implemented by representative instructions stored on a machine readable storage medium. Such instructions may reside completely or at least partially within a main memory and or within a processor during execution thereof by the machine the main memory and the processor portions storing the instructions then also constituting a machine readable storage media. Programmable logic circuitry may have registers state machines etc. configured by the processor implementing the computer readable media. Such logic circuitry as programmed may then be understood to be physically transformed into a system falling within the scope of the embodiments described herein. Instructions representing various logic within the processor which when read by a machine may also cause the machine to fabricate logic adhering to the architectures described herein and or to perform the techniques described herein. Such representations known as cell designs or IP cores may be stored on a tangible machine readable medium and supplied to various customers or manufacturing facilities to load into the fabrication machines that actually make the logic or processor.

While certain features set forth herein have been described with reference to embodiments this description is not intended to be construed in a limiting sense. Hence various modifications of the implementations described herein as well as other implementations which are apparent to persons skilled in the art to which the present disclosure pertains are deemed to be within the spirit and scope of the present disclosure.

In one or more first embodiments a computer implemented method of enhancing an image includes scoring based on a filtering criteria individual pixel values of image data representing an image frame at an input image resolution. The method includes downsampling the image data to a representation of the image frame having a reduced resolution lower than the input image resolution. The method includes filtering the downsampled image data. The method includes upsampling the filtered downsampled image data back to the input image resolution. The method includes blending the input image data with the upsampled filtered image data as a function of the pixel scoring.

In furtherance of the first embodiment blending the input image data with the filtered image data further comprises blending at least one of a luma value or a chroma value of individual pixels in the input image data with the luma or chroma value of corresponding pixels in the upsampled filtered image data.

In furtherance of the first embodiment scoring pixels within the image frame further comprises determining a skin tone detection score for individual pixels of the input image. Blending the input image data with the filtered image data as a function of the pixel scoring further comprises modulating a weighting of the input image data relative to the filtered image data for the individual pixels as a function of each pixel skin tone detection score.

In furtherance of the embodiment immediately above blending the input image data with the filtered image data as a function of the pixel scoring further comprises interpolating between a value of a pixel in the input image data and a value of the pixel in the filtered image data based on the skin tone detection score for the pixel.

In furtherance of the embodiment immediately above linearly interpolating between the value of a pixel in the input image data and a value of the pixel in the filtered image data based on the skin tone detection score for the pixel further comprises determining a weighted sum of the value of the pixel in the input image data and the value of the pixel in the filtered image data the two pixel values weighted complementarily by the skin tone detection score.

In furtherance of the embodiment immediately above the skin tone detection score is a value between 0 and 1 that is proportional to a probability the individual pixel comprises a skin tone.

In furtherance of the first embodiment filtering the down sampled image data further comprises smoothing a pixel value of the downsampled image based on values of the downsampled image pixels neighboring the pixel being smoothed with a bilateral filter.

In furtherance of the embodiment immediately above filtering the down sampled image data further comprises performing a recursive bilateral filtering of pixel values in the downsampled image.

In furtherance of the first embodiment the input image data comprises pixel values in a YUV color space. Downsampling the image data further comprises at least a 4 resolution reduction from the input image resolution. Upsampling the image data further comprises at least a 4 resolution increase from the downsampled image resolution.

In furtherance of the first embodiment the method further includes retrieving the input image data from a buffer storing at least one of a decoded representation of the image or a captured image exposed at the input image resolution by a camera module. The method further includes converting prior to scoring the pixels the input image data from RGB color space to YUV color space. The method further includes storing the blended image data to a memory.

In furtherance of the embodiment immediately above the method further includes outputting the blended image data from the memory to at least one of a display device or an encoder.

In furtherance of the embodiment above the method further includes writing a stream of consecutively exposed image data frames from a camera hardware module CM to the buffer at a video frame rate. The method further includes performing each of the pixel scoring image data downsampling image data upscaling image data filtering and image data blending on each consecutively exposed video data frame at least at the video frame rate.

In one or more second embodiments a computerized image enhancement system includes a detection module coupled to receive input image data representing an image frame at an input image resolution the detection module including logic to determine a skin tone detection score for individual pixels of the image data. The system includes a downsampling module coupled to receive the input image data the downsampling module including logic to downsample the image data to a representation of the image frame having a reduced resolution lower than the input image resolution. The system includes a filtering module coupled to receive the downsampled image data the filtering module including logic to smooth the downsampled image data. The system includes an upsampling module coupled to receive the filtered downsample image data the upsampling module including logic to upsample the filtered downsampled image data back to the input image resolution. The system includes a blending module coupled to receive the input image data the skin tone detection scores and the upsampled filter image data wherein the blending module includes logic to blend the input image data with the upsampled filtered image data as a function of the skin tone detection scores.

In furtherance of the second embodiment the detection module is to determine a skin tone detection score that is proportional to a probability that an individual pixel comprises a skin tone. The blending module is to interpolate between a luma or chroma value of a pixel in the input image data and a luma or chroma value of the corresponding pixel in the filtered image data based on the skin tone detection score for the pixel.

In furtherance of the embodiment immediately above the filtering module includes logic to bilaterally filter individual pixel values in the downsampled image. The blending module include logic to linearly interpolate between a luma or chroma value of a pixel in the input image data and a luma or chroma value of the corresponding pixel in the filtered image data by determining a weighted sum of the luma or chroma value of the pixel in the input image data and the luma or chroma value of the pixel in the filtered image data the two luma or chroma values weighted complementarily by the skin tone detection score.

In furtherance of the second embodiment the system further includes an applications processor including a user space and kernel space the applications processor including logic circuitry to implement the filtering module and the blending module. The system further includes a camera hardware module CM coupled to the applications processor to generate a stream of input image data representing time consecutive image frames exposed at the input image resolution. The system further includes a memory coupled to the applications processor to store a representation of the blended image data output from the applications processor. The system further includes at least one of a display coupled to the memory to present the blended image data and an encoder coupled to the memory to encode the blended image data into a compressed representation.

In furtherance of the embodiment immediately above the detection module further comprises fixed function logic circuitry coupled to the applications processor the fixed function logic circuitry to output the skin tone detection scores to the applications processor.

In one or more third embodiment one or more computer readable storage media has instructions stored thereon which when executed by a processor cause the processor to perform a method including scoring based on a filtering criteria individual pixel values of image data representing an image frame at an input image resolution. The instructions further cause the processor to downsample the image data to a representation of the image frame having a reduced resolution lower than the input image resolution. The instructions further cause the processor to filter the downsampled image data. The instructions further cause the processor upsample the filtered downsampled image data back to the input image resolution. The instructions further cause the processor blend the input image data with the upsampled filtered image data as a function of the pixel scoring.

In furtherance of the third embodiment the media further store instructions thereon which when executed by a processor cause the processor to score the pixels by determining a skin tone detection score between 0 and 1 that is proportional to a probability the individual pixel comprises a skin tone. The instructions further cause the processor to filter the downsampled image data by smoothing a pixel value of the downsampled image based on a value of one or more downsampled image pixel neighboring the pixel being smoothed. The instructions further cause the processor to blend the input image data with the upsampled filtered image data by blending at least one of a luma value or a chroma value of individual pixels in the input image data with the luma or chroma value of corresponding pixels in the upsampled filtered image data.

In furtherance of the third embodiment the media further store instructions thereon which when executed by a processor cause the processor to blend at least one of a luma value or a chroma value of individual pixels in the input image data with the luma or chroma value of corresponding pixels in the upsampled filtered image data by determining a weighted sum of the luma or chroma value of the pixel in the input image data and the luma or chroma value of the pixel in the filtered image data the two luma or chroma values weighted complementarily by the skin tone detection score.

In furtherance of the embodiment immediately above the media further store instructions thereon which when executed by a processor cause the processor to smooth a pixel value of the downsampled image by performing a bilateral filtering of individual pixel values in the downsampled image.

In furtherance of the third embodiment the media further store instructions thereon which when executed by a processor cause the processor to retrieve the input image data from a buffer storing at least one of a decoded representation of the image or a captured image exposed at the input image resolution by a camera module. The instructions further cause the processor to convert prior to scoring the pixels the input image data from RGB color space to YUV color space. The instructions further cause the processor to store the blended image data to a memory.

In one or more fourth embodiment one or more computer readable storage media has instructions stored thereon which when executed by a processor cause the processor to perform any one of the first embodiments.

In one or more fifth embodiment a video camera platform includes an image processing means to perform any one of the first embodiments. The platform further includes a camera hardware module CM to generate a stream of input image data representing time consecutive image frames exposed at the input image resolution. The platform further includes an electronic memory to store the blended image data.

In furtherance of the fifth embodiment the image processing means further includes a detection means to receive input image data representing an image frame at an input image resolution and to determine a skin tone detection score for individual pixels of the image data. The image processing means further includes a downsampling means to receive the input image data and to downsample the image data to a representation of the image frame having a reduced resolution lower than the input image resolution. The image processing means further includes a filtering means coupled to receive the downsampled image data and to smooth the downsampled image data. The image processing means further includes an upsampling means to receive the filtered downsample image data and to upsample the filtered downsampled image data back to the input image resolution. The image processing means further includes a blending means coupled to receive the input image data the skin tone detection scores and the upsampled filter image data and to blend the input image data with the upsampled filtered image data as a function of the skin tone detection scores.

In furtherance of the embodiment immediately above the platform further includes a camera hardware module CM coupled to the applications processor to generate a stream of input image data representing time consecutive image frames exposed at the input image resolution. The platform further includes an electronic memory to store the blended image data output from the applications processor. The platform further includes at least one of a display to present the blended image data or an encoder to encode the blended image data into a compressed representation.

It will be recognized that the embodiments are not limited to the exemplary embodiments so described but can be practiced with modification and alteration without departing from the scope of the appended claims. For example the above embodiments may include specific combination of features. However the above embodiments are not limited in this regard and in embodiments the above embodiments may include undertaking only a subset of such features undertaking a different order of such features undertaking a different combination of such features and or undertaking additional features than those features explicitly listed. Scope should therefore be determined with reference to the appended claims along with the full scope of equivalents to which such claims are entitled.

