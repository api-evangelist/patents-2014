---

title: Voice recognition virtual test engineering assistant
abstract: System and method of systems and methods of controlling an IC test equipment in response to verbal commands issued by test equipment users. A control apparatus according to the present disclosure includes a speech detection device operable to detect verbal commands and test control software configured to control operations of the test equipment. The control software is added with verbal command recognition capabilities. Program action commands defined in the test control software are associated with respective recognizable verbal commands. Upon a recognizable verbal command is detected, it is interpreted into the corresponding program action command which triggers the intended test program actions. The control apparatus may also have a gesture detection device, through which user gesture commands can be detected and interpreted into corresponding program actions commands.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09495266&OS=09495266&RS=09495266
owner: ADVANTEST CORPORATION
number: 09495266
owner_city: Tokyo
owner_country: JP
publication_date: 20140515
---
The present patent application claims priority to the provisional patent application No. 61 824 342 filed on May 16 2013 which is hereby incorporated by reference in its entirety.

The present disclosure relates generally to the field of semiconductor test equipments and more specifically to the field of test equipment control.

In semiconductor manufacturing an automatic test equipment is used to test an integrated circuit IC device known as the Device Under Test DUT or Unit Under Test UUT e.g. to characterize electrical properties detect abnormalities and evaluate product quality. During test operations test signals are provided to the DUT and the resultant output signals generated from the DUT are evaluated against expectation values.

An automated test equipment can be controlled by test control software running in an external control apparatus typically a personal computer. The control apparatus can execute test plans configured in the software in response to operators input and thereby generate control signals for the operations of the test equipment. The test control software can render a graphical user interface through which a user can provide instructions to control test operations such as selecting a test plan configuring a test setting test signal parameters etc.

Conventionally a user of the test equipment interacts with the test control software by using a monitor a keyboard and a mouse that are attached to the control apparatus. As the control apparatus is typically located some distance from the test equipment in a production facility e.g. in a different room a user is unable to simultaneously perform manual operations e.g. debugging the load board at the test head and interact with the control apparatus. Thus the user often feels tethered to the vicinity of the control apparatus.

Moreover the keyboard and mouse often superimpose an inefficient mechanism for using graphical user interface that the test engineer navigates often also using complex and cumbersome syntax in order to program and interact with the test control software.

In addition a control apparatus is usually a computer loaded with non work related application programs as well as the test control software. The computer is often misused by equipment operations for non work related activities e.g. Internet surfing and on line chatting etc.

Therefore it would be advantageous to provide an intuitive mechanism to facilitate user interactions with a control apparatus of a test equipment.

Provided herein are systems and methods of controlling a test equipment in response to verbal commands issued by one or more test equipment users. A control apparatus according to the present disclosure includes a speech detection device operable to detect verbal commands and test control software configured to control operations of the test equipment. The control software is added with verbal command recognition capabilities. Program action commands defined in the test control software are associated with respective recognizable verbal commands. Upon a recognizable verbal command being detected it is interpreted into the corresponding program action command which triggers the intended test program actions. Feedback confirmation may be employed. The control apparatus may also have a gesture detection device through which user gesture commands can be detected and interpreted into corresponding program actions commands.

As a test equipment operator can advantageously issue verbal commands to the control apparatus remotely using embodiments of the present disclosure the operator can advantageously perform manual diagnosis near the test equipment and control a test operation through the test control software at the same time. In addition verbal commands can be designed to be simple and intuitive eliminating the need for operators to memorize complex and error prone syntax. Further the usage of verbal gesture commands bypasses the need for a keyboard and mouse to control the test equipment. A control apparatus may be used in a product facility without a keyboard and mouse eliminating operator potential mischievous unwanted behavior and thereby improving productivity.

In one embodiment of the present disclosure a computer implemented method of controlling a test equipment for Integrated Circuit IC devices comprises 1 receiving first indications of a verbal command issued by a user 2 interpreting the first indications into a program action command recognizable by a device diagnostic program wherein the device diagnostic program is configured to control the test equipment to perform test procedures on electrical characteristics of one or more integrated circuit IC devices and 3 providing the program action command to the device diagnostic program.

The method may further comprise rendering a graphical user interface GUI on a display device wherein the GUI is configured to display the program action command on the display device subsequent to the interpreting and receive a user confirmation before the providing. The GUI may be configured to display a help menu comprising a plurality of program action commands recognizable by the device diagnostic program and respective audio commands associated therewith.

The method may further comprise receiving second indications of a gesture command issued by a user the second indications received via an imaging device interpreting the second indications into the program action command and providing the program action command to the device diagnostic program.

The verbal command may start with a cue phrase indicating an association between the verbal command and the device diagnostic program. The program action command may cause the device diagnostic program to render a request for a parameter range input. The method may further comprise receiving third indications of a first limit and a second limit that are issued by a user and converting the indications to the parameter range input.

The method may further comprise receiving fourth indications of facial features of a user wherein the facial features are detected via an image device and authenticating the user to use the device diagnostic program based on the third indications before the interpreting.

In another embodiment of the present disclosure an electronic test system comprises a test apparatus configured to in response to control signals provide test input signals to an electronic device under test and collect test output signals from the electronic device a first communication channel a control system coupled to the test equipment via the first communication channel. The control system comprises a speech detection assembly configured to detect a speech event and generate first signals upon detection of the speech event a processor and memory coupled to the processor and comprising instructions that when executed by the processor causes the processor to perform a method of controlling the test apparatus responsive to user commands. The instructions comprise 1 a speech recognition module configured to generate a speech recognition result in response to the first signals 2 a voice command recognition module configured to determine a first program action command in response to the recognition result and 3 a diagnostic control module operable to control the test apparatus and configured to perform one or more program actions responsive to the program action command.

In another embodiment of the present disclosure a control system for controlling a test equipment comprises a bus a voice detection unit coupled to the bus and configured to detect voice commands issued from users and generate first signals responsive to the voice commands a processor coupled to the bus memory coupled to the processor and comprising instructions. The instructions when executed by the processor cause the processor to perform a method comprising interpreting the first signals into corresponding program action commands that are actionable by a device diagnostic program wherein the device diagnostic program is configured to control operations of the test equipment and providing the program action commands to the device diagnostic program.

This summary contains by necessity simplifications generalizations and omissions of detail consequently those skilled in the art will appreciate that the summary is illustrative only and is not intended to be in any way limiting. Other aspects inventive features and advantages of the present invention as defined solely by the claims will become apparent in the non limiting detailed description set forth below.

Reference will now be made in detail to the preferred embodiments of the present invention examples of which are illustrated in the accompanying drawings. While the invention will be described in conjunction with the preferred embodiments it will be understood that they are not intended to limit the invention to these embodiments. On the contrary the invention is intended to cover alternatives modifications and equivalents which may be included within the spirit and scope of the invention as defined by the appended claims. Furthermore in the following detailed description of embodiments of the present invention numerous specific details are set forth in order to provide a thorough understanding of the present invention. However it will be recognized by one of ordinary skill in the art that the present invention may be practiced without these specific details. In other instances well known methods procedures components and circuits have not been described in detail so as not to unnecessarily obscure aspects of the embodiments of the present invention. The drawings showing embodiments of the invention are semi diagrammatic and not to scale and particularly some of the dimensions are for the clarity of presentation and are shown exaggerated in the drawing Figures. Similarly although the views in the drawings for the ease of description generally show similar orientations this depiction in the Figures is arbitrary for the most part. Generally the invention can be operated in any orientation.

It should be borne in mind however that all of these and similar terms are to be associated with the appropriate physical quantities and are merely convenient labels applied to these quantities. Unless specifically stated otherwise as apparent from the following discussions it is appreciated that throughout the present invention discussions utilizing terms such as processing or accessing or executing or storing or rendering or the like refer to the action and processes of a computer system or similar electronic computing device that manipulates and transforms data represented as physical electronic quantities within the computer system s registers and memories and other computer readable media into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage transmission or client devices. When a component appears in several embodiments the use of the same reference numeral signifies that the component is the same component as illustrated in the original embodiment.

Overall embodiments of the present disclosure employ a control system capable of controlling test equipment in response to user rendered verbal and or gesture commands. The control system includes a test control program configured to control operations of the test equipment in response to user input. A user verbal gesture command can be detected via a speech gesture detection device and interpreted into a prescribed program action command executable by the test control program. As a result a test operation instructed by the program action command may be performed on a semiconductor device loaded on the test equipment.

A test equipment system herein may be any semiconductor device test equipment that is well known in the art. For example it may be a simple computer controlled digital multimeter or a complicated system containing complex test instruments real or simulated electronic test equipment capable of automatically testing and diagnosing faults in sophisticated electronic packaged parts or on wafer testing including System On Chips SoCs and Integrated Circuits ICs . A test control program herein is a software program customized for the associated test equipment.

If the speech is recognized then a verbal command is identified at based on the signals. At the verbal command is interpreted into a program action command executable by the test control program. At the identified program action command is optionally presented to the user for verification to proceed. For example the identified program action command may be displayed in a display device or repeated through a speaker.

If the user confirms at that the identified program action command is intended by the user speech a corresponding program action is performed at . Some program action commands may directly result in generation of control signals controlling the operation of test equipment e.g. applying test signals on the devices under test. Other program actions may be used as user input to prompt other types of program actions as defined in the program such as opening a diagnosis function module or to input parameters etc.

In some embodiments the control apparatus is equipped with a gesture recognition mechanism coupled to the test control program. Similar with verbal command recognition a user gesture can be recognized and interpreted as a command executable by the test control program. In some embodiments the control apparatus is equipped with an imaging device and a facial recognition program where a user s facial features can be detected and recognized to authenticate the user for using the test control system including the verbal gesture command control.

The recognition level programs collaborate to translate the detected speech gesture into text. This level includes driver programs or drivers recognition application programming interfaces APIs and recognition applications for a microphone a gesture detector and a camera. The drivers enable the user input devices e.g. microphone camera and gesture detector to interact with the operating system of the control apparatus. The recognition APIs provide a programming interface for program developers to program the speech gesture facial recognition program .

The respective recognition applications process an input speech gesture element into corresponding text. The speech recognition application may carry any audio processing feature that is well known in the art such as natural language processing automatic correction dictation disambiguation interactive tutorial personalization adaption support for multiple languages acoustic noise suppression echo cancellation beam formation to identify the current sound source etc. The gesture recognition application may utilize any feature that is well known in the art such as automatic detection and localization 3D gesture recognition body pose estimation motion tracking feature extraction real time reaction etc.

The interpretation level has a GUI module and interpretation modules for verbal commands gesture commands and facial features respectively. The translated text from level is fed to a suitable command interpretation module in the command interpretation level and is interpreted into a program action command recognizable by the test control program . The interpretation processes can be implemented in any suitable method or process that is well known in the art. As to be described in greater detail the GUI module can render a GUI e.g. for displaying identified program action commands and for receiving user adjustment on various features in the recognition application programs .

The program action command identified from the interpretation level is then provided to a test control program for execution. The test control program interacts with the interpretation level through the control software API . In effect the test control program can be controlled by a user verbal gesture command.

Various functionalities described in can be combined into an integrated program or partitioned and implemented as separate modules. As will be appreciated by those with ordinary skill in the art the various programs described in can be implemented in any one or more suitable programming languages that are known to those skilled in the art such as C C Java Python Perl C VB VBS etc.

If a detected speech event is recognized at the speech is processed as a verbal command at and then translated into one of the selected program action commands recognizable by the test control program in . In this example the program action commands assigned with verbal commands includes loading test plan unloading test plan opening Wavescope tool opening Wave Logic Analyzer tool retesting SBCMD level configuration running a script closing the test control program disconnecting the verbal control. It will be appreciated that any user instruction or input e.g. setting test parameters defined in the test control program can be selected and assigned with one or more verbal gesture commands. The selected program action commands may be most frequently used commands.

In the simplified form the control computer includes a CPU e.g. a dual core 2.66 GHz processor a GPU network circuits memory and I O interfaces . Depending on the individual configuration and type of the computer memory may be volatile such as RAM non volatile such as ROM flash memory etc. or some combination thereof. The peripherals including a microphone a camera and a motion detector are coupled to the computer through I O interfaces .

A test control program voice gesture detection device drivers and verbal gesture command recognition interpretation programs are stored in a memory device and runs on an operation system. Functionalities of the programs are described in greater detail with reference to . The operation system may be any suitable operation system OS such as Windows Embedded POSREADY7 Windows 7 Windows 8 Consumer Preview or Windows Embedded Standard 7 etc. The CPU can execute the programs based on user instructions including those issued by voice or gesture as described above. Thereby control signals can be determined and conveyed to the test equipment through a communication channel .

The test equipment includes a plurality of test modules A B . . . N. Each module is connected with terminals of a device under test DUT and can perform testing on the DUT based on the control signals generated by the control system .

For instance a test module can generate a test signal from the test data on the basis of a sequence predetermined by the test control program and provides the test signal to the DUT terminals. In response the DUT can generate an output signal which is compared with an expectation value. Then the test module can send the output signal data and the expectation values back to the control computer .

The control computer may also comprise an optional graphics subsystem for presenting information to the computer user e.g. by displaying information on an attached display device connected by a video cable. According to embodiments of the present disclosure the graphics subsystem may be coupled directly to the display device through the video cable. In alternate embodiments display device may be integrated into the computing system e.g. a laptop or touchpad and does not require a video cable.

Additionally the control computer may also have additional features and functionalities. For example computing system may also include additional storage media removable and or non removable including but not limited to magnetic or optical disks or tape. Computer storage media includes volatile and nonvolatile removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data.

The control computer also includes an optional alphanumeric input device an optional cursor control or directing device and one or more signal communication interfaces input output devices e.g. a network interface card . Optional alphanumeric input device can communicate information and command selections to central processor. Using network circuits and a communication interface the control computer can be communicatively coupled to other computer systems over a communication network such as the Internet or an intranet e.g. a local area network or can receive data e.g. a digital television signal .

It will be appreciated that any suitable type of sensing mechanism of the speech detection device e.g. a microphone or gesture detection device can be used to receive user commands for purposes of practicing the present disclosure. The gesture detection device may be capable of recognizing bodily motion or static gestures such as formed by a hand or face. The gesture detection device may have a standard 2D camera wired gloves depth aware cameras stereo camera or remote controllers.

The detection devices may be built in devices of the control computer separate peripherals attachable to the control computer through USB ports or components of an integrated peripheral e.g. Microsoft Kinect . In some embodiments the speech detection device or gesture detection device are capable of communicating with the control compute through wireless channels so that a user can carry them around.

The GUI includes a status text box for displaying information regarding verbal command recognitions or recognition failures and program actions that are invoked by detected verbal gesture commands. Two slide bars allow users to adjust speech recognition confidence according to their individual traits of voices. The Help GUI button allows a user to bring up a verbal command reference manual as to be described in greater detail below. The Connect button allows the user to connect and initialize the accessory peripheral and initialize the associated speech recognition program. The Disconnect button allows the users to disconnect the accessory peripheral. The Log check box allows users to log status information to a file. The Word Wrap check box Select All button Copy button and Clear button allow users to manipulate the text displayed in the status text box .

In this example two text lines and are displayed in the status text box upon detection of a verbal command e.g. Anna please load the Testplan. Line displays date of the recognition confidence level. Line displays the program action command Loading Test Plan translated from the verbal command.

Upon receiving a program action command the test control program may correspondingly render a GUI window to display information regarding the testing processes and results. is a screenshot of an exemplary GUI prompted by a program action command that is translated from a verbal command in accordance with an embodiment of the present disclosure. The test line shows the identified test plan named testplan is being loaded.

A test control program may allow users to compile a series of program actions into a script file e.g. a script based command SBCMD . A verbal command calling out the script file can effectively invokes all the program actions defined therein. For example a script may aggregate instructions for the test equipment to run a sequence of measurements on a DUT including e.g. power consumption continuity voltage thresholds timing waveforms and etc. is a screenshot of a GUI window showing the program actions responsive to a verbal command calling for a script based command in accordance with an embodiment of the present disclosure.

Although certain preferred embodiments and methods have been disclosed herein it will be apparent from the foregoing disclosure to those skilled in the art that variations and modifications of such embodiments and methods may be made without departing from the spirit and scope of the invention. It is intended that the invention shall be limited only to the extent required by the appended claims and the rules and principles of applicable law.

