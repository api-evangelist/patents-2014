---

title: Method and system for garbage collection in a storage system based on longevity of stored data
abstract: A method for managing data. The method includes receiving a first request to write data to persistent storage and in response to the first request, writing the data to a short-lived block in the persistent storage, where the data is short-lived data or data of unknown longevity. The method further includes performing a modified garbage collection operation that includes: selecting a first frag page in a first block, determining that the first frag page is live, and migrating, based on the determination that the first frag page is live, the first frag page to a long-lived block in the persistent storage, where the long-lived block is distinct from the short-lived block and wherein the long-lived block does not include any short-lived data.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09600409&OS=09600409&RS=09600409
owner: EMC IP HOLDING COMPANY LLC
number: 09600409
owner_city: Hopkinton
owner_country: US
publication_date: 20140829
---
In a storage system it is often the case that to write one block of data on average half a block of data requires migration. As a result writing data to the storage system introduces significant latency in the system and consequently reduces the overall performance of the system. In order to manage data in a storage system a garbage collector is typically used to reclaim memory from data that is no longer in use.

In general in one aspect the invention relates to a non transitory computer readable medium comprising instructions which when executed by a processor perform a method the method including receiving a first request to write data to persistent storage in response to the first request writing the data to a short lived block in the persistent storage where the data is short lived data and performing a modified garbage collection operation including selecting a first frag page in a first block determining that the first frag page is live migrating based on the determination that the first frag page is live the first frag page to a long lived block in the persistent storage where the long lived block is distinct from the short lived block and wherein the long lived block does not include any short lived data.

In general in one aspect the invention relates to a method for managing data. The method includes receiving a first request to write data to persistent storage in response to the first request writing the data to a short lived block in the persistent storage wherein the data is one selected from a group consisting of short lived data and data of unknown longevity and performing a modified garbage collection operation that includes selecting a first frag page in a first block determining that the first frag page is live migrating based on the determination that the first frag page is live the first frag page to a long lived block in the persistent storage where the long lived block is distinct from the short lived block and wherein the long lived block does not include any short lived data.

In general in one aspect the invention relates to a storage appliance including persistent storage a non transitory computer readable medium comprising instructions and a processor configured to execute the instructions where the instructions when executed by the processor perform the method. The method includes a receiving a first request to write data to the persistent storage b in response to the first request writing the data to a short lived block in the persistent storage wherein the data is one selected from a group consisting of short lived data and data of unknown longevity and c performing a modified garbage collection operation comprising selecting a first frag page in a first block determining that the first frag page is live migrating based on the determination that the first frag page is live the first frag page to a long lived block in the persistent storage wherein the long lived block is distinct from the short lived block and wherein the long lived block does not include any short lived data wherein at least a portion of the modified garbage collection operation is performed in parallel with at least one selected from a group consisting of a and b .

Other aspects of the invention will be apparent from the following description and the appended claims.

Specific embodiments of the invention will now be described in detail with reference to the accompanying figures. In the following detailed description of embodiments of the invention numerous specific details are set forth in order to provide a more thorough understanding of the invention. However it will be apparent to one of ordinary skill in the art that the invention may be practiced without these specific details. In other instances well known features have not been described in detail to avoid unnecessarily complicating the description

In the following description of any component described with regard to a figure in various embodiments of the invention may be equivalent to one or more like named components described with regard to any other figure. For brevity descriptions of these components will not be repeated with regard to each figure. Thus each and every embodiment of the components of each figure is incorporated by reference and assumed to be optionally present within every other figure having one or more like named components. Additionally in accordance with various embodiments of the invention any description of the components of a figure is to be interpreted as an optional embodiment which may be implemented in addition to in conjunction with or in place of the embodiments described with regard to a corresponding like named component in any other figure.

In general embodiments of the invention relate to a method and system in which longevity of data is used to sort the data within or written to a storage appliance. Specifically embodiments of the invention relate to storing data that is persistent separately from data that is short lived. By sorting data based on longevity write amplitude in the storage appliance may be decreased in accordance with one or more embodiments of the invention. In one or more embodiments of the invention write amplitude corresponds to the number of migrations of data in the storage appliance required for each write to the storage appliance. Because the number of program erase cycles may decrease the lifetime of a solid state memory module there is a performance benefit by decreasing the write amplitude.

In one or more embodiments of the invention a client is any system or process executing on a system that includes functionality to issue a read request to the storage appliance and or issue a write request to the storage appliance. In one or more embodiments of the invention the clients may each include a processor not shown memory not shown and persistent storage not shown .

In one or more embodiments of the invention a client is operatively connected to the storage appliance . In one or more embodiments of the invention the storage appliance is a system that includes volatile and persistent storage and is configured to service read requests and or write requests from one or more clients . The storage appliance further is configured to implement the modified garbage collection operation which includes migrating any table of contents TOC entries and frags to a long lived block in a manner consistent with the modified garbage collection operation described below see e.g. . The storage appliance is further configured to store data from write requests in the storage appliance in a manner consistent with the method described below see e.g. .

In one or more embodiments of the invention the storage appliance includes a processor memory and one or more solid state memory modules e.g. solid state memory module A A solid state memory module B B solid state memory module N N .

In one or more embodiments of the invention memory may be any volatile memory including but not limited to Dynamic Random Access Memory DRAM Synchronous DRAM SDR SDRAM and DDR SDRAM. In one or more embodiments of the invention memory is configured to temporarily store various data including data for TOC entries and frags prior to such data being stored in a solid state memory module e.g. A B N . Memory is operatively connected to the processor .

In one or more embodiments of the invention the processor is a group of electronic circuits with a single core or multi cores that are configured to execute instructions. The processor is configured to execute instructions to implement one or more embodiments of the invention where the instructions are stored on a non transitory computer readable medium not shown that is located within or that is operatively connected to the storage appliance . Alternatively the storage appliance may be implemented using hardware. The storage appliance may be implemented using any combination of software and or hardware without departing from the invention.

In one or more embodiments of the invention the storage appliance is configured to create and update an in memory data structure where the in memory data structure is stored in the memory . In one or more embodiments of the invention the in memory data structure includes mappings direct or indirect between logical addresses and physical addresses. In one or more embodiments of the invention the logical address is an address at which the data appears to reside from the perspective of the client . In one or more embodiments of the invention the logical address is or includes a hash value generated by applying a hash function e.g. SHA 1 MD 5 etc. to an n tuple. In one or more embodiments of the invention the n tuple is where the object ID defines an object e.g. file and the offset ID defines a location relative to the starting address of the object. In another embodiment of the invention the n tuple is where the birth time corresponds to the time when the file identified using the object ID was created. Alternatively the logical address may include a logical object ID and a logical byte address or a logical object ID and a logical address offset. In another embodiment of the invention the logical address includes an object ID and an offset ID. Those skilled in the art will appreciate that multiple logical addresses may be mapped to a single physical address and that the logical address is not limited to the above embodiments.

In one or more embodiments of the invention the physical address may correspond to a location in the memory or a location in a solid state memory module e.g. A B N . In one or more embodiments of the invention the in memory data structure may map a single hash value to multiple physical addresses if there are multiple copies of the data in the storage appliance .

In one or more embodiments of the invention the solid state memory modules e.g. A B N correspond to any data storage device that uses solid state memory to store persistent data. In one or more embodiments of the invention solid state memory may include but is not limited to NAND Flash memory NOR Flash memory Magnetic RAM Memory M RAM Spin Torque Magnetic RAM Memory ST MRAM Phase Change Memory PCM or any other memory defined as a non volatile Storage Class Memory SCM .

Those skilled in the art will appreciate that the invention is not limited to the configuration shown in .

The following discussion describes embodiments of the invention implemented using solid state memory devices. Turning to shows a solid state memory module of a data storage device not shown in accordance with one or more embodiments of the invention. The data storage device not shown may include multiple solid state memory modules. The solid state memory module includes one or more blocks. In one or more embodiments of the invention a block is the smallest erasable unit of storage within the solid state memory module .

In one or more embodiments of the invention rewriting a page within a block requires the entire block to be rewritten. A block has a limited number of program e.g. write erase cycles where a program erase cycle includes writing one or more pages to the block then erasing the entire block. Pages in a block may be migrated to another block to maintain a similar number of program erase cycles across the blocks referred to as wear leveling .

In one or more embodiments of the invention a long lived block is a block that stores persistent data where persistent data is data whose longevity outlasts at least one garbage collection cycle. Said another way data is determined to be persistent data also referred to as long lived data if the data is associated with a live page see . In one or more embodiments of the invention a garbage collection cycle corresponds to iterating through the blocks to perform a modified garbage collection operation see to each block in the storage appliance. In one or more embodiments of the invention a short lived block is a block that either stores short lived data or data that has an unknown longevity. Data that has an unknown longevity is assumed to be short lived in accordance with one or more embodiments of the invention. In one or more embodiments of the invention short lived data in short lived blocks are stored separately from persistent data in long lived blocks. In one or more embodiments of the invention short lived data are likely to be outdated or obsolete i.e. no longer in use prior to the end of a garbage collection cycle. Said another way short lived data is data that is not likely migrated in a modified garbage collection operation see because the data is dead e.g. outdated obsolete etc. . Alternatively while data with unknown longevity is assumed to be short lived it is also possible that the data is long lived data e.g. the data with unknown longevity would be considered long lived data if it located in a live page during the garbage collection process see e.g. step .

This process is repeated until there is only one page remaining in the block to fill. At this point a TOC page is created and stored in the last page of the block . Those skilled in the art will appreciate that the total cumulative size of the TOC entries in the TOC page may be less than the size of the page. In such cases the TOC page may include padding to address the difference between the cumulative size of the TOC entries and the page size. Finally because there are other TOC pages in the block TOC page includes a reference to one other TOC page .

As shown in the TOC pages are linked from the top of the block to bottom of the page such that the TOC page may be obtained by following a reference from a TOC page that is above the TOC page. For example TOC page may be accessed using the reference in TOC page .

Those skilled in the art will appreciate that while block only includes frag pages and TOC pages block may include pages e.g. a page that includes parity data other than frag pages and TOC pages without departing from the invention. Such other pages may be located within the block and depending on the implementation interleaved between the TOC pages and the frag pages.

Those skilled in the art will appreciate that the TOC entry may include additional or fewer fields than shown in without departing from the invention. Further the fields in the TOC entry may be arranged in a different order and or combined without departing from the invention. In addition while the fields in the TOC entry shown in appear to all be of the same size the size of various fields in the TOC entry may be non uniform with the size of any given field varying based on the implementation of the TOC entry.

Turning to the flowcharts while the various steps in the flowchart are presented and described sequentially one of ordinary skill will appreciate that some or all of the steps may be executed in different orders may be combined or omitted and some or all of the steps may be executed in parallel. In one or more embodiments of the invention one or more steps shown in may be performed in parallel with one or more of the other steps shown in . More specifically write requests received in and a modified garbage collection operation in may occur in parallel. Therefore sorting data within the storage appliance based on longevity of the data may result in potentially coalescing data from write requests if known to be persistent data and migrated data from the modified garbage collection operation in accordance with one or more embodiments of the invention.

Turning to shows a flowchart for receiving a write request in accordance with one or more embodiments of the invention.

In Step a write request to write data to the storage appliance is received from a client. The request may include the data to be stored or may include a reference to the data to be stored. The request may take any form without departing from the invention.

In Step a determination is made about whether the data is persistent data. In one or more embodiments of the invention determining that data is persistent data may be done via an application programming interface API that communicates the data is persistent to the storage appliance. For example a tag or bits may be added to the write request or to the data itself that the storage appliance recognizes as persistent. Communicating that data is persistent to the storage appliance may involve other methods without departing from the invention.

If a determination is made that the data is persistent data the method may proceed to Step . In Step a long lived block is identified. In one or more embodiments of the invention any free or empty block may be selected as a long lived block. Additionally or alternatively a block whose program erase cycle is above a certain threshold may be selected as a long lived block for wear leveling the blocks. In this case persistent data written to the long lived block has a high likelihood of remaining in the block thereby reducing the program erase cycles of the long lived block. Alternate methods to select a long lived block may be used without departing from the invention.

In Step the data is written to the long lived block. In one or more embodiments of the invention data is stored as a frag typically as part of a frag page in the long lived block. A TOC entry is generated and stored for the frag typically as part of a TOC page in the long lived block.

Returning to Step if a determination is made that the data is not persistent data the method may proceed to Step . In one or more embodiments of the invention if the data is not persistent data either the data is known as short lived e.g. via an API or the data has an unknown longevity. The data is stored separately in a short lived block from the persistent data in the long lived block in accordance with one or more embodiments of the invention. Said another way there is no overlap between persistent data in the long lived block and data in the short lived block. In Step a short lived block is identified. In one or more embodiments of the invention any free or empty block may be selected as a short lived block. Additionally or alternatively a block whose program erase cycle is below a certain threshold may be selected as a short lived block for wear leveling the blocks. In this case data written to the short lived block has a high likelihood of being erased thereby increasing the program erase cycles of the short lived block. Alternate methods to select a short lived block may be used without departing from the invention.

In Step data is written to a short lived block. In one or more embodiments of the invention data is stored as a frag typically as part of a frag page in the short lived block. A TOC entry is generated and stored for the frag typically as part of a TOC page in the short lived block.

Turning to shows a flowchart for a modified garbage collection operation in accordance with one or more embodiments of the invention. As described above the modified garbage collection operation may occur in parallel to write requests received by the storage appliance.

In Step a block in the storage appliance is selected. In Step a TOC page in the block is selected. In Step a TOC entry in the TOC page in the block is selected.

In Step a derived physical address using information in the TOC entry is generated. In one or more embodiments of the invention the derived physical address for a frag is defined as the following n tuple where the page ID and byte are stored in the TOC entry and the remaining data in the n tuple may be derived from the page ID and byte.

In Step a stored physical address in an in memory data structure is looked up using an n tuple in the TOC entry. In one or more embodiments of the invention an in memory data structure includes a mapping between an n tuple e.g. and a stored physical address of the frag.

In Step a determination is made about whether the derived physical address matches the stored physical address. In one or more embodiments of the invention the derived physical address matches the stored physical address if the frag associated with the TOC entry is live e.g. up to date in use . In one or more embodiments of the invention the derived physical address does not match the stored physical address if the frag associated with the TOC entry is dead e.g. no longer in use outdated obsolete . If a determination is made that the derived physical address matches the stored physical address the method may proceed to Step otherwise the method may proceed to Step . In Step the frag associated with the TOC entry is marked as live. For example one or more bits may be associated with the frag to mark the frag as live.

In Step the frag associated with the TOC entry is marked as dead. For example one or more bits may be associated with the frag to mark the frag as dead.

In Step a determination is made about whether there are remaining TOC entries in the TOC page. In one or more embodiments of the invention the TOC pages includes one or more TOC entries. If a determination is made that there are remaining TOC entries in the TOC page the method may return to Step discussed above otherwise the method may proceed to Step .

In Step a determination is made about whether there are remaining TOC pages in the block. In one or more embodiments of the invention there may be one or more TOC pages in the block. If a determination is made that there are remaining TOC pages in the block the method may return to Step discussed above otherwise the method may proceed to Step . In Step a determination is made about whether all the pages in the block are marked as dead. If a determination is made that all the pages in the block are marked as dead the method may proceed to Step otherwise the method may proceed to Step . In Step the block is erased because no migration of data is required.

In Step a determination is made about whether there are remaining blocks in a solid state memory module. In one or more embodiments of the invention a solid state memory module includes one or more blocks. If a determination is made that there are remaining blocks in the solid state memory module the method may return to Step discussed above.

In Step a determination is made about whether all pages in the block are marked as live. If a determination is made that all pages in the block are marked as live the method may proceed to Step otherwise the method may proceed to Step . In Step a determination is made about whether wear leveling is required. As described above wear leveling balances the number of program erase cycles across the blocks in a solid state memory module. In one or more embodiments of the invention wear leveling may be required if the block has a program erase cycle value below a threshold. Said another way the block may require a program erase cycle to prevent another block with a higher program erase cycle from increasing their program erase cycle value. If a determination is made that wear leveling is required the method may proceed to Step otherwise the method may return to Step .

In Step each live page is migrated to a long lived block. In one or more embodiments of the invention each live page is considered persistent data because each live page outlasted at least one garbage collection cycle. In one or more embodiments of the invention any free or empty block may be selected as a long lived block. Additionally or alternatively a block whose program erase cycle is above a certain threshold may be selected as a long lived block for wear leveling the blocks. In this case persistent data written to the long lived block should remain in the block reducing the program erase cycles of the long lived block. Alternate methods to select a long lived block may be used without departing from the invention. In one or more embodiments of the invention data is rewritten as a frag typically as part of a frag page in the long lived block. A TOC entry is generated and stored for the frag typically as part of a TOC page in the long lived block. The method may then return to Step discussed above.

Referring to consider a scenario in which a first iteration of garbage collection occurs on block block block and block in parallel to receiving write requests W W W W W W and W where data written in W and W are persistent data. Block and Block are empty and available to write any migrated data or data from write requests.

Garbage collection operation occurs first on block in parallel to receiving write requests W W and W. Block is erased because each page in block is marked as dead. Block is selected randomly to write data from write requests W W and W. Additionally TOC entries associated with W W and W respectively are generated and stored as part of TOC page in block .

Garbage collection is then performed on block . The only live page that requires migration in block is page J. Block is randomly selected for migration of page J. Additionally a TOC entry associated with page J is generated and stored as part of TOC page in block . After the migration of page J block is erased. Write request W is then received. Block is randomly selected to write the data associated with W. Additionally a TOC entry associated with W is generated and stored as part of TOC page in block .

Garbage collection then occurs on block in parallel to receiving write requests W W and W. Pages Q O and N are the live pages in block that require migration. Pages Q and O and data associated with W W and W are randomly selected to migrate to block . Additionally TOC entries associated with Q O W W and W respectively are generated and stored as part of TOC page in block . Page N is randomly selected to migrate to block . A TOC entry associated with N is generated and stored as part of TOC page in block . After the migration of pages Q O and N Block is erased.

Finally garbage collection occurs at block in parallel to receiving write request W. All pages are live in block . Wear leveling of block is not required and so no migration occurs in block . W is randomly selected to write to block . Additionally a TOC entry associated with W is generated and stored as part of TOC page in block .

The garbage collection operation has cycled through each of the blocks i.e. block block block and block to migrate any live pages to either block or block . Further the write requests received in parallel to garbage collection are allocated to either block or block . Given a total of eight write requests four migrations are required in the first iteration.

Referring to consider a scenario in which a second iteration of garbage collection occurs after the first iteration discussed in . The second iteration of the garbage collection occurs on block block block and block in parallel to receiving write requests W W W W W W and W where W is long lived or persistent data. Block and Block are erased after the first iteration in and available to write any migrated data or data from write requests.

Garbage collection starts at block in parallel to receiving write requests W W W and W. Block was erased in the first iteration see and does not include any pages to migrate. Block is randomly selected to write the data associated with write requests W W W and W. Additionally TOC entries associated with W W W and W respectively are generated and stored as part of TOC page in block .

Garbage collection then occurs at block in parallel to receiving write request W. All pages that were live in block in the first iteration see remain live. As discussed above in wear leveling of block is not required and so once again no migration occurs in block . Block is randomly selected to write the data associated with W. Additionally a TOC entry associated with W is generated and stored as part of TOC page in block .

Garbage collection is then performed on block in parallel to receiving write requests W and W. Pages W and W are the live pages in block that require migration. Block is selected at random to write data associated with W in parallel to writing pages W and W. Additionally TOC entries associated with W W and W respectively are generated and stored as part of TOC page in block . Block is selected at random to write data associated with W. A TOC entry associated with W is also generated and stored as part of TOC page in block . After the migration of pages W and W Block is erased.

Finally garbage collection occurs at block . All pages are live in block . Wear leveling of block is not required and so no migration occurs in block .

Garbage collection has cycled through each of the blocks i.e. block block block and block to migrate any live pages to either block or block . Further the write requests received in parallel to the modified garbage collection operation are allocated to either block or block . Given a total of seven write requests eight migrations are required in the second iteration. Over the two iterations there are 12 migrations for 15 data writes. The write amplitude may then be calculated as 1 write 12 migrations 15 writes 1.8. Said another way for every write 0.8 additional writes are required.

Referring to consider a scenario in which a first iteration of a modified garbage collection operation occurs on block block block and block in parallel to receiving write requests W W W W W W and W where data written in W and W are persistent data. Block is selected as a short lived block and block is selected as a long lived block.

A modified garbage collection operation occurs first on block in parallel to receiving write requests W W and W. Block is erased because each page in block is marked as dead. Longevity of W W and W are unknown. Therefore W W and W are written to block short lived block . Additionally TOC entries associated with W W and W respectively are generated and stored as part of TOC page in block short lived block .

The modified garbage collection operation is then performed on block . The only live page that requires migration in block is page J. Because page J survives or outlasts garbage collection page J is likely persistent data. Page J is then migrated to block long lived block . Additionally a TOC entry associated with page J is generated and stored as part of TOC page in block long lived block . After the migration of page J block is erased. Write request W is then received. W is communicated as including persistent data through an application programming interface API . W is then written to block long lived block rather than block short lived block that is reserved for write requests with unknown longevity. Additionally a TOC entry associated with W is generated and stored as part of TOC page in block long lived block .

The modified garbage collection operation then occurs on block in parallel to receiving write requests W W and W. Pages Q O and N are the live pages in block that require migration. Once again since pages Q O and N are live when the garbage collection occurs pages Q O and N are likely persistent data. Longevity of data associated with write requests W W and W are unknown and likely short lived. Pages Q O and N are then migrated to block long lived block in parallel to writing W W and W to block short lived block . Additionally TOC entries associated with W W and W respectively are generated and stored as part of TOC page in block short lived block . TOC entries associated with pages Q O and N respectively are also generated and stored as part of TOC page in block long lived block . After the migration of pages Q O and N Block is erased.

Finally the modified garbage collection operation occurs at block in parallel to receiving write request W. All pages are live in block . Wear leveling of block is not required and so no migration occurs in block . Similarly to write request W write request W communicates through the API that W includes persistent data. W is then written to block long lived block . Additionally a TOC entry associated with W is generated and stored as part of TOC page in block long lived block .

The modified garbage collection operation has cycled through each of the blocks i.e. block block block and block to migrate any live pages to block long lived block . Further the write requests received in parallel to the modified garbage collection are allocated to block long lived block if the write request is known to include persistent data e.g. W W . Otherwise the write requests are allocated to block short lived block . Given a total of eight write requests four migrations are required in the first iteration.

Referring to consider a scenario in which a second iteration of a modified garbage collection operation occurs after the first iteration discussed in . The second iteration of the modified garbage collection operation occurs on block block block and block in parallel to receiving write requests W W W W W W and W where W is long lived or persistent data. Block that was erased in the first iteration see is selected as a short lived block. Block that was erased in the first iteration see is selected as a long lived block.

The modified garbage collection operation starts at block in parallel to receiving write requests W W W and W. Block was erased in the first iteration see and does not include any pages to migrate. Longevity of W W W and W are unknown. Therefore W W W and W are written to block short lived block . Additionally TOC entries associated with W W W and W respectively are generated and stored as part of TOC page in block short lived block .

The modified garbage collection operation then occurs at block in parallel to receiving write request W. All pages that were live in block in the first iteration see remain live. As discussed above in wear leveling of block is not required and so once again no migration occurs in block . Write request W is communicated as including persistent data through an API. W is written to block long lived block rather than block short lived block that is reserved for write requests with unknown longevity or known to be short lived. Additionally a TOC entry associated with W is generated and stored as part of TOC page in block long lived block .

The modified garbage collection is then performed on block in parallel to receiving write requests W and W. Both write requests W and W have data with unknown longevity and are likely short lived. Pages W and W are the live pages in block that require migration. Because pages W and W are live when the garbage collection occurs pages W and W are likely persistent data. Pages W and W are then migrated to block long lived block in parallel to writing W and W to block short lived block . Additionally TOC entries associated with W and W respectively are generated and stored as part of TOC page in block long lived block . TOC entries associated with W and W respectively are also generated and stored as part of TOC page in block short lived block . After the migration of pages W and W Block is erased.

Finally the modified garbage collection operation occurs at block . All pages are live in block . Wear leveling of block is not required and so no migration occurs in block .

The modified garbage collection operation has cycled through each of the blocks i.e. block block block and block to migrate any live pages to block long lived block . Further the write requests received in parallel to the modified garbage collection operation are allocated to block long lived block if the write request is known to include persistent data e.g. W . Otherwise the write requests are allocated to block short lived block .

Given a total of seven write requests two migrations are required in the second iteration. Over the two iterations there are 6 migrations for 15 data writes. The write amplitude may then be calculated as 1 write 6 migrations 15 writes 1.4. Said another way for every write 0.4 additional writes are required. The write amplitude of 1.4 achieved by sorting data based on longevity during a modified garbage collection operation while receiving write requests is an improvement to the write amplitude of 1.8 achieved by ignoring longevity of data during traditional garbage collection while receiving write requests.

One or more embodiments of the invention provide a system and method in which data stored in the storage appliance are sorted based on longevity of the data. In this manner all data known as persistent data are stored in long lived blocks while short lived data or data with unknown longevity are stored in short lived blocks. By arranging the data according to the various embodiments of the invention the storage appliance improves performance of a given solid state memory module or a subset thereof by decreasing data migration during garbage collection. By decreasing data migration during garbage collection write amplitude in the storage appliance may be minimized in accordance with one or more embodiments of the invention. Minimizing the write amplitude may result in a fewer number of program erase cycles of a solid state memory module because of decreased data migration for each write. Because the number of program erase cycles reduces the lifetime of a solid state memory module there is a performance gain by minimizing the write amplitude.

Further embodiments of the invention enable the creation of an in memory data structure which allows the storage appliance to access data in a single look up step. Said another way the storage appliance may use the in memory data structure to directly ascertain the physical address es of the data in the storage appliance. Using this information the storage appliance is able to directly access the data and does not need to traverse any intermediate metadata hierarchy in order to obtain the data.

One or more embodiments of the invention may be implemented using instructions executed by one or more processors in the system. Further such instructions may corresponds to computer readable instructions that are stored on one or more non transitory computer readable mediums

While the invention has been described with respect to a limited number of embodiments those skilled in the art having benefit of this disclosure will appreciate that other embodiments can be devised which do not depart from the scope of the invention as disclosed herein. Accordingly the scope of the invention should be limited only by the attached claims.

