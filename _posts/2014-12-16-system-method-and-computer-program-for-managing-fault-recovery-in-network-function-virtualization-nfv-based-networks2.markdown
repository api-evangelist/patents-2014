---

title: System, method, and computer program for managing fault recovery in network function virtualization (NFV) based networks
abstract: According to one aspect of the present invention there is provided a system, method, and computer program product for recovering from a network failure in a communication network using network function virtualization (NFV-based network), the method including: selecting a first network component of the NFV-based network, detecting at least one probable failure of the first network component, identifying at least one virtual network function (VNF) instance using the first network component, selecting a second network component to be used by same VNF for replacing the VNF instance in the first network component when the first network component is faulty, and securing at least one resource of the second network component for the VNF.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09645899&OS=09645899&RS=09645899
owner: Amdocs Development Limited
number: 09645899
owner_city: Limassol
owner_country: CY
publication_date: 20141216
---
This application claims the benefit of U.S. Provisional Application No. 61 918 597 filed Dec. 19 2013 U.S. Provisional Application No. 61 941 380 filed Feb. 18 2014 U.S. Provisional Application No. 61 981 116 filed Apr. 17 2014 U.S. Provisional Application No. 62 026 508 filed Jul. 18 2014 and U.S. Provisional Application No. 62 026 512 filed Jul. 18 2014 the entire contents of which are incorporated herein by reference.

The present invention relates to telecommunications and or data communications and more particularly to network function virtualization NFV of telecommunications networks.

Network Function Virtualization is a term or a name of a proposed architecture of telecom services as published by the European Telecommunications Standards Institute ETSI in a series of documents available from the ETSI website. NFV uses generic hardware platform and software adapted for the generic hardware platform. Thus NFV creates a network much more flexible and dynamic than a legacy communication network. In NFV based networks a Virtual Network Function VNF decouples the software implementation of the network function from the infrastructure resources it runs on by virtualization. A network service is based on one or more VNFs and or Physical Network Functions PNFs their interconnections and chaining definitions. The VNFs can be executed on almost any generic hardware processing facility. Therefore VNFs may be installed removed and moved between hardware facilities much more easily less costly and thus more frequently.

This flexibility and dynamics of the VNF based network complicates the means by which network availability is preserved. There is thus a need for addressing these and or other issues associated with the prior art.

According to one aspect of the present invention there is provided a system method and computer program product for recovering from a network failure in a communication network using network function virtualization NFV based network the method including selecting a first network component of the NFV based network detecting at least one probable failure of the first network component identifying at least one virtual network function VNF instance using the first network component selecting a second network component to be used by same VNF for replacing the VNF instance in the first network component when the first network component is faulty and securing at least one resource of the second network component for the VNF.

As shown in a first network component of a network function virtualization NFV based network is selected. See operation . Further at least one probable failure of the first network component is detected. See operation .

Additionally at least one virtual network function VNF instance using the first network component is identified. See operation . The at least one first VNF instance is associated with a VNF.

Furthermore a second network component is selected to be used by the VNF for replacing the VNF instance in the first network component when the first network component is faulty. See operation . Moreover at least one resource of the second network component is secured for the VNF. See operation .

In one embodiment the method may include verifying that the VNF is installed in the second network component for forming a backup for the VNF instance using the first network component.

In another embodiment the method may further include initiating a mirroring process maintaining in the second network component an updated copy of data associated with the VNF instance of the first network component. In this case the updated copy of data may enable initiating a copy of the VNF instance in the second network component with minimal delay.

Further in one embodiment the method may further include creating a plan for replacing upon failure of the first network component the VNF instance operating in the first network component with a VNF instance operating in the second network component. In another embodiment the method may include replacing upon failure of the first network component the VNF instance operating in the first network component with a VNF instance operating in the second network component.

Still yet in one embodiment the NFV based network may include a third network component. In this case at least one probable failure of the third network component may be detected. Additionally at least one VNF instance using the third network component may be identified. Further at least one resource of the second network component may be secured for the VNF. In this case the at least one resource secured for the VNF of the first network component of the NFV based network may be secured for the VNF of the third network component of the NFV based network.

In another embodiment at least one probable failure of the third network component may be detected. In addition at least one VNF instance using the third network component may be identified. Further a fourth network component may be selected to be used by same VNF for replacing the VNF instance in the third network component when the first network component is faulty and at least one resource of the fourth network component may be secured for the VNF. In this case at least one resource of the second network component and at least one resource of the fourth network component may be secured for both the VNFs of the first and third network components.

In the context of the present description the terms network and communication network refer to the hardware and software connecting one or more communication elements including wireline networks wireless networks and or combinations thereof.

The terms network function virtualization NFV and virtual network function NFV are described in a series of documents published by the European Telecommunications Standards Institute ETSI and available from the ETSI website. The term virtual network function or feature VNF refers to a particular implementation of a function a feature or a service provided by the network internally within the network or externally to a customer subscriber end user a terminal or a server. A VNF may include the software program implementation of the function or feature or service. The term VNF instance VNF I refers to a particular process or task executing the VNF program by a particular virtual machine or processor or computing facility and or used by a particular customer or subscriber end user terminal or server etc. .

The term service refers to any type of use such as a use case that a NFV based communication network may offer or provide to one or more communication elements. A service may include switching data or content between any number of elements providing content from a server to a communication element or between servers securing and protecting communication and content processing content provided by the customer or by a third party providing backup and redundancy etc. A service may be using partial functionality of a VNF or may include one or more VNFs and or one or more VNF instances forming a service sub network or interconnection model . In the context of the present description the term chain may refer to such service sub network such as a particular plurality of VNFs and or VNF instances associated with a particular service type or a service instance.

The term deployment when referring to hardware elements including processing elements memory elements storage elements connectivity communication elements etc. refer to the configuration or topology of these hardware elements creating the NFV based network. The term deployment when referring to software elements such a VNFs and VNF instances refers to the association between such software elements and hardware elements.

The term deployment optimizations refers to association of software and hardware elements in a manner that satisfies a particular set of requirements and or rules such as load related and performance related requirements or a manner that makes a better use of a particular hardware deployment such as by reducing operational cost.

The terms service deployment optimization or service optimization or chain optimization refer to optimizing the deployment of a service chain i.e. optimizing the deployment of one or more VNF instances making a particular service. The terms chain optimization and service optimization may thus be used interchangeably.

The term session refers to a communication connection between two or more entities that persists for a period of time during which data may be exchanged there between. A session may be implemented and managed by a session layer in the corresponding network protocol. The term session may include a network session and a logical session. The network session may be associated with the devices used to communicate while the logical session may be associated with the communicating parties users and may persist regardless of the communication means that the parties are using.

The term service continuity includes and applies to the terms session continuity and streaming continuity . Streaming refers to streaming media session or service such as sound including voice video multimedia animation etc. The term service usually applies to a group of VNFs or the functionality provided by the group of VNFs but may also apply to a single VNF or the functionality provided by the VNF . The term continuity indicates that the session or the service is not interrupted or that an interruption is short enough that a user is not aware of such interruption or that the interruption does not cause any loss of data or that the loss is handled in acceptable manner e.g. a few packets of speech lost but the conversation can continue etc. .

The term availability or service availability refers to a level of the service or a characteristic of the service in which the service provider should provide the service albeit possible hardware or software faults. For example the service provider may obligate to the customer to provide a particular level of processing power communication features such as bandwidth latency and jitter database consistency etc. Such level or characteristic of the service should be available to the customer even when a hardware component or a software component providing the service do not function properly. Providing availability may therefore require additional resources such as backup resources and or mirroring. Hence availability may also refer to the terms fault recovery and redundancy .

The term fault recovery refers to the process of recovering one or more of the network s services functions and features after a fault whether caused by a hardware malfunction a system crash a software bug or a security breech or fault. A hardware malfunction includes but is not limited to any type of inadequate performance associated with for example power supply processing units memory storage transmission line etc. The term fault recovery also applies to recovering the functionality of one or more VNFs or VNF instances with respect to any of the above. The terms security breech or security fault may be used interchangeably.

The term redundancy refers to any type of component of the network that is fully or partly duplicated provided in standby mode or otherwise available to replace another component of the network when that other component stops functioning properly or otherwise indicates some kind of fault. Redundancy may apply but is not limited to hardware software data and or content.

More illustrative information will now be set forth regarding various optional architectures and uses in which the foregoing method may or may not be implemented per the desires of the user. It should be strongly noted that the following information is set forth for illustrative purposes and should not be construed as limiting in any manner. Any of the following features may be optionally incorporated with or without the exclusion of other features described.

The principles and operation of a system method and computer program product for planning preparing and managing fault recovery in a network using network function virtualization NFV according to various embodiments may be further understood with reference to the following drawings and accompanying description.

As shown in at least one NFV based network is provided. The NFV based communication network includes an NFV management system an NFV orchestration NFV O module and a fault recovery module according to one embodiment.

In the context of the present network architecture the NFV based network may take any form including but not limited to a telecommunications network a local area network LAN a wireless network a wide area network WAN such as the Internet peer to peer network cable network etc. While only one network is shown it should be understood that two or more similar or different NFV based networks may be provided.

The NFV based network may include one or more computation facilities each including one or more hardware units and being interconnected by communication links to form the NFV based network . At least one of the computation facilities may include the NFV management system . The NFV management system may include the NFV O module and the fault recovery module .

The NFV O module may be executed by one or more processors or servers such as computation facilities of the NFV based network . The NFV O module may be executed as an NFV O instance or component. The NFV O module may therefore include a plurality of NFV O instances or components as will be further explained below.

The fault recovery module may be a part or a component of the NFV O module . However the fault recovery module the NFV O module and the NFV management system may be separate software programs provided by different vendors. In one embodiment the NFV based network may even have a plurality of any of the NFV management systems the NFV O modules and or the fault recovery module .

A plurality of devices are communicatively coupled to the NFV based network . For example a server computer and a computer or terminal may be coupled to the NFV based network for communication purposes. Such end user computer or terminal may include a desktop computer a lap top computer a tablet computer and or any other type of logic or data processing device. Still yet various other devices may be coupled to the NFV based network including a personal digital assistant PDA device a mobile phone device a television e.g. cable aerial mobile or satellite television etc. etc. These devices may be owned and or operated by end users subscribers and or customers of the NFV based network . Others of the devices such as administration station may be owned and or operated by the operator of the NFV based network .

A network administrator may supervise at least some aspects of the operation of the NFV based network by controlling an NFV infrastructure including the NFV management system the NFV O and the fault recovery module .

In one embodiment the hardware unit may represent a computing facility of or a part of a computing facility . The hardware unit may include a computing machine. The term computing machine relates to any type or combination of computing devices or computing related units including but not limited to a processing device a memory device a storage device and or a communication device.

The hardware unit may therefore be a network server and the computing facility may be a plurality of network servers or a data center including cloud based infrastructure. As an option the hardware unit may be implemented in the context of any of the devices of the NFV based network of and or and in any desired communication environment.

Each hardware unit or computing machine computing device computing related unit and or hardware component etc. including each communication link between such hardware units may be associated with one or more performance type and a respective performance rating or value where the hardware unit and or communication link is operative to provide the performance value. Performance types are for example processing power cash memory capacity regular memory capacity e.g. RAM dynamic or volatile memory etc. non volatile memory e.g. such as flash memory etc. capacity storage capacity power cooling bandwidth bitrate latency jitter bit error rate and packet loss etc. Virtual machines may run on top of the hardware unit and a VNF may be run on one or more of such virtual machines.

The hardware unit may be operative to provide computing infrastructure and resources for any type and or instance of software component executed within the NFV based network of . In this regard the hardware unit may be operative to process any of the processes described herein including but not limited to any NFV related software component and or process. The hardware unit is operative to process virtual network functions VNFs VNF instances network function virtualization orchestration NFV O software modules and functions data center management software and or cloud management systems CMS etc.

In various embodiments the hardware unit may include at least one processor unit one or more memory units e.g. random access memory RAM a non volatile memory such as a Flash memory etc. one or more storage units e.g. including a hard disk drive and or a removable storage drive representing a floppy disk drive a magnetic tape drive a compact disk drive etc. one or more communication units one or more graphic processors and displays and one or more communication buses connecting the various units devices.

The hardware unit may also include one or more computer programs or computer control logic algorithms which may be stored in any of the memory units and or storage units . Such computer programs when executed enable the hardware unit to perform various functions e.g. as set forth in the context of etc. . The memory units and or the storage units and or any other storage are possible examples of tangible computer readable media.

It is appreciated that computer program may include any of the NFV management system the NFV O and or the fault recovery module of .

In one embodiment the NFV management system may include an NFV O module . The NFV management system may include one or more NFV O modules . In various embodiments each of the NFV O modules may include orchestration and workflow management that is responsible for managing i.e. orchestrating and executing all NFV O processes including inbound and or outbound communication and interfaces.

The NFV management system may include a deployment optimization module that enables a user to devise automatic mechanisms for network optimizations. The deployment optimization module may operate these mechanisms automatically and continuously to optimize the distribution of VNFs and their VNF instances in real time or near real time by migrating VNFs and VNF instances e.g. VNF instances of etc. between hardware units e.g. hardware units of etc. .

More information regarding possible processes and or embodiments for performing optimization of VNF deployment as may be performed by deployment optimization module may be found in U.S. Provisional Patent Application No. 61 941 380 titled System Method And Computer Program For Managing Hierarchy and Optimization In A Network Function Virtualization NFV Based Communication Network and U.S. patent application Ser. No. 14 572 719 titled System Method And Computer Program For Managing Hierarchy and Optimization In A Network Function Virtualization NFV Based Communication Network which are incorporated by reference herein in their entirety.

The NFV management system may also include a chain optimization module . The chain optimization module may be a part of deployment optimization module and may enable a user to devise automatic mechanisms for optimizing the deployment of chains or groups of VNFs and VNF instances. A service provided by an NFV based network is typically made of a particular chain or group of particular VNFs and their respective VNF instances. The chain optimization module optimizes the deployment of chains or groups of services between hardware units according to the requirements and specifications associated with and or adapted to the particular service or chain or a group.

The chain optimization module may operate these mechanisms automatically and continuously to optimize in real time the operation of chains or groups of the VNFs and their VNF instances by re planning their distribution among hardware units and optionally also by migrating the VNFs and associated VNF instances between hardware units.

More information regarding possible processes and or embodiments for performing migration of a group of VNFs and or VNF instances chain migration such as by deployment optimization module may be found in U.S. Provisional Patent Application No. 62 026 512 titled System Method And Computer Program For Optimizing a Chain of Virtual Network Functions In A Network Based On Function Virtualization and U.S. patent application Ser. No. 14 572 728 titled System Method And Computer Program For Optimizing a Chain of Virtual Network Functions In A Network Based On Function Virtualization which are incorporated by reference herein in their entirety.

The NFV management system may also include a service fulfillment module that manages service and resource e.g. VNF instance lifecycle activities as part of the process and orchestration activities. This may include on boarding initiation e.g. instantiation installation and configuration scaling termination software update e.g. of a running VNF etc. test environment and or rollback procedure. Additionally the service fulfillment module may also provide decomposition of an order to multiple network services and the activation of such network service as a single VNF instance or as a chain of VNF instances.

Order decomposition includes translating business orders into a network oriented service implementation plan. For example a business order may be decomposed into a plurality of functions some of which may be provided by different software programs or modules e.g. such as various VNFs instantiated as a plurality of VNF instances across one or more data centers. Performing order decomposition the service fulfillment module may consult the deployment optimization module for the best deployment option to customer order in a given network and resource condition. Performing order decomposition the service fulfillment module may then initiate the service including all its components. Order decomposition may be performed in several locations across an NFV O hierarchy. For example initial decomposition may be performed in the root of the NFV O and then further decomposition may be performed in the relevant data centers.

In one embodiment an activation and provisioning module may provide the plan for activation and provisioning of the service to the orchestration and workflow management . The activation and provisioning module may also provide feedback on fulfillment status to an upper layer. This upper layer may include the business support services BSS .

The NFV management system may also include an assurance module and a service management module capable of gathering real time data on network elements status and creating a consolidated view of services and network health. The assurance module includes assurance functionality and may interact with the service management module to perform assurance related lifecycle management procedures. Lifecycle management can be also triggered by other modules policies manual intervention or from the VNFs themselves etc. The assurance module and the service management module may also trigger events associated with lifecycle management and faults. The assurance module and the service management module may monitor the health of the network and may execute fault recovery activities.

The assurance module and the service management module provide the ability to monitor services status and performance according to the required criteria. The assurance module and the service management module may also interact with the network infrastructure e.g. including computing storage and networking etc. to receive the required information analyze the information and act upon each incident according to the defined policy. The assurance module and the service management module are able to interact with analytics to enrich a policy assurance module. Interfaces may also be provided for implementation by an external system.

The NFV management system may also include a policy management module that enables a user to define and configure offline and or real time policy for controlling VNF and service related rules. The policy management module may contain the preconfigured policies and activities as well as selection rules for the NFV O process to determine the preferred policy or activity to be performed for a particular process event. The policy management may be multi layered including vendor policy service policy and operator policy etc. The policy mechanism may trigger the suitable policy layer vendor service operator .

The NFV management system may also include an administration module that provides an overall view of the network manual lifecycle management and intervention and manual system administration and configuration. The administration module may be operable to enable a user such as an administrator e.g. administrator of etc. to manage view and operate the NFV O system. The administration module may also provide a view of the network topology and services the ability to perform specific activities such as manual lifecycle management and changing service and connectivity configuration.

The NFV management system may also include an inventory management module that maintains a distributed view of deployed services and hardware resources. Inventory catalogues may reflect the current instantiation and allocation of the resources and services within the network mapped into products and or customer entities.

The NFV management system may also include a big data analytics module that analyzes network and service data to support network decisions involving services and subscribers to improve network performance based on actual usage patterns. The big data analytics module may also generate what if scenarios to support business oriented planning processes. Additionally the big data analytics module may function to analyze and evaluate the information for various planning aspects e.g. Virtual Network Capacity Planning Data Center Capacity Planning Value based planning Cost analysis for network deployment alternatives etc. deployment and management e.g. Guided Operator Recommendations. What if scenario analysis and simulation application rapid elasticity and resource usage optimization etc. and may support business oriented planning processes.

The NFV management system may also include a catalog module may include records defining various aspects of the network such as products services and resources such as hardware units and VNFs e.g. a VNF directory etc. . The catalog module may include a collection of centralized hierarchical information repositories containing resource service and product definitions with their relationship versioning and or descriptors etc. Such records may include templates enabling a user such as an administrator to define particular network components such as resources products services etc. A resource template may define resources descriptors attributes activities procedures and or connectivity etc. A service template may define a service variation from resource building blocks. A product template may define parameters of a sellable product e.g. prices rating etc. based on service composition e.g. in one embodiment this may be part of a BSS catalogue .

The inventory management module the big data analytics module and or the catalog module may support multiple data centers multiple CMSs and provide a centralized view across the infrastructure. The inventory management module the big data analytics module and or the catalog module may also support hybrid networks and services maintaining both physical and virtual resources.

The NFV management system may also include an accounting and licensing module that may be operable to record and manage network software usage data for commercial purposes including licensing accounting billing and reconciliation of services with subscribers and providers. The accounting and licensing module may manage licensing and usage of virtual network applications including the ability to support complex rating schemes based on various parameters such as CPU memory data etc. The accounting and licensing module may enable users to define the pricing of particular VNF modules and provide settlement with vendors. The accounting and licensing module may also enable the evaluation of internal costs of services provided within the network for calculating return on investment ROI .

The NFV management system may also include a fault recovery module otherwise named disaster recovery planning module or DRP etc. that enables a user to plan and manage disaster recovery procedures for the NFV O and or the entire network.

Service availability is a major and essential issue in any communication network. Network function virtualization NFV enables new and powerful tools for preserving service availability. In this context service availability provides means for the network to survive faults non stop operation or to quickly recover from faults. These means are based on redundancy built into the system. In a legacy network redundancy is allocated rigidly usually within the hardware scope of a particular service. An NFV based network enables much more flexible and dynamic allocation of redundancy thus increasing the efficiency and survivability of the network.

In a non stop network all the components of the network are at least doubled and all the network components and particularly processing memory and storage are duplicated at all times. Thus no single point of failure may cause a network outage.

Quick recovery architecture is based on N 1 or N m configuration. This architecture does not eliminate service discontinuity in case of failure but shortens the period of service or network outage. N m architecture requires restarting the failed sessions being relatively instantaneous and recovery of the failed memory and storage being relatively lengthy . Mirroring processes enable shortening the down period of a service heavily based on memory or storage. Quick recovery architecture may also utilize inherent redundancy for example where two or more communicating units are connected in two or more parallel connections.

In an NFV based network any hardware unit may provide redundancy whether in a non stop manner or a quick recovery N m manner. Similarly VNF and a respective VNF instance providing redundancy whether in a non stop or a quick recovery manner may be installed and executed on any or a plurality of hardware unit.

Subsequently a service using a group of VNFs and a respective VNF instances may have redundancy provided by a matching group of VNFs and a respective VNF instances installed over a plurality of hardware units.

The fault recovery module plans the recovery procedures from particular faults and accordingly plans the provisioning and deployment of redundancy of hardware units VNFs and VNF instance so that hardware units supporting redundancy have sufficient resources processing power memory storage etc. to execute the backup VNF instances when fault recovery is required.

To utilize efficiently the hierarchical structure and flexibility provided by the NFV architecture the fault recovery module uses the following mechanisms continuous monitoring of the network activity continuous predictive analysis providing continuous analysis of customer behavior and predicting customers needs and network requirements continuous calculation of optimization of the network s NFV configuration i.e. the optimal deployment of VNF instances resource conversion consideration and continuous migration of VNF instances along the network hierarchy to achieve the current or near future optimal deployment while preserving service session continuity. Continuous means run time real time online on the fly etc.

More information regarding possible processes for migrating VNF instances and preserving session continuity as well as managing predictive or preventive maintenance as may be embodied in fault recovery module or an associated process may be found in U.S. Provisional Patent Application No. 61 918 597 titled System Method And Computer Program For Preserving Service Continuity In A Network Function Virtualization NFV Based Communication Network and U.S. patent application Ser. No. 14 572 716 titled System Method And Computer Program For Preserving Service Continuity In A Network Function Virtualization NFV Based Communication Network which are incorporated by reference herein in their entirety.

The NFV management system may also include a security management module that provides the authentication authorization and accounting services of application security across the network. The security management module may include for example an authentication module and function. In one embodiment the authentication module and function e.g. including identity management etc. may authenticate the identity of each user defined in the system. Each user may have a unique user identity and password. The system may support password based authentication with flexible password policy. Integration with external authentication providers may be done via additional system enhancements. The authorization module and function may support a role based access control RBAC mechanism where each user is assigned with one or more roles according to the business needs based on the least privileges concept e.g. standard or administrator roles . In one embodiment the accounting and licensing module may provide an audit of security events such as authentication or login events.

As an option the security management module may use rules to protect sensitive information. For example such rules may be used to ensure the data accessed is used for the specific purposes for which it was collected sensitive information is encrypted when in storage transit and masked truncated on display and logs and that the entire security system is deployed in the customer s intranet network i.e. behind network infrastructure measures in an independent domain etc.

More information regarding possible processes for managing security as may be embodied security management module may be found in U.S. Provisional Patent Application No. 61 981 116 titled System Method And Computer Program For Managing Security In A Network Based On Network Function Virtualization NFV and U.S. patent application Ser. No. 14 572 723 titled System Method And Computer Program For Managing Security In A Network Based On Network Function Virtualization NFV which are incorporated by reference herein in their entirety.

In one embodiment the NFV management system may further include a Secure Development Life Cycle SDLC module that ensures that security aspects are handled during a project s life cycle such as security design security testing etc.

As shown further in the NFV management system may include a service planning module . The service planning module may be used by a communication service provider CSP sales representative enterprise and or technician as part of selling engagement process with enterprise SMB customers.

The service planning module may also provide the ability to interact with catalogues customer data network and ordering systems to provide online network service proposals for the enterprise customers with ability to quote update the proposal validate the serviceability and network inventory and once done provide the service order for activation using the northbound interface.

The NFV management system may also include east west APIs that include various domains activities interfaces including an information source to a big data repository and interaction capability with a physical network system OSS .

Northbound APIs provides application programming interfaces APIs to various external software packages such as business support system BSS for service order fulfillment cancel and update activities status notification resource inventory view monitoring system assurance system service planning tool administration tool for system view and configuration and big data repository etc.

Further the southbound APIs may provide APIs for external software packages such as CMS including service and VNFs lifecycle activities receiving from the infrastructure status and monitoring information for upstream system and activities e.g. assurance an SDN Controller or other connectivity system to configure inter and intra data center connectivity an EMS to configure the VNF and a VNF for a direct configuration.

As shown in the NFV based network may include hardware units connected via transmission lines and VNFs implemented as software programs installed in hardware units . Some of the hardware units may be directly connected to a customer. The customer may be a subscriber an end user or an organization represented herein as a terminal or a server or a plurality of terminals and or servers . The NFV based network may also include a NFV management system an NFV orchestration NFV O and a fault recovery module which may all represent elements described in the context of the previous figures etc. .

As shown further in several typically different VNFs may be installed in the same hardware unit . Additionally the same VNF may be installed in different hardware units .

A VNF may be executed by a processor of the hardware unit in the form of a VNF instance . Therefore a particular VNF installed in a particular hardware unit may be incarnated in e.g. initiated executed as etc. any number of VNF instances . The VNF instances may be independent of each other. Additionally each VNF instance may serve different terminals and or servers . The NFV based network connects to and between communication terminal devices that may be operated by one or more customers subscribers and or end users.

It is appreciated that a network operator may manage one or more services deployed in the customer s premises. Therefore some of the hardware units may reside within the premises of the network operator while other hardware units may reside in the customer s premises. Similarly a server such as server computer of may reside in the premises of the network operator or in the customer s premises. Consequently when the network operator provides and or manages one or more services for a customer s terminal devices such as a server computer the NFV based network of the network operator may directly manage the VNFs providing the services and their VNF instances .

In such situation the NFV based network may manage the services irrespectively of the location of the terminal devices e.g. the server computer etc. whether in the premises of the network operator or in the customer s premises. In other words the NFV based network may be managing the VNFs and the VNF instances providing the services as well as the terminal devices e.g. the server computer etc. being co located within the same computing device e.g. the hardware unit etc. whether in the premises of the network operator or in the customer s premises or in a commercial cloud or any other place.

A service provided by the communication network may be implemented using one or more VNFs. For example the service may be a group or a chain of interconnected VNFs. The VNFs making the group or the service may be installed and executed by a single processor by several processors on the same rack within several racks in the same data center or by processors distributed within two or more data centers. In some cases chain optimization may be employed by optimizing the deployment of a service in a communication network using network function virtualization and to optimizing the deployment of a group or a chain of virtual network functions in the NFV based network . Therefore the term chain optimization refers to the planning and or managing of the deployment of VNFs making a chain or a group of VNFs providing a particular service.

For example shows a first service including the VNFs and their respective VNF instances and and a thick line. In this example the group or chain of the VNFs making first service are connected as a chain of VNFs . However the VNFs making a service may be connected in any conceivable form such as a star tree root tree branch mesh etc. including combinations thereof. It is noted that the VNFs may be executed by two or more VNF instances such as VNF .

The deployment of the group or chain of the VNFs making the first service is therefore limited by constraints such as the capacity of the communication link bandwidth and or latency delay .

A VNF may have a list of requirements or specifications such as processing power cash memory capacity regular memory capacity e.g. RAM dynamic or volatile memory etc. non volatile memory e.g. such as flash memory etc. capacity storage capacity power requirements cooling requirements etc. A particular VNF instance providing a particular function e.g. to a particular customer entity etc. may have further requirements or modified requirements for example associated with a particular quality of service QoS or service level agreement SLA . Such requirements may include maximum latency or delay average latency and maximum variance latency jitter maximal allowed packet loss etc. Other requirements may include service availability redundancy backup provisions for roll back and or recovery fault tolerance and or fail safe operation etc.

A service made of a chain or a group of VNFs and their VNF instances may have a similar list of requirements or specifications covering the service as a whole. Therefore such requirements or specifications may imply affect or include requirements or specifications regarding communication links between the VNFs and or the VNF instances . Such requirements or specifications may include bandwidth latency bit error rate and or packet loss etc. Such communication requirements or specifications may further impose deployment limitations or constraints requiring particular VNFs and or VNF instances to reside in the same data center or within the same rack or even in the same computing device for example sharing memory or being executed by the same processor. Security measures may add further requirements or specifications such as co location of some of the VNFs and or the VNF instances .

In the context of the NFV based network has a hierarchical structure. There may be at least four aspects of the hierarchical structure of the NFV based network . The networking or traffic aspect refers to the arrangement of the transmission lines between the hardware units . The processing aspect refers to the arrangement of the hardware units . The software aspect refers to the arrangement of the VNFs . The operational aspect refers to the arrangement of the VNF instances .

One aspect of the optimization process in an NFV based network is that it may be based on real time needs rather than long term statistically anticipated needs. One potential limitation on network reconfiguration in NFV based networks is that network configuration does not result in a deterioration beyond acceptable level of any of the current services. The NFV deployment module e.g. module of etc. may function to enable and manage migration of services between the hardware units the VNFs and the VNF instances in real time without affecting or with a minimal effect on the availability of a service and while securing service and session continuity.

In the context of the current description the term continuous means that the deployment optimization module and or a chain optimization module e.g. the chain optimization module of etc. performs the relevant optimization task or process in run time or real time or online or on the fly or repetitively and without adversely affecting the network s functionality and its services.

Unlike a legacy network the NFV based network may have two topologies the topology of the hardware devices and the topology of the VNFs the distribution of VNFs among the hardware devices . The topology of the hardware network is relatively stable while the VNF topology can be optimized in real time. Another benefit of the NFV based network is that modifying the software topology e.g. the distribution of VNFs among the hardware devices is much less costly than any modification of the hardware topology. However any modification of the network has its cost including the cost of making such modification possible. Added cost may result from the need to process the modification of the topology and the re distribution of VNF instances and to maintain excess resources for such purpose.

Thus in some cases it may be desired to localize the NFV O and particularly the deployment optimization processes associated with the deployment optimization module and the chain optimization module to reduce the cost and simultaneously to secure the possibility to expand the scope of the network managed by these processes if needed.

The fault recovery module plans the recovery procedures from particular faults and accordingly plans the provisioning and deployment of redundancy of hardware units VNFs and VNF instance so that hardware units supporting redundancy have sufficient resources processing power memory storage etc. to execute the backup VNF instances when fault recovery is required.

In a first example shown in terminals designated by numerals and may communicate via hardware units designated by numerals and their associate transmission lines and their respective VNF s and VNF instance s .

In a second example shown in terminals designated by numerals and may communicate via hardware units designated by numerals and their associate transmission lines and their respective VNF s and VNF instance s .

In a third example shown in terminals designated by numerals and may communicate via hardware units designated by numerals and and their associate transmission lines VNF s and VNF instance s . The communication path of this example provides an alternative communication path for the communication path of the second example replacing hardware unit with hardware units and . Therefore communication paths of the second and third examples have inherent redundancy with respect to hardware units and and the transmission lines to and from these units.

The examples above involve one or more VNFs and VNF instances providing a service or an application connected with the communication between terminals and or and . These VNFs and their respective VNF instances may be located and or installed and or operated in any of the hardware units connecting the relevant terminals .

For example for terminals and of the first example the VNFs and their VNF instances can be located in any of hardware units and . For example for terminals and of the second and third examples VNFs and their VNF instances can be located in any of hardware units such as hardware units and for the second example or hardware units and for the third example .

It is appreciated that according to the second and third examples discussed above hardware unit may provide redundancy for hardware unit and the transmission line to and from hardware unit and may replace it when hardware unit becomes faulty. Similarly hardware unit may provide redundancy for hardware unit and the transmission line to and from hardware unit and may replace it when hardware unit becomes faulty.

It is also appreciated that the system described above with reference to including fault recovery module and using the NFV architecture enables redundancy between different hardware units such as hardware units of different hardware construction e.g. different processors or number of processors different memory size different storage size etc. . This system also enables redundancy between hardware units of different type such as different operating systems. Further this system supports redundancy irrespective of the location of the hardware units . For example where a first hardware unit providing redundancy for a second hardware unit is located in a different geographical region.

It is further appreciated that the system described above with reference to including fault recovery module and using the NFV architecture enables redundancy irrespective of the application such as a VNF or a group of VNFs or a service comprising a group of VNFs . Additionally this system supports redundancy irrespective of the composition of VNFs or VNF instances in the two or more hardware units providing redundancy. For example a first and a second hardware units may provide redundancy for a third hardware unit where each of the first and a second hardware units provide redundancy for a different group of VNFs or VNF instances . Similarly a first hardware unit may provide redundancy for two or more different group of VNFs or VNF instances in different hardware units .

It is appreciated that the system described above with reference to including fault recovery module and using the NFV architecture enables mirroring between various combinations of hardware units VNFs and or VNF instances as discussed above with reference to redundancy. In this respect any hardware units in the network can provided redundancy and or mirroring to any other hardware unit VNF and or VNF instance .

Reference is now made to which is a simplified flow chart of a computing process executing a fault recovery module according to one embodiment.

According to the embodiment shown in process starts in step by collecting failure data. Failure data refers to any type of information for example regarding the type of hardware or software e.g. hardware element or component such as power supply processor memory storage cooling etc. software component such as operating system application software VNF etc. any type of fault associated with each particular type of network component a particular hardware or software components as deployed in the network the relations of each particular network component hardware or software with other network components mean time between failures MTBF and mean time to repair MTTR the relation of each type of fault to age and usage of the particular component the ongoing load and use of each particular network components customers needs and operator s commitments such as QoS and SLA and actual failures.

Some of the failure data is received from suppliers of hardware and software products. For example MTBF and MTTR values etc. Some of the failure data is collected by various modules of an NFV O for the particular hardware and or software components of the NFV based network. For example the ongoing load and use of each particular network components customers needs and operator s commitments etc. Some of the failure data is collected by various modules of the NFV O for particular types of hardware and or software components of the NFV based network. For example types of faults associated with each type of network component types of faults associated with particular combinations of network components the relation of each type of fault to age and usage etc.

Step feeds the data to memory or storage that serves as the means of storage and communication between the various processes steps of the fault recovery module.

Process proceeds to step by calculating the probability of a particular failure of a network component for each and every network component.

Process then step prioritize the failures by their probability the affected services according to the service agreements with the relevant customers and considering the cost of altering the current fault recovery plan if such exists .

Thereafter in step for each failure and according to priority process locates target network components that can replace the anticipated faulty network component at the particular anticipated time and according to the current and anticipated distribution of load e.g. traffic load processing load memory load storage load etc. . That is to say that such target network component is expected to have at the time of the failure all the resources required to host the functionality currently hosted by the anticipated faulty component typically taking in account service agreements e.g. SLA with the relevant customers.

For each failure and according to priority process selects the preferred target replacement network components according to the VNF instances executed by the anticipated faulty component step . It is appreciated that more than one target replacement network component can be selected for an anticipated faulty component. In that sense VNF instances executed by the anticipated faulty component may be distributed in a plurality of replacement network components. It is appreciated that if backup resources are scarce a VNF instance can be split into two or more VNF instances distributed in a respective number of target replacement network components.

In step for each failure and according their respective priorities process secures the required resources in the selected target replacement backup network components. It is appreciated that by securing the resources these resources are not allocated to other VNF instances or any other type of consumers of the relevant resources. This ensures the availability of the secured resources when the respective failure occurs.

In step for each failure and according their respective priorities process prepares a recovery plan for migrating the adversely affected VNF instances from the anticipated faulty component to the replacing components.

It is appreciated that the same resources may be allocated and or secured for two or more recovery plans. This means for example that the same resources of a particular target replacement backup network component may be allocated and or secured for VNF instances associated with two or more anticipated faulty network component that are unlikely to fail within the same time period. Therefore for example high priority services or VNF instances may have exclusive target replacement backup network component while two or more lower priority services or VNF instances may share a target replacement backup network component.

It is appreciated that for example two or more pools of secured resources can be allocated in two or more target replacement backup network components for three or more anticipated faulty network components.

Consequently in step process determines for each failure and according to priority whether to install a VNF in the replacing components in advance of the predicted failure to shorten the recovery process. If deemed needed process installs the VNF module.

In step process also determines for each failure and according to priority whether a mirroring process is required. If deemed needed process plans and initiates mirroring processes between the affected VNF instances and the backup VNFs according to the service agreements with the relevant customers to further shorten the recovery process. The term affected VNF instance refers to a VNF instance that is expected to be adversely affected by a particular probable future fault for which the current recovery plan is prepared.

It is appreciated that the process described above is repeated for various probable failures of a particular network component and for various network components typically according to the list of priorities. Therefore process generates a plurality of failure recovery plans typically at least one plan for each failure of each network component.

It is appreciated that where a failure of a network element disables and or deactivates the network element so that another possible failure cannot occur for the same network element the same target replacement backup network components and or the same resources may be used for two or more different possible failures of the same network element.

It is appreciated that target replacement backup network components are selected based on their respective currently anticipated loads. It is appreciated that loads may evolve differently than anticipated requiring changes of the fault recovery plans. Therefore for example when load data changes including data regarding anticipated loads process may have to recalculate some of the recovery plans for example by reprocessing at least some of steps through .

When a fault occurs process executes step initiating a recovery processes according to the received step failure event. An indication of a failure may be received from various sources for example an element management system EMS and or a data center DC management system and or a cloud management system CMS may report a hardware failure a control VNF instance which is dedicated to measuring the availability and well being of particular hardware components may indicate hardware problems a control VNF instance which is dedicated to measuring particular loads may indicate excessive loads or poor performance VNF instances may have control points in which system performance is measured and reported a customer may complain about poor network performance or poor performance of a particular service etc. and an NFV O may collect failure reports and performance reports analyze the reports and determine a failure.

The distributed architecture of an NFV O enables faster response to local events on one hand and improved scalability on the other hand. In a distributed NFV O architecture decision processes are performed in self contained and local decision points closer to the customer and closer to the events e.g. such as network or security faults etc. .

The hierarchy of a distributed NFV O can be viewed as a tree of two component types a core component and a leaf component . The NFV O core component can be a child of another core component and or a parent of one or more core components or leaf components . A leaf component cannot be a parent of a core component or a leaf component .

Orchestration parameters managed by a particular leaf component or core component may be reported in real time to the supervising parent core component . In addition to the supervision this continuous updating process enables the supervising component to provide backup and or support recovery processes associated with hardware and or software faults as well as security faults and or breeches.

To provide redundancy a leaf component may be supervised by two or more core components and child core components may be supervised by two or more parent core components . The orchestration parameters managed by a particular core component or leaf component may also be mirrored to the backup core components . Optionally the NFV O core components may have the same fully functional orchestration capabilities while leaf components may be limited to simple well defined and localized sub orchestration tasks and thus may provide a faster response to demands and changing load.

A cloud management system CMS is a software package managing one or more hardware units operating one or more VNFs and executing one or more VNF instances. A CMS can be managed by one or more leaf components or core components or combinations thereof. A CMS can be located in the operator s premises or in the customer s premises or partly in both.

An NFV O component such as a core components or a leaf component typically orchestrates a particular predefined territory. The territory may be one or more cloud management systems one or more services one or more customers etc. Therefore there can be an overlap between territories of different NFV O components. For example one NFV O component may orchestrate a CMS another NFV O component may orchestrate a service that is at least partly provided by the same CMS and additionally a third NFV O component may orchestrate services for a particular customer connected to that same CMS .

If for any reason the first responder NFV O component cannot resolve the problem for example for lack of adequate or sufficient resources within the territory of the particular NFV O component the problem may be escalated above to the supervising or parent NFV O component.

The NFV O is a central component of the network as a system and thus may present a risk from a security perspective. For example an attack against the NFV O may result in a total network outage. Securing the NFV O is therefore a goal and a challenge. A distributed NFV O architecture enhances the network resilience endurance. When an attack on a particular instance of the NFV O is detected the NFV O instance may be isolated and its functionality may be transferred to one or more other NFV O instances.

Another aspect of the NFV O hierarchy is stratified granularity or resolution of the orchestration process. An NFV based network may include a very large number of hardware elements e.g. processors memory units storage units communication links etc. and an even larger number of VNFs and VNF instances. Each of the VNF instances may have a number of requirements e.g. such as processing power memory size storage size communication bandwidth latency and jitter etc. . Each of these hardware elements and software modules may produce a number of load values e.g. corresponding to their respective requirements .

All of this creates a large amount of data that should be processed continuously or repeatedly to determine possible adverse conditions e.g. a particular overload or a potential cost saving situation. Such situation may require deployment optimization e.g. the planning of a newly optimized deployment of VNF instances and redeployment e.g. implementing the optimized deployment . The NFV O hierarchy enables scalability of the redeployment optimization process by distributing the process in a hierarchical manner.

One optional aspect of hierarchical deployment optimization is that higher levels in the NFV O hierarchy processes deployment optimization in a coarser granularity or resolution while lower levels in the NFV O hierarchy processes deployment optimization in a finer granularity or resolution .

For example while a leaf component manages its part territory of the NFV based network in terms of particular hardware elements e.g. processors memory units storage units communication links etc. and software elements e.g. VNFs and VNF instances a core component may manage its part territory of the NFV based network in terms of whole subordinate child core components or leaf components it supervises. Thus such parent core component may perform deployment optimization in terms of requirements and load values applied to whole subordinate child core components or leaf components .

A customer may use the services of several telecom operators. For example the customer may be an international company operating in several countries. Such a customer usually establishes a virtual private network VPN across this plurality of telecom operators. Considering that these operators now operate NFV based networks the customer may establish a service including a plurality of VNFs where different VNFs are part of different networks. Managing such inter operator VNF chains or services requires tight coordination across different NFV based networks.

Such coordination can be implemented using various techniques. For example the coordination may be implemented by enabling tight coordination between NFV Os of the different NFV based networks. As another example the coordination may be implemented by establishing an inter network NFV O module that manages one or more inter network VNF chains or services of a particular customer.

Optionally such inter network NFV O may supervise two or more child or leaf NFV O modules each within a particular NFV based network incorporating an NFV participating in the particular VNF chain or service. It is appreciated that NFV Os of different operators may be provided by different NFV O vendors.

In a first network configuration a single NFV O module may manage the deployment of VNFs and VNF instances throughout the entire NFV based network. A deployment optimization module e.g. and a chain optimization module of the NFV O module may continuously investigate the development of loads and provide alternative deployment plans. Consequently the NFV O module may redeploy VNFs and VNF instances and reallocate network resources accordingly.

Deployment optimization is indicated when one part of the NFV based network is over loaded or approaches an overload situation while another part of NFV based network is relatively idle. The redeployment migrates some of the network entities e.g. VNFs and VNF instances from the overloaded part of NFV based network to the relatively idle part of the NFV based network to free resources where needed mostly. Therefore the deployment optimization and redeployment activities may follow the changes of load distribution.

Reference is now made to which is a simplified flow chart of a fault recovery process as disclosed above with reference to step of and according to one embodiment.

The purpose of the fault recovery process step of is to migrate the VNF instances executed by the faulty hardware unit in their respective backup hardware units as determined by the fault recovery planning process steps to of computing process executing the fault recovery module .

It is noted that the term faulty hardware unit may refer to any type of hardware fault and or a software fault associated with the faulty hardware unit. Such hardware or software fault may completely terminate the capabilities of the faulty hardware unit of partly affect some of the capabilities. Therefore it is possible that all the VNF instances are aborted instantaneously or that only few are affected but still function or any combination thereof. Thus one or more of the VNF instances should be migrated and restarted at their backup hardware units while other VNF instances should be migrated while preserving session continuity at least partly. It is noted that the VNF instances to be migrated are determined according to the particular fault.

The fault recovery process of step starts with step to identify the faulty hardware unit and then step to identify the particular fault. Then in step fault recovery process loads the fault recovery plan associated with the identified faulty hardware unit and fault.

The fault recovery process of step proceeds to step to determine the VNF instances that should be migrated as well as their respective backup hardware units and the migration methods.

The fault recovery process of step then proceeds to step and step to migrate the VNF instances according to the fault recovery plan until all the VNF instances are migrated and their associated services are continued.

The fault recovery process of step then reports step the current status as well as the current location of the migrated VNF instances to the fault recovery planning procedure to prepare a new recovery plan consistent with the newly created deployment of VNF instances as well as to the deployment optimization procedure.

Reference is now made to which is a simplified flow chart of a VNF migrating routine as disclosed above with reference to step of and according to one embodiment.

The VNF migrating routine of step starts with step to determine if the required VNF code e.g. a VNF exists in the backup hardware unit. If the required VNF does not exist in the backup hardware unit the VNF migrating routine of step that is process proceeds to step to install the required VNF in the backup hardware unit. If the VNF in the backup hardware unit requires particular to take over and or continue the processing of the migrating VNF instance step such data is loaded step from the migrating VNF instance or from a mirroring facility or from a backup facility or from any other database managed by the VNF O. VNF migrating routine of step then proceeds to step to initiate in the backup hardware unit a VNF instance and configure it according to the parameters of the VNF instance of the first hardware unit. The VNF migrating routine of step then proceeds to step to divert all or part of the communication incoming to the VNF instance of the faulty hardware unit to the VNF instance of the backup hardware unit.

It is appreciated that the contents U.S. Provisional Patent Application No. 61 918 597 titled System Method And Computer Program For Preserving Service Continuity In A Network Function Virtualization NFV Based Communication Network and U.S. patent application Ser. No. 14 572 716 titled System Method And Computer Program For Preserving Service Continuity In A Network Function Virtualization NFV Based Communication Network may form at least a part of a possible embodiment of step of process as described with reference to . It is appreciated that FIGS. 11 and 12 of U.S. patent application Ser. No. 14 572 716 titled System Method And Computer Program For Preserving Service Continuity In A Network Function Virtualization NFV Based Communication Network as well as their respective description may be used instead of or in addition to herein.

Coupled to the network is a plurality of devices. For example a server computer and an end user computer may be coupled to the network for communication purposes. Such end user computer may include a desktop computer lap top computer and or any other type of logic. Still yet various other devices may be coupled to the network including a personal digital assistant PDA device a mobile phone device a television etc.

As shown a system is provided including at least one central processor which is connected to a communication bus . The system also includes main memory e.g. random access memory RAM etc. . The system also includes a graphics processor and a display .

The system may also include a secondary storage . The secondary storage includes for example a hard disk drive and or a removable storage drive representing a floppy disk drive a magnetic tape drive a compact disk drive etc. The removable storage drive reads from and or writes to a removable storage unit in a well known manner.

Computer programs or computer control logic algorithms may be stored in the main memory the secondary storage and or any other memory for that matter. Such computer programs when executed enable the system to perform various functions as set forth above for example . Memory storage and or any other storage are possible examples of tangible computer readable media.

While various embodiments have been described above it should be understood that they have been presented by way of example only and not limitation. Thus the breadth and scope of a preferred embodiment should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

