---

title: Common event-based multidevice media playback
abstract: A system for event-based synchronized multimedia playback, comprising a media source device and a plurality of destination devices, each destination device comprising a local clock, and a synchronization module on one of the devices. The synchronization module transmits common events, E, each with a unique event number, to each of the plurality of destination devices. Each destination device records time Dxwhen event Eis received and transmits an acknowledgement message back to the synchronization module comprising time Dxand event number n. The synchronization module determines phase and frequency differences between clocks of respective destination devices; computes a frequency adjustment to compensate for phase and rate differences; and directs each respective destination device to adjust its clock phase and frequency accordingly. Each destination device adjusts its local clock as directed or may perform a sample rate conversion on sample data in order to enable synchronized media playback.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09338208&OS=09338208&RS=09338208
owner: Blackfire Research Corporation
number: 09338208
owner_city: San Francisco
owner_country: US
publication_date: 20141002
---
This application is a continuation of U.S. patent application Ser. No. 14 303 502 titled SYNCHRONOUS PLAYBACK OF MEDIA USING A WI FI NETWORK WITH THE MEDIA ORIGINATING FROM A BLUETOOTH SOURCE filed on Jun. 12 2014 which claims the benefit of and priority to U.S. provisional patent application Ser. No. 61 833 927 titled SYNCHRONOUS PLAYBACK OF MEDIA USING A WI FI NETWORK WITH THE MEDIA ORIGINATING FROM A BLUETOOTH SOURCE filed on Jun. 12 2013 the entire specification of which is incorporated herein by reference and is also a continuation in part of U.S. patent application Ser. No. 13 561 029 titled PACKET LOSS ANTICIPATION AND PRE EMPTIVE RETRANSMISSION FOR LOW LATENCY MEDIA APPLICATIONS filed on Jul. 28 2012 and is a continuation in part of U.S. patent application Ser. No. 14 083 426 titled COMMON EVENT BASED MULTI DEVICE PLAYBACK filed on Nov. 16 2013 which is a continuation in part of U.S. patent application Ser. No. 11 627 957 titled Streaming Media System and Method and filed on Jan. 27 2007 and claims a benefit of and priority to U.S. provisional patent application Ser. No. 61 727 624 filed on Nov. 16 2012 titled COMMON EVEN BASED MULTIDEVICE MEDIA PLAYBACK the entire specification of each of which is incorporated herein by reference.

This application is also a continuation of U.S. patent application Ser. No. 14 303 527 titled BROADCASTING MEDIA FROM A STATIONARY SOURCE TO MULTIPLE MOBILE DEVICES OVER WI FI and filed on Jun. 12 2014 which claims the benefit of and priority to U.S. provisional patent application Ser. No. 61 833 928 titled BROADCASTING MEDIA FROM A STATIONARY SOURCE TO MULTIPLE MOBILE DEVICES OVER WI FI filed on Jun. 12 2013 the entire specification of which is incorporated herein by reference and is also a continuation in part of U.S. patent application Ser. No. 13 561 029 titled PACKET LOSS ANTICIPATION AND PRE EMPTIVE RETRANSMISSION FOR LOW LATENCY MEDIA APPLICATIONS filed on Jul. 28 2012 and is a continuation in part of U.S. patent application Ser. No. 14 083 426 titled COMMON EVENT BASED MULTI DEVICE PLAYBACK filed on Nov. 16 2013 which is a continuation in part of U.S. patent application Ser. No. 11 627 957 titled Streaming Media System and Method and filed on Jan. 27 2007 and also claims a benefit of and priority to U.S. provisional patent application Ser. No. 61 727 624 filed on Nov. 16 2012 titled COMMON EVEN BASED MULTIDEVICE MEDIA PLAYBACK the entire specification of each of which is incorporated herein by reference.

The disclosure relates to the field of digital media and more particularly to the field of synchronized digital multimedia playback.

Today there are many forms of digital media many types of digital media sources many types of digital media playback rendering systems and lots of ways of connecting media sources to media playback systems.

Digital media hereafter referred to as media comes in many forms formats and containers including Digital Video Disks media files and media streams. The media contents can be audio video images or meta data media components and various combinations of each. For example a popular audio format is known as MP3 and a popular video format is H264. MP3 is an audio specific media format that was designed by the Moving Picture Experts Group MPEG as part of its MPEG 1 standard and later extended in the MPEG 2 standard. H264 is a standard developed by the International Organization for Standardization ISO International Electrotechnical Commission IEC joint working group the Moving Picture Experts Group MPEG . Movies are typically multimedia formats with a video and multiple audio channels in it. For example a 5.1 movie contains 1 video channel media component and 6 audio channels audio components . 5.1 is the common name for six channel surround sound multichannel audio systems.

Digital media sources include media devices such as Digital Video Disk players Blu ray players computer and mobile devices and internet based cloud media services. Blu ray Disc BD is an optical disc storage medium developed by the Blu ray Disc Association. Internet based media services include services such as Netflix and Spotify . Netflix is a media service and trademark of Netflix Inc. Spotify is a media service and trademark of Spotify Ltd. Digital media playback media rendering destinations systems include computer based devices laptops and smartphones as well as network audio and video devices. A SmartTV is an example of a digital media rendering device that can play media from an internet cloud based media service such as Netflix . A SmartTV which is also sometimes referred to as Connected TV or Hybrid TV is used to describe the integration of the internet and Web features into modern television sets and set top boxes as well as the technological convergence between computers and these television sets set top boxes. An Internet radio device is another example of a digital media rendering device.

The connectivity between these media sources and devices is varied but is evolving over time towards network based connectivity using Internet protocol IP protocols. This is because IP connectivity is convenient ubiquitous and cheap.

IP networks come in many forms the most prevalent being Ethernet based wired IP networking. Ethernet is a family of computer networking technologies for local area networks LANs that is standardized as IEEE Institute of Electrical and Electronics Engineers Standard 802.3. In recent years with the prevalence of mobile computing devices Wi Fi a type of IP network has become the most popular means for connecting network devices wirelessly. Wi Fi is a trademark of the Wi Fi Alliance and a brand name for products using the IEEE 802.11 family of standards. IP networks can use several different types of messaging including unicast multicast and broadcast messaging such messaging being the sending of IP packets.

The term Unicast may be used to refer to a type of Internet Protocol transmission in which information is sent from only one sender to only one receiver. In other words unicast transmission is a one to one node transmission between two nodes only. In unicasting each outgoing packet has a unicast destination address which means it is destined for a particular destination that has that address. All other destinations that may hear that packet ignore the packet if the packet s destination address is not the same as that destination s address.

Many IP protocols are accessed from software programs via a socket application programming interface. This socket interface is defined as part of the POSIX standard. POSIX is an acronym for Portable Operating System Interface which is a family of standards specified by the IEEE for maintaining compatibility between operating systems.

The convenience and benefits of IP networking means that all of these media sources and playback systems if not already network enabled are becoming network enabled. Many Blu ray players now have Ethernet and Wi Fi network connectivity. Today most higher end TVs are smart TVs that have network capability. Similarly audio play back devices and even radios are network and Internet enabled.

Mobile devices such as mobile phones tablets document readers or notebooks are able to receive and store media and have powerful multimedia audio and video capabilities and may be connected to the internet via cell phone data services or broadband links such as Wi Fi that are high bandwidth and can access online media services that have wide and deep content.

The use cases or applications of these various forms of digital media media services and media sources and playback systems have been evolving. Initially it was enough to connect a media source to a media destination over an IP network. This is widely used today with Internet based media source services such as Netflix and a computer as a media destination. Users watch Netflix movies streamed over a wired IP network the internet to a computer. This is a case of a single point one IP source to single point one IP destination connection over a wired IP network. Even though the Netflix media service may send the same media to multiple households each of these is a single point to single point TCP IP connection. A further evolution of this is to use a wireless Wi Fi connection instead of a wired Ethernet connection. This is still a single point to single point connection.

A further extension of the above use cases exists where a media source connects to multiple destinations rather than a single destination. These are single point one IP source to multi point multiple IP destinations applications. An example would be where a user is playing a 5.1 movie media file to a wireless video playback device and 6 independent wireless audio destinations making up a full 5.1 surround sound system. In this case the media is going from one media source to 7 media destinations simultaneously. In another example a user is playing music from one media source to six audio playback systems placed around the home in six different rooms.

In both of these cases it is necessary to play render the media at all destinations time synchronously. Furthermore it is necessary to limit the use of resources at the media source such as keeping memory use to a minimum. In addition it is necessary with multiple devices receiving media to manage network bandwidth efficiently.

Currently when the same media data needs to be sent to multiple network destinations the general technique for doing so is to use data multicasting to the multiple destinations that need to receive the data. In such a system the media is multicast to all the destinations and it is up to each destination to attempt to render the media appropriately. If during rendering there is an error where a renderer does not receive new media data or does not receive it correctly the renderer may render erroneous data and then attempt to recover and continue correct media rendering from the point after the error when correct data is received.

In the applications envisioned here there is a need to send media from a source to multiple media devices such as TV and speakers in the same listening and viewing space. Furthermore there is a need to send this media over a wireless network such as Wi Fi.

For these applications this means all of the media rendering devices such as speakers that are in the same listening or viewing zone need to be precisely synchronized to each other so the listener and or viewer does not discern any unintended media experience.

Secondly because the media is transported over wireless there is a very high likely hood of a media error where the media is not received at each destination reliably or uniformly. If using broadcast or multicasts to send packets the same broadcast or multicast packet may be received at one destination but not received heard by another destination.

Disclosed is a method for event based synchronized multimedia playback that solves the above problems of media error and loss of synchronization when transmitting to multiple media receiver devices.

According to a preferred embodiment a system for event based synchronized multimedia playback comprising a plurality of media playback devices each of which maintains audio phase and timing through synchronization based on crystal clock cycles is disclosed. According to the embodiment a plurality of media playback devices may be connected to a plurality of media source devices by way of an IP enabled network such as the Internet or any other data network utilizing an IP protocol. Media may be broadcast over such a network to playback devices each of which may play similar or distinct media elements as may be desirable during playback for example one speaker may play the left audio channel while a second speaker the right audio channel as is common in sound systems in the art .

According to a preferred embodiment a system for event based synchronized multimedia playback comprising a media source device and a plurality of destination devices each comprising a local clock is disclosed. The synchronization module in the media source device transmits a common events E comprising a unique event number n at the media source to each of the plurality of destination devices. Each destination device records time Dxwhen event Eis received and transmits an acknowledgement message back to the synchronization module comprising time Dxand the unique event number n. The synchronization module for each of the plurality of receiver devices determines the phase and frequency differences between the clock signal of the respective receiver devices computes a phase and frequency adjustment to compensate for differences and directs the respective destination device to adjust its clock phase and frequency accordingly. Each receiver device adjusts its local clock as directed or performs a sample rate conversion in order to synchronize media playback.

According to another preferred embodiment a method for event based synchronized multimedia playback is disclosed the method comprising the steps of a periodically transmitting from a media source device containing a synchronization module and connected to a network and adapted to stream media over the network a common event Ecomprising a unique event number n b receiving via the network at each of a plurality of receiver devices comprising a local clock the event E c recording at each receiving device a time Dxwhen event Eis received d transmitting an acknowledgement message from each receiving device back to the media source comprising at least the time Dxand the unique event number n e determining using a synchronization module stored and operating on one of the media source device and the plurality of destination devices the phase and frequency difference between the clock signals of the respective destination devices f computing a frequency adjustment to compensate for the phase and frequency difference determined in step e g directing the respective receiver device to adjust its clock phase and frequency by an amount equal to the frequency adjustment computed in step f and h adjusting the local clock of each receiver device as directed in step c in order to synchronize media playback.

The term Unicast may be used to refer to a type of Internet Protocol transmission in which information is sent from only one sender to only one receiver. In other words unicast transmission is a one to one node transmission between two nodes only. In unicasting each outgoing packet has a unicast destination address which means it is destined for a particular destination that has that address. All other destinations that may hear that packet ignore the packet if the packet s destination address is not the same as that destination s address.

As used herein broadcast messaging or broadcasting refers to a type of Internet Protocol transmission in which information is sent from just one computer but is received by all the computers connected on the network. This would mean that every time a computer or a node transmits a broadcast packet all the other computers could receive that information packet.

As used herein multicast messaging or multicasting refers to a type of Internet Protocol transmission or communication in which there may be more than one sender and the information sent is meant for a set of receivers that have joined a multicast group the set of receivers possibly being a subset of all the receivers. In multicasting each multicast packet is addressed to a multicast address. This address is a group address. Any destination can subscribe to the address and therefore can listen and receive packets sent to the multicast address that it subscribed to. The benefit of multicasting is that a single multicast packet sent can be received by multiple destinations. This saves network traffic if the same packet needs to be sent to multiple destinations. When the same data needs to be sent to multiple IP destinations generally broadcasting or multicasting rather than unicasting provides the most efficient use of the network.

In this description the terms broadcast and multicast may be used. In both broadcasting and multicasting when messages are sent they are received by multiple destinations. Therefore as used herein the terms broadcast and multicast may be used interchangeably to refer to one packet being received by multiple destinations. In some cases this description only refers to the media being sent or transmitted without specifying whether it is broadcast multicast or unicast. In such case it means any one of these methods may be used for sending or transmitting the media.

As used herein the terms message and packet are often used and may be used interchangeably. A packet is a data set to be sent or received on an Internet Protocol IP network. The packet may or may not be the same as an IP packet . The term message as used herein refers to the logical information contained in such a packet.

As used herein the segment may also be used to refer to a data set. A data set is a set of bytes of data. Data may be any type of data including media or control or informational data. In this description the term data and packet may also be used interchangeable depending on context. Packet may refer to a data set and data refers to data in general.

Numerous alternative embodiments are disclosed herein it should be understood that these embodiments are presented for illustrative purposes only. The described embodiments are not intended to be limiting in any sense. In general embodiments are described in sufficient detail to enable those skilled in the art to practice one or more of the inventions and it is to be understood that other embodiments may be utilized and that structural logical software electrical and other changes may be made without departing from the scope of what is disclosed.

According to an embodiment of the invention in order to broadcast media over a Wi Fi network it is first necessary to recognize that broadcast or multicast media will not be received at all destinations uniformly. Some destinations will receive a multicast packet referring to a data set to be sent or received on an Internet Protocol IP network. The packet may or may not be the same as an IP packet . The term message as used herein refers to the logical information contained in such a packet may also be referred to interchangeably as a message or segment while others will not.

IP networks were first designed to operate over wired networks. By design the packet communications on these networks were best effort . This means any packet transmitted on the network may not be received by the intended destination. This is most often due to a collision where another device starts to communicate at the same moment as the device of interest thereby causing a collision. Another method of loss would be the devices in the network path such as routers simply dropping the packet for example due to the lack of buffer space. Other reasons for loss could be that the wired line is simply noisy and the packet transmission got corrupted though this is rare for the wired case vs. the wireless case.

In all these wired situations it is generally the case that if the transmission for example a multicast message was received by one device on a subnet or wire all the other devices on the same wire or subnet would also receive the transmission correctly. This is because in the wired case the noise or interference situation of a device on one part of the wire is not so different from the noise situation at another part of the wire. If the wired devices are connected via a switch rather than a hub the same issues are true and the amount of noise or interference is minimal.

In Wi Fi the differences in receipt of Wi Fi traffic at each Wi Fi device in a subnet is substantial. Therefore it is necessary to account for this.

According to an embodiment of the invention all devices i.e. a source device and various destination devices and see may be networked together on a local network . This is typically an IP network and may be a wired or a wireless e.g. Wi Fi network. This local network may be further connected to the Internet.

In many media systems it is desirable to send the media to multiple playback devices and have each playback device render the media in phase. For example it is desirable to send the left channel of stereo audio media to the left audio playback device and the right channel of the stereo media to the right audio playback device and to have both these devices play the media correctly in phase.

If rendered waves and are not in phase then users may hear a beat frequency that is related to the difference in frequency between the two waves and . Furthermore over time the two audio outputs may differ to a continually increasing extent. For instance in the example used previously if the second subsystem is off by 50 parts per million ppm and a 3 minute song ends with a drum beat the second subsystem will play the final drum beat 9 milliseconds later than the first subsystem . After ten such songs the difference will be 90 milliseconds which will be very noticeable.

Therefore when multiple audio devices and are playing the same media it is necessary to adjust and ensure that the rendering clock on each system has the same phase offset and frequency.

A CPU clock crystal on a typical CPU will be the basis of the CPU clock generated internally by CPU . This CPU clock will then be used for all CPU timing activity. Some CPUs may generate many different clock signals internal to CPU based on this CPU clock. CPU may also have many clock peripherals and clock registers based on the CPU clock that can be used for various timing related activities. For example a clock peripheral may be configured to interrupt the CPU periodically every 100 milliseconds. Since this clock is based originally on CPU crystal the accuracy of this period will depend on the accuracy of CPU crystal . Typically a program running on CPU can also read a clock register which will show the number of clock counts CPU has counted since CPU was powered up and reset. These clock counts will increment at a rate that is related to CPU crystal . This clock may be used to drive the DAC output sample rate and the rate at which audio samples are provided to the DAC.

In some embodiments system may further comprise a separate audio clock with its own independent crystal for sending an audio clock signal to CPU and DAC for managing the timing of playback of audio signals sent from CPU to DAC and for generating audio output from such audio signals via the DAC .

Alternate embodiments may use various combinations of external and internal clock sources to drive the DAC sample rate.

In media systems such as that shown in where it is necessary to send the media to multiple playback devices and to have each playback device render the media in phase the media needs to be marked with some time reference information and each device needs to play this media according to this time information. This means each device needs to use the same time reference so that its rendering activity is time aligned.

The time for the nth message to get to the xth device is Tx. The transport time to each destination may be different due to network packet transmission issues. This difference will change over time and from device to device. These changes in Tx are referred to as transport jitter Jx at device x.

Based on the information in each clock message Cxand the corresponding local clock value Dxrecorded each destination x may compute information to adjust its local clock Dx to match common source clock C . Destinations may adjust local clocks D1 Dx phases counts Px to match a best estimate of the current phase count Pc of the source clock C . Similarly destinations may adjust local clocks D1 Dx frequencies Fx to match a best estimate of current frequency Fc of common source clock C .

Estimating the transport time Tx is critical for this system. One common way of doing this is to measure round trip time from source to destination by sending a message from source to destination Dx and having destination Dx acknowledge this message. The total time from sending an outgoing message to receiving an incoming acknowledge message is the round trip time. Halving this time provides an estimate of outgoing transit time. If this is done many times and filtered the filtered result Tacan be used as the average transit time from a source to destination Dx. The actual transit time Txfor the nth message will be Ta Jx where Jxis the jitter the deviation from the average for this nth message. Jxcan be estimated using the standard deviation of the Tx times measured.

In this scheme each destination device uses the common source clock information to adjust its local clock values and clock rate to match that of common source clock . That is common source clock is a global clock used in the system and all destination clocks are aligned to this. The media is then rendered at each device using local clocks .

The precision of this system may be limited because transport jitter may impact both the frequency and phase calculations. This may be mitigated somewhat by filtering the parameters used in the calculation over a period of time as mentioned above. The rendering of the media is done by destination devices since clocks associated with these devices are used as a basis for media rendering this means the phase accuracy of media rendering is affected by transport time jitter. If transport time jitter Jx is 1 to 2 milliseconds as it can be on a Wi Fi network then the maximum phase accuracy that can be achieved is limited to this range.

A further issue with this system is that virtual clock time only increments at intervals of received messages. This can be addressed by using a local clock to interpolate time in between these message intervals. The problem is that each device s local clock may be slightly different from the others and therefore interpolated virtual clocks may jump forward or move slightly backwards at each adjustment made as a result of received messages. This may cause the media rendering to jump forward or backwards by small amounts from time to time.

A further issue is that in many systems a common global clock is not available or even if it is available it is not accurate enough for synchronization purposes. For example the source devices local clock may be accessed through a programming API however since the caller program is usually running in a multitasking operating system that may have delays or task swaps during the API call the local clock time will be incorrect by that time. For example the caller program may call the local clock API and it may read the hardware clock value then before the function returns the current program thread is tasked swapped and returns only in the next program thread time slice. This means the hardware clock value returned is now out of date by the time slice period. Most common operating systems can have a time slice period of up to 25 100 milliseconds so the hardware clock value may be out of date by many milliseconds. This is the case for many general purpose source devices such as Smartphones or notebooks. By contrast the destination devices used in this invention are special purpose devices and therefore the software operates at a lower level with much better local clock read accuracy.

Therefore various embodiments of the invention may be designed with the goal of not using or requiring the ability to read the source devices local clock accurately.

The disclosed configuration renders media using each device s local rendering clocks only. The destination devices local clock referred to here is the clock that is used as the base for the rate sample rate at which media samples are fed to the DAC digital to analog converter to convert render the digital media samples into audio or video signals. This local clock may be a hardware clock or it may be a virtual clock a software object such as an interrupt service routine that may be assisted by a hardware clock feeding samples to the DAC for conversion to audio or video signals.

These destination clocks are continuous and smooth in how they increment and therefore smooth in how they render the media. However it may be necessary to adjust for the potential differences in device clocks. One embodiment addresses this adjustment by breaking into two problems. The first problem is detecting the frequency differences. The second problem is adjusting for the differences. To detect the difference one embodiment uses a common event based technique rather than a common clock.

In one embodiment any series of events that are received by all the destination devices and where each event is uniquely identifiable and where each event is received by all the destination devices as the same time may be used as the common event described here. In one embodiment the synchronization manager S is the source of such common events.

The synchronization calculation manager S may reside on any computing device on the network including on a destination device .

Each destination device x has a local clock Dx that is used as the basis for rendering media by the device.

Each destination device x on receipt of an event message n sends an event Acknowledge message AK Dx for the nth event with the value Dx that was recorded on receipt of the event n and the unique event number n to the synchronization calculation manager S . The synchronization calculation manager receives all event Acknowledge messages AK Dx with Dxvalues in them performs calculations and then sends back clock adjustment messages AJ Ax to each device x with Adjustment information Axin it. The calculations performed are shown below 

In this common event system one device s clock the first destination device device 1 is used as the phase reference clock. With these calculations the synchronization module computes a phase offset local clock value and a percent frequency local clock rate adjustment for each destination device x sends this adjustment information to the destination x and asks it to make adjustments so that the local clock at each destination device x will match that of the local clock of destination device 1.

For example ignoring the jitter if between common even event 1 E1 and event 2 E2 the first destination devices local clock increments 100 counts and destination device x increments 101 counts then device x is running fast with respect to destination device 1 and its clock rate needs to be decreased by 1 count out of 101. Further more if the 1st destination devices local clock was 2500 at Event 1 E1 and destination x local clock was 3000 at Event 1 E1 then destination x s local clock needs to be adjusted to 2500 to match the phase of the 1st destination device.

While this embodiment defines the frequency adjustment as a percent of frequency other embodiments may define the frequency adjustment in other forms including an absolute new frequency or the number of samples to add or drop. All of these forms are referred to as frequency adjustment for the purpose of this specification. Also the use of the word frequency refers to a clock rate and is related and may refer to both the audio sample crystal rate and the sample output rate. Generally the sample output rate is a multiple of the audio sample crystal rate.

The phase adjustment refers to the adjustment of a clock value and the clock value may be for a clock incrementing at the audio crystal rate or the sample output clock output rate or some other counter value related to the sample output clock.

A key issue in this common event system is that the acknowledge messages and adjustment messages may not arrive at a predictable time at the receiving end as they are being sent over an IP network. Each acknowledge message includes the destination device number.

Therefore the synchronization module cannot group acknowledge messages for the same event by time of arrival. For example some acknowledge messages for Event 1 may arrive at the synchronization Module after acknowledge messages for Event 2 arrive. Therefore acknowledge messages are grouped into sets of event acknowledge messages based on the unique event number.

To do this the synchronization module can associate all acknowledge messages sent from the set of destination devices for each Unique EVENT. Therefore the synchronization module marks each event message with a number n which is unique over time for the lifetime of the system. This may simply be an event number that increments with each event. All the destination devices include this unique event number in the acknowledge messages AK . When ever an acknowledge messages AK is received at the synchronization Module the acknowledge messages are placed in a collection of acknowledge messages AK Dab . . . AK D1n . . . AK Dxn AK D1n 1 . . . etc. Then this collection is searched to find a subset of all the acknowledge messages for a particular event number n AK D1n . . . AK Dxn . Then the phase change Qxn with respect to device 1 is calculated using the values from this subset as shown in the calculations above. The values in this subset may be further filtered prior to use.

In an alternate embodiment the event messages may come from an outside source such as by using the beacon messages of the Wi Fi system. In this case the time value in the beacon messages may be used as a unique event number. Note the time value is not used as a time value but only as a unique event number

Overall the common clock method aligns all clocks with the common clock at the source the adjustment calculations are done independently at each destination and the accuracy is dependent on recording accuracy Rx and transport jitter Jx.

The lower plot shows the common event approach used in various embodiments of the invention. In this approach clock D1 of first destination device becomes a reference global clock used in the system. Additional destination devices adjust their clocks Dx to the global clock of D1 . Phase differences P of these clocks are unaffected by transport latencies and only related by how accurately they record a common event at the point of receipt. Transport latency L1 is only a factor in projecting global clock back to source . In an embodiment of the invention source adjusts its clock to match destination clock D1 if needed. In this embodiment there is no need for a source clock or such an adjustment.

Overall the common event approach aligns all clocks with one of the destination clocks and the accuracy is dependent on recording accuracy Rx only. Since transport jitter Jx tends to be many times larger than recording accuracy Rx as transport jitter is affected by all the devices and processes involved in the transport of the message whereas the recording accuracy is only dependent on and local to the destination hardware and its software . Transport jitter can be many milliseconds whereas recording jitter is usually less than a few hundred microseconds. So the common event approach being dependent only on recording accuracy is a better approach to providing high levels of phase synchronization accuracy with less effort and complexity.

The adjustment of the local clock rate can be done in a number of ways. The common approach is to literally adjust the clock rate of the rendering clock. Usually this requires some sort of hardware subsystem that can generate a clock that is adjustable. An alternative approach is to leave the rendering clock alone and to adjust the media data instead. This approach is to convert the sample rate do a sample rate conversion to compensate for the clock rate difference. If a 1 KHz audio signal were sampled at 44.1 KHz and was then rendered by a 44.1 KHz clock the audio signal rendered will be an accurate representation of the original. If the rendering clock is 44 KHz instead then the 1 KHz audio signal will be rendered at a slightly lower tone and will not be an accurate representation of the original. If the audio data were now sample rate converted from 44.1 KHz to 44 KHz and rendered using the 44 KHz rendering clock the 1 KHz audio signal rendered will now again be an accurate representation of the original.

A preferred embodiment of the invention uses the latter sample rate conversion approach. When frequency adjustment messages are received by each destination instead of adjusting the rendering clock each destination performs a sample rate conversion on the data stream increasing or decreasing the sample rate of the data. This has the same net effect as adjusting the rendering clock.

Typically the difference in frequency is related to the accuracy of clock crystals which are specified in PPM parts per million. A 100 PPM crystal is accurate to 

Headings of sections provided in this patent application and the title of this patent application are for convenience only and are not to be taken as limiting the disclosure in any way.

Devices that are in communication with each other need not be in continuous communication with each other unless expressly specified otherwise. In addition devices that are in communication with each other may communicate directly or indirectly through one or more intermediaries logical or physical.

A description of an embodiment with several components in communication with each other does not imply that all such components are required. To the contrary a variety of optional components may be described to illustrate a wide variety of possible embodiments of one or more of the inventions and in order to more fully illustrate one or more aspects of the inventions. Similarly although process steps method steps algorithms or the like may be described in a sequential order such processes methods and algorithms may generally be configured to work in alternate orders unless specifically stated to the contrary. In other words any sequence or order of steps that may be described in this patent application does not in and of itself indicate a requirement that the steps be performed in that order. The steps of described processes may be performed in any order practical. Further some steps may be performed simultaneously despite being described or implied as occurring non simultaneously e.g. because one step is described after the other step . Moreover the illustration of a process by its depiction in a drawing does not imply that the illustrated process is exclusive of other variations and modifications thereto does not imply that the illustrated process or any of its steps are necessary to one or more of the invention s and does not imply that the illustrated process is preferred. Also steps are generally described once per embodiment but this does not mean they must occur once or that they may only occur once each time a process method or algorithm is carried out or executed. Some steps may be omitted in some embodiments or some occurrences or some steps may be executed more than once in a given embodiment or occurrence.

When a single device or article is described it will be readily apparent that more than one device or article may be used in place of a single device or article. Similarly where more than one device or article is described it will be readily apparent that a single device or article may be used in place of the more than one device or article.

The functionality or the features of a device may be alternatively embodied by one or more other devices that are not explicitly described as having such functionality or features. Thus other embodiments of one or more of the inventions need not include the device itself.

Techniques and mechanisms described or referenced herein will sometimes be described in singular form for clarity. However it should be noted that particular embodiments include multiple iterations of a technique or multiple instantiations of a mechanism unless noted otherwise. Process descriptions or blocks in figures should be understood as representing modules segments or portions of code which include one or more executable instructions for implementing specific logical functions or steps in the process. Alternate implementations are included within the scope of embodiments of the present invention in which for example functions may be executed out of order from that shown or discussed including substantially concurrently or in reverse order depending on the functionality involved as would be understood by those having ordinary skill in the art.

Generally the techniques disclosed herein may be implemented on hardware or a combination of software and hardware. For example they may be implemented in an operating system kernel in a separate user process in a library package bound into network applications on a specially constructed machine on an application specific integrated circuit ASIC or on a network interface card.

Software hardware hybrid implementations of at least some of the embodiments disclosed herein may be implemented on a programmable network resident machine which should be understood to include intermittently connected network aware machines selectively activated or reconfigured by a computer program stored in memory. Such network devices may have multiple network interfaces that may be configured or designed to utilize different types of network communication protocols. A general architecture for some of these machines may be disclosed herein in order to illustrate one or more exemplary means by which a given unit of functionality may be implemented. According to specific embodiments at least some of the features or functionalities of the various embodiments disclosed herein may be implemented on one or more general purpose computers associated with one or more networks such as for example an end user computer system a client computer a network server or other server system a mobile computing device e.g. tablet computing device mobile phone smartphone laptop and the like a consumer electronic device a music player or any other suitable electronic device router switch or the like or any combination thereof. In at least some embodiments at least some of the features or functionalities of the various embodiments disclosed herein may be implemented in one or more virtualized computing environments e.g. network computing clouds virtual machines hosted on one or more physical computing machines or the like . Moreover in some embodiments one or more aspects or all aspects of the invention may optionally be implemented via a specially programmed chip for instance an application specific integrated circuit or ASIC or an erasable programmable read only memory or EPROM or via some other hardware only approach known in the art.

Referring now to there is shown a block diagram depicting an exemplary computing device suitable for implementing at least a portion of the features or functionalities disclosed herein. Computing device may be for example any one of the computing machines listed in the previous paragraph or indeed any other electronic device capable of executing software or hardware based instructions according to one or more programs stored in memory. Computing device may be adapted to communicate with a plurality of other computing devices such as clients or servers over communications networks such as a wide area network a metropolitan area network a local area network a wireless network the Internet or any other network using known protocols for such communication whether wireless or wired.

In one embodiment computing device includes one or more central processing units CPU one or more interfaces and one or more busses such as a peripheral component interconnect PCI bus . When acting under the control of appropriate software or firmware CPU may be responsible for implementing specific functions associated with the functions of a specifically configured computing device or machine. For example in at least one embodiment a computing device may be configured or designed to function as a server system utilizing CPU local memory and or remote memory and interface s . In at least one embodiment CPU may be caused to perform one or more of the different types of functions and or operations under the control of software modules or components which for example may include an operating system and any appropriate applications software drivers and the like.

CPU may include one or more processors such as for example a processor from one of the Intel ARM Qualcomm and AMD families of microprocessors. In some embodiments processors may include specially designed hardware such as application specific integrated circuits ASICs electrically erasable programmable read only memories EEPROMs field programmable gate arrays FPGAs and so forth for controlling operations of computing device . In a specific embodiment a local memory such as non volatile random access memory RAM and or read only memory ROM including for example one or more levels of cached memory may also form part of CPU . However there are many different ways in which memory may be coupled to system . Memory may be used for a variety of purposes such as for example caching and or storing data programming instructions and the like.

As used herein the term processor is not limited merely to those integrated circuits referred to in the art as a processor a mobile processor or a microprocessor but broadly refers to a microcontroller a microcomputer a programmable logic controller an application specific integrated circuit and any other programmable circuit.

In one embodiment interfaces are provided as network interface cards NICs . Generally NICs control the sending and receiving of data packets over a computer network other types of interfaces may for example support other peripherals used with computing device . Among the interfaces that may be provided are Ethernet interfaces frame relay interfaces cable interfaces DSL interfaces token ring interfaces graphics interfaces and the like. In addition various types of interfaces may be provided such as for example universal serial bus USB Serial Ethernet Firewire PCI parallel radio frequency RF Bluetooth near field communications e.g. using near field magnetics 802.11 WiFi frame relay TCP IP ISDN fast Ethernet interfaces Gigabit Ethernet interfaces asynchronous transfer mode ATM interfaces high speed serial interface HSSI interfaces Point of Sale POS interfaces fiber data distributed interfaces FDDIs and the like. Generally such interfaces may include ports appropriate for communication with appropriate media. In some cases they may also include an independent processor and in some in stances volatile and or non volatile memory e.g. RAM .

Although the system shown in illustrates one specific architecture for a computing device for implementing one or more of the inventions described herein it is by no means the only device architecture on which at least a portion of the features and techniques described herein may be implemented. For example architectures having one or any number of processors may be used and such processors may be present in a single device or distributed among any number of devices. In one embodiment a single processor handles communications as well as routing computations while in other embodiments a separate dedicated communications processor may be provided. In various embodiments different types of features or functionalities may be implemented in a system according to the invention that includes a client device such as a tablet device or smartphone running client software and server systems such as a server system described in more detail below .

Regardless of network device configuration the system of the present invention may employ one or more memories or memory modules such as for example remote memory block and local memory configured to store data program instructions for the general purpose network operations or other information relating to the functionality of the embodiments described herein or any combinations of the above . Program instructions may control execution of or comprise an operating system and or one or more applications for example. Memory or memories may also be configured to store data structures configuration data encryption data historical system operations information or any other specific or generic non program information described herein.

Because such information and program instructions may be employed to implement one or more systems or methods described herein at least some network device embodiments may include nontransitory machine readable storage media which for example may be configured or designed to store program instructions state information and the like for performing various operations described herein. Examples of such nontransitory machine readable storage media include but are not limited to magnetic media such as hard disks floppy disks and magnetic tape optical media such as CD ROM disks magneto optical media such as optical disks and hardware devices that are specially configured to store and perform program instructions such as read only memory devices ROM flash memory solid state drives memristor memory random access memory RAM and the like. Examples of program instructions include both object code such as may be produced by a compiler machine code such as may be produced by an assembler or a linker byte code such as may be generated by for example a Java compiler and may be executed using a Java virtual machine or equivalent or files containing higher level code that may be executed by the computer using an interpreter for example scripts written in Python Perl Ruby Groovy or any other scripting language .

In some embodiments systems according to the present invention may be implemented on a standalone computing system. Referring now to there is shown a block diagram depicting a typical exemplary architecture of one or more embodiments or components thereof on a standalone computing system. Computing device includes processors that may run software that carry out one or more functions or applications of embodiments of the invention such as for example a client application . Processors may carry out computing instructions under control of an operating system such as for example a version of Microsoft s Windows operating system Apple s Mac OS X or iOS operating systems some variety of the Linux operating system Google s Android operating system or the like. In many cases one or more shared services may be operable in system and may be useful for providing common services to client applications . Services may for example be Windows services user space common services in a Linux environment or any other type of common service architecture used with operating system . Input devices may be of any type suitable for receiving user input including for example a keyboard touchscreen microphone for example for voice input mouse touchpad trackball or any combination thereof. Output devices may be of any type suitable for providing output to one or more users whether remote or local to system and may include for example one or more screens for visual output speakers printers or any combination thereof. Memory may be random access memory having any structure and architecture known in the art for use by processors for example to run software. Storage devices may be any magnetic optical mechanical memristor or electrical storage device for storage of data in digital form. Examples of storage devices include flash memory magnetic hard drive CD ROM and or the like.

In some embodiments systems of the present invention may be implemented on a distributed computing network such as one having any number of clients and or servers. Referring now to there is shown a block diagram depicting an exemplary architecture for implementing at least a portion of a system according to an embodiment of the invention on a distributed computing network. According to the embodiment any number of clients may be provided. Each client may run software for implementing client side portions of the present invention clients may comprise a system such as that illustrated in . In addition any number of servers may be provided for handling requests received from one or more clients . Clients and servers may communicate with one another via one or more electronic networks which may be in various embodiments any of the Internet a wide area network a mobile telephony network a wireless network such as WiFi Wimax and so forth or a local area network or indeed any network topology known in the art the invention does not prefer any one network topology over any other . Networks may be implemented using any known network protocols including for example wired and or wireless protocols.

In addition in some embodiments servers may call external services when needed to obtain additional information or to refer to additional data concerning a particular call. Communications with external services may take place for example via one or more networks . In various embodiments external services may comprise web enabled services or functionality related to or installed on the hardware device itself. For example in an embodiment where client applications are implemented on a smartphone or other electronic device client applications may obtain information stored in a server system in the cloud or on an external service deployed on one or more of a particular enterprise s or user s premises.

In some embodiments of the invention clients or servers or both may make use of one or more specialized services or appliances that may be deployed locally or remotely across one or more networks . For example one or more databases may be used or referred to by one or more embodiments of the invention. It should be understood by one having ordinary skill in the art that databases may be arranged in a wide variety of architectures and using a wide variety of data access and manipulation means. For example in various embodiments one or more databases may comprise a relational database system using a structured query language SQL while others may comprise an alternative data storage technology such as those referred to in the art as NoSQL for example Hadoop Cassandra Google BigTable and so forth . In some embodiments variant database architectures such as column oriented databases in memory databases clustered databases distributed databases or even flat file data repositories may be used according to the invention. It will be appreciated by one having ordinary skill in the art that any combination of known or future database technologies may be used as appropriate unless a specific database technology or a specific arrangement of components is specified for a particular embodiment herein. Moreover it should be appreciated that the term database as used herein may refer to a physical database machine a cluster of machines acting as a single database system or a logical database within an overall database management system. Unless a specific meaning is specified for a given use of the term database it should be construed to mean any of these senses of the word all of which are understood as a plain meaning of the term database by those having ordinary skill in the art.

Similarly most embodiments of the invention may make use of one or more security systems and configuration systems . Security and configuration management are common information technology IT and web functions and some amount of each are generally associated with any IT or web systems. It should be understood by one having ordinary skill in the art that any configuration or security subsystems known in the art now or in the future may be used in conjunction with embodiments of the invention without limitation unless a specific security or configuration system or approach is specifically required by the description of any specific embodiment.

In various embodiments functionality for implementing systems or methods of the present invention may be distributed among any number of client and or server components. For example various software modules may be implemented for performing various functions in connection with the present invention and such modules can be variously implemented to run on server and or client components.

The various embodiments disclosed herein accordingly enable the sending of media from a source to multiple media devices such as TV and speakers in the same listening and viewing space. According toe the embodiments this may be done over a wireless network such as Wi Fi. The various embodiments enable all of the media rendering devices such as speakers that are in the same listening or viewing zone to be precisely synchronized to each other so the listener and or viewer does not discern any unintended media experience.

The skilled person will be aware of a range of possible modifications of the various embodiments described above. Accordingly the present invention is defined by the claims and their equivalents.

