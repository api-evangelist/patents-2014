---

title: Workflow processing in a distributed computing environment
abstract: An example method is provided to perform workflow processing in a distributed computing environment comprising a first node, a second node and a data store accessible by the first node and second node. The method may comprise the first node retrieving, from the data store, state information associated with a workflow being processed by the second node. The method may further comprise, in response to determination that load balancing from the second node to the first node is required based on the state information of the workflow, the first node initiating the load balancing by updating the state information of the workflow in the data store. If the state information is successfully updated, the first node may resume processing of the workflow by performing a workflow step to be completed by the second node, but otherwise, abandon the load balancing.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09444885&OS=09444885&RS=09444885
owner: VMware, Inc.
number: 09444885
owner_city: Palo Alto
owner_country: US
publication_date: 20140318
---
Unless otherwise indicated herein the approaches described in this section are not admitted to be prior art by inclusion in this section.

Distributed computing environments are increasingly utilized to support various commercial and technical applications. A distributed computing environment includes multiple nodes that are generally designed to operate independently. Nodes may be added as necessary facilitating scalability and load sharing. Among the challenges with distributed computing environments is the handling of faulty nodes that cause defective or incomplete application processing. Nodes may fail or restart due to various reasons such as hardware failures software failures network failures and other factors such as an earthquake fire or flood etc.

In the following detailed description reference is made to the accompanying drawings which form a part hereof. In the drawings similar symbols typically identify similar components unless context dictates otherwise. The illustrative embodiments described in the detailed description drawings and claims are not meant to be limiting. Other embodiments may be utilized and other changes may be made without departing from the spirit or scope of the subject matter presented here. It will be readily understood that the aspects of the present disclosure as generally described herein and illustrated in the drawings can be arranged substituted combined and designed in a wide variety of different configurations all of which are explicitly contemplated herein.

Nodes in a distributed computing environment may be used for workflow processing. In contrast to conventional processing of a single piece of software code a workflow may be constructed by creating a series of workflow steps and linking them together to complete for example a long operation task procedure routine function etc. For example a workflow may include three interdependent workflow steps where workflow step depends from workflow step which in turn depends from workflow step . Workflow steps and in that order may be performed separately by one or more nodes.

Throughout the present disclosure a node may be any suitable physical or logical entity to perform workflow processing such as a physical server virtual machine host etc. Nodes may be implemented using any suitable technique for example each may run an instance of Workflow Engine not shown for simplicity to process workflows as a series of workflow steps. Although not shown distributed computing environment may include any suitable communication architecture to facilitate communication among nodes . Also multiple nodes may be supported by the same physical entity or different physical entities.

To facilitate workflow processing distributed computing environment further includes shared data store accessible by nodes . Data store may employ any suitable data storage technology such as horizontally scalable NoSQL Not only Structured Query Language that uses key value KV data structure etc.

Nodes may be dynamically and independently added and removed in distributed computing environment . Multiple nodes may be grouped together as a cluster which represents an aggregate set of resources in distributed computing environment . Nodes may be dynamically added to or removed from a cluster and a cluster of nodes may access the same data store for workflow processing and load sharing. In this case distributed computing environment is also known as a clustered environment.

Data store stores state information of workflows e.g. Workflow to M etc. that are being processed by various nodes . Workflow processing by nodes may be based on workflow creation requests from clients e.g. to K etc. which will be collectively referred to as clients or individually as a general client . After workflow processing is completed workflow result if any is sent by node to the requesting client . Instead of sending the result the requesting client may retrieve state information of the workflow in data store to ascertain whether it has been completed.

In distributed computing environment there might be situations where node e.g. second node fails to complete a workflow e.g. Workflow due to reasons such as failures and restarts etc. In these situations node e.g. second node might remain in a stalled state before it recovers thus impeding the progress of the workflow and possibly hindering that of other workflows. To complete the workflow load balancing may be performed such that workflow processing is resumed by another node e.g. first node . Effectively as indicated by arrow first node steals the workflow from second node .

State information may include any suitable information from which the requirement for load balancing may be determined and processing of a workflow may be resumed. For example state information may include without limitation attribute e.g. lastUpdateTime that relates to a time the workflow was last updated in data store and event from which an incomplete workflow step may be determined etc.

An event may generally describe what has occurred in a previous workflow step and may be used to determine the next workflow step such as to resume processing of the workflow after load balancing . As such workflow processing by nodes may be event based which involves handling one event after another until there are no more events and corresponding workflow steps. Each workflow step except the first may be triggered by an event that has not been handled or processed. For example the next workflow step may be determined programmatically by each event and handling of the event causes the execution of the next workflow step.

In the example in events are stored in the form of a journal log each having a processing time e.g. maximum processing time maxPrTime associated with the time required for a node to handle the corresponding event and workflow step. Different workflow steps may have different processing times. Although maxPrTime is provided as an example it will be appreciated that an expected or average processing time of the event etc. may be recorded.

After each workflow step is completed journal log may be updated with a new event to mark its completion. A handled event may be removed from journal log or simply marked as handled and not considered in subsequent steps. After handling each event the whole workflow state may be persisted into data store e.g. as a single JSON Java Script Object Notion document together with its journal log where that handled event is not present anymore.

At block first node retrieves from data store state information associated with a workflow e.g. Workflow being processed by second node . At block the first node determines whether load balancing from second node to first node is required based on state information of the workflow.

For example the retrieved state information may include attribute i.e. lastUpdateTime event associated with a workflow step to be completed by second node and processing time i.e. maxPrTime . Based on state information first node may determine that load balancing is required if the retrieved processing time of event i.e. maxPrTime has elapsed since state information was last updated i.e. lastUpdateTime .

At block in response to determination that load balancing is required the first node initiates the load balancing by updating state information of the workflow in data store . For example load balancing may be initiated by first node updating attribute i.e. lastUpdateTime .

At blocks and if state information is successfully updated first node resumes processing of the workflow and performs a workflow step to be completed by the second node based on state information . Otherwise at block first node abandons the load balancing .

Example process provides resilience to failures and restarts of nodes in distributed computing environment . State information of the workflow being processed by second node is stored in data store and accessible by first node for load balancing . When it is determined that load balancing is required e.g. due to failure or restart of the second node etc. first node initiates load balancing to resume processing of the workflow.

According to example process state information of the workflow may be updated and persistently stored in data store by second node after each workflow step is completed. This allows first node to determine what workflow step is to be completed such that it can take over without having to repeat any previous workflow steps. Any suitable technique may be used to update state information such as via an Application Programming Interface API provided by data store etc.

According to example process since workflow steps may be performed more than once due to load balancing e.g. initially by second node followed by first node according to example process workflow steps may be designed as idempotent steps such that they may be safely repeated. The term idempotent may generally refer to the steps producing the same effect and result in the same state information whether they are invoked once or many times. Idempotent steps may be performed using any suitable technique such as if there are multiple operations inside a single workflow step some operations may be determined e.g. programmatically as not necessary.

Example process may also reduce the likelihood of if not prevent multiple nodes in distributed computing environment processing the same workflow. In particular first node resumes processing of the workflow after successfully updating its state information in data store . Otherwise if first node fails to update state information e.g. due to load balancing by a third node before the attempt by first node etc. first node will abandon load balancing . Therefore this reduces the likelihood of if not prevents conflicts between multiple nodes attempting to steal the same workflow.

Since nodes in distributed computing environment may independently determine whether load balancing is required and resume processing of workflows based on state information in shared data store scalability is supported in distributed computing environment . Example process should be contrasted with a centralized approach which requires a central controller to monitor workflows being processed by various nodes and direct load balancing using a messaging system.

The centralized approach has a number of disadvantages. The central controller usually requires current knowledge of all nodes to make load balancing decisions which necessitating communication links from each node to the central controller. The centralized approach often has poor scalability due to rapid increase of overheads as the number of nodes increases. Also failure of the central controller will lead to defective load balancing. By contrast load balancing decisions are decentralized to nodes according to example process . Further since load balancing is abandoned by each node when update of the state information fails a locking service e.g. cluster wide to manage conflicts between nodes is not required.

Workflows processing may be implemented using any suitable technique such as object oriented programming etc. For example journal log may be implemented as an object with a class that inherits a common base class defining maxPrTime as an attribute. Attribute lastUpdateTime may be part of an abstract base workflow class so that the Workflow Engine instance of each node may process different workflows in a similar way. All concrete workflows extend the base workflow class and inherit attribute lastUpdateTime . Event may be implemented as a class that programmatically specifies the associated next workflow step.

Examples of workflow processing by second node and first node will now be explained in more detail with reference to and respectively.

In the example in second node is processing a ChangeUserName workflow to change the name of a user with userId 394523048 from oldName Name1 to newName Name2. Any other suitable workflow with or without input parameters may be processed in a similar manner.

At block in second node creates a new workflow with input parameters userId 394523048 oldName Name1 and newName Name2 and inserts its state information accordingly. In particular second node inserts attribute lastUpdateTime T see logs the initial event WorkflowScheduledEvent in journal log see and stores the received input parameters as user defined information see . The maximum processing time maxPrTime of the initial event is set as E. For example the initial state information may be prepared in the RAM random access memory of second node and then inserted by second node into data store . In practice state information may be inserted subsequently and updated as a whole e.g. as a single JSON document . As indicated at the first workflow step i.e. step is associated with event WorkflowScheduledEvent in journal log see .

At block in second node performs step of the ChangeUserName workflow and updates its state information accordingly. In the example in second node handles the top event logged at block in journal log i.e. WorkflowScheduledEvent see . The event triggers step that reserves newName Name2 against a Name Reservation System.

After successfully completing step second node updates state information of the Workflow in data store . In particular second node updates attribute lastUpdateTime T see and logs new event NewUserNameReservedEvent see with maxPrTime E. User defined information see remains unchanged and not shown for simplicity in subsequent steps. Since WorkflowScheduledEvent see is handled second node also removes it from data store . As indicated at new event NewUserNameReservedEvent see is associated with the next workflow step i.e. step .

At block in second node performs step of the ChangeUserName workflow and updates its state information accordingly. In the example in handling of the top event logged at block in journal log i.e. NewUserNameReservedEvent see triggers step that updates a User Entity denoted by user defined state userId 394523048. After successfully completing step second node updates lastUpdateTime T see and logs new event UserEntityNameUpdatedEvent see with maxPrTime E. The previous event see is removed from data store . As indicated at new event UserEntityNameUpdatedEvent see is associated with the next workflow step i.e. step .

At block in workflow processing continues with second node performing step and updates state information of the workflow accordingly. In particular handling of UserEntityNameUpdatedEvent see triggers step that releases oldName Name1 against the Name Reservation System previously accessed at block .

After successfully executing step second node persists new state information that includes attribute lastUpdateTime T see and new event OldUserNameReleasedEvent see in data store . Event UserEntityNameUpdatedEvent see is removed from data store . As indicated at new event OldUserNameReleasedEvent see is associated with the next workflow step i.e. step .

Similarly at block in second node performs step and updates state information of the workflow accordingly. Since step is the last step in the workflow handling of the top event in journal log OldUserNameReleasedEvent see results in a dummy step and no new event is logged. Second node updates state information by deleting it from data store because ChangeUserName workflow is successfully completed.

Blocks to in may be summarized using the pseudo code in Table 1. After a pending workflow is obtained see line 1 an event based workflow processing is performed where the workflow is processed as a series of steps see line 2 by handling one event after another see line 3 and updating state information in data store after performing each corresponding workflow step see line 4 .

According to blocks to in second node persistently stores state information of Workflow in data store after successfully completing each step. If second node fails to complete a particular step another node such as first node may resume processing of Workflow based on persisted state information without having to repeat any of the previous completed steps.

For example at in consider the situation where second node fails to complete step associated with event UserEntityNameUpdatedEvent see and does not update attribute lastUpdateTime and journal log . In this case first node may initiate load balancing from second node to itself and resume processing of Workflow .

At block in related to in first node retrieves state information of Workflow from data store . For example first node may implement a Workflow Monitor component not shown for simplicity that scans data store such as once at start up and then periodically at regular intervals. A snapshot of Workflow may be retrieved including state information of Workflow that is updated by second node at block in .

At block in related to in first node determines whether load balancing is required such as whether second node is taking too long to complete step associated with event UserEntityNameUpdatedEvent see . The Workflow Monitor component of first node may include an isEligibleForRebalance routine that is invoked to determine if maxPrTime E see has elapsed since lastUpdateTime T see . If yes first node determines that load balancing is required to resume processing of Workflow effectively stealing it from second node .

First node may retrieve state information of Workflow i.e. block and determine whether load balancing is required i.e. block after determining that it has the capacity to perform additional workflow processing i.e.to resume processing of Workflow . For example nodes may use multi thread programming to execute threads simultaneously. A ThreadPoolExecutor component each node maintains a bounded queue of 1000 workflows which means that 100 workflow steps from 1000 workflows may be performed concurrently. If the queue is at or near full capacity first node may decide not to take on Workflow . Further if first node does not have any more capacity its Workflow Monitor component may pause scanning using isEligibleForRebalance for a period of time and resume scanning when it has capacity.

At block in related to in first node initiates load balancing by updating state information of Workflow . In this example first node updates attribute lastUpdateTime from T see to T see .

At blocks and in related to and in if lastUpdateTime T see is successfully updated to T first node resumes processing of Workflow by performing a step to be completed by second node . For example handling of UserEntityNameUpdatedEvent see triggers step which releases oldName Name1 against a Name Reservation System.

After completing step first node persists new state information that includes attribute lastUpdateTime T see and new event OldUserNameReleasedEvent see in data store . The previous event UserEntityNameUpdatedEvent see is removed from data store .

Block in is similar to block in . First node performs final step triggered by OldUserNameReleasedEvent see which results in a dummy step and no new event is logged. Since all steps have been completed state information of Workflow is deleted from data store .

At blocks and in related to and in since attribute lastUpdateTime T see is not successfully updated from T to T first node abandons load balancing .

As will be described with reference to the purpose of the abandonment is to reduce the likelihood of or prevent a conflict caused by multiple nodes processing the same workflow.

In the example in third node successfully performs load balancing and resumes processing of Workflow . To reduce the likelihood if not avoid first node stealing the same Workflow an optimistic locking approach may be used. This means first node is not permitted to update state information if third node updated the same state information after it was last retrieved by first node . This in between update causes the first node to abandon its load balancing attempt.

As will be explained with reference to and Table 2 below the optimistic locking approach may be based on version numbers. Compared to corresponding Table 1 when retrieving state information of pending Workflow see line 1 its version number e.g. version is also obtained. If state information is successfully updated see line 4 data store returns an updated version number e.g. version . Otherwise i.e. update has failed a programmatic exception such as an optimistic locking exception or OptimisticLockingException is experienced by the requesting node e.g. first node .

Version numbers before and after an update are indicated at e.g. version and e.g. version in respectively. Although version numbers and are shown to be part of state information in as an example and for easy reference it should be understood that it is not mandatory for data store to store versioning information of a workflow e.g. as part of an entity row or record associated with the workflow . The versioning information may simply be internally managed by data store and supplied by an API of data store to nodes .

At in after first node retrieves state information see third node updates version of state information of Workflow successfully. This updates attribute lastUpdateTime from T to Tand increases the version number to version see .

Due to this in between update by third node when first node attempts to update version of state information of Workflow at in the update will not be successful because the version number is now version . As such when Workflow is stolen by third node it cannot be immediately stolen again by a different node i.e. first node in this example.

Since the update at in is not successful first node also experiences OptimisticLockingException . First node then abandons the load balancing and leaves state information of Workflow unchanged.

Referring to Table 2 again OptimisticLockingException may be thrown after first node attempts to update attribute lastUpdateTime using workflowRepository.updateWorkflow Workflow version at line 5. In general optimistic locking may be used for low contended resources such as in the present workflow processing application.

At in if second node tries to update attribute lastUpdateTime e.g. after recovering from a failure of version it may also experience exception OptimisticLockingException since the most recent version number is version . Also if and when second node refreshes state information of Workflow it will learn that attribute lastUpdateTime and corresponding version number have been updated i.e. an indication that Workflow has been stolen and load balancing has occurred.

Although not shown in to state information of a workflow may further include an additional attribute that identifies node that successfully updates state information i.e. lastUpdateNodeIdentifier . Similarly if and when second node refreshes state information of Workflow after experiencing OptimisticLockingException the additional attribute may be used as an indication to second node as to which node has stolen Workflow .

The above examples can be implemented by hardware software or firmware or a combination thereof. is a schematic diagram of an example computer system for workflow processing in distributed computing environment . Example computer system is capable of acting as first node and second node described herein.

Example computer system may include processor memory network interface device and bus that facilitates communication among these illustrated components and other components. Processor is to perform processes described herein with reference to to . Memory may store relevant information to perform workflow processing in distributed computing environment such as state information of workflows etc. Memory may further store machine readable instructions executable by processor to cause processor to perform processes described herein with reference to to .

The methods processes and components described herein may be implemented by hardware including hardware logic circuitry software or firmware or a combination thereof. The term processor is to be interpreted broadly to include a processing unit ASIC logic unit or programmable gate array etc. The techniques introduced above may be implemented in special purpose hardwired circuitry in software and or firmware in conjunction with programmable circuitry or in a combination thereof. Special purpose hardwired circuitry may be in the form of for example one or more application specific integrated circuits ASICs programmable logic devices PLDs field programmable gate arrays FPGAs and others.

Software and or firmware to implement the techniques introduced here may be stored on a non transitory machine readable storage medium and may be executed by one or more general purpose or special purpose programmable microprocessors. A machine readable storage medium as the term is used herein includes any mechanism that provides i.e. stores and or transmits information in a form accessible by a machine e.g. a computer network device personal digital assistant PDA mobile device manufacturing tool any device with a set of one or more processors etc. . For example a machine accessible storage medium includes recordable non recordable media e.g. read only memory ROM random access memory RAM magnetic disk storage media optical storage media flash memory devices etc. 

The figures are only illustrations of an example wherein the units components or processes shown in the figures are not necessarily essential for implementing the present disclosure. Those skilled in the art will understand that the units in the device in the example can be arranged in the device in the examples as described or can be alternatively located in one or more devices different from that in the examples. The units in the examples described can be combined into one module or further divided into a plurality of sub units.

It will be appreciated by persons skilled in the art that numerous variations and or modifications may be made to the above described embodiments without departing from the broad general scope of the present disclosure. The present embodiments are therefore to be considered in all respects as illustrative and not restrictive.

