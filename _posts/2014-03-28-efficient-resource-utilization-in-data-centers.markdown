---

title: Efficient resource utilization in data centers
abstract: A method for efficiently using resources (e.g., memory devices) in data centers of a distributed storage system includes identifying high-availability jobs and low-availability jobs that demand usage of resources of the distributed system. The method further includes allocating resource usage to the jobs, determining a first load of the jobs on resources available during a failure event, and determining a second load of the jobs on the resources lost during the failure event. The method includes determining a scaled third load of the jobs on the resources available during the failure event based on the first and second loads and reallocating resource usage assigned to the low-availability jobs to the high-availability jobs during the failure event. The reallocation is associated with the scaled third load of the jobs.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=09311194&OS=09311194&RS=09311194
owner: Google Inc.
number: 09311194
owner_city: Mountain View
owner_country: US
publication_date: 20140328
---
This disclosure relates to efficiently using storage resources in data centers during maintenance or a failure of one or more of the storage resources.

A distributed system generally includes many loosely coupled computers each of which typically includes a computing resource e.g. one or more processors and or storage resources e.g. memory flash memory and or disks . A distributed storage system overlays a storage abstraction e.g. key value store or file system on the storage resources of a distributed system. In the distributed storage system a server process running on one computer can export that computer s storage resources to client processes running on other computers. Remote procedure calls RPC may transfer data from server processes to client processes. Alternatively Remote Direct Memory Access RDMA primitives may be used to transfer data from server hardware to client processes.

One aspect of the disclosure provides a method executed on a data processing device for efficiently using resources e.g. memory devices in data centers of a distributed storage system. The method includes identifying high availability jobs and low availability jobs that demand usage of resources of the distributed system. The method further includes allocating resource usage to the jobs determining a first load of the jobs on resources available during a failure event and determining a second load of the jobs on the resources lost during the failure event. The method includes determining a scaled third load of the jobs on the resources available during the failure event based on the first and second loads and reallocating resource usage assigned to the low availability jobs to the high availability jobs during the failure event. The reallocation is associated with the scaled third load of the jobs.

Implementations of the disclosure may include one or more of the following features. In some implementations the high availability jobs have a higher execution priority than the low availability jobs. The resources may include non transitory memory devices.

In some implementations determining the scaled third load of the jobs includes using a scaling factor corresponding to an increased load on the resources available during the failure event to handle any jobs associated with the resources lost during the failure event. The scaling factor is based on a type of encoding of data.

In some examples when the resources include data storage resources having spindles and the jobs all include high availability read jobs or low availability read jobs the method includes determining a number of read requests per spindle for reallocating the resource usage based on the read requests per spindle. Additionally or alternatively the method includes determining a read maximum fraction for reallocating the resource usage based on the read maximum fraction.

In some implementations when the resources include data storage resources having spindles and the jobs all include high availability jobs or low availability jobs the method includes determining an adjusted request for read operations during the failure event used for reallocating the resource usage based on the adjusted request for read operations. Additionally or alternatively the method includes determining an overall spindle demand during the failure event for reallocating the resource usage based on the overall spindle demand during the failure event. The method may further include determining a fraction spindle quota increase per spindle for reallocating the resource usage based on the fraction spindle quota increase. Additionally or alternatively the method may include determining a fraction spindle quota available for the high availability jobs considered for reallocating the resource usage based on the fraction spindle quota.

In some examples the method includes determining a low availability scaled third load of the jobs on temporary resources available during the failure event based on the first and second loads of low availability jobs. When the resources include data storage resources having spindles the method may include determining a fraction of high availability spindle usage prior to the failure event for reallocating the resource usage based on the fraction of high availability spindle usage. Additionally or alternatively the method includes determining an increase factor of low availability job usage for reallocating the resource usage based on the increase factor of low availability job usage.

In some implementations the method includes determining a total of low availability usage per spindle after a resource is lost for reallocating the resource usage based on the total of low availability usage per spindle. Additionally or alternatively the method further includes determining a total spindle usage for reallocating the resource usage based on the total spindle usage.

Another aspect of the disclosure provides a method executed on a data processing device for identifying high availability jobs and low availability jobs that demand usage of data storage resources of a distributed storage system. The data storage resource has spindles. The method further includes determining a spindle quota for the high availability jobs and determining a spindle quota for the low availability jobs. The method further includes redistributing at least a portion of the spindle quota associated with the low availability jobs to the high availability jobs during a failure event.

In some examples when the jobs all include high availability read jobs or low availability read jobs the method includes determining a number of read requests per spindle when a loss of at least one data storage resource occurs. The method also includes determining a read maximum fraction to reallocate the resource usage based on the read requests per spindle or the read maximum fraction.

In some implementations when the jobs all include high availability jobs or low availability jobs the method includes determining a fraction spindle quota increase per spindle and a fraction spindle quota available for the high availability jobs for reallocating the resource usage based on the fraction spindle quota increase or the fraction spindle quota. The method further includes determining a low availability scaled third load of the jobs on temporary resources available during the failure event based on the first and second loads of availability jobs.

In some examples when the resources include data storage resources having spindles the method includes determining a fraction of high availability spindle usage for reallocating the resource usage based on the fraction of high availability spindle usage. Additionally or alternatively the method includes determining an increase factor of low availability job usage and determining a total of low availability usage per spindle for real locating the resource usage based on the total of low availability usage per spindle. The method may further include determining a total spindle usage for reallocating the resource usage based on the total spindle usage.

Yet another aspect of the disclosure provides a system for efficiently using resources e.g. processors and or memory devices in data centers. The system includes resources of a distributed storage system and a computer processor in communication with the resources. The computer processor identifies high availability jobs and low availability jobs that demand usage of resources of a distributed storage system. The high availability jobs have a higher execution priority than the low availability jobs. The computer processor also allocates resource usage to the jobs determines a first load of the jobs on resources available during a failure event determines a second load of the jobs on resources lost during the failure event and determines a scaled third load of the jobs on the resources available during the failure event based on the first and second loads. The computer processor further reallocates resources usage assigned to the low availability jobs to the high availability jobs during the failure event. The reallocation is associated with the scaled third load of the jobs. In some examples the resources include non transitory memory devices.

In some implementations the computer processor determines the scaled third load of the jobs by using a scaling factor corresponding to an increased load on the resources available during the failure event to handle any jobs associated with the resources lost during the failure event. The scaling factor is based on a type of encoding of data. When all the jobs include high availability read jobs or low availability read jobs the computer processor determines a number of read requests per spindle and determines a read maximum fraction which are used for reallocating the resource usage based on the read requests per spindle or the read maximum fraction.

In some examples when the jobs all include high availability jobs or low availability jobs the computer processor determines a fraction spindle quota increase and a fraction spindle quota for reallocating the resource usage based on the fraction spindle quota increase or the fraction spindle quota. The system may further determine a low availability scaled third load of the jobs on temporary resources available during the failure event based on the first and second loads of low availability jobs. The computer processor further determines a fraction of high avail ability spindle usage for reallocating the resource usage based on the fraction of high availability spindle usage.

In some implementations the computer processor determines an increase factor of low availability job usage and determines a total of low availability usage per spindle for reallocating the resource usage based on the total of low availability usage per spindle. The computer processor further determines a total spindle usage to reallocate the resource usage based on the total spindle usage.

The details of one or more implementations of the disclosure are set forth in the accompanying drawings and the description below. Other aspects features and advantages will be apparent from the description and drawings and from the claims.

Referring to in some implementations a distributed storage system includes loosely coupled resource hosts e.g. computers or servers each having a computing resource e.g. one or more processors or central processing units CPUs in communication with storage resources e.g. memory flash memory dynamic random access memory DRAM phase change memory PCM and or disks having spindles that may be used for caching data . A storage abstraction e.g. key value store or file system overlain on the storage resources allows scalable use of the storage resources by one or more clients . The clients may communicate with the resource hosts through a network e.g. via RPC .

The distributed storage system may include multiple layers of redundancy where data is replicated and or encoded and stored in multiple data centers. Data centers not shown house computer systems and their associated components such as telecommunications and storage systems . Data centers usually include backup power supplies redundant communications connections environmental controls to maintain a constant temperature and security devices. Data centers may be large industrial scale operations that use a great amount of electricity e.g. as much as a small town . Data centers may be located in different geographical locations e.g. different cities different countries and different continents . In some examples the data centers or portions thereof requires maintenance e.g. due to a power outage or disconnecting a portion of the storage system for replacing parts or a system failure or a combination thereof . The data stored in these data centers and in particular the distributed storage system may be unavailable to users clients during the maintenance period resulting in the impairment or halt of a user s operations. Therefore it is desirable to provide a distributed storage system capable of efficiently using the storage resources of the resource hosts during a maintenance and or certain data center hardware software failures without moving the data in advance of such a maintenance or failure. The system may adjust a load of the available resources and jobs of the adjusted load may be executed in a predefined order such as high availability jobs before the low availability jobs.

In some implementations the distributed storage system is single sided eliminating the need for any server jobs for responding to remote procedure calls RPC from clients to store or retrieve data on their corresponding resource hosts and may rely on specialized hardware to process remote requests instead. Single sided refers to the method by which most of the request processing on the resource hosts may be done in hardware rather than by software executed on CPUs of the resource hosts . Rather than having a processor of a resource host e.g. a server execute a server process that exports access of the corresponding storage resource e.g. non transitory memory to client processes executing on the clients the clients may directly access the storage resource through a network interface controller NIC of the resource host . In other words a client process executing on a client may directly interface with one or more storage resources without requiring execution of a of any server processes executing on the computing resources . This single sided distributed storage architecture offers relatively high throughput and low latency since clients can access the storage resources without interfacing with the computing resources of the resource hosts . This has the effect of decoupling the requirements for storage and CPU cycles that typical two sided distributed storage systems carry. The single sided distributed storage system can utilize remote storage resources regardless of whether there are spare CPU cycles on that resource host furthermore since single sided operations do not contend for server CPU resources a single sided system can serve cache requests with very predictable low latency even when resource hosts are running at high CPU utilization. Thus the single sided distributed storage system allows higher utilization of both cluster storage and CPU resources than traditional two sided systems while delivering predictable low latency.

In some implementations the distributed storage system includes a storage logic portion e.g. encoding system a data control portion and a data storage portion . The storage logic portion may include a transaction application programming interface API e.g. a single sided transactional system client library that is responsible for accessing the underlying data for example via RPC or single sided operations. The data control portion may manage allocation and access to storage resources with tasks such as allocating storage resources registering storage resources with the corresponding network interface controller setting up connections between the client s and the resource hosts handling errors in case of machine failures etc. The data storage portion may include the loosely coupled resource hosts 

The distributed storage system may store data in dynamic random access memory DRAM and serve the data from the remote hosts via remote direct memory access RDMA capable network interface controllers . A network interface controller also known as a network interface card network adapter or LAN adapter may be a computer hardware component that connects a computing resource to the network . Both the resource hosts and the client may each have a network interface controller for network communications. A host process executing on the computing processor of the resource host registers a set of remote direct memory accessible regions of the memory with the network interface controller . The host process may register the remote direct memory accessible regions of the memory with a permission of read only or read write. The network interface controller of the resource host creates a client key for each registered memory region 

The single sided operations performed by the network interface controllers may be limited to simple reads writes and compare and swap operations none of which may be sophisticated enough to act as a drop in replacement for the software logic implemented by a traditional cache server job to carry out cache requests and manage cache policies. The transaction API translates commands such as look up or insert data commands into sequences of primitive network interface controller operations. The transaction API interfaces with the data control and data storage portions of the distributed storage system .

The distributed storage system may include a co located software process to register memory for remote access with the network interface controllers and set up connections with client processes . Once the connections are set up client processes can access the registered memory via engines in the hardware of the network interface controllers without any involvement from software on the local CPUs of the corresponding resource hosts .

Referring to in some implementations the distributed storage system includes multiple cells each cell including resource hosts and a curator in communication with the resource hosts . The curator e.g. process may execute on a computing processor e.g. server having a non transitory memory connected to the network and manage the data storage e.g. manage a file system stored on the resource hosts control data placements and or initiate data recovery. Moreover the curator may track an existence and storage location of data on the resource hosts . Redundant curators are possible. In some implementations the curator s track the striping of data across multiple resource hosts and the existence and or location of multiple copies of a given stripe for redundancy and or performance. In computer data storage data striping is the technique of segmenting logically sequential data such as a file in a way that accesses of sequential segments are made to different physical storage devices e.g. cells and or resource hosts . Striping is useful when a processing device requests access to data more quickly than a storage device can provide access. By performing segment accesses on multiple devices multiple segments can be accessed concurrently. This provides more data access throughput which avoids causing the processor to idly wait for data accesses.

In some implementations the transaction API interfaces between a client e.g. with the client process and the curator . In some examples the client communicates with the curator through one or more remote procedure calls RPC . In response to a client request the transaction API may find the storage location of certain data on resource host s and obtain a key that allows access to the data . The transaction API communicates directly with the appropriate resource hosts via the network interface controllers to read or write the data e.g. using remote direct memory access . In the case that a resource host is non operational or the data was moved to a different resource host the client request fails prompting the client to re query the curator .

Referring to in some implementations the curator stores and manages file system metadata . The metadata may include a file map that maps files to file descriptors . The curator may examine and modify the representation of its persistent metadata . The curator may use three different access patterns for the metadata read only file transactions and stripe transactions.

Referring to data may be one or more files where each file has a specified replication level and or error correcting code . The curator may divide each file into a collection of stripes with each stripe being replicated or encoded independently from the remaining stripes . For a replicated file each stripe is a single logical chunk that the curator replicates as stripe replicas and stores on multiple storage resources . In that scenario a stripe replica is also referred to as a chunk . For an encoded file each stripe consists of multiple data chunks Dand non data chunks C e.g. code chunks that the curator places on multiple storage resources where the collection of data chunks D and non data chunks C forms a single code word. In general the curator may place each stripe on storage resources independently of how the other stripes in the file are placed on the storage resources . The error correcting code adds redundant data or parity data to a file so that the file can later be recovered by a receiver even when a number of errors tip to the capability of the code being used were introduced. The error correcting code is used to maintain data integrity in storage devices to reconstruct data for performance latency or to more quickly drain machines.

Referring back to in some implementations file descriptors stored by the curator contain metadata such as the file map which maps the stripes to stripe replicas or to data chunks D and non data chunks C as appropriate stored on the memory hosts . To open a file a client sends a request to the curator which returns a file descriptor . The client uses the file descriptor to translate file chunk offsets to remote memory locations . The file descriptor may include a client key e.g. a 32 bit key that is unique to a chunk on a memory host and is used to RDMA read that chunk . After the client loads the file descriptor the client may access the data of a file via RDMA or another data retrieval method.

The curator may maintain status information for all memory hosts that are part of the cell . The status information may include capacity free space load on the memory host latency of the memory host from a client s point of view and a current state. The curator may obtain this information by querying the memory hosts in the cell directly and or by querying a client to gather latency statistics from a client s point of view. In some examples the curator uses the memory host status information to make rebalancing draining recovery decisions and allocation decisions.

The curator s may allocate chunks in order to handle client requests for more storage space in a file and for rebalancing and recovery. In some examples the processor replicates chunks among the storage devices differently than distributing the data chunks D and the code chunks C among the storage devices . The curator may maintain a load map of memory host load and liveliness. In some implementations the curator allocates a chunk by generating a list of candidate memory hosts and sends an allocate chunk request to each of the candidate memory hosts . If the memory host is overloaded or has no available space the memory host can deny the request . In this case the curator selects a different memory host . Each curator may continuously scan its designated portion of the file namespace examining all the metadata every minute or so. The curator may use the tile scan to check the integrity of the metadata determine work that needs to be performed and or to generate statistics. The file scan may operate concurrently with other operations of the curator . The scan itself may not modify the metadata but schedules work to be done by other components of the system and computes statistics.

Referring to each stripe is divided into data chunks D and non data chunks C based on an encoding level e.g. Reed Solomon Codes nested codes or other erasure coding. The non data chunks C may be code chunks C e.g. for Reed Solomon codes . In other examples the non data chunks C may be code check chunks CC word check chunks WC and code check word check chunks CCWC for nested coding .

A data chunk D is a specified amount of data . In some implementations a data chunk D is a contiguous portion of data from a file . In other implementations a data chunk D is one or more non contiguous portions of data from a file . For example a data chunk D can be 256 bytes or other units of data .

A damaged chunk e.g. data chunk D or non data chunk C is a chunk containing one or more errors. Typically a damaged chunk is identified using an error detecting code . For example a damaged chunk can be completely erased e.g. if the chunk was stored in a hard drive destroyed in a hurricane or a damaged chunk can have a single bit flipped. A healthy chunk is a chunk that is not damaged. A damaged chunk can be damaged intentionally for example where a particular resource host is shut down for maintenance. A damaged chunk may be a missing or unavailable chunk . In that case damaged chunks can be identified by identifying chunks that are stored at resource hosts that are being shut down. In some implementations damaged chunks may be recovered using healthy chunks . Damaged chunks e.g. data chunks D or non data chunks C may be damaged due to various reasons. Damaged chunks within a stripe may be recovered from the healthy chunks . The non data chunks C of a file include an error correcting code chunk . The error correcting code chunks include a chunk of data based on one or more data chunks D. In some implementations each code chunk C is the same specified size e.g. 256 bytes as the data chunks D. The code chunks C are generated using an error correcting code e.g. a Maximal Distance Separable MDS code. Examples of MDS codes include Reed Solomon codes. Various techniques can be used to generate the code chunks C. In general any error correcting code can be used that can reconstruct d data chunks D from any set of d unique healthy chunks either data chunks D or code chunks C .

A codeword is a set of data chunks D and code chunks C based on those data chunks D. If an MDS code is used to generate a codeword containing d data chunks D and c code chunks C then all of the chunks data or code can be reconstructed as long as any healthy chunks data or code are available from the codeword.

Referring to in nested coding techniques an encoded data block includes a data block having data chunks D and error correcting code chunks i.e. non data chunks C that is being stored is viewed as forming a two dimensional R C array. There are X code chunks C for each column C called code check chunks CC that can be used to reconstruct X or fewer damaged chunks per column. There are Y code chunks C called word check chunks WC for the entire 2 D array. When there are more than X damaged chunks in one or more columns C the word check chunks WC are used in addition to other healthy chunks to reconstruct damaged chunks . Although some examples described in this specification illustrate encoded data blocks i.e. data block and code chunks C i.e. non data chunks C as forming a two dimensional array it is possible for coding techniques to create encoded data blocks configured differently. For instance different columns can have different numbers of code check chunks CC i.e. the code check chunk CC and columns C that contain word check chunks WC can have different numbers of rows than columns that contain data chunks D and code check chunks C.

The codes C can be used to store data across resource hosts by allocating each column C of data chunks D to a data center. Each chunk within the columns C can be allocated to a resource host within a data center. Then if X or fewer chunks are lost at a data center the chunks can be reconstructed using only intra data center communication e.g. so no other data centers have to provide data in performing reconstruction . If more than X chunks are lost in one or more data centers then the Y word check chunks WC are used to attempt reconstruction. Thus inter data center communication which may be more expensive e.g. slower than intra data center communication is only needed when more than X chunks are damaged within a single data center.

The codes can also be used within a single data center. Instead of allocating different columns C to different data centers the encoding system stores all of the columns at a single data center. The data chunks D and code chunks C can be stored at distinct resource hosts within that data center. This is useful for example where reading data from resource hosts during reconstruction is expensive e.g. time consuming so that the encoding system can read fewer chunks during reconstruction than would be needed using conventional coding techniques. Small numbers of damaged chunks can be reconstructed by reading small numbers of other chunks code check chunks CC and other data chunks D in the column C and large numbers of damaged chunks can be reconstructed using the word check chunks WC when needed.

Referring to in some implementations a nested coding technique shows data chunks D and code chunks C that form a codeword. As shown the nested coding technique is a two dimensional 2D nested coding technique but a three dimensional 3D nested coding technique may also be applied. A 2D nested code is created from an arbitrary linear MDS code in systematic form. Word check chunks WC that are based on a data block are partitioned into two groups the first group including X code chunks C and the second group including N code chunks C. The block of data is viewed as forming an array of columns C and X code chunks C in the first group are used to create X column chunks per column by splitting them into separate components per column split code check chunks CC . The N code chunks C in the second group form word check chunks WC.

For example shows data block D0 D41 where D0 D41 are data chunks D and code chunks C0 C7 C that are based on the data block D0 D41 316. The data chunks D0 D41 D and the code chunks C0 C7 C form a codeword. The code chunks C are partitioned into a first group that includes C0 C1 and a second group that includes C2 C7. C0 C1 are split to form split code check chunks CC. C2 C7 are used as word check chunks WC.

Referring to a resulting encoded data block that includes the data block D0 D41 and additional code chunks C split code check chunks CC and word check chunks WC is shown. To generate a split code check chunk CC corresponding to C0 for column j denoted C0 j C0 is generated as though all the data chunks D not in column j have the value zero. That is C0 j has the value that would result from performing the operations to generate C0 using the full data block of data chunks D but instead using only the column j with all of the other columns zeroed out. For example if a generator matrix would be used to generate C0 for the full data block then the generator matrix can be modified to generate C0 j so that it has the value that would result from using the original generator matrix and applying that original generator matrix to the data block with data chunks D in columns other than column j zeroed out.

The split code check chunks CC for C1 j for each column C are generated similarly but using C1 instead of C0. As a result C0 is a linear combination of C0 0 C0 6 and C1 is a linear Combination of C1 0 C1 6. That is 0 0 1 and 1 1 2 The chunks denoted as in can be generated in various ways e.g. as described further below with reference to .

In the example of the resulting encoded data block includes 42 data chunks D and 8 code chunks C. Referring to the original code used to create the encoded block the code chunks C belong to one of two groups as described above X 2 of which are in the first group and N 6 of which are in the second group. Whenever there are two or fewer X or fewer damaged chunks within one of the first seven columns the damaged chunks can be corrected using the healthy chunks of the columns C and the split code check chunks CC for the column C. To see this let j denote the column C including the two or fewer damaged chunks and consider the codeword obtained by zeroing out all the data chunks D from columns C other than j. In that codeword C0 C0 j and C1 C1 j. As a result the two or fewer damaged chunks in other columns as containing all zero data chunks D and by viewing the word check chunks WC as being damaged.

In the example shown in the word check chunks WC fully fill an entire column C the column to the right . 2D nested codes can be created with an arbitrary number of columns C of word check chunks WC. The columns C of word check chunks WC can have the same number of rows R as the columns of data chunks D or different numbers of rows R and the columns C of word check chunks WC can have different numbers of rows R from each other. Columns C of word check chunks WC can but do not have to have code check chunks CC i.e. code check word check chunks CCWC. Increasing the number of word check chunks WC improves the reliability of the stored data but uses more storage at resource hosts . In general for nested codes columns C include either data chunks D or word check chunks WC and not both.

In general a 2D nested code with X split code check chunks CC per column C and N word check chunks WC can be used to reconstruct X damaged chunks per column C in those columns that include data chunks D while performing only intra columns communication which is typically e.g. intra data center communication . In reconstructing multiple damaged chunks within the block those damaged chunks are typically reconstructed first because intra column communication is less expensive than inter column communication but other damaged chunks may remain. If after reconstructing damaged chunks within columns N X or fewer other chunks are still damaged because they were not able to be reconstructed using intra column communication those other damaged chunks can be reconstructed using the word check chunks WC and the split code check chunks CC. The word check chunks WC in the first group C0 and C1 can be determined from the split code check chunks CC e.g. using the formula Ci C i j even though those word check chunks WC are not explicitly stored.

To see this let Z denote the number of word check chunks WC that are damaged and let Y denote the number of word check chunks WC in the first group that cannot be reconstructed from their corresponding split code check chunks CC according to the formula Ci C 0 j to split code check chunks CC being damaged. Using that formula X Y word check chunks WC from the first group can be determined resulting in a codeword e.g. the one shown in with Y damaged word check chunks WC in the first group and Z damaged word check chunks WC in the second group. Because there are at most N X total damaged chunks there are at most N X Y Z damaged data chunks D. Thus it is possible to use the resulting codeword to reconstruct all of the damaged chunks as it includes at most N X Y Z Y Z N X damaged chunks .

Referring to in some implementations the resulting encoded block includes code check chunks CC for the word check chunks WC i.e. code check word check chunks CCWC . Compared to the encoded block of the block of includes the code check chunks C0 7 and C1 7 CC in place of the locations marked with in . This is one way to provide for reconstructing damaged word check chunks WC without relying on inter column communication. The code check chunks C0 7 and C1 7 CC can be generated in various ways. For example those code check chunks CC can be generated based on C2 C7 in the same manner that C0 0 and C1 0 are generated based on D0 D5. The resulting encoded block of using the example nested code can be used to reconstruct up to eight damaged chunks after performing intra column reconstruction. Code check chunks C can be added for any number of columns that include word check chunks WC.

Referring to in some implementations the curator distributes data using a nested code . The system receives a data block step . The data block can include m ndata chunks C where mis a number of data rows and nis a number of data columns and mand nare greater than or equal to one. The encoded block includes m n chunks that include m n where n is the total number of rows R of data chunks D and non data chunks C and n is the number of columns C of data chunks D and non data chunks C in and n are greater than or equal to one. The system generates one or more columns C of word check chunks WC using a first linear error correcting code in systematic form and the data chunks D step . The word check chunks WC and the data chunks D of the same row R form a codeword. For each of mrow of data chunks D the system generates one or more split code check chunks CC for the column C step . The split code check chunks CC are generated so that a linear combination of n split code check chunks CC from different columns C forms a first word check chunk WC of a first codeword including the data chunks D and the m word check chunks WC. The first word check chunk WC and any other word check chunks WC resulting from a linear combination of split code check chunks CC from different columns C forms a codeword with the data chunks D and the word check chunks WC generated in step . For example the split code check chunks CC for each columns C can be generated using a splitting error correcting code and the mdata chunks D or the word check chunks WC wherein the splitting error correcting code includes a splitting generator matrix that codes the same as a generator matrix for the first linear error correcting code applied to the data chunks D with the data chunks D zeroed out for columns C other than the column C.

The system stores the column C of data chunks D and the split code check chunks CC and the word check chunks WC step . In some implementations the system stores all the chunks at a single group of resource hosts . In some other implementations the system allocates each column C to a distinct group of resource hosts . When the system identifies one or more damaged chunks the system can reconstruct the damaged chunks using the split code check chunks CC and the word check chunks WC. Typically the system attempts to reconstruct damaged chunks using the split code check chunks CC and other data chunks in the same column C. If after reconstructing damaged chunks using only the split code check chunks CC some damaged chunks remain the system uses the word check chunks WC for reconstruction including the word check chunks WC that can be determined by determining a linear combination of the split code check chunks CC. In some examples when there are multiple losses the system uses any of the chunks including data chunks D.

The storage system or portions thereof may undergo a system failure for a period of time. The data distributed on the resource hosts of the storage system may not be available for users. For example referring back to a resource host may be undergoing maintenance or has a system failure therefore data e.g. stripe replicas data chunks D and non data chunks C stored on the resource host may not be retrievable i.e. the data is inaccessible . In addition the resource host may take an extended period of time e.g. a week to be functional or for maintenance to be completed. Within the period during which the resource host is not available the storage system may recover the lost data so that the data is available if a user makes a file request .

Referring to the curator may determine or receive a system hierarchy of the distributed storage system to identify the levels e.g. levels 1 4 at which maintenance or failure may occur without affecting a user s access to stored data . Maintenance or failures strict hierarchy non strict hierarchy may include power maintenance failures cooling system maintenance failures networking maintenance failures updating or replacing parts or other maintenance or power outage affecting the distributed storage system . Maintenance may be scheduled and in some examples an unscheduled system failure may occur.

The system hierarchy includes system levels e.g. levels 1 4 with maintenance units system domains spanning one or more system levels 1 4. Each system domain has an active state or an inactive state. A distribution center module includes one or more cells and each cell includes one or more racks of resource hosts . Each cell also includes cell cooling cell power e.g. bus ducts and cell level networking e.g. network switch es . Similarly each rack includes rack cooling rack power e.g. bus ducts and rack level networking e.g. network switch es .

The system levels may include first second third and fourth system levels 1 4. The first system level 1 corresponds to resource hosts or host machines of data processing devices non transitory memory devices or network devices e.g. NICs . Each host machine resource host has a system domain . The second system level 2 corresponds to racks and cooling deliverers power deliverers e.g. bus ducts or communication deliverers e.g. network switches and cables of the host machines at the rack level. Each rack or rack level cooling deliverer power deliverer or communication deliverer has a system domain . The third system level 3 corresponds to any cells of the distribution center module and the cell cooling cell power or cell level networking supplied to the associated racks . Each cell or cell cooling cell power or cell level networking has a system domain . The fourth system level 4 corresponds to the distribution center module . Each distribution center module has a system domain .

The curator determines based on the mappings of the hierarchy components which resource hosts are inactive when a hierarchy component is undergoing maintenance. Once the curator maps the system domains to the resource hosts and therefore to their corresponding processor resources and storage resources the curator determines a highest level e.g. levels 1 4 at which maintenance can be performed while maintaining processor or data availability.

A system domain includes a hierarchy component undergoing maintenance and any hierarchy components depending therefrom. Therefore when one hierarchy component undergoes maintenance that hierarchy component is inactive and any other hierarchy components in the system domain of the hierarchy component are also inactive. For example when a resource host undergoes maintenance a level 1 system domain which includes the storage device the data processor and the NIC is in the inactive state. When a rack undergoes maintenance a level 2 system domain which includes the rack and any resource hosts depending from the rack is in the inactive state. When a cell component for example to any one of the cell cooling component the bust duct and or the network switch of the cell component undergoes maintenance a level 3 system domain which includes the cell and any hierarchy components in levels 3 and 4 that depend from the cell component is in the inactive state. Finally when a distribution center module undergoes maintenance a level 4 system domain which includes the distribution center module and any hierarchy components in levels 2 to 4 depending from the distribution center module is in the inactive state.

In some examples as shown in a non strict hierarchy component may have dual feeds i.e. the hierarchy component depends on two or more other hierarchy components . For example a cell component may have a feed from two distribution center modules and or a rack may have a dual feed from two cell components . As shown a level 2 system domain may include two racks where the second rack includes two feeds from two cell components . Therefore the second rack is part of two system domains and . Therefore the lower levels of the system hierarchy are maintained without causing the loss of the higher levels of the system hierarchy . This causes a redundancy in the distributed storage system which allows for data accessibility. In particular the distribution center module may be maintained without losing any of the cell components depending from it. In some examples the racks include a dual powered rack that allows the maintenance of the bus duct without losing power to the dual powered racks depending from it. In some examples system domains that may be maintained without causing outages are ignored when distributing chunks to allow for maintenance however the ignored system domains may be included when distributing the chunks since an unplanned outage may still cause the loss of chunks .

In some examples a cooling device such as the cell cooling and the rack cooling are used to cool the cell components and the racks respectively. The cell cooling component may cool one or multiple cell components . Similarly a rack cooling component may cool one or more racks . The curator stores the association of the resource hosts with the cooling devices i.e. the cell cooling and the rack cooling . In some implementations the curator considers all possible combinations of maintenance that might occur within the storage system to determine a system hierarchy or a combination of maintenance hierarchies before storing the association of the resource hosts with the cooling devices for example a system hierarchy where one or more cooling devices fail or a system hierarchy where the network devices fail or a system hierarchy where the power distribution fails.

Therefore when a hierarchy component in the storage system undergoes maintenance or failures that hierarchy component and any hierarchy components that are mapped to or depending from that hierarchy component are in an inactive state. A hierarchy component in an inactive state is inaccessible by a user while a hierarchy component in an active state is accessible by a user allowing the user to process access data stored supported maintained by that hierarchy component . As previously mentioned during the inactive state a user is incapable of accessing the resource host associated with the system domains undergoing maintenance and therefore the client is incapable of accessing the files i.e. chunks which include stripe replicas data chunks D and non data chunks C .

In some implementations the curator restricts a number of chunks distributed to storage devices of any one system domain e.g. based on the mapping of the hierarchy components . Therefore if a level 1 system domain is inactive the curator maintains accessibility to the file or stripe although some chunks may be inaccessible. In some examples for each file or stripe the curator determines a maximum number of chunks that may be placed within any storage device within a single system domain so that if a system domain associated with the storage device storing chunks for a file is undergoing maintenance the curator may still retrieve the file . The maximum number of chunks ensures that the curator is capable of reconstructing the file although some chunks may be unavailable. In some examples the maximum number of chunks is set to a lower threshold to accommodate for any system failures while still being capable of reconstructing the file from the chunks . When the curator places chunks on the storage devices the curator ensures that within a stripe no more than the maximum number of chunks are inactive when a single system domain undergoes maintenance. Moreover the curator may also restrict the number of processing jobs on a data processor of a resource host within a system domain e.g. based on the mapping of the hierarchy components . Therefore if a level 1 system domain is inactive the curator maintains accessibility to the jobs although some of the processors of the resource hosts are inactive.

Referring to scheduled and unscheduled maintenance failure events cause a decrease in the storage system capacity to store data and an increase in the cost of each job or storage bandwidth since some of the jobs require data reconstruction . For example during normal operation of the system 100 of the storage devices or the total storage resources S are available and can handle 100 of the operations or load L associated with the total resources S e.g. a number of input output operations per second allowed to hard disk storage or the amount of hard disk spindle utilization access allowed for such storage for storing data on the storage devices of the resource hosts see . The system may experience a failure or a maintenance event causing a portion of the total resources S to be inaccessible. Losing a portion of the resources R leads to losing a portion of the load Lthat was handled by the lost resources R . Therefore as shown in the remaining resources Rcan handle an associated load Lthat is associated with the remaining resources R. Referring to the system determines an adjusted load Lthat the remaining resources Rhandle during the maintenance or failure event. The adjusted load Lis greater than the load Lassociated with the remaining resources S therefore the remaining resources Shandle a greater load due to a maintenance or failure event.

For example if the system experiences a failure event or a maintenance event causing 5 of the resources to become unavailable the storage capacity or remaining resources available Sis reduced to 95 which is a decrease of 5 from the 100 of the available resources . In addition 5 lost resources Scauses a loss in the load or operations handled by the 5 of the resources lost S. The system increases the load Lof the remaining resources to compensate for the load Lassociated with the lost resources S. During a failure or maintenance event the cost of an operation i.e. the number of read operations or write operations to reconstruct the data increases because the system has to reconstruct data that was lost due to the 5 reduced capacity. Therefore the system determines the increase in the load to reconstruct lost data associated with the lost resources S before determining the adjusted load Lassociated with the remaining resources S.

As previously described replication encoding and erasure coding e.g. Reed Solomon and nested coding are often used to provide data availability when a failure or maintenance occurs. In the case of replicated encoding lost data is replicated and relocated and therefore a direct data access is available without the need for reconstructing the data . However for erasure codes direct data may become unavailable and may require expensive data reconstruction. In some examples the different erasure coding may have a different cost of reconstruction. A cost of reconstruction is the additional operations needed to reconstruct the lost data . For each lost chunk requiring one read of an erasure encoded data a reconstruction scaling factor F of reads is needed to reconstruct the lost chunk . For example if one chunk is lost due to a lost resource a number of chunks e.g. 2 or more are needed to reconstruct the lost chunks . The reconstruction cost leads to an increase in the load adjusted load L handled by the available or remaining resources S. The increased load Lto reconstruct the lost data of the lost resources Sis calculated using the following equation 3 where Lis the quantity of load lost that is associated with the lost resources S. The system increases the load Lassociated with the remaining resources Sand determines an adjusted load L. The adjusted load Lon the remaining resources Sduring a maintenance or failure event is determined by the following equation 4 where Lis the load handled by the remaining resources Sduring a failure or maintenance event. Eq. 3 and Eq. 4 may be combined into Eq. 5 below 5A 

Referring to and using Reed Solomon for encoding the data the reconstruction scaling factor F may equal 8 which means for every lost chunk an additional 8 reads are needed to reconstruct the lost data . Other reconstruction scaling factors F are possible as well. Therefore a 5 loss of the resources results in the following 95 5 8 135 5B 

Thus a 5 loss of resources leads to a 135 usage of the resources to reconstruct the data lost due to the 5 loss. Assuming that 100 of resources equals to 1000 operations per second where an operation is a read or a write operation a 5 loss of the storage resources results in 95 available resources or 950 operations per second. Applying the above equation 950 ops s 8 50 ops sec 1350 ops s 5C 

Therefore to recover a loss of 50 operations per second 400 operations per second 8 50 are needed which totals 1350 operations per second.

The calculations determined with respect to the Reed Solomon encoding may also be applied to nested coding. Referring to for example assuming that the reconstruction scaling factor F of the nested coding equals 2 and a 5 loss of resources has occurred applying Eq. 5A results in the following 95 2 5 105 5D 

Thus a loss of 5 of the resources in a nested code encoded system results in a total load increase of 105 . Considering that 100 of resources equals to 1000 operations per second where an operation is a read or a write operation a 5 loss of the resources results in 95 available resources or 950 operations per second. Applying the above equation 950 ops s 2 50 ops s 1050 ops s 5E 

Therefore to recover a loss of 50 operations per second 100 operations per second 2 50 are needed which totals 1050 operations per second. Other reconstruction scaling factors F for nested encoded data are possible as well however generally the reconstruction scaling factors F for nested encoding is less than the reconstruction scaling factors F for nested encoding for Reed Solomon coding.

Considering the Reed Solomon example and the nested coding example the increased load Lis directly related to the reconstruction scaling factor F. The larger the reconstruction scaling factor F the larger the load increase Land therefore the adjusted load L.

Referring to in some implementations the system identifies two classes of jobs requests . A first class of jobs includes high availability jobs and a second class includes standard or low availability jobs . The system executes processing jobs on the processor of the resource host and storage jobs for accessing storing data on the storage devices of the resource hosts . The high availability jobs are jobs that have a higher priority than the low availability jobs when both types of jobs are within a quota discussed below . In some examples when a maintenance event or a failure occurs the system accommodates for the lost load associated with the lost resources by increasing the load or spindle quotas allocated to the remaining resources.

Referring to in some implementations during a failure or a maintenance event the system gives the high availability jobs a higher priority than the low availability jobs . In some examples the system applies a best effort to the low availability jobs to complete the low availability jobs . This causes a decrease in the data accessed or requested by the low availability jobs which allows the system to use the freed up spindles to adjust an increase in the load of the high availability jobs . Therefore the low availability spindle usage or load can be distributed to the high availability jobs during the maintenance or failure event. The spindle quota or portions thereof used for the low availability jobs may be redistributed to the high availability jobs

In some implementations the spindles are balanced across all the hierarchy components and all job requests are high availability job requests using nested coding. A high availability spindle job quota may be determined from the following values a number P of hierarchy components a number of reads per degraded mode read D degraded mode read is when a reconstruction occurs to read the data chunk D and a fraction of the spindle utilization used for the read operations Rwhen all the hierarchy components are available.

In some examples the high availability job requests may include read requests Rand write requests R as shown in the below equation 6 where Ris a number cost e.g. resource utilization cost or spindle usage of read requests and Ris a number cost e.g. resource utilization cost or spindle usage of write requests. Since R is the total number of requests then we can rewrite the previous equation in terms of fractions to determine the value of the write request in fractions R 1 7 where Ris a fraction of the spindle utilization going to write requests and Ris a fraction of the spindle utilization going to read requests when all the resources R are available i.e. when there are no failure or maintenance events.

In some implementations assuming that the only requests are read operations when a maintenance event occurs an increased load per spindle results due to a decreased spindle power or the number of available spindles and an increased chunk reads. The chunk reads increase because more reads are needed to reconstruct the chunks that were lost due to the maintenance event that caused the loss of the storage resources storing these lost chunks . Therefore to determine the number of reads per spindle factor Rgiven a loss of one hierarchy component we use the following equation 

To determine the read maximum fraction R we consider the reciprocal of the number of reads per spindle factor R 

Considering the above equations Eq. 8A and Eq. 9A let s assume that the data chunks D are distributed throughout hierarchy component i.e. P 10 and that it takes 3 reads to reconstruct one chunk lost due to the maintenance or failure event i.e. D 3. We can calculate the number of reads per spindle factor Rby applying the Eq. 8A 

Determining the read maximum fraction R we consider the reciprocal of the number of reads per spindle factor R 

Thus for nested coding when P 10 and D 3 the number of reads per spindle factor Rgiven a loss of one hierarchy component equals 1.333 on the available storage resources Sthat are handling the adjusted load L.

Eqs. 8A and 9A are discussed with respect to nested coding but may be applied to replicated coding and Reed Solomon coding as shown in Table 1 and Table 2 below. Table 1 shows exemplary calculations for Eq. 8A to determine the number of reads per spindle factor R and Table 2 shows exemplary calculations for Eq. 9A to determine the read maximum fraction R. The calculations assume that only one hierarchy component is lost. The calculations assume that all the requested jobs are high availability read jobs however the same calculations may apply if all the jobs are low availability read jobs .

Assuming that the requests are high availability read and write requests during a failure or a maintenance event the requests for the read maximum fraction R when all storage resources are available increases to include the impact of the lost data and the reads required to reconstruct the lost data . Therefore the adjusted request for reads Rmay be determined using the following equation 

The overall spindle demand Rmust be supported by the fraction of the remaining spindles yielding an increase in demand per spindle of P P 1 . To determine the fraction spindle quota increase for the high availability jobs R we consider 

To determine the fraction spindle quota Ravailable for the high availability jobs we consider the reciprocal of the above equation 

As an example applying Eqs. 6 through 12 Requals which means that of the job requests are used for reading and the remaining of the requests Rare used for writing. Considering a nested code having n 3 4.3 1 4 1 where there are 3 4 data chunks D 3 1 word check chunks WC 4 code check chunks CC and 1 code check word check chunk CCWC for the given nested code D 3 which comes from the first digit to the right of the equals sign . Therefore the fraction of spindle quota that can be used for high availability requests may be determined by applying Eq. 12 

Eqs. 12 and 13A are discussed with respect to nested coding but may be applied to replicated coding and Reed Solomon coding as shown in Table 3 and Table 4 below. Table 3 shows exemplary calculations for Eq. 12 to determine the number of reads Rper spindle factor and Table 4 shows exemplary calculations for Eq. 13 to determine the read maximum fraction R. The calculations assume that only one hierarchy component is lost. The calculations also assume that all the requested jobs are high availability jobs read and write jobs however the same calculations may apply if all the jobs are low availability jobs .

The above formulas are used to calculate the high availability spindle fraction Rconsidering that all the jobs are high availability jobs using nested coding. Another consideration taken is that all the data i.e. chunks are evenly distributed within the hierarchy component . However the data may not be evenly distributed throughout the hierarchy component which may lead to a decrease in the high availability spindle fraction Rthat is available. Moreover in some examples not all the data is encoded with nested codes. For example if some data is replicated data it does not increase the demand for reads when a hierarchy component is lost. Therefore having data that is replicated would tend to increase the high availability spindle fraction R.

In some implementations the bytes and the spindles are evenly balanced across the hierarchy components . When determining the spindle quota the important factor is the distribution of the spindles rather than the bytes across the hierarchy components . Therefore when the spindles are not evenly distributed across the hierarchy components consider the parameter P above to be the largest integer such that at most 1 P of the spindles are located on any one of the hierarchy components . In this instance the above formula can be used to calculate the fraction of spindle quota that can be used for the high availability requests

In general when a hierarchy component is lost due to maintenance or failure the low availability requests are evicted and they receive no spindle quota or a best effort is applied. However in some examples additional temporary resources may be available during maintenance on all or many of the hierarchy components . In such an instance both high availability jobs and low availability jobs continue their operation with one lost hierarchy component . The following equations determine the quantity of temporary spindles that are required to maintain the operation of the high availability and the low availability jobs . Previously only high availability jobs were considered but in this case both high availability jobs and low availability jobs are considered. To determine the quantity of temporary spindles that are required the following values are used the number P of hierarchy components a number Dof reads per degraded mode read for high availability jobs a number of reads Dper degraded mode read for low availability jobs and a fraction of the spindle utilization used for the read operations Rwhen all the hierarchy components are available.

In some examples when one hierarchy component is lost the high availability jobs create a load per spindle on the remaining spindles that equals the total load per spindle when no hierarchy components are lost. In addition to this load per spindle denoted as 1 the low availability requests create additional load as quantified below. First let

The above equation Eq. 17 may be used to determine the high availability spindle usage Fincreased by a factor Mof 

Moreover after a hierarchy components is lost a total of low availability usage per spindle Fis determined by the following equation 

Adding the low availability spindle usage per spindle Fto the per spindle high availability usage results in the following equation 

In some examples applying Eqs. 14A 16A and 19A consider Requals which means that of the requests are used for reading and the remaining of the requests Rare used for writing. For D 3 assuming that Dequals 8 which models the case of all non SC data being encoded with rs 8.4 and P 40 which corresponds to a 20 MW cell with 500 kW bus ducts . In the examples we assume that only the low availability jobs increase the spindle requirement.

For every spindle that is normally present in the cell an additional 0.065 temporary spindles should be added in order to allow both high availability and low availability job requests to operate during maintenance as determines as follows 1 0.944 1.145 0.065 19B 

Considering another example applying the above Eqs. 14A 16A and 19A consider Requals which means that of the requests are used for reading and the remaining of the requests Rare used for writing. For D 3 assuming that Dequals 8 which models the case of all non SC data being encoded with rs 8.4 and P 60 which corresponds to a 20 MW cell with 500 kW bus ducts .

For every spindle that is normally present in the cell an additional 0.042 temporary spindles should be added in order to allow both high availability and low availability job requests to operate during maintenance as determined as follow 1 0.962 1.096 0.042 19C 

Referring to in some implementations a method for efficiently using resources e.g. memory devices in data centers of a distributed storage system includes identifying high availability jobs and low availability jobs that demand usage of resources of the distributed system . The method further includes allocating resource usage to the jobs determining a first load of the jobs on resources available during a failure event and determining a second load of the jobs on the resources lost during the failure event. The method includes determining a scaled third load of the jobs on the resources available during the failure event based on the first and second loads and reallocating resource usage assigned to the low availability jobs to the high availability jobs during the failure event. The reallocation is associated with the scaled third load of the jobs .

In some implementations the high availability jobs have a higher execution priority than the low availability jobs . The resources may include non transitory memory devices. The method includes determining the scaled third load of the jobs using Eq. 5A. When the resources include data storage resources having spindles and the jobs all include high availability read jobs or low availability read jobs the method includes determining a number of read requests per spindle Rusing Eq. 8A. The method includes reallocating the resource usage based on the read requests per spindle R. Additionally or alternatively the method includes determining a read maximum fraction Rusing Eq. 9A. The method includes reallocating the resource usage based on the read maximum fraction R.

In some implementations when the resources include data storage resources having spindles and the jobs all include high availability jobs or low availability jobs the method includes determining an adjusted request for read operations Rduring the failure event using Eq. 10. The method includes reallocating the resource usage based on the adjusted request for read operations. Additionally or alternatively the method includes determining an overall spindle demand Rduring the failure event using Eq. 11. The method includes reallocating the resource usage based on the overall spindle demand Rduring the failure event. The method may further include determining a fraction spindle quota increase Rper spindle using Eq. 12. The method includes reallocating the resource usage based on the fraction spindle quota increase. Additionally or alternatively the method includes determining a fraction spindle quota Ravailable for the high availability jobs using Eq. 13. The method includes reallocating the resource usage based on the fraction spindle quota R.

In some examples the method includes determining a low availability scaled third load of the jobs on temporary resources available during the failure event based on the first and second loads of low availability jobs . When the resources include data storage resources having spindles the method may include determining a fraction of high availability spindle usage Fprior to the failure event using Eq. 14A. The method includes reallocating the resource usage based on the fraction of high availability spindle usage F. Additionally or alternatively the method includes determining an increase factor of low availability job usage Musing Eq. 16A. The method includes reallocating the resource usage based on the increase factor of low availability job usage M.

In some implementations the method includes determining a total of low availability usage per spindle Fafter a resource is lost using Eq. 19A. The method includes reallocating the resource usage based on the total of low availability usage per spindle F. Additionally or alternatively the method includes determining a total spindle usage Fusing Eq. 21. The method includes reallocating the resource usage based on the total spindle usage.

Referring to in some implementations a method includes identifying high availability jobs and low availability jobs that demand usage of data storage resources of a distributed storage system . The data storage resource has spindles. The method further includes determining a spindle quota for the high availability jobs and determining a spindle quota for the low availability jobs . The method further includes redistributing at least a portion of the spindle quota associated with the low availability jobs to the high availability jobs during a failure event.

In some examples when the jobs all include high availability read jobs or low availability read jobs the method includes determining a number of read requests per spindle Rwhen a loss of at least one data storage resource occurs using Eq. 8A. The method also includes determining a read maximum fraction Rusing Eq. 9A. The method includes reallocating the resource usage based on the read requests per spindle Ror the read maximum fraction R.

In some implementations when the jobs all include high availability jobs or low availability jobs the method includes determining a fraction spindle quota increase Rper spindle using Eq. 12 and a fraction spindle quota Ravailable for the high availability jobs using Eq. 13. The method includes reallocating the resource usage based on the fraction spindle quota increase Ror the fraction spindle quota R. The method further includes determining a low availability scaled third load of the jobs on temporary resources available during the failure event based on the first and second loads of availability jobs .

In some examples when the resources include data storage resources having spindles the method includes determining a fraction of high availability spindle usage Fprior to the failure event using Eq. 14A. The method includes reallocating the resource usage based on the fraction of high availability spindle usage F. Additionally or alternatively the method includes determining an increase factor of low availability job usage Musing Eq. 16A and determining a total of low availability usage per spindle Fafter a resource is lost using Eq. 19A. The method includes reallocating the resource usage based on the total of low availability usage per spindle F. The method may further include determining a total spindle usage Fusing Eq. 21. The method includes reallocating the resource usage based on the total spindle usage F.

Various implementations of the systems and techniques described here can be realized in digital electronic circuitry integrated circuitry specially designed ASICs application specific integrated circuits computer hardware firmware software and or combinations thereof. These various implementations can include implementation in one or more computer programs that are executable and or interpretable on a programmable system including at least one programmable processor which may be special or general purpose coupled to receive data and instructions from and to transmit data and instructions to a storage system at least one input device and at least one output device.

These computer programs also known as programs software software applications or code include machine instructions for a programmable processor and can be implemented in a high level procedural and or object oriented programming language and or in assembly machine language. As used herein the terms machine readable medium and computer readable medium refer to any computer program product apparatus and or device e.g. magnetic discs optical disks memory Programmable Logic Devices PLDs used to provide machine instructions and or data to a programmable processor including a machine readable medium that receives machine instructions as a machine readable signal. The term machine readable signal refers to any signal used to provide machine instructions and or data to a programmable processor.

Implementations of the subject matter and the functional operations described in this specification can be implemented in digital electronic circuitry or in computer software firmware or hardware including the structures disclosed in this specification and their structural equivalents or in combinations of one or more of them. Moreover subject matter described in this specification can be implemented as one or more computer program products i.e. one or more modules of computer program instructions encoded on a computer readable medium for execution by or to control the operation of data processing apparatus. The computer readable medium can be a machine readable storage device a machine readable storage substrate a memory device a composition of matter affecting a machine readable propagated signal or a combination of one or more of them. The terms data processing apparatus computing device and computing processor encompass all apparatus devices and machines for processing data including by way of example a programmable processor a computer or multiple processors or computers. The apparatus can include in addition to hardware code that creates an execution environment for the computer program in question e.g. code that constitutes processor firmware a protocol stack a database management system an operating system or a combination of one or more of them. A propagated signal is an artificially generated signal e.g. a machine generated electrical optical or electromagnetic signal that is generated to encode information for transmission to suitable receiver apparatus.

A computer program also known as an application program software software application script or code can be written in any form of programming language including compiled or interpreted languages and it can be deployed in any form including as a stand alone program or as a module component subroutine or other unit suitable for use in a computing environment. A computer program does not necessarily correspond to a file in a file system. A program can be stored in a portion of a file that holds other programs or data e.g. one or more scripts stored in a markup language document in a single file dedicated to the program in question or in multiple coordinated files e.g. files that store one or more modules sub programs or portions of code . A computer program can be deployed to be executed on one computer or on multiple computers that are located at one site or distributed across multiple sites and interconnected by a communication network.

The processes and logic flows described in this specification can be performed by one or more programmable processors executing one or more computer programs to perform functions by operating on input data and generating output. The processes and logic flows can also be performed by and apparatus can also be implemented as special purpose logic circuitry e.g. an FPGA field programmable gate array or an ASIC application specific integrated circuit .

Processors suitable for the execution of a computer program include by way of example both general and special purpose microprocessors and any one or more processors of any kind of digital computer. Generally a processor will receive instructions and data from a read only memory or a random access memory or both. The essential elements of a computer are a processor for performing instructions and one or more memory devices for storing instructions and data. Generally a computer will also include or be operatively coupled to receive data from or transfer data to or both one or more mass storage devices for storing data e.g. magnetic magneto optical disks or optical disks. However a computer need not have such devices. Moreover a computer can be embedded in another device e.g. a mobile telephone a personal digital assistant PDA a mobile audio player a Global Positioning System GPS receiver to name just a few. Computer readable media suitable for storing computer program instructions and data include all forms of non volatile memory media and memory devices including by way of example semiconductor memory devices e.g. EPROM EEPROM and flash memory devices magnetic disks e.g. internal hard disks or removable disks magneto optical disks and CD ROM and DVD ROM disks. The processor and the memory can be supplemented by or incorporated in special purpose logic circuitry.

To provide for interaction with a user one or more aspects of the disclosure can be implemented on a computer having a display device e.g. a CRT cathode ray tube LCD liquid crystal display monitor or touch screen for displaying information to the user and optionally a keyboard and a pointing device e.g. a mouse or a trackball by which the user can provide input to the computer. Other kinds of devices can be used to provide interaction with a user as well for example feedback provided to the user can be any form of sensory feedback e.g. visual feedback auditory feedback or tactile feedback and input from the user can be received in any form including acoustic speech or tactile input. In addition a computer can interact with a user by sending documents to and receiving documents from a device that is used by the user for example by sending web pages to a web browser on a user s client device in response to requests received from the web browser.

One or more aspects of the disclosure can be implemented in a computing system that includes a backend component e.g. as a data server or that includes a middleware component e.g. an application server or that includes a frontend component e.g. a client computer having a graphical user interface or a Web browser through which a user can interact with an implementation of the subject matter described in this specification or any combination of one or more such backend middleware or frontend components. The components of the system can be interconnected by any form or medium of digital data communication e.g. a communication network. Examples of communication networks include a local area network LAN and a wide area network WAN an inter network e.g. the Internet and peer to peer networks e.g. ad hoc peer to peer networks .

The computing system can include clients and servers. A client and server are generally remote from each other and typically interact through a communication network. The relationship of client and server arises by virtue of computer programs running on the respective computers and having a client server relationship to each other. In some implementations a server transmits data e.g. an HTML page to a client device e.g. for purposes of displaying data to and receiving user input from a user interacting with the client device . Data generated at the client device e.g. a result of the user interaction can be received from the client device at the server.

While this specification contains many specifics these should not be construed as limitations on the scope of the disclosure or of what may be claimed but rather as descriptions of features specific to particular implementations of the disclosure. Certain features that are described in this specification in the context of separate implementations can also be implemented in combination in a single implementation. Conversely various features that are described in the context of a single implementation can also be implemented in multiple implementations separately or in any suitable sub combination. Moreover although features may be described above as acting in certain combinations and even initially claimed as such one or more features from a claimed combination can in some cases be excised from the combination and the claimed combination may be directed to a sub combination or variation of a sub combination.

Similarly while operations are depicted in the drawings in a particular order this should not be understood as requiring that such operations be performed in the particular order shown or in sequential order or that all illustrated operations be performed to achieve desirable results. In certain circumstances multi tasking and parallel processing may be advantageous. Moreover the separation of various system components in the embodiments described above should not be understood as requiring such separation in all embodiments and it should be understood that the described program components and systems can generally be integrated together in a single software product or packaged into multiple software products.

A number of implementations have been described. Nevertheless it will be understood that various modifications may be made without departing from the spirit and scope of the disclosure. Accordingly other implementations are within the scope of the following claims. For example the actions recited in the claims can be performed in a different order and still achieve desirable results.

